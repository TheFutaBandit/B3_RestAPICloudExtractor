Bug_ID,Bug_Summary,Bug_Description
HIVE-27724,Upgrade ivy for CVE-2022-46751 fix,Upgrade org.apache.ivy:ivy from 2.5.1 to 2.5.2 to fix the vulnerability.
HIVE-24807,Unknown column 'B0.CATALOG_NAME' in 'where clause',"I am trying hive-rel-release-3.1.0 on Hadoop 3.1.1 . when start hiveserver2, I get error log below:

 

2021-02-22T14:03:13,308 ERROR [pool-8-thread-33] metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOException: Exception thrown when executing query : SELECT DISTINCT 'org.apache.hadoop.hive.metastore.model.MFunction' AS `NUCLEUS_TYPE`,`A0`.`CLASS_NAME`,`A0`.`CREATE_TIME`,`A0`.`FUNC_NAME`,`A0`.`FUNC_TYPE`,`A0`.`OWNER_NAME`,`A0`.`OWNER_TYPE`,`A0`.`FUNC_ID` FROM `FUNCS` `A0` LEFT OUTER JOIN `DBS` `B0` ON `A0`.`DB_ID` = `B0`.`DB_ID` WHERE `B0`.`CATALOG_NAME` = ?
 at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:677)
 at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:391)
 at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:228)
 at org.apache.hadoop.hive.metastore.ObjectStore.getAllFunctions(ObjectStore.java:9393)
 at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
 at com.sun.proxy.$Proxy26.getAllFunctions(Unknown Source)
 at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_all_functions(HiveMetaStore.java:7102)
 at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
 at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
 at com.sun.proxy.$Proxy27.get_all_functions(Unknown Source)
 at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_all_functions.getResult(ThriftHiveMetastore.java:17242)
 at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_all_functions.getResult(ThriftHiveMetastore.java:17226)
 at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
 at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:636)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:631)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:631)
 at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
NestedThrowablesStackTrace:
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown column 'B0.CATALOG_NAME' in 'where clause'
 at sun.reflect.GeneratedConstructorAccessor45.newInstance(Unknown Source)
 at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
 at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
 at com.mysql.jdbc.Util.handleNewInstance(Util.java:408)
 at com.mysql.jdbc.Util.getInstance(Util.java:383)
 at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1062)
 at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4226)
 at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:4158)
 at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2615)
 at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2776)
 at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2840)
 at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2082)
 at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2212)
 at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)
 at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)
 at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeQuery(ParamLoggingPreparedStatement.java:375)
 at org.datanucleus.store.rdbms.SQLController.executeStatementQuery(SQLController.java:552)
 at org.datanucleus.store.rdbms.query.JDOQLQuery.performExecute(JDOQLQuery.java:617)
 at org.datanucleus.store.query.Query.executeQuery(Query.java:1855)
 at org.datanucleus.store.query.Query.executeWithArray(Query.java:1744)
 at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:368)
 at org.datanucleus.api.jdo.JDOQuery.execute(JDOQuery.java:228)
 at org.apache.hadoop.hive.metastore.ObjectStore.getAllFunctions(ObjectStore.java:9393)
 at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
 at com.sun.proxy.$Proxy26.getAllFunctions(Unknown Source)
 at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_all_functions(HiveMetaStore.java:7102)
 at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
 at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
 at com.sun.proxy.$Proxy27.get_all_functions(Unknown Source)
 at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_all_functions.getResult(ThriftHiveMetastore.java:17242)
 at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_all_functions.getResult(ThriftHiveMetastore.java:17226)
 at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
 at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:636)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor$1.run(HadoopThriftAuthBridge.java:631)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
 at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:631)
 at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)"
HIVE-22522,llap doesn't work using complex join operation,"ERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. 
 Dag received [DAG_TERMINATE, SERVICE_PLUGIN_ERROR] in RUNNING state.
 Error reported by TaskScheduler [[2:LLAP]][SERVICE_UNAVAILABLE] 
 No LLAP Daemons are runningVertex killed, vertexName=Reducer 3, vertexId=vertex_1574126686177_0029_47_08,
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED, 
 failedTasks:0 killedTasks:1, Vertex vertex_1574126686177_0029_47_08 [Reducer 3] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Map 1, vertexId=vertex_1574126686177_0029_47_05, 
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED,
 failedTasks:0 killedTasks:23, Vertex vertex_1574126686177_0029_47_05 [Map 1] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1574126686177_0029_47_07, 
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED,
 failedTasks:0 killedTasks:68, Vertex vertex_1574126686177_0029_47_07 [Reducer 2] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Reducer 4, vertexId=vertex_1574126686177_0029_47_06,
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED,
 failedTasks:0 killedTasks:72, Vertex vertex_1574126686177_0029_47_06 [Reducer 4] killed/failed due to:
 DAG_TERMINATED]DAG did not succeed due to SERVICE_PLUGIN_ERROR. failedVertices:0 killedVertices:4
INFO : Completed executing command(queryId=hive_20191120101841_c7d177d8-28bb-48f8-a14f-eb653333fc3b); 
Time taken: 557.077 seconds
Error: Error while processing statement: FAILED: Execution Error,
 return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. 
 Dag received [DAG_TERMINATE, SERVICE_PLUGIN_ERROR] in RUNNING state.
 Error reported by TaskScheduler [[2:LLAP]][SERVICE_UNAVAILABLE] 
 No LLAP Daemons are runningVertex killed, vertexName=Reducer 3, vertexId=vertex_1574126686177_0029_47_08,
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED, 
 failedTasks:0 killedTasks:1, Vertex vertex_1574126686177_0029_47_08 [Reducer 3] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Map 1, vertexId=vertex_1574126686177_0029_47_05, 
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED, 
 failedTasks:0 killedTasks:23, Vertex vertex_1574126686177_0029_47_05 [Map 1] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Reducer 2, vertexId=vertex_1574126686177_0029_47_07, 
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED, 
 failedTasks:0 killedTasks:68, Vertex vertex_1574126686177_0029_47_07 [Reducer 2] killed/failed due to:
 DAG_TERMINATED]Vertex killed, vertexName=Reducer 4, vertexId=vertex_1574126686177_0029_47_06, 
 diagnostics=[Vertex received Kill while in RUNNING state., Vertex did not succeed due to DAG_TERMINATED, 
 failedTasks:0 killedTasks:72, Vertex vertex_1574126686177_0029_47_06 [Reducer 4] killed/failed due to:
 DAG_TERMINATED]DAG did not succeed due to SERVICE_PLUGIN_ERROR. failedVertices:0 killedVertices:
 4 (state=08S01,code=2)"
HIVE-21174,hive.stats.ndv.error parameter documentation issue,"Hive documentation for hive.stats.ndv.error does not specify that hive.stats.ndv.error will only affect FM Sketch and not HLL.

 

https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties"
HIVE-20599,CAST(INTERVAL_DAY_TIME AS STRING) is throwing SemanticException,"SELECT CAST(from_utc_timestamp(timestamp '2018-05-02 15:30:30', 'PST') - from_utc_timestamp(timestamp '1970-01-30 16:00:00', 'PST') AS STRING);

throws below Exception
{code:java}
Error: Error while compiling statement: FAILED: SemanticException Line 0:-1 Wrong arguments ''PST'': No matching method for class org.apache.hadoop.hive.ql.udf.UDFToString with (interval_day_time). Possible choices: _FUNC_(bigint)  _FUNC_(binary)  _FUNC_(boolean)  _FUNC_(date)  _FUNC_(decimal(38,18))  _FUNC_(double)  _FUNC_(float)  _FUNC_(int)  _FUNC_(smallint)  _FUNC_(string)  _FUNC_(timestamp)  _FUNC_(tinyint)  _FUNC_(void) (state=42000,code=40000){code}"
HIVE-20135,Fix incompatible change in TimestampColumnVector to default to UTC,"HIVE-20007 changed the default for TimestampColumnVector to be to use UTC, which breaks the API compatibility with storage-api 2.6."
HIVE-20123,Fix masking tests after HIVE-19617,"Masking tests results were changed inadvertently when HIVE-19617 went in, since table names were changed."
HIVE-20102,Add a couple of additional tests for query parsing,
HIVE-20076,ACID: Fix Synthetic ROW__ID generation for vectorized orc readers,Delete on a partitioned table removes more rows than expected
HIVE-20002,Shipping jdbd-storage-handler dependency jars in LLAP,"Shipping the following jars to LLAP to make jdbc storage-handler work: commons-dbcp, commons-pool, db specific jdbc jar whichever exists in classpath."
HIVE-19997,Batches for TestMiniDruidCliDriver,"I have observed {{TestMiniDruidCliDriver}} takes a long time to execute. I verified that execution is not batched. We could batch tests as we do with {{TestHBaseCliDriver}}, i.e., 5 q files per batch, as there is only a small number of tests."
HIVE-19980,GenericUDTFGetSplits fails when order by query returns 0 rows,"When order by query returns 0 rows, there will not be any files in temporary table location for GenericUDTFGetSplits

which results in the following exception
{code:java}
Caused by: java.lang.ArrayIndexOutOfBoundsException: 0
  at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:217)
  at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.getSplits(GenericUDTFGetSplits.java:420)
  ... 52 more{code}"
HIVE-19978,Backport HIVE-18037 to branch-3,
HIVE-19973,Enable materialized view rewriting by default,"Change property value for {{hive.materializedview.rewriting}} to {{true}}. For tests, it is already {{true}} by default."
HIVE-19972,Followup to HIVE-19928 : Fix the check for managed table,"The check for managed table should use ENUM comparison rather than string comparison.

The check in the patch will always return false, thus maintaining existing behavior."
HIVE-19965,Make HiveEndPoint use IMetaStoreClient.add_partition,"it currently uses ""alter table add partition if exists...""

which since HIVE-18814 requires X lock on the table which blocks other streaming writers from making progress.  

HIVE-19961 to investigate if X lock can be relaxed, etc."
HIVE-19964,Apply resource plan fails if trigger expression has quotes,"{code:java}
0: jdbc:hive2://localhost:10000> CREATE TRIGGER global.big_hdfs_read WHEN HDFS_BYTES_READ > '300kb' DO KILL;
INFO : Compiling command(queryId=pjayachandran_20180621131017_72b1441b-d790-4db7-83ca-479735843890): CREATE TRIGGER global.big_hdfs_read WHEN HDFS_BYTES_READ > '300kb' DO KILL
INFO : Semantic Analysis Completed (retrial = false)
INFO : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO : Completed compiling command(queryId=pjayachandran_20180621131017_72b1441b-d790-4db7-83ca-479735843890); Time taken: 0.015 seconds
INFO : Executing command(queryId=pjayachandran_20180621131017_72b1441b-d790-4db7-83ca-479735843890): CREATE TRIGGER global.big_hdfs_read WHEN HDFS_BYTES_READ > '300kb' DO KILL
INFO : Starting task [Stage-0:DDL] in serial mode
INFO : Completed executing command(queryId=pjayachandran_20180621131017_72b1441b-d790-4db7-83ca-479735843890); Time taken: 0.025 seconds
INFO : OK
No rows affected (0.054 seconds)
0: jdbc:hive2://localhost:10000> ALTER TRIGGER global.big_hdfs_read ADD TO UNMANAGED;
INFO : Compiling command(queryId=pjayachandran_20180621131031_dd489324-db23-412f-9409-32ba697a10e5): ALTER TRIGGER global.big_hdfs_read ADD TO UNMANAGED
INFO : Semantic Analysis Completed (retrial = false)
INFO : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO : Completed compiling command(queryId=pjayachandran_20180621131031_dd489324-db23-412f-9409-32ba697a10e5); Time taken: 0.014 seconds
INFO : Executing command(queryId=pjayachandran_20180621131031_dd489324-db23-412f-9409-32ba697a10e5): ALTER TRIGGER global.big_hdfs_read ADD TO UNMANAGED
INFO : Starting task [Stage-0:DDL] in serial mode
INFO : Completed executing command(queryId=pjayachandran_20180621131031_dd489324-db23-412f-9409-32ba697a10e5); Time taken: 0.029 seconds
INFO : OK
No rows affected (0.054 seconds)
0: jdbc:hive2://localhost:10000> ALTER RESOURCE PLAN global ENABLE;
INFO : Compiling command(queryId=pjayachandran_20180621131036_26a5f4f3-91e3-4bec-ab42-800adb90104e): ALTER RESOURCE PLAN global ENABLE
INFO : Semantic Analysis Completed (retrial = false)
INFO : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO : Completed compiling command(queryId=pjayachandran_20180621131036_26a5f4f3-91e3-4bec-ab42-800adb90104e); Time taken: 0.012 seconds
INFO : Executing command(queryId=pjayachandran_20180621131036_26a5f4f3-91e3-4bec-ab42-800adb90104e): ALTER RESOURCE PLAN global ENABLE
INFO : Starting task [Stage-0:DDL] in serial mode
INFO : Completed executing command(queryId=pjayachandran_20180621131036_26a5f4f3-91e3-4bec-ab42-800adb90104e); Time taken: 0.021 seconds
INFO : OK
No rows affected (0.045 seconds)
0: jdbc:hive2://localhost:10000> ALTER RESOURCE PLAN global ACTIVATE;
INFO : Compiling command(queryId=pjayachandran_20180621131037_551b2af0-321b-4638-8ac0-76771a159f4b): ALTER RESOURCE PLAN global ACTIVATE
INFO : Semantic Analysis Completed (retrial = false)
INFO : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO : Completed compiling command(queryId=pjayachandran_20180621131037_551b2af0-321b-4638-8ac0-76771a159f4b); Time taken: 0.017 seconds
INFO : Executing command(queryId=pjayachandran_20180621131037_551b2af0-321b-4638-8ac0-76771a159f4b): ALTER RESOURCE PLAN global ACTIVATE
INFO : Starting task [Stage-0:DDL] in serial mode
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Invalid expression: HDFS_BYTES_READ > 300kb
INFO : Completed executing command(queryId=pjayachandran_20180621131037_551b2af0-321b-4638-8ac0-76771a159f4b); Time taken: 0.037 seconds
Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. Invalid expression: HDFS_BYTES_READ > 300kb (state=08S01,code=1){code}"
HIVE-19956,Include yarn registry classes to jdbc standalone jar,HS2 Active/Passive HA requires some yarn registry classes. Include it in JDBC standalone jar. 
HIVE-19951,Vectorization: Need to disable encoded LLAP I/O for ORC when there is data type conversion  (Schema Evolution),"Currently, reading encoded ORC data does not support data type conversion.  So, encoded reading and cache populating needs to be disabled."
HIVE-19946,VectorizedRowBatchCtx.recordIdColumnVector cannot be shared between different JVMs,"VectorizedRowBatchCtx.recordIdColumnVector was used temporarily to pass record id column, which is virtual, between a reducer and a mapper. However, when the reducer and the mapper are not in a same JVM, it makes incorrect results."
HIVE-19941,Row based Filters added via Hive Ranger policies are not pushed to druid,"Issue is that when applying table mask we add virtual columns, however non-native tables do not have virtual columns, we need to skip adding virtual columns when generating masking query. 

Stack Trace - 
{code} 
org.apache.hadoop.hive.ql.parse.SemanticException: Line 1:79 Invalid table alias or column reference 'BLOCK__OFFSET__INSIDE__FILE'
: (possible column names are: __time, yearmonth, year, month, dayofmonth, dayofweek, weekofyear, hour, minute, second, payment_typ
e, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount, trip_time)
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genAllExprNodeDesc(SemanticAnalyzer.java:11830) ~[hive-exec-2.1.0.2.6.
4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.SemanticAnalyzer.genExprNodeDesc(SemanticAnalyzer.java:11778) ~[hive-exec-2.1.0.2.6.4.0
-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genSelectLogicalPlan(CalcitePlanner.java:3780) ~[hi
ve-exec-2.1.0.2.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:4117) ~[hive-exe
c-2.1.0.2.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:4016) ~[hive-exe
c-2.1.0.2.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.genLogicalPlan(CalcitePlanner.java:4060) ~[hive-exe
c-2.1.0.2.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1340) ~[hive-exec-2.1.0.2
.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1277) ~[hive-exec-2.1.0.2
.6.4.0-91.jar:2.1.0.2.6.4.0-91]
        at org.apache.calcite.tools.Frameworks$1.apply(Frameworks.java:113) ~[calcite-core-1.10.0.2.6.4.0-91.jar:1.10.0.2.6.4.0-91
]
        at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:997) ~[calcite-core-1.10.0.2.6.4.0-91.jar
:1.10.0.2.6.4.0-91]
        at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:149) ~[calcite-core-1.10.0.2.6.4.0-91.jar:1.10.0.2.6.4.
0-91]
        at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:106) ~[calcite-core-1.10.0.2.6.4.0-91.jar:1.10.0.2.6.4.
0-91]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1082) ~[hive-exec-2.1.0.2.6.4.0-91.jar:2
.1.0.2.6.4.0-91]
{code} "
HIVE-19938,Upgrade scripts for information schema,To make schematool -upgradeSchema work for information schema.
HIVE-19928,Load Data for managed tables should set the owner of loaded files to a configurable user,"load data of managed tables should set the owner of the loaded files to a configurable user. the default user should be hive.`

If the owner of existing file is not hive, then a rename/move operation should be replaced by copy with the copied file having hive as owner."
HIVE-19923,"Follow up of HIVE-19615, use UnaryFunction instead of prefix",Correct usage of Druid isnull function is {code} isnull(exp){code}
HIVE-19921,Fix perf duration and queue name in HiveProtoLoggingHook,"The perf log should return duration instead of end time.

The queue name should be llap queue for llap queries."
HIVE-19920,Schematool fails in embedded mode when auth is on,This is a follow up of HIVE-19775. We need to override more properties in embedded hs2.
HIVE-19917,Export of full CRUD transactional table fails if table is not in default database,"The actual issues is fixed by HIVE-19861.
This is a follow up to add a test case.

Issue:
{noformat}
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Can not create a Path from a null string
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:940) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:945) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTableLike(DDLTask.java:5099) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:433) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeAcidExport(UpdateDeleteSemanticAnalyzer.java:195) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:106) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:288) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:658) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1813) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1760) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1755) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:194) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:257) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:243) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:541) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:527) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:312) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:562) ~[hive-service-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:647) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[?:1.8.0_112]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[?:1.8.0_112]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_112]
Caused by: java.lang.IllegalArgumentException: Can not create a Path from a null string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:164) ~[hadoop-common-3.0.0.3.0.0.0-1485.jar:?]
	at org.apache.hadoop.fs.Path.<init>(Path.java:180) ~[hadoop-common-3.0.0.3.0.0.0-1485.jar:?]
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.createTempTable(SessionHiveMetaStoreClient.java:459) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.create_table_with_environment_context(SessionHiveMetaStoreClient.java:117) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:831) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createTable(HiveMetaStoreClient.java:816) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at sun.reflect.GeneratedMethodAccessor124.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:212) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at com.sun.proxy.$Proxy55.createTable(Unknown Source) ~[?:?]
	at sun.reflect.GeneratedMethodAccessor124.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_112]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_112]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient$SynchronizedHandler.invoke(HiveMetaStoreClient.java:2768) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	at com.sun.proxy.$Proxy55.createTable(Unknown Source) ~[?:?]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:929) ~[hive-exec-3.0.0.3.0.0.0-1485.jar:3.0.0.3.0.0.0-1485]
	... 27 more
2018-06-14T17:53:32,112 ERROR [07758225-f4e7-4fc2-a9e5-c6ed19e9fcfd HiveServer2-Handler-Pool: Thread-143]: metadata.Hive (:()) - Table tpch.tbl_export_05da5215_6695_420e_99e9_24a9bb5d1a39 not found: hive.tpch.tbl_export_05da5215_6695_420e_99e9_24a9bb5d1a39 table not found
2018-06-14T17:53:32,113 ERROR [07758225-f4e7-4fc2-a9e5-c6ed19e9fcfd HiveServer2-Handler-Pool: Thread-143]: ql.Driver (:()) - FAILED: SemanticException org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found tbl_export_05da5215_6695_420e_99e9_24a9bb5d1a39
org.apache.hadoop.hive.ql.parse.SemanticException: org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found tbl_export_05da5215_6695_420e_99e9_24a9bb5d1a39
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeAcidExport(UpdateDeleteSemanticAnalyzer.java:198)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeInternal(UpdateDeleteSemanticAnalyzer.java:106)
	at org.apache.hadoop.hive.ql.parse.BaseSemanticAnalyzer.analyze(BaseSemanticAnalyzer.java:288)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:658)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1813)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1760)
	at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1755)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126)
	at org.apache.hive.service.cli.operation.SQLOperation.prepare(SQLOperation.java:194)
	at org.apache.hive.service.cli.operation.SQLOperation.runInternal(SQLOperation.java:257)
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:243)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:541)
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementAsync(HiveSessionImpl.java:527)
	at org.apache.hive.service.cli.CLIService.executeStatementAsync(CLIService.java:312)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:562)
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557)
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:647)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hive.ql.metadata.InvalidTableException: Table not found tbl_export_05da5215_6695_420e_99e9_24a9bb5d1a39
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1141)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1092)
	at org.apache.hadoop.hive.ql.metadata.Hive.getTable(Hive.java:1079)
	at org.apache.hadoop.hive.ql.parse.UpdateDeleteSemanticAnalyzer.analyzeAcidExport(UpdateDeleteSemanticAnalyzer.java:196)
	... 23 more
{noformat}
"
HIVE-19912,"Schema evolution checks prints a log line in INFO mode for each vectorized rowbatch, impacts performance","While benchmarking query96, noticed 17K log lines printed for each vector rowbactch

 

In file ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcInputFormat.java

 
{code:java}
@@ -2554,8 +2554,8 @@ public static TypeDescription getDesiredRowTypeDescr(Configuration conf,
     }

     if (haveSchemaEvolutionProperties) {
-      if (LOG.isInfoEnabled()) {
-        LOG.info(""Using schema evolution configuration variables schema.evolution.columns "" +
+      if (LOG.isDebugEnabled()) {
+        LOG.debug(""Using schema evolution configuration variables schema.evolution.columns "" +
             schemaEvolutionColumnNames.toString() +
             "" / schema.evolution.columns.types "" +
             schemaEvolutionTypeDescrs.toString() +{code}
 "
HIVE-19908,Block Insert Overwrite with Union All on full CRUD ACID tables using HIVE_UNION_SUBDIR_,This currently results in data loss.  Will block and suggest using truncate + insert.
HIVE-19904,Load data rewrite into Tez job fails for ACID,"Load data rewrite into IAS fails for ACID as there is some code which does not take into account the table name could be in upper case, specifically ValidTxnWriteIdList"
HIVE-19903,Disable temporary insert-only transactional table,
HIVE-19898,Disable TransactionalValidationListener when the table is not in the Hive catalog,"The TransactionalValidationListener does validation of tables specified as transactional tables, as well as enforcing create.as.acid. While this can be useful to Hive, this may not be useful to other catalogs which do not support transactional tables, and would not benefit from being automatically tagged as a transactional table. This should be changed so the TransactionalValidationListener does not run for non-hive catalogs."
HIVE-19892,Disable query results cache for for HiveServer2 doAs=true,"If running HS2 with doAs=true, the temp query results directory will have ownership/permissions based on the doAs user. A subsequent query running as a different user may not be able to access this query results directory. Results caching will have to be disabled in this case."
HIVE-19890,ACID: Inherit bucket-id from original ROW_ID for delete deltas,"The ACID delete deltas for unbucketed tables are written to arbitrary files, which should instead be shuffled using the bucket-id instead of hash(ROW__ID)."
HIVE-19889,Wrong results due to PPD of non deterministic functions with CBO,"The following query can give wrong results when CBO is on:
{code}
select * from (
select part1,randum123
from (SELECT *, cast(rand() as double) AS randum123 FROM testA where part1='CA' and part2 = 'ABC') a
where randum123 <= 0.5) s where s.randum123 > 0.25 limit 20;

The plan of the query is as follows:
STAGE PLANS:
  Stage: Stage-1
    Map Reduce
      Map Operator Tree:
          TableScan
            alias: testa
            Statistics: Num rows: 2 Data size: 4580 Basic stats: COMPLETE Column stats: NONE
            Filter Operator
              predicate: ((rand() <= 0.5D) and (rand() > 0.25D)) (type: boolean)
              Statistics: Num rows: 1 Data size: 2290 Basic stats: COMPLETE Column stats: NONE
              Select Operator
                expressions: 'CA' (type: string), rand() (type: double)
                outputColumnNames: _col0, _col1
                Statistics: Num rows: 1 Data size: 2290 Basic stats: COMPLETE Column stats: NONE
                Limit
                  Number of rows: 20
                  Statistics: Num rows: 1 Data size: 2290 Basic stats: COMPLETE Column stats: NONE
                  File Output Operator
                    compressed: false
                    Statistics: Num rows: 1 Data size: 2290 Basic stats: COMPLETE Column stats: NONE
                    table:
                        input format: org.apache.hadoop.mapred.SequenceFileInputFormat
                        output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat
                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe

  Stage: Stage-0
    Fetch Operator
      limit: 20
      Processor Tree:
        ListSink
{code}

The relevant part in the plan is the filter:

{code}
            Filter Operator
              predicate: ((rand() <= 0.5D) and (rand() > 0.25D)) (type: boolean)
{code}

The predicates randum123 <= 0.5 and s.randum123 > 0.25 were pushed down.  And randum123 was resolved to rand().  This is bad because it will result in invocation of rand() two times and rand() UDF is non-deterministic.  Both the rand calls can generate values that can satisfy the predicates independently, but not together, whereas the original intention of the query is to give results when rand falls between 0.25 and 0.5.

A sample result:

{code}
CA	0.9191984370369802
CA	0.397933021566812
{code}

where the condition was not satisfied."
HIVE-19885,Druid Kafka Ingestion - Allow user to set kafka consumer properties via table properties,Allow users to set kafka consumer properties via table properties. 
HIVE-19884,Invalidation cache may throw NPE when there is no data in table used by materialized view,
HIVE-19881,Allow metadata-only dump for database which are not source of replication,If the dump is meta data only then allow dump even if the db is not source of replication
HIVE-19880,Repl Load to return recoverable vs non-recoverable error codes,"To enable bootstrap of large databases, application has to have the ability to keep retrying the bootstrap load till it encounters a fatal error. The ability to identify if an error is fatal or not will be decided by hive and communication of the same will happen to application via error codes.

So there should be different error codes for recoverable vs non-recoverable failures which should be propagated to application as part of running the repl load command."
HIVE-19879,Remove unused calcite sql operator.,HIVE-19796 introduced by mistake an unused sql operator.
HIVE-19877,Remove setting hive.execution.engine as mr in HiveStreamingConnection,HiveStreamingConnection explicitly sets execution engine to mr which was from old code. It is no longer required. 
HIVE-19876,Multiple fixes for Driver.isValidTxnListState,"1) Only locks for tables should be checked.
2) Check on whether {{txnWriteIdList}} is null or not needs to be fixed: it should be done on the configuration property value, as the object {{txnWriteIdList}} will never be null."
HIVE-19875,increase LLAP IO queue size for perf,"According to [~gopalv] queue limit has perf impact, esp. during hashtable load for mapjoin where in the past IO used to queue up more data for processing to process.
1) Overall the default limit could be adjusted higher.
2) Depending on Decimal64 availability, the weight for decimal columns could be reduced."
HIVE-19873,Cleanup operation log on query cancellation after some delay,"When a query is executed using beeline and the query is cancelled due to query timeout or kill query or triggers and when there is cursor on operation log row set, the cursor can thrown an exception as cancel will cleanup the operation log in the background. This can return a non-zero exit code in beeline. Query cancellation on success should return exit code 0.

Adding a delay to the cleanup of operation logging in operation cancel can avoid the close during read. "
HIVE-19872,hive-schema-3.1.0.hive.sql is missing on master and branch-3,"Information schema initialization with schematool will fail with ""Unknown version specified for initialization: 3.1.0""."
HIVE-19869,Remove double formatting bug followup of HIVE-19382,"HIVE-19382 has a minor bug that happens when users provide custom format as part of FROM_UNIXTIMESTAMP function.
Here is an example query
{code}
SELECT SUM(`ssb_druid_100`.`lo_revenue`) AS `sum_lo_revenue_ok`,
CAST(FROM_UNIXTIME(UNIX_TIMESTAMP(CAST(`ssb_druid_100`.`__time` AS TIMESTAMP)), 'yyyy-MM-dd HH:00:00') AS TIMESTAMP) AS `thr___time_ok`
 FROM `druid_ssb`.`ssb_druid_100` `ssb_druid_100`
GROUP BY CAST(FROM_UNIXTIME(UNIX_TIMESTAMP(CAST(`ssb_druid_100`.`__time` AS TIMESTAMP)), 'yyyy-MM-dd HH:00:00') AS TIMESTAMP);
{code}"
HIVE-19868,Add support for float aggregator,
HIVE-19866,improve LLAP cache purge,"1) Memory needs to be accounted for.
2) LRFU eviction doesn't need to maintain state between individual removals."
HIVE-19864,Address TestTriggersWorkloadManager flakiness,TestTriggersWorkloadManager seems flaky and all test cases gets timed out at times. 
HIVE-19862,Postgres init script has a glitch around UNIQUE_DATABASE,"{code}
ALTER TABLE ONLY ""DBS"" ADD CONSTRAINT ""UNIQUE_DATABASE"" UNIQUE (""NAME"");
{code}
Should also include ""CTLG_NAME""."
HIVE-19861,Fix temp table path generation for acid table export,"Temp tables that are analyzed by the SemanticAnalyzer get their default location set to a location in the session directory. Export of Acid tables also creates temp tables, but this is done via a plan transformation, and the temp table creation never goes through the SemanticAnalyzer, meaning the location is not set. There is some other logic in DDLTask (which I am changing in HIV-19837) which ends up automatically setting this path to the default table location in the warehouse directory. This should be fixed so that the path defaults to a location in the session directory, like with normal temp tables.

cc [~ekoifman]"
HIVE-19859,Inspect lock components for DBHiveLock while verifying whether transaction list is valid,
HIVE-19857,Set 3.1.0 for sys db version,
HIVE-19853,Arrow serializer needs to create a TimeStampMicroTZVector instead of TimeStampMicroVector,"HIVE-19723 changed nanosecond to microsecond in Arrow serialization. However, it needs to be microsecond with time zone."
HIVE-19852,update jackson to latest,Update jackson version to latest 2.9.5
HIVE-19851,upgrade jQuery version,jQuery version seems to be very old. Update to latest stable version. 
HIVE-19838,simplify & fix ColumnizedDeleteEventRegistry load loop,"Apparently sometimes the delete count in ACID stats doesn't match what merger actually returns.
It could be due to some deltas having duplicate deletes from parallel queries (I guess?) that are being squashed by the merger or some other reasons beyond my mortal comprehension.

The loop assumes the merger will return the exact number of records, so it fails with array index exception. Also, it could actually be done in a single loop."
HIVE-19837,Setting to have different default location for external tables,Allow external tables to have a different default location than managed tables
HIVE-19833,reduce LLAP IO min allocation to match ORC variable CB size,
HIVE-19827,hiveserver2 startup should provide a way to override TEZ_CONF_DIR,"HS2 should use /etc/tez/conf, HSI should use /etc/tez_llap/conf "
HIVE-19826,OrcRawRecordMerger doesn't work for more than one file in non vectorized case,"Key object in the map is reused and reset, leading to bizarre merges and wrong results."
HIVE-19824,Improve online datasize estimations for MapJoins,"Statistics.datasize() only accounts for ""real"" data size; but for example handling 1M rows might introduce some datastructure overhead...if the ""real"" data is small - even this overhead might become the real memory usage

for 6.5M rows of (int,int) the estimation is 52MB
in reality this eats up ~260MB from which 210MB is used to service the hashmap functionality to that many rows."
HIVE-19817,Hive streaming API + dynamic partitioning + json/regex writer does not work,New streaming API for dynamic partitioning only works with delimited record writer. Json and Regex writers does not work.
HIVE-19815,Repl dump should not propagate the checkpoint and repl source properties,"For replication scenarios of A-> B -> C the repl dump on B should not include the checkpoint property when dumping out table information. 
Alter tables/partitions during incremental should not propagate this as well.
Also should not propagate the the db level parameters set by replication internally."
HIVE-19813,SessionState.start don't have to be synchronized,"This is introduced in HIVE-14690. However, only check-set block needs to be synchronized, not the whole block. The method will start Tez AM, which is a long operation. Make the method synchronized will serialize session start thus slow down hs2."
HIVE-19810,StorageHandler fail to ship jars in Tez intermittently,"Hive relies on StorageHandler to ship jars to backend automatically in several cases: JdbcStorageHandler, HBaseStorageHandler, AccumuloStorageHandler. This does not work reliably, in particular, the first dag in the session will have those jars, the second will not unless container is reused. In the later case, the containers allocated to first dag will be reused in the second dag so the container will have additional resources."
HIVE-19808,GenericUDTFGetSplits should support ACID reads in the temp. table read path,"1. Map-only reads work on ACID tables.
2. Temp. table reads (for multi-vertex queries) work on non-ACID tables.
3. But temp. table reads don't work on ACID tables.

{code}
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create temp table: java.lang.IllegalStateException: calling recordValidTxn() more than once in the same txnid:420
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.createPlanFragment(GenericUDTFGetSplits.java:303)
	at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.process(GenericUDTFGetSplits.java:202)
	at org.apache.hadoop.hive.ql.exec.UDTFOperator.process(UDTFOperator.java:116)
	at org.apache.hadoop.hive.ql.exec.Operator.baseForward(Operator.java:985)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:931)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:918)
	at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)
	at org.apache.hadoop.hive.ql.exec.Operator.baseForward(Operator.java:985)
	at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:931)
	at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:125)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:492)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:484)
	at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:145)
	... 16 more
{code}"
HIVE-19801,JDBC: Add some missing classes to jdbc standalone jar and remove hbase classes,
HIVE-19799,remove jasper dependency,jasper dependency version looks old and unwanted. There is a comment which says it is required by thrift but I don't see jasper as thrift dependency. Try removing it to see if its safe (after precommit test run). 
HIVE-19796,Push Down TRUNC Fn to Druid Storage Handler,"Push down Queries with TRUNC date function such as 
{code}
SELECT SUM((`ssb_druid_100`.`discounted_price` * `ssb_druid_100`.`net_revenue`)) AS `sum_calculation_4998925219892510720_ok`,
  CAST(TRUNC(CAST(`ssb_druid_100`.`__time` AS TIMESTAMP),'MM') AS DATE) AS `tmn___time_ok`
FROM `druid_ssb`.`ssb_druid_100` `ssb_druid_100`
GROUP BY CAST(TRUNC(CAST(`ssb_druid_100`.`__time` AS TIMESTAMP),'MM') AS DATE)
{code}"
HIVE-19794,Disable removing order by from subquery in GenericUDTFGetSplits,"spark-llap always wraps query under a subquery, until that is removed from spark-llap
hive compiler is going to remove inner order by in GenericUDTFGetSplits. disable that optimization until then."
HIVE-19793,disable LLAP IO batch-to-row wrapper for ACID deletes/updates,"1) Batch to row converter doesn't propagate columns correctly because they are not in the schema.
2) Then, even if it did, the current VrbCtx model of ACID column propagation only works with VectorMapOperator. Regular MapOperator has no such context; the reader ends up storing the vector in some fake temporary ctx. I left a TODO that combined with a fix to (1) could fix this instead of disabling it."
HIVE-19789,reenable orc_llap test,"Test has been disabled, looks like by mistake (or due to some issue with the patch there that was never addressed), in HIVE-11394.
It needs to be reenabled."
HIVE-19777,NPE in TezSessionState,"Encountered while running ""insert into table values (..)""

Looks like it is due to the fact that TezSessionState.close() sets console to null at the start of the method, and then calls getSession() which attempts to log to console.

{noformat}
java.lang.NullPointerException: null
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.getSession(TezSessionState.java:711) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionState.close(TezSessionState.java:646) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.closeIfNotDefault(TezSessionPoolManager.java:353) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.getSession(TezSessionPoolManager.java:467) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.WorkloadManagerFederation.getUnmanagedSession(WorkloadManagerFederation.java:66) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.WorkloadManagerFederation.getSession(WorkloadManagerFederation.java:38) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:184) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2497) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2149) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1826) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1569) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1563) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:157) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:218) ~[hive-exec-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683) ~[hive-cli-4.0.0-SNAPSHOT.jar:4.0.0-SNAPSHOT]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_121]
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_121]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_121]
        at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_121]
        at org.apache.hadoop.util.RunJar.run(RunJar.java:308) ~[hadoop-common-3.0.0.3.0.0.0-SNAPSHOT.jar:?]
        at org.apache.hadoop.util.RunJar.main(RunJar.java:222) ~[hadoop-common-3.0.0.3.0.0.0-SNAPSHOT.jar:?]
{noformat}"
HIVE-19776,HiveServer2.startHiveServer2 retries of start has concurrency issues,"HS2 starts the thrift binary/http servers in background, while it proceeds to do other setup (eg create zookeeper entries). If there is a ZK error and it attempts to stop and start in the retry loop within HiveServer2.startHiveServer2, the retry fails because the thrift server doesn't get stopped if it was still getting initialized.

The thrift server initialization and stopping needs to be synchronized.
"
HIVE-19775,Schematool should use HS2 embedded mode in privileged auth mode,"Follow up of  HIVE-19389.
Authorization checks don't make sense for embedded mode and since it is not used in that mode it leads to issues if authorization is enabled (eg, username not set).
"
HIVE-19773,CBO exception while running queries with tables that are not present in materialized views,"When we obtain the valid list of write ids, some tables in the materialized views may not be present in the list because they are not present in the query, which leads to exceptions (hidden in logs) when we try to load the materialized views in the planner, as we need to verify whether they are outdated or not."
HIVE-19772,Streaming ingest V2 API can generate invalid orc file if interrupted,"Hive streaming ingest generated 0 length and 3 byte files which are invalid orc files. This will throw the following exception during compaction

{code}
Error: org.apache.orc.FileFormatException: Not a valid ORC file hdfs://cn105-10.l42scl.hortonworks.com:8020/apps/hive/warehouse/culvert/year=2018/month=7/delta_0000025_0000025/bucket_00005 (maxFileLength= 3) at org.apache.orc.impl.ReaderImpl.extractFileTail(ReaderImpl.java:546) at org.apache.orc.impl.ReaderImpl.<init>(ReaderImpl.java:370) at org.apache.hadoop.hive.ql.io.orc.ReaderImpl.<init>(ReaderImpl.java:60) at org.apache.hadoop.hive.ql.io.orc.OrcFile.createReader(OrcFile.java:90) at org.apache.hadoop.hive.ql.io.orc.OrcRawRecordMerger.<init>(OrcRawRecordMerger.java:1124) at org.apache.hadoop.hive.ql.io.orc.OrcInputFormat.getRawReader(OrcInputFormat.java:2373) at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:1000) at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.map(CompactorMR.java:977) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:460) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:344) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
{code}"
HIVE-19771,allowNullColumnForMissingStats should not be false when column stats are estimated,"Otherwise we may throw an Exception.

{noformat}
2018-05-26T00:30:22,335 DEBUG [HiveServer2-Background-Pool: Thread-631]: stats.StatsUtils (:()) - Estimated average row size: 372
2018-05-26T00:30:22,352 DEBUG [HiveServer2-Background-Pool: Thread-631]: calcite.RelOptHiveTable (:()) - Stats for column a in table basetable_rebuild stored in cache
2018-05-26T00:30:22,352 DEBUG [HiveServer2-Background-Pool: Thread-631]: calcite.RelOptHiveTable (:()) -  colName: a colType: int countDistincts: 4 numNulls: 1 avgColLen: 4.0 numTrues: 0 numFalses: 0 Range: [ min: -9223372036854775808 max: 9223372036854775807 ] isPrimaryKey: false isEstimated: true
2018-05-26T00:30:22,352 DEBUG [HiveServer2-Background-Pool: Thread-631]: calcite.RelOptHiveTable (:()) - Stats for column b in table basetable_rebuild stored in cache
2018-05-26T00:30:22,352 DEBUG [HiveServer2-Background-Pool: Thread-631]: calcite.RelOptHiveTable (:()) -  colName: b colType: varchar(256) countDistincts: 4 numNulls: 1 avgColLen: 256.0 numTrues: 0 numFalses: 0 isPrimaryKey: false isEstimated: true
2018-05-26T00:30:22,352 ERROR [HiveServer2-Background-Pool: Thread-631]: calcite.RelOptHiveTable (:()) - No Stats for default@basetable_rebuild, Columns: a, b
java.lang.RuntimeException: No Stats for default@basetable_rebuild, Columns: a, b
        at org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.updateColStats(RelOptHiveTable.java:586) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.getColStat(RelOptHiveTable.java:606) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.RelOptHiveTable.getColStat(RelOptHiveTable.java:592) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.reloperators.HiveTableScan.getColStat(HiveTableScan.java:155) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.stats.HiveRelMdDistinctRowCount.getDistinctRowCount(HiveRelMdDistinctRowCount.java:78) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.optimizer.calcite.stats.HiveRelMdDistinctRowCount.getDistinctRowCount(HiveRelMdDistinctRowCount.java:65) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at GeneratedMetadataHandler_DistinctRowCount.getDistinctRowCount_$(Unknown Source) ~[?:?]
        at GeneratedMetadataHandler_DistinctRowCount.getDistinctRowCount(Unknown Source) ~[?:?]
        at org.apache.calcite.rel.metadata.RelMetadataQuery.getDistinctRowCount(RelMetadataQuery.java:781) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.rel.metadata.RelMdRowCount.getRowCount(RelMdRowCount.java:207) ~[calcite-core-1.16.0.jar:1.16.0]
        at GeneratedMetadataHandler_RowCount.getRowCount_$(Unknown Source) ~[?:?]
        at GeneratedMetadataHandler_RowCount.getRowCount(Unknown Source) ~[?:?]
        at org.apache.calcite.rel.metadata.RelMetadataQuery.getRowCount(RelMetadataQuery.java:235) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.rel.externalize.RelWriterImpl.explain_(RelWriterImpl.java:100) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.rel.externalize.RelWriterImpl.done(RelWriterImpl.java:156) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.rel.AbstractRelNode.explain(AbstractRelNode.java:312) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.plan.RelOptUtil.toString(RelOptUtil.java:1991) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1898) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner$CalcitePlannerAction.apply(CalcitePlanner.java:1613) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.calcite.tools.Frameworks$1.apply(Frameworks.java:118) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.prepare.CalcitePrepareImpl.perform(CalcitePrepareImpl.java:1052) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.tools.Frameworks.withPrepare(Frameworks.java:154) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.calcite.tools.Frameworks.withPlanner(Frameworks.java:111) ~[calcite-core-1.16.0.jar:1.16.0]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.logicalPlan(CalcitePlanner.java:1418) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.parse.CalcitePlanner.genLogicalPlan(CalcitePlanner.java:369) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.HiveMaterializedViewsRegistry.parseQuery(HiveMaterializedViewsRegistry.java:416) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.HiveMaterializedViewsRegistry.addMaterializedView(HiveMaterializedViewsRegistry.java:225) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.HiveMaterializedViewsRegistry.createMaterializedView(HiveMaterializedViewsRegistry.java:188) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.MaterializedViewTask.execute(MaterializedViewTask.java:61) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2479) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2150) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1826) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1567) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1561) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:157) ~[hive-exec-3.0.0.jar:3.0.0-SNAPSHOT]
        at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:221) ~[hive-service-3.0.0.jar:3.0.0]
        at org.apache.hive.service.cli.operation.SQLOperation.access$700(SQLOperation.java:87) ~[hive-service-3.0.0.jar:3.0.0]
{noformat}"
HIVE-19768,Utility to convert tables to conform to Hive strict managed tables mode,"Create a utility that can check existing hive tables and convert them if necessary to conform to strict managed tables mode.
- Managed non-transactional ORC tables will be converted to full transactional tables
- Managed non-transactional tables of other types will be converted to insert-only transactional tables
- Tables with non-native storage/schema will be converted to external tables."
HIVE-19762,Druid Queries containing Joins gives wrong results. ,"Druid queries that have joins against self table gives wrong results. 
e.g. 
{code} 
SELECT
username AS `username`,
SUM(double1) AS `sum_double1`
FROM
druid_table_with_nulls `tbl1`
  JOIN (
    SELECT
    username AS `username`,
    SUM(double1) AS `sum_double2`
    FROM druid_table_with_nulls
    GROUP BY `username`
    ORDER BY `sum_double2`
    DESC  LIMIT 10
  )
  `tbl2`
    ON (`tbl1`.`username` = `tbl2`.`username`)
GROUP BY `tbl1`.`username`;
{code} 

In this case one of the queries is a druid scan query and other is groupBy query. 
During planning, the properties of these queries are set to the tableDesc and serdeInfo, while setting the map work, we overwrite the properties from the properties present in serdeInfo, this causes the scan query results to be deserialized using wrong column names and results in Null values. "
HIVE-19758,Set hadoop.version=3.1.0 in standalone-metastore,"When HIVE-19243 set hadoop.version=3.1.0 it did not change the value used in standalone-metastore which still uses 3.0.0-beta1.
 At the moment standalone-metastore is still a module of hive and so this can suck in the wrong code."
HIVE-19755,insertsel_fail.q.out needs to be updated on branch-3,
HIVE-19754,vector_decimal_2 failing on branch-3,caused by HIVE-19108. This needs golden file update only on branch-3
HIVE-19753,Strict managed tables mode in Hive,"Create a mode in Hive which enforces that all managed tables are transactional (both full or insert-only tables allowed). Non-transactional tables, as well as non-native tables, must be created as external tables when this mode is enabled.
The idea would be that in strict managed tables mode all of the data written to managed tables would have been done through Hive.
The mode would be enabled using config setting hive.strict.managed.tables."
HIVE-19750,Initialize NEXT_WRITE_ID. NWI_NEXT on converting an existing table to full acid,"Need to set this to a reasonably high value the the table.
This will reserve a range of write IDs that will be treated by the system as committed.
This is needed so that we can assign unique ROW__IDs to each row in files that already exist in the table.  For example, if the value is initialized to the number of files currently in the table, we can think of each file as written by a separate transaction and thus a free to assign bucketProperty (BucketCodec) of ROW_ID in whichever way is convenient.
it's guaranteed that all rows get unique ROW_IDs this way."
HIVE-19744,In Beeline if -u is specified the default connection should not be tried at all,"I wanted to explicitly connect to a hiveserver by specifying {{-u}} but that didn't work because it was not running/etc...
The strange thing is that somehow the default connection is activated...and tried

The possible ""hazard"" here is that if someone specifies {{-u $MY_DEV_HS2 -f recreate_db.sql}} to run some sql script...beeline may connect somewhere else and run the commands there - which might have serious consequences.... (in the above case having default as production might be interesting)

{code}
beeline -u jdbc:hive2://localhost:10502/;transportMode=binary  -n hrt_qa
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/hdp/3.0.0.0-1406/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/hdp/3.0.0.0-1406/hadoop/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10502/
18/05/31 07:51:20 [main]: WARN jdbc.HiveConnection: Failed to connect to localhost:10502
Unknown HS2 problem when communicating with Thrift server.
Error: Could not open client transport with JDBC Uri: jdbc:hive2://localhost:10502/: Invalid status 72 (state=08S01,code=0)
Connecting to jdbc:hive2://ctr-e138-1518143905142-336795-01-000016.hwx.site:2181,ctr-e138-1518143905142-336795-01-000008.hwx.site:2181,ctr-e138-1518143905142-336795-01-000014.hwx.site:2181,ctr-e138-1518143905142-336795-01-000009.hwx.site:2181,ctr-e138-1518143905142-336795-01-000015.hwx.site:2181/default;httpPath=cliservice;principal=hive/_HOST@EXAMPLE.COM;serviceDiscoveryMode=zooKeeper;ssl=true;transportMode=http;zooKeeperNamespace=hiveserver2
18/05/31 07:51:21 [main]: INFO jdbc.HiveConnection: Connected to ctr-e138-1518143905142-336795-01-000003.hwx.site:10001
18/05/31 07:51:21 [main]: ERROR jdbc.HiveConnection: Error opening session
org.apache.thrift.transport.TTransportException: javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path validation failed: java.security.cert.CertPathValidatorException: signature check failed
{code}"
HIVE-19739,Bootstrap REPL LOAD to use checkpoints to validate and skip the loaded data/metadata.,"Currently. bootstrap REPL LOAD have added checkpoint identifiers in DB/table/partition object properties once the data/metadata related to the object is successfully loaded.

If the Db exist and is not empty, then currently we are throwing exception. But need to support it for the retry scenario after a failure.

If there is a retry of bootstrap load using the same dump, then instead of throwing error, we should check if any of the tables/partitions are completely loaded using the checkpoint identifiers. If yes, then skip it or else drop/create them again.

If the bootstrap load is performed using different dump, then it should throw exception.

Allow bootstrap on empty Db only if ckpt property is not set. Also, if bootstrap load is completed on the target Db, then shouldn't allow bootstrap retry at all."
HIVE-19734,"Beeline: When beeline-site.xml is present, beeline does not honor -n (username) and -p (password) arguments",
HIVE-19731,Change staging tmp directory used by TestHCatLoaderComplexSchema,"Another one that is set to default and hence is flaky.

https://builds.apache.org/job/PreCommit-HIVE-Build/11321/testReport/org.apache.hive.hcatalog.pig/TestHCatLoaderComplexSchema/testSyntheticComplexSchema_3_/

{noformat}
org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access ‘/tmp/hadoop/mapred/staging/hiveptest985275899/.staging/job_local985275899_0088’: No such file or directory

	at org.apache.hadoop.util.Shell.runCommand(Shell.java:1009) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.run(Shell.java:902) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1227) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1321) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:1303) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:840) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem$1.apply(ChecksumFileSystem.java:508) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem$FsOperation.run(ChecksumFileSystem.java:489) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.ChecksumFileSystem.setPermission(ChecksumFileSystem.java:511) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:727) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.mkdirs(JobResourceUploader.java:658) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:172) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:133) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_102]
	at javax.security.auth.Subject.doAs(Subject.java:422) ~[?:1.8.0_102]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:336) [hadoop-mapreduce-client-core-3.1.0.jar:?]
	at sun.reflect.GeneratedMethodAccessor36.invoke(Unknown Source) ~[?:?]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_102]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_102]
	at org.apache.pig.backend.hadoop23.PigJobControl.submit(PigJobControl.java:128) [pig-0.16.0-h2.jar:?]
	at org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:194) [pig-0.16.0-h2.jar:?]
	at java.lang.Thread.run(Thread.java:745) [?:1.8.0_102]
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:276) [pig-0.16.0-h2.jar:?]
{noformat}"
HIVE-19728,beeline with USE_BEELINE_FOR_HIVE_CLI fails when trying to set hive.aux.jars.path,"Since HIVE-19385 it's possible to redirect bin/hive to beeline. This is not working as expected though, because in {{bin/hive}} we're setting {{hive.aux.jars.path}}. This leads to the following error:

{code}
$ USE_BEELINE_FOR_HIVE_CLI=true hive

...
Error: Could not open client transport for any of the Server URI's in ZooKeeper: Failed to open new session: java.lang.IllegalArgumentException: Cannot modify hive.aux.jars.path at runtime. It is not in list of params that are allowed to be modified at runtime (state=08S01,code=0)
Beeline version 3.0.0 by Apache Hive
beeline> 
{code}

We already avoid setting {{hive.aux.jars.path}} when running {{beeline}} service but the USE_BEELINE_FOR_HIVE_CLI override happens after that.

I'd suggest checking the value of USE_BEELINE_FOR_HIVE_CLI right after we've selected the service to run (cli/beeline/...) and override cli->beeline there."
HIVE-19727,Fix Signature matching of table aliases,"there is a probable problem with alias matching: ""t1 as a"" is matched to ""t2 as a"" "
HIVE-19726,ORC date PPD is broken,"When kryo was in version 2.22 we added a fix in HIVE-7222 and later in HIVE-10819. Now that we have updated kryo to 3.0.3 that old workaround fix was never removed. The issue was that kryo serialized Timestamp to Date type. So to recover the timestamp, during deserialization we deserialized *any* date instance to Timestamp object which is wrong (we don't know if date was serialized as date or timestamp serialized as date in first place). This breaks PPD on date time as kryo deserialization always converts Date to Timestamp breaking PPD because of type mismatch.
Now that we have newer kryo version we can remove the code added in HIVE-10819.   "
HIVE-19725,Add ability to dump non-native tables in replication metadata dump,"if hive.repl.dump.metadata.only is set to true, allow dumping non native tables also. 

Data dump for non-native tables should never be allowed."
HIVE-19723,"Arrow serde: ""Unsupported data type: Timestamp(NANOSECOND, null)""","Spark's Arrow support only provides Timestamp at MICROSECOND granularity. Spark 2.3.0 won't accept NANOSECOND. Switch it back to MICROSECOND.
The unit test org.apache.hive.jdbc.TestJdbcWithMiniLlapArrow will just need to change the assertion to test microsecond. And we'll need to add this to documentation on supported datatypes."
HIVE-19713,itests/hive-jmh should not reference a concreate storage-api version,"
this is a bigger problem on branch-3; where storage-api is 2.6.1; but hive-jmh references 2.7.0 (which is for master)
"
HIVE-19708,Repl copy retrying with cm path even if the failure is due to network issue,"* During repl load
 ** for filesystem based copying of file if the copy fails due to a connection error to source Name Node, we should recreate the filesystem object.
 ** the retry logic for local file copy should be triggered using the original source file path ( and not the CM root path ) since failure can be due to network issues between DFSClient and NN.

 * When listing files in tables / partition to include them in _files, we should add retry logic when failure occurs. FileSystem object here also should be recreated since the existing one might be in inconsistent state."
HIVE-19706,Disable TestJdbcWithMiniHS2#testHttpRetryOnServerIdleTimeout,"https://builds.apache.org/job/PreCommit-HIVE-Build/11190/testReport/junit/org.apache.hive.jdbc/TestJdbcWithMiniHS2/testHttpRetryOnServerIdleTimeout/history/

It seems to timeout sporadically. I will ignore specifically that test."
HIVE-19700,Workaround for JLine issue with UnsupportedTerminal,"From the JLine's ConsoleReader, readLine(prompt, mask) calls the following beforeReadLine() method.
{code}
        try {
            // System.out.println(""is terminal supported "" + terminal.isSupported());
            if (!terminal.isSupported()) {
                beforeReadLine(prompt, mask);
            }
{code}

So specifically when using UnsupportedTerminal {{-Djline.terminal}} and {{prompt=null}} and {{mask!=null}}, a ""null"" string gets printed to the console before and after the query result. {{UnsupportedTerminal}} is required to be used when running beeline as a background process, hangs otherwise.

{code}
    private void beforeReadLine(final String prompt, final Character mask) {
        if (mask != null && maskThread == null) {
            final String fullPrompt = ""\r"" + prompt
                + ""                 ""
                + ""                 ""
                + ""                 ""
                + ""\r"" + prompt;

            maskThread = new Thread()
            {
                public void run() {
                    while (!interrupted()) {
                        try {
                            Writer out = getOutput();
                            out.write(fullPrompt);
{code}

So the {{prompt}} is null and {{mask}} is NOT in atleast 2 scenarios in beeline. 
when beeline's silent=true, prompt is null
* https://github.com/apache/hive/blob/master/beeline/src/java/org/apache/hive/beeline/BeeLine.java#L1264
when running multiline queries
* https://github.com/apache/hive/blob/master/beeline/src/java/org/apache/hive/beeline/Commands.java#L1093

When executing beeline in script mode (commands in a file), there should not be any masking while reading lines from the script file. aka, entire line should be a beeline command or part of a multiline hive query.

So it should be safe to use a null mask instead of {{ConsoleReader.NULL_MASK}} when using UnsupportedTerminal as jline terminal."
HIVE-19699,Re-enable TestReOptimization,https://builds.apache.org/job/PreCommit-HIVE-Build/11180/testReport/junit/org.apache.hadoop.hive.ql.plan.mapping/TestReOptimization/testStatCachingMetaStore/
HIVE-19698,TestAMReporter#testMultipleAM is flaky,"https://builds.apache.org/job/PreCommit-HIVE-Build/11184/testReport/junit/org.apache.hadoop.hive.llap.daemon.impl.comparator/TestAMReporter/testMultipleAM/

It timeouts sporadically:
https://builds.apache.org/job/PreCommit-HIVE-Build/11184/testReport/junit/org.apache.hadoop.hive.llap.daemon.impl.comparator/TestAMReporter/testMultipleAM/history/
"
HIVE-19697,TestReOptimization#testStatCachingMetaStore is flaky,https://builds.apache.org/job/PreCommit-HIVE-Build/11180/testReport/junit/org.apache.hadoop.hive.ql.plan.mapping/TestReOptimization/testStatCachingMetaStore/
HIVE-19695,Year Month Day extraction functions need to add an implicit cast for column that are String types,"To avoid surprising/wrong results, Hive Query plan shall add an explicit cast over non date/timestamp column type when user try to extract Year/Month/Hour etc..
This is an example of misleading results.
{code}
create table test_base_table(`timecolumn` timestamp, `date_c` string, `timestamp_c` string,  `metric_c` double);
insert into test_base_table values ('2015-03-08 00:00:00', '2015-03-10', '2015-03-08 00:00:00', 5.0);
CREATE TABLE druid_test_table
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (""druid.segment.granularity"" = ""DAY"")
AS select
cast(`timecolumn` as timestamp with local time zone) as `__time`, `date_c`, `timestamp_c`, `metric_c` FROM test_base_table;
select
year(date_c), month(date_c),day(date_c), hour(date_c),
year(timestamp_c), month(timestamp_c),day(timestamp_c), hour(timestamp_c)
from druid_test_table;
{code} 

will return the following wrong results:
{code}
PREHOOK: query: select
year(date_c), month(date_c),day(date_c), hour(date_c),
year(timestamp_c), month(timestamp_c),day(timestamp_c), hour(timestamp_c)
from druid_test_table
PREHOOK: type: QUERY
PREHOOK: Input: default@druid_test_table
#### A masked pattern was here ####
POSTHOOK: query: select
year(date_c), month(date_c),day(date_c), hour(date_c),
year(timestamp_c), month(timestamp_c),day(timestamp_c), hour(timestamp_c)
from druid_test_table
POSTHOOK: type: QUERY
POSTHOOK: Input: default@druid_test_table
#### A masked pattern was here ####
1969	12	31	16	1969	12	31	16 
{code}"
HIVE-19691,Start SessionState in materialized views registry,"SessionState is not initialized when we load the materialized views, which leads to a NullPointerException and other issues."
HIVE-19690,"multi-insert query with multiple GBY, and distinct in only some branches can produce incorrect results",
HIVE-19688,Make catalogs updatable,The initial changes for catalogs did not include an ability to alter catalogs.  We need to add that.
HIVE-19687,Export table on acid partitioned table is failing,"*Reproducer*

{code:sql}
create table exportPartitionTable(id int, name string) partitioned by(country string) clustered by (id) into 2 buckets  stored as orc tblproperties (""transactional""=""true"");
export table exportPartitionTable PARTITION (country='india') to '/tmp/exportDataStore';
{code}

*Error*
{noformat}
FAILED: SemanticException [Error 10004]: Line 1:165 Invalid table alias or column reference 'india': (possible column names are: id, name, country)
{noformat}"
HIVE-19684,Hive stats optimizer wrongly uses stats against non native tables,"Stats of non native tables are inaccurate, thus queries over non native tables can not optimized by stats optimizer.
Take example of query 
{code}
Explain select count(*) from (select `__time` from druid_test_table limit 1) as src ;
{code} 

the plan will be reduced to 
{code}
POSTHOOK: query: explain extended select count(*) from (select `__time` from druid_test_table limit 1) as src
POSTHOOK: type: QUERY
STAGE DEPENDENCIES:
  Stage-0 is a root stage
STAGE PLANS:
  Stage: Stage-0
    Fetch Operator
      limit: 1
      Processor Tree:
        ListSink
{code}"
HIVE-19682,Provide option for GenericUDTFGetSplits to return only schema metadata,"For some uses cases it is necessary to know the output schema for a HiveQL before executing the query. But there is no existing client API that provides this information.

Hive JDBC doesn't provide the schema for parametric types in {{ResultSetMetaData}}.

GenericUDTFGetSplits bundles the proper schema metadata with the fragments for input splits. An option can be added to return only the schema metadata from compilation, and the generation of input splits can be skipped.

"
HIVE-19680,Push down limit is not applied for Druid storage handler.,"Query like 
{code}
select `__time` from druid_test_table limit 1;
{code}
returns more than one row."
HIVE-19677,Disable sample6.q,"Flaky test, already found similar behavior with sample2.q and sample4.q (HIVE-19657). More info to reproduce and try to fix the issue in HIVE-19673."
HIVE-19675,Cast to timestamps on Druid time column leads to an exception,"The following query fail due to a formatting issue.
{code}
SELECT CAST(`ssb_druid_100`.`__time` AS TIMESTAMP) AS `x_time`,
. . . . . . . . . . . . . . . .>   SUM(`ssb_druid_100`.`lo_revenue`) AS `sum_lo_revenue_ok`
. . . . . . . . . . . . . . . .> FROM `druid_ssb`.`ssb_druid_100` `ssb_druid_100`
. . . . . . . . . . . . . . . .> GROUP BY CAST(`ssb_druid_100`.`__time` AS TIMESTAMP);
{code} 
Exception
{code} 
Error: java.io.IOException: java.lang.NumberFormatException: For input string: ""1991-12-31 19:00:00"" (state=,code=0)
{code}
[~jcamachorodriguez] maybe this is fixed by your upcoming patches."
HIVE-19669,Upgrade ORC to 1.5.1,
HIVE-19660,update branch-3 to be version 3.1 and fix storage-api mismatch,"Currently we have branch-3.0 presumably for 3.0.X releases, but branch-3 is marked as 3.0 and master as 3.1-SNAPSHOT.
Also storage-api features break the build on branch-3 because storage-api version does not match."
HIVE-19655,Mask stats for TestMiniLlapLocalCliDriver#smb_mapjoin_15,"Flaky sometimes. We care about algorithm selection, it should be OK to mask."
HIVE-19654,Change tmp staging mapred directory for TestBlobstoreCliDriver,Similar to HIVE-19626.
HIVE-19646,Filesystem closed error in HiveProtoLoggingHook,"Exception in proto logging hook on secure cluster.

{code}
2018-05-18T04:48:01,136 ERROR [Hive Hook Proto Log Writer 0]: hooks.HiveProtoLoggingHook (:()) - Error writing proto message for query hive_20180518043717_ca3ab4df-6cab-4920-aa44-2340ae246ad2, eventType: QUERY_SUBMITTED:
java.io.IOException: Filesystem closed
 at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:472) ~[hadoop-hdfs-client-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1652) ~[hadoop-hdfs-client-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1569) ~[hadoop-hdfs-client-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1566) ~[hadoop-hdfs-client-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1581) ~[hadoop-hdfs-client-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1734) ~[hadoop-common-3.0.0.3.0.0.0-1298.jar:?]
 at org.apache.hadoop.hive.ql.hooks.DatePartitionedLogger.getPathForDate(DatePartitionedLogger.java:89) ~[hive-exec-3.0.0.3.0.0.0-1298.jar:3.0.0.3.0.0.0-1298]
 at org.apache.hadoop.hive.ql.hooks.DatePartitionedLogger.getWriter(DatePartitionedLogger.java:73) ~[hive-exec-3.0.0.3.0.0.0-1298.jar:3.0.0.3.0.0.0-1298]
 at org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook$EventLogger.writeEvent(HiveProtoLoggingHook.java:283) ~[hive-exec-3.0.0.3.0.0.0-1298.jar:3.0.0.3.0.0.0-1298]
 at org.apache.hadoop.hive.ql.hooks.HiveProtoLoggingHook$EventLogger.lambda$generateEvent$1(HiveProtoLoggingHook.java:274) ~[hive-exec-3.0.0.3.0.0.0-1298.jar:3.0.0.3.0.0.0-1298]
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_161]
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_161]
 at java.lang.Thread.run(Thread.java:748) [?:1.8.0_161]
{code}"
HIVE-19644,change WM syntax to avoid conflicts with identifiers starting with a number,"Time/etc literals conflict with non-ANSI query column names starting with a number that were previously supported without quotes (e.g. 30days).
"
HIVE-19643,MM table conversion doesn't need full ACID structure checks,
HIVE-19639,a transactional Hive table cannot be imported as an external table,"When transactional table is imported to a external table, the table should be imported as a non transactional table, as external tables cannot be transactional.
"
HIVE-19637,Add slow test report script to testutils,"Wrote the attached utility script to find top K slow tests from precommit test url. Would like to get that committed to testutils so that its useful for everyone.

{code:title=ascii mode}
$ python gen-report.py -b 11102 -a

Processing 1073 test xml reports from http://104.198.109.242/logs/PreCommit-HIVE-Build-11102/test-results/..

Top 25 testsuite in terms of execution time (in seconds).. [Total time: 73882.661 seconds]

##########################################################################################################
██████████████████████████████████████████████████  20806  TestCliDriver
███████████████████████                              9601  TestMiniLlapLocalCliDriver
███████████████████                                  8210  TestSparkCliDriver
██████                                               2744  TestMinimrCliDriver
█████                                                2262  TestEncryptedHDFSCliDriver
████                                                 2021  TestMiniSparkOnYarnCliDriver
████                                                 1808  TestHiveCli
███                                                  1566  TestMiniLlapCliDriver
███                                                  1345  TestReplicationScenarios
██                                                   1238  TestMiniDruidCliDriver
██                                                    940  TestNegativeCliDriver
██                                                    865  TestHBaseCliDriver
█                                                     681  TestMiniTezCliDriver
█                                                     555  TestTxnCommands2WithSplitUpdateAndVectorization
█                                                     543  TestCompactor
█                                                     528  TestTxnCommands2
                                                      378  TestStreaming
                                                      374  TestBlobstoreCliDriver
                                                      328  TestNegativeMinimrCliDriver
                                                      302  TestTxnCommandsWithSplitUpdateAndVectorization
                                                      301  TestHCatClient
                                                      299  TestTxnCommands
                                                      261  TestTxnLoadData
                                                      258  TestAcidOnTez
                                                      240  TestHBaseNegativeCliDriver

Top 25 testcases in terms of execution time (in seconds).. [Total time: 63102.607 seconds]

###############################################################################################################################################
██████████████████████████████████████████████████  680  TestMinimrCliDriver_testCliDriver[infer_bucket_sort_reducers_power_two]
█████████████████████████████████████████████       623  TestMinimrCliDriver_testCliDriver[infer_bucket_sort_map_operators]
███████████████████████████████                     429  TestMinimrCliDriver_testCliDriver[infer_bucket_sort_dyn_part]
███████████████████████████                         374  TestSparkCliDriver_testCliDriver[vectorization_short_regress]
███████████████████████████                         374  TestMiniLlapLocalCliDriver_testCliDriver[vectorization_short_regress]
████████████████████████                            330  TestMiniDruidCliDriver_testCliDriver[druidmini_dynamic_partition]
█████████████████                                   238  TestMiniLlapLocalCliDriver_testCliDriver[vector_outer_join5]
████████████████                                    227  TestMiniDruidCliDriver_testCliDriver[druidmini_test_insert]
███████████████                                     214  TestEncryptedHDFSCliDriver_testCliDriver[encryption_auto_purge_tables]
███████████████                                     211  TestMiniLlapCliDriver_testCliDriver[unionDistinct_1]
███████████████                                     210  TestMiniSparkOnYarnCliDriver_testCliDriver[vector_outer_join5]
███████████████                                     206  TestMinimrCliDriver_testCliDriver[bucket_num_reducers_acid]
██████████████                                      202  TestMinimrCliDriver_testCliDriver[infer_bucket_sort_merge]
██████████████                                      198  TestCliDriver_testCliDriver[typechangetest]
████████████                                        172  TestEncryptedHDFSCliDriver_testCliDriver[encryption_drop_table]
████████████                                        164  TestMinimrCliDriver_testCliDriver[infer_bucket_sort_num_buckets]
███████████                                         158  TestCliDriver_testCliDriver[mm_all]
███████████                                         155  TestMiniSparkOnYarnCliDriver_testCliDriver[spark_dynamic_partition_pruning]
██████████                                          145  TestMiniSparkOnYarnCliDriver_testCliDriver[spark_vectorized_dynamic_partition_pruning]
██████████                                          141  TestMiniLlapCliDriver_testCliDriver[mm_all]
██████████                                          140  TestMiniDruidCliDriver_testCliDriver[druidmini_mv]
██████████                                          137  TestSparkCliDriver_testCliDriver[auto_join_filters]
█████████                                           135  TestMiniLlapLocalCliDriver_testCliDriver[vector_outer_join3]
█████████                                           124  TestMiniSparkOnYarnCliDriver_testCliDriver[vector_outer_join3]
████████                                            121  TestCliDriver_testCliDriver[type_change_test_int_vectorized]
{code}

{code:title=text mode}
$ python gen-report.py -b 11102

Processing 1073 test xml reports from http://104.198.109.242/logs/PreCommit-HIVE-Build-11102/test-results/..

Top 25 testsuite in terms of execution time (in seconds).. [Total time: 73882.661 seconds]
TestCliDriver	20805.579
TestMiniLlapLocalCliDriver	9601.362
TestSparkCliDriver	8210.062
TestMinimrCliDriver	2743.746
TestEncryptedHDFSCliDriver	2261.866
TestMiniSparkOnYarnCliDriver	2021.468
TestHiveCli	1807.56
TestMiniLlapCliDriver	1565.858
TestReplicationScenarios	1345.344
TestMiniDruidCliDriver	1237.776
TestNegativeCliDriver	940.321
TestHBaseCliDriver	864.707
TestMiniTezCliDriver	681.457
TestTxnCommands2WithSplitUpdateAndVectorization	555.382
TestCompactor	543.173
TestTxnCommands2	527.84
TestStreaming	378.325
TestBlobstoreCliDriver	374.134
TestNegativeMinimrCliDriver	328.128
TestTxnCommandsWithSplitUpdateAndVectorization	301.718
TestHCatClient	301.324
TestTxnCommands	298.694
TestTxnLoadData	260.841
TestAcidOnTez	258.262
TestHBaseNegativeCliDriver	240.198

Top 25 testcases in terms of execution time (in seconds).. [Total time: 63102.607 seconds]
TestMinimrCliDriver_testCliDriver[infer_bucket_sort_reducers_power_two]	680.326
TestMinimrCliDriver_testCliDriver[infer_bucket_sort_map_operators]	623.404
TestMinimrCliDriver_testCliDriver[infer_bucket_sort_dyn_part]	429.358
TestSparkCliDriver_testCliDriver[vectorization_short_regress]	374.491
TestMiniLlapLocalCliDriver_testCliDriver[vectorization_short_regress]	374.164
TestMiniDruidCliDriver_testCliDriver[druidmini_dynamic_partition]	329.945
TestMiniLlapLocalCliDriver_testCliDriver[vector_outer_join5]	238.5
TestMiniDruidCliDriver_testCliDriver[druidmini_test_insert]	226.773
TestEncryptedHDFSCliDriver_testCliDriver[encryption_auto_purge_tables]	214.09
TestMiniLlapCliDriver_testCliDriver[unionDistinct_1]	210.803
TestMiniSparkOnYarnCliDriver_testCliDriver[vector_outer_join5]	209.894
TestMinimrCliDriver_testCliDriver[bucket_num_reducers_acid]	206.339
TestMinimrCliDriver_testCliDriver[infer_bucket_sort_merge]	201.754
TestCliDriver_testCliDriver[typechangetest]	198.371
TestEncryptedHDFSCliDriver_testCliDriver[encryption_drop_table]	172.267
TestMinimrCliDriver_testCliDriver[infer_bucket_sort_num_buckets]	163.617
TestCliDriver_testCliDriver[mm_all]	158.401
TestMiniSparkOnYarnCliDriver_testCliDriver[spark_dynamic_partition_pruning]	155.255
TestMiniSparkOnYarnCliDriver_testCliDriver[spark_vectorized_dynamic_partition_pruning]	145.481
TestMiniLlapCliDriver_testCliDriver[mm_all]	141.369
TestMiniDruidCliDriver_testCliDriver[druidmini_mv]	139.815
TestSparkCliDriver_testCliDriver[auto_join_filters]	137.391
TestMiniLlapLocalCliDriver_testCliDriver[vector_outer_join3]	135.227
TestMiniSparkOnYarnCliDriver_testCliDriver[vector_outer_join3]	124.469
TestCliDriver_testCliDriver[type_change_test_int_vectorized]	120.85
{code}"
HIVE-19632,Remove webapps directory from standalone jar,JDBC standalone jar contains webapps static files which just adds to the jar size and are not required by the clients. 
HIVE-19631,reduce epic locking in AbstractService,"Some services have synchronized method that do lengthy remote calls, and these block everyone trying to e.g. getHiveConf. "
HIVE-19629,Enable Decimal64 reader after orc version upgrade,ORC 1.5.0 supports new fast decimal 64 reader. New VRB has to be created for making use of decimal 64 column vectors. Also LLAP IO will need a new reader to reader from long stream to decimal 64. 
HIVE-19626,Change tmp staging mapred directory for CliDriver,"We do not see many failures anymore, but one of the intermittent ones is this:
https://builds.apache.org/job/PreCommit-HIVE-Build/11101/testReport/junit/org.apache.hadoop.hive.cli/TestCliDriver/testCliDriver_localtimezone_/

As with other tests, we can change the staging directory property value."
HIVE-19620,Change tmp directory used by PigServer in HCat tests,
HIVE-19619,Allow comparisons between doubles and bigints,"Hive doesn't allow binary comparison between doubles and bigints. That is overly restrictive since all other DBs (mysql, postgres, oracle and sql server) allows that."
HIVE-19617,Rename test tables to avoid collisions during execution in batches,
HIVE-19615,Proper handling of is null and not is null predicate when pushed to Druid,"Recent development in Druid introduced new semantic of null handling [here|https://github.com/b-slim/druid/commit/219e77aeac9b07dc20dd9ab2dd537f3f17498346]

Based on those changes when need to honer push down of expressions with is null/ is not null predicates.
The prosed fix overrides the mapping of Calcite Function to Druid Expression to much the correct semantic.

"
HIVE-19614,GenericUDTFGetSplits does not honor ORDER BY,GenericUDTFGetSplits handles ORDER BY by writing the results to temp table. However running select * on that temp table may create >1 splits which will lose the original ordering. 
HIVE-19613,GenericUDTFGetSplits should handle fetch task with temp table rewrite,"GenericUDTFGetSplits fails for fetch task only queries. Fetch task only queries can be handled same way as >1 task queries using temp tables. 
{code:java}
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Was expecting a single TezTask.
at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.createPlanFragment(GenericUDTFGetSplits.java:262)
at org.apache.hadoop.hive.ql.udf.generic.GenericUDTFGetSplits.process(GenericUDTFGetSplits.java:201)
at org.apache.hadoop.hive.ql.exec.UDTFOperator.process(UDTFOperator.java:116)
at org.apache.hadoop.hive.ql.exec.Operator.baseForward(Operator.java:984)
at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:930)
at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:917)
at org.apache.hadoop.hive.ql.exec.SelectOperator.process(SelectOperator.java:95)
at org.apache.hadoop.hive.ql.exec.Operator.baseForward(Operator.java:984)
at org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:930)
at org.apache.hadoop.hive.ql.exec.TableScanOperator.process(TableScanOperator.java:125)
at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:492)
at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:484)
at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:145)
... 16 more{code}"
HIVE-19612,Add option to mask lineage in q files,"Similar to {{HIVE-19572}}, with {{-- MASK_LINEAGE}}."
HIVE-19608,disable flaky tests 2,"union_stats
{noformat}
java.lang.AssertionError: 
Client Execution succeeded but contained differences (error code = 1) after executing union_stats.q 
362a363
> 	COLUMN_STATS_ACCURATE	{\""BASIC_STATS\"":\""true\""}
364a366,367
> 	numRows             	1000                
> 	rawDataSize         	10624    
{noformat}
Every few runs
bucketizedinputformat for MiniSparkOnYarn; OOMs occasionally, example https://issues.apache.org/jira/browse/HIVE-19596



"
HIVE-19605,TAB_COL_STATS table has no index on db/table name,"The TAB_COL_STATS table is missing an index on (CAT_NAME, DB_NAME, TABLE_NAME). The getTableColumnStatistics call queries based on this tuple. This makes those queries take a significant amount of time in large metastores since they do a full table scan."
HIVE-19604,Incorrect Handling of Boolean in DruidSerde,"Results of boolean expressions from Druid are expressed in the form of numeric 1 or 0. 
When reading the results in DruidSerde both 1 and 0 are translated to String and then we call Boolean.valueOf(stringForm), this leads to the boolean being read always as false."
HIVE-19598,Add Acid V1 to V2 upgrade module,"The on-disk layout for full acid (transactional) tables has changed 3.0.

Any transactional table that has any update/delete events in any deltas that have not been Major compacted, must go through a Major compaction before upgrading to 3.0.  No more update/delete/merge should be run after/during major compaction.

Not doing so will result in data corruption/loss.

 

Need to create a utility tool to help with this process.  HIVE-19233 started this but it needs more work."
HIVE-19595,Regenerate webui port in MiniHS2,Causes tests flakiness if they same port is used.
HIVE-19594,Add custom tmp folders to tests to avoid collisions,
HIVE-19592,TestWorkloadManager - add retry for now,
HIVE-19590,mask stats in llap_smb,
HIVE-19589,Disable TestAutoPurge tests and annotate TestTriggersWorkloadManager with retry,
HIVE-19588,Several invocation of file listing when creating VectorizedOrcAcidRowBatchReader,"Looks like we are doing file listing several times when creating one instance of VectorizedOrcAcidRowBatchReader
 AcidUtils.parseBaseOrDeltaBucketFilename() does full file listing (when there are files with bucket_* prefix) just to get a single file out of a path to figure out if it has ACID schema (as part of HIVE-18190).
 There is full file listing where we populate
 1) ColumnizedDeleteEventRegistry
 2) SortMergedDeleteEventRegistry
 3) Twice in computeOffsetAndBucket()

 

Attaching profiles which [~gopalv] took while debugging. "
HIVE-19586,Optimize Count(distinct X) pushdown based on the storage capabilities ,"h1. Goal
Provide a way to rewrite queries with combination of COUNT(Distinct) and Aggregates like SUM as a series of Group By.
This can be useful to push down to Druid queries like 
{code}
 select count(DISTINCT interval_marker), count (distinct dim), sum(num_l) FROM druid_test_table GROUP  BY `__time`, `zone` ;
{code}
In general this can be useful to be used in cases where storage handlers can not perform count (distinct column)

h1. How to do it.
Use the Calcite rule {code} org.apache.calcite.rel.rules.AggregateExpandDistinctAggregatesRule{code} that breaks down Count distinct to a single Group by with Grouping sets or multiple series of Group by that might be linked with Joins if multiple counts are present.
FYI today Hive does have a similar rule {code} org.apache.hadoop.hive.ql.optimizer.calcite.rules.HiveExpandDistinctAggregatesRule{code}, but it only provides a rewrite to Grouping sets based plan.
I am planing to use the actual Calcite rule, [~ashutoshc] any concerns or caveats to be aware of?

h2. Concerns/questions
Need to have a way to switch between Grouping sets or Simple chained group by based on the plan cost. For instance for Druid based scan it makes always sense (at least today) to push down a series of Group by and stitch result sets in Hive later (as oppose to scan everything). 
But this might be not true for other storage handler that can handle Grouping sets it is better to push down the Grouping sets as one table scan.
Am still unsure how i can lean on the cost optimizer to select the best plan, [~ashutoshc]/[~jcamachorodriguez] any inputs?


"
HIVE-19578,HLL merges tempList on every add, See comments on HIVE-18866; this has significant perf overhead after the even bigger overhead from hashing is removed.  !Screen Shot 2018-05-16 at 15.29.12 .png!
HIVE-19577,CREATE TEMPORARY TABLE LIKE  and INSERT generate output format mismatch errors,
HIVE-19575,TestAutoPurgeTables seems flaky,I cannot reproduce the flakiness locally. Maybe we can retry this flaky test using RetryTestRunner. 
HIVE-19573,Fix flaky TestMiniLlapLocalCliDriver#explainuser_4.q,
HIVE-19572,Add option to mask stats and data size in q files,"Some tests are flaky because of minimal data size differences, e.g., one byte. However, many times we do not actually care about these differences. One example is {{default_constraint.q}}.

Patch adds the possibility to mask 1) printing of stats selectively on q files by adding the {{-- MASK_STATS}} option, and 2) printing of data size stats selectively on q files by adding the {{-- MASK_DATA_SIZE}} option."
HIVE-19569,alter table db1.t1 rename db2.t2 generates MetaStoreEventListener.onDropTable(),"When renaming a table within the same DB, this operation causes {{MetaStoreEventListener.onAlterTable()}} to fire but when changing DB name for a table it causes {{MetaStoreEventListener.onDropTable()}} + {{MetaStoreEventListener.onCreateTable()}}.
The files from original table are moved to new table location.  
This creates confusing semantics since any logic in {{onDropTable()}} doesn't know about the larger context, i.e. that there will be a matching {{onCreateTable()}}.

In particular, this causes a problem for Acid tables since files moved from old table use WriteIDs that are not meaningful with the context of new table.

Current implementation is due to replication.  This should ideally be changed to raise a ""not supported"" error for tables that are marked for replication.

cc [~sankarh]"
HIVE-19567,Fix flakiness in TestTriggers,Identified another flakiness in TestTriggersMoveWorkloadManager which can cause intermittent test failures. 
HIVE-19565,Vectorization: Fix NULL / Wrong Results issues in STRING Functions,"Write new UT tests that use random data and intentional isRepeating batches to checks for NULL and Wrong Results for vectorized STRING functions:
 * char_length
 * concat
 * initcap
 * length
 * lower
 * ltrim
 * octet_length
 * rtrim
 * trim
 * upper
 * UDF:
 ** hex
 ** substr

BUGs found in LTRIM, CONCAT, and SUBSTR."
HIVE-19562,Flaky test: TestMiniSparkOnYarn FileNotFoundException in spark-submit,"Seeing sporadic failures during test setup. Specifically, when spark-submit runs this error (or a similar error) gets thrown:

{code}
2018-05-15T10:55:02,112  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient: Exception in thread ""main"" java.io.FileNotFoundException: File file:/tmp/spark-56e217f7-b8a5-4c63-9a6b-d737a64f2820/__spark_libs__7371510645900072447.zip does not exist
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:641)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:867)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:631)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:442)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:365)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:316)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.copyFileToRemote(Client.scala:356)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.org$apache$spark$deploy$yarn$Client$$distribute$1(Client.scala:478)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.prepareLocalResources(Client.scala:565)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.createContainerLaunchContext(Client.scala:863)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.submitApplication(Client.scala:169)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.Client.run(Client.scala:1146)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.yarn.YarnClusterApplication.start(Client.scala:1518)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136)
2018-05-15T10:55:02,113  INFO [RemoteDriver-stderr-redir-27d3dcfb-2a10-4118-9fae-c200d2e095a5 main] client.SparkSubmitSparkClient:      at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
{code}

Essentially, Spark is writing some files for container localization to a tmp dir, and that tmp dir is getting deleted. We have seen a lot of issues with writing files to {{/tmp/}} in the past, so its probably best to write these files to a test-specific dir."
HIVE-19560,Retry test runner and retry rule for flaky tests,"Implement custom test runner that retries failed tests as a workaround for flakiness. Also a test rule for retrying failed tests (for cases where custom test runner is not possible, e.g ParametrizedTests which already is a customer TestRunner). "
HIVE-19557,stats: filters for dates are not taking advantage of min/max values,"in StatsRulesProcFactory 
[https://github.com/apache/hive/blob/ab189f54047bbf6beeeaf8d0dcfd5fbe92e465fb/ql/src/java/org/apache/hadoop/hive/ql/optimizer/stats/annotation/StatsRulesProcFactory.java#L754|dates are assumed to be an integer]; however this is currently not true - and the resulting exception is handled as a default case... for N/3


{code}
set hive.explain.user=true;

create table d1(d date);
--  tblproperties('transactional'='false');

insert into d1 values
        ('2010-10-01'),
        ('2010-10-02'),
        ('2010-10-03'),
        ('2010-10-04'),
        ('2010-10-05'),
        ('2010-10-06'),
        ('2010-10-07'),
        ('2010-10-08'),
        ('2010-10-09'),
        ('2010-10-10');

analyze table d1 compute statistics for columns;

desc formatted d1;
desc formatted d1 d;

explain
select 'stats: FIL ~0 read',count(1) from d1 where d < '2010-03-01';

explain
select 'stats: FIL estimate some read',count(1) from d1 where d < '2010-10-03';

explain
select 'stats: FIL estimate all read',count(1) from d1 where d < '2010-11-03';
{code}"
HIVE-19555,Enable TestMiniLlapLocalCliDriver#tez_dynpart_hashjoin_1.q and TestMiniLlapLocalCliDriver#tez_vector_dynpart_hashjoin_1.q,
HIVE-19534,Allow implementations to access member variables of AbstractRecordWriter,"The AbstractRecordWriter class in the Hive 3 Streaming API (package org.apache.hive.streaming) provides common functionality for processing incoming records (each as a byte[]) where subclasses often need only to implement the encode() and createSerde() methods and let AbstractRecordWriter handle the rest.

However for some custom RecordWriters, the records may not be available as a byte array, and thus the custom RecordWriter may need to handle the writes and the ""paperwork"" such as connection stats updates (number of records written, e.g.), basically the same code that is in the write(long, byte[]) method. To do that, the subclass will need access to the member variables of AbstractRecordWriter, which are currently private. The same likely holds for the private methods.

This Jira proposes to make the member variables and methods of AbstractRecordWriter protected (or package-protected) as prudent. "
HIVE-19530,Vectorization: Fix JDBCSerde and re-enable vectorization,According to [~jcamachorodriguez] there is a big switch statement in the code that has might have missing types. This can lead to the string types seen.
HIVE-19529,Vectorization: Date/Timestamp NULL issues,"Wrong results found for:
 date_add/date_sub

UT areas:
 date_add/date_sub

datediff

to_date

interval_year_month + interval_year_month
 interval_day_time + interval_day_time
 interval_day_time + timestamp
 timestamp + interval_day_time
 date + interval_day_time
 interval_day_time + date
 interval_year_month + date
 date + interval_year_month
 interval_year_month + interval_year_month
 timestamp + interval_year_month

date - date
 interval_year_month - interval_year_month
 interval_day_time - interval_day_time
 timestamp - interval_day_time
 timestamp - timestamp
 date - timestamp
 timestamp - date
 date - interval_day_time
 date - interval_year_month
 timestamp - interval_year_month"
HIVE-19516,TestNegative merge_negative_5 and mm_concatenate are causing timeouts,"I haven't tried to reproduce this in isolation but it is reproducible if you run in batch on local system 
{noformat}
mvn -B test  -Dtest.groups= -Dtest=TestNegativeCliDriver -Dqfile=udf_invalid.q,authorization_uri_export.q,default_constraint_complex_default_value.q,druid_datasource2.q,check_constraint_max_length.q,view_update.q,default_partition_name.q,authorization_public_create.q,load_wrong_fileformat_rc_seq.q,default_constraint_invalid_type.q,altern1.q,describe_xpath1.q,drop_view_failure2.q,temp_table_rename.q,invalid_select_column_with_subquery.q,udf_trunc_error1.q,insert_view_failure.q,dbtxnmgr_nodbunlock.q,authorization_show_columns.q,cte_recursion.q,merge_constraint_notnull.q,clusterbyorderby.q,orc_type_promotion2.q,ctas_noperm_loc.q,udf_min.q,udf_instr_wrong_args_len.q,invalid_create_tbl2.q,part_col_complex_type.q,authorization_drop_db_empty.q,smb_mapjoin_14.q,subquery_scalar_multi_rows.q,alter_partition_coltype_2columns.q,subquery_corr_in_agg.q,insert_overwrite_notnull_constraint.q,authorization_show_grant_otheruser_wtab.q,regex_col_groupby.q,ptf_negative_DuplicateWindowAlias.q,exim_22_export_authfail.q,authorization_insert_noinspriv.q,udf_likeany_wrong1.q,groupby_key.q,ambiguous_col.q,groupby3_multi_distinct.q,authorization_alter_drop_ptn.q,invalid_cast_from_binary_5.q,show_create_table_does_not_exist.q,invalid_select_column.q,exim_20_managed_location_over_existing.q,interval_3.q,authorization_compile.q,join35.q,udf_concat_ws_wrong3.q,create_or_replace_view8.q,create_external_with_notnull_constraint.q,split_sample_out_of_range.q,materialized_view_no_transactional_rewrite.q,authorization_show_grant_otherrole.q,create_with_constraints_duplicate_name.q,invalid_stddev_samp_syntax.q,authorization_view_disable_cbo_7.q,autolocal1.q,avro_non_nullable_union.q,load_orc_negative_part.q,drop_view_failure1.q,columnstats_partlvl_invalid_values_autogather.q,exim_13_nonnative_import.q,alter_table_wrong_regex.q,udf_next_day_error_2.q,authorization_select.q,udf_trunc_error2.q,authorization_view_7.q,udf_format_number_wrong5.q,touch2.q,orc_type_promotion1.q,lateral_view_alias.q,show_tables_bad_db1.q,unset_table_property.q,alter_non_native.q,nvl_mismatch_type.q,load_orc_negative3.q,authorization_create_role_no_admin.q,invalid_distinct1.q,authorization_grant_server.q,orc_type_promotion3_acid.q,hms_using_serde_alter_table_update_columns.q,show_tables_bad1.q,macro_unused_parameter.q,drop_invalid_constraint3.q,drop_partition_filter_failure.q,char_pad_convert_fail3.q,exim_23_import_exist_authfail.q,drop_invalid_constraint4.q,authorization_create_macro1.q,archive1.q,subquery_multiple_cols_in_select.q,change_hive_hdfs_session_path.q,udf_trunc_error3.q,invalid_variance_syntax.q,authorization_truncate_2.q,invalid_avg_syntax.q,invalid_select_column_with_tablename.q,mm_truncate_cols.q,groupby_grouping_sets1.q,druid_location.q,groupby2_multi_distinct.q,authorization_sba_drop_table.q,dynamic_partitions_with_whitelist.q,compare_string_bigint_2.q,udf_greatest_error_2.q,authorization_view_6.q,show_tablestatus.q,duplicate_alias_in_transform_schema.q,create_with_fk_uk_same_tab.q,udtf_not_supported3.q,alter_table_constraint_invalid_fk_col2.q,udtf_not_supported1.q,dbtxnmgr_notableunlock.q,ptf_negative_InvalidValueBoundary.q,alter_table_constraint_duplicate_pk.q,udf_printf_wrong4.q,create_view_failure9.q,udf_elt_wrong_type.q,selectDistinctStarNeg_1.q,invalid_mapjoin1.q,load_stored_as_dirs.q,input1.q,udf_sort_array_wrong1.q,invalid_distinct2.q,invalid_select_fn.q,authorization_role_grant_otherrole.q,archive4.q,load_nonpart_authfail.q,recursive_view.q,authorization_view_disable_cbo_1.q,desc_failure4.q,create_not_acid.q,udf_sort_array_wrong3.q,char_pad_convert_fail0.q,udf_map_values_arg_type.q,alter_view_failure6_2.q,alter_partition_change_col_nonexist.q,update_non_acid_table.q,authorization_view_disable_cbo_5.q,ct_noperm_loc.q,interval_1.q,authorization_show_grant_otheruser_all.q,authorization_view_2.q,show_tables_bad2.q,groupby_rollup2.q,truncate_column_seqfile.q,create_view_failure5.q,authorization_create_view.q,ptf_window_boundaries.q,ctasnullcol.q,input_part0_neg_2.q,create_or_replace_view1.q,udf_max.q,exim_01_nonpart_over_loaded.q,msck_repair_1.q,orc_change_fileformat_acid.q,udf_nonexistent_resource.q,msck_repair_3.q,exim_19_external_over_existing.q,serde_regex2.q,msck_repair_2.q,exim_06_nonpart_noncompat_storage.q,illegal_partition_type4.q,udf_sort_array_by_wrong1.q,windowing_leadlag_in_udaf.q,avro_decimal.q,materialized_view_update.q,illegal_partition_type2.q,invalid_varchar_length_1.q,authorization_view_5.q,nested_complex_neg.q,lockneg_try_drop_locked_db.q,constraint_partition_columns.q,authorization_insertpart_noinspriv.q,avro_add_column_extschema.q,udf_sort_array_wrong2.q,drop_database_cascade.q,archive3.q,alter_view_failure5.q,load_orc_negative1.q,create_external_acid.q,check_constraint_temporary_udf.q,file_with_header_footer_negative.q,alter_view_failure6.q,create_view_failure6.q,char_pad_convert_fail1.q,invalid_var_samp_syntax.q,update_partition_col.q,database_create_already_exists.q,union2.q,windowing_invalid_udaf.q,authorization_public_drop.q,truncate_table_failure5.q,alter_view_failure2.q,udf_reflect_neg.q,interval_2.q,column_rename2.q,set_hiveconf_validation0.q,materialized_view_drop2.q,repl_dump_requires_admin.q,alter_view_failure7.q,alter_view_failure4.q,alter_view_failure3.q,udf_map_keys_arg_type.q,alter_partition_with_whitelist.q,authorization_show_role_principals_no_admin.q,table_nonprintable_negative.q,clusterbydistributeby.q,authorization_rolehierarchy_privs.q,alter_notnull_constraint_violation.q,check_constraint_aggregate.q,script_broken_pipe3.q,column_rename3.q,authorization_fail_create_db.q,compute_stats_long.q,sortmerge_mapjoin_mismatch_1.q,insert_into6.q,select_charliteral.q,fs_default_name2.q,check_constraint_qual_name.q,archive_multi5.q,input4.q,create_udaf_failure.q,create_table_failure1.q,regex_col_1.q,materialized_view_authorization_no_select_perm.q,decimal_precision_1.q,columnstats_partlvl_multiple_part_clause.q,udf_if_not_bool.q,materialized_view_replace_with_view.q,invalid_cast_to_binary_6.q,lockneg5.q,mm_delete.q,database_drop_not_empty.q,smb_bucketmapjoin.q,alter_rename_partition_failure2.q,invalid_cast_to_binary_4.q,decimal_precision.q,create_view_failure10.q,invalid_cast_to_binary_3.q,groupby_invalid_position.q,load_wrong_fileformat_txt_seq.q,exchange_partition_neg_partition_exists.q,authorization_not_owner_alter_tab_serdeprop.q,alter_rename_partition_failure.q,merge_negative_5.q,authorization_invalid_priv_v2.q,bucket_mapjoin_wrong_table_metadata_1.q,lockneg2.q,join28.q,exchange_partition_neg_test.q,lockneg_try_lock_db_in_use.q,udf_assert_true.q,udf_coalesce.q,join29.q,archive_partspec4.q,exim_24_import_part_authfail.q,exim_08_nonpart_noncompat_serde.q,udtf_explode_not_supported4.q,create_view_failure4.q,default_constraint_invalid_default_value_type.q,invalid_char_length_1.q,udf_in.q,create_view_failure3.q,strict_pruning_2.q,insertexternal1.q,alter_partition_change_col_dup_col.q,authorization_ctas2.q,uniquejoin.q,authorization_role_grant_nosuchrole.q,column_rename4.q,create_with_fk_wrong_ref2.q,authorization_role_case.q,udf_if_wrong_args_len.q,create_skewed_table_col_name_value_no_mismatch.q,compare_string_bigint.q,archive_insert2.q,authorization_grant_table_fail1.q,exim_02_all_part_over_overlap.q,archive_multi1.q,subquery_in_groupby.q,authorization_role_grant.q,insert_into_with_schema3.q,create_with_fk_constraint.q,materialized_view_insert.q,orc_replace_columns1.q,updateBasicStats.q,udf_likeall_wrong1.q,udf_map_keys_arg_num.q,subquery_scalar_corr_multi_rows.q,exchange_partition_neg_partition_exists2.q,udf_test_error.q,distinct_windowing_failure2.q,authorization_caseinsensitivity.q,update_bucket_col.q,create_or_replace_view3.q,lockneg_query_tbl_in_locked_db.q,authorization_select_view.q,check_constraint_tbl_level.q,create_or_replace_view4.q,disallow_incompatible_type_change_on2.q,ptf_negative_DistributeByOrderBy.q,desc_failure3.q,create_insert_outputformat.q,alter_table_wrong_location2.q,groupby_grouping_sets5.q,authorization_uri_create_table_ext.q,invalid_t_create2.q,load_data_parquet_empty.q,groupby_grouping_sets6.q,subquery_corr_grandparent.q,archive_insert3.q,authorization_alter_table_exchange_partition_fail2.q,invalid_cast_from_binary_2.q,authorize_grant_public.q,authorization_fail_drop_db.q,insert_into_with_schema4.q,parquet_alter_part_table_drop_columns.q,unionSortBy.q,invalid_char_length_2.q,insert_multi_into_notnull.q,groupby_grouping_id1.q,strict_orderby_2.q,udf_next_day_error_1.q,authorize_revoke_public.q,load_part_authfail.q,drop_default_partition_filter.q,orc_replace_columns2.q,alter_file_format.q,authorization_alter_db_owner_default.q,authorization_uri_createdb.q,authorization_import_ptn.q,selectDistinctWithoutAggr.q,split_sample_wrong_format.q,authorization_fail_8.q,regex_col_2.q,ptf_negative_PartitionBySortBy.q,stats_aggregator_error_2.q,drop_table_failure1.q,stats_aggregator_error_1.q,udf_concat_ws_wrong1.q,exim_12_nonnative_export.q,clustern4.q,strict_orderby.q,authorization_insertoverwrite_nodel.q,exim_18_part_spec_missing.q,invalid_t_transform.q,columnstats_tbllvl_complex_type.q,authorization_grant_table_allpriv.q,msck_repair_4.q,set_hiveconf_validation1.q,authorization_alter_table_exchange_partition_fail.q,ctas_noemptyfolder.q,clustern2.q,set_hiveconf_validation2.q,bucket_mapjoin_mismatch1.q,mm_convert.q,truncate_bucketed_column.q,druid_datasource.q,udf_assert_true2.q,strict_join_2.q,udf_format_number_wrong3.q,default_constraint_invalid_default_value_length.q,masking_acid_update.q,materialized_view_no_transactional_rewrite_2.q,materialized_view_authorization_drop_other.q,dyn_part1.q,default_constraint_invalid_default_value2.q,select_star_suffix.q,subquery_select_distinct.q,authorization_uri_create_table1.q,special_character_in_tabnames_1.q,archive_partspec2.q,analyze_non_existent_tbl.q,create_with_pk_constraints_enforced.q,orderby_position_unsupported.q,subquery_subquery_chain_exists.q,orc_reorder_columns1_acid.q,subquery_notin_implicit_gby.q,notable_alias4.q,semijoin2.q,desc_failure1.q,ptf_negative_HavingLeadWithPTF.q,alter_tableprops_external_with_default_constraint.q,create_unknown_udf_udaf.q,materialized_view_authorization_create_no_grant.q,orc_change_serde.q,uniquejoin3.q,stats_publisher_error_1.q,authorization_part.q,alter_table_constraint_invalid_fk_tbl1.q,fileformat_void_input.q,truncate_table_failure3.q,alter_table_constraint_invalid_fk_tbl2.q,mismatch_columns_insertion.q,repl_load_requires_admin.q
{noformat}

{noformat}
mvn -B test  -Dtest.groups= -Dtest=TestNegativeCliDriver -Dqfile=nopart_insert.q,insert_into_with_schema.q,input41.q,having1.q,create_table_failure3.q,default_constraint_invalid_default_value.q,database_drop_not_empty_restrict.q,windowing_after_orderby.q,orderbysortby.q,subquery_select_distinct2.q,authorization_uri_alterpart_loc.q,udf_last_day_error_1.q,constraint_duplicate_name.q,create_table_failure4.q,alter_tableprops_external_with_notnull_constraint.q,semijoin5.q,udf_format_number_wrong4.q,deletejar.q,exim_11_nonpart_noncompat_sorting.q,show_tables_bad_db2.q,drop_func_nonexistent.q,alter_table_non_partitioned_table_cascade.q,check_constraint_subquery.q,load_wrong_fileformat.q,check_constraint_udtf.q,lockneg_try_db_lock_conflict.q,udf_field_wrong_args_len.q,create_table_failure2.q,create_with_fk_constraints_enforced.q,groupby2_map_skew_multi_distinct.q,mm_update.q,authorization_update_noupdatepriv.q,show_columns2.q,authorization_insert_noselectpriv.q,orc_replace_columns3_acid.q,compare_double_bigint.q,authorization_set_nonexistent_conf.q,alter_rename_partition_failure3.q,split_sample_wrong_format2.q,create_with_fk_pk_same_tab.q,compare_double_bigint_2.q,authorization_show_roles_no_admin.q,materialized_view_authorization_rebuild_no_grant.q,unionLimit.q,authorization_revoke_table_fail2.q,duplicate_insert3.q,authorization_desc_table_nosel.q,stats_noscan_non_native.q,orc_change_serde_acid.q,create_or_replace_view7.q,exim_07_nonpart_noncompat_ifof.q,create_with_unique_constraints_enforced.q,udf_concat_ws_wrong2.q,fileformat_bad_class.q,merge_negative_2.q,exim_15_part_nonpart.q,authorization_not_owner_drop_view.q,external1.q,authorization_uri_insert.q,create_with_fk_wrong_ref.q,columnstats_tbllvl_incorrect_column.q,authorization_show_parts_nosel.q,authorization_not_owner_drop_tab.q,external2.q,authorization_deletejar.q,temp_table_create_like_partitions.q,udf_greatest_error_1.q,ptf_negative_AggrFuncsWithNoGBYNoPartDef.q,alter_view_as_select_not_exist.q,touch1.q,groupby3_map_skew_multi_distinct.q,insert_into_notnull_constraint.q,exchange_partition_neg_partition_missing.q,groupby_cube_multi_gby.q,columnstats_tbllvl.q,drop_invalid_constraint2.q,alter_table_add_partition.q,update_not_acid.q,archive5.q,alter_table_constraint_invalid_pk_col.q,ivyDownload.q,udf_instr_wrong_type.q,bad_sample_clause.q,authorization_not_owner_drop_tab2.q,authorization_alter_db_owner.q,show_columns1.q,orc_type_promotion3.q,create_view_failure8.q,strict_join.q,udf_add_months_error_1.q,groupby_cube2.q,groupby_cube1.q,groupby_rollup1.q,genericFileFormat.q,invalid_cast_from_binary_4.q,drop_invalid_constraint1.q,serde_regex.q,show_partitions1.q,check_constraint_nonboolean_expr.q,invalid_cast_from_binary_6.q,create_with_multi_pk_constraint.q,udf_field_wrong_type.q,groupby_grouping_sets4.q,groupby_grouping_sets3.q,insertsel_fail.q,udf_locate_wrong_type.q,orc_type_promotion1_acid.q,set_table_property.q,create_or_replace_view2.q,groupby_grouping_sets2.q,alter_view_failure.q,distinct_windowing_failure1.q,invalid_t_alter2.q,alter_table_constraint_invalid_fk_col1.q,invalid_varchar_length_2.q,authorization_show_grant_otheruser_alltabs.q,subquery_windowing_corr.q,compact_non_acid_table.q,authorization_view_4.q,authorization_disallow_transform.q,materialized_view_authorization_rebuild_other.q,authorization_fail_4.q,dbtxnmgr_nodblock.q,set_hiveconf_internal_variable1.q,input_part0_neg.q,udf_printf_wrong3.q,load_orc_negative2.q,druid_buckets.q,archive2.q,authorization_addjar.q,invalid_sum_syntax.q,insert_into_with_schema1.q,udf_add_months_error_2.q,dyn_part_max_per_node.q,authorization_revoke_table_fail1.q,udf_printf_wrong2.q,archive_multi3.q,udf_printf_wrong1.q,subquery_subquery_chain.q,authorization_view_disable_cbo_4.q,no_matching_udf.q,create_view_failure7.q,drop_native_udf.q,truncate_column_list_bucketing.q,authorization_uri_add_partition.q,authorization_view_disable_cbo_3.q,bad_exec_hooks.q,authorization_view_disable_cbo_2.q,fetchtask_ioexception.q,char_pad_convert_fail2.q,authorization_set_role_neg1.q,serde_regex3.q,authorization_delete_nodeletepriv.q,materialized_view_delete.q,create_or_replace_view6.q,bucket_mapjoin_wrong_table_metadata_2.q,udf_sort_array_by_wrong2.q,local_mapred_error_cache.q,alter_external_acid.q,mm_concatenate.q,authorization_fail_3.q,set_hiveconf_internal_variable0.q,udf_last_day_error_2.q,alter_table_constraint_invalid_ref.q,create_table_wrong_regex.q,describe_xpath4.q,join32.q,insert_sorted.q,describe_xpath2.q,authorization_role_grant_otheruser.q,masking_acid_merge.q,authorization_ctas.q,authorization_fail_5.q,alter_view_failure9.q,insert_into_acid_notnull.q,illegal_partition_type3.q,alter_table_constraint_invalid_pk_tbl.q,authorization_uri_import.q,database_drop_does_not_exist.q,date_literal3.q,archive_multi4.q,date_literal2.q,gby_star2.q,authorization_table_grant_nosuchrole.q,insert_into_with_schema2.q,join_cond_unqual_ambiguous_vc.q,archive_multi2.q,analyze1.q,invalid_distinct3.q,fs_default_name1.q,subquery_in_on.q,show_columns3.q,column_rename1.q,authorization_view_1.q,ptf_negative_JoinWithAmbigousAlias.q,groupby_rollup3.q,truncate_table_failure6.q,groupby_cube3.q,invalid_create_tbl1.q,illegal_partition_type.q,cachingprintstream.q,create_function_nonudf_class.q,exchange_partition_neg_table_missing2.q,dbtxnmgr_notablelock.q,create_view_failure1.q,create_view_failure2.q,alter_view_failure8.q,check_constraint_window_fun.q,update_notnull_constraint.q,authorization_drop_db_cascade.q,archive_partspec3.q,truncate_partition_column.q,alter_partition_partial_spec_dyndisabled.q,udf_format_number_wrong2.q,column_rename5.q,authorization_import.q,authorization_fail_2.q,script_error.q,archive_partspec5.q,script_broken_pipe2.q,update_no_such_table.q,exim_09_nonpart_noncompat_serdeparam.q,invalid_cast_from_binary_1.q,archive_partspec1.q,unionDistributeBy.q,drop_function_failure.q,authorization_priv_current_role_neg.q,archive_insert1.q,authorization_addpartition.q,archive_multi6.q,exim_05_nonpart_noncompat_coltype.q,druid_case.q,invalid_cast_to_binary_5.q,orderby_invalid_position.q,materialized_view_authorization_create_no_select_perm.q,exchange_partition_neg_with_fullacid_table.q,druid_address.q,delete_not_acid.q,temp_table_partitions.q,constraint_invalide_name.q,authorization_uri_load_data.q,udf_locate_wrong_args_len.q,duplicate_insert1.q,duplicate_insert2.q,udf_sort_array_by_wrong3.q,stats_publisher_error_2.q,show_tableproperties1.q,invalid_cast_to_binary_2.q,authorization_drop_admin_role.q,lockneg1.q,exim_16_part_noncompat_schema.q,database_switch_does_not_exist.q,ctas.q,exim_10_nonpart_noncompat_bucketing.q,unionOrderBy.q,addpart1.q,ptf_negative_NoWindowDefn.q,authorization_set_invalidconf.q,udtf_explode_not_supported3.q,ptf_negative_AmbiguousWindowDefn.q,create_external_with_check_constraint.q,udtf_invalid_place.q,join_cond_unqual_ambiguous.q,udf_format_number_wrong1.q,authorization_view_disable_cbo_6.q,exim_25_import_nonexist_authfail.q,authorization_role_cycles1.q,invalid_char_length_3.q,groupby_struct.q,join_alt_syntax_comma_on.q,exchange_partition_neg_incomplete_partition.q,udf_test_error_reduce.q,load_wrong_noof_part.q,authorization_export_ptn.q,drop_partition_failure.q,subquery_in_implicit_gby.q,udf_map_values_arg_num.q,udf_elt_wrong_args_len.q,alter_table_wrong_location.q,archive_insert4.q,authorization_grant_table_fail_nogrant.q,authorization_create_func1.q,dyn_part3.q,cte_with_in_subquery.q,drop_table_used_by_mv.q,column_change_skewedcol_type1.q,materialized_view_drop.q,selectDistinctStarNeg_2.q,exchange_partition_neg_with_mm_table.q,invalid_std_syntax.q,unset_view_property.q,authorization_view_3.q,subquery_exists_implicit_gby.q,authorization_set_role_neg2.q,authorization_grant_group.q,invalid_min_syntax.q,semijoin3.q,truncate_nonexistant_column.q,exchange_partition_neg_table_missing.q,gby_star.q,truncate_partition_column2.q,insertover_dynapart_ifnotexists.q,unionClusterBy.q,udf_qualified_name.q,udaf_invalid_place.q,spark_job_max_tasks.q,authorization_cannot_create_default_role.q,nonkey_groupby.q,spark_stage_max_tasks.q,ptf_negative_HavingLeadWithNoGBYNoWindowing.q,alter_view_as_select_with_partition.q,load_exist_part_authfail.q,archive_multi7.q,authorization_create_func2.q,authorization_grant_uri.q,line_terminator.q,load_view_failure.q,groupby_grouping_sets8.q,invalid_cast_from_binary_3.q,exim_21_part_managed_external.q,insert_into4.q,database_create_invalid_name.q,groupby_grouping_sets7.q,subq_insert.q,dyn_part2.q,alter_external_with_notnull_constraint.q,exchange_partition.q,lateral_view_join.q,allow_change_col_type_par_neg.q,create_function_nonexistent_db.q,create_function_nonexistent_class.q,authorization_not_owner_alter_tab_rename.q,strict_pruning.q,subquery_notexists_implicit_gby.q,orc_reorder_columns1.q,columnstats_partlvl_invalid_values.q,orc_reorder_columns2.q,authorization_dfs.q,udf_format_number_wrong7.q,exim_17_part_spec_underspec.q,druid_partitions.q,authorization_drop_role_no_admin.q,windowing_ll_no_over.q,subquery_corr_from.q,desc_failure2.q,load_non_native.q,windowing_ll_no_neg.q,authorization_role_grant2.q,lockneg4.q,lockneg3.q,drop_table_failure2.q,temp_table_authorize_create_tbl.q,dyn_part_max.q,orc_reorder_columns2_acid.q,change_hive_local_session_path.q,insert_into5.q,insert_into1.q,insert_into3.q,udf_in_2.q,udtf_explode_not_supported2.q,sample.q,udtf_explode_not_supported1.q,authorization_droppartition.q,orc_type_promotion2_acid.q,materialized_view_load.q,right_side_join.q,authorization_fail_1.q,authorization_cannot_create_all_role.q,invalid_max_syntax.q,udf_array_contains_wrong1.q,authorization_cannot_create_none_role.q,subquery_in_lhs.q,orc_replace_columns3.q,udf_size_wrong_args_len.q,create_skewed_table_dup_col_name.q,authorization_fail_7.q,authorization_invalid_priv_v1.q,invalidate_view1.q,union22.q,subquery_scalar_multi_columns.q,disallow_incompatible_type_change_on1.q,semijoin1.q,create_skewed_table_failure_invalid_col_name.q,udf_when_type_wrong.q,timestamp_literal.q,create_external_with_default_constraint.q,truncate_table_failure4.q,masking_acid_delete.q,check_constraint_violation.q,uniquejoin2.q,authorization_grant_table_dup.q,invalid_tbl_name.q,authorization_createview.q,alter_external_with_default_constraint.q,truncate_table_failure1.q,alter_partition_coltype_invalidtype.q,show_tablestatus_not_existing_part.q,authorization_msck.q,truncate_table_failure2.q,joinneg.q
{noformat}

I didn't really do too much digging but quick look at hive logs suggest this is related to compaction"
HIVE-19515,TestRpc.testServerPort is consistently failing,{{TestRpc.testServerPort}} is consistently failing due to HIVE-17838
HIVE-19512,"If parallel execution is enabled, metastore is throwing out of sequence error.","The move task does meta store operations. If the meta hive object is shared between Move tasks, then meta store throwing out of sequence error. So each move task should have a hive object of its own. "
HIVE-19509,Disable tests that are failing continuously,"As per discussion in mailing list. We will bring the failure count to zero and be less tolerant with ptest runs that are not clean.

- TestSequenceFileReadWrite#testSequenceTableWriteReadMR and TestSequenceFileReadWrite#testTextTableWriteReadMR have been disabled (HIVE-19506).
- TestNegativeCliDriver: merge_negative_5.q and mm_concatenate.q have been disabled (HIVE-19517).
- TestMiniLlapLocalCliDriver: bucket_map_join_tez1.q (diff), sysdb.q (diff), special_character_in_tabnames_1.q (failure), tez_smb_1.q (diff), union_fast_stats.q (diff), schema_evol_orc_acidvec_part.q, schema_evol_orc_vec_part_llap_io.q, tez_dynpart_hashjoin_1.q (diff), and tez_vector_dynpart_hashjoin_1.q (diff) have been disabled.
- TestCliDriver: fouter_join_ppr.q has been disabled.
- TestStats#partitionedTableDeprecatedCalls, TestStats#partitionedTableInHiveCatalog, and TestStats#partitionedTableOtherCatalog have been disabled.
- TestOldSchema#testPartitionOps has been disabled.
- TestSSL#testSSLFetchHttp has been disabled.
- TestAcidOnTez#testCtasTezUnion and TestAcidOnTez#testNonStandardConversion01 have been disabled.
- TestBeeLineWithArgs#testQueryProgress and TestBeeLineWithArgs#testQueryProgressParallel have been disabled.
- TestMiniDruidKafkaCliDriver : druidkafkamini_basic.q has been disabled.
- TestTxnExIm#testUpgrade has been disabled.

- TestDanglingQOuts.checkDanglingQOut has been disabled till we fix all the previous test errors, since I did not want to delete the dangling q.out files (they may serve as a reference)."
HIVE-19504,Change default value for hive.auto.convert.join.shuffle.max.size property,"The property default value is too low by mistake (10MB), it is missing three trailing zeros.

{code}
    HIVECONVERTJOINMAXSHUFFLESIZE(""hive.auto.convert.join.shuffle.max.size"", 10000000L,
       ""If hive.auto.convert.join.noconditionaltask is off, this parameter does not take affect. \n"" +
       ""However, if it is on, and the predicted size of the larger input for a given join is greater \n"" +
       ""than this number, the join will not be converted to a dynamically partitioned hash join. \n"" +
       ""The value \""-1\"" means no limit.""),
{code}"
HIVE-19500,Prevent multiple selectivity estimations for the same variable in conjuctions,"see HIVE-19097 for problem description

for filters like: {{(d_year in (2001,2002) and d_year = 2001)}} the current estimation is around {{(1/NDV)**2}} (iff column stats are available) ....

actually the source of the problem was a small typo in HIVE-17465 "
HIVE-19499,Bootstrap REPL LOAD shall add tasks to create checkpoints for db/tables/partitions.,"Currently. bootstrap REPL LOAD expect the target database to be empty or not exist to start bootstrap load.

But, this adds overhead when there is a failure in between bootstrap load and there is no way to resume it from where it fails. So, it is needed to create checkpoints in table/partitions to skip the completely loaded objects.

Use the fully qualified path of the dump directory as a checkpoint identifier. This should be added to the table / partition properties in hive via a task, as the last task in the DAG for table / partition creation."
HIVE-19498,Vectorization: CAST expressions produce wrong results,"Wrong results for:

DATE --> BOOLEAN
 DOUBLE --> DECIMAL
 STRING|CHAR|VARCHAR --> DECIMAL
 TIMESTAMP --> LONG"
HIVE-19496,Check untar folder,We need to check if the file is under untar folder.
HIVE-19495,Arrow SerDe itest failure,"""You tried to write a Bit type when you are using a ValueWriter of type NullableMapWriter."""
HIVE-19494,Accept shade prefix during reflective instantiation of output format,"Hive Streaming API jars are sometimes shaded with a different prefix when used in environments where another version of hive already exists (spark for example). In most cases, shading is done with rename of classes with some prefix. If an uber/assembly jar is generated with renamed prefix, Hive Streaming API will not work as Hive Streaming API will reflectively instantiate outputformat class using FQCN string provided by metastore table storage descriptor object. 
For example: 
RecordWriter will create instance of OutputFormat using string ""org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat"". When a shaded jar with renamed class references are used, this class will not be found by the classloader. 

We can optionally accept a shade prefix from user via config which will be tried (as fallback) when ClassNotFoundException is thrown."
HIVE-19493,VectorUDFDateDiffColCol copySelected does not handle nulls correctly,The {{copySelected}} method in {{VectorUDFDateDiffColCol}} class was missed during HIVE-18622
HIVE-19490,Locking on Insert into for non native and managed tables.,"Current state of the art: 

Managed non native table like Druid Tables, will need to get a Lock on Insert into or insert Over write. The nature of this lock is set to Exclusive by default for any non native table.

This implies that Inserts into Druid table will Lock any read query as well during the execution of the insert into. IMO this lock (on insert into) is  not needed since the insert statement is appending data and the state of loading it is managed partially by Hive Storage handler hook and part of it by Druid. 

What i am proposing is to relax the lock level to shared for all non native tables on insert into operations and keep it as Exclusive Write for insert Overwrite for now.

 

Any feedback is welcome.

cc [~ekoifman] / [~ashutoshc] / [~jdere] / [~hagleitn]

Also am not sure what is the best way to unit test this currently am using debugger to check if locks are what i except, please let me know if there is a better way to do this. 

 "
HIVE-19488,"Enable CM root based on db parameter, identifying a db as source of replication.","* add a parameter at db level to identify if its a source of replication. user should set this.

 * Enable CM root only for databases that are a source of a replication policy, for other db's skip the CM root functionality.

 * prevent database drop if the parameter indicating its source of a replication, is set.

 * as an upgrade to this version, user should set the property on all existing database policies, in affect.

 * the parameter should be of the form . –  repl.source.for : List < policy ids >"
HIVE-19485,dump directory for non native tables should not be created,
HIVE-19481,Tablesample uses incorrect logic to pick files corresponding to buckets.,"Ran ""mvn test -Dtest=TestMiniLlapLocalCliDriver -Dqfile=sample10.q "" after changing the table to be 
insert-only transactional. 

The following queries returns couple of rows whereis no row results returns for non-ACID table. 
query: select ds, count(1) from srcpartbucket tablesample (bucket 2 out of 4 on key) where ds is not null group by ds ORDER BY ds ASC

2008-04-08      14
2008-04-09      14
..
query: select ds, count(1) from srcpartbucket tablesample (bucket 1 out of 2 on key) where ds is not null group by ds ORDER BY ds ASC

2008-04-08      4
2008-04-09      4

"
HIVE-19479,encoded stream seek is incorrect for 0-length RGs in LLAP IO,"The PositionProvider offset is not updated correctly and an error like this may happen:
{noformat}
Caused by: java.lang.IllegalArgumentException: Seek in LENGTH to 541 is outside of the data
	at org.apache.orc.impl.InStream$UncompressedStream.seek(InStream.java:161)
	at org.apache.orc.impl.InStream$UncompressedStream.seek(InStream.java:123)
	at org.apache.orc.impl.RunLengthIntegerReaderV2.seek(RunLengthIntegerReaderV2.java:331)
	at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedTreeReaderFactory$StringStreamReader.seek(EncodedTreeReaderFactory.java:298)
	at org.apache.hadoop.hive.ql.io.orc.encoded.EncodedTreeReaderFactory$StringStreamReader.seek(EncodedTreeReaderFactory.java:258)
	at org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.repositionInStreams(OrcEncodedDataConsumer.java:250)
	at org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.decodeBatch(OrcEncodedDataConsumer.java:134)
	at org.apache.hadoop.hive.llap.io.decode.OrcEncodedDataConsumer.decodeBatch(OrcEncodedDataConsumer.java:62)
{noformat}

We found this happens when ORC writes a strange stream combination - data stream for a RG has no values (the rows all have nulls), but there are values (0-s) in length stream for the same rows. That is technically a valid ORC file, although writing the 0s is completely useless. 
This may be fixed separately in ORC, but since these files now exist in the wild we should handle them correctly."
HIVE-19474,Decimal type should be casted as part of the CTAS or INSERT Clause.,"HIVE-18569  introduced a runtime config variable to allow the indexing of Decimal as Double, this leads to kind of messy state, Hive metadata think the column is still decimal while it is stored as double. Since the Hive metadata of the column is Decimal the logical optimizer will not push down aggregates. i tried to fix this by adding some logic to the application but it makes the code very clumsy with lot of branches. Instead i propose to revert  HIVE-18569  and let the user introduce an explicit cast this will be better since the metada reflects actual storage type and push down aggregates will kick in and there is no config needed without adding any code or bug.

cc [~ashutoshc] and [~nishantbangarwa]

You can see the difference with the following DDL
{code:java}
create table test_base_table(`timecolumn` timestamp, `interval_marker` string, `num_l` DECIMAL(10,2));
insert into test_base_table values ('2015-03-08 00:00:00', 'i1-start', 4.5);
set hive.druid.approx.result=true;
CREATE TABLE druid_test_table
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (""druid.segment.granularity"" = ""DAY"")
AS
select cast(`timecolumn` as timestamp with local time zone) as `__time`, `interval_marker`, cast(`num_l` as double)
FROM test_base_table;
describe druid_test_table;
explain select sum(num_l), min(num_l) FROM druid_test_table;
CREATE TABLE druid_test_table_2
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (""druid.segment.granularity"" = ""DAY"")
AS
select cast(`timecolumn` as timestamp with local time zone) as `__time`, `interval_marker`, `num_l`
FROM test_base_table;
describe druid_test_table_2;
explain select sum(num_l), min(num_l) FROM druid_test_table_2;

{code}
 

 "
HIVE-19472,HiveStreamingConnection swallows exception on partition creation,HiveStreamingConnection swallows exception on partition creation
HIVE-19467,Make storage format configurable for temp tables created using LLAP external client,"Temp tables created for complex queries when using the LLAP external client are created using the default storage format. Default to orc, and make configurable."
HIVE-19466,Update constraint violation error message,Currently for both CHECK and NOT NULL constraint violation hive throws {{NOT NULL Constraint violated}}.
HIVE-19465,Upgrade ORC to 1.5.0,
HIVE-19464,Upgrade Parquet to 1.10.0,
HIVE-19463,TezTask - getting groups may fail (PartialGroupNameException in some tests),"{noformat}
org.apache.hadoop.security.ShellBasedUnixGroupsMapping$PartialGroupNameException: The user name 'hive_test_user' is not found. id: hive_test_user: no such user
id: hive_test_user: no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:294) ~[hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:207) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:384) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:319) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:269) [hadoop-common-3.1.0.jar:?]
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3542) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2323) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2286) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache.get(LocalCache.java:3953) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3957) [guava-19.0.jar:?]
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4875) [guava-19.0.jar:?]
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:227) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1540) [hadoop-common-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.exec.tez.TezTask.execute(TezTask.java:163) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
{noformat}"
HIVE-19462,Fix mapping for char_length function to enable pushdown to Druid. ,"currently char_length is not push down to Druid because of missing mapping form/to calcite

This patch will add this mapping.

 

 "
HIVE-19460,Improve stats estimations for NOT IN operator,
HIVE-19454,Test failure : org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1 fails with java.lang.AssertionError,"org.apache.hadoop.hive.ql.TestTxnCommands2WithSplitUpdateAndVectorization.testNonAcidToAcidConversion1 refers to the same test case.

Maven command used is : mvn -Dtest=TestTxnCommands2 test

Error:
{code:java}
[INFO] Running org.apache.hadoop.hive.ql.TestTxnCommands2
[ERROR] Tests run: 44, Failures: 1, Errors: 0, Skipped: 3, Time elapsed: 618.215 s <<< FAILURE! - in org.apache.hadoop.hive.ql.TestTxnCommands2
[ERROR] testNonAcidToAcidConversion1(org.apache.hadoop.hive.ql.TestTxnCommands2)  Time elapsed: 17.557 s  <<< FAILURE!
java.lang.AssertionError
        at org.junit.Assert.fail(Assert.java:86)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.junit.Assert.assertTrue(Assert.java:52)
        at org.apache.hadoop.hive.ql.TestTxnCommands2.testNonAcidToAcidConversion1(TestTxnCommands2.java:499)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
        at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)
        at org.junit.rules.RunRules.evaluate(RunRules.java:20)
        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:379)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:340)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:125)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:413)

[INFO]
[INFO] Results:
[INFO]
[ERROR] Failures:
[ERROR]   TestTxnCommands2.testNonAcidToAcidConversion1:499
[INFO]
[ERROR] Tests run: 44, Failures: 1, Errors: 0, Skipped: 3

{code}"
HIVE-19440,Make StorageBasedAuthorizer work with information schema,"With HIVE-19161, Hive information schema works with external authorizer (such as ranger). However, we also need to make StorageBasedAuthorizer synchronization work as it is also widely use."
HIVE-19435,Incremental replication cause data loss if a table is dropped followed by create and insert-into with different partition type.,"If the incremental dump have drop of partitioned table followed by create/insert on non-partitioned table with same name, doesn't replicate the data. Explained below.

Let's say we have a partitioned table T1 which was already replicated to target.

DROP_TABLE(T1)->CREATE_TABLE(T1) (Non-partitioned) -> INSERT(T1)(10) 

After REPL LOAD, T1 doesn't have any data.

Same is valid for non-partitioned to partitioned and partition spec mismatch case as well.

 "
HIVE-19433,HiveJoinPushTransitivePredicatesRule hangs,"*Reproducer*
{code:sql}
    CREATE TABLE `table1`(
       `idp_warehouse_id` bigint,
       `idp_audit_id` bigint,
       `idp_effective_date` date,
       `idp_end_date` date,
       `idp_delete_date` date,
       `pruid` varchar(32),
       `prid` bigint,
       `prtimesheetid` bigint,
       `prassignmentid` bigint,
       `prchargecodeid` bigint,
       `prtypecodeid` bigint,
       `prsequence` bigint,
       `prmodby` varchar(96),
       `prmodtime` timestamp,
       `prrmexported` bigint,
       `prrmckdel` bigint,
       `slice_status` int,
       `role_id` bigint,
       `user_lov1` varchar(30),
       `user_lov2` varchar(30),
       `incident_id` bigint,
       `incident_investment_id` bigint,
       `odf_ss_actuals` bigint,
       `practsum` decimal(38,20));

    CREATE TABLE `table2`(
       `idp_warehouse_id` bigint,
       `idp_audit_id` bigint,
       `idp_effective_date` date,
       `idp_end_date` date,
       `idp_delete_date` date,
       `pruid` varchar(32),
       `prid` bigint,
       `prtimesheetid` bigint,
       `prassignmentid` bigint,
       `prchargecodeid` bigint,
       `prtypecodeid` bigint,
       `prsequence` bigint,
       `prmodby` varchar(96),
       `prmodtime` timestamp,
       `prrmexported` bigint,
       `prrmckdel` bigint,
       `slice_status` int,
       `role_id` bigint,
       `user_lov1` varchar(30),
       `user_lov2` varchar(30),
       `incident_id` bigint,
       `incident_investment_id` bigint,
       `odf_ss_actuals` bigint,
       `practsum` decimal(38,20));

    explain SELECT          s.idp_warehouse_id AS source_warehouse_id
    FROM            table1 s
    JOIN

                           table2 d
    ON              (
                                    s.prid = d.prid )
    JOIN
                             table2 e
    ON
                                    s.prid = e.prid
    WHERE
    concat(
                    CASE
                                    WHEN s.prid IS NULL THEN 1
                                    ELSE s.prid
                    END,',',
                    CASE
                                    WHEN s.prtimesheetid IS NULL THEN 1
                                    ELSE s.prtimesheetid
                    END,',',
                    CASE
                                    WHEN s.prassignmentid IS NULL THEN 1
                                    ELSE s.prassignmentid
                    END,',',
                    CASE
                                    WHEN s.prchargecodeid IS NULL THEN 1
                                    ELSE s.prchargecodeid
                    END,',',
                    CASE
                                    WHEN (s.prtypecodeid) IS NULL THEN ''
                                    ELSE s.prtypecodeid
                    END,',',
                    CASE
                                    WHEN s.practsum IS NULL THEN 1
                                    ELSE s.practsum
                    END,',',
                    CASE
                                    WHEN s.prsequence IS NULL THEN 1
                                    ELSE s.prsequence
                    END,',',
                    CASE
                                    WHEN length(s.prmodby) IS NULL THEN ''
                                    ELSE s.prmodby
                    END,',',
                    CASE
                                    WHEN s.prmodtime IS NULL THEN cast(from_unixtime(unix_timestamp('2017-12-08','yyyy-MM-dd') ) AS timestamp)
                                    ELSE s.prmodtime
                    END,',',
                    CASE
                                    WHEN s.prrmexported IS NULL THEN 1
                                    ELSE s.prrmexported
                    END,',',
                    CASE
                                    WHEN s.prrmckdel IS NULL THEN 1
                                    ELSE s.prrmckdel
                    END,',',
                    CASE
                                    WHEN s.slice_status IS NULL THEN 1
                                    ELSE s.slice_status
                    END,',',
                    CASE
                                    WHEN s.role_id IS NULL THEN 1
                                    ELSE s.role_id
                    END,',',
                    CASE
                                    WHEN length(s.user_lov1) IS NULL THEN ''
                                    ELSE s.user_lov1
                    END,',',
                    CASE
                                    WHEN length(s.user_lov2) IS NULL THEN ''
                                    ELSE s.user_lov2
                    END,',',
                    CASE
                                    WHEN s.incident_id IS NULL THEN 1
                                    ELSE s.incident_id
                    END,',',
                    CASE
                                    WHEN s.incident_investment_id IS NULL THEN 1
                                    ELSE s.incident_investment_id
                    END,',',
                    CASE
                                    WHEN s.odf_ss_actuals IS NULL THEN 1
                                    ELSE s.odf_ss_actuals
                    END ) != concat(
                    CASE
                                    WHEN length(d.pruid) IS NULL THEN ''
                                    ELSE d.pruid
                    END,',',
                    CASE
                                    WHEN d.prid IS NULL THEN 1
                                    ELSE d.prid
                    END,',',
                    CASE
                                    WHEN d.prtimesheetid IS NULL THEN 1
                                    ELSE d.prtimesheetid
                    END,',',
                    CASE
                                    WHEN d.prassignmentid IS NULL THEN 1
                                    ELSE d.prassignmentid
                    END,',',
                    CASE
                                    WHEN d.prchargecodeid IS NULL THEN 1
                                    ELSE d.prchargecodeid
                    END,',',
                    CASE
                                    WHEN (d.prtypecodeid) IS NULL THEN ''
                                    ELSE d.prtypecodeid
                    END,',',
                    CASE
                                    WHEN d.practsum IS NULL THEN 1
                                    ELSE d.practsum
                    END,',',
                    CASE
                                    WHEN d.prsequence IS NULL THEN 1
                                    ELSE d.prsequence
                    END,',',
                    CASE
                                    WHEN length(d.prmodby) IS NULL THEN ''
                                    ELSE d.prmodby
                    END,',',
                    CASE
                                    WHEN d.prmodtime IS NULL THEN cast(from_unixtime(unix_timestamp('2017-12-08','yyyy-MM-dd') ) AS timestamp)
                                    ELSE d.prmodtime
                    END,',',
                    CASE
                                    WHEN d.prrmexported IS NULL THEN 1
                                    ELSE d.prrmexported
                    END,',',
                    CASE
                                    WHEN d.prrmckdel IS NULL THEN 1
                                    ELSE d.prrmckdel
                    END,',',
                    CASE
                                    WHEN d.slice_status IS NULL THEN 1
                                    ELSE d.slice_status
                    END,',',
                    CASE
                                    WHEN d.role_id IS NULL THEN 1
                                    ELSE d.role_id
                    END,',',
                    CASE
                                    WHEN length(d.user_lov1) IS NULL THEN ''
                                    ELSE d.user_lov1
                    END,',',
                    CASE
                                    WHEN length(d.user_lov2) IS NULL THEN ''
                                    ELSE d.user_lov2
                    END,',',
                    CASE
                                    WHEN d.incident_id IS NULL THEN 1
                                    ELSE d.incident_id
                    END,',',
                    CASE
                                    WHEN d.incident_investment_id IS NULL THEN 1
                                    ELSE d.incident_investment_id
                    END,',',
                    CASE
                                    WHEN d.odf_ss_actuals IS NULL THEN 1
                                    ELSE d.odf_ss_actuals
                    END );
{code}"
HIVE-19423,REPL LOAD creates staging directory in source dump directory instead of table data location,REPL LOAD creates staging directory in source dump directory instead of table data location. In case of replication from on-perm to cloud it can create problem. 
HIVE-19421,Upgrade version of Jetty to 9.3.20.v20170531,Move Jetty up to 9.3.20.v20170531
HIVE-19418,add background stats updater similar to compactor,"There's a JIRA HIVE-19416 to add snapshot version to stats for MM/ACID tables to make them usable in a transaction without breaking ACID (for metadata-only optimization). However, stats for ACID tables can still become unusable if e.g. two parallel inserts run - neither sees the data written by the other, so after both finish, the snapshots on either set of stats won't match the current snapshot and the stats will be unusable.

Additionally, for ACID and non-ACID tables alike, a lot of the stats, with some exceptions like numRows, cannot be aggregated (i.e. you cannot combine ndvs from two inserts), and for ACID even less can be aggregated (you cannot derive min/max if some rows are deleted but you don't scan the rest of the dataset).

Therefore we will add background logic to metastore (similar to, and partially inside, the ACID compactor) to update stats.
It will have 3 modes of operation.
1) Off.
2) Update only the stats that exist but are out of date (generating stats can be expensive, so if the user is only analyzing a subset of tables it should be able to only update that subset). We can simply look at existing stats and only analyze for the relevant partitions and columns.
3) On: 2 + create stats for all tables and columns missing stats.
There will also be a table parameter to skip stats update. 

In phase 1, the process will operate outside of compactor, and run analyze command on the table. The analyze command will automatically save the stats with ACID snapshot information if needed, based on HIVE-19416, so we don't need to do any special state management and this will work for all table types. However it's also more expensive.

In phase 2, we can explore adding stats collection during MM compaction that uses a temp table. If we don't have open writers during major compaction (so we overwrite all of the data), the temp table stats can simply be copied over to the main table with correct snapshot information, saving us a table scan.

In phase 3, we can add custom stats collection logic to full ACID compactor that is not query based, the same way as we'd do for (2). Alternatively we can wait for ACID compactor to become query based and just reuse (2).





"
HIVE-19415,Support CORS for all HS2 web endpoints,"HIVE-19277 changes alone are not sufficient to support CORS. CrossOriginFilter has to be added to jetty which will serve appropriate response for OPTIONS pre-flight request. 

"
HIVE-19410,don't create serde reader in LLAP if there's no cache,Seems to crop up in some tests.
HIVE-19409,Disable incremental rewriting with outdated materialized views,"Add an option to disable incremental rewriting with outdated materialized views. It will be disabled by default, and this will be an opt-in feature."
HIVE-19390,Useless error messages logged for dummy table stats,Queries like INSERT INTO t1 VALUES (20); gets rewritten into insert into t1 select 20 from default_db.default_tblname which later throws as compiler tries to get stats
HIVE-19389,"Schematool: For Hive's Information Schema, use embedded HS2 as default","Currently, for initializing/upgrading Hive's information schema, we require a full jdbc url (for HS2). It will be good to have it connect using embedded HS2 by default."
HIVE-19385,Optional hive env variable to redirect bin/hive to use Beeline,"With beeline-site and beeline-user-site, the user can easily specify default hs2 urls to connect. We can use an optional env variable, which when set, will enable bin/hive to use beeline."
HIVE-19384,Vectorization: IfExprTimestamp* do not handle NULLs correctly,"HIVE-18622: ""Vectorization: IF Statements, Comparisons, and more do not handle NULLs correctly"" didn't quite fix the IfExprTimestamp* classes right....
{noformat}
// Carefully handle NULLs...

outputColVector.noNulls = false;{noformat}"
HIVE-19382,Acquire locks before generating valid transaction list for some operations,"To ensure correctness, in particular for operations that require exclusive ({{INSERT OVERWRITE}}) and semishared ({{UPDATE}}/{{DELETE}}) locks.

This is a temporary fix till lock acquisition is moved before analyze in HIVE-18948.

With this fix, system proceed as follows. The driver will acquire the snapshot, compile the query wrt that snapshot, and then, it will acquire locks. If snapshot is still valid, it will continue as usual. But if snapshot is not valid anymore, it will recompile the query.

This is easier to implement than full solution described in HIVE-18948 because we do not need to move the logic to extract the read/write entities from a query before compilation (actually while parsing)."
HIVE-19381,Function replication in cloud fail when download resource from AWS,Another case replication shall use the config in with clause.
HIVE-19374,Parse and process ALTER TABLE SET OWNER command syntax,Subtask that parses the new alter table set owner syntax and implements code to call HMS to change the owner of a table to a user or a role.
HIVE-19370,Issue: ADD Months function on timestamp datatype fields in hive,"*Issue:*

while using ADD_Months function on a timestamp datatype column the output omits the time part[HH:MM:SS] part from output.

which should not be the case.

*query:* EMAIL_FAILURE_DTMZ is of datatype timestamp in hive.

hive> select CUSTOMER_ID,EMAIL_FAILURE_DTMZ,ADD_MONTHS (EMAIL_FAILURE_DTMZ , 1) from TABLE1 where CUSTOMER_ID=125674937;
OK
125674937   2015-12-09 12:25:53     2016-01-09

*hiver version :*

hive> !hive --version;
 Hive 1.2.1000.2.5.6.0-40

 

can you please help if somehow I can get below as output:

 

125674937   2015-12-09 12:25:53           2016-01-09 12:25:53"
HIVE-19366,Vectorization causing TestStreaming.testStreamBucketingMatchesRegularBucketing to fail,Disabled vectorization for TestStreaming#testStreamBucketingMatchesRegularBucketing test case in HIVE-19211 as it is giving incorrect results (the issue is mostly related to wrong table directory location which returns 0 splits). 
HIVE-19365,Index on COMPLETED_TXN_COMPONENTS in Metastore RDBMS has different names in different scripts,"In mysql and mssql install scripts the index is called COMPLETED_TXN_COMPONENTS_IDX2  Everywhere else it is called COMPLETED_TXN_COMPONENTS_IDX, which is breaking upgrade scripts for 3.0 to 3.1 since they don't know which index to update.  One name should be chosen and used everywhere."
HIVE-19358,CBO decorrelation logic should generate Hive operators,"Decorrelation logic may generate logical instances of the operators in the plan (e.g., LogicalFilter instead of HiveFilter). This leads to errors while costing the tree in the Volcano planner (used in MV rewriting), since logical operators do not have a cost associated to them."
HIVE-19357,Vectorization: assert_true HiveException erroneously gets suppressed to NULL,"This could be limited to assert exceptions; but might interfere with other exceptions...discovered while ""fixing"" testreopt after HIVE-19269

{code}
create table tu(id_uv int,id_uw int,u int);
create table tv(id_uv int,v int);
create table tw(id_uw int,w int);

insert into tu values (10,10,10),(1,1,1),(2,2,2),(3,3,3),(4,4,4),(5,5,5),(6,6,6);
insert into tv values (10,10),(1,1),(2,2),(3,3);
insert into tw values (10,10),(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9);

set zzz=0;
set hive.vectorized.execution.enabled=false;
select assert_true(${hiveconf:zzz}>sum(1)) from tu join tv on (tu.id_uv=tv.id_uv) where u<10 and v>1;
-- fails as expected

set hive.vectorized.execution.enabled=true;
select assert_true(${hiveconf:zzz}>sum(1)) from tu join tv on (tu.id_uv=tv.id_uv) where u<10 and v>1;
-- there is a result set
{code}"
HIVE-19352,Vectorization: Disable vectorization for org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData,Turning vectorization on triggers a bug - see followup Jira HIVE-19353.
HIVE-19350,Vectorization: Turn off vectorization for explainuser_1.q / spark_explainuser_1,"Seem like the operator number instability issue to me that Pengcheng Xiong worked on that could occur with vectorization.

For now, turning off vectorization for:

TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1]

TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1] 

Follow up Jira is HIVE-19351."
HIVE-19348, org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp are failing," * org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp.testDifferentFiltersAreNotMatched	2.7 sec	7
 * org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp.testUnrelatedFiltersAreNotMatched0	1.4 sec	7
 * org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp.testUnrelatedFiltersAreNotMatched1	1.8 sec	7
*  org.apache.hadoop.hive.ql.plan.mapping.TestOperatorCmp.testSameFiltersMatched	1.8 sec	7
*  org.apache.hadoop.hive.ql.plan.mapping.TestReOptimization.testNotReExecutedIfAssertionError

{noformat}
Error Message
expected:<1> but was:<2>
{noformat}
"
HIVE-19347,TestTriggersWorkloadManager tests are failing consistently,"Caused by the patch which turned on vectorization. Following tests are  failing due to the patch:

* org.apache.hive.jdbc.TestJdbcDriver2.testResultSetMetaData
* org.apache.hadoop.hive.cli.TestMiniSparkOnYarnCliDriver.testCliDriver[spark_explainuser_1]
* org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver[explainuser_1]
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerHighBytesWrite	10 sec	14
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerCustomReadOps	7.7 sec	14
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerCustomCreatedFiles	15 sec	14
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testMultipleTriggers2	17 sec	14
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerSlowQueryExecutionTime	1.5 sec	14
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerSlowQueryElapsedTime
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerVertexRawInputSplitsNoKill	20 sec	18
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerHighShuffleBytes	1.4 sec	18
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerCustomNonExistent	2.6 sec	18
* org.apache.hive.jdbc.TestTriggersWorkloadManager.testTriggerHighBytesRead

{noformat}
Error Message
Expected query to succeed expected null, but was:<java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex failed, vertexName=Map 3, vertexId=vertex_1524884047358_0001_21_01, diagnostics=[Task failed, taskId=task_1524884047358_0001_21_01_000000, diagnostics=[TaskAttempt 0 failed, info=[Error: Error while running task ( failure ) : attempt_1524884047358_0001_21_01_000000_0:java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: java.io.IOException: java.lang.NullPointerException
 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:296)
 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.run(TezProcessor.java:250)
 at org.apache.tez.runtime.LogicalIOProcessorRuntimeTask.run(LogicalIOProcessorRuntimeTask.java:374)
 at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:73)
 at org.apache.tez.runtime.task.TaskRunner2Callable$1.run(TaskRunner2Callable.java:61)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)
 at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:61)
 at org.apache.tez.runtime.task.TaskRunner2Callable.callInternal(TaskRunner2Callable.java:37)
 at org.apache.tez.common.CallableWithNdc.call(CallableWithNdc.java:36)
 at org.apache.hadoop.hive.llap.daemon.impl.StatsRecordingThreadPool$WrappedCallable.call(StatsRecordingThreadPool.java:110)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
 at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.io.IOException: java.io.IOException: java.lang.NullPointerException
 at org.apache.hadoop.hive.ql.exec.tez.MapRecordSource.pushRecord(MapRecordSource.java:80)
 at org.apache.hadoop.hive.ql.exec.tez.MapRecordProcessor.run(MapRecordProcessor.java:419)
 at org.apache.hadoop.hive.ql.exec.tez.TezProcessor.initializeAndRunProcessor(TezProcessor.java:267)
 ... 15 more
{noformat}"
HIVE-19344,Change default value of msck.repair.batch.size ,{{msck.repair.batch.size}} default to 0 which means msck will try to add all the partitions in one API call to HMS. This can potentially add huge memory pressure on HMS. The default value should be changed to a reasonable number so that in case of large number of partitions we can batch the addition of partitions. Same goes for {{msck.repair.batch.max.retries}}
HIVE-19340,Disable timeout of transactions opened by replication task at target cluster,"The transactions opened by applying EVENT_OPEN_TXN should never be aborted automatically due to time-out. Aborting of transaction started by replication task may leads to inconsistent state at target which needs additional overhead to clean-up. So, it is proposed to mark the transactions opened by replication task as special ones and shouldn't be aborted if heart beat is lost. This helps to ensure all ABORT and COMMIT events will always find the corresponding txn at target to operate."
HIVE-19336,Disable SMB/Bucketmap join for external tables,
HIVE-19334,Use actual file size rather than stats for fetch task optimization with external tables,
HIVE-19332,Disable compute.query.using.stats for external table,Hive can use statistics to answer queries like count(*). This can be problematic on external tables where another tool might add files that Hive doesn’t know about. In that case Hive will return incorrect results.
HIVE-19331,"Repl load config in ""with"" clause not pass to Context.getStagingDir","Another failure similar to HIVE-18626, causing exception when s3 credentials are in ""REPL LOAD"" with clause.

{code}
Caused by: java.lang.IllegalStateException: Error getting FileSystem for s3a://nat-yc-r7-nmys-beacon-cloud-s3-2/hive_incremental_testing.db/hive_incremental_testing_new_tabl...: org.apache.hadoop.fs.s3a.AWSClientIOException: doesBucketExist on nat-yc-r7-nmys-beacon-cloud-s3-2: com.amazonaws.AmazonClientException: No AWS Credentials provided by BasicAWSCredentialsProvider EnvironmentVariableCredentialsProvider SharedInstanceProfileCredentialsProvider : com.amazonaws.AmazonClientException: Unable to load credentials from Amazon EC2 metadata service: No AWS Credentials provided by BasicAWSCredentialsProvider EnvironmentVariableCredentialsProvider SharedInstanceProfileCredentialsProvider : com.amazonaws.AmazonClientException: Unable to load credentials from Amazon EC2 metadata service
        at org.apache.hadoop.hive.ql.Context.getStagingDir(Context.java:359)
        at org.apache.hadoop.hive.ql.Context.getExternalScratchDir(Context.java:487)
        at org.apache.hadoop.hive.ql.Context.getExternalTmpPath(Context.java:565)
        at org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.loadTable(ImportSemanticAnalyzer.java:370)
        at org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.createReplImportTasks(ImportSemanticAnalyzer.java:926)
        at org.apache.hadoop.hive.ql.parse.ImportSemanticAnalyzer.prepareImport(ImportSemanticAnalyzer.java:329)
        at org.apache.hadoop.hive.ql.parse.repl.load.message.TableHandler.handle(TableHandler.java:43)
        ... 24 more
{code}"
HIVE-19327,qroupby_rollup_empty.q fails for insert-only transactional tables,
HIVE-19323,Create metastore SQL install and upgrade scripts for 3.1,Now that we've branched for 3.0 we need to create SQL install and upgrade scripts for 3.1
HIVE-19317,Handle schema evolution from int like types to decimal,"If int like type is changed to decimal on parquet data, select results in errors."
HIVE-19312,MM tables don't work with BucketizedHIF,
HIVE-19308,Provide an Arrow stream reader for external LLAP clients ,This is a sub-class of LlapBaseRecordReader that wraps the socket inputStream and produces Arrow batches for an external client.
HIVE-19307,Support ArrowOutputStream in LlapOutputFormatService,Support pushing arrow batches through org.apache.arrow.vector.ipc.ArrowOutputStream in LllapOutputFormatService.
HIVE-19306,Arrow batch serializer,Leverage the ThriftJDBCBinarySerDe code path that already exists in SemanticAnalyzer/FileSinkOperator to create a serializer that batches rows into Arrow vector batches.
HIVE-19277,Active/Passive HA web endpoints does not allow cross origin requests,CORS is not allowed with web endpoints added for active/passive HA. Enable CORS by default for all web endpoints. 
HIVE-19275,Vectorization: Defer Wrong Results / Execution Failures when Vectorization turned on,"*Quite a number of the bucket* tests had Wrong Results or Execution Failures.

And others like semijoin, skewjoin, avro_decimal_native, mapjoin_addjar, mapjoin_decimal, nullgroup, decimal_join, mapjoin1.

Some of the problems might be as simple as ""-- SORT_QUERY_RESULTS"" is missing.

The bucket* problems looked more serious.

*This change sets ""hive.vectorized.execution.enabled"" to false at the top of those Q files.*

*Subtasks need to be created to investigate the issues.*"
HIVE-19274,Add an OpTreeSignature persistence checker hook,Adding a Hook to run during testing which checks that OpTreeSignatures are working as expected would be really usefull; it should run at least during the PerfCliDriver 
HIVE-19271,TestMiniLlapLocalCliDriver default_constraint and check_constraint failing,
HIVE-19269,Vectorization: Turn On by Default,Reflect that our most expected Hive deployment will be using vectorization and change the default of hive.vectorized.execution.enabled to true.
HIVE-19264,Vectorization: Reenable vectorization in vector_adaptor_usage_mode.q,[~vihangk1] observed vectorization had accidentally been turned off.
HIVE-19259,"Create view on tables having union all fail with ""Table not found""","create view on table with union work well while ""union all"" failed with table not found, here are the reproduce steps.

{code}
_hive> create table foo(id int);_
_OK_
_Time taken: 0.401 seconds_
_hive> create table bar(id int);_
_OK_
 
_// view on table union_
_hive> create view unionview as with tmp_1 as ( select * from foo ), tmp_2 as (select * from bar ) select * from tmp_1 union  select * from tmp_2;_ 
_OK_
_Time taken: 0.517 seconds_
_hive> select * from unionview;_
_OK_
_Time taken: 5.805 seconds_
 
 
_// view on union all_ 
_hive> create view unionallview as with tmp_1 as ( select * from foo ), tmp_2 as (select * from bar ) select * from tmp_1 union all  select * from tmp_2;_ 
_OK_
_Time taken: 1.535 seconds_
_hive> select * from unionallview;_
_FAILED: SemanticException Line 1:134 Table not found 'tmp_1' in definition of VIEW unionallview [_
_with tmp_1 as ( select `foo`.`id` from `default`.`foo` ), tmp_2 as (select `bar`.`id` from `default`.`bar` ) select `tmp_1`.`id` from tmp_1 union all  select `tmp_2`.`id` from tmp_2_
_] used as unionallview at Line 1:14_
_{code}_"
HIVE-19258,add originals support to MM tables (and make the conversion a metadata only operation),
HIVE-19257,HIVE-19157 commit references wrong jira,1eea5a80ded2df33d57b2296b3bed98cb18383fd on master references wrong jira.
HIVE-19252,TestJdbcWithMiniKdcCookie.testCookieNegative is failing consistently,For last 8 builds.
HIVE-19248,REPL LOAD couldn't copy file from source CM path and also doesn't throw error if file copy fails.,"Hive replication uses Hadoop distcp to copy files from primary to replica warehouse. If the HDFS block size is different across clusters, it cause file copy failures.
{code:java}
2018-04-09 14:32:06,690 ERROR [main] org.apache.hadoop.tools.mapred.CopyMapper: Failure in copying hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 to hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0
java.io.IOException: File copy failed: hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 --> hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0
 at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:299)
 at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:266)
 at org.apache.hadoop.tools.mapred.CopyMapper.map(CopyMapper.java:52)
 at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
 at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
 at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
 at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:170)
 at java.security.AccessController.doPrivileged(Native Method)
 at javax.security.auth.Subject.doAs(Subject.java:422)
 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1869)
 at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:164)
Caused by: java.io.IOException: Couldn't run retriable-command: Copying hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 to hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/000259_0
 at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:101)
 at org.apache.hadoop.tools.mapred.CopyMapper.copyFileWithRetry(CopyMapper.java:296)
 ... 10 more
Caused by: java.io.IOException: Check-sum mismatch between hdfs://chelsea/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/000259_0 and hdfs://marilyn/apps/hive/warehouse/tpch_flat_orc_1000.db/customer/.hive-staging_hive_2018-04-09_14-30-45_723_7153496419225102220-2/-ext-10001/.distcp.tmp.attempt_1522833620762_4416_m_000000_0. Source and target differ in block-size. Use -pb to preserve block-sizes during copy. Alternatively, skip checksum-checks altogether, using -skipCrc. (NOTE: By skipping checksums, one runs the risk of masking data-corruption during file-transfer.)
 at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.compareCheckSums(RetriableFileCopyCommand.java:212)
 at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doCopy(RetriableFileCopyCommand.java:130)
 at org.apache.hadoop.tools.mapred.RetriableFileCopyCommand.doExecute(RetriableFileCopyCommand.java:99)
 at org.apache.hadoop.tools.util.RetriableCommand.execute(RetriableCommand.java:87)
 ... 11 more
{code}
Distcp failed as the CM path for the file doesn't point to source file system. So, it is needed to get the qualified cm root URI as part of files listed in dump.

Also, REPL LOAD returns success even if distcp jobs failed.

CopyUtils.doCopyRetry doesn't throw error if copy failed even after maximum attempts. 

So, need to perform 2 things.
 # If copy of multiple files fail for some reason, then retry with same set of files again but need to set CM path if original source file is missing or modified based on checksum. Let distcp to skip the properly copied files. FileUtil.copy will always overwrite the files.
 # If source path is moved to CM path, then delete the incorrectly copied files.
 # If copy fails for maximum attempt, then throw error.

 "
HIVE-19247,StatsOptimizer: Missing stats fast-path for Date,"{code}
2018-04-19T18:57:24,268 DEBUG [67259108-c184-4c92-9e18-9e2969244442 HiveServer2-Handler-Pool: Thread-73]: optimizer.StatsOptimizer (StatsOptimizer.java:process(614)) - Unsupported type: date encountered in metadata optimizer for column : jour
{code}

{code}
if (udaf instanceof GenericUDAFMin) {
            ExprNodeColumnDesc colDesc = (ExprNodeColumnDesc)exprMap.get(((ExprNodeColumnDesc)aggr.getParameters().get(0)).getColumn());
            String colName = colDesc.getColumn();
            StatType type = getType(colDesc.getTypeString());
            if (!tbl.isPartitioned()) {
              if (!StatsSetupConst.areColumnStatsUptoDate(tbl.getParameters(), colName)) {
                Logger.debug(""Stats for table : "" + tbl.getTableName() + "" column "" + colName
                    + "" are not up to date."");
                return null;
              }
              ColumnStatisticsData statData = hive.getMSC().getTableColumnStatistics(
                  tbl.getDbName(), tbl.getTableName(), Lists.newArrayList(colName))
                  .get(0).getStatsData();
              String name = colDesc.getTypeString().toUpperCase();
              switch (type) {
                case Integeral: {
                  LongSubType subType = LongSubType.valueOf(name);
                  LongColumnStatsData lstats = statData.getLongStats();
                  if (lstats.isSetLowValue()) {
                    oneRow.add(subType.cast(lstats.getLowValue()));
                  } else {
                    oneRow.add(null);
                  }
                  break;
                }
                case Double: {
                  DoubleSubType subType = DoubleSubType.valueOf(name);
                  DoubleColumnStatsData dstats = statData.getDoubleStats();
                  if (dstats.isSetLowValue()) {
                    oneRow.add(subType.cast(dstats.getLowValue()));
                  } else {
                    oneRow.add(null);
                  }
                  break;
                }
                default: // unsupported type
                  Logger.debug(""Unsupported type: "" + colDesc.getTypeString() + "" encountered in "" +
                      ""metadata optimizer for column : "" + colName);
                  return null;
              }
            }
{code}

{code}
    enum StatType{
      Integeral,
      Double,
      String,
      Boolean,
      Binary,
      Unsupported
    }

    enum LongSubType {
      BIGINT { @Override
      Object cast(long longValue) { return longValue; } },
      INT { @Override
      Object cast(long longValue) { return (int)longValue; } },
      SMALLINT { @Override
      Object cast(long longValue) { return (short)longValue; } },
      TINYINT { @Override
      Object cast(long longValue) { return (byte)longValue; } };

      abstract Object cast(long longValue);
    }
{code}

Date is stored in stats (& also the typo there)."
HIVE-19243,Upgrade hadoop.version to 3.1.0,"Given that Hadoop 3.1.0 has been released, we need to upgrade hadoop.version to 3.1.0. This change is required for HIVE-18037 since it depends on YARN Service which had its first release in 3.1.0 (and is non-existent in 3.0.0)."
HIVE-19237,Only use an operatorId once in a plan,Column stats autogather plan part is added from a plan compiled by the driver itself; however that driver starts to use operatorIds from 1 ; so it's possible that 2 SEL_1 operators end up in the same plan...
HIVE-19231,Beeline generates garbled output when using UnsupportedTerminal,"We had a customer that was using some sort of front end that would invoke beeline commands with some query files on a node that that remote to the HS2 node.

So beeline runs locally on this edge but connects to a remote HS2. Since the fix made in HIVE-14342, the beeline started producing garbled line in the output. Something like
{code:java}
^Mnull                                                   ^Mnull^Mnull                                                   ^Mnull00-0000	All Occupations	135185230	42270
11-0000	Management occupations	6152650	100310{code}
 

I havent been able to reproduce the issue locally as I do not have their system, but with some additional instrumentation I have been able to get some info regarding the beeline process.

Essentially, such invocation causes beeline process to run with {{-Djline.terminal=jline.UnsupportedTerminal}} all the time and thus causes the issue. They can run the same beeline command directly in the shell on the same host and it does not cause this issue.

PID            S   TTY          TIME COMMAND
44107  S    S  ?        00:00:00 bash beeline -u ...

PID              S     TTY          TIME COMMAND
48453  S+   S     pts/4    00:00:00 bash beeline -u ...

Somehow that process wasnt attached to any local terminals. So the check made for /dev/stdin wouldnt work.

 

Instead an additional check to check the TTY session of the process before using the UnsupportedTerminal (which really should only be used for backgrounded beeline sessions) seems to resolve the issue."
HIVE-19230,Schema column width inconsistency in Oracle ,"This is for oracle only. Does not appear to be an issue with other DBs. When you upgrade hive schema from 2.1.0 to hive 3.0.0, the width of TXN_COMPONENTS.TC_TABLE is 256 and COMPLETED_TXN_COMPONENTS.CTC_TABLE is 128.

But if you install hive 3.0 schema directly, their widths are 128 and 256 respectively. This is consistent with schemas for other databases."
HIVE-19228,Remove commons-httpclient 3.x usage,Commons-httpclient is not supported well anymore.  Remove dependency and move to Apache HTTP client.
HIVE-19222,"TestNegativeCliDriver tests are failing due to ""java.lang.OutOfMemoryError: GC overhead limit exceeded""",TestNegativeCliDriver tests are failing with OOM recently. Not sure why. I will try to increase the memory to test out.  
HIVE-19219,Incremental REPL DUMP should throw error if requested events are cleaned-up.,"This is the case where the events were deleted on source because of old event purging and hence min(source event id) > target event id (last replicated event id).

Repl dump should fail in this case so that user can drop the database and bootstrap again.

Cleaner thread is concurrently removing the expired events from NOTIFICATION_LOG table. So, it is necessary to check if the current dump missed any event while dumping. After fetching events in batches, we shall check if it is fetched in contiguous sequence of event id. If it is not in contiguous sequence, then likely some events missed in the dump and hence throw error."
HIVE-19214,High throughput ingest ORC format,"Create delta files with all ORC overhead disabled (no index, no compression, no dictionary). Compactor will recreate the orc files with index, compression and dictionary encoding."
HIVE-19211,New streaming ingest API and support for dynamic partitioning,"- New streaming API under new hive sub-module
- Dynamic partitioning support
- Auto-rollover transactions
- Automatic heartbeating"
HIVE-19210,Create separate module for streaming ingest,This will retain the old hcat streaming API for old clients. The new streaming ingest API will be separate module under hive. 
HIVE-19209,Streaming ingest record writers should accept input stream,Record writers in streaming ingest currently accepts byte[]. Provide an option for clients to pass in input stream directly from which byte[] for record can be constructed. 
HIVE-19206,Automatic memory management for open streaming writers,"Problem:
 When there are 100s of record updaters open, the amount of memory required by orc writers keeps growing because of ORC's internal buffers. This can lead to potential high GC or OOM during streaming ingest.

Solution:
 The high level idea is for the streaming connection to remember all the open record updaters and flush the record updater periodically (at some interval). Records written to each record updater can be used as a metric to determine the candidate record updaters for flushing. 
 If stripe size of orc file is 64MB, the default memory management check happens only after every 5000 rows which may which may be too late when there are too many concurrent writers in a process. Example case would be 100 writers open and each of them have almost full stripe of 64MB buffered data, this would take 100*64MB ~=6GB of memory. When all of the record writers flush, the memory usage drops down to 100*~2MB which is just ~200MB memory usage."
HIVE-19200,Vectorization: Disable vectorization for LLAP I/O when a non-VECTORIZED_INPUT_FILE_FORMAT mode is needed (i.e. rows) and data type conversion is needed,"Disable vectorization for issue in HIVE-18763 until we can do the harder VRB conversion code.

The main changes are:

1) In the Vectorizer, detect if data type conversion is needed between the partition and the desired table schema.  If so and LLAP I/O is enabled that does encoded catching, then do not vectorize.  Why? When LLAP I/O is in encoded catching mode, it delivers VectorizedRowBatch (VRB) to the VectorMapOperator instead of (object) rows.  We currently do not have logic for converting VRBs.  So, we either get Wrong Results or more likely ClassCastException on the expected vs actual ColumnVector columns.

2) Cleaned up error message logic.that was suppressing the new message from the EXPLAIN VECTORIZATION display.

3) NOTE: Some of the SELECT statements in the schema_evol_test*.q are commented out because I bumped into a another bug.  I'll file that one soon and add comments to the Q files. 

---------------------------------------------------------------------------------------------------------------------------------------------------------------

The longer-term solution can be done later in steps:

1) Write a new code that can take a VectorizedRowBatch (VRB) and convert columns to different data types.  This is needed when LLAP is doing its encoding / caching and feeds VRBs to VectorMapOperator instead of rows.  Similar to what MapOperator does today, VectorMapOperator would need to be enhanced to convert partition VRBs into the table schema VRBs that the vector operator tree expect.

2) Today, vectorization logic is strictly positional based.  It insists that the partition columns have the same names as the table schema.  The MapOperator (and ORC) does more general conversion that uses column names instead of column position.  We'd need to enhance all 3 classes to handle column name based conversion.  The 3 classes are: the new VRB-to-VRB conversion class, VectorDeserializeRow, and VectorAssignRow."
HIVE-19196,TestTriggersMoveWorkloadManager is flaky,"This is a flaky test which randomly fails. Consider improving its stability.
{code}

org.apache.hive.jdbc.TestTriggersMoveWorkloadManager.testTriggerMoveConflictKill

Failing for the past 1 build (Since Failed#10161 )
Took 2.4 sec.
Error Message
'""eventType"" : ""GET""' expected in STDERR capture, but not found.
Stacktrace
java.lang.AssertionError: '""eventType"" : ""GET""' expected in STDERR capture, but not found.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hive.jdbc.AbstractJdbcTriggersTest.runQueryWithTrigger(AbstractJdbcTriggersTest.java:169)
	at org.apache.hive.jdbc.TestTriggersMoveWorkloadManager.testTriggerMoveConflictKill(TestTriggersMoveWorkloadManager.java:261)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}"
HIVE-19195,Fix flaky tests and cleanup testconfiguration to run llap specific tests in llap only.,"This test is certainly flaky. Seems like it makes some assumption about available memory. Consider dropping this altogether.

 Also remove tests from llaplocal.shared list to llaplocal so that they dont run in MR.

Makes HIVE-17055 redundant.
{code:java}
Client Execution succeeded but contained differences (error code = 1) after executing auto_sortmerge_join_2.q 
1101,1103d1100
< Hive Runtime Error: Map local work exhausted memory
< FAILED: Execution Error, return code 3 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask
< ATTEMPT: Execute BackupTask: org.apache.hadoop.hive.ql.exec.mr.MapRedTask
{code}"
HIVE-19194,TestDruidStorageHandler fails,"This tests fails randomly. If its not reproducible locally consider improving its stability since it does fail once in a while on Hive QA. 

{code}

java.lang.AssertionError: expected:<0> but was:<1> at org.junit.Assert.fail(Assert.java:88) at org.junit.Assert.failNotEquals(Assert.java:743) at org.junit.Assert.assertEquals(Assert.java:118) at org.junit.Assert.assertEquals(Assert.java:555) at org.junit.Assert.assertEquals(Assert.java:542) at org.apache.hadoop.hive.druid.TestDruidStorageHandler.testCommitMultiInsertOverwriteTable(TestDruidStorageHandler.java:414)

{code}"
HIVE-19193,TestActivePassiveHA fails,"This looks like a flaky test. If its not reproducible locally try improving on stability of this test, since it does fail randomly with Hive QA.
{code:java}
java.lang.AssertionError: expected:<true> but was:<false>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hive.jdbc.TestActivePassiveHA.testManualFailover(TestActivePassiveHA.java:356)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74){code}"
HIVE-19186,Multi Table INSERT statements query has a flaw for partitioned table when INSERT INTO and INSERT OVERWRITE are used,"One problem test case is: 

create table intermediate(key int) partitioned by (p int) stored as orc;
insert into table intermediate partition(p='455') select distinct key from src where key >= 0 order by key desc limit 2;
insert into table intermediate partition(p='456') select distinct key from src where key is not null order by key asc limit 2;
insert into table intermediate partition(p='457') select distinct key from src where key >= 100 order by key asc limit 2;

create table multi_partitioned (key int, key2 int) partitioned by (p int);

from intermediate
insert into table multi_partitioned partition(p=2) select p, key
insert overwrite table multi_partitioned partition(p=1) select key, p;"
HIVE-19171,Persist runtime statistics in metastore,
HIVE-19168,Ranger changes for llap commands,"New llap commands ""llap cluster -info"" and ""llap cache -purge"" require some changes so that Ranger can log the commands for auditing. "
HIVE-19167,"Map data type doesn't keep the order of the key/values pairs as read (Part 2, The Sequel or SQL)   ","HIVE-19116: ""Vectorization: Vector Map data type doesn't keep the order of the key/values pairs as read"" didn't fix all the places where HashMap is used instead of LinkedHashMap."
HIVE-19164,TestMetastoreVersion failures,"Following tests are failing consistently and are reproducible on master:

* testVersionMatching
* testMetastoreVersion

I tried debugging it and found that ObjectStore.getMSSchemaVersion() throws an exception {{No matching version found}}. 
To fetch schema version this method executes {code:sql} SELECT FROM org.apache.hadoop.hive.metastore.model.MVersionTable {code} but for whatever reason execution returns empty result set resulting in the exception. Both test failures are due to this exception. I tried debugging the query execution but didn't really go nowhere with it. I suspect this could be due to recent metastore changes. I tried reproducing this outside test but with no success."
HIVE-19161,Add authorizations to information schema,We need to control the access of information schema so user can only query the information authorized to.
HIVE-19159,TestMTQueries.testMTQueries1 failure,I have confirmed that HIVE-18051 caused this failure
HIVE-19157,Assert that Insert into Druid Table fails if the publishing of metadata by HS2 fails,"The usual work flow of loading Data into Druid relies on the fact that HS2 is able to load Segments metadata from HDFS that are produced by LLAP/TEZ works.
In some cases where HS2 is not able to perform `ls` on the HDFS path the insert into query will return success and will not insert any data.
This bug was introduced at function {code} org.apache.hadoop.hive.druid.DruidStorageHandlerUtils#getCreatedSegments{code} 
when we added feature to allow create empty tables.
{code}
 try {
      fss = fs.listStatus(taskDir);
    } catch (FileNotFoundException e) {
      // This is a CREATE TABLE statement or query executed for CTAS/INSERT
      // did not produce any result. We do not need to do anything, this is
      // expected behavior.
      return publishedSegmentsBuilder.build();
    }
{code}

Am still looking for the way to fix this, [~jcamachorodriguez]/[~ashutoshc] any idea what is the best way to detect that it is an empty create table statement? 

 
"
HIVE-19155,Day time saving cause Druid inserts to fail with org.apache.hive.druid.io.druid.java.util.common.UOE: Cannot add overlapping segments,"If you try to insert data around the daylight saving time hour the query fails with following exception
{code}
2018-04-10T11:24:58,836 ERROR [065fdaa2-85f9-4e49-adaf-3dc14d51be90 main] exec.DDLTask: Failed
org.apache.hadoop.hive.ql.metadata.HiveException: org.apache.hive.druid.io.druid.java.util.common.UOE: Cannot add overlapping segments [2015-03-08T05:00:00.000Z/2015-03-09T05:00:00.000Z and 2015-03-09T04:00:00.000Z/2015-03-10T04:00:00.000Z] with the same version [2018-04-10T11:24:48.388-07:00]
        at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:914) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:919) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4831) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:394) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2443) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:2114) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1797) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1538) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1532) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:157) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:204) [hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239) [hive-cli-3.1.0-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188) [hive-cli-3.1.0-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402) [hive-cli-3.1.0-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:335) [hive-cli-3.1.0-SNAPSHOT.jar:?]
        at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1455) [hive-it-util-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1429) [hive-it-util-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:177) [hive-it-util-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:104) [hive-it-util-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
        at org.apache.hadoop.hive.cli.TestMiniDruidCliDriver.testCliDriver(TestMiniDruidCliDriver.java:59) [test-classes/:?]
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_92]
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_92]
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_92]
{code}

You can reproduce this using the following DDL 
{code}
create database druid_test;
use druid_test;

create table test_table(`timecolumn` timestamp, `userid` string, `num_l` float);

insert into test_table values ('2015-03-08 00:00:00', 'i1-start', 4);
insert into test_table values ('2015-03-08 23:59:59', 'i1-end', 1);

insert into test_table values ('2015-03-09 00:00:00', 'i2-start', 4);
insert into test_table values ('2015-03-09 23:59:59', 'i2-end', 1);

insert into test_table values ('2015-03-10 00:00:00', 'i3-start', 2);
insert into test_table values ('2015-03-10 23:59:59', 'i3-end', 2);

CREATE TABLE druid_table
STORED BY 'org.apache.hadoop.hive.druid.DruidStorageHandler'
TBLPROPERTIES (""druid.segment.granularity"" = ""DAY"")
AS
select cast(`timecolumn` as timestamp with local time zone) as `__time`, `userid`, `num_l` FROM test_table;
{code}

The fix is to always adjust the Druid segments identifiers to UTC.
"
HIVE-19141,"TestNegativeCliDriver insert_into_notnull_constraint, insert_into_acid_notnull failing","These tests have been consistently failing for a while. I suspect HIVE-18727 has caused these failures. HIVE-18727 changed the code to throw ERROR instead of EXCEPTION if constraints are violated. I guess Negative cli driver doesn't handle errors.

Following are full list of related failures:

TestNegativeCliDriver.alter_notnull_constraint_violation
TestNegativeCliDriver.insert_into_acid_notnull 
TestNegativeCliDriver.insert_into_notnull_constraint 
TestNegativeCliDriver.insert_multi_into_notnull 
TestNegativeCliDriver.insert_overwrite_notnull_constraint 
TestNegativeCliDriver.update_notnull_constraint"
HIVE-19140,Update metastore upgrade scripts to prepare for 3.1.0 development,Now that branch for hive 3.0.0 is cut and we have started preparing for hive 3.1.0 development we need to add metastore upgrade scripts to upgrade from 3.0.0 to 3.1.0
HIVE-19135,Need tool to allow admins to create catalogs and move existing dbs to catalog during upgrade,As part of upgrading to Hive 3 admins may wish to create new catalogs and move some existing databases into those catalogs.  We can do this by adding options to schematool.  This guarantees that only admins can do these operations.
HIVE-19134,Update copyright NOTICE and fix rat check failures,
HIVE-19131,DecimalColumnStatsMergerTest comparison review,"DecimalColumnStatsMergerTest has a strange comparison logic, which needs to be reviewed.

Regarding low and high values, it uses compareTo with the same direction, which seems to be incorrect: old.compareTo(new) > 0 -> pick old value in both cases
{code:java}
Decimal lowValue = aggregateData.getLowValue() != null && (aggregateData.getLowValue().compareTo(newData.getLowValue()) > 0) ? aggregateData .getLowValue() : newData.getLowValue(); aggregateData.setLowValue(lowValue); 
Decimal highValue = aggregateData.getHighValue() != null && (aggregateData.getHighValue().compareTo(newData.getHighValue()) > 0) ? aggregateData .getHighValue() : newData.getHighValue();

{code}"
HIVE-19128,Update golden files for spark perf tests,
HIVE-19126,CachedStore: Use memory estimation to limit cache size during prewarm,"We can rely on https://github.com/apache/hive/blob/master/llap-server/src/java/org/apache/hadoop/hive/llap/IncrementalObjectSizeEstimator.java to estimate memory of SharedCache. This jira addresses the size estimation during prewarm, so that we can stop when we hit the memory limit. In a follow-up jira, we will work on estimation/eviction after prewarm is complete, so that we can keep the frequently used tables and their partitions in cache."
HIVE-19120,catalog not properly set for some tables in SQL upgrade scripts,A catalog column is added to the PARTITION_EVENTS and NOTIFICATION_LOG but the upgrade scripts do not include an UPDATE statement to set this to the default value.
HIVE-19118,Vectorization: Turning on vectorization in escape_crlf produces wrong results,Found in vectorization enable by default experiment.
HIVE-19110,Vectorization: Enabling vectorization causes TestContribCliDriver udf_example_arraymapstruct.q to produce Wrong Results,Found in vectorization enable by default experiment.
HIVE-19109,Vectorization: Enabling vectorization causes TestCliDriver delete_orig_table.q to produce Wrong Results,Found in vectorization enable by default experiment.
HIVE-19108,Vectorization and Parquet: Turning on vectorization in parquet_ppd_decimal.q causes Wrong Query Results,Found in vectorization enable by default experiment.
HIVE-19096,query result cache interferes with explain analyze ,"if  result cache is active; the explain analyze doesn't really return usefull informations; even for unseen queries the result is like this:

{code}
+----------------------------------------+
|                Explain                 |
+----------------------------------------+
| Stage-0                                |
|   Fetch Operator                       |
|     Cached Query Result:true,limit:-1  |
|                                        |
+----------------------------------------+
{code}
"
HIVE-19054,"Function replication shall use ""hive.repl.replica.functions.root.dir"" as root","It's wrongly use fs.defaultFS as the root, ignore ""hive.repl.replica.functions.root.dir"" definition, thus prevent replicating to cloud destination."
HIVE-19027,Make materializations invalidation cache work with multiple active remote metastores,"The main points:
 - Only MVs that use transactional tables can have a time window value of 0. Those are the only MVs that can be guaranteed to not be outdated when a query is executed.
 - For MVs that +cannot be outdated+, comparison is based on valid write id lists.
 - For MVs that +can be outdated+:
 ** The window for valid outdated MVs can be specified in intervals of 1 minute.
 ** A materialized view is outdated if it was built before that time window and any source table has been modified since.

A time window of -1 means to always use the materialized view for rewriting without any checks concerning its validity. If a materialized view uses an external table, the only way to trigger the rewriting would be to set the property to -1, since currently we do not capture for validation purposes whether the external source tables have been modified since the MV was created or not."
HIVE-19023,Druid storage Handler still using old select query when the CBO fails,"See usage of function {code} org.apache.hadoop.hive.druid.io.DruidQueryBasedInputFormat#createSelectStarQuery{code}
this can be replaced by scan query that is more efficent.

"
HIVE-19016,Vectorization and Parquet: Disable vectorization for nested complex types,"Original title: Vectorization and Parquet: When vectorized, parquet_nested_complex.q produces RuntimeException: Unsupported type used

 

Adding ""SET hive.vectorized.execution.enabled=true;"" to parquet_nested_complex.q triggers this call stack:
{noformat}
Caused by: java.lang.RuntimeException: Unsupported type used in list:array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<array<int>>>>>>>>>>>>>>>>>>>>>>
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.checkListColumnSupport(VectorizedParquetRecordReader.java:589) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.buildVectorizedParquetReader(VectorizedParquetRecordReader.java:525) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.checkEndOfRowGroup(VectorizedParquetRecordReader.java:440) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.nextBatch(VectorizedParquetRecordReader.java:401) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.next(VectorizedParquetRecordReader.java:353) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.parquet.vector.VectorizedParquetRecordReader.next(VectorizedParquetRecordReader.java:92) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.HiveContextAwareRecordReader.doNext(HiveContextAwareRecordReader.java:360) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
{noformat}
FYI: [~vihangk1]"
HIVE-19009,Retain and use runtime statistics during hs2 lifetime,
HIVE-18988,Support bootstrap replication of ACID tables,"Bootstrapping of ACID tables, need special handling to replicate a stable state of data.
 - If ACID feature enables, then perform bootstrap dump for ACID tables with in read txn.
 -> Dump table/partition metadata.
 -> Get the list of valid data files for a table using same logic as read txn do.
 -> Dump latest ValidWriteIdList as per current read txn.
 - Set the valid last replication state such that it doesn't miss any open txn started after triggering bootstrap dump.
 - If any txns on-going which was opened before triggering bootstrap dump, then it is not guaranteed that if open_txn event captured for these txns. Also, if these txns are opened for streaming ingest case, then dumped ACID table data may include data of open txns which impact snapshot isolation at target. To avoid that, bootstrap dump should wait for timeout (new configuration: hive.repl.bootstrap.dump.open.txn.timeout). After timeout, just force abort those txns and continue.
 - If any txns force aborted belongs to a streaming ingest case, then dumped ACID table data may have aborted data too. So, it is necessary to replicate the aborted write ids to target to mark those data invalid for any readers."
HIVE-18946,Fix columnstats merge NPE,"after analyzing an empty table may lead to an NPE when inserting into it...

{code}
2018-03-13T06:54:22,503 ERROR [df3fb505-e0bc-4595-a874-b735dab8dff6 main] metastore.RetryingHMSHandler: java.lang.NullPointerException
        at org.apache.hadoop.hive.metastore.api.Decimal.compareTo(Decimal.java:318)
        at org.apache.hadoop.hive.metastore.columnstats.merge.DecimalColumnStatsMerger.merge(DecimalColumnStatsMerger.java:35)
        at org.apache.hadoop.hive.metastore.utils.MetaStoreUtils.mergeColStats(MetaStoreUtils.java:778)
        at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.set_aggr_stats_for(HiveMetaStore.java:6934)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
        at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
        at com.sun.proxy.$Proxy55.set_aggr_stats_for(Unknown Source)
[...]
{code}

reproduce

{code}
set hive.stats.autogather=true;
set hive.explain.user=true;

drop table if exists testdeci2;

create table testdeci2(
id int,
amount decimal(10,3),
sales_tax decimal(10,3),
item string)
stored as orc location '/tmp/testdeci2'
TBLPROPERTIES (""transactional""=""false"")
;


analyze table testdeci2 compute statistics for columns;

insert into table testdeci2 values(1,12.123,12345.123,'desk1'),(2,123.123,1234.123,'desk2');
{code}"
HIVE-18875,Enable SMB Join by default in Tez,
HIVE-18866,Semijoin and analyze: Implement a Long -> Hash64 vector fast-path,"A significant amount of CPU is wasted with JMM restrictions on byte[] arrays.

To transform from one Long -> another Long, this goes into a byte[] array, which shows up as a hotspot.

!perf-hash64-long.png!"
HIVE-18840,CachedStore: Prioritize loading of recently accessed tables during prewarm,"On clusters with large metadata, prewarming the cache can take several hours. Now that CachedStore does not block on prewarm anymore (after HIVE-18264), we should prioritize loading of recently accessed tables during prewarm."
HIVE-18816,CREATE TABLE (ACID) doesn't work with TIMESTAMPLOCALTZ column type,"*Reproducer*
{code:sql}
set hive.support.concurrency=true;
set hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;

CREATE TABLE table_acid(d int, tz timestamp with local time zone)
    clustered by (d) into 2 buckets stored as orc TBLPROPERTIES ('transactional'='true');
{code}

*Error*
{code:sql}
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.IllegalArgumentException: Unknown primitive type TIMESTAMPLOCALTZ
{code}

*Error stack*
{noformat}
org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.IllegalArgumentException: Unknown primitive type TIMESTAMPLOCALTZ
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:906) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.DDLTask.createTable(DDLTask.java:4788) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:389) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:205) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:97) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:2314) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1985) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1687) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1438) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1427) [hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239) [hive-cli-3.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188) [hive-cli-3.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402) [hive-cli-3.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:335) [hive-cli-3.0.0-SNAPSHOT.jar:?]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClientInternal(QTestUtil.java:1345) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.QTestUtil.executeClient(QTestUtil.java:1319) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CoreCliDriver.runTest(CoreCliDriver.java:173) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.control.CliAdapter.runTest(CliAdapter.java:104) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.cli.TestMiniLlapLocalCliDriver.testCliDriver(TestMiniLlapLocalCliDriver.java:59) [test-classes/:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_101]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_101]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_101]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_101]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) [junit-4.11.jar:?]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.11.jar:?]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) [junit-4.11.jar:?]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.11.jar:?]
	at org.apache.hadoop.hive.cli.control.CliAdapter$2$1.evaluate(CliAdapter.java:92) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) [junit-4.11.jar:?]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) [junit-4.11.jar:?]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:?]
	at org.junit.runners.Suite.runChild(Suite.java:127) [junit-4.11.jar:?]
	at org.junit.runners.Suite.runChild(Suite.java:26) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:?]
	at org.apache.hadoop.hive.cli.control.CliAdapter$1$1.evaluate(CliAdapter.java:73) [hive-it-util-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.junit.rules.RunRules.evaluate(RunRules.java:20) [junit-4.11.jar:?]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:?]
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:369) [surefire-junit4-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:275) [surefire-junit4-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:239) [surefire-junit4-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:160) [surefire-junit4-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:373) [surefire-booter-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:334) [surefire-booter-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:119) [surefire-booter-2.20.1.jar:2.20.1]
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:407) [surefire-booter-2.20.1.jar:2.20.1]
Caused by: java.lang.IllegalArgumentException: Unknown primitive type TIMESTAMPLOCALTZ
	at org.apache.hadoop.hive.ql.io.orc.OrcStruct.createObjectInspector(OrcStruct.java:547) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.orc.OrcStruct$OrcStructInspector.<init>(OrcStruct.java:197) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.orc.OrcStruct.createObjectInspector(OrcStruct.java:550) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.orc.OrcSerde.initialize(OrcSerde.java:117) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.serde2.AbstractSerDe.initialize(AbstractSerDe.java:54) ~[hive-serde-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.serde2.SerDeUtils.initializeSerDe(SerDeUtils.java:540) ~[hive-serde-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreUtils.getDeserializer(HiveMetaStoreUtils.java:85) ~[hive-metastore-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreUtils.getDeserializer(HiveMetaStoreUtils.java:72) ~[hive-metastore-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.getDeserializerFromMetaStore(Table.java:286) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Table.checkValidity(Table.java:207) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.metadata.Hive.createTable(Hive.java:877) ~[hive-exec-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]
	... 55 more
{noformat}"
HIVE-18792,Allow standard compliant syntax for insert on partitioned tables,"Following works:

{code}

create table t1 (a int, b int, c int);

create table t2 (a int, b int, c int) partitioned by (d int);

insert into t1 values (1,2,3);

insert into t1 (c, b, a) values (1,2,3);

insert into t1 (a,b) values (1,2);

{code}

For partitioned tables it should work similarly but doesn't.  All of following fails:

{code}

insert into t2 values (1,2,3,4);

insert into t2 (a, b, c, d) values (1,2,3,4);

insert into t2 (c,d) values (1,2);

insert into t2 (a,b) values (1,2);

{code}

All of above should work. Also note following works:

{code}

insert into t2 partition(d)  values (1,2,3,4);

insert into t2 partition(d=4)  values (1,2,3);

{code}

 "
HIVE-18748,Rename table impacts the ACID behavior as table names are not updated in meta-tables.,"ACID implementation uses metatables such as TXN_COMPONENTS, COMPLETED_TXN_COMPONENTS, COMPACTION_QUEUE, COMPLETED_COMPCTION_QUEUE etc to manage ACID operations.

Per table write ID implementation (HIVE-18192) introduces couple of metatables such as NEXT_WRITE_ID and TXN_TO_WRITE_ID to manage write ids allocated per table.

Now, when we rename any tables, it is necessary to update the corresponding table names in these metatables as well. Otherwise, ACID table operations won't work properly.

Since, this change is significant and have other side-effects, we propose to disable rename tables on ACID tables until a fix is figured out."
HIVE-18743,CREATE TABLE on S3 data can be extremely slow. DO_NOT_UPDATE_STATS workaround is buggy.,"When hive.stats.autogather=true then the Metastore lists all files under the table directory to populate basic stats like file counts and sizes. This file listing operation can be very expensive particularly on filesystems like S3.

One way to address this issue is to reconfigure hive.stats.autogather=false.

*Here's the bug*
It is my understanding that the DO_NOT_UPDATE_STATS table property is intended to selectively prevent this stats collection. Unfortunately, this table property is checked *after* the expensive file listing operation, so the DO_NOT_UPDATE_STATS does not seem to work as intended. See:

https://github.com/apache/hive/blob/master/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/utils/MetaStoreUtils.java#L633

Relevant code snippet:
{code}
  public static boolean updateTableStatsFast(Database db, Table tbl, Warehouse wh,
                                             boolean madeDir, boolean forceRecompute, EnvironmentContext environmentContext) throws MetaException {
    if (tbl.getPartitionKeysSize() == 0) {
      // Update stats only when unpartitioned
      FileStatus[] fileStatuses = wh.getFileStatusesForUnpartitionedTable(db, tbl);
      return updateTableStatsFast(tbl, fileStatuses, madeDir, forceRecompute, environmentContext); <--- DO_NOT_UPDATE_STATS is checked in here after wh.getFileStatusesForUnpartitionedTable() has already been called
    } else {
      return false;
    }
  }
{code}
"
HIVE-18739,Add support for Import/Export from Acid table,
HIVE-18434,Type is not determined correctly for comparison between decimal column and string constant,
HIVE-18410,[Performance][Avro] Reading flat Avro tables is very expensive in Hive,"There's a performance penalty when reading flat [no nested fields] Avro tables. When reading the same flat dataset in Pig, it takes half the time.  On profiling, a lot of time is spent in {{AvroDeserializer.deserializeSingleItemNullableUnion()}}. The bulk of the time is spent in GenericData.get().resolveUnion(), which calls GenericData.getSchemaName(Object datum), which does a lot of instanceof checks.  This could be simplified with performance benefits. A approach is described in this patch which almost halves the runtime."
HIVE-18394,"Materialized view: ""Create Materialized View"" should default to rewritable ones","This is a usability ticket, since it is possible to end up creating materialized views and realize that they need an additional flag to be picked up by the optimizer to do rewrites to.

{code:sql}
create materialized view ca as select * from customer, customer_address where c_current_addr_sk = ca_address_sk;
set hive.materializedview.rewriting=true;
select count(1) from customer, customer_address where c_current_addr_sk = ca_address_sk; -- does not use materialized view
{code}

Needs another step

{code:sql}
alter materialized view ca enable rewrite;
{code}

And then, it kicks in 

{code:sql}
select count(1) from customer, customer_address where c_current_addr_sk = ca_address_sk;
OK
12000000
Time taken: 0.494 seconds, Fetched: 1 row(s)
{code}
"
HIVE-18193,Migrate existing ACID tables to use write id per table rather than global transaction id,"dependent upon HIVE-18192

For existing ACID Tables we need to update the table level write id metatables/sequences so any new operations on these tables works seamlessly without any conflicting data in existing base/delta files.

1. Need to create metadata tables such as NEXT_WRITE_ID and TXN_TO_WRITE_ID.

2. Add entries for each ACID/MM tables into NEXT_WRITE_ID where NWI_NEXT is set to current value of NEXT_TXN_ID.NTXN_NEXT.

3. All current open/abort transactions to have an entry in TXN_TO_WRITE_ID such that T2W_TXNID=T2W_WRITEID=Open/AbortedTxnId.

4. Added new column TC_WRITEID in TXN_COMPONENTS and CTC_WRITEID in COMPLETED_TXN_COMPONENTS to store the write id which should be set as respective values of TC_TXNID and CTC_TXNID from the same row."
HIVE-18079,Statistics: Allow HyperLogLog to be merged to the lowest-common-denominator bit-size,"HyperLogLog can merge a 14 bit HLL into a 10 bit HLL bitset, because of its mathematical hash distribution & construction.

Allow the squashing of a 14 bit HLL -> 10 bit HLL without needing a second scan over the data-set."
HIVE-18044,CompactorMR.CompactorOutputCommitter.abortTask() not implemented,"Can it explain the following?
{noformat}
Exception running child : org.apache.hadoop.fs.FileAlreadyExistsException: /apps/hiv/workmanagement.db/serviceorder_longtext/_tmp_40a7286b-da40-4624-baf3-4de12ec421f4/base_22699743/bucket_00006 for client 10.1.71.22 already exists 
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2784) 
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2671) 
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2555) 
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:735) 
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:408) 
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) 
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640) 
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)
{noformat}

and from yarn app log
{noformat}
2017-11-01 15:44:20,201 FATAL [IPC Server handler 3 on 42141] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1509391924057_1453_m_000002_1 - exited : org.apache.hadoop.fs.FileAlreadyExistsException: /apps/hive/warehouse/workmanagement.db/serviceorder_longtext/_tmp_e95a96e2-e605-47d9-b878-bb662cd9ece2/base_22490990/bucket_00007 for client 10.│
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2784)                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2671)                                                                                                                                                                                                                                                                      │
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2555)                                                                                                                                                                                                                                                                         │
│       at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:735)                                                                                                                                                                                                                                                                   │
│       at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:408)                                                                                                                                                                                                                  │
│       at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)                                                                                                                                                                                                             │
│       at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)                                                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)                                                                                                                                                                                                                                                                                                  │
│       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)                                                                                                                                                                                                                                                                                                  │
│       at java.security.AccessController.doPrivileged(Native Method)                                                                                                                                                                                                                                                                                                    │
│       at javax.security.auth.Subject.doAs(Subject.java:422)                                                                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)                                                                                                                                                                                                                                                                                                    │
│                                                                                                                                                                                                                                                                                                                                                                        │
│       at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)                                                                                                                                                                                                                                                                                         │
│       at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)                                                                                                                                                                                                                                                                  │
│       at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)                                                                                                                                                                                                                                                          │
│       at java.lang.reflect.Constructor.newInstance(Constructor.java:423)                                                                                                                                                                                                                                                                                               │
│       at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1804)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1701)                                                                                                                                                                                                                                                                                                  │
│       at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1636)                                                                                                                                                                                                                                                                                                  │
│       at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:480)                                                                                                                                                                                                                                                                         │
│       at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:476)                                                                                                                                                                                                                                                                         │
│       at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:476)                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:417)                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:930)                                                                                                                                                                                                                                                                                                   │
│       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:911)                                                                                                                                                                                                                                                                                                   │
│       at org.apache.hadoop.hive.ql.io.orc.WriterImpl.getStream(WriterImpl.java:2112)                                                                                                                                                                                                                                                                                   │
│       at org.apache.hadoop.hive.ql.io.orc.WriterImpl.flushStripe(WriterImpl.java:2129)                                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.hive.ql.io.orc.WriterImpl.close(WriterImpl.java:2434)                                                                                                                                                                                                                                                                                       │
│       at org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat$1.close(OrcOutputFormat.java:326)                                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.hive.ql.txn.compactor.CompactorMR$CompactorMap.close(CompactorMR.java:655)                                                                                                                                                                                                                                                                  │
│       at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:61)                                                                                                                                                                                                                                                                                                     │
│       at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:453)                                                                                                                                                                                                                                                                                               │
│       at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)                                                                                                                                                                                                                                                                                                        │
│       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:170)                                                                                                                                                                                                                                                                                                  │
│       at java.security.AccessController.doPrivileged(Native Method)                                                                                                                                                                                                                                                                                                    │
│       at javax.security.auth.Subject.doAs(Subject.java:422)                                                                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:164)                                                                                                                                                                                                                                                                                                   │
│Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.FileAlreadyExistsException): /apps/hive/warehouse/workmanagement.db/serviceorder_longtext/_tmp_e95a96e2-e605-47d9-b878-bb662cd9ece2/base_22490990/bucket_00007 for client 10.1.71.19 already exists                                                                                               │
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2784)                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2671)                                                                                                                                                                                                                                                                      │
│       at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2555)                                                                                                                                                                                                                                                                         │
│       at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:735)                                                                                                                                                                                                                                                                   │
│       at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:408)                                                                                                                                                                                                                  │
│       at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)                                                                                                                                                                                                             │
│       at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)                                                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)                                                                                                                                                                                                                                                                                                  │
│       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)                                                                                                                                                                                                                                                                                                  │
│       at java.security.AccessController.doPrivileged(Native Method)                                                                                                                                                                                                                                                                                                    │
│       at javax.security.auth.Subject.doAs(Subject.java:422)                                                                                                                                                                                                                                                                                                            │
│       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)                                                                                                                                                                                                                                                                          │
│       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)                                                                                                                                                                                                                                                                                                    │
│                                                                                                                                                                                                                                                                                                                                                                        │
│       at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1554)                                                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.ipc.Client.call(Client.java:1498)                                                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.ipc.Client.call(Client.java:1398)                                                                                                                                                                                                                                                                                                           │
│       at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)                                                                                                                                                                                                                                                                            │
│       at com.sun.proxy.$Proxy14.create(Unknown Source)                                                                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:313)                                                                                                                                                                                                                                      │
│       at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                                                                                                                                                                                                                                                                                                   │
│       at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)                                                                                                                                                                                                                                                                                 │
│       at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)                                                                                                                                                                                                                                                                         │
│       at java.lang.reflect.Method.invoke(Method.java:498)                                                                                                                                                                                                                                                                                                              │
│       at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:291)                                                                                                                                                                                                                                                               │
│       at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:203)                                                                                                                                                                                                                                                                     │
│       at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:185)                                                                                                                                                                                                                                                                     │
│       at com.sun.proxy.$Proxy15.create(Unknown Source)                                                                                                                                                                                                                                                                                                                 │
│       at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1799)                                                                                                                                                                                                                                                                          │
│       ... 22 more
{noformat}"
HIVE-17930,ReplChangeManager should use FileSystem object from current thread,"ReplChangeManager is a singleton and it has member FileSystem object that is created during initialization and then is re-used across recycle method calls.

With doAs=true mode, this doesn't work well as the FileSystem object would have been created using a user different from the current user.
This is also leading to errors with doAs=false mode, with long running HS2 instances, as it is failing to renew the kerberos tickets (reason for this effect is unclear).
"
HIVE-17824,msck repair table should drop the missing partitions from metastore,"{{msck repair table <tablename>}} is often used in environments where the new partitions are loaded as directories on HDFS or S3 and users want to create the missing partitions in bulk. However, currently it only supports addition of missing partitions. If there are any partitions which are present in metastore but not on the FileSystem, it should also delete them so that it truly repairs the table metadata.

We should be careful not to break backwards compatibility so we should either introduce a new config or keyword to add support to delete unnecessary partitions from the metastore. This way users who want the old behavior can easily turn it off. "
HIVE-17657,export/import for MM tables is broken,"there is mm_exim.q but it's not clear from the tests what file structure it creates 
On import the txnids in the directory names would have to be remapped if importing to a different cluster.  Perhaps export can be smart and export highest base_x and accretive deltas (minus aborted ones).  Then import can ...?  It would have to remap txn ids from the archive to new txn ids.  This would then mean that import is made up of several transactions rather than 1 atomic op.  (all locks must belong to a transaction)

One possibility is to open a new txn for each dir in the archive (where start/end txn of file name is the same) and commit all of them at once (need new TMgr API for that).  This assumes using a shared lock (if any!) and thus allows other inserts (not related to import) to occur.
What if you have delta_6_9, such as a result of concatenate?  If we stipulate that this must mean that there is no delta_6_6 or any other ""obsolete"" delta in the archive we can map it to a new single txn delta_x_x.

Add read_only mode for tables (useful in general, may be needed for upgrade etc) and use that to make the above atomic."
HIVE-17227,Incremental replication load should create tasks in execution phase rather than semantic phase ,as we did for bootstrap replication load in HIVE-16896 we should use a mechanism to dynamically create dag graph for incremental replication as well.
HIVE-15190,Field names are not preserved in ORC files written with ACID,"To repro:
{noformat}
drop table if exists orc_nonacid;
drop table if exists orc_acid;

create table orc_nonacid (a int) clustered by (a) into 2 buckets stored as orc;
create table orc_acid (a int) clustered by (a) into 2 buckets stored as orc TBLPROPERTIES('transactional'='true');

insert into table orc_nonacid values(1), (2);
insert into table orc_acid values(1), (2);
{noformat}

Running {{hive --service orcfiledump <file>}} on the files created by the {{insert}} statements above, you'll see that for {{orc_nonacid}}, the files have schema {{struct<a:int>}} whereas for {{orc_acid}}, the files have schema {{struct<operation:int,originalTransaction:bigint,bucket:int,rowId:bigint,currentTransaction:bigint,row:struct<_col0:int>>}}. The last field {{row}} should have schema {{struct<a:int>}}."
HIVE-12192,Hive should carry out timestamp computations in UTC,"Hive currently uses the ""local"" time of a java.sql.Timestamp to represent the SQL data type TIMESTAMP WITHOUT TIME ZONE. The purpose is to be able to use {{Timestamp#getYear()}} and similar methods to implement SQL functions like {{year}}.

When the SQL session's time zone is a DST zone, such as America/Los_Angeles that alternates between PST and PDT, there are times that cannot be represented because the effective zone skips them.

{code}
hive> select TIMESTAMP '2015-03-08 02:10:00.101';
2015-03-08 03:10:00.101
{code}

Using UTC instead of the SQL session time zone as the underlying zone for a java.sql.Timestamp avoids this bug, while still returning correct values for {{getYear}} etc. Using UTC as the convenience representation (timestamp without time zone has no real zone) would make timestamp calculations more consistent and avoid similar problems in the future.

Notably, this would break the {{unix_timestamp}} UDF that specifies the result is with respect to [""the default timezone and default locale""|https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-DateFunctions]. That function would need to be updated to use the {{System.getProperty(""user.timezone"")}} zone."
