Bug ID,Bug Summary,Bug Description
CASSANDRA-19606,Fix building debian packages,"Trying to run cassandra-deb-packaging.sh will result in the docker image looping:

{noformat}
Errors were encountered while processing:
 ed
 quilt
 cassandra-build-deps
E: Sub-process /usr/bin/dpkg returned an error code (1)
(Reading database ... 36721 files and directories currently installed.)
Removing cassandra-build-deps (5.0~beta2-20240501gitae9be29918) ...
mk-build-deps: Unable to install all build-dep packages
mk-build-deps failed… trying again after 10s… 
{noformat}"
CASSANDRA-19427,Fix concurrent access of ClientWarn causing AIOBE for SELECT WHERE IN queries with multiple coordinator-local partitions,"On one of our clusters, we noticed rare but periodic ArrayIndexOutOfBoundsExceptions:

 
{code:java}
message=""Uncaught exception on thread Thread[ReadStage-3,5,main]""
exception=""java.lang.RuntimeException: java.lang.ArrayIndexOutOfBoundsException
at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2579)
at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:119)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ArrayIndexOutOfBoundsException""{code}
 

 

The error was in a Runnable, so the stacktrace didn't directly indicate where the error was coming from. We enabled JFR to log the underlying exception that was thrown:
 
{code:java}
message=""Uncaught exception on thread Thread[ReadStage-2,5,main]"" exception=""java.lang.RuntimeException: java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 0
at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2579)
at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:119)
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 0
at java.base/java.util.ArrayList.add(ArrayList.java:487)
at java.base/java.util.ArrayList.add(ArrayList.java:499)
at org.apache.cassandra.service.ClientWarn$State.add(ClientWarn.java:84)
at org.apache.cassandra.service.ClientWarn$State.access$000(ClientWarn.java:77)
at org.apache.cassandra.service.ClientWarn.warn(ClientWarn.java:51)
at org.apache.cassandra.db.ReadCommand$1MetricRecording.onClose(ReadCommand.java:596)
at org.apache.cassandra.db.transform.BasePartitions.runOnClose(BasePartitions.java:70)
at org.apache.cassandra.db.transform.BaseIterator.close(BaseIterator.java:95)
at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:2260)
at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2575)
... 6 more""{code}
 
 

An AIOBE on ArrayList.add(E) should only be possible when multiple threads attempt to call the method at the same time.

 

This was seen while executing a SELECT WHERE IN query with multiple partition keys. This exception could happen when multiple local reads are dispatched by the coordinator in org.apache.cassandra.service.reads.AbstractReadExecutor#makeRequests. In this case, multiple local reads exceed the tombstone warning threshold, so multiple tombstone warnings are added to the same ClientWarn.State reference.  Currently, org.apache.cassandra.service.ClientWarn.State#warnings is an ArrayList, which isn't safe for concurrent modification, causing the AIOBE to be thrown.

 

I have a patch available for this, and I'm preparing it now. The patch is simple - it just changes org.apache.cassandra.service.ClientWarn.State#warnings to a thread-safe CopyOnWriteArrayList. I also have a jvm-dtest that demonstrates the issue but doesn't need to be merged - it shows how a SELECT WHERE IN query with local reads that add client warnings can add to the same ClientWarn.State from different threads. I'll push that in a separate branch just for demonstration purposes.

 

Demonstration branch: [https://github.com/apache/cassandra/compare/trunk...aratno:cassandra:CASSANDRA-19427-aiobe-clientwarn-demo]

Fix branch: [https://github.com/apache/cassandra/compare/trunk...aratno:cassandra:CASSANDRA-19427-aiobe-clientwarn-fix] (PR linked below)

 

This appears to have been an issue since at least 3.11, that was the earliest release I checked."
CASSANDRA-18910,Debian packaging broken by quilt?,"Something has changed in the docker image that is breaking the debian packaging in all versions, similar to this:

{quote}
dpkg-buildpackage: info: source package cassandra
dpkg-buildpackage: info: source version 4.1.4-20231004git486acc68f1
dpkg-buildpackage: info: source distribution unstable
dpkg-buildpackage: info: source changed by build <build@1518e06a5507>
dpkg-buildpackage: info: host architecture amd64
 dpkg-source --tar-ignore=.git --before-build .
 fakeroot debian/rules clean
QUILT_PATCHES=debian/patches \
        quilt --quiltrc /dev/null pop -a -R || test $? = 1
No patch removed
make: *** [/usr/share/quilt/quilt.make:23: unpatch] Error 1
dpkg-buildpackage: error: fakeroot debian/rules clean subprocess returned exit status 2
{quote}"
CASSANDRA-18739,UDF functions fail to load on rolling restart,"UDFs fail to reload properly after a rolling restart.
h3. *Symptom:*

NPE thrown when used after restart.
h3. *Steps to recreate:*
 # Create a cluster as per cql file
 # Populate the cluster with data.cql.
 # Execute SELECT city_measurements(city, measurement, 16.5) AS m FROM current
 # expect min and max values for cities.
 # Performing a rolling restart on one server.
 # When the server is back up
 # Execute SELECT city_measurements(city, measurement, 16.5) AS m FROM current
 # expect: error result with NPE message.


{*}Analysis{*}:

During system restart the SchemaKeyspace.fetchNonSystemKeyspaces() is called, when a keyspace with a UDF is loaded the SchemaKeyspace method createUDFFromRow() is called, this in turn calls UDFunction.create() which eventually calls back to UDFunction constructor where the Schema.instance.getKeyspaceMetadata() is called with the keyspace for the UDF name as the argument. However, the keyspace for the UDF name is being constructed and is not yet in the instance so the method returns null for the KeyspaceMetadata. That null KeyspaceMetadata is then used in the udfContext.

Later when the UDF method is called, if there is a need to call a method on the keyspaceMetadata, such as udfContext.newUDTValue() where the implementation uses keyspaceMetadata.types, a null pointer is thrown.

I have verified this affects version 4.0, 4.1 and trunk. I have not verified 3.x but I suspect it is the same there.

I modified UDFunction constructor to assert that the metadata was not null and received the following stack trace

ERROR [main] 2023-08-09 11:44:46,408 CassandraDaemon.java:911 - Exception encountered during startup
java.lang.AssertionError: No metadata for temperatures.city_measurements_sfunc
    at org.apache.cassandra.cql3.functions.UDFunction.<init>(UDFunction.java:240)
    at org.apache.cassandra.cql3.functions.JavaBasedUDFunction.<init>(JavaBasedUDFunction.java:195)
    at org.apache.cassandra.cql3.functions.UDFunction.create(UDFunction.java:276)
    at org.apache.cassandra.schema.SchemaKeyspace.createUDFFromRow(SchemaKeyspace.java:1182)
    at org.apache.cassandra.schema.SchemaKeyspace.fetchUDFs(SchemaKeyspace.java:1131)
    at org.apache.cassandra.schema.SchemaKeyspace.fetchFunctions(SchemaKeyspace.java:1119)
    at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:859)
    at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesWithout(SchemaKeyspace.java:848)
    at org.apache.cassandra.schema.SchemaKeyspace.fetchNonSystemKeyspaces(SchemaKeyspace.java:836)
    at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:132)
    at org.apache.cassandra.schema.Schema.loadFromDisk(Schema.java:121)
    at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:287)
    at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:765)
    at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:889)

 

{{*Possible solution:*}}

*Version 4.x*

Create a KeyspaceMetadata.Builder class that uses accepts the types, tables and views but uses a builder for the functions.

Add a KeyspaceMetadata constructor to accept the KeyspaceMetadata.Builder so that the function builder keyspaceMetadata value can be set correctly during construction of the KeyspaceMetadata.

Modify SchemaKeyspace.fetchKeyspace(string) so that it uses the KeyspaceMetadata.Builder.

 

*Version 5.x*

Similar to 4.x except that the KeyspaceMetadata.Builder will have to have builders for Views and Tables because the functions necessary to construct those objects will not be available until the KeyspaceMetadata.Builder constructs it.

 "
CASSANDRA-18725,IsolatedJMX should not release all TCPEndpoints on instance shutdown,"In the original implementation of the JMX feature, we fixed some memory leaks by clearing some internal state in Java’s TCPEndpoint. However, that implementation was overly aggressive and cleared the whole map, vs. just removing the endpoints created by the individual instances. This causes issues when you remove a node from the cluster (as all of the endpoints are cleared, not just the ones in use by that instance).
 
In stead, we should check if the endpoint was created by the instance in question and only remove it if it was."
CASSANDRA-18709,Test failure: dtest.jmx_test.TestJMX.test_compactionstats,"Seen here:

[https://ci-cassandra.apache.org/job/Cassandra-trunk/1646/testReport/dtest.jmx_test/TestJMX/test_compactionstats/]
h3.  
{code:java}
Error Message
AttributeError: 'NoneType' object has no attribute 'named'

Stacktrace
self = <jmx_test.TestJMX object at 0x7fe78cfc2940> def test_compactionstats(self): """""" @jira_ticket CASSANDRA-10504 @jira_ticket CASSANDRA-10427 Test that jmx MBean used by nodetool compactionstats properly updates the progress of a compaction """""" cluster = self.cluster cluster.populate(1) node = cluster.nodelist()[0] cluster.start() # Run a quick stress command to create the keyspace and table node.stress(['write', 'n=1', 'no-warmup']) # Disable compaction on the table node.nodetool('disableautocompaction keyspace1 standard1') node.nodetool('setcompactionthroughput 1') node.stress(['write', 'n=150K', 'no-warmup']) node.flush() # Run a major compaction. This will be the compaction whose # progress we track. node.nodetool_process('compact') # We need to sleep here to give compaction time to start # Why not do something smarter? Because if the bug regresses, # we can't rely on jmx to tell us that compaction started. time.sleep(5) compaction_manager = make_mbean('db', type='CompactionManager') with JolokiaAgent(node) as jmx: progress_string = jmx.read_attribute(compaction_manager, 'CompactionSummary')[0] # Pause in between reads # to allow compaction to move forward time.sleep(2) updated_progress_string = jmx.read_attribute(compaction_manager, 'CompactionSummary')[0] var = 'Compaction@{uuid}(keyspace1, standard1, {progress}/{total})bytes' if self.cluster.version() >= LooseVersion('4.0'): # CASSANDRA-15954 var = 'Compaction({taskUuid}, {progress} / {total} bytes)@{uuid}(keyspace1, standard1)' > progress = int(parse.search(var, progress_string).named['progress']) E AttributeError: 'NoneType' object has no attribute 'named' jmx_test.py:218: AttributeError
{code}
 "
CASSANDRA-18643,jackson-core vulnerability: CVE-2022-45688,"This is failing owasp.

https://nvd.nist.gov/vuln/detail/CVE-2022-45688

{quote}
A stack overflow in the XML.toJSONObject component of hutool-json v5.8.10 allows attackers to cause a Denial of Service (DoS) via crafted JSON or XML data.
{quote}"
CASSANDRA-18609,snappy-java vulnerability: CVE-2023-34453,"Failing owasp:

[https://nvd.nist.gov/vuln/detail/CVE-2023-34453]

bq. Due to unchecked multiplications, an integer overflow may occur in versions prior to 1.1.10.1, causing a fatal error. "
CASSANDRA-18608,"snappy-java vulnerability: CVE-2023-34455, CVE-2023-34454, CVE-2023-34453","Failing owasp:

[https://nvd.nist.gov/vuln/detail/CVE-2023-34455]
{quote}Due to use of an unchecked chunk length, an unrecoverable fatal error can occur in versions prior to 1.1.10.1.
{quote}

[https://nvd.nist.gov/vuln/detail/CVE-2023-34454]
{quote}Due to unchecked multiplications, an integer overflow may occur in versions prior to 1.1.10.1, causing an unrecoverable fatal error. 
{quote}

[https://nvd.nist.gov/vuln/detail/CVE-2023-34453]
{quote}Due to unchecked multiplications, an integer overflow may occur in versions prior to 1.1.10.1, causing a fatal error.
{quote}
"
CASSANDRA-18448,"Missing ""SSTable Count"" metric  when using nodetool with ""--format"" option","Hi, 

I'm using ""nodetool cfstats --format json"" to gather some metrics/infomation about our tables. 
I noticed that the ""SSTable Count"" is missing when using ""–format"" option. 

If I don't use ""–format""  option, I can set ""SSTable Count"" in the output. 

*Output of ""nodetool cfstats --format json | jq"":* 
{code:java}
{  ""total_number_of_tables"": 38,  ""stress_test"": {    ""write_latency_ms"": 0.8536725334338424,    ""tables"": {      ""res1"": {        ""average_tombstones_per_slice_last_five_minutes"": null,        ""bloom_filter_off_heap_memory_used"": ""159256"",        ""memtable_switch_count"": 754,        ""maximum_tombstones_per_slice_last_five_minutes"": 0,        ""memtable_cell_count"": 0,        ""memtable_data_size"": ""0"",        ""average_live_cells_per_slice_last_five_minutes"": null,        ""local_read_latency_ms"": ""NaN"",        ""local_write_latency_ms"": ""NaN"",        ""pending_flushes"": 0,        ""compacted_partition_minimum_bytes"": 785940,        ""local_read_count"": 0,        ""sstable_compression_ratio"": 0.6294161376582798,        ""dropped_mutations"": ""52751"",        ""bloom_filter_false_positives"": 0,        ""off_heap_memory_used_total"": ""58842196"",        ""memtable_off_heap_memory_used"": ""0"",        ""index_summary_off_heap_memory_used"": ""18972"",        ""bloom_filter_space_used"": ""159408"",        ""sstables_in_each_level"": [],        ""compacted_partition_maximum_bytes"": 4055269,        ""space_used_total"": ""302694398635"",        ""local_write_count"": 297111,        ""compression_metadata_off_heap_memory_used"": ""58663968"",        ""number_of_partitions_estimate"": 99614,        ""maximum_live_cells_per_slice_last_five_minutes"": 0,        ""space_used_live"": ""302694398635"",        ""compacted_partition_mean_bytes"": 3827283,        ""bloom_filter_false_ratio"": ""0.00000"",        ""percent_repaired"": 0,        ""space_used_by_snapshots_total"": ""0""      }    },    ""read_latency_ms"": null,    ""pending_flushes"": 0,    ""write_count"": 594308,    ""read_latency"": null,    ""read_count"": 0  }}
 {code}
*Output of ""nodetool cfstats"":* 
{code:java}
----------------
Keyspace : stress_test
        Read Count: 0
        Read Latency: NaN ms
        Write Count: 594308
        Write Latency: 0.8536725334338424 ms
        Pending Flushes: 0
                Table: res1
                SSTable count: 19                
                Space used (live): 302694398635
                Space used (total): 302694398635
                Space used by snapshots (total): 0
                Off heap memory used (total): 58842196
                SSTable Compression Ratio: 0.6294161376582798
                Number of partitions (estimate): 99614
                Memtable cell count: 0
                Memtable data size: 0
                Memtable off heap memory used: 0
                Memtable switch count: 754
                Local read count: 0
                Local read latency: NaN ms
                Local write count: 297111
                Local write latency: NaN ms
                Pending flushes: 0
                Percent repaired: 0.0
                Bloom filter false positives: 0
                Bloom filter false ratio: 0.00000
                Bloom filter space used: 159408
                Bloom filter off heap memory used: 159256
                Index summary off heap memory used: 18972
                Compression metadata off heap memory used: 58663968
                Compacted partition minimum bytes: 785940
                Compacted partition maximum bytes: 4055269
                Compacted partition mean bytes: 3827283
                Average live cells per slice (last five minutes): NaN
                Maximum live cells per slice (last five minutes): 0
                Average tombstones per slice (last five minutes): NaN
                Maximum tombstones per slice (last five minutes): 0
                Dropped Mutations: 52751*  
----------------
 {code}
 "
CASSANDRA-18336,Do not remove SSTables when cause of FSReadError is OutOfMemoryError while using best_effort disk failure policy,"1.When this exception occurs in the system
{code:java}
// 
ERROR [CompactionExecutor:351627] 2023-02-21 17:59:20,721 CassandraDaemon.java:581 - Exception in thread Thread[CompactionExecutor:351627,1,main]
org.apache.cassandra.io.FSReadError: java.io.IOException: Map failed
    at org.apache.cassandra.io.util.ChannelProxy.map(ChannelProxy.java:167)
    at org.apache.cassandra.io.util.MmappedRegions$State.add(MmappedRegions.java:310)
    at org.apache.cassandra.io.util.MmappedRegions$State.access$400(MmappedRegions.java:246)
    at org.apache.cassandra.io.util.MmappedRegions.updateState(MmappedRegions.java:170)
    at org.apache.cassandra.io.util.MmappedRegions.<init>(MmappedRegions.java:73)
    at org.apache.cassandra.io.util.MmappedRegions.<init>(MmappedRegions.java:61)
    at org.apache.cassandra.io.util.MmappedRegions.map(MmappedRegions.java:104)
    at org.apache.cassandra.io.util.FileHandle$Builder.complete(FileHandle.java:365)
    at org.apache.cassandra.io.sstable.format.big.BigTableWriter.openEarly(BigTableWriter.java:337)
    at org.apache.cassandra.io.sstable.SSTableRewriter.maybeReopenEarly(SSTableRewriter.java:172)
    at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:124)
    at org.apache.cassandra.db.compaction.writers.DefaultCompactionWriter.realAppend(DefaultCompactionWriter.java:64)
    at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.append(CompactionAwareWriter.java:137)
    at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:193)
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
    at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:77)
    at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:100)
    at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:298)
    at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
    at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
    at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
    at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
    at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
    at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.io.IOException: Map failed
    at java.base/sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:1016)
    at org.apache.cassandra.io.util.ChannelProxy.map(ChannelProxy.java:163)
    ... 23 common frames omitted
Caused by: java.lang.OutOfMemoryError: Map failed
    at java.base/sun.nio.ch.FileChannelImpl.map0(Native Method)
    at java.base/sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:1013)


{code}
2.Restart the node, Verifying logfile transaction ,All sstables are deleted
{code:java}
// code placeholder
INFO  [main] 2023-02-21 18:00:23,350 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8819408-big-Index.db 
INFO  [main] 2023-02-21 18:00:23,615 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8819408-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,504 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_c923b230-b077-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:46,510 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_461935b0-b1ce-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:46,517 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,517 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,518 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,520 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,520 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,520 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,521 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,521 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830658-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,521 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,526 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,526 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,537 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830657-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,537 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,537 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,539 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,539 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,540 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,541 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,541 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,541 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830660-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,541 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,541 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,543 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,545 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,545 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,545 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,545 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,546 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830659-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,549 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_461935b0-b1ce-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:46,550 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_69071e60-b18e-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:46,577 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,577 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,579 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,579 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828386-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,580 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,584 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,584 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,585 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,585 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,585 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,585 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828385-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,586 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,590 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,592 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,592 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,602 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,602 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,602 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,602 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828384-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,606 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_69071e60-b18e-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:46,610 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_8b8205e0-b18e-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:46,641 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,644 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,644 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,644 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,684 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,684 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,684 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,684 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828320-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,685 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,687 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,688 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,727 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,728 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,728 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,728 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,728 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828183-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,728 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,731 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Filter.db 
INFO  [main] 2023-02-21 18:00:46,732 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Summary.db 
INFO  [main] 2023-02-21 18:00:46,732 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Data.db 
INFO  [main] 2023-02-21 18:00:46,770 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:46,770 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:46,771 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:46,771 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828255-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:46,774 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_8b8205e0-b18e-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:46,775 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_008f3d00-b1ce-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:46,779 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830650-big-Index.db 
INFO  [main] 2023-02-21 18:00:46,787 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830650-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,020 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_008f3d00-b1ce-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:47,022 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_6f265950-b18e-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:47,050 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,055 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,055 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,072 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,072 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,072 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,072 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,074 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828337-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,074 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,077 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,078 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,092 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,093 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,093 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,093 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,093 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828375-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,093 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,097 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,098 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,113 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,113 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,113 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,113 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,113 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828354-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,117 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_6f265950-b18e-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:47,118 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_fb014430-b18e-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,133 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,134 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,134 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,246 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,246 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,246 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,247 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827806-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,247 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,255 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,255 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,255 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,368 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,369 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,369 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,369 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828112-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,369 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Index.db 
INFO  [main] 2023-02-21 18:00:47,374 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Filter.db 
INFO  [main] 2023-02-21 18:00:47,374 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Summary.db 
INFO  [main] 2023-02-21 18:00:47,374 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Data.db 
INFO  [main] 2023-02-21 18:00:47,484 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Digest.crc32 
INFO  [main] 2023-02-21 18:00:47,485 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:00:47,485 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-Statistics.db 
INFO  [main] 2023-02-21 18:00:47,485 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827506-big-TOC.txt 
INFO  [main] 2023-02-21 18:00:47,490 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_fb014430-b18e-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:00:47,492 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_unknowncompactiontype_695c4f33-b1ce-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:00:47,502 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Index.db 
INFO  [main] 2023-02-21 18:00:48,045 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Filter.db 
INFO  [main] 2023-02-21 18:00:48,053 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Summary.db 
INFO  [main] 2023-02-21 18:00:48,053 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Data.db 
INFO  [main] 2023-02-21 18:01:21,166 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Digest.crc32 
INFO  [main] 2023-02-21 18:01:21,202 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:01:21,272 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-Statistics.db 
INFO  [main] 2023-02-21 18:01:21,272 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7859661-big-TOC.txt 
INFO  [main] 2023-02-21 18:01:21,272 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Index.db 
INFO  [main] 2023-02-21 18:01:21,276 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Filter.db 
INFO  [main] 2023-02-21 18:01:21,276 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Data.db 
INFO  [main] 2023-02-21 18:01:21,500 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Summary.db 
INFO  [main] 2023-02-21 18:01:21,500 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Digest.crc32 
INFO  [main] 2023-02-21 18:01:21,500 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:01:21,501 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-Statistics.db 
INFO  [main] 2023-02-21 18:01:21,501 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830374-big-TOC.txt 
INFO  [main] 2023-02-21 18:01:21,501 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Index.db 
INFO  [main] 2023-02-21 18:01:21,841 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Filter.db 
INFO  [main] 2023-02-21 18:01:21,842 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Summary.db 
INFO  [main] 2023-02-21 18:01:21,842 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Data.db 
INFO  [main] 2023-02-21 18:01:22,779 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Digest.crc32 
INFO  [main] 2023-02-21 18:01:22,779 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:01:22,780 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-Statistics.db 
INFO  [main] 2023-02-21 18:01:22,780 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821887-big-TOC.txt 
INFO  [main] 2023-02-21 18:01:22,780 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Filter.db 
INFO  [main] 2023-02-21 18:01:22,825 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Index.db 
INFO  [main] 2023-02-21 18:01:24,891 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Summary.db 
INFO  [main] 2023-02-21 18:01:24,892 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Data.db 
INFO  [main] 2023-02-21 18:02:02,190 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Digest.crc32 
INFO  [main] 2023-02-21 18:02:02,352 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:02:02,461 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-Statistics.db 
INFO  [main] 2023-02-21 18:02:02,461 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5298119-big-TOC.txt 
INFO  [main] 2023-02-21 18:02:02,462 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Index.db 
INFO  [main] 2023-02-21 18:02:02,466 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Filter.db 
INFO  [main] 2023-02-21 18:02:02,467 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Data.db 
INFO  [main] 2023-02-21 18:02:02,763 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Summary.db 
INFO  [main] 2023-02-21 18:02:02,764 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Digest.crc32 
INFO  [main] 2023-02-21 18:02:02,764 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:02:02,764 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-Statistics.db 
INFO  [main] 2023-02-21 18:02:02,764 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8826214-big-TOC.txt 
INFO  [main] 2023-02-21 18:02:02,765 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Index.db 
INFO  [main] 2023-02-21 18:02:05,377 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Filter.db 
INFO  [main] 2023-02-21 18:02:05,388 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Summary.db 
INFO  [main] 2023-02-21 18:02:05,388 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Data.db 
INFO  [main] 2023-02-21 18:02:41,367 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Digest.crc32 
INFO  [main] 2023-02-21 18:02:41,368 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:02:41,397 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-Statistics.db 
INFO  [main] 2023-02-21 18:02:41,397 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7315697-big-TOC.txt 
INFO  [main] 2023-02-21 18:02:41,398 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Index.db 
INFO  [main] 2023-02-21 18:02:42,034 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Filter.db 
INFO  [main] 2023-02-21 18:02:42,049 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Data.db 
INFO  [main] 2023-02-21 18:04:02,731 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Summary.db 
INFO  [main] 2023-02-21 18:04:02,732 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Digest.crc32 
INFO  [main] 2023-02-21 18:04:02,732 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:04:02,770 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-Statistics.db 
INFO  [main] 2023-02-21 18:04:02,770 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6687036-big-TOC.txt 
INFO  [main] 2023-02-21 18:04:02,770 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Index.db 
INFO  [main] 2023-02-21 18:04:02,784 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Filter.db 
INFO  [main] 2023-02-21 18:04:02,785 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Data.db 
INFO  [main] 2023-02-21 18:04:02,889 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Summary.db 
INFO  [main] 2023-02-21 18:04:02,890 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Digest.crc32 
INFO  [main] 2023-02-21 18:04:02,890 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:04:02,890 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-Statistics.db 
INFO  [main] 2023-02-21 18:04:02,890 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829808-big-TOC.txt 
INFO  [main] 2023-02-21 18:04:02,890 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Index.db 
INFO  [main] 2023-02-21 18:04:03,384 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Filter.db 
INFO  [main] 2023-02-21 18:04:03,418 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Data.db 
INFO  [main] 2023-02-21 18:04:38,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Summary.db 
INFO  [main] 2023-02-21 18:04:38,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Digest.crc32 
INFO  [main] 2023-02-21 18:04:38,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:04:38,245 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-Statistics.db 
INFO  [main] 2023-02-21 18:04:38,245 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6839605-big-TOC.txt 
INFO  [main] 2023-02-21 18:04:38,246 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Filter.db 
INFO  [main] 2023-02-21 18:04:38,293 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Index.db 
INFO  [main] 2023-02-21 18:04:39,438 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Summary.db 
INFO  [main] 2023-02-21 18:04:39,438 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Data.db 
INFO  [main] 2023-02-21 18:05:28,014 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Digest.crc32 
INFO  [main] 2023-02-21 18:05:28,015 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:05:28,041 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-Statistics.db 
INFO  [main] 2023-02-21 18:05:28,041 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5373453-big-TOC.txt 
INFO  [main] 2023-02-21 18:05:28,041 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Filter.db 
INFO  [main] 2023-02-21 18:05:28,042 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Index.db 
INFO  [main] 2023-02-21 18:05:28,277 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Data.db 
INFO  [main] 2023-02-21 18:06:17,552 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Summary.db 
INFO  [main] 2023-02-21 18:06:17,553 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Digest.crc32 
INFO  [main] 2023-02-21 18:06:17,554 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:06:17,565 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-Statistics.db 
INFO  [main] 2023-02-21 18:06:17,565 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5607362-big-TOC.txt 
INFO  [main] 2023-02-21 18:06:17,566 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Index.db 
INFO  [main] 2023-02-21 18:06:17,567 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Filter.db 
INFO  [main] 2023-02-21 18:06:17,568 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Summary.db 
INFO  [main] 2023-02-21 18:06:17,568 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Data.db 
INFO  [main] 2023-02-21 18:06:24,899 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Digest.crc32 
INFO  [main] 2023-02-21 18:06:24,900 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:06:24,932 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-Statistics.db 
INFO  [main] 2023-02-21 18:06:24,933 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5301216-big-TOC.txt 
INFO  [main] 2023-02-21 18:06:24,933 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Filter.db 
INFO  [main] 2023-02-21 18:06:24,949 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Index.db 
INFO  [main] 2023-02-21 18:06:29,880 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Data.db 
INFO  [main] 2023-02-21 18:08:11,665 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Summary.db 
INFO  [main] 2023-02-21 18:08:11,666 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Digest.crc32 
INFO  [main] 2023-02-21 18:08:11,666 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:08:11,667 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-Statistics.db 
INFO  [main] 2023-02-21 18:08:11,667 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5450265-big-TOC.txt 
INFO  [main] 2023-02-21 18:08:11,667 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Index.db 
INFO  [main] 2023-02-21 18:08:11,717 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Filter.db 
INFO  [main] 2023-02-21 18:08:11,717 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Summary.db 
INFO  [main] 2023-02-21 18:08:11,718 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Data.db 
INFO  [main] 2023-02-21 18:08:22,177 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Digest.crc32 
INFO  [main] 2023-02-21 18:08:22,178 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:08:22,178 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-Statistics.db 
INFO  [main] 2023-02-21 18:08:22,178 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8741761-big-TOC.txt 
INFO  [main] 2023-02-21 18:08:22,178 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Filter.db 
INFO  [main] 2023-02-21 18:08:22,212 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Index.db 
INFO  [main] 2023-02-21 18:08:22,641 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Summary.db 
INFO  [main] 2023-02-21 18:08:22,642 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Data.db 
INFO  [main] 2023-02-21 18:09:16,035 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Digest.crc32 
INFO  [main] 2023-02-21 18:09:16,036 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:09:16,162 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-Statistics.db 
INFO  [main] 2023-02-21 18:09:16,162 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5496274-big-TOC.txt 
INFO  [main] 2023-02-21 18:09:16,163 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Index.db 
INFO  [main] 2023-02-21 18:09:16,302 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Filter.db 
INFO  [main] 2023-02-21 18:09:16,303 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Summary.db 
INFO  [main] 2023-02-21 18:09:16,303 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Data.db 
INFO  [main] 2023-02-21 18:09:30,352 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Digest.crc32 
INFO  [main] 2023-02-21 18:09:30,353 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:09:30,353 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-Statistics.db 
INFO  [main] 2023-02-21 18:09:30,354 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-6882038-big-TOC.txt 
INFO  [main] 2023-02-21 18:09:30,354 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Filter.db 
INFO  [main] 2023-02-21 18:09:30,377 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Index.db 
INFO  [main] 2023-02-21 18:09:32,789 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Summary.db 
INFO  [main] 2023-02-21 18:09:32,789 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Data.db 
INFO  [main] 2023-02-21 18:10:17,487 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Digest.crc32 
INFO  [main] 2023-02-21 18:10:17,692 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:10:17,741 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-Statistics.db 
INFO  [main] 2023-02-21 18:10:17,742 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5356040-big-TOC.txt 
INFO  [main] 2023-02-21 18:10:17,743 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Filter.db 
INFO  [main] 2023-02-21 18:10:17,743 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Index.db 
INFO  [main] 2023-02-21 18:10:17,758 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Summary.db 
INFO  [main] 2023-02-21 18:10:17,758 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Data.db 
INFO  [main] 2023-02-21 18:10:17,758 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Digest.crc32 
INFO  [main] 2023-02-21 18:10:17,758 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:10:17,759 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-Statistics.db 
INFO  [main] 2023-02-21 18:10:17,759 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821799-big-TOC.txt 
INFO  [main] 2023-02-21 18:10:17,760 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Index.db 
INFO  [main] 2023-02-21 18:10:18,081 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Filter.db 
INFO  [main] 2023-02-21 18:10:18,117 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Data.db 
INFO  [main] 2023-02-21 18:11:06,042 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Summary.db 
INFO  [main] 2023-02-21 18:11:06,043 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Digest.crc32 
INFO  [main] 2023-02-21 18:11:06,043 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:11:06,079 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-Statistics.db 
INFO  [main] 2023-02-21 18:11:06,079 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6087561-big-TOC.txt 
INFO  [main] 2023-02-21 18:11:06,080 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Index.db 
INFO  [main] 2023-02-21 18:11:06,159 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Filter.db 
INFO  [main] 2023-02-21 18:11:06,159 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Data.db 
INFO  [main] 2023-02-21 18:11:16,709 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Summary.db 
INFO  [main] 2023-02-21 18:11:16,711 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Digest.crc32 
INFO  [main] 2023-02-21 18:11:16,711 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:11:16,711 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-Statistics.db 
INFO  [main] 2023-02-21 18:11:16,902 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8790094-big-TOC.txt 
INFO  [main] 2023-02-21 18:11:16,903 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Index.db 
INFO  [main] 2023-02-21 18:11:17,170 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Filter.db 
INFO  [main] 2023-02-21 18:11:17,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Summary.db 
INFO  [main] 2023-02-21 18:11:17,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Data.db 
INFO  [main] 2023-02-21 18:11:59,054 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Digest.crc32 
INFO  [main] 2023-02-21 18:11:59,055 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:11:59,076 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-Statistics.db 
INFO  [main] 2023-02-21 18:11:59,076 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5504090-big-TOC.txt 
INFO  [main] 2023-02-21 18:11:59,076 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Index.db 
INFO  [main] 2023-02-21 18:11:59,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Filter.db 
INFO  [main] 2023-02-21 18:11:59,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Summary.db 
INFO  [main] 2023-02-21 18:11:59,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Data.db 
INFO  [main] 2023-02-21 18:12:28,397 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Digest.crc32 
INFO  [main] 2023-02-21 18:12:28,397 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:12:28,398 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-Statistics.db 
INFO  [main] 2023-02-21 18:12:28,398 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8132762-big-TOC.txt 
INFO  [main] 2023-02-21 18:12:28,398 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Index.db 
INFO  [main] 2023-02-21 18:12:28,400 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Filter.db 
INFO  [main] 2023-02-21 18:12:28,400 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Data.db 
INFO  [main] 2023-02-21 18:12:42,749 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Summary.db 
INFO  [main] 2023-02-21 18:12:42,750 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Digest.crc32 
INFO  [main] 2023-02-21 18:12:42,750 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:12:42,774 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-Statistics.db 
INFO  [main] 2023-02-21 18:12:42,774 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6383747-big-TOC.txt 
INFO  [main] 2023-02-21 18:12:42,775 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Filter.db 
INFO  [main] 2023-02-21 18:12:42,775 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Index.db 
INFO  [main] 2023-02-21 18:12:42,820 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Summary.db 
INFO  [main] 2023-02-21 18:12:42,821 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Data.db 
INFO  [main] 2023-02-21 18:12:55,614 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Digest.crc32 
INFO  [main] 2023-02-21 18:12:55,618 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:12:55,630 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-Statistics.db 
INFO  [main] 2023-02-21 18:12:55,630 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5649641-big-TOC.txt 
INFO  [main] 2023-02-21 18:12:55,630 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Filter.db 
INFO  [main] 2023-02-21 18:12:55,711 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Index.db 
INFO  [main] 2023-02-21 18:12:57,535 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Data.db 
INFO  [main] 2023-02-21 18:15:07,614 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Summary.db 
INFO  [main] 2023-02-21 18:15:07,615 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Digest.crc32 
INFO  [main] 2023-02-21 18:15:07,615 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:15:07,640 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-Statistics.db 
INFO  [main] 2023-02-21 18:15:07,640 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5530049-big-TOC.txt 
INFO  [main] 2023-02-21 18:15:07,641 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Index.db 
INFO  [main] 2023-02-21 18:15:07,909 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Filter.db 
INFO  [main] 2023-02-21 18:15:07,950 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Data.db 
INFO  [main] 2023-02-21 18:15:58,262 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Summary.db 
INFO  [main] 2023-02-21 18:15:58,263 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Digest.crc32 
INFO  [main] 2023-02-21 18:15:58,263 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:15:58,325 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-Statistics.db 
INFO  [main] 2023-02-21 18:15:58,325 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8694773-big-TOC.txt 
INFO  [main] 2023-02-21 18:15:58,326 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Index.db 
INFO  [main] 2023-02-21 18:15:58,326 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Filter.db 
INFO  [main] 2023-02-21 18:15:58,326 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Summary.db 
INFO  [main] 2023-02-21 18:15:58,327 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Data.db 
INFO  [main] 2023-02-21 18:15:58,535 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Digest.crc32 
INFO  [main] 2023-02-21 18:15:58,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:15:58,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-Statistics.db 
INFO  [main] 2023-02-21 18:15:58,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8828410-big-TOC.txt 
INFO  [main] 2023-02-21 18:15:58,536 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Index.db 
INFO  [main] 2023-02-21 18:15:58,550 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Filter.db 
INFO  [main] 2023-02-21 18:15:58,551 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Summary.db 
INFO  [main] 2023-02-21 18:15:58,551 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Data.db 
INFO  [main] 2023-02-21 18:15:58,856 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Digest.crc32 
INFO  [main] 2023-02-21 18:15:58,857 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:15:58,858 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-Statistics.db 
INFO  [main] 2023-02-21 18:15:58,858 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8827236-big-TOC.txt 
INFO  [main] 2023-02-21 18:15:58,858 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Index.db 
INFO  [main] 2023-02-21 18:15:58,860 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Filter.db 
INFO  [main] 2023-02-21 18:15:58,860 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Data.db 
INFO  [main] 2023-02-21 18:16:19,652 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Summary.db 
INFO  [main] 2023-02-21 18:16:19,653 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Digest.crc32 
INFO  [main] 2023-02-21 18:16:19,654 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:16:19,664 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-Statistics.db 
INFO  [main] 2023-02-21 18:16:19,664 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5499870-big-TOC.txt 
INFO  [main] 2023-02-21 18:16:19,665 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:16:19,772 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-Data.db 
INFO  [main] 2023-02-21 18:17:13,519 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-Filter.db 
INFO  [main] 2023-02-21 18:17:13,519 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-Index.db 
INFO  [main] 2023-02-21 18:17:13,537 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-Statistics.db 
INFO  [main] 2023-02-21 18:17:13,538 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5221771-big-Summary.db 
INFO  [main] 2023-02-21 18:17:13,538 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Index.db 
INFO  [main] 2023-02-21 18:17:13,549 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Filter.db 
INFO  [main] 2023-02-21 18:17:13,549 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Data.db 
INFO  [main] 2023-02-21 18:17:14,232 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Summary.db 
INFO  [main] 2023-02-21 18:17:14,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Digest.crc32 
INFO  [main] 2023-02-21 18:17:14,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:17:14,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-Statistics.db 
INFO  [main] 2023-02-21 18:17:14,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8807317-big-TOC.txt 
INFO  [main] 2023-02-21 18:17:14,233 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Index.db 
INFO  [main] 2023-02-21 18:17:14,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Filter.db 
INFO  [main] 2023-02-21 18:17:14,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Summary.db 
INFO  [main] 2023-02-21 18:17:14,236 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Data.db 
INFO  [main] 2023-02-21 18:17:14,339 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Digest.crc32 
INFO  [main] 2023-02-21 18:17:14,339 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:17:14,339 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-Statistics.db 
INFO  [main] 2023-02-21 18:17:14,340 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830077-big-TOC.txt 
INFO  [main] 2023-02-21 18:17:14,340 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Index.db 
INFO  [main] 2023-02-21 18:17:14,354 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Filter.db 
INFO  [main] 2023-02-21 18:17:14,354 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Data.db 
INFO  [main] 2023-02-21 18:17:17,432 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Summary.db 
INFO  [main] 2023-02-21 18:17:17,433 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Digest.crc32 
INFO  [main] 2023-02-21 18:17:17,433 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:17:17,449 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-Statistics.db 
INFO  [main] 2023-02-21 18:17:17,450 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8816850-big-TOC.txt 
INFO  [main] 2023-02-21 18:17:17,450 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Index.db 
INFO  [main] 2023-02-21 18:17:17,969 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Filter.db 
INFO  [main] 2023-02-21 18:17:17,970 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Summary.db 
INFO  [main] 2023-02-21 18:17:17,970 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Data.db 
INFO  [main] 2023-02-21 18:18:43,709 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Digest.crc32 
INFO  [main] 2023-02-21 18:18:43,710 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:18:43,710 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-Statistics.db 
INFO  [main] 2023-02-21 18:18:43,710 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5790369-big-TOC.txt 
INFO  [main] 2023-02-21 18:18:43,711 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Index.db 
INFO  [main] 2023-02-21 18:18:43,739 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Filter.db 
INFO  [main] 2023-02-21 18:18:43,739 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Summary.db 
INFO  [main] 2023-02-21 18:18:43,739 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Data.db 
INFO  [main] 2023-02-21 18:18:43,885 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Digest.crc32 
INFO  [main] 2023-02-21 18:18:43,885 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:18:43,885 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-Statistics.db 
INFO  [main] 2023-02-21 18:18:43,886 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8829549-big-TOC.txt 
INFO  [main] 2023-02-21 18:18:43,886 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Index.db 
INFO  [main] 2023-02-21 18:18:44,106 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Filter.db 
INFO  [main] 2023-02-21 18:18:44,106 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Data.db 
INFO  [main] 2023-02-21 18:18:47,122 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Summary.db 
INFO  [main] 2023-02-21 18:18:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Digest.crc32 
INFO  [main] 2023-02-21 18:18:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:18:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-Statistics.db 
INFO  [main] 2023-02-21 18:18:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821888-big-TOC.txt 
INFO  [main] 2023-02-21 18:18:47,123 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Index.db 
INFO  [main] 2023-02-21 18:18:47,199 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Filter.db 
INFO  [main] 2023-02-21 18:18:47,199 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Summary.db 
INFO  [main] 2023-02-21 18:18:47,199 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Data.db 
INFO  [main] 2023-02-21 18:18:49,411 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Digest.crc32 
INFO  [main] 2023-02-21 18:18:49,412 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:18:49,412 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-Statistics.db 
INFO  [main] 2023-02-21 18:18:49,412 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-6861414-big-TOC.txt 
INFO  [main] 2023-02-21 18:18:49,413 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Index.db 
INFO  [main] 2023-02-21 18:18:49,414 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Filter.db 
INFO  [main] 2023-02-21 18:18:49,414 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Data.db 
INFO  [main] 2023-02-21 18:18:49,634 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Summary.db 
INFO  [main] 2023-02-21 18:18:49,635 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Digest.crc32 
INFO  [main] 2023-02-21 18:18:49,635 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:18:49,635 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-Statistics.db 
INFO  [main] 2023-02-21 18:18:49,635 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8820208-big-TOC.txt 
INFO  [main] 2023-02-21 18:18:49,636 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Index.db 
INFO  [main] 2023-02-21 18:18:49,699 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Filter.db 
INFO  [main] 2023-02-21 18:18:49,699 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Summary.db 
INFO  [main] 2023-02-21 18:18:49,699 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Data.db 
INFO  [main] 2023-02-21 18:19:17,136 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Digest.crc32 
INFO  [main] 2023-02-21 18:19:17,137 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:19:17,253 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-Statistics.db 
INFO  [main] 2023-02-21 18:19:17,253 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8413340-big-TOC.txt 
INFO  [main] 2023-02-21 18:19:17,253 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Index.db 
INFO  [main] 2023-02-21 18:19:17,310 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Filter.db 
INFO  [main] 2023-02-21 18:19:17,310 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Data.db 
INFO  [main] 2023-02-21 18:19:36,881 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Summary.db 
INFO  [main] 2023-02-21 18:19:36,882 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Digest.crc32 
INFO  [main] 2023-02-21 18:19:36,882 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:19:36,883 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-Statistics.db 
INFO  [main] 2023-02-21 18:19:36,883 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7039803-big-TOC.txt 
INFO  [main] 2023-02-21 18:19:36,883 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Filter.db 
INFO  [main] 2023-02-21 18:19:36,884 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Index.db 
INFO  [main] 2023-02-21 18:19:36,917 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Summary.db 
INFO  [main] 2023-02-21 18:19:36,917 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Data.db 
INFO  [main] 2023-02-21 18:19:45,481 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Digest.crc32 
INFO  [main] 2023-02-21 18:19:45,482 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:19:45,483 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-Statistics.db 
INFO  [main] 2023-02-21 18:19:45,483 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5428383-big-TOC.txt 
INFO  [main] 2023-02-21 18:19:45,483 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Filter.db 
INFO  [main] 2023-02-21 18:19:45,570 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Index.db 
INFO  [main] 2023-02-21 18:19:45,639 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Summary.db 
INFO  [main] 2023-02-21 18:19:45,640 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Data.db 
INFO  [main] 2023-02-21 18:20:48,586 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Digest.crc32 
INFO  [main] 2023-02-21 18:20:48,587 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:20:48,618 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-Statistics.db 
INFO  [main] 2023-02-21 18:20:48,618 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5580716-big-TOC.txt 
INFO  [main] 2023-02-21 18:20:48,619 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Index.db 
INFO  [main] 2023-02-21 18:20:48,666 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Filter.db 
INFO  [main] 2023-02-21 18:20:48,666 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Summary.db 
INFO  [main] 2023-02-21 18:20:48,666 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Data.db 
INFO  [main] 2023-02-21 18:20:51,050 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Digest.crc32 
INFO  [main] 2023-02-21 18:20:51,051 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:20:51,051 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-Statistics.db 
INFO  [main] 2023-02-21 18:20:51,051 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8781750-big-TOC.txt 
INFO  [main] 2023-02-21 18:20:51,052 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Filter.db 
INFO  [main] 2023-02-21 18:20:51,061 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Index.db 
INFO  [main] 2023-02-21 18:20:51,121 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Summary.db 
INFO  [main] 2023-02-21 18:20:51,121 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Data.db 
INFO  [main] 2023-02-21 18:21:19,118 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Digest.crc32 
INFO  [main] 2023-02-21 18:21:19,118 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:21:19,140 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-Statistics.db 
INFO  [main] 2023-02-21 18:21:19,140 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5400271-big-TOC.txt 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Filter.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Index.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Summary.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Data.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Digest.crc32 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-Statistics.db 
INFO  [main] 2023-02-21 18:21:19,141 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821263-big-TOC.txt 
INFO  [main] 2023-02-21 18:21:19,142 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Index.db 
INFO  [main] 2023-02-21 18:21:19,160 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Filter.db 
INFO  [main] 2023-02-21 18:21:19,160 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Data.db 
INFO  [main] 2023-02-21 18:21:22,503 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Summary.db 
INFO  [main] 2023-02-21 18:21:22,504 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Digest.crc32 
INFO  [main] 2023-02-21 18:21:22,505 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:21:22,505 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-Statistics.db 
INFO  [main] 2023-02-21 18:21:22,505 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8744460-big-TOC.txt 
INFO  [main] 2023-02-21 18:21:22,505 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Filter.db 
INFO  [main] 2023-02-21 18:21:22,505 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Index.db 
INFO  [main] 2023-02-21 18:21:22,660 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Data.db 
INFO  [main] 2023-02-21 18:22:11,241 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Summary.db 
INFO  [main] 2023-02-21 18:22:11,242 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:11,242 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:11,244 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:11,244 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-5334445-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:11,244 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Index.db 
INFO  [main] 2023-02-21 18:22:11,328 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Filter.db 
INFO  [main] 2023-02-21 18:22:11,335 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Summary.db 
INFO  [main] 2023-02-21 18:22:11,335 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Data.db 
INFO  [main] 2023-02-21 18:22:42,109 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:42,109 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:42,109 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:42,110 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/mc-217343-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:42,110 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Index.db 
INFO  [main] 2023-02-21 18:22:42,481 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Filter.db 
INFO  [main] 2023-02-21 18:22:42,481 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Summary.db 
INFO  [main] 2023-02-21 18:22:42,481 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Data.db 
INFO  [main] 2023-02-21 18:22:50,519 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:50,520 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:50,539 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:50,539 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-7588148-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:50,540 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Index.db 
INFO  [main] 2023-02-21 18:22:50,570 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Filter.db 
INFO  [main] 2023-02-21 18:22:50,570 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Data.db 
INFO  [main] 2023-02-21 18:22:50,729 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Summary.db 
INFO  [main] 2023-02-21 18:22:50,729 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:50,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:50,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:50,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821882-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:50,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Index.db 
INFO  [main] 2023-02-21 18:22:50,736 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Filter.db 
INFO  [main] 2023-02-21 18:22:50,736 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Summary.db 
INFO  [main] 2023-02-21 18:22:50,736 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Data.db 
INFO  [main] 2023-02-21 18:22:51,729 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:51,729 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:51,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:51,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8821885-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:51,730 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Index.db 
INFO  [main] 2023-02-21 18:22:51,758 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Filter.db 
INFO  [main] 2023-02-21 18:22:51,759 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Summary.db 
INFO  [main] 2023-02-21 18:22:51,759 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Data.db 
INFO  [main] 2023-02-21 18:22:54,456 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Digest.crc32 
INFO  [main] 2023-02-21 18:22:54,457 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-CompressionInfo.db 
INFO  [main] 2023-02-21 18:22:54,457 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-Statistics.db 
INFO  [main] 2023-02-21 18:22:54,457 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8716073-big-TOC.txt 
INFO  [main] 2023-02-21 18:22:54,646 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_unknowncompactiontype_695c4f33-b1ce-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:22:54,648 LogTransaction.java:536 - Verifying logfile transaction [nb_txn_compaction_60e393e0-b1ce-11ed-a081-5d5a5c990823.log in /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b]
INFO  [main] 2023-02-21 18:22:54,650 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830665-big-Index.db 
INFO  [main] 2023-02-21 18:22:54,656 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830665-big-Data.db 
INFO  [main] 2023-02-21 18:22:54,673 LogTransaction.java:240 - Unfinished transaction log, deleting /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb_txn_compaction_60e393e0-b1ce-11ed-a081-5d5a5c990823.log 
INFO  [main] 2023-02-21 18:22:54,694 Keyspace.java:386 - Creating replication strategy kairosdb params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}
INFO  [main] 2023-02-21 18:22:54,715 ColumnFamilyStore.java:385 - Initializing kairosdb.data_points
INFO  [SSTableBatchOpen:2] 2023-02-21 18:22:54,720 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830647-big (179.084MiB)
INFO  [SSTableBatchOpen:5] 2023-02-21 18:22:54,721 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830662-big (4.039MiB)
INFO  [SSTableBatchOpen:7] 2023-02-21 18:22:54,721 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830663-big (3.589MiB)
INFO  [SSTableBatchOpen:6] 2023-02-21 18:22:54,721 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830661-big (39.789MiB)
INFO  [SSTableBatchOpen:8] 2023-02-21 18:22:54,721 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830664-big (6.007MiB)
INFO  [SSTableBatchOpen:3] 2023-02-21 18:22:54,739 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830583-big (190.543MiB)
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:54,739 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830440-big (191.089MiB)
INFO  [SSTableBatchOpen:4] 2023-02-21 18:22:54,747 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/data_points-870fab7087ba11eb8b50d3c6960df21b/nb-8830513-big (194.560MiB)
INFO  [main] 2023-02-21 18:22:54,947 ColumnFamilyStore.java:385 - Initializing kairosdb.row_key_index
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:54,977 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_key_index-8742543087ba11eba3799bdca9e7ad04/mc-1-big (7.580MiB)
INFO  [main] 2023-02-21 18:22:55,023 ColumnFamilyStore.java:385 - Initializing kairosdb.row_key_time_index
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:55,054 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_key_time_index-87a4234087ba11eba3799bdca9e7ad04/nb-26770-big (0.075KiB)
INFO  [SSTableBatchOpen:3] 2023-02-21 18:22:55,070 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_key_time_index-87a4234087ba11eba3799bdca9e7ad04/nb-26769-big (0.052KiB)
INFO  [SSTableBatchOpen:2] 2023-02-21 18:22:55,077 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_key_time_index-87a4234087ba11eba3799bdca9e7ad04/nb-26768-big (2.671MiB)
INFO  [main] 2023-02-21 18:22:55,131 ColumnFamilyStore.java:385 - Initializing kairosdb.row_keys
INFO  [SSTableBatchOpen:5] 2023-02-21 18:22:55,135 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_keys-8793f6a087ba11eb8b50d3c6960df21b/nb-796510-big (7.682MiB)
INFO  [SSTableBatchOpen:4] 2023-02-21 18:22:55,190 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_keys-8793f6a087ba11eb8b50d3c6960df21b/nb-769597-big (50.002MiB)
INFO  [SSTableBatchOpen:2] 2023-02-21 18:22:55,203 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_keys-8793f6a087ba11eb8b50d3c6960df21b/mc-75-big (87.496MiB)
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:55,209 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_keys-8793f6a087ba11eb8b50d3c6960df21b/mc-256221-big (51.492MiB)
INFO  [SSTableBatchOpen:3] 2023-02-21 18:22:55,211 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/kairosdb/row_keys-8793f6a087ba11eb8b50d3c6960df21b/nb-550752-big (50.323MiB)
INFO  [main] 2023-02-21 18:22:55,357 ColumnFamilyStore.java:385 - Initializing kairosdb.service_index
INFO  [main] 2023-02-21 18:22:55,381 ColumnFamilyStore.java:385 - Initializing kairosdb.spec
INFO  [main] 2023-02-21 18:22:55,393 ColumnFamilyStore.java:385 - Initializing kairosdb.string_index
INFO  [main] 2023-02-21 18:22:55,409 ColumnFamilyStore.java:385 - Initializing kairosdb.tag_indexed_row_keys
INFO  [main] 2023-02-21 18:22:55,419 Keyspace.java:386 - Creating replication strategy system_auth params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}
INFO  [main] 2023-02-21 18:22:55,425 ColumnFamilyStore.java:385 - Initializing system_auth.network_permissions
INFO  [main] 2023-02-21 18:22:55,440 ColumnFamilyStore.java:385 - Initializing system_auth.resource_role_permissons_index
INFO  [main] 2023-02-21 18:22:55,457 ColumnFamilyStore.java:385 - Initializing system_auth.role_members
INFO  [main] 2023-02-21 18:22:55,473 ColumnFamilyStore.java:385 - Initializing system_auth.role_permissions
INFO  [main] 2023-02-21 18:22:55,485 ColumnFamilyStore.java:385 - Initializing system_auth.roles
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:55,518 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_auth/roles-5bc52802de2535edaeab188eecebb090/mc-1-big (0.100KiB)
INFO  [main] 2023-02-21 18:22:55,543 Keyspace.java:386 - Creating replication strategy system_distributed params KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}
INFO  [main] 2023-02-21 18:22:55,558 ColumnFamilyStore.java:385 - Initializing system_distributed.parent_repair_history
INFO  [SSTableBatchOpen:2] 2023-02-21 18:22:55,577 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-49-big (1.398KiB)
INFO  [SSTableBatchOpen:24] 2023-02-21 18:22:55,585 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-44-big (1.376KiB)
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:55,591 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-24-big (0.863KiB)
INFO  [SSTableBatchOpen:3] 2023-02-21 18:22:55,593 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-5-big (0.644KiB)
INFO  [SSTableBatchOpen:8] 2023-02-21 18:22:55,594 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-12-big (1.130KiB)
INFO  [SSTableBatchOpen:9] 2023-02-21 18:22:55,595 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-16-big (0.990KiB)
INFO  [SSTableBatchOpen:18] 2023-02-21 18:22:55,598 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-39-big (1.646KiB)
INFO  [SSTableBatchOpen:14] 2023-02-21 18:22:55,598 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-57-big (2.019KiB)
INFO  [SSTableBatchOpen:4] 2023-02-21 18:22:55,605 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-68-big (0.920KiB)
INFO  [SSTableBatchOpen:16] 2023-02-21 18:22:55,606 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-107-big (0.728KiB)
INFO  [SSTableBatchOpen:23] 2023-02-21 18:22:55,607 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-43-big (0.592KiB)
INFO  [SSTableBatchOpen:15] 2023-02-21 18:22:55,608 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-31-big (1.451KiB)
INFO  [SSTableBatchOpen:11] 2023-02-21 18:22:55,611 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-80-big (0.944KiB)
INFO  [SSTableBatchOpen:20] 2023-02-21 18:22:55,611 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-106-big (0.589KiB)
INFO  [SSTableBatchOpen:5] 2023-02-21 18:22:55,622 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-88-big (0.935KiB)
INFO  [SSTableBatchOpen:6] 2023-02-21 18:22:55,623 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-20-big (1.151KiB)
INFO  [SSTableBatchOpen:10] 2023-02-21 18:22:55,623 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-76-big (1.481KiB)
INFO  [SSTableBatchOpen:12] 2023-02-21 18:22:55,624 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/mc-1-big (16.284KiB)
INFO  [SSTableBatchOpen:17] 2023-02-21 18:22:55,626 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-95-big (3.737KiB)
INFO  [SSTableBatchOpen:13] 2023-02-21 18:22:55,626 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-84-big (1.031KiB)
INFO  [SSTableBatchOpen:7] 2023-02-21 18:22:55,633 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-64-big (1.132KiB)
INFO  [SSTableBatchOpen:19] 2023-02-21 18:22:55,636 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-100-big (0.561KiB)
INFO  [SSTableBatchOpen:21] 2023-02-21 18:22:55,656 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-99-big (1.159KiB)
INFO  [SSTableBatchOpen:22] 2023-02-21 18:22:55,683 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/parent_repair_history-deabd734b99d3b9c92e5fd92eb5abf14/nb-104-big (0.720KiB)
INFO  [main] 2023-02-21 18:22:55,733 ColumnFamilyStore.java:385 - Initializing system_distributed.repair_history
INFO  [SSTableBatchOpen:14] 2023-02-21 18:22:55,747 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-45-big (2.741KiB)
INFO  [SSTableBatchOpen:2] 2023-02-21 18:22:55,747 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-25-big (1.789KiB)
INFO  [SSTableBatchOpen:7] 2023-02-21 18:22:55,747 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-89-big (1.814KiB)
INFO  [SSTableBatchOpen:3] 2023-02-21 18:22:55,747 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-112-big (1.327KiB)
INFO  [SSTableBatchOpen:19] 2023-02-21 18:22:55,749 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-32-big (3.927KiB)
INFO  [SSTableBatchOpen:4] 2023-02-21 18:22:55,756 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-67-big (3.370KiB)
INFO  [SSTableBatchOpen:18] 2023-02-21 18:22:55,757 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-81-big (3.249KiB)
INFO  [SSTableBatchOpen:10] 2023-02-21 18:22:55,758 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-110-big (1.354KiB)
INFO  [SSTableBatchOpen:11] 2023-02-21 18:22:55,761 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-44-big (1.250KiB)
INFO  [SSTableBatchOpen:12] 2023-02-21 18:22:55,761 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-50-big (3.340KiB)
INFO  [SSTableBatchOpen:6] 2023-02-21 18:22:55,765 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-93-big (2.319KiB)
INFO  [SSTableBatchOpen:21] 2023-02-21 18:22:55,765 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-85-big (1.789KiB)
INFO  [SSTableBatchOpen:1] 2023-02-21 18:22:55,770 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-113-big (1.334KiB)
INFO  [SSTableBatchOpen:15] 2023-02-21 18:22:55,773 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-101-big (3.239KiB)
INFO  [SSTableBatchOpen:22] 2023-02-21 18:22:55,774 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-21-big (2.331KiB)
INFO  [SSTableBatchOpen:8] 2023-02-21 18:22:55,785 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-40-big (4.339KiB)
INFO  [SSTableBatchOpen:23] 2023-02-21 18:22:55,789 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-17-big (2.308KiB)
INFO  [SSTableBatchOpen:13] 2023-02-21 18:22:55,794 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-106-big (0.766KiB)
INFO  [SSTableBatchOpen:16] 2023-02-21 18:22:55,797 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-13-big (2.822KiB)
INFO  [SSTableBatchOpen:9] 2023-02-21 18:22:55,802 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-105-big (2.460KiB)
INFO  [SSTableBatchOpen:5] 2023-02-21 18:22:55,802 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-6-big (1.802KiB)
INFO  [SSTableBatchOpen:24] 2023-02-21 18:22:55,805 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-74-big (2.896KiB)
INFO  [SSTableBatchOpen:17] 2023-02-21 18:22:55,808 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/mc-1-big (0.812KiB)
INFO  [SSTableBatchOpen:20] 2023-02-21 18:22:55,811 SSTableReaderBuilder.java:351 - Opening /historyData/cassandra/data/system_distributed/repair_history-759fffad624b318180eefa9a52d1f627/nb-59-big (5.973KiB) {code}
3.Bugs can be reproduced.Just set  vm.max_ map_ count as a small value, and then trigger OOM, and restart the node."
CASSANDRA-18157,Test Failure: TestUpgrade_current_2_1_x_To_indev_3_11_x.test_bootstrap_multidc (upgrade),"Flaky.

{noformat}
Unexpected error found in node logs (see stdout for full details). Errors: [[node4] ""WARN  [MessagingService-Incoming-/127.0.0.1] 2022-12-20 14:00:30,243 IncomingTcpConnection.java:107 - UnknownColumnFamilyException reading from socket; closing
org.apache.cassandra.db.UnknownColumnFamilyException: Couldn't find table for cfId 5bc52802-de25-35ed-aeab-188eecebb090. If a table was just created, this is likely due to the schema not being fully propagated.  Please wait for schema agreement on table creation.
\tat org.apache.cassandra.config.CFMetaData$Serializer.deserialize(CFMetaData.java:1594)
\tat org.apache.cassandra.db.ReadCommand$Serializer.deserialize(ReadCommand.java:765)
\tat org.apache.cassandra.db.ReadCommand$Serializer.deserialize(ReadCommand.java:704)
\tat org.apache.cassandra.io.ForwardingVersionedSerializer.deserialize(ForwardingVersionedSerializer.java:50)
\tat org.apache.cassandra.net.MessageIn.read(MessageIn.java:123)
\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:207)
\tat org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:195)
\tat org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:98)""]
{noformat}"
CASSANDRA-18153,"Memtable being flushed without hostId in version ""me"" and newer during CommitLogReplay","On ticket CASSANDRA-16619 some files were changed to allow Cassandra to store HostID in the new ""me"" SSTable version.

But SSTables flushed during CommitLogReplay miss this HostID info.

 

In the next Cassandra startup, if these SSTables were still present, system.log will show:


{{WARN Origin of 3 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored}}

{{WARN }}{{{}Origin of 3 sstables is unknown or doesn't match the local node; commitLogIntervals for them were ignored{}}}{{{}{}}}{{ }}

 

And debug.log will show a list of SSTables, witch can include ""md"" and ""me"" version (before upgradesstables):

 

{{Ignored commitLogIntervals from the following sstables: [/var/lib/cassandra/data/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca/me-3-big-Data.db, /var/lib/cassandra/data/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca/md-1-big-Data.db, /var/lib/cassandra/data/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca/md-2-big-Data.db]}}

 

https://issues.apache.org/jira/browse/CASSANDRA-16619"
CASSANDRA-18118,Do not leak 2015 memtable synthetic Epoch,"This [Epoch|https://github.com/apache/cassandra/blob/cassandra-3.11/src/java/org/apache/cassandra/db/rows/EncodingStats.java#L48] can [leak|https://github.com/apache/cassandra/blob/cassandra-3.11/src/java/org/apache/cassandra/db/Memtable.java#L392] affecting all the timestamps logic.  It has been observed in a production env it can i.e. prevent proper sstable and tombstone cleanup.

To reproduce create the following table:
{noformat}
drop keyspace test;
create keyspace test WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1};
CREATE TABLE test.test (
    key text PRIMARY KEY,
    id text
) WITH bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '2', 'tombstone_compaction_interval': '3000', 'tombstone_threshold': '0.1', 'unchecked_tombstone_compaction': 'true'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.0
    AND default_time_to_live = 10
    AND gc_grace_seconds = 10
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';

CREATE INDEX id_idx ON test.test (id);
{noformat}

And stress load it with:
{noformat}
insert into test.test (key,id) values('$RANDOM_UUID $RANDOM_UUID', 'eaca36a1-45f1-469c-a3f6-3ba54220363f') USING TTL 10
{noformat}

Notice how all inserts have a 10s TTL, the default 10s TTL and gc_grace is also at 10s. This is to speed up the repro:
- Run the load for a couple minutes and track sstables disk usage. You will see it does only increase, nothing gets cleaned up and it doesn't stop growing (notice all this is well past the 10s gc_grace and TTL)
- Running a flush and a compaction while under load against the keyspace, table or index doesn't solve the issue.
- Stopping the load and running a compaction doesn't solve the issue. Flushing does though.
- On the original observation where TTL was around 600s and gc_grace around 1800s we could get GBs of sstables that weren't cleaned up or compacted away after hours of work.
- Reproduction can also happen on plain sstables by repeatedly inserting/deleting/overwriting the same values over and over again without 2i indices or TTL being involved.

The problem seems to be [EncodingStats|https://github.com/apache/cassandra/blob/cassandra-3.11/src/java/org/apache/cassandra/db/rows/EncodingStats.java#L48] using a synthetic Epoch in 2015 which plays nice with Vint serialization.  Unfortunately {{Memtable}} is using that to keep track of the {{minTimestamp}} which can leak the 2015 Epoch. This confuses any logic consuming that timestamp. In this particular case purge and fully expired sstables weren't properly detected.
"
CASSANDRA-18105,TRUNCATED data come back after a restart or upgrade,"When we use the TRUNCATE command to delete all data in the table, the deleted data come back after a node restart or upgrade. This problem happens at the latest releases (2.2.19, 3.0.28, or 4.0.7)
h1. Steps to reproduce
h2. To reproduce it at release (3.0.28 or 4.0.7)

Start up a single Cassandra node. Using the default configuration and execute the following cqlsh commands.
{code:java}
CREATE KEYSPACE IF NOT EXISTS ks WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 };
CREATE TABLE  ks.tb (c3 TEXT,c4 TEXT,c2 INT,c1 TEXT, PRIMARY KEY (c1, c2, c3 ));
INSERT INTO ks.tb (c3, c1, c2) VALUES ('val1','val2',1);
CREATE INDEX IF NOT EXISTS tb ON ks.tb ( c3);
TRUNCATE TABLE ks.tb;
DROP INDEX IF EXISTS ks.tb; {code}
Execute a read command
{code:java}
cqlsh> SELECT c2 FROM ks.tb; 

 c2
----

(0 rows) {code}
Then, we flush the node and kill the Cassandra daemon by
{code:java}
bin/nodetool flush
pgrep -f cassandra | xargs kill -9 {code}
We restart the node. When the node has started, perform the same read, and the deleted data comes back again.
{code:java}
cqlsh> SELECT c2 FROM ks.tb; 

 c2
----
  1

(1 rows) {code}
h2. To reproduce it at release (2.2.19)

We don't need to kill the Cassandra daemon. Use bin/nodetool stopdaemon is enough. The other steps are the same as reproducing it at 4.0.7 or 3.0.28.
{code:java}
bin/nodetool -h ::FFFF:127.0.0.1 flush 
bin/nodetool -h ::FFFF:127.0.0.1 stopdaemon{code}
 

I have put the full log to reproduce it for release 4.0.7 and 2.2.19 in the comments."
CASSANDRA-18096,Do not spam the logs with MigrationCoordinator not able to pull schemas,"When a node is joining a cluster, there is this output upon startup:

{code}
cassandra_node_6  | INFO  [GossipStage:1] 2022-12-06 12:48:07,187 Gossiper.java:1413 - Node /172.19.0.5:7000 is now part of the cluster
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
cassandra_node_6  | WARN MigrationCoordinator.java:650 - Can't send schema pull request: node /172.19.0.5:7000 is down.
{code}

This is there for a lot of already existing nodes. You got the idea. This log is misleading, it indeed can not pull requests because ""node is down"" but it is not down, it just thinks it is because Gossiper has not had a chance to receive any gossip about these nodes _yet_.

I put there more logs and it writes this:

{code}
 MigrationCoordinator.java:655 - Can't send schema pull request: node /172.19.0.5:7000 is down: NORMAL, isAlive: false
{code}

When I do this:

{code}
        if (!gossiper.hasEndpointState(endpoint))
            return;

        if (!gossiper.isAlive(endpoint))
        {
            EndpointState endpointStateForEndpoint = gossiper.getEndpointStateForEndpoint(endpoint);
            String status = Gossiper.getGossipStatus(endpointStateForEndpoint);
            logger.warn(""Can't send schema pull request: node {} is down: {}, isAlive: {}"", endpoint, status, endpointStateForEndpoint.isAlive());
            callback.onFailure(endpoint, RequestFailureReason.UNKNOWN);
            return;
        }
{code}

So it is in NORMAL but it is not alive yet which is quite strange.

The fix is to still return prematurely but we would not skip the logging on WARN only in case isAlive is false and status is _not_NORMAL. We would however still log on TRACE at least.

(1) https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/schema/MigrationCoordinator.java#L648-L653"
CASSANDRA-17921,Harden JMX by resolving beanshooter issues,"Fix JMX security vulnerabilities

As reported by Murray McAllister, there are multiple JMX vulnerabilities
in the default Cassandra configuration on 3.0, 3.11, 4.0 and trunk,
across Java 8 and Java 11. These are limited to authenticated JMX users
only.

Vulnerabilities:
1. (Java 8 and 11) Remote Java Library loading and execution via MLet
2. (Java 11 only) Remote Java file reads via DiagnosticCommandMBean's
   compilerDirectivesAdd implementation leaking arbitrary file contents
3. (Java 11 only) Remote .so library loading via JVMTI

qtc-de/beanshooter is a JMX enumeration tool that uses these mechanisms
and others:
https://github.com/qtc-de/beanshooter/blob/2ec4f7a4b44a29f52315973fe944eb34bc772063/beanshooter/src/de/qtc/beanshooter/mbean/diagnostic/Dispatcher.java#L48

Remote file reads via compilerDirectiveAdd does not appear to be
reproducible on Java 8 (cassandra-{3.0,3.11}, Java 1.8.0_345-b01 from
Adoptium / Temurin). Using qtc-de/beanshooter and cassandra-3.0
(a78db628):
{code}
$ java -jar target/beanshooter-3.0.0-jar-with-dependencies.jar diagnostic read --verbose 127.0.0.1 7199 /tmp/hello
[-] A method with signature compilerDirectivesAdd([Ljava.lang.String;) does not exist on the endpoint.
[-] If you invoked a deployed MBean, make sure that the correct version was deployed.
[-] Cannot continue from here.
{code}

Java 8 also appears to not be vulnerable to remote library loading:
{code}
$ java -jar target/beanshooter-3.0.0-jar-with-dependencies.jar diagnostic load --verbose 127.0.0.1 7199 /tmp/hello
[-] A method with signature jvmtiAgentLoad([Ljava.lang.String;) does not exist on the endpoint.
[-] If you invoked a deployed MBean, make sure that the correct version was deployed.
[-] Cannot continue from here.
{code}

But Java 8 does appear to be vulnerable to MLet:
{code}
$ java -jar target/beanshooter-3.0.0-jar-with-dependencies.jar tonka deploy --stager-url http://localhost:8000 127.0.0.1 7199
[+] Starting MBean deployment.
[+]
[+]     Deplyoing MBean: TonkaBean
[+]
[+]             MBean class is not known by the server.
[+]             Starting MBean deployment.
[+]
[+]                     Deplyoing MBean: MLet
[+]                     MBean with object name DefaultDomain:type=MLet was successfully deployed.
[+]
[+]             Loading MBean from http://localhost:8000
[+]
[+]                     Creating HTTP server on: localhost:8000
[+]                     Creating MLetHandler for endpoint: /
[+]                     Creating JarHandler for endpoint: /fb0f34fe7c4f456bb44c07d9650dbf1e
[+]                     Starting HTTP server.
[+]
[+]                     Incoming request from: localhost
[+]                     Requested resource: /
[+]                     Sending mlet:
[+]
[+]                             Class:     de.qtc.beanshooter.tonkabean.TonkaBean
[+]                             Archive:   fb0f34fe7c4f456bb44c07d9650dbf1e
[+]                             Object:    MLetTonkaBean:name=TonkaBean,id=1
[+]                             Codebase:  http://localhost:8000
[+]
[+]                     Incoming request from: localhost
[+]                     Requested resource: /fb0f34fe7c4f456bb44c07d9650dbf1e
[+]                     Sending jar file with md5sum: 39d35ebd20aee73fbb83928584a530d7
[+]
[+]     MBean with object name MLetTonkaBean:name=TonkaBean,id=1 was successfully deployed.
{code}

Java 11 appears to be vulnerable to all three vulnerabilities, using JDK
Adoptium / Temurin 11.0.16.1+1 and cassandra-4.0 (5beab63b).

This patch fixes the above issues by introducing a new system property:
`cassandra.jmx.security.profile`, which can be set to ""restrictive""
(default) or ""lax"". The restrictive profile blocks the mechanisms for
all three vulnerabilities, by introducing a JMX
MBeanServerAccessController. Users can use the lax profile if they
require these mechanisms, or use their own authorization proxy by
specifying `cassandra.jmx.authorizer`."
CASSANDRA-17840,IndexOutOfBoundsException in Paging State Version Inference (V3 State Received on V4 Connection),"In {{PagingState.java}}, {{index}} is an integer field, and we add long values to it without a {{Math.toIntExact}} check. While we’re checking for negative return values returned by {{getUnsignedVInt}}, there's a chance that the value returned by it is so large that addition operation would cause integer overflow, or the value itself is large enough to cause overflow."
CASSANDRA-17806,Flaky test_rolling_upgrade,"The fix on CASSANDRA-17140 needs to be extended into other places as it seems it now fails only one in a billion but still we can fix that one.

{noformat}
Regression

dtest-upgrade.upgrade_tests.upgrade_through_versions_test.TestProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_3_11_X_HEAD.test_rolling_upgrade (from Cassandra dtests)
Failing for the past 1 build (Since
#115 )
Took 10 min.
Failed 1 times in the last 9 runs. Flakiness: 12%, Stability: 88%
Error Message

RuntimeError: A subprocess has terminated early. Subprocess statuses: Process-1 (is_alive: True), Process-2 (is_alive: False), attempting to terminate remaining subprocesses now.

Stacktrace

self = <upgrade_tests.upgrade_through_versions_test.TestProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_3_11_X_HEAD object at 0x7f4d313e4e50>

    @pytest.mark.timeout(3000)
    def test_rolling_upgrade(self):
        """"""
            Test rolling upgrade of the cluster, so we have mixed versions part way through.
            """"""
>       self.upgrade_scenario(rolling=True)

upgrade_tests/upgrade_through_versions_test.py:340: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
upgrade_tests/upgrade_through_versions_test.py:417: in upgrade_scenario
    self._check_on_subprocs(self.fixture_dtest_setup.subprocs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <upgrade_tests.upgrade_through_versions_test.TestProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_3_11_X_HEAD object at 0x7f4d313e4e50>
subprocs = [<Process name='Process-1' pid=10867 parent=389 stopped exitcode=-SIGKILL daemon>, <Process name='Process-2' pid=10881 parent=389 stopped exitcode=1 daemon>]

    def _check_on_subprocs(self, subprocs):
        """"""
            Check on given subprocesses.
    
            If any are not alive, we'll go ahead and terminate any remaining alive subprocesses since this test is going to fail.
            """"""
        subproc_statuses = [s.is_alive() for s in subprocs]
        if not all(subproc_statuses):
            message = ""A subprocess has terminated early. Subprocess statuses: ""
            for s in subprocs:
                message += ""{name} (is_alive: {aliveness}), "".format(name=s.name, aliveness=s.is_alive())
            message += ""attempting to terminate remaining subprocesses now.""
            self._terminate_subprocs()
>           raise RuntimeError(message)
E           RuntimeError: A subprocess has terminated early. Subprocess statuses: Process-1 (is_alive: True), Process-2 (is_alive: False), attempting to terminate remaining subprocesses now.

upgrade_tests/upgrade_through_versions_test.py:475: RuntimeError
{noformat}
"
CASSANDRA-17660,jvm-dtest upgrade failures due to 3.x Ping not allowing serialize,"trunk jvm upgrade tests periodically fail due to the ping message not being able to be serialized on 3.x branches.  We need support for jvm-dtest even if we ignore the messages.

{code}
Suppressed: java.lang.UnsupportedOperationException
		at org.apache.cassandra.net.PingMessage$PingMessageSerializer.serialize(PingMessage.java:45)
		at org.apache.cassandra.net.PingMessage$PingMessageSerializer.serialize(PingMessage.java:41)
		at org.apache.cassandra.distributed.impl.Instance.serializeMessage(Instance.java:362)
		at org.apache.cassandra.distributed.impl.Instance$1.allowIncomingMessage(Instance.java:302)
		at org.apache.cassandra.net.MessagingService.receive(MessagingService.java:866)
		at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:224)
		at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:193)
		at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:96)
{code}"
CASSANDRA-17611,Fix replace_address_test.TestReplaceAddress.test_fail_when_seed,"Seen [with|https://ci-cassandra.apache.org/job/Cassandra-3.11/349/testReport/dtest.replace_address_test/TestReplaceAddress/test_fail_when_seed/] and [without vnode|https://ci-cassandra.apache.org/job/Cassandra-3.11/348/testReport/dtest-novnode.replace_address_test/TestReplaceAddress/test_fail_when_seed/]:
{code:java}
Error Message
test teardown failure

Stacktrace
Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [MessagingService-Incoming-/127.0.0.1] 2022-04-28 22:04:36,765 CassandraDaemon.java:244 - Exception in thread Thread[MessagingService-Incoming-/127.0.0.1,5,main] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:58) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:148) at org.apache.cassandra.net.MessagingService.receive(MessagingService.java:1035) at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:215) at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:195) at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:98), ERROR [MessagingService-Incoming-/127.0.0.1] 2022-04-28 22:04:36,765 CassandraDaemon.java:244 - Exception in thread Thread[MessagingService-Incoming-/127.0.0.1,5,main] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:58) at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379) at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:148) at org.apache.cassandra.net.MessagingService.receive(MessagingService.java:1035) at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:215) at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:195) at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:98)]
{code}
 "
CASSANDRA-17583,Fix flaky test - org.apache.cassandra.distributed.test.MessageForwardingTest.mutationsForwardedToAllReplicasTest,"h3. Error Message

/127.0.0.3 appending to commitlog traces expected:<100> but was:<98>
h3. Stacktrace
{noformat}
junit.framework.AssertionFailedError: /127.0.0.3 appending to commitlog traces expected:<100> but was:<98> at org.apache.cassandra.distributed.test.MessageForwardingTest.lambda$mutationsForwardedToAllReplicasTest$8(MessageForwardingTest.java:92) at java.base/java.util.HashMap.forEach(HashMap.java:1336) at org.apache.cassandra.distributed.test.MessageForwardingTest.mutationsForwardedToAllReplicasTest(MessageForwardingTest.java:91) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{noformat}"
CASSANDRA-17581,"nodetool with Java 8u331 returns ""URISyntaxException: 'Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199'"""," Error when {{{color:#0747a6}new NodeProbe(""127.0.0.1"", 7199){color}}} with {color:#de350b}JDK 1.8.0_332{color}:
{code:java}
java.io.IOException: Failed to retrieve RMIServer stub:
 javax.naming.InvalidNameException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199
 Root exception is java.lang.IllegalArgumentException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199 {code}

Here is the error stack trace:
{noformat}
2022-04-24 07:22:40 [grizzly-http-server-2] [INFO] c.b.h.b.s.c.CassandraMetrics - Probe to cassandra node: '127.0.0.1:7199'
2022-04-24 07:22:40 [grizzly-http-server-2] [WARN] c.b.h.b.s.c.CassandraMetrics - Unable to get metrics from host '127.0.0.1':
java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.InvalidNameException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199 [Root exception is java.lang.IllegalArgumentException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199]
    at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:369) ~[?:1.8.0_332]
    at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270) ~[?:1.8.0_332]
    at org.apache.cassandra.tools.NodeProbe.connect(NodeProbe.java:191) ~[cassandra-all-3.10.jar:3.10]
    at org.apache.cassandra.tools.NodeProbe.<init>(NodeProbe.java:158) ~[cassandra-all-3.10.jar:3.10]
    at com.baidu.hugegraph.backend.store.cassandra.CassandraMetrics.newNodeProbe(CassandraMetrics.java:308) ~[hugegraph-cassandra-0.13.0.jar:?]
    at com.baidu.hugegraph.backend.store.cassandra.CassandraMetrics.getMetricsByHost(CassandraMetrics.java:100) ~[hugegraph-cassandra-0.13.0.jar:?]
    at com.baidu.hugegraph.backend.store.cassandra.CassandraMetrics.executeAllHosts(CassandraMetrics.java:299) ~[hugegraph-cassandra-0.13.0.jar:?]
    at com.baidu.hugegraph.backend.store.cassandra.CassandraMetrics.metrics(CassandraMetrics.java:86) ~[hugegraph-cassandra-0.13.0.jar:?]
    at com.baidu.hugegraph.backend.store.cassandra.CassandraStore.lambda$registerMetaHandlers$0(CassandraStore.java:99) ~[hugegraph-cassandra-0.13.0.jar:?]
    at com.baidu.hugegraph.backend.store.MetaDispatcher.dispatchMetaHandler(MetaDispatcher.java:45) ~[hugegraph-core-0.13.0.jar:0.13.0.0]
    at com.baidu.hugegraph.backend.store.AbstractBackendStore.metadata(AbstractBackendStore.java:53) ~[hugegraph-core-0.13.0.jar:0.13.0.0]
    at com.baidu.hugegraph.backend.tx.AbstractTransaction.metadata(AbstractTransaction.java:109) ~[hugegraph-core-0.13.0.jar:0.13.0.0]
    at com.baidu.hugegraph.StandardHugeGraph.metadata(StandardHugeGraph.java:975) ~[hugegraph-core-0.13.0.jar:0.13.0.0]
    at com.baidu.hugegraph.auth.HugeGraphAuthProxy.metadata(HugeGraphAuthProxy.java:669) ~[hugegraph-api-0.13.0.jar:0.67.0.0]
    at com.baidu.hugegraph.api.metrics.MetricsAPI.backend(MetricsAPI.java:87) ~[hugegraph-api-0.13.0.jar:0.67.0.0]
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_332]
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_332]
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_332]
    at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_332]
    at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$TypeOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:205) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.internal.Errors.process(Errors.java:315) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.internal.Errors.process(Errors.java:297) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.internal.Errors.process(Errors.java:267) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317) ~[jersey-common-2.25.1.jar:?]
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:305) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154) ~[jersey-server-2.25.1.jar:?]
    at org.glassfish.jersey.grizzly2.httpserver.GrizzlyHttpContainer.service(GrizzlyHttpContainer.java:384) ~[jersey-container-grizzly2-http-2.25.1.jar:?]
    at org.glassfish.grizzly.http.server.HttpHandler$1.run(HttpHandler.java:200) ~[grizzly-http-server-2.4.4.jar:2.4.4]
    at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:569) ~[grizzly-framework-2.4.4.jar:2.4.4]
    at org.glassfish.grizzly.threadpool.AbstractThreadPool$Worker.run(AbstractThreadPool.java:549) ~[grizzly-framework-2.4.4.jar:2.4.4]
    at java.lang.Thread.run(Thread.java:750) [?:1.8.0_332]
Caused by: javax.naming.InvalidNameException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.newNamingException(rmiURLContext.java:295) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parseCompat(rmiURLContext.java:223) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parse(rmiURLContext.java:109) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext.getRootURLContext(rmiURLContext.java:314) ~[?:1.8.0_332]
    at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:215) ~[?:1.8.0_332]
    at javax.naming.InitialContext.lookup(InitialContext.java:417) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287) ~[?:1.8.0_332]
    ... 40 more
Caused by: java.lang.IllegalArgumentException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199
    at java.net.URI.create(URI.java:852) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parseCompat(rmiURLContext.java:213) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parse(rmiURLContext.java:109) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext.getRootURLContext(rmiURLContext.java:314) ~[?:1.8.0_332]
    at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:215) ~[?:1.8.0_332]
    at javax.naming.InitialContext.lookup(InitialContext.java:417) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287) ~[?:1.8.0_332]
    ... 40 more
Caused by: java.net.URISyntaxException: Malformed IPv6 address at index 7: rmi://[127.0.0.1]:7199
    at java.net.URI$Parser.fail(URI.java:2873) ~[?:1.8.0_332]
    at java.net.URI$Parser.parseIPv6Reference(URI.java:3494) ~[?:1.8.0_332]
    at java.net.URI$Parser.parseServer(URI.java:3244) ~[?:1.8.0_332]
    at java.net.URI$Parser.parseAuthority(URI.java:3180) ~[?:1.8.0_332]
    at java.net.URI$Parser.parseHierarchical(URI.java:3122) ~[?:1.8.0_332]
    at java.net.URI$Parser.parse(URI.java:3078) ~[?:1.8.0_332]
    at java.net.URI.<init>(URI.java:588) ~[?:1.8.0_332]
    at java.net.URI.create(URI.java:850) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parseCompat(rmiURLContext.java:213) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext$Parser.parse(rmiURLContext.java:109) ~[?:1.8.0_332]
    at com.sun.jndi.url.rmi.rmiURLContext.getRootURLContext(rmiURLContext.java:314) ~[?:1.8.0_332]
    at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:215) ~[?:1.8.0_332]
    at javax.naming.InitialContext.lookup(InitialContext.java:417) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922) ~[?:1.8.0_332]
    at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287) ~[?:1.8.0_332]
    ... 40 more {noformat}"
CASSANDRA-17524,Schema mutations may not be completed on drain,"The drain logic (invoked explicitly with nodetool or from the JVM
shutdown hook) closes down executor stages that can create mutations (counter,
view, mutation) before closing down the commitlog. The gossip
stage also commits schema mutations, and should be treated the same way.

The messaging service is shut down as part of drain, so there should be
no new Gossip messages received, however any messages still queued
in the executor could still run after the commitlog allocator is shut down as
part of drain, causing the gossip stage thread to hang indefinitely waiting
for a new segment that never arrives.

Here is an example from an in-JVM dtest, showing an update to the peers table as it shuts down.
{code:java}
park:-1, Unsafe (jdk.internal.misc)
park:323, LockSupport (java.util.concurrent.locks)
await:289, WaitQueue$Standard$AbstractSignal (org.apache.cassandra.utils.concurrent)
await:282, WaitQueue$Standard$AbstractSignal (org.apache.cassandra.utils.concurrent)
awaitUninterruptibly:186, Awaitable$Defaults (org.apache.cassandra.utils.concurrent)
awaitUninterruptibly:259, Awaitable$AbstractAwaitable (org.apache.cassandra.utils.concurrent)
awaitAvailableSegment:283, AbstractCommitLogSegmentManager (org.apache.cassandra.db.commitlog)
advanceAllocatingFrom:257, AbstractCommitLogSegmentManager (org.apache.cassandra.db.commitlog)
allocate:55, CommitLogSegmentManagerStandard (org.apache.cassandra.db.commitlog)
add:282, CommitLog (org.apache.cassandra.db.commitlog)
beginWrite:50, CassandraKeyspaceWriteHandler (org.apache.cassandra.db)
applyInternal:622, Keyspace (org.apache.cassandra.db)
apply:506, Keyspace (org.apache.cassandra.db)
apply:215, Mutation (org.apache.cassandra.db)
apply:220, Mutation (org.apache.cassandra.db)
apply:229, Mutation (org.apache.cassandra.db)
executeInternalWithoutCondition:644, ModificationStatement (org.apache.cassandra.cql3.statements)
executeLocally:635, ModificationStatement (org.apache.cassandra.cql3.statements)
executeInternal:431, QueryProcessor (org.apache.cassandra.cql3)
updateTokens:804, SystemKeyspace (org.apache.cassandra.db)
updateTokenMetadata:2941, StorageService (org.apache.cassandra.service)
handleStateNormal:3057, StorageService (org.apache.cassandra.service)
onChange:2498, StorageService (org.apache.cassandra.service)
markAsShutdown:607, Gossiper (org.apache.cassandra.gms)
doVerb:39, GossipShutdownVerbHandler (org.apache.cassandra.gms)
lambda$new$0:78, InboundSink (org.apache.cassandra.net)
accept:-1, 581110313 (org.apache.cassandra.net.InboundSink$$Lambda$2638)
accept:64, InboundSink$Filtered (org.apache.cassandra.net)
accept:50, InboundSink$Filtered (org.apache.cassandra.net)
accept:97, InboundSink (org.apache.cassandra.net)
accept:45, InboundSink (org.apache.cassandra.net)
run:433, InboundMessageHandler$ProcessMessage (org.apache.cassandra.net)
run:124, ExecutionFailure$1 (org.apache.cassandra.concurrent)
runWorker:1128, ThreadPoolExecutor (java.util.concurrent)
run:628, ThreadPoolExecutor$Worker (java.util.concurrent)
run:30, FastThreadLocalRunnable (io.netty.util.concurrent)
run:829, Thread (java.lang)
{code}
This causes an exception during shutdown for the in-JVM dtest as it is
unable to shutdown {{{}Stage.GOSSIP{}}}, but does not prevent regular
shutdown for Cassandra as the executors are not stopped. The schema update
would be lost, despite requesting a graceful shutdown."
CASSANDRA-17387,Test failure: dtest-offheap.counter_test.TestCounters.test_13691,"This test fails only off heap on 3.11, hard to say when it started as it was always failing since we have Butler. Marking it critical as it shows breaking config change.
h3. Stacktrace

Unexpected error found in node logs (see stdout for full details). Errors: [ERROR [main] 2022-02-10 05:06:27,462 DatabaseDescriptor.java (line 117) Fatal configuration error org.apache.cassandra.exceptions.ConfigurationException: Invalid yaml. Please remove properties [memtable_allocation_type] from your cassandra.yaml at org.apache.cassandra.config.YamlConfigurationLoader$MissingPropertiesChecker.check(YamlConfigurationLoader.java:137) at org.apache.cassandra.config.YamlConfigurationLoader.loadConfig(YamlConfigurationLoader.java:100) at"
CASSANDRA-17349,Fix flaky test - dtest-novnode.repair_tests.repair_test.TestRepair.test_simple_sequential_repair,"Failed 2 times in the last 9 runs. Flakiness: 37%, Stability: 77%
Error Message

cassandra.DriverException: ID mismatch while trying to reprepare (expected b'ba2c66a4f13080265ea718e037637d4a', got b'52faf62235132756a26828817a81168d'). This prepared statement won't work anymore. This usually happens when you run a 'USE...' query after the statement was prepared.

Stacktrace

self = <repair_tests.repair_test.TestRepair object at 0x7ff6850f5a60>

    def test_simple_sequential_repair(self):
        """"""
            Calls simple repair test with a sequential repair
            """"""
>       self._simple_repair(sequential=True)

repair_tests/repair_test.py:363: "
CASSANDRA-17348,Fix flaky test - org.apache.cassandra.distributed.test.GossipTest.nodeDownDuringMove,"Failed 5 times in the last 12 runs. Flakiness: 36%, Stability: 58%

Error Message

java.lang.AssertionError

Stacktrace

java.lang.RuntimeException: java.lang.AssertionError
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.waitOn(IsolatedExecutor.java:218)
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$sync$19(IsolatedExecutor.java:124)
	at org.apache.cassandra.distributed.test.GossipTest.nodeDownDuringMove(GossipTest.java:124)
Caused by: java.lang.AssertionError
	at org.apache.cassandra.locator.TokenMetadata.getTokens(TokenMetadata.java:568)
	at org.apache.cassandra.distributed.test.GossipTest.lambda$nodeDownDuringMove$805d71c$1(GossipTest.java:122)
	at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$null$17(IsolatedExecutor.java:123)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:83)
	at java.lang.Thread.run(Thread.java:748)
"
CASSANDRA-17314,Test Failure: org.apache.cassandra.db.ScrubTest.testScrubCorruptedCounterRow,"Failed 10 times in the last 14 runs. Flakiness: 61%, Stability: 28%

Error Message
Timeout occurred. Please note the time in the report does not reflect the time until the timeout.

{code}
Stacktrace
junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout.
	at java.util.Vector.forEach(Vector.java:1277)
	at java.util.Vector.forEach(Vector.java:1277)
	at java.util.Vector.forEach(Vector.java:1277)
	at jdk.nashorn.internal.scripts.Script$3$\^eval\_.:program(<eval>:13)
	at jdk.nashorn.internal.runtime.ScriptFunctionData.invoke(ScriptFunctionData.java:637)
	at jdk.nashorn.internal.runtime.ScriptFunction.invoke(ScriptFunction.java:494)
	at jdk.nashorn.internal.runtime.ScriptRuntime.apply(ScriptRuntime.java:393)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:449)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:406)
	at jdk.nashorn.api.scripting.NashornScriptEngine.evalImpl(NashornScriptEngine.java:402)
	at jdk.nashorn.api.scripting.NashornScriptEngine.eval(NashornScriptEngine.java:155)
	at javax.script.AbstractScriptEngine.eval(AbstractScriptEngine.java:264)
	at java.util.Vector.forEach(Vector.java:1277)
{code}"
CASSANDRA-17312,dtest-large.replace_address_test.TestReplaceAddress.test_restart_failed_replace (from Cassandra dtests),"Consistently failing on 3.0.x

https://ci-cassandra.apache.org/job/Cassandra-3.0/240/testReport/dtest-large.replace_address_test/TestReplaceAddress/test_restart_failed_replace_2/

Failed 8 times in the last 16 runs. Flakiness: 73%, Stability: 50%

Error Message
ccmlib.node.TimeoutError: 26 Jan 2022 23:07:02 [replacement] after 90.12/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log:  Head: INFO  [main] 2022-01-26 23:04:33,906 YamlConfigura  Tail: ...endingRangeCalculator:1] 2022-01-26 23:06:41,472 TokenMetadata.java:226 - Token -3193255413308472407 changing ownership from /127.0.0.3 to /127.0.0.4

{code}
Stacktrace
self = <replace_address_test.TestReplaceAddress object at 0x7f99546197c0>

    @since('2.2')
    @pytest.mark.resource_intensive
    def test_restart_failed_replace(self):
        """"""
            Test that if a node fails to replace, it can join the cluster even if the data is wiped.
            """"""
>       self._test_restart_failed_replace(mode='wipe')

replace_address_test.py:479: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
replace_address_test.py:539: in _test_restart_failed_replace
    self.replacement_node.start(jvm_args=[""-Dcassandra.replace_address_first_boot={}""
../venv/lib/python3.8/site-packages/ccmlib/node.py:901: in start
    self.wait_for_binary_interface(from_mark=self.mark)
../venv/lib/python3.8/site-packages/ccmlib/node.py:689: in wait_for_binary_interface
    self.watch_log_for(""Starting listening for CQL clients"", **kwargs)
../venv/lib/python3.8/site-packages/ccmlib/node.py:588: in watch_log_for
    TimeoutError.raise_if_passed(start=start, timeout=timeout, node=self.name,
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

start = 1643238332.8472316, timeout = 90
msg = ""Missing: ['Starting listening for CQL clients'] not found in system.log:\n Head: INFO  [main] 2022-01-26 23:04:33,906...26 23:06:41,472 TokenMetadata.java:226 - Token -3193255413308472407 changing ownership from /127.0.0.3 to /127.0.0.4\n""
node = 'replacement'

    @staticmethod
    def raise_if_passed(start, timeout, msg, node=None):
        if start + timeout < time.time():
>           raise TimeoutError.create(start, timeout, msg, node)
E           ccmlib.node.TimeoutError: 26 Jan 2022 23:07:02 [replacement] after 90.12/90 seconds Missing: ['Starting listening for CQL clients'] not found in system.log:
E            Head: INFO  [main] 2022-01-26 23:04:33,906 YamlConfigura
E            Tail: ...endingRangeCalculator:1] 2022-01-26 23:06:41,472 TokenMetadata.java:226 - Token -3193255413308472407 changing ownership from /127.0.0.3 to /127.0.0.4

../venv/lib/python3.8/site-packages/ccmlib/node.py:56: TimeoutError
{code}

This test can be run isolation via 'pytest --force-resource-intensive-tests --cassandra-dir=~/cassandra replace_address_test.py::TestReplaceAddress::test_restart_failed_replace'"
CASSANDRA-17302,Test Failure: dtest-offheap.topology_test.TestTopology.test_decommissioned_node_cant_rejoin,"https://ci-cassandra.apache.org/job/Cassandra-4.0/317/testReport/dtest-offheap.topology_test/TestTopology/test_decommissioned_node_cant_rejoin/

Failed 1 times in the last 20 runs. Flakiness: 5%, Stability: 95%

Error Message
AssertionError: assert None  +  where None = <function search at 0x7f0de9492c10>('This node was decommissioned and will not rejoin the ring', '', re.MULTILINE)  +    where <function search at 0x7f0de9492c10> = re.search  +    and   '' = <built-in method join of str object at 0x7f0de963b4b0>([])  +      where <built-in method join of str object at 0x7f0de963b4b0> = '\n'.join  +    and   re.MULTILINE = re.MULTILINE

{code}
Stacktrace
self = <topology_test.TestTopology object at 0x7f0de5899430>

    @since('3.0')
    def test_decommissioned_node_cant_rejoin(self):
        """"""
            @jira_ticket CASSANDRA-8801
    
            Test that a decommissioned node can't rejoin the cluster by:
    
            - creating a cluster,
            - decommissioning a node, and
            - asserting that the ""decommissioned node won't rejoin"" error is in the
            logs for that node and
            - asserting that the node is not running.
            """"""
        rejoin_err = 'This node was decommissioned and will not rejoin the ring'
        self.fixture_dtest_setup.ignore_log_patterns = list(self.fixture_dtest_setup.ignore_log_patterns) + [
            rejoin_err]
    
        self.cluster.populate(3).start()
        node1, node2, node3 = self.cluster.nodelist()
    
        logger.debug('decommissioning...')
        node3.decommission(force=self.cluster.version() >= '4.0')
        logger.debug('stopping...')
        node3.stop()
        logger.debug('attempting restart...')
        node3.start(wait_other_notice=False)
        try:
            # usually takes 3 seconds, so give it a generous 15
            node3.watch_log_for(rejoin_err, timeout=15)
        except TimeoutError:
            # TimeoutError is not very helpful to the reader of the test output;
            # let that pass and move on to string assertion below
            pass
    
>       assert re.search(rejoin_err,
                         '\n'.join(['\n'.join(err_list) for err_list in node3.grep_log_for_errors()]), re.MULTILINE)
E       AssertionError: assert None
E        +  where None = <function search at 0x7f0de9492c10>('This node was decommissioned and will not rejoin the ring', '', re.MULTILINE)
E        +    where <function search at 0x7f0de9492c10> = re.search
E        +    and   '' = <built-in method join of str object at 0x7f0de963b4b0>([])
E        +      where <built-in method join of str object at 0x7f0de963b4b0> = '\n'.join
E        +    and   re.MULTILINE = re.MULTILINE

topology_test.py:416: AssertionError
{code}"
CASSANDRA-17296,Test Failure: dtest-upgrade.upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD.test_rolling_upgrade,"2 failures in 30, looks flaky on timing / subprocess termination.

https://ci-cassandra.apache.org/job/Cassandra-trunk/920/testReport/dtest-upgrade.upgrade_tests.upgrade_through_versions_test/TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD/test_rolling_upgrade/

Failed 2 times in the last 30 runs. Flakiness: 10%, Stability: 93%
Error Message
RuntimeError: A subprocess has terminated early. Subprocess statuses: Process-1 (is_alive: True), Process-2 (is_alive: False), attempting to terminate remaining subprocesses now.
Stacktrace
self = <upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD object at 0x7f22685cebb0>

    @pytest.mark.timeout(3000)
    def test_rolling_upgrade(self):
        """"""
            Test rolling upgrade of the cluster, so we have mixed versions part way through.
            """"""
>       self.upgrade_scenario(rolling=True)

upgrade_tests/upgrade_through_versions_test.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
upgrade_tests/upgrade_through_versions_test.py:398: in upgrade_scenario
    self._check_on_subprocs(self.fixture_dtest_setup.subprocs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <upgrade_tests.upgrade_through_versions_test.TestProtoV4Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD object at 0x7f22685cebb0>
subprocs = [<Process name='Process-1' pid=28667 parent=314 stopped exitcode=-SIGKILL daemon>, <Process name='Process-2' pid=28686 parent=314 stopped exitcode=1 daemon>]

    def _check_on_subprocs(self, subprocs):
        """"""
            Check on given subprocesses.
    
            If any are not alive, we'll go ahead and terminate any remaining alive subprocesses since this test is going to fail.
            """"""
        subproc_statuses = [s.is_alive() for s in subprocs]
        if not all(subproc_statuses):
            message = ""A subprocess has terminated early. Subprocess statuses: ""
            for s in subprocs:
                message += ""{name} (is_alive: {aliveness}), "".format(name=s.name, aliveness=s.is_alive())
            message += ""attempting to terminate remaining subprocesses now.""
            self._terminate_subprocs()
>           raise RuntimeError(message)
E           RuntimeError: A subprocess has terminated early. Subprocess statuses: Process-1 (is_alive: True), Process-2 (is_alive: False), attempting to terminate remaining subprocesses now.

upgrade_tests/upgrade_through_versions_test.py:456: RuntimeError"
CASSANDRA-17273,Lazy transaction log replica creation allows incorrect replica content divergence during compaction,"Recently encountered this around compaction/anticompaction:

{noformat}
2022-01-13 10:18:24,325 ERROR [main] org.apache.cassandra.db.lifecycle.LogTransaction - Unexpected disk state: failed to read transaction log [mf_txn_anticompactionafterrepair_2f826324-742c-11ec-b293-65cae21e111c.log in .../d1/data/.../files-c351f12917af3a5cbc57791cdf178a1f, .../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f]
Files and contents follow:
.../d1/data/.../files-c351f12917af3a5cbc57791cdf178a1f/mf_txn_anticompactionafterrepair_2f826324-742c-11ec-b293-65cae21e111c.log
	ADD:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350438-big,0,8][2380834168]
	REMOVE:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350435-big,1642049328006,8][2338829485]
	REMOVE:[.../d1/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350436-big,1642049366291,8][4248366924]
	COMMIT:[,0,0][2613697770]
.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/mf_txn_anticompactionafterrepair_2f826324-742c-11ec-b293-65cae21e111c.log
	ADD:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350437-big,0,8][4051162457]
		***Does not match <ADD:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350438-big,0,8][2380834168]> in first replica file
	ADD:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350438-big,0,8][2380834168]
	REMOVE:[.../d2/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350435-big,1642049328006,8][2338829485]
	REMOVE:[.../d1/data/.../files-c351f12917af3a5cbc57791cdf178a1f/prod_p203-files-mf-350436-big,1642049366291,8][4248366924]
	COMMIT:[,0,0][2613697770]
{noformat}

We have two data directories and two transaction log files, but one is missing an ADD entry when the contents of the two log replicas should be identical. One scenario that can cause this is the following:

1. Start anticompaction on a single file, in directory {{/tmp/d0}}.

2. Call {{trackNew()}} with 2 new files, both in a single directory, but in directory {{/tmp/d1}}. This initializes the log file in {{/tmp/d1}}, but there is still no log file in {{/tmp/d0}}.

3. Anticompaction only writes to one of the files in {{/tmp/d1}} (say all other keys were outside the repaired range).

4. When anticompaction is done, the empty writer is aborted and we call {{untrackNew()}}, which removes the added file from the registered log “records"" (BUT NOT FROM DISK in {{/tmp/d1}}).

5. The REMOVE record is added. This references {{/tmp/d0}}. We lazily create the log file there by dumping all the records we have in memory to that file, which does not include the aborted SSTable above.

6. Now the log files contain:

{noformat}
/tmp/d1/logfile.log:
ADD:[/tmp/d1/AntiCompactionTest/AntiCompactionTest-e4fdddf0746e11ecb73ad5a997381615/AntiCompactionTest-AntiCompactionTest-mf-2-big,0,8][3268492367]
ADD:[/tmp/d1/AntiCompactionTest/AntiCompactionTest-e4fdddf0746e11ecb73ad5a997381615/AntiCompactionTest-AntiCompactionTest-mf-3-big,0,8][2813724425]
REMOVE:[/tmp/d0/AntiCompactionTest/AntiCompactionTest-e4fdddf0746e11ecb73ad5a997381615/AntiCompactionTest-AntiCompactionTest-mf-1-big,1642078019000,8][2401235379]
COMMIT:[,0,0][2613697770]
** /tmp/d0/logfile.log:
ADD:[/tmp/d1/AntiCompactionTest/AntiCompactionTest-e4fdddf0746e11ecb73ad5a997381615/AntiCompactionTest-AntiCompactionTest-mf-3-big,0,8][2813724425]
REMOVE:[/tmp/d0/AntiCompactionTest/AntiCompactionTest-e4fdddf0746e11ecb73ad5a997381615/AntiCompactionTest-AntiCompactionTest-mf-1-big,1642078019000,8][2401235379]
COMMIT:[,0,0][2613697770]
{noformat}"
CASSANDRA-17254,nodetool toppartitions can fail because ByteBuffer.array() returns more bytes than would be considered valid by UTF8Serializer.validate,"The error below is caused by the use of [{{ByteBuffer.array()}}|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/db/ColumnFamilyStore.java#L1628]. Doing so not only makes the hex key potentially incorrect but causes invalid data to be passed to {{AbstractType.getString}} and ultimately {{UTF8Validator.validate}}. 

{code}
error: String didn't validate.
-- StackTrace --
org.apache.cassandra.serializers.MarshalException: String didn't validate.
	at org.apache.cassandra.serializers.UTF8Serializer.validate(UTF8Serializer.java:35)
	at org.apache.cassandra.db.marshal.AbstractType.getString(AbstractType.java:129)
	at org.apache.cassandra.db.ColumnFamilyStore.finishLocalSampling(ColumnFamilyStore.java:1633)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
{code}"
CASSANDRA-17252,ConnectionLimitHandler may leaks connection count if remote connection drops,"In some cases, Netty does not return the original IP used for per-IP counting when the channel becomes inactive,
which throws an NPE before decrementing the active per-IP count.


{code:java}
java.lang.NullPointerException
at org.apache.cassandra.transport.ConnectionLimitHandler.channelInactive(ConnectionLimitHandler.java:101)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
       at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
       at io.netty.handler.codec.ByteToMessageDecoder.channelInputClosed(ByteToMessageDecoder.java:389)
       at io.netty.handler.codec.ByteToMessageDecoder.channelInactive(ByteToMessageDecoder.java:354)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
       at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
       at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
       at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
       at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
       at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:819)
       at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
       at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)
       at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:497)
       at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
       at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
       at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
       at java.base/java.lang.Thread.run(Thread.java:834)
{code}
"
CASSANDRA-17239,Race in CompactionExecutorTest,"CompactionExecutorTest has a race between the runnable/callable under test completing
and the {{afterExecute}} method stashing it for the test.  Replace the wait/sleep loop
with a {{SimpleCondition}} that is signaled once the test task throwable has been recorded.

This seems fairly hard to hit but has happened on CI.  It took about 2600 iterations on my MacBook to trigger, but you can artificially hit frequently by adding a sleep at the start of the afterExecute method.
"
CASSANDRA-17213,CompactStorageUpgradeTest.compactStorageUpgradeTest fails w/OOM,"[https://ci-cassandra.apache.org/job/Cassandra-trunk/882/testReport/org.apache.cassandra.distributed.upgrade/CompactStorageUpgradeTest/compactStorageUpgradeTest/]
h3. Error Message

GC overhead limit exceeded
h3. Stacktrace

java.lang.OutOfMemoryError: GC overhead limit exceeded at sun.net.www.ParseUtil.encodePath(ParseUtil.java:105) at sun.misc.URLClassPath$JarLoader.checkResource(URLClassPath.java:969) at sun.misc.URLClassPath$JarLoader.getResource(URLClassPath.java:1056) at sun.misc.URLClassPath.getResource(URLClassPath.java:249) at java.net.URLClassLoader$1.run(URLClassLoader.java:366) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at org.apache.cassandra.distributed.shared.InstanceClassLoader.findClass(InstanceClassLoader.java:140) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClassInternal(InstanceClassLoader.java:123) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClass(InstanceClassLoader.java:109) at org.codehaus.jackson.map.introspect.BasicClassIntrospector.<clinit>(BasicClassIntrospector.java:62) at org.codehaus.jackson.map.ObjectMapper.<clinit>(ObjectMapper.java:188) at org.apache.cassandra.utils.FBUtilities.<clinit>(FBUtilities.java:74) at org.apache.cassandra.distributed.impl.Instance.<init>(Instance.java:144) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper$$Lambda$21599/1714755496.apply(Unknown Source) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.newInstance(AbstractCluster.java:247) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.<init>(AbstractCluster.java:226) at org.apache.cassandra.distributed.UpgradeableCluster.newInstanceWrapper(UpgradeableCluster.java:46) at org.apache.cassandra.distributed.UpgradeableCluster.newInstanceWrapper(UpgradeableCluster.java:36) at org.apache.cassandra.distributed.impl.AbstractCluster.newInstanceWrapperInternal(AbstractCluster.java:515) at org.apache.cassandra.distributed.impl.AbstractCluster.<init>(AbstractCluster.java:470) at org.apache.cassandra.distributed.UpgradeableCluster.<init>(UpgradeableCluster.java:40) at org.apache.cassandra.distributed.UpgradeableCluster.<init>(UpgradeableCluster.java:36) at org.apache.cassandra.distributed.UpgradeableCluster$Builder.lambda$new$0(UpgradeableCluster.java:86) at org.apache.cassandra.distributed.UpgradeableCluster$Builder$$Lambda$73/1631826609.newCluster(Unknown Source) at org.apache.cassandra.distributed.shared.AbstractBuilder.createWithoutStarting(AbstractBuilder.java:158) at org.apache.cassandra.distributed.shared.AbstractBuilder.start(AbstractBuilder.java:140) at org.apache.cassandra.distributed.UpgradeableCluster.create(UpgradeableCluster.java:73) at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:223) at org.apache.cassandra.distributed.upgrade.CompactStorageUpgradeTest.compactStorageUpgradeTest(CompactStorageUpgradeTest.java:159)
h3. Standard Output

out of memory on output stream

 

Appears consistent"
CASSANDRA-17049,Fix rare NPE caused by batchlog replay / node decomission races,"Batchlog replay process collects addresses of the hosts that have been hinted to, so it can flush hints for them to disk before confirming deletion of the replayed batches. If a node has been decommissioned during replay, however, when the time comes to flush the hints at the very end of replay, {{StorageService.getHostIdForEndpoint()}} will return {{null}} for its address, which will, down the line, cause {{HintsCatalog::get()}} to be invoked with a {{null}} host id argument, causing an NPE.

The simple fix is to check returned host ids for addresses for nulls, and collect hinted host ids instead of hinted addresses."
CASSANDRA-16986,DROP Table should not recycle active CommitLog segments,"Right now, DROP TABLE recycles all active CL segments and explicitly marks intervals as clean for all dropping tables. I believe that this is not necessary.

Recycling of CL segments was introduced in CASSANDRA-3578. Back then, it was necessary to recycle all active segments because:
1. CommitLog reused old segments after they were clean. This is no longer the case, I believe, since CASSANDRA-6809.
2. CommitLog segments must have been closed and recycled on {{DROP TABLE}} to avoid resurrecting data if a table with the same name is created. This was an issue because tables didn't have unique ids yet (CASSANDRA-5202).

Given that {{DROP TABLE}} triggers flush, which in turn cleans CL intervals in Keyspace#unloadCF, I think that we can avoid the call to {{forceRecycleAll}} there."
CASSANDRA-16973,Fix org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution,"org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution fails in [3.11|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.concurrent/LongSharedExecutorPoolTest/testPromptnessOfExecution/]
h3.  
{code:java}
Stacktrace
junit.framework.AssertionFailedError at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:169) at org.apache.cassandra.concurrent.LongSharedExecutorPoolTest.testPromptnessOfExecution(LongSharedExecutorPoolTest.java:102)

Standard Output
Completed 0K batches with 0.0M events Running for 120s with load multiplier 0.5

Standard Error
SLF4J: The following set of substitute loggers may have been accessed SLF4J: during the initialization phase. Logging calls during this SLF4J: phase were not honored. However, subsequent logging calls to these SLF4J: loggers will work as normally expected. SLF4J: See also
http://www.slf4j.org/codes.html#substituteLogger
SLF4J: org.apache.cassandra.LogbackStatusListener
{code}
 "
CASSANDRA-16972,Fix org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding ,"[org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding|https://jenkins-cm4.apache.org/job/Cassandra-devbranch/1119/testReport/junit/org.apache.cassandra.cql3/ViewTest/testTruncateWhileBuilding/]  fails in 3.11

 
{code:java}
Error Message
expected:<0> but was:<1>

Stacktrace
junit.framework.AssertionFailedError: expected:<0> but was:<1> at org.apache.cassandra.Util.spinAssertEquals(Util.java:575) at org.apache.cassandra.cql3.ViewTest.testTruncateWhileBuilding(ViewTest.java:1656) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$9.evaluate(BMUnitRunner.java:342) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$6.evaluate(BMUnitRunner.java:241) at org.jboss.byteman.contrib.bmunit.BMUnitRunner$1.evaluate(BMUnitRunner.java:75)
{code}
 "
CASSANDRA-16960,Improve MV TTL error message,"Old MVs could have been created with a {{default_time_to_live}} before the time of CASSANDRA-12868.

A few years forward customers altering that MV for other reasons might get a very confusing message which can benefit from some clarification.

{code}
ALTER MATERIALIZED VIEW XXXXX_view WITH gc_grace_seconds = 10800;

Cannot set or alter default_time_to_live for a materialized view. Data in a materialized view always expire at the same time than the corresponding data in the parent table.
{code}
"
CASSANDRA-16954,Flaky tests due to teardown failure,"Different dtests in several CircleCI builds failed with teardown failure due to network failure with the error:
{code}
test teardown failure
Unexpected error found in node logs (see stdout for full details). Errors: [WARN  [epollEventLoopGroup-5-4] 2021-09-14 09:35:15,897 ExceptionHandlers.java:134 - Unknown exception in client networking
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer, WARN  [epollEventLoopGroup-5-4] 2021-09-14 09:35:15,897 ExceptionHandlers.java:134 - Unknown exception in client networking
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer]
{code}

For example, {{test_view_metadata_cleanup}} from {{materialized_views_test.TestMaterializedViews}} failed in [this build|https://app.circleci.com/pipelines/github/k-rus/cassandra/18/workflows/0cb193f3-ffe8-41c1-a376-43c91634579e/jobs/185/tests#failed-test-0] or {{test_expiration_overflow_policy_reject}} from {{ttl_test.TestTTL}} failed in [this build|https://app.circleci.com/pipelines/github/k-rus/cassandra/8/workflows/da99468d-c513-4a4f-9fd3-48b67482ce3e/jobs/67/tests#failed-test-0]"
CASSANDRA-16948,offline_tools_test.py::TestOfflineTools::test_sstableverify fails on 3.11,"As noted by [~stefan.miklosovic]:

===Flaky Test Report===

test_sstableverify failed and was not selected for rerun.
        <class 'AssertionError'>
        assert None
 +  where None = <function search at 0x7fef074b5550>(('WARNING: Corrupted SSTable : ' + '/tmp/dtest-z6njep37/test/node1/data2/keyspace1/standard1-9b45a1f0149411ecbc69f72e6826361e/me-12-big-Data.db'), ""Subprocess sstableverify on keyspace1 : standard1 with options: ['-v'] exited with non-zero status; exit status: 1; \...p/dtest-z6njep37/test/node1/cdc_raw; setting cdc_total_space_in_mb to 3831.  You can override this in cassandra.yaml\n"")
 +    where <function search at 0x7fef074b5550> = re.search
        [<TracebackEntry /home/ubuntu/cassandra-dtest/offline_tools_test.py:303>]
"
CASSANDRA-16868,Secondary indexes on primary key columns can miss some writes,"Secondary indexes on primary key columns can miss some writes. For example, an update after a deletion won't create an index entry:
{code:java}
CREATE TABLE t (pk int, ck int, v int, PRIMARY KEY (pk, ck));
CREATE INDEX ON t(ck);
INSERT INTO t(pk, ck, v) VALUES (1, 2, 3); -- creates an index entry (right)
DELETE FROM t WHERE pk = 1 AND ck = 2; -- deletes the previous index entry (right)
UPDATE t SET v = 3 WHERE pk = 1 AND ck = 2; -- doesn't create a new index entry (wrong)
SELECT * FROM t WHERE ck = 2; -- doesn't find the row (wrong)
{code}
This happens because the update uses the {{LivenssInfo}} of the previously deleted row (see [here|https://github.com/apache/cassandra/blob/cassandra-3.0.25/src/java/org/apache/cassandra/index/internal/CassandraIndex.java#L439]). The same happens when updating an expired row:
{code:java}
CREATE TABLE t (pk int, ck int, v int, PRIMARY KEY (pk, ck));
CREATE INDEX ON t(ck);
UPDATE t USING TTL 1 SET v = 3 WHERE pk = 1 AND ck = 2; -- creates a non-expiring index entry (right)
-- wait for the expiration of the above row
SELECT * FROM t WHERE ck = 2; -- deletes the index entry (right)
UPDATE t SET v = 3 WHERE pk = 1 AND ck = 2; -- doesn't create an index entry (wrong)
SELECT * FROM t WHERE ck = 2; -- doesn't find the row (wrong)
{code}
I think that the fix for this is just using the {{getPrimaryKeyIndexLiveness}} in {{updateRow}}, as it's used in {{insertRow}}.

Another related problem is that {{getPrimaryKeyIndexLiveness}} uses [the most recent TTL in the columns contained on the indexed row fragment|https://github.com/apache/cassandra/blob/cassandra-3.0.25/src/java/org/apache/cassandra/index/internal/CassandraIndex.java#L519] as the TTL of the index entry, producing an expiring index entry that ignores the columns without TTL that are already present in flushed sstables. So we can find this other error when setting a TTL over flushed indexed data:
{code:java}
CREATE TABLE t(k1 int, k2 int, v int, PRIMARY KEY ((k1, k2)));
CREATE INDEX idx ON t(k1);
INSERT INTO t (k1, k2, v) VALUES (1, 2, 3);
-- flush
UPDATE t USING TTL 1 SET v=0 WHERE k1=1 AND k2=2; -- creates an index entry with TTL (wrong)
-- wait for TTL expiration
SELECT TTL(v) FROM t WHERE k1=1; -- doesn't find the row (wrong)
{code}
The straightforward fix is just ignoring the TTL of the columns for indexes on primary key components, so we don't produce expiring index entries in that case. The index entries will be eventually deleted during index reads, when we are sure that they are not pointing to any live data.
  "
CASSANDRA-16856,Prevent broken concurrent schema pulls,"There's a race condition around pulling schema changes, that can occur in case the schema changes push/propagation mechanism is not immediately effective (e.g. because of network delay, or because of the pulling node being down, etc.).

If schema changes happen on node 1, these changes do not reach node 2 immediately through the SCHEMA.PUSH mechanism, and are first recognized during gossiping, the corresponding SCHEMA.PULL request from node 2 can catch the node 1 schema in the middle of it being modified by another schema change request. This can easily lead to problems (e.g. if a new table is being added, and the node 2 request reads the changes that need to be applied to  system_schema.tables, but not the ones that need to be applied to system_schema.columns).

This PR addresses that by synchronizing the SCHEMA.PULL ""RPC call"" executed in node 1 by a request from node 2 with the method for applying schema changes in node 1."
CASSANDRA-16796,Clear pending ranges for a SHUTDOWN peer,"If a node involved in a MOVE operation should fail, peers can sometimes maintain pending ranges for it even when it has left the ring and/or been replaced (in practice until the peer is next bounced). This in turn can lead to bogus unavailable responses to clients if a replica for the any of the pending ranges should go down.

If the moving node crashes hard, a subsequent replacement will correctly fail as long as cassandra.consistent.rangemovement is set to true because the new node will learn the MOVING status from the remaining peers. A graceful shutdown, however, causes that status to be replaced with SHUTDOWN, but doesn't update TokenMetadata, so pending ranges remain for the down node, even after it has been removed from the ring."
CASSANDRA-16757,Fix org.apache.cassandra.distributed.upgrade.CompactStorage2to3UpgradeTest,"{color:#172b4d}[https://jenkins-cm4.apache.org/job/Cassandra-3.0/153/testReport/junit/org.apache.cassandra.distributed.upgrade/CompactStorage2to3UpgradeTest/testDropCompactWithClusteringAndValueColumn/]{color}
{code:java}
Error Message
org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 0 responses.

Stacktrace
java.lang.RuntimeException: org.apache.cassandra.exceptions.ReadTimeoutException: Operation timed out - received only 0 responses. at org.apache.cassandra.distributed.impl.IsolatedExecutor.waitOn(IsolatedExecutor.java:209) at org.apache.cassandra.distributed.impl.IsolatedExecutor.lambda$sync$5(IsolatedExecutor.java:109) at org.apache.cassandra.distributed.impl.Coordinator.executeWithResult(Coordinator.java:69) at org.apache.cassandra.distributed.api.ICoordinator.execute(ICoordinator.java:32) at org.apache.cassandra.distributed.upgrade.CompactStorage2to3UpgradeTest$ResultsRecorder.validateResults(CompactStorage2to3UpgradeTest.java:356) at
{code}
[https://jenkins-cm4.apache.org/job/Cassandra-3.0/153/testReport/junit/org.apache.cassandra.distributed.upgrade/CompactStorage2to3UpgradeTest/singleColumn/] 
{code:java}
Error Message
Metaspace

Stacktrace
java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:756) at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142) at java.net.URLClassLoader.defineClass(URLClassLoader.java:468) at java.net.URLClassLoader.access$100(URLClassLoader.java:74) at java.net.URLClassLoader$1.run(URLClassLoader.java:369) at java.net.URLClassLoader$1.run(URLClassLoader.java:363) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:362) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClassInternal(InstanceClassLoader.java:101) at org.apache.cassandra.distributed.shared.InstanceClassLoader.loadClass(InstanceClassLoader.java:87) at org.codehaus.jackson.map.deser.StdDeserializerProvider.<init>(StdDeserializerProvider.java:89) at org.codehaus.jackson.map.ObjectMapper.<init>(ObjectMapper.java:391) at org.codehaus.jackson.map.ObjectMapper.<init>(ObjectMapper.java:358) at org.codehaus.jackson.map.ObjectMapper.<init>(ObjectMapper.java:338) at org.apache.cassandra.utils.FBUtilities.<clinit>(FBUtilities.java:74) at org.apache.cassandra.distributed.impl.Instance.<init>(Instance.java:144) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper$$Lambda$2095/2058566824.apply(Unknown Source) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.newInstance(AbstractCluster.java:182) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.delegateForStartup(AbstractCluster.java:163) at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.startup(AbstractCluster.java:200) at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:189) at org.apache.cassandra.distributed.upgrade.CompactStorage2to3UpgradeTest.singleColumn(CompactStorage2to3UpgradeTest.java:109)
{code}
 

 "
CASSANDRA-16754,Flaky o.a.c.distributed.test.SchemaTest,"The JVM dtest {{org.apache.cassandra.distributed.test.SchemaTest}} is flaky:
 [https://ci-cassandra.apache.org/job/Cassandra-4.0.0/34/testReport/junit/org.apache.cassandra.distributed.test/SchemaTest/readRepairWithCompaction_2/]
{code:java}
Error Message
FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
Stacktrace
java.lang.RuntimeException: FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:582)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: FSWriteError in /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:256)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:273)
	at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.handleReplayedSegment(AbstractCommitLogSegmentManager.java:349)
	at org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:178)
	at org.apache.cassandra.distributed.impl.Instance.lambda$startup$10(Instance.java:508)
Caused by: java.nio.file.NoSuchFileException: /home/cassandra/cassandra/tmp/dtests5018452609443646984/node2/commitlog/CommitLog-7-1624286958980.log
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.implDelete(UnixFileSystemProvider.java:249)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.delete(AbstractFileSystemProvider.java:105)
	at java.base/java.nio.file.Files.delete(Files.java:1142)
	at org.apache.cassandra.io.util.FileUtils.deleteWithConfirm(FileUtils.java:250)
{code}
Although it doesn't fail frequently on CI it's quite easy to reproduce it locally.

I think the failure is caused by the two tests on the class not waiting for the future returned by {{IInstance#shutdown()}}."
CASSANDRA-16741,Remediate Cassandra 3.11.10 JAR dependency vulnerability - com.google.guava_guava,"A JAR dependency is flagged in Cassandra 3.11.10 as having vulnerabilities that have been fixed in newer releases. The following is the Cassandra 3.11.10 source tree for their JAR dependencies: [https://github.com/apache/cassandra/tree/181a4969290f1c756089b2993a638fe403bc1314/lib] . 

JAR *com.google.guava_guava* version *18.0* has the following vulnerability and is fixed in version *30.0*. Recommendation is to upgrade to version *30.1.1-jre* or greater.

 
||id||cvss||desc||link||packageName||packageVersion||severity||status||vecStr||
|CVE-2018-10237|5.9|Unbounded memory allocation in Google Guava 11.0 through 24.x before 24.1.1 allows remote attackers to conduct denial of service attacks against servers that depend on this library and deserialize attacker-provided data, because the AtomicDoubleArray class (when serialized with Java serialization) and the CompoundOrdering class (when serialized with GWT serialization) perform eager allocation without appropriate checks on what a client has sent and whether the data size is reasonable.|https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2018-10237|com.google.guava_guava|18.0|medium|fixed in 24.1.1|CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H|
|CVE-2020-8908|3.3|A temp directory creation vulnerability exists in all versions of Guava, allowing an attacker with access to the machine to potentially access data in a temporary directory created by the Guava API com.google.common.io.Files.createTempDir(). By default, on unix-like systems, the created directory is world-readable (readable by an attacker with access to the system). The method in question has been marked @Deprecated in versions 30.0 and later and should not be used. For Android developers, we recommend choosing a temporary directory API provided by Android, such as context.getCacheDir(). For other Java developers, we recommend migrating to the Java 7 API java.nio.file.Files.createTempDirectory() which explicitly configures permissions of 700, or configuring the Java runtime\'s java.io.tmpdir system property to point to a location whose permissions are appropriately configured.|https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2020-8908|com.google.guava_guava|18.0|low|fixed in 30.0|CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N|

A possible fix strategy is to simply update the JAR to their newest version.
 * See [https://mvnrepository.com/artifact/com.google.guava/guava/30.1.1-jre]"
CASSANDRA-16737,ALTER ... ADD can increase the number of SSTables being read,"With the following SSTables:
{code:java}
CREATE TABLE my_table (pk int, ck int, v1 int, PRIMARY KEY(pk, ck))

INSERT INTO my_table (pk, ck, v1) VALUES (1, 1, 1) USING TIMESTAMP 1000;
--> flush()
INSERT INTO my_table (pk, ck, v1) VALUES (1, 1, 2) USING TIMESTAMP 2000;
--> flush()
INSERT INTO my_table  (pk, ck, v1) VALUES (1, 1, 3) USING TIMESTAMP 3000
--> flush()
{code}
the following query:
{code:java}
SELECT pk, ck, v1 FROM my_table WHERE pk = 1 AND ck = 1{code}
will only read the third SSTable.

If we add a column to the table (e.g. {{ALTER TABLE my_table ADD v2 int}}) and rerun the query, the query will read the 3 SSTables.

The reason for this behavior is due to the fact that C* is trying to read all the {{fetched}} columns to ensure that it will return a row if at least one of its column is non null.

In practice for CQL tables, C* does not need to fetch all columns if the row contains a primary key liveness as it is enough to guaranty that the row exists. By consequence, even after the addition of the new column C* should read only the third SSTable."
CASSANDRA-16735,Adding columns via ALTER TABLE can generate corrupt sstables,"This is similar to CASSANDRA-13004 and was caused by CASSANDRA-15899

Basically the column placeholders introduced in 15899 can get read-repaired in to the memtable and later flushed to disk and in some cases this can conflict with the actual column (if the actual column is a collection for example) and cause CorruptSSTableExceptions.

Fix is probably to just revert 15899, at least until if and when we find a solution that we can rely on. Will post that + test next week."
CASSANDRA-16690,Flaky NativeAllocatorTest.testBookKeeping,"Flaky [here|https://ci-cassandra.apache.org/job/Cassandra-4.0/52/testReport/junit/org.apache.cassandra.utils.memory/NativeAllocatorTest/testBookKeeping_cdc/]

{noformat}
Error Message

java.lang.AssertionError: expected:<0> but was:<1>

Stacktrace

java.util.concurrent.ExecutionException: java.lang.AssertionError: expected:<0> but was:<1>
	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.cassandra.utils.memory.NativeAllocatorTest.testBookKeeping(NativeAllocatorTest.java:154)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Caused by: java.lang.AssertionError: expected:<0> but was:<1>
	at org.apache.cassandra.utils.memory.NativeAllocatorTest.lambda$testBookKeeping$2(NativeAllocatorTest.java:131)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
{noformat}
"
CASSANDRA-16681,org.apache.cassandra.utils.memory.LongBufferPoolTest - tests are flaky,"Jenkins history:

[https://jenkins-cm4.apache.org/job/Cassandra-4.0/50/testReport/junit/org.apache.cassandra.utils.memory/LongBufferPoolTest/testPoolAllocateWithRecyclePartially/history/]

Fails being run in a loop in CircleCI:

https://app.circleci.com/pipelines/github/ekaterinadimitrova2/cassandra/844/workflows/945011f4-00ac-4678-89f6-5c0db0a40169/jobs/5008

 "
CASSANDRA-16673,Avoid race in AbstractReplicationStrategy endpoint caching,"We should make sure we track which ringVersion we are caching in AbstractReplicationStrategy to avoid a race where we might return the wrong EndpointsForRange.

{code}
Caused by: java.lang.IllegalArgumentException: 9010454139840013625 is not contained within (9223372036854775801,-4611686018427387905]
	at org.apache.cassandra.locator.EndpointsForRange.forToken(EndpointsForRange.java:59)
	at org.apache.cassandra.locator.AbstractReplicationStrategy.getNaturalReplicasForToken(AbstractReplicationStrategy.java:104)
	at org.apache.cassandra.locator.ReplicaLayout.forTokenReadLiveSorted(ReplicaLayout.java:330)
	at org.apache.cassandra.locator.ReplicaPlans.forRead(ReplicaPlans.java:594)
{code}"
CASSANDRA-16671,Cassandra can return no row when the row columns have been deleted.,"It is the semantic of CQL that a (CQL) row exists as long as it has one non-null column (including the PK columns).

To determine if a row has some *non-null primary key*, Cassandra relies on the row primary key liveness. 

For example:

{code}
CREATE TABLE test (pk int, ck int, v int, PRIMARY KEY(pk, ck));
INSERT INTO test(pk, ck, v) VALUES (1, 1, 1);
DELETE v FROM test WHERE pk = 1 AND ck = 1
SELECT v FROM test;
{code}
will return
{code}
v
---
null 
{code}

{{UPDATE}} statements do not set the row primary key liveness by consequence if the user had used an {{UPDATE}} statement instead of an {{INSERT}} the {{SELECT}} query would *not have returned any rows*.

CASSANDRA-16226 introduced a regression by stopping early in the timestamp ordered logic if an {{UPDATE}} statement covering all the columns was found in an SSTable. As the row returned did not have a primary key liveness if another node was also returning a column deletion, the expected row will not be returned.

The problem can be reproduced with the following test:
{code}
   @Test
    public void testSelectWithUpdatedColumnOnOneNodeAndColumnDeletionOnTheOther() throws Throwable
    {
        try (Cluster cluster = init(builder().withNodes(2).start()))
        {
            cluster.schemaChange(withKeyspace(""CREATE TABLE %s.tbl (pk int, ck text, v int, PRIMARY KEY (pk, ck))""));
            cluster.get(1).executeInternal(withKeyspace(""INSERT INTO %s.tbl (pk, ck, v) VALUES (1, '1', 1) USING TIMESTAMP 1000""));
            cluster.get(1).flush(KEYSPACE);
            cluster.get(1).executeInternal(withKeyspace(""UPDATE %s.tbl USING TIMESTAMP 2000 SET v = 2 WHERE pk = 1 AND ck = '1'""));
            cluster.get(1).flush(KEYSPACE);

            cluster.get(2).executeInternal(withKeyspace(""DELETE v FROM %s.tbl USING TIMESTAMP 3000 WHERE pk=1 AND ck='1'""));
            cluster.get(2).flush(KEYSPACE);

            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT * FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
                       row(1, ""1"", null)); // <-- FAIL
            assertRows(cluster.coordinator(2).execute(withKeyspace(""SELECT v FROM %s.tbl WHERE pk=1 AND ck='1'""), ConsistencyLevel.ALL),
                       row((Integer) null));

        }
    }
{code}

 cc: [~maedhroz], [~ifesdjeen]

"
CASSANDRA-16638,compactions/repairs hangs (backport CASSANDRA-16552),"Hi

We meet an issue during repairs (but more probably compaction issue in fact) since we upgraded from 3.11.1 to 3.11.10.

We are using reaper, but the issue doesn't seem to come from it (according to [~adejanovski@hotmail.com] ). When the problem happens, repairs driven by reaper are blocked.

Basically reaper hangs with the message ""All nodes are busy or have too many pending compactions for the remaining candidate segments."" and indeed one node has a lot of compaction pending tasks :

 
{code:java}
$ nodetool compactionstats
pending tasks: 95
- mt_metrics.metric_32: 95 
{code}
Errors in log are :

 
{code:java}
WARN [CompactionExecutor:12909] 2021-04-28 08:59:51,241 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12909] 2021-04-28 09:00:19,484 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12908] 2021-04-28 09:00:51,241 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/d
....
WARN [CompactionExecutor:12907] 2021-04-28 08:58:51,097 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350757-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350755-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350738-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350759-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350761-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350740-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/metric_32-23300de089c311e882a61bd0fd209f48/md-350751-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/mt_metrics/
.... 
{code}

The error happened several times in few weeks and up to now always concerns LCS tables.

a.dejanoski mentioned me https://issues.apache.org/jira/browse/CASSANDRA-15242 but I have no trace of messages like ""disk boundaries are out of date for keyspacename.tablename"" or ""Refreshing disk boundary cache for keyspacename.tablename"".

The workaround is simple : just restart the node once it is identified. Pending compactions tasks rerun well.

We have the issue on 2 of our clusters on 3.11.10.
Does someone else met the issue ?"
CASSANDRA-16619,Loss of commit log data possible after sstable ingest,"SSTable metadata contains commit log positions of the sstable. These positions are used to filter out mutations from the commit log on restart and only make sense for the node on which the data was flushed.

If an SSTable is moved between nodes they may cover regions that the receiving node has not yet flushed, and result in valid data being lost should these sections of the commit log need to be replayed.

Solution:
The chosen solution introduces a new sstable metadata (StatsMetadata) - originatingHostId (UUID), which is the local host id of the node on which the sstable was created, or null if not known. Commit log intervals from an sstable are taken into account during Commit Log replay only when the originatingHostId of the sstable matches the local node's hostId.

For new sstables the originatingHostId is set according to StorageService's local hostId.
For compacted sstables the originatingHostId set according to StorageService's local hostId, and only commit log intervals from local sstables is preserved in the resulting sstable.

discovered by [~jakubzytka]
"
CASSANDRA-16607,Fix flaky test testRequestResponse – org.apache.cassandra.net.MockMessagingServiceTest,"https://ci-cassandra.apache.org/blue/organizations/jenkins/Cassandra-devbranch/detail/Cassandra-devbranch/659/tests/

{code}
Error
expected:<1> but was:<0>
Stacktrace
junit.framework.AssertionFailedError: expected:<1> but was:<0>
	at org.apache.cassandra.net.MockMessagingServiceTest.testRequestResponse(MockMessagingServiceTest.java:81)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
Standard Output
INFO  [main] 2021-04-15 08:22:46,838 YamlConfigurationLoader.java:93 - Configuration location: file:/home/cassandra/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-04-15 08:22:46,840 YamlConfigurationLoader.java:112 - Loading settings from file:/home/cassandra/cassandra/test/conf/cassandra.yaml
DEBUG [main] 2021-04-15 08:22:46,899 InternalLoggerFactory.java:63 - Using SLF4J as the default logging framework
DEBUG [main] 2021-04-15 08:22:46,911 PlatformDependent0.java:417 - -Dio.netty.noUnsaf
...[truncated 61235 chars]...
te NORMAL, token [a57d4b7f61f49471614b7ac41f16477e]
DEBUG [main] 2021-04-15 08:22:49,840 StorageService.java:2674 - New node /127.0.0.1:7069 at token a57d4b7f61f49471614b7ac41f16477e
DEBUG [main] 2021-04-15 08:22:49,848 StorageService.java:2727 - Node /127.0.0.1:7069 state NORMAL, token [a57d4b7f61f49471614b7ac41f16477e]
INFO  [main] 2021-04-15 08:22:49,848 StorageService.java:2730 - Node /127.0.0.1:7069 state jump to NORMAL
DEBUG [main] 2021-04-15 08:22:49,849 StorageService.java:1619 - NORMAL
{code}"
CASSANDRA-16601,Flaky CassandraIndexTest,"See failure [here|https://ci-cassandra.apache.org/job/Cassandra-trunk/436/testReport/junit/org.apache.cassandra.index.internal/CassandraIndexTest/indexCorrectlyMarkedAsBuildAndRemoved_cdc/]


{noformat}
Error Message

expected:<1> but was:<0>

Stacktrace

junit.framework.AssertionFailedError: expected:<1> but was:<0>
	at org.apache.cassandra.index.internal.CassandraIndexTest.indexCorrectlyMarkedAsBuildAndRemoved(CassandraIndexTest.java:588)
{noformat}

"
CASSANDRA-16592,The token function in where clause return incorrect data when using token equal condition and Specified a non-exist token value,"I get incorrect value when use query like 'select Token(pk1,pk2),pk1,pk2 from ks.table1 where token(pk1,pk2) = tokenValue'. The returned token value mismatch the where condition.

This problem is reproduced in 3.11.3 and 4.0.

Here is my schema and select statement
{code:java}
// schema
cqlsh> desc testprefix.cprefix_03 ;CREATE TABLE testprefix.cprefix_03 (
    pk1 int,
    pk2 int,
    ck1 text,
    ck2 text,
    t1 int,
    PRIMARY KEY ((pk1, pk2), ck1, ck2)
) WITH CLUSTERING ORDER BY (ck1 ASC, ck2 ASC)
    AND additional_write_policy = '99p'
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND cdc = false
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '16', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND default_time_to_live = 0
    AND extensions = {}
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair = 'BLOCKING'
    AND speculative_retry = '99p';


{code}
execute cql query
{code:java}
// code placeholder
cqlsh> SELECT Token(pk1,pk2), pk1,pk2  from testprefix.cprefix_03 WHERE  token(pk1, pk2) =-9223372036854775808 LIMIT 2; 
system.token(pk1, pk2) | pk1    | pk2
------------------------+--------+---------
   -9222849988925915479 | 394560 | 3394560
   -9222849988925915479 | 394560 | 3394560
(2 rows)

cqlsh> SELECT Token(pk1,pk2) from testprefix.cprefix_03 where pk1 = 394560 and pk2 = 3394560 LIMIT 2; 
system.token(pk1, pk2)
------------------------
   -9222849988925915479
   -9222849988925915479
(2 rows)

cqlsh> SELECT Token(pk1,pk2), pk1,pk2  from testprefix.cprefix_03 WHERE  token(pk1, pk2) =-9222849988925915479 LIMIT 2; 
system.token(pk1, pk2) | pk1    | pk2
------------------------+--------+---------
   -9222849988925915479 | 394560 | 3394560
   -9222849988925915479 | 394560 | 3394560
(2 rows){code}
we can find  that token value in the condition  are inconsistent with the values in the result.

--------------------------------------------------------------------------------------------

Then review the source code, to seek the anwser. 
{code:java}
// code placeholder
private static void addRange(SSTableReader sstable, AbstractBounds<PartitionPosition> requested, List<AbstractBounds<PartitionPosition>> boundsList)
{
    if (requested instanceof Range && ((Range)requested).isWrapAround())    //  first condition
    {
        if (requested.right.compareTo(sstable.first) >= 0)
        {
            // since we wrap, we must contain the whole sstable prior to stopKey()
            Boundary<PartitionPosition> left = new Boundary<PartitionPosition>(sstable.first, true);
            Boundary<PartitionPosition> right;
            right = requested.rightBoundary();
            right = minRight(right, sstable.last, true);
            if (!isEmpty(left, right))
                boundsList.add(AbstractBounds.bounds(left, right));
        }
        if (requested.left.compareTo(sstable.last) <= 0)
        {
            // since we wrap, we must contain the whole sstable after dataRange.startKey()
            Boundary<PartitionPosition> right = new Boundary<PartitionPosition>(sstable.last, true);
            Boundary<PartitionPosition> left;
            left = requested.leftBoundary();
            left = maxLeft(left, sstable.first, true); // second condition
            if (!isEmpty(left, right))
                boundsList.add(AbstractBounds.bounds(left, right));
        }
    }
    else
    {
        assert requested.left.compareTo(requested.right) <= 0 || requested.right.isMinimum();
        Boundary<PartitionPosition> left, right;
        left = requested.leftBoundary();
        right = requested.rightBoundary();
        left = maxLeft(left, sstable.first, true);
        // apparently isWrapAround() doesn't count Bounds that extend to the limit (min) as wrapping
        right = requested.right.isMinimum() ? new Boundary<PartitionPosition>(sstable.last, true)
                                                : minRight(right, sstable.last, true);
        if (!isEmpty(left, right))
            boundsList.add(AbstractBounds.bounds(left, right));
    }
}
{code}
 * we use token equal ,so isWrapAround is true.
 * requestd.left = requestd.right = -9223372036854775808,
 * the real sst dataBoundary.left = -9222849988925915479
 * so the maxLeft return the real dataBoudary.left. We get the incorrect  data

 "
CASSANDRA-16581,Failure to execute queries should emit a KPI other than read timeout/unavailable so it can be alerted/tracked,When we are unable to parse a message we do not have a way to detect this from a monitoring point of view so can get into situations where we believe the database is fine but the clients are on-fire.  This case popped up in the 2.1 to 3.0 upgrade as paging state wasn’t mixed-mode safe.
CASSANDRA-16578,NativeLibrary#getProcessID() does not handle `UnsatisfiedLinkError`,"NativeLibrary#getProcessID() does not handle `UnsatisfiedLinkError` (derived from Error, not Exception) as the other native methods do. Therefore, it can never return -1 when it fails for this reason, and can break callers that would otherwise be able to handle the situation gracefully. Most other methods in the class do this, but this one is missing the handling of this error."
CASSANDRA-16577,Node waits for schema agreement on removed nodes,"CASSANDRA-15158 might have introduced a bug where bootstrapping nodes wait for schema agreement from nodes that have been removed if token allocation for keyspace is enabled.

 

It is fairly easy to reproduce with the following steps:
{noformat}
// Create 3 node cluster
ccm create test --vnodes -n 3 -s -v 3.11.10

// Remove two nodes
ccm node2 decommission
ccm node3 decommission
ccm node2 remove
ccm node3 remove

// Create keyspace to change the schema. It works if the schema never changes.
ccm node1 cqlsh -x ""CREATE KEYSPACE k WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};""

// Add allocate parameter
ccm updateconf 'allocate_tokens_for_keyspace: k'

// Add node2 again to cluster
ccm add node2 -i 127.0.0.2 -j 7200 -r 2200
ccm node2 start{noformat}
 

This will cause node2 to throw exception on startup:
{noformat}
WARN  [main] 2021-04-08 14:10:53,272 StorageService.java:941 - There are nodes in the cluster with a different schema version than us we did not merged schemas from, our version : (a5da47ec-ffe3-3111-b2f3-325f771f1539), outstanding versions -> endpoints : {8e9ec79e-5ed2-3949-8ac8-794abfee3837=[/127.0.0.3]}
ERROR [main] 2021-04-08 14:10:53,274 CassandraDaemon.java:803 - Exception encountered during startup
java.lang.RuntimeException: Didn't receive schemas for all known versions within the timeout
        at org.apache.cassandra.service.StorageService.waitForSchema(StorageService.java:947) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.dht.BootStrapper.allocateTokens(BootStrapper.java:206) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.dht.BootStrapper.getBootstrapTokens(BootStrapper.java:177) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:1073) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:753) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.StorageService.initServer(StorageService.java:687) ~[apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:395) [apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:633) [apache-cassandra-3.11.10.jar:3.11.10]
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:786) [apache-cassandra-3.11.10.jar:3.11.10]
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,279 HintsService.java:209 - Paused hints dispatch
WARN  [StorageServiceShutdownHook] 2021-04-08 14:10:53,280 Gossiper.java:1670 - No local state, state is in silent shutdown, or node hasn't joined, not announcing shutdown
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,280 MessagingService.java:985 - Waiting for messaging service to quiesce
INFO  [ACCEPT-/127.0.0.2] 2021-04-08 14:10:53,281 MessagingService.java:1346 - MessagingService has terminated the accept() thread
INFO  [StorageServiceShutdownHook] 2021-04-08 14:10:53,416 HintsService.java:209 - Paused hints dispatch{noformat}
 

 

 "
CASSANDRA-16495,Scheduled (Delayed) Schema Pull Tasks May Run After MIGRATION Stage Shutdown During Decommission,"A new test added in CASSANDRA-16181 stumbled across this, although it doesn’t happen consistently. When [failure occurs|https://app.circleci.com/pipelines/github/maedhroz/cassandra/235/workflows/eb8133ce-9373-4136-b404-ceca167353f6/jobs/1355/tests], it appears to be because a delayed schema pull happens after decommission shuts down the MIGRATION stage’s thread pool.

{noformat}
ERROR [node1_isolatedExecutor:1] node1 2021-02-15 19:35:36,284 CassandraDaemon.java:579 - Exception in thread Thread[node1_NonPeriodicTasks:1,5,node1] java.util.concurrent.RejectedExecutionException: ThreadPoolExecutor has shut down at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1.rejectedExecution(DebuggableThreadPoolExecutor.java:72) 
at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825) 
at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355) 
at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor.execute(DebuggableThreadPoolExecutor.java:176) 
at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:118) at org.apache.cassandra.concurrent.Stage.submit(Stage.java:129) 
at org.apache.cassandra.schema.MigrationCoordinator.lambda$scheduleSchemaPull$2(MigrationCoordinator.java:362) 
at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264) 
at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) 
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) 
at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) 
at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) 
at java.base/java.lang.Thread.run(Thread.java:834)
{noformat}

A fix might be as simple as shutting down ScheduledExecutors.nonPeriodicTasks in StorageService#decommission(). See the original discussion [here|https://issues.apache.org/jira/browse/CASSANDRA-16181?focusedCommentId=17293329&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17293329]."
CASSANDRA-16483,ColumnFilter::toString doesn't return a valid CQL fragment,"This was changed in CASSANDRA-16415 to include indications about queried vs fetched reagular & static columns. However, the result is used by {{AbstractReadQuery::toCQLString}}, which causes it to produce an illegal query string.

This breaks a couple of dtests because they're looking for CQL strings in logs, which are no longer found:
* {{upgrade_tests/paging_test.py::TestPagingWithDeletions::test_failure_threshold_deletions}}
* {{cql_test.py::TestCQLSlowQuery}} has a couple of failing tests, {{test_local_query/test_remote_query}}

We should also check audit and fql logs (and any other place where {{toCQLString}} is used.
"
CASSANDRA-16457,Hint messages are incorrectly re-serialized for filtering in in-jvm dtests,"Hint messages for dropped tables can still be dispatched, but they’re ignored on the receiving side all usual code paths. Since we’re attempting to re-serialize hint message for dropped table in in-jvm tests, we exercise path that is impossible in regular code, and for which there is no protocol specification. 


Stack trace: 

{code}
INFO  [AsyncAppender-Worker-ASYNC] 2021-02-17 18:50:13,759 SubstituteLogger.java:169 - ERROR [MutationStage-2] 2021-02-17 18:50:13,726 AbstractLocalAwareExecutorService.java:166 - Uncaught exception on thread Thread[MutationStage-2,5,node4]
java.lang.NullPointerException: null
	at org.apache.cassandra.hints.Hint$Serializer.serializedSize(Hint.java:150)
	at org.apache.cassandra.hints.HintMessage$Serializer.serializedSize(HintMessage.java:86)
	at org.apache.cassandra.hints.HintMessage$Serializer.serializedSize(HintMessage.java:77)
	at org.apache.cassandra.net.Message$Serializer.payloadSize(Message.java:1289)
	at org.apache.cassandra.net.Message$Serializer.access$1200(Message.java:607)
	at org.apache.cassandra.net.Message.payloadSize(Message.java:1341)
	at org.apache.cassandra.net.Message.access$900(Message.java:66)
	at org.apache.cassandra.net.Message$Serializer.serializePost40(Message.java:759)
	at org.apache.cassandra.net.Message$Serializer.serialize(Message.java:618)
	at org.apache.cassandra.distributed.impl.Instance.serializeMessage(Instance.java:322)
	at org.apache.cassandra.distributed.impl.Instance.lambda$registerInboundFilter$4(Instance.java:273)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:62)
	at org.apache.cassandra.net.InboundSink$Filtered.accept(InboundSink.java:49)
	at org.apache.cassandra.net.InboundSink.accept(InboundSink.java:93)
	at org.apache.cassandra.distributed.impl.Instance.lambda$null$6(Instance.java:365)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:119)
	at relocated.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
{code}"
CASSANDRA-16428,Fix selections of JDKs in debian docker images on arm64,"The debian docker [image|https://github.com/apache/cassandra-builds/blob/trunk/docker/buster-image.docker] used by the [cassandra-deb-packaging.sh|https://github.com/apache/cassandra-builds/blob/trunk/build-scripts/cassandra-deb-packaging.sh] tries to set the jdk like
{code}
update-java-alternatives --set java-1.8.0-openjdk-amd64
{code}

This won't work on arm64.
Suggestion is to replace it with the following:
{code}
update-java-alternatives --set $(update-java-alternatives -l | cut -d"" "" -f1 | grep java-1.8)
{code}"
CASSANDRA-16427,In-JVM dtest paging does not handle Group By correctly,"In-JVM dtest paging is using a pager that disregards the type of the executed query, resulting into `GROUP BY` queries being executed like normal SELECT queries without GROUP BY clause."
CASSANDRA-16415,Digest mismatches during upgrade,"The test has been failing and can always be reproduced in the recent CI. 

Stack trace: 
{code:java}
junit.framework.AssertionFailedError: Found Digest Mismatch
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.checkTraceForDigestMismatch(MixedModeReadTest.java:89)
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.lambda$mixedModeReadColumnSubsetDigestCheck$0(MixedModeReadTest.java:63)
 at org.apache.cassandra.distributed.upgrade.UpgradeTestBase$TestCase.run(UpgradeTestBase.java:171)
 at org.apache.cassandra.distributed.upgrade.MixedModeReadTest.mixedModeReadColumnSubsetDigestCheck(MixedModeReadTest.java:76) {code}
The initial investigation shows that 
 * The test only fails in the setup phase of mixedModeReadColumnSubsetDigestCheck. The cluster version is *Versions.Major.v3X*
 * The test failure is likely a consequence of CASSANDRA-15962. After dropping the commit in branch cassandra-3.11 and rebuild the dtest jar, the upgrade test can pass. Meanwhile, dropping the other commits does not help. "
CASSANDRA-16394,Fix schema aggreement race conditions in in-JVM dtests ,"There there are two race conditions in in-JVM dtest schema agreement, which are causing test failures:

1. First is caused by the fact we’re starting waiting for schema propagation already after the schema agreement was reached (which was resulting into us endlessly waiting for an agreement that has already been established);
 2. The other one was because the callback to notify about successful agreement can be triggered already after the other node has notified about it, and control flow might have moved cluster to a different configuration.

Example of exception:
{code:java}
Caused by: java.lang.IllegalStateException: Schema agreement not reached
	at org.apache.cassandra.distributed.impl.AbstractCluster$ChangeMonitor.waitForCompletion(AbstractCluster.java:?)
	at org.apache.cassandra.distributed.impl.AbstractCluster.lambda$schemaChange$5(AbstractCluster.java:?)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:?)
	at java.util.concurrent.FutureTask.run(FutureTask.java:?)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:?)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:?)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:?)
	at java.lang.Thread.run(Thread.java:?)
{code}"
CASSANDRA-16387,UpgradeTest sporadically failing on schema updates,"We’ve observed {{UpdateTest}} failing during what appears to be a schema change:

https://app.circleci.com/pipelines/github/maedhroz/cassandra/192/workflows/ed5305e6-e4f9-420e-9f0a-6153333746dc/jobs/1068

It almost looks like the Gossiper can’t find its own endpoint state in the endpoint state map, and the failure is not consistent, which might suggest a race."
CASSANDRA-16307,GROUP BY queries with paging can return deleted data,"{{GROUP BY}} queries using paging and CL>ONE/LOCAL_ONE. This dtest reproduces the problem:
{code:java}
try (Cluster cluster = init(Cluster.create(2)))
{
    cluster.schemaChange(withKeyspace(""CREATE TABLE %s.t (pk int, ck int, PRIMARY KEY (pk, ck))""));
    ICoordinator coordinator = cluster.coordinator(1);
    coordinator.execute(withKeyspace(""INSERT INTO %s.t (pk, ck) VALUES (0, 0)""), ConsistencyLevel.ALL);
    coordinator.execute(withKeyspace(""INSERT INTO %s.t (pk, ck) VALUES (1, 1)""), ConsistencyLevel.ALL);
    
    cluster.get(1).executeInternal(withKeyspace(""DELETE FROM %s.t WHERE pk=0 AND ck=0""));
    cluster.get(2).executeInternal(withKeyspace(""DELETE FROM %s.t WHERE pk=1 AND ck=1""));
    String query = withKeyspace(""SELECT * FROM %s.t GROUP BY pk"");
    Iterator<Object[]> rows = coordinator.executeWithPaging(query, ConsistencyLevel.ALL, 1);
    assertRows(Iterators.toArray(rows, Object[].class));
}
{code}
Using a 2-node cluster and RF=2, the test inserts two partitions in both nodes. Then it locally deletes each row in a separate node, so each node sees a different partition alive, but reconciliation should produce no alive partitions. However, a {{GROUP BY}} query using a page size of 1 wrongly returns one of the rows.

This has been detected during CASSANDRA-16180, and it is probably related to CASSANDRA-15459, which solved a similar problem for group-by queries with limit, instead of paging."
CASSANDRA-16294,Potential NPE in JVMStabilityInspector,"On either a FileNotFoundException or SocketException, JVMStabilityInspector checks the error message for the string ""Too many open files"". However, both of these exceptions have a constructor which sets a null message, which can lead to NPE if handled."
CASSANDRA-16261,Prevent unbounded number of flushing tasks,"The cleaner thread is not prevented from queueing an unbounded number of flushing tasks for memtables that are almost empty.

This patch adds a mechanism to track the number of pending flushing
tasks in the memtable cleaner. Above the maximum number (2x the flushing
threads by default), only memtables using at least MCT memory will be
flushed, where MCT stands for Memory Cleanup Threshold.

This patch also fixes a possible problem tracking the memory marked as
""reclaiming"" in the memtable allocators and pool. Writes that complete
only after a memtable has been scheduled for flushing, did not report
their memory as reclaiming. Normally this should be a small value of no
consequence, but if the flushing tasks are blocked for a long period,
and there is a sufficient number of writes, or these writes use
a sufficiently large quantity of memory, this would cause the memtable
cleaning algorithm to schedule repeated flushing tasks because the used
memory is always > reclaiming memory + MCT."
CASSANDRA-16259,tablehistograms cause ArrayIndexOutOfBoundsException,"After upgrading some nodes in our cluster from 3.11.8 to 3.11.9 an error appeared on the upgraded nodes when trying to access *tablehistograms*. The same command run on our .8 nodes return as expected, only the upgraded .9 nodes fail. Not all tables fail when queried, but about 90% of them do.

We use Datastax MCAC which appears to query histograms every 30 seconds, this outputs to the system.log:
{noformat}
WARN  [insights-3-1] 2020-11-09 01:11:22,331 UnixSocketClient.java:830 - Error reporting:
java.lang.ArrayIndexOutOfBoundsException: 115
    at org.apache.cassandra.metrics.TableMetrics.combineHistograms(TableMetrics.java:261) ~[apache-cassandra-3.11.9.jar:3.11.9]
    at org.apache.cassandra.metrics.TableMetrics.access$000(TableMetrics.java:48) ~[apache-cassandra-3.11.9.jar:3.11.9]
    at org.apache.cassandra.metrics.TableMetrics$11.getValue(TableMetrics.java:376) ~[apache-cassandra-3.11.9.jar:3.11.9]
    at org.apache.cassandra.metrics.TableMetrics$11.getValue(TableMetrics.java:373) ~[apache-cassandra-3.11.9.jar:3.11.9]
    at com.datastax.mcac.UnixSocketClient.writeMetric(UnixSocketClient.java:839) [datastax-mcac-agent.jar:na]
    at com.datastax.mcac.UnixSocketClient.access$700(UnixSocketClient.java:78) [datastax-mcac-agent.jar:na]
    at com.datastax.mcac.UnixSocketClient$2.lambda$onGaugeAdded$0(UnixSocketClient.java:626) ~[datastax-mcac-agent.jar:na]
    at com.datastax.mcac.UnixSocketClient.writeGroup(UnixSocketClient.java:819) [datastax-mcac-agent.jar:na]
    at com.datastax.mcac.UnixSocketClient.lambda$restartMetricReporting$2(UnixSocketClient.java:798) [datastax-mcac-agent.jar:na]
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_272]
    at io.netty.util.concurrent.ScheduledFutureTask.run(ScheduledFutureTask.java:126) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:399) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
    at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:307) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_272]{noformat}
Manually trying a histogram from the CLI:
{noformat}
$ nodetool tablehistograms logdata log_height_index
error: 115
-- StackTrace --
java.lang.ArrayIndexOutOfBoundsException: 115
	at org.apache.cassandra.metrics.TableMetrics.combineHistograms(TableMetrics.java:261)
	at org.apache.cassandra.metrics.TableMetrics.access$000(TableMetrics.java:48)
	at org.apache.cassandra.metrics.TableMetrics$11.getValue(TableMetrics.java:376)
	at org.apache.cassandra.metrics.TableMetrics$11.getValue(TableMetrics.java:373)
	at org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxGauge.getValue(CassandraMetricsRegistry.java:250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)
	at com.sun.jmx.remote.security.MBeanServerAccessController.getAttribute(MBeanServerAccessController.java:320)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1445)
	at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1408)
	at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:639)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{noformat}"
CASSANDRA-16228,TableMetrics are exposed before ColumnFamilyStore is fully initialized,"The {{ColumnFamilyStore}} exposes the {{TableMetrics}} before it is fully initialized, due to that it is possible to perform a call via the metrics that access uninitialized part of the {{ColumnFamilyStore}}. 

The following test can be added to ColumnFamilyMetricTest to show the issue:
{code:java}
@Test
public void testStartupRaceConditionOnMetricListeners()
{
 // Since the ColumnFamilyStore instance reference escapes during the construction
 // we have a race condition and listeners can see an instance that is in an unknown state.
 // This test just check that all callbacks can access the data without throwing any exception.
 registerMetricListener();
 SchemaLoader.createKeyspace(""Keyspace2"",
 KeyspaceParams.simple(1),
 SchemaLoader.standardCFMD(""Keyspace2"", ""Standard2""));
}

private void registerMetricListener()
{
 CassandraMetricsRegistry.Metrics.addListener(new MetricRegistryListener.Base()
 {
 @Override
 public void onGaugeAdded(String name, Gauge<?> gauge)
 {
 gauge.getValue();
 }

 @Override
 public void onGaugeRemoved(String name)
 {

 }

 @Override
 public void onCounterAdded(String name, Counter counter)
 {
 counter.getCount();
 }

 @Override
 public void onCounterRemoved(String name)
 {

 }

 @Override
 public void onHistogramAdded(String name, Histogram histogram)
 {
 histogram.getCount();
 }

 @Override
 public void onHistogramRemoved(String name)
 {

 }

 @Override
 public void onMeterAdded(String name, Meter meter)
 {
 meter.getCount();
 }

 @Override
 public void onMeterRemoved(String name)
 {

 }

 @Override
 public void onTimerAdded(String name, Timer timer)
 {
 timer.getCount();
 }

 @Override
 public void onTimerRemoved(String name)
 {

 }
 });{code}

While looking into that ticket we also discovered a problem with the used of {{Metered}} in {{CacheMetrics}}.
Metrics reporter looks for metrics classes that are instance of the standard codahale classes. Due to that, other Metered implementations are not be exposed through the reporter. This ticket will also address that issue."
CASSANDRA-16223,Reading dense table yields invalid results in case of row scan queries,"{{ThriftIntegrationTest}} is broken in the way that it does not actually test reads before and after flushing, because it does not do flush at all (see https://github.com/apache/cassandra/blob/cassandra-3.11/test/unit/org/apache/cassandra/cql3/validation/ThriftIntegrationTest.java#L939). After fixing that method so that it really flushes memtables to disk, we can see inconsistency in reads from dense table - the results returned from memtable differs from the results returned from sstable (the later are wrong, cell values are skipped unexpectedly).

{noformat}
java.lang.AssertionError: Invalid value for row 0 column 0 (value of type ascii), expected <value1> but got <>
{noformat}

In principle this problems is about skipping column values when doing row scan queries with explicitly selected columns (not wildcard), when the columns belong to a super column. This happens only when reading from sstables, it does not happen when reading from memtables.
"
CASSANDRA-16210,Synchronize Keyspace instance store/clear,DTest failure: dtest-large.repair_tests.repair_test.TestRepairDataSystemTable.test_repair_table (vnodes) - one random failure was reported which pointed to a race condition to be spotted. 
CASSANDRA-16207,NPE when calling broadcast address on unintialized node,"When trying to run upgrades, sometimes we’re calling broadcasts addrerss on an uninitialised new node:

{code}
java.lang.IllegalStateException: Can't use shut down instances, delegate is null
	at org.apache.cassandra.distributed.impl.AbstractCluster$Wrapper.delegate(AbstractCluster.java:163)
	at org.apache.cassandra.distributed.impl.DelegatingInvokableInstance.broadcastAddress(DelegatingInvokableInstance.java:53) 
	at org.apache.cassandra.distributed.impl.Instance$2.allowIncomingMessage(Instance.java:278) 
	at org.apache.cassandra.net.MessagingService.receive(MessagingService.java:1031) ~[dtest-3.0.19.jar:?]
	at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:213) 
	at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:182) 
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:93) 
{code}"
CASSANDRA-16201,Reduce amount of allocations during batch statement execution,"In a Cas 2.1 / 3.0 / 3.11 / 4.0b2 comparison test with the same load profile, we see 4.0b2 going OOM from time to time. According to a heap dump, we have multiple NTR threads in a 3-digit MB range.

This is likely related to object array pre-allocations at the size of {{BatchUpdatesCollector.updatedRows}} per {{BTree}} although there is always only 1 {{BTreeRow}} in the {{BTree}}.
 !screenshot-1.png|width=100%! 

So it seems we have many, many 20K elemnts pre-allocated object arrays resulting in a shallow heap of 80K each, although there is only one element in the array.

This sort of pre-allocation is causing a lot of memory pressure.
"
CASSANDRA-16156,Decomissioned nodes are picked for gossip when unreachable nodes are considered for gossiping ,"After node is decommissioned, it is still considered for gossip via “unreachable” nodes, which results into following exceptions:
 
{code}
INFO  [node4_Messaging-EventLoop-3-3] node4 2020-09-29 16:37:37,527 NoSpamLogger.java:91 - /127.0.0.4:7012->/127.0.0.1:7012-URGENT_MESSAGES-[no-channel] failed to connect
io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /127.0.0.1:7012
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:702)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:576)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)
 {code}

Trace of the method that attempts to establish connection:

{code} 
org.apache.cassandra.net.MessagingService.getOutbound(MessagingService.java:492)
	at org.apache.cassandra.net.MessagingService.doSend(MessagingService.java:335)
	at org.apache.cassandra.net.OutboundSink$Filtered.accept(OutboundSink.java:55)
	at org.apache.cassandra.net.OutboundSink.accept(OutboundSink.java:70)
	at org.apache.cassandra.net.MessagingService.send(MessagingService.java:327)
	at org.apache.cassandra.net.MessagingService.send(MessagingService.java:314)
	at org.apache.cassandra.gms.Gossiper.sendGossip(Gossiper.java:813)
	at org.apache.cassandra.gms.Gossiper.maybeGossipToUnreachableMember(Gossiper.java:840)
	at org.apache.cassandra.gms.Gossiper.access$400(Gossiper.java:86)
 {code}

LEFT and other nodes that are considered dead should not be picked for gossip with unreachable nodes."
CASSANDRA-16127,NullPointerException when calling nodetool enablethrift,"Having thrift disabled, it's impossible to enable it again without restarting the node:
{code}
$ nodetool statusthrift
not running
$ nodetool enablethrift
error: null
-- StackTrace --
java.lang.NullPointerException
	at org.apache.cassandra.service.StorageService.startRPCServer(StorageService.java:392)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468)
	at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
{code}
"
CASSANDRA-16124,nodetool enablebinary throws exception,"I think there is a bug in 3.11.8, if you disable the Native port its not possible to enable it (without restarting Cassandra).
{quote}> nodetool statusbinary
 running
 > nodetool disablebinary
 > nodetool statusbinary
 not running
 > nodetool enablebinary
 error: Error starting native transport: setup() must be called first for CassandraDaemon
 – StackTrace –
 java.lang.RuntimeException: Error starting native transport: setup() must be called first for CassandraDaemon
 at org.apache.cassandra.service.StorageService.startNativeTransport(StorageService.java:429)
 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
 at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
 at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
 at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
 at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
 at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
 at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
 at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
 at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
 at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468)
 at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
 at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
 at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401)
 at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829)
 at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
 at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 at java.lang.reflect.Method.invoke(Method.java:498)
 at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
 at sun.rmi.transport.Transport$1.run(Transport.java:200)
 at sun.rmi.transport.Transport$1.run(Transport.java:197)
 at java.security.AccessController.doPrivileged(Native Method)
 at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
 at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568)
 at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)
 at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683)
 at java.security.AccessController.doPrivileged(Native Method)
 at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
{quote}
I think this was introduced with CASSANDRA-15967. In {{CassandraDaemon.stopNativeTransport()}} {{nativeTransportService}} is set to {{null}} and when {{CassandraDaemon.startNativeTransport()}} is called the exception is thrown. By adding a call to {{CassandraDaemon.initializeNativeTransport()}} before calling {{CassandraDaemon.startNativeTransport()}} works but I'm not sure what the intention here is."
CASSANDRA-16112,in-jvm dtests should validate Instance#serializeMessage serializeSize matches bytes written,In 3.0 sizeOf is an optimization but in 4.0 its used for message header and as such must be correct; this check is not done when mock messaging is used so may ignore mixed-mode issues.
CASSANDRA-16072,Reduce thread contention in CommitLogSegment and HintsBuffer by rewriting CAS loops to atomic adds,"Follow up to CASSANDRA-15922

Both CommitLogSegment and HintsBuffer use AtomicIntegers for the current offset when allocating. Like in CASSANDRA\-15922 the loops on {{.compareAndSet(..)}} can be replaced with atomic adds using the {{. getAndAdd(..)}} method.

In highly contended environments the CAS failures can be high, starving writes in a running Cassandra node. On the same cluster CASSANDRA\-15922 was found, after CASSANDRA\-15922's fix was deployed, there was still problems around commit log flushing and hints. No flamegraph was collected that demonstrated the thread contention as clearly as was found in CASSANDRA\-15922, but the performance fix proposed here hopefully is obvious enough."
CASSANDRA-16071,max_compaction_flush_memory_in_mb is interpreted as bytes,"In CASSANDRA-12662, [~scottcarey] [reported|https://issues.apache.org/jira/browse/CASSANDRA-12662?focusedCommentId=17070055&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-17070055] that the {{max_compaction_flush_memory_in_mb}} setting gets incorrectly interpreted in bytes rather than megabytes as its name implies.

{quote}
1.  the setting 'max_compaction_flush_memory_in_mb' is a misnomer, it is actually memory in BYTES.  If you take it at face value, and set it to say, '512' thinking that means 512MB,  you will produce a million temp files rather quickly in a large compaction, which will exhaust even large values of max_map_count rapidly, and get the OOM: Map Error issue above and possibly have a very difficult situation to get a cluster back into a place where nodes aren't crashing while initilaizing or soon after.  This issue is minor if you know about it in advance and set the value IN BYTES.
{quote}

"
CASSANDRA-16063,Fix user experience when upgrading to 4.0 with compact tables,"The code to handle compact tables has been removed from 4.0, and the intended upgrade path to 4.0 for users having compact tables on 3.x is that they must execute {{ALTER ... DROP COMPACT STORAGE}} on all of their compact tables *before* attempting the upgrade.

Obviously, some users won't read the upgrade instructions (or miss a table) and may try upgrading despite still having compact tables. If they do so, the intent is that the node will _not_ start, with a message clearly indicating the pre-upgrade step the user has missed. The user will then downgrade back the node(s) to 3.x, run the proper {{ALTER ... DROP COMPACT STORAGE}}, and then upgrade again.

But while 4.0 does currently fail startup when finding any compact tables with a decent message, I believe the check is done too late during startup.

Namely, that check is done as we read the tables schema, so within [{{Schema.instance.loadFromDisk()}}|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/CassandraDaemon.java#L241].  But by then, we've _at least_ called {{SystemKeyspace.persistLocalMetadata()}}} and {{SystemKeyspaceMigrator40.migrate()}}, which will get into the commit log, and even possibly flush new {{na}} format sstables. As a results, a user might not be able to seemlessly restart the node on 3.x (to drop compact storage on the appropriate tables).

Basically, we should make sure the check for compact tables done at 4.0 startup is done as a {{StartupCheck}}, before the node does anything.

We should also add a test for this (checking that if you try upgrading to 4.0 with compact storage, you can downgrade back with no intervention whatsoever).
"
CASSANDRA-15984,thrift_hsha_test.TestThriftHSHA test_closing_connections is broken on 3.0 and 3.11,"This test seems to have been broken on 3.0 for a while now; I ran Circle CI with HIGHER configs from ab6a87bf60174d9a6e7cd727702da3004c0dbeeb (from Jul 6 18:05:18 2020)  all the way to HEAD ebf9c74c4ea8aefb1262458664571fdb52b76102 (from Jul 24 18:47:39 2020).

Interestingly, when I run the test locally against latest 3.0 it passes.

This is not a flaky test, as it fails on no-vnode and vnode for every attempt (tried 9 times)

{code}
        if rc != 0:
>           raise ToolError(cmd_args, rc, out, err)
E           ccmlib.node.ToolError: Subprocess ['nodetool', '-h', 'localhost', '-p', '7100', 'enablethrift'] exited with non-zero status; exit status: 2; 
E           stderr: error: Could not create ServerSocket on address /127.0.0.1:9160.
E           -- StackTrace --
E           org.apache.thrift.transport.TTransportException: Could not create ServerSocket on address /127.0.0.1:9160.
E           	at org.apache.thrift.transport.TNonblockingServerSocket.<init>(TNonblockingServerSocket.java:96)
E           	at org.apache.thrift.transport.TNonblockingServerSocket.<init>(TNonblockingServerSocket.java:79)
E           	at org.apache.thrift.transport.TNonblockingServerSocket.<init>(TNonblockingServerSocket.java:75)
E           	at org.apache.cassandra.thrift.TCustomNonblockingServerSocket.<init>(TCustomNonblockingServerSocket.java:39)
E           	at org.apache.cassandra.thrift.THsHaDisruptorServer$Factory.buildTServer(THsHaDisruptorServer.java:80)
E           	at org.apache.cassandra.thrift.TServerCustomFactory.buildTServer(TServerCustomFactory.java:55)
E           	at org.apache.cassandra.thrift.ThriftServer$ThriftServerThread.<init>(ThriftServer.java:128)
E           	at org.apache.cassandra.thrift.ThriftServer.start(ThriftServer.java:55)
E           	at org.apache.cassandra.service.StorageService.startRPCServer(StorageService.java:386)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
E           	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
E           	at java.lang.reflect.Method.invoke(Method.java:498)
E           	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
E           	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
E           	at java.lang.reflect.Method.invoke(Method.java:498)
E           	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
E           	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
E           	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
E           	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
E           	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
E           	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
E           	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
E           	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
E           	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468)
E           	at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
E           	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
E           	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401)
E           	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
E           	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
E           	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
E           	at java.lang.reflect.Method.invoke(Method.java:498)
E           	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
E           	at sun.rmi.transport.Transport$1.run(Transport.java:200)
E           	at sun.rmi.transport.Transport$1.run(Transport.java:197)
E           	at java.security.AccessController.doPrivileged(Native Method)
E           	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
E           	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:573)
E           	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:834)
E           	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:688)
E           	at java.security.AccessController.doPrivileged(Native Method)
E           	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:687)
E           	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
E           	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
E           	at java.lang.Thread.run(Thread.java:748)

../env/src/ccm/ccmlib/node.py:2162: ToolError
{code}"
CASSANDRA-15938,Fix support for adding UDT fields to clustering keys,"Adding UDT fields to clustering keys is broken in all versions, however slightly differently.

In 4.0, there will be a brief moment while schema changes are propagated during which we won’t be able to decode and compare byte sequences. Unfortunately, it is unclear what we should do in such cases, since we can’t just come up with a comparator, and we can’t ignore non-null trailing values, since this will lead to cases where compare for tuples `a;1` and `a;2` would return 0, effectively making them equal, and we don’t know how to compare unknown trailing values. Probably we should reject such query since we can’t sort correctly, but we should make the error message more descriptive than just ""Index 1 out of bounds for length 1”. The only problem is that we get this exception only on flush right now, so data already propagates to the node by that time.

In 3.0, the problem is a bit worse than that, since in 3.0 we do not ignore trailing nulls, so some of the values, written before `ALTER TYPE .. ADD` become inaccessible. Both old values, and the new ones should always be accessible.
"
CASSANDRA-15924,Avoid emitting empty range tombstones from RangeTombstoneList,"In {{RangeTombstoneList#iterator}} there is a chance we emit empty range tombstones depending on the slice passed in. This can happen during read repair with either an empty slice or with paging and the final page being empty.

This creates problems in RTL if we try to insert a new range tombstone which covers the empty ones;
{code}
Caused by: java.lang.AssertionError
	at org.apache.cassandra.db.RangeTombstoneList.insertFrom(RangeTombstoneList.java:541)
	at org.apache.cassandra.db.RangeTombstoneList.addAll(RangeTombstoneList.java:217)
	at org.apache.cassandra.db.MutableDeletionInfo.add(MutableDeletionInfo.java:141)
	at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:137)
	at org.apache.cassandra.db.Memtable.put(Memtable.java:254)
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1210)
	at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:573)
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:421)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:210)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:215)
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:224)
	at org.apache.cassandra.cql3.statements.ModificationStatement.executeInternalWithoutCondition(ModificationStatement.java:582)
	at org.apache.cassandra.cql3.statements.ModificationStatement.executeInternal(ModificationStatement.java:572)
{code}"
CASSANDRA-15922,High CAS failures in NativeAllocator.Region.allocate(..) ,"h4. Problem

The method {{NativeAllocator.Region.allocate(..)}} uses an {{AtomicInteger}} for the current offset in the region. Allocations depends on a {{.compareAndSet(..)}} call.

In highly contended environments the CAS failures can be high, starving writes in a running Cassandra node.

h4. Example

It has been witnessed up to 33% of CPU time stuck in the {{NativeAllocator.Region.allocate(..)}} loop (due to the CAS failures) during a heavy spark analytics write load.

These nodes: 40 CPU cores and 256GB ram; have relevant settings
 - {{memtable_allocation_type: offheap_objects}}
 - {{memtable_offheap_space_in_mb: 5120}}
 - {{concurrent_writes: 160}}

Numerous  flamegraphs demonstrate the problem. See attached [^profile_pbdpc23zafsrh_20200702.svg].

h4. Suggestion: ThreadLocal Regions

One possible solution is to have separate Regions per thread.  
Code wise this is relatively easy to do, for example replacing NativeAllocator:59 
{code}private final AtomicReference<Region> currentRegion = new AtomicReference<>();{code}
with
{code}private final ThreadLocal<AtomicReference<Region>> currentRegion = new ThreadLocal<>() {...};{code}

But this approach substantially changes the allocation behaviour, with more than concurrent_writes number of Regions in use at any one time. For example with {{concurrent_writes: 160}} that's 160+ regions, each of 1MB. 

h4. Suggestion: Simple Contention Management Algorithm (Constant Backoff)

Another possible solution is to introduce a contention management algorithm that a) reduces CAS failures in high contention environments, b) doesn't impact normal environments, and c) keeps the allocation strategy of using one region at a time.

The research paper [arXiv:1305.5800|https://arxiv.org/abs/1305.5800] describes this contention CAS problem and demonstrates a number of algorithms to apply. The simplest of these algorithms is the Constant Backoff CAS Algorithm.

Applying the Constant Backoff CAS Algorithm involves adding one line of code to {{NativeAllocator.Region.allocate(..)}} to sleep for one (or some constant number) nanoseconds after a CAS failure occurs.
That is...
{code}
    // we raced and lost alloc, try again
    LockSupport.parkNanos(1);
{code}

h4. Constant Backoff CAS Algorithm Experiments

Using the code attached in NativeAllocatorRegionTest.java the concurrency and CAS failures of {{NativeAllocator.Region.allocate(..)}} can be demonstrated. 

In the attached [^NativeAllocatorRegionTest.java] class, which can be run standalone, the {{Region}} class: copied from {{NativeAllocator.Region}}; has also the {{casFailures}} field added. The following two screenshots are from data collected from this class on a 6 CPU (12 core) MBP, running the {{NativeAllocatorRegionTest.testRegionCAS}} method.

This attached screenshot shows the number of CAS failures during the life of a Region (over ~215 million allocations), using different threads and park times. This illustrates the improvement (reduction) of CAS failures from zero park time, through orders of magnitude, up to 10000000ns (10ms). The biggest improvement is from no algorithm to a park time of 1ns where CAS failures are ~two orders of magnitude lower. From a park time 10μs and higher there is a significant drop also at low contention rates.

 !Screen Shot 2020-07-05 at 13.16.10.png|width=500px! 

This attached screenshot shows the time it takes to fill a Region (~215 million allocations), using different threads and park times. The biggest improvement is from no algorithm to a park time of 1ns where performance is one order of magnitude faster. From a park time of 100μs and higher there is a even further significant drop, especially at low contention rates.

 !Screen Shot 2020-07-05 at 13.26.17.png|width=500px! 

Repeating the test run show reliably similar results:  [^Screen Shot 2020-07-05 at 13.37.01.png]  and  [^Screen Shot 2020-07-05 at 13.35.55.png].

h4. Region Per Thread Experiments

Implementing Region Per Thread: see the {{NativeAllocatorRegionTest.testRegionThreadLocal}} method; we can expect zero CAS failures of the life of a Region. For performance we see two orders of magnitude lower times to fill up the Region (~420ms).

 !Screen Shot 2020-07-05 at 13.48.16.png|width=200px! 

h4. Costs

Region per Thread is an unrealistic solution as it introduces many new issues and problems, from increased memory use to leaking memory and GC issues. It is better tackled as part of a TPC implementation.

The backoff approach is simple and elegant, and seems to improve throughput in all situations. It does introduce context switches which may impact throughput in some busy throughput scenarios, so this should to be tested further."
CASSANDRA-15907,Operational Improvements & Hardening for Replica Filtering Protection,"CASSANDRA-8272 uses additional space on the heap to ensure correctness for 2i and filtering queries at consistency levels above ONE/LOCAL_ONE. There are a few things we should follow up on, however, to make life a bit easier for operators and generally de-risk usage:

(Note: Line numbers are based on {{trunk}} as of {{3cfe3c9f0dcf8ca8b25ad111800a21725bf152cb}}.)

*Minor Optimizations*

* {{ReplicaFilteringProtection:114}} - Given we size them up-front, we may be able to use simple arrays instead of lists for {{rowsToFetch}} and {{originalPartitions}}. Alternatively (or also), we may be able to null out references in these two collections more aggressively. (ex. Using {{ArrayList#set()}} instead of {{get()}} in {{queryProtectedPartitions()}}, assuming we pass {{toFetch}} as an argument to {{querySourceOnKey()}}.)
* {{ReplicaFilteringProtection:323}} - We may be able to use {{EncodingStats.merge()}} and remove the custom {{stats()}} method.
* {{DataResolver:111 & 228}} - Cache an instance of {{UnaryOperator#identity()}} instead of creating one on the fly.
* {{ReplicaFilteringProtection:217}} - We may be able to scatter/gather rather than serially querying every row that needs to be completed. This isn't a clear win perhaps, given it targets the latency of single queries and adds some complexity. (Certainly a decent candidate to kick even out of this issue.)

*Documentation and Intelligibility*

* There are a few places (CHANGES.txt, tracing output in {{ReplicaFilteringProtection}}, etc.) where we mention ""replica-side filtering protection"" (which makes it seem like the coordinator doesn't filter) rather than ""replica filtering protection"" (which sounds more like what we actually do, which is protect ourselves against incorrect replica filtering results). It's a minor fix, but would avoid confusion.
* The method call chain in {{DataResolver}} might be a bit simpler if we put the {{repairedDataTracker}} in {{ResolveContext}}.

*Testing*

* I want to bite the bullet and get some basic tests for RFP (including any guardrails we might add here) onto the in-JVM dtest framework.

*Guardrails*

* As it stands, we don't have a way to enforce an upper bound on the memory usage of {{ReplicaFilteringProtection}} which caches row responses from the first round of requests. (Remember, these are later used to merged with the second round of results to complete the data for filtering.) Operators will likely need a way to protect themselves, i.e. simply fail queries if they hit a particular threshold rather than GC nodes into oblivion. (Having control over limits and page sizes doesn't quite get us there, because stale results _expand_ the number of incomplete results we must cache.) The fun question is how we do this, with the primary axes being scope (per-query, global, etc.) and granularity (per-partition, per-row, per-cell, actual heap usage, etc.). My starting disposition   on the right trade-off between performance/complexity and accuracy is having something along the lines of cached rows per query. Prior art suggests this probably makes sense alongside things like {{tombstone_failure_threshold}} in {{cassandra.yaml}}."
CASSANDRA-15902,OOM because repair session thread not closed when terminating repair,"In our cluster, after a while some nodes running slowly out of memory. On that nodes we observed that Cassandra Reaper terminate repairs with a JMX call to {{StorageServiceMBean.forceTerminateAllRepairSessions()}} because reaching timeout of 30 min.

In the memory heap dump we see lot of instances of {{io.netty.util.concurrent.FastThreadLocalThread}} occupy most of the memory:
{noformat}
119 instances of ""io.netty.util.concurrent.FastThreadLocalThread"", loaded by ""sun.misc.Launcher$AppClassLoader @ 0x51a800000"" occupy 8.445.684.480 (93,96 %) bytes. {noformat}
In the thread dump we see lot of repair threads:
{noformat}
grep ""Repair#"" threaddump.txt | wc -l
      50 {noformat}
 

The repair jobs are waiting for the validation to finish:
{noformat}
""Repair#152:1"" #96170 daemon prio=5 os_prio=0 tid=0x0000000012fc5000 nid=0x542a waiting on condition [0x00007f81ee414000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        - parking to wait for  <0x00000007939bcfc8> (a com.google.common.util.concurrent.AbstractFuture$Sync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
        at com.google.common.util.concurrent.AbstractFuture$Sync.get(AbstractFuture.java:285)
        at com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:116)
        at com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(Uninterruptibles.java:137)
        at com.google.common.util.concurrent.Futures.getUnchecked(Futures.java:1509)
        at org.apache.cassandra.repair.RepairJob.run(RepairJob.java:160)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81)
        at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$13/480490520.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748) {noformat}
 

Thats the line where the threads stuck:
{noformat}
// Wait for validation to complete
Futures.getUnchecked(validations); {noformat}
 

The call to {{StorageServiceMBean.forceTerminateAllRepairSessions()}} stops the thread pool executor. It looks like that futures which are in progress will therefor never be completed and the repair thread waits forever and won't be finished.

 

Environment:

Cassandra version: 3.11.4 and 3.11.6

Cassandra Reaper: 1.4.0

JVM memory settings:
{noformat}
-Xms11771M -Xmx11771M -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled -XX:MaxMetaspaceSize=100M {noformat}
on another cluster with same issue:
{noformat}
-Xms31744M -Xmx31744M -XX:+UseG1GC -XX:MaxGCPauseMillis=100 -XX:+ParallelRefProcEnabled -XX:MaxMetaspaceSize=100M {noformat}
Java Runtime:
{noformat}
openjdk version ""1.8.0_212""
OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_212-b03)
OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.212-b03, mixed mode) {noformat}
 

The same issue described in this comment: https://issues.apache.org/jira/browse/CASSANDRA-14355?focusedCommentId=16992973&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16992973

As suggested in the comments I created this new specific ticket."
CASSANDRA-15898,cassandra 3.11.4 deadlock,"We are running apache-cassandra-3.11.4, 10 node cluster with -Xms32G -Xmx32G -Xmn8G using CMS.
after running couple of days one of the node become unresponsive and threaddump (jstack -F) shows deadlock.


Found one Java-level deadlock:
=============================

""Native-Transport-Requests-144"": waiting to lock Monitor@0x00007cd5142e4d08 (Object@0x00007f6e00348268, a java/io/ExpiringCache),
 which is held by ""CompactionExecutor:115134""
""CompactionExecutor:115134"": waiting to lock Monitor@0x00007f6bcaf130f8 (Object@0x00007f6dff31faa0, a ch/qos/logback/core/joran/spi/ConfigurationWatchList),
 which is held by ""Native-Transport-Requests-144""

Found a total of 1 deadlock.

I have seen this couple of time now with different nodes with following in system.log

IndexSummaryRedistribution.java:77 - Redistributing index summaries
 NoSpamLogger.java:91 - Maximum memory usage reached (536870912), cannot allocate chunk of 1048576

also lookin in gc log there has not been a ParNew collection for last 10hrs, only CMS collections.

1739842.375: [GC (CMS Final Remark) [YG occupancy: 2712269 K (7549760 K)]
1739842.375: [Rescan (parallel) , 0.0614157 secs]
1739842.437: [weak refs processing, 0.0000994 secs]
1739842.437: [class unloading, 0.0231076 secs]
1739842.460: [scrub symbol table, 0.0061049 secs]
1739842.466: [scrub string table, 0.0043847 secs][1 CMS-remark: 17696837K(25165824K)] 20409107K(32715584K), 0.0953750 secs] [Times: user=2.95 sys=0.00, real=0.09 secs]
1739842.471: [CMS-concurrent-sweep-start]
1739848.572: [CMS-concurrent-sweep: 6.101/6.101 secs] [Times: user=6.13 sys=0.00, real=6.10 secs]
1739848.573: [CMS-concurrent-reset-start]
1739848.645: [CMS-concurrent-reset: 0.072/0.072 secs] [Times: user=0.08 sys=0.00, real=0.08 secs]
1739858.653: [GC (CMS Initial Mark) [1 CMS-initial-mark: 17696837K(25165824K)] 
20409111K(32715584K), 0.0584838 secs] [Times: user=2.68 sys=0.00, real=0.06 secs]
1739858.713: [CMS-concurrent-mark-start]
1739860.496: [CMS-concurrent-mark: 1.784/1.784 secs] [Times: user=84.77 sys=0.00, real=1.79 secs]
1739860.497: [CMS-concurrent-preclean-start]
1739860.566: [CMS-concurrent-preclean: 0.070/0.070 secs] [Times: user=0.07 sys=0.00, real=0.07 secs]
1739860.567: [CMS-concurrent-abortable-preclean-start]CMS: abort preclean due to time
1739866.333: [CMS-concurrent-abortable-preclean: 5.766/5.766 secs] [Times: user=5.80 sys=0.00, real=5.76 secs]

Java HotSpot(TM) 64-Bit Server VM (25.162-b12) for linux-amd64 JRE (1.8.0_162-b12)
Memory: 4k page, physical 792290076k(2780032k free), swap 16777212k(16693756k free)

CommandLine flags:
-XX:+AlwaysPreTouch
-XX:CICompilerCount=15
-XX:+CMSClassUnloadingEnabled
-XX:+CMSEdenChunksRecordAlways
-XX:CMSInitiatingOccupancyFraction=40
-XX:+CMSParallelInitialMarkEnabled
-XX:+CMSParallelRemarkEnabled
-XX:CMSWaitDuration=10000
-XX:ConcGCThreads=50
-XX:+CrashOnOutOfMemoryError
-XX:GCLogFileSize=10485760
-XX:+HeapDumpOnOutOfMemoryError
-XX:InitialHeapSize=34359738368
-XX:InitialTenuringThreshold=1
-XX:+ManagementServer
-XX:MaxHeapSize=34359738368
-XX:MaxNewSize=8589934592
-XX:MaxTenuringThreshold=1
-XX:MinHeapDeltaBytes=196608
-XX:NewSize=8589934592
-XX:NumberOfGCLogFiles=10
-XX:OldPLABSize=16
-XX:OldSize=25769803776
-XX:OnOutOfMemoryError=kill -9 %p
-XX:ParallelGCThreads=50
-XX:+PerfDisableSharedMem
-XX:+PrintGC
-XX:+PrintGCDetails
-XX:+PrintGCTimeStamps
-XX:+ResizeTLAB
-XX:StringTableSize=1000003
-XX:SurvivorRatio=8
-XX:ThreadPriorityPolicy=42
-XX:ThreadStackSize=256
-XX:-UseBiasedLocking
-XX:+UseCMSInitiatingOccupancyOnly
-XX:+UseConcMarkSweepGC
-XX:+UseCondCardMark
-XX:+UseFastUnorderedTimeStamps
-XX:+UseGCLogFileRotation
-XX:+UseNUMA
-XX:+UseNUMAInterleaving
-XX:+UseParNewGC
-XX:+UseTLAB
-XX:+UseThreadPriorities"
CASSANDRA-15896,NullPointerException in SELECT JSON statement when a UUID field contains an empty string,"It seems that Cassandra accept empty strings """" ( FROM JSON string ) for UUID fields but crash when asking for JSON serialization of those fields.

 

Cassandra version 3.6.11.6 running in docker from official Dockerhub image.

Java driver:
{code:java}
<!-- https://mvnrepository.com/artifact/com.datastax.oss/java-driver-core -->
<dependency>
    <groupId>com.datastax.oss</groupId>
    <artifactId>java-driver-core</artifactId>
    <version>4.7.0</version>
</dependency>
{code}
The attached code is to allow bug reproducibility:
{code:java}
package com.foo.bar;
import com.datastax.oss.driver.api.core.CqlSession;
import com.datastax.oss.driver.api.core.CqlSessionBuilder;
import com.datastax.oss.driver.api.core.cql.PreparedStatement;
import com.datastax.oss.driver.api.core.cql.ResultSet;
import com.datastax.oss.driver.api.core.cql.Row;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.junit.After;
import org.junit.Before;
import org.junit.Test;

import java.net.InetSocketAddress;
import java.net.URI;
import java.util.*;

import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertNotNull;

/**
 * @author Domenico Lupinetti <ostico@gmail.com> - 23/06/2020
 */
public class NullPointerExceptionTest {

    protected String uuid;
    protected CqlSession cqlSession;

    @Before
    public void setUp() throws Exception {

        URI node = new URI( ""tcp://localhost:9042"" );
        final CqlSessionBuilder builder = CqlSession.builder();

        cqlSession = builder.addContactPoint( new InetSocketAddress(
                node.getHost(),
                node.getPort()
        ) ).withLocalDatacenter( ""datacenter1"" ).build();

        cqlSession.execute( ""CREATE KEYSPACE IF NOT EXISTS test_suite WITH replication = {'class':'SimpleStrategy','replication_factor':1};"" );

        String sb = ""CREATE TABLE IF NOT EXISTS test_suite.test ( id uuid PRIMARY KEY, another_id uuid, subject text );"";

        cqlSession.execute( sb );
        PreparedStatement stm = cqlSession.prepare( ""INSERT INTO test_suite.test JSON :payload"" );

        this.uuid = UUID.randomUUID().toString();

        HashMap<String, String> payload = new HashMap<>();
        payload.put( ""id"", this.uuid );

        // ******* This exception do not happens if the field is set as NULL
        payload.put( ""another_id"", """" );  //<------ EMPTY STRING AS UUID
        payload.put( ""subject"", ""Alighieri, Dante. Divina Commedia"" );

        ObjectMapper objM = new ObjectMapper();
        cqlSession.execute(
                stm.bind().setString( ""payload"", objM.writeValueAsString( payload ) )
        );  //<------ serialize as JSON

    }

    @After
    public void tearDown() throws Exception {
        cqlSession.execute( ""DROP TABLE IF EXISTS test_suite.test;"" );
        cqlSession.execute( ""DROP KEYSPACE test_suite;"" );
        cqlSession.close();
    }

    @Test
    public void testNullPointer() {

        PreparedStatement stmt       = cqlSession.prepare( ""SELECT JSON id, another_id FROM test_suite.test where id = :id;"" );
        ResultSet         resultSet  = cqlSession.execute( stmt.bind().setUuid( ""id"", UUID.fromString( this.uuid ) ) ); // <------ EXCEPTION
        Row               r          = resultSet.one();

        assertNotNull( r );
        assertNotNull( r.getString( ""[json]"" ) );
        assertFalse( Objects.requireNonNull( r.getString( ""[json]"" ) ).isEmpty() );

    }

}


{code}
Client stack Trace:
{code:java}
com.datastax.oss.driver.api.core.servererrors.ServerError: java.lang.NullPointerExceptioncom.datastax.oss.driver.api.core.servererrors.ServerError: java.lang.NullPointerException
 at com.datastax.oss.driver.api.core.servererrors.ServerError.copy(ServerError.java:54) at com.datastax.oss.driver.internal.core.util.concurrent.CompletableFutures.getUninterruptibly(CompletableFutures.java:149) at com.datastax.oss.driver.internal.core.cql.CqlRequestSyncProcessor.process(CqlRequestSyncProcessor.java:53) at com.datastax.oss.driver.internal.core.cql.CqlRequestSyncProcessor.process(CqlRequestSyncProcessor.java:30) at com.datastax.oss.driver.internal.core.session.DefaultSession.execute(DefaultSession.java:230) at com.datastax.oss.driver.api.core.cql.SyncCqlSession.execute(SyncCqlSession.java:53) at com.foo.bar.NullPointerExceptionTest.testNullPointer(NullPointerExceptionTest.java:74) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68) at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33) at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:230) at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:58)
{code}
Cassandra stack Trace:

 
{code:java}
ERROR [Native-Transport-Requests-1] 2020-06-23 09:57:48,074 ErrorMessage.java:384 - Unexpected exception during requestERROR [Native-Transport-Requests-1] 2020-06-23 09:57:48,074 ErrorMessage.java:384 - Unexpected exception during requestjava.lang.NullPointerException: null at org.apache.cassandra.db.marshal.AbstractType.toJSONString(AbstractType.java:156) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.selection.Selection.rowToJson(Selection.java:343) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.selection.Selection$ResultSetBuilder.getOutputRow(Selection.java:494) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.selection.Selection$ResultSetBuilder.build(Selection.java:477) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:794) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:438) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:416) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:289) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:117) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:225) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:532) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:509) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:146) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.transport.Message$Dispatcher.processRequest(Message.java:686) [apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.transport.Message$Dispatcher.lambda$channelRead0$0(Message.java:592) [apache-cassandra-3.11.6.jar:3.11.6] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_252] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:165) ~[apache-cassandra-3.11.6.jar:3.11.6] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:113) ~[apache-cassandra-3.11.6.jar:3.11.6] at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
{code}"
CASSANDRA-15880,Memory leak in CompressedChunkReader,"CompressedChunkReader uses java.lang.ThreadLocal to reuse ByteBuffer for compressed data. ByteBuffers leak due to peculiar ThreadLocal quality.
ThreadLocals are stored in a map, where the key is a weak reference to a ThreadLocal and the value is the user's object (ByteBuffer in this case). When a last strong reference to a ThreadLocal is lost, weak reference to ThreadLocal (key) is removed but the value (ByteBuffer) is kept until cleaned by ThreadLocal heuristic expunge mechanism. See ThreadLocal's ""stale entries"" for details.

When a number of long-living threads is high enough this results in thousands of ByteBuffers stored as stale entries in ThreadLocals. In a not-so-lucky scenario we get OutOfMemoryException."
CASSANDRA-15805,Potential duplicate rows on 2.X->3.X upgrade when multi-rows range tombstones interacts with collection tombstones,"The legacy reading code ({{LegacyLayout}} and {{UnfilteredDeserializer.OldFormatDeserializer}}) does not handle correctly the case where a range tombstone covering multiple rows interacts with a collection tombstone.

A simple example of this problem is if one runs on 2.X:
{noformat}
CREATE TABLE t (
  k int,
  c1 text,
  c2 text,
  a text,
  b set<text>,
  c text,
  PRIMARY KEY((k), c1, c2)
);

// Delete all rows where c1 is 'A'
DELETE FROM t USING TIMESTAMP 1 WHERE k = 0 AND c1 = 'A';
// Inserts a row covered by that previous range tombstone
INSERT INTO t(k, c1, c2, a, b, c) VALUES (0, 'A', 'X', 'foo', {'whatever'}, 'bar') USING TIMESTAMP 2;
// Delete the collection of that previously inserted row
DELETE b FROM t USING TIMESTAMP 3 WHERE k = 0 AND c1 = 'A' and c2 = 'X';
{noformat}

If the following is ran on 2.X (with everything either flushed in the same table or compacted together), then this will result in the inserted row being duplicated (one part containing the {{a}} column, the other the {{c}} one).

I will note that this is _not_ a duplicate of CASSANDRA-15789 and this reproduce even with the fix to {{LegacyLayout}} of this ticket. That said, the additional code added to CASSANDRA-15789 to force merging duplicated rows if they are produced _will_ end up fixing this as a consequence (assuming there is no variation of this problem that leads to other visible issues than duplicated rows). That said, I ""think"" we'd still rather fix the source of the issue.
"
CASSANDRA-15804,system_schema keyspace complain of schema mismatch during upgrade,"When upgrading from 3.11.4 to 3.11.6, we got the following error:

{code:Plain Text}
ERROR [MessagingService-Incoming-/10.20.11.59] 2020-05-07 13:53:52,627 CassandraDaemon.java:228 - Exception in thread Thread[MessagingService-Incoming-/10.20.11.59,5,main]
java.lang.RuntimeException: Unknown column kind during deserialization
    at org.apache.cassandra.db.Columns$Serializer.deserialize(Columns.java:464) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.SerializationHeader$Serializer.deserializeForMessaging(SerializationHeader.java:419) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.deserializeHeader(UnfilteredRowIteratorSerializer.java:195) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize30(PartitionUpdate.java:851) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize(PartitionUpdate.java:839) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:425) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.db.Mutation$MutationSerializer.deserialize(Mutation.java:434) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:675) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.service.MigrationManager$MigrationsSerializer.deserialize(MigrationManager.java:658) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.net.MessageIn.read(MessageIn.java:123) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:192) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:180) ~[apache-cassandra-3.11.4.jar:3.11.4]
    at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:94) ~[apache-cassandra-3.11.4.jar:3.11.4]
{code}

I've noticed that system_schema.dropped_columns has a new column called ""kind"".
No issues arise from this error message, and the error disappeared after upgrading all nodes. But it still caused concerns due to the ERROR logging level, although ""nodetool describecluster"" reported only one schema version.

It makes sense for the system keyspaces to not be included for the ""describecluster"" schema version check, but it seems to me that these internal schema mismatches should be ignored if the versions are different between the nodes."
CASSANDRA-15789,Rows can get duplicated in mixed major-version clusters and after full upgrade,"In a mixed 2.X/3.X major version cluster a sequence of row deletes, collection overwrites, paging, and read repair can cause 3.X nodes to split individual rows into several rows with identical clustering. This happens due to 2.X paging and RT semantics, and a 3.X {{LegacyLayout}} deficiency.

To reproduce, set up a 2-node mixed major version cluster with the following table:

{code}
CREATE TABLE distributed_test_keyspace.tlb (
    pk int,
    ck int,
    v map<text, text>,
    PRIMARY KEY (pk, ck)
);
{code}

1. Using either node as the coordinator, delete the row with ck=2 using timestamp 1

{code}
DELETE FROM tbl USING TIMESTAMP 1 WHERE pk = 1 AND ck = 2;
{code}

2. Using either node as the coordinator, insert the following 3 rows:

{code}
INSERT INTO tbl (pk, ck, v) VALUES (1, 1, {'e':'f'}) USING TIMESTAMP 3;
INSERT INTO tbl (pk, ck, v) VALUES (1, 2, {'g':'h'}) USING TIMESTAMP 3;
INSERT INTO tbl (pk, ck, v) VALUES (1, 3, {'i':'j'}) USING TIMESTAMP 3;
{code}

3. Flush the table on both nodes

4. Using the 2.2 node as the coordinator, force read repar by querying the table with page size = 2:
 
{code}
SELECT * FROM tbl;
{code}

5. Overwrite the row with ck=2 using timestamp 5:

{code}
INSERT INTO tbl (pk, ck, v) VALUES (1, 2, {'g':'h'}) USING TIMESTAMP 5;}}
{code}

6. Query the 3.0 node and observe the split row:

{code}
cqlsh> select * from distributed_test_keyspace.tlb ;

 pk | ck | v
----+----+------------
  1 |  1 | {'e': 'f'}
  1 |  2 | {'g': 'h'}
  1 |  2 | {'k': 'l'}
  1 |  3 | {'i': 'j'}
{code}

This happens because the read to query the second page ends up generating the following mutation for the 3.0 node:

{code}
ColumnFamily(tbl -{deletedAt=-9223372036854775808, localDeletion=2147483647,
             ranges=[2:v:_-2:v:!, deletedAt=2, localDeletion=1588588821]
                    [2:v:!-2:!,   deletedAt=1, localDeletion=1588588821]
                    [3:v:_-3:v:!, deletedAt=2, localDeletion=1588588821]}-
             [2:v:63:false:1@3,])
{code}

Which on 3.0 side gets incorrectly deserialized as

{code}
Mutation(keyspace='distributed_test_keyspace', key='00000001', modifications=[
  [distributed_test_keyspace.tbl] key=1 partition_deletion=deletedAt=-9223372036854775808, localDeletion=2147483647 columns=[[] | [v]]
    Row[info=[ts=-9223372036854775808] ]: ck=2 | del(v)=deletedAt=2, localDeletion=1588588821, [v[c]=d ts=3]
    Row[info=[ts=-9223372036854775808] del=deletedAt=1, localDeletion=1588588821 ]: ck=2 |
    Row[info=[ts=-9223372036854775808] ]: ck=3 | del(v)=deletedAt=2, localDeletion=1588588821
])
{code}

{{LegacyLayout}} correctly interprets a range tombstone whose start and finish {{collectionName}} values don't match as a wrapping fragment of a legacy row deletion that's being interrupted by a collection deletion (correctly) - see [code|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/db/LegacyLayout.java#L1874-L1889]. Quoting the comment inline:

{code}
// Because of the way RangeTombstoneList work, we can have a tombstone where only one of
// the bound has a collectionName. That happens if we have a big tombstone A (spanning one
// or multiple rows) and a collection tombstone B. In that case, RangeTombstoneList will
// split this into 3 RTs: the first one from the beginning of A to the beginning of B,
// then B, then a third one from the end of B to the end of A. To make this simpler, if
 // we detect that case we transform the 1st and 3rd tombstone so they don't end in the middle
 // of a row (which is still correct).
{code}

{{LegacyLayout#addRowTombstone()}} method then chokes when it encounters such a tombstone in the middle of an existing row - having seen {{v[c]=d}} first, and mistakenly starts a new row, while in the middle of an existing one: (see [code|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/db/LegacyLayout.java#L1500-L1501]).
"
CASSANDRA-15778,"CorruptSSTableException after a 2.1 SSTable is upgraded to 3.0, failing reads","Below is the exception with stack trace. This issue is consistently reproduce-able.
{code:java}
ERROR [SharedPool-Worker-1] 2020-05-01 14:57:57,661 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-1,5,main]ERROR [SharedPool-Worker-1] 2020-05-01 14:57:57,661 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-1,5,main]org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/data/cassandra/data/<ks>/<cf-fda511301fb311e7bd79fd24f2fcfb0d/md-10151-big-Data.db at org.apache.cassandra.db.columniterator.AbstractSSTableIterator$Reader.hasNext(AbstractSSTableIterator.java:349) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.hasNext(AbstractSSTableIterator.java:220) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.columniterator.SSTableIterator.hasNext(SSTableIterator.java:33) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:95) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:32) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:129) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:95) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:32) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:129) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:129) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:131) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:87) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:77) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:294) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:187) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:180) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:176) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:76) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:341) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.ReadCommandVerbHandler.doVerb(ReadCommandVerbHandler.java:47) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_231] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:165) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:137) [nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [nf-cassandra-3.0.19.8.jar:3.0.19.8] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_231]Caused by: java.lang.ArrayIndexOutOfBoundsException: 121 at org.apache.cassandra.db.ClusteringPrefix$Deserializer.prepare(ClusteringPrefix.java:425) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.UnfilteredDeserializer$CurrentDeserializer.prepareNext(UnfilteredDeserializer.java:170) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.UnfilteredDeserializer$CurrentDeserializer.hasNext(UnfilteredDeserializer.java:151) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.columniterator.SSTableIterator$ForwardReader.computeNext(SSTableIterator.java:140) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.columniterator.SSTableIterator$ForwardReader.hasNextInternal(SSTableIterator.java:172) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] at org.apache.cassandra.db.columniterator.AbstractSSTableIterator$Reader.hasNext(AbstractSSTableIterator.java:336) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] ... 27 common frames omitted

Caused by: java.lang.ArrayIndexOutOfBoundsException: 121
    at org.apache.cassandra.db.ClusteringPrefix$Deserializer.prepare(ClusteringPrefix.java:425) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8]
    at org.apache.cassandra.db.UnfilteredDeserializer$CurrentDeserializer.prepareNext(UnfilteredDeserializer.java:170) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8]
    at org.apache.cassandra.db.UnfilteredDeserializer$CurrentDeserializer.hasNext(UnfilteredDeserializer.java:151) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8]
    at org.apache.cassandra.db.columniterator.SSTableIterator$ForwardReader.computeNext(SSTableIterator.java:140) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8]
    at org.apache.cassandra.db.columniterator.SSTableIterator$ForwardReader.hasNextInternal(SSTableIterator.java:172) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8]
    at org.apache.cassandra.db.columniterator.AbstractSSTableIterator$Reader.hasNext(AbstractSSTableIterator.java:336) ~[nf-cassandra-3.0.19.8.jar:3.0.19.8] ... 27 common frames omitted
{code}

Column family definition
{code:java}
CREATE TABLE <keyspace>.""<cf>"" (
 key text,
 value text,
 PRIMARY KEY (key, value)
 ) WITH COMPACT STORAGE
 AND CLUSTERING ORDER BY (value ASC)
 AND bloom_filter_fp_chance = 0.01
 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
 AND comment = ''
 AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
 AND compression = {'enabled': 'false'}
 AND crc_check_chance = 1.0
 AND dclocal_read_repair_chance = 0.1
 AND default_time_to_live = 0
 AND gc_grace_seconds = 864000
 AND max_index_interval = 2048
 AND memtable_flush_period_in_ms = 0
 AND min_index_interval = 128
 AND read_repair_chance = 0.0
 AND speculative_retry = '99PERCENTILE';{code}"
CASSANDRA-15667,"StreamResultFuture check for completeness is inconsistent, leading to races","{{StreamResultFuture#maybeComplete()}} uses {{StreamCoordinator#hasActiveSessions()}} to determine if all sessions are completed, but then accesses each session state via {{StreamCoordinator#getAllSessionInfo()}}: this is inconsistent, as the former relies on the actual {{StreamSession}} state, while the latter on the {{SessionInfo}} state, and the two are concurrently updated with no coordination whatsoever.

This leads to races, i.e. apparent in some dtest spurious failures, such as {{TestBootstrap.resumable_bootstrap_test}} in CASSANDRA-15614 cc [~e.dimitrova]."
CASSANDRA-15595,"Many errors of ""java.lang.AssertionError: Illegal bounds""","Hi, i'm running cassandra 3.11.6 and getting on all hosts many errors of:
{code}
ERROR [ReadStage-6] 2020-02-24 13:53:34,528 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[ReadStage-6,5,main]
java.lang.AssertionError: Illegal bounds [-2102982480..-2102982472); size: 2761628520
        at org.apache.cassandra.io.util.Memory.checkBounds(Memory.java:345) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.util.Memory.getLong(Memory.java:254) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.compress.CompressionMetadata.chunkFor(CompressionMetadata.java:234) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.util.CompressedChunkReader$Standard.readChunk(CompressedChunkReader.java:114) ~[apache-cassandra-3.11.6.ja
r:3.11.6]
        at org.apache.cassandra.cache.ChunkCache.load(ChunkCache.java:158) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.cache.ChunkCache.load(ChunkCache.java:39) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalLoadingCache.lambda$new$0(BoundedLocalCache.java:2949) ~[caffeine-2.2.6.jar:na]
        at com.github.benmanes.caffeine.cache.BoundedLocalCache.lambda$doComputeIfAbsent$15(BoundedLocalCache.java:1807) ~[caffeine-2.2.6.jar:na]
        at java.util.concurrent.ConcurrentHashMap.compute(ConcurrentHashMap.java:1853) ~[na:1.8.0-zing_19.12.102.0]
        at com.github.benmanes.caffeine.cache.BoundedLocalCache.doComputeIfAbsent(BoundedLocalCache.java:1805) ~[caffeine-2.2.6.jar:na]
        at com.github.benmanes.caffeine.cache.BoundedLocalCache.computeIfAbsent(BoundedLocalCache.java:1788) ~[caffeine-2.2.6.jar:na]
        at com.github.benmanes.caffeine.cache.LocalCache.computeIfAbsent(LocalCache.java:97) ~[caffeine-2.2.6.jar:na]
        at com.github.benmanes.caffeine.cache.LocalLoadingCache.get(LocalLoadingCache.java:66) ~[caffeine-2.2.6.jar:na]
        at org.apache.cassandra.cache.ChunkCache$CachingRebufferer.rebuffer(ChunkCache.java:236) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.cache.ChunkCache$CachingRebufferer.rebuffer(ChunkCache.java:214) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.util.RandomAccessReader.reBufferAt(RandomAccessReader.java:65) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.util.RandomAccessReader.seek(RandomAccessReader.java:207) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.util.FileHandle.createReader(FileHandle.java:150) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.sstable.format.SSTableReader.getFileDataInput(SSTableReader.java:1807) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.columniterator.AbstractSSTableIterator.<init>(AbstractSSTableIterator.java:103) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.columniterator.SSTableIterator.<init>(SSTableIterator.java:49) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:72) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.io.sstable.format.big.BigTableReader.iterator(BigTableReader.java:65) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.StorageHook$1.makeRowIterator(StorageHook.java:100) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndSSTablesInTimestampOrder(SinglePartitionReadCommand.java:982) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDiskInternal(SinglePartitionReadCommand.java:693) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.SinglePartitionReadCommand.queryMemtableAndDisk(SinglePartitionReadCommand.java:670) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.SinglePartitionReadCommand.queryStorage(SinglePartitionReadCommand.java:504) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.ReadCommand.executeLocally(ReadCommand.java:423) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.db.ReadCommandVerbHandler.doVerb(ReadCommandVerbHandler.java:48) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0-zing_19.12.102.0]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:165) ~[apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:137) [apache-cassandra-3.11.6.jar:3.11.6]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:113) [apache-cassandra-3.11.6.jar:3.11.6]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0-zing_19.12.102.0]
{code}

Someone familiar with that error?
"
CASSANDRA-15567,Allow EXTRA_CLASSPATH to work in tarball/source installations,Both the debian and redhat packaging modify cassandra.in.sh to support the EXTRA_CLASSPATH variable.  It would be nice to just put this in cassandra.in.sh proper so people without a package installation can use it as well.
CASSANDRA-15501,Duplicate results with DISTINCT queries in mixed mode 2.1/3.0,When a client switches coordinator from a 2.1 node to a 3.0 node it sends a 2.1 paging state to the 3.0 node. The 2.1 {{PagingState}} does not have {{remainingInPartition}} so on the 3.0 side we default this to Integer.MAX_VALUE. This value is then used to decide if the lastKey should be included in the result.
CASSANDRA-15430,Cassandra 3.0.18: BatchMessage.execute - 10x more on-heap allocations compared to 2.1.18,"In a 6 node loadtest cluster, we have been running with 2.1.18 a certain production-like workload constantly and sufficiently. After upgrading one node to 3.0.18 (remaining 5 still on 2.1.18 after we have seen that sort of regression described below), 3.0.18 is showing increased CPU usage, increase GC, high mutation stage pending tasks, dropped mutation messages ...

Some spec. All 6 nodes equally sized:
 * Bare metal, 32 physical cores, 512G RAM
 * Xmx31G, G1, max pause millis = 2000ms
 * cassandra.yaml basically unchanged, thus same settings in regard to number of threads, compaction throttling etc.

Following dashboard shows highlighted areas (CPU, suspension) with metrics for all 6 nodes and the one outlier being the node upgraded to Cassandra 3.0.18.
 !dashboard.png|width=1280!

Additionally we see a large increase on pending tasks in the mutation stage after the upgrade:
 !mutation_stage.png!

And dropped mutation messages, also confirmed in the Cassandra log:
{noformat}
INFO  [ScheduledTasks:1] 2019-11-15 08:24:24,780 MessagingService.java:1022 - MUTATION messages were dropped in last 5000 ms: 41552 for internal timeout and 0 for cross node timeout
INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,157 StatusLogger.java:52 - Pool Name                    Active   Pending      Completed   Blocked  All Time Blocked
INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,168 StatusLogger.java:56 - MutationStage                   256     81824     3360532756         0                 0

INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,168 StatusLogger.java:56 - ViewMutationStage                 0         0              0         0                 0

INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,168 StatusLogger.java:56 - ReadStage                         0         0       62862266         0                 0

INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,169 StatusLogger.java:56 - RequestResponseStage              0         0     2176659856         0                 0

INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,169 StatusLogger.java:56 - ReadRepairStage                   0         0              0         0                 0

INFO  [ScheduledTasks:1] 2019-11-15 08:24:25,169 StatusLogger.java:56 - CounterMutationStage              0         0              0         0                 0
...
{noformat}
Judging from a 15min JFR session for both, 3.0.18 and 2.1.18 on a different node, high-level, it looks like the code path underneath {{BatchMessage.execute}} is producing ~ 10x more on-heap allocations in 3.0.18 compared to 2.1.18.
 !jfr_allocations.png!

Left => 3.0.18
 Right => 2.1.18

JFRs zipped are exceeding the 60MB limit to directly attach to the ticket. I can upload them, if there is another destination available."
CASSANDRA-15426,Cassandra 3.11.5 fails to start on Windows ,"Cassandra 3.11.5 fails to start on Windows server 2012 R2. with following error trace.

Cassandra 3.11.4 doesn't fail on Windows 2012 R2. 

   

org.apache.cassandra.io.FSReadError: java.io.IOException: Invalid folder descriptor trying to create log replica C:\Users\Administrator\Downloads\apache-cassandra-3.11.5-bin.tar\apache-cassandra-3.11.5-bin\apache-cassandra-3.11.5\data\data\system\local-7ad54392bcdd35a684174e047860b377
 at org.apache.cassandra.db.lifecycle.LogReplica.create(LogReplica.java:58) ~[apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.lifecycle.LogReplicaSet.maybeCreateReplica(LogReplicaSet.java:86) ~[apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.lifecycle.LogFile.makeRecord(LogFile.java:311) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.lifecycle.LogFile.add(LogFile.java:283) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.lifecycle.LogTransaction.trackNew(LogTransaction.java:139) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.lifecycle.LifecycleTransaction.trackNew(LifecycleTransaction.java:528) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.io.sstable.format.big.BigTableWriter.<init>(BigTableWriter.java:81) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.io.sstable.format.big.BigFormat$WriterFactory.open(BigFormat.java:92) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.io.sstable.format.SSTableWriter.create(SSTableWriter.java:102) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.create(SimpleSSTableMultiWriter.java:119) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.compaction.AbstractCompactionStrategy.createSSTableMultiWriter(AbstractCompactionStrategy.java:588) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.compaction.CompactionStrategyManager.createSSTableMultiWriter(CompactionStrategyManager.java:1027) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.ColumnFamilyStore.createSSTableMultiWriter(ColumnFamilyStore.java:532) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.Memtable$FlushRunnable.createFlushWriter(Memtable.java:504) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.Memtable$FlushRunnable.<init>(Memtable.java:443) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.Memtable$FlushRunnable.<init>(Memtable.java:420) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.Memtable.createFlushRunnables(Memtable.java:307) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.Memtable.flushRunnables(Memtable.java:298) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1153) [apache-cassandra-3.11.5.jar:3.11.5]
 at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1118) [apache-cassandra-3.11.5.jar:3.11.5]
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_161]
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_161]
 at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:84) [apache-cassandra-3.11.5.jar:3.11.5]
 at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_161]
Caused by: java.io.IOException: Invalid folder descriptor trying to"
CASSANDRA-15408,Cassandra throws SyntaxException for obsolete keywords that Thrift API permits,"In [this refactor|https://github.com/apache/cassandra/commit/b31845c4a7982358a7c5bfd9bcf572fda6c1bfa9#diff-826a67bf1ae2e45372a35a6a2a6f3f3cL74] of CFPropDefs to TableAttributes for CASSANDRA-9712, three obsolete keywords were removed:
{code:java}
        obsoleteKeywords.add(""index_interval"");
        obsoleteKeywords.add(""replicate_on_write"");
        obsoleteKeywords.add(""populate_io_cache_on_flush"");
{code}
 
The Thrift API continues to reference these keywords as deprecated, so it's not clear that they are actually unsupported.

Could we either add them back as obsoleteKeywords, or add a change log that statements with these properties will fail (There is already a changelog about ""index_interval"" but not the other two)?  I understand that the Thrift API is totally deprecated so I don't feel strongly about cleaning it up."
CASSANDRA-15400,Cassandra 3.0.18 went OOM several hours after joining a cluster,"We have been moving from Cassandra 2.1.18 to Cassandra 3.0.18 and have been facing an OOM two times with 3.0.18 on newly added nodes joining an existing cluster after several hours being successfully bootstrapped.

Running in AWS:
* m5.2xlarge, EBS SSD (gp2)
* Xms/Xmx12G, Xmn3G, CMS GC, OpenJDK8u222
* 4 compaction threads, throttling set to 32 MB/s

What we see is a steady increase in the OLD gen over many hours.
!cassandra_jvm_metrics.png!

* The node started to join / auto-bootstrap the cluster on Oct 30 ~ 12:00
* It basically finished joining the cluster (UJ => UN) ~ 19hrs later on Oct 31 ~ 07:00 also starting to be a member of serving client read requests
!cassandra_operationcount.png!

Memory-wise (on-heap) it didn't look that bad at that time, but old gen usage constantly increased.

We see a correlation in increased number of SSTables and pending compactions.
!cassandra_sstables_pending_compactions.png!

Until we reached the OOM somewhere in Nov 1 in the night. After a Cassandra startup (metric gap in the chart above), number of SSTables + pending compactions is still high, but without facing memory troubles since then.

This correlation is confirmed by the auto-generated heap dump with e.g. ~ 5K BigTableReader instances with ~ 8.7GByte retained heap in total.
!cassandra_hprof_dominator_classes.png!

Having a closer look on a single object instance, seems like each instance is ~ 2MByte in size.
!cassandra_hprof_bigtablereader_statsmetadata.png!
With 2 pre-allocated byte buffers (highlighted in the screen above) at 1 MByte each

We have been running with 2.1.18 for > 3 years and I can't remember dealing with such OOM in the context of extending a cluster.

While the MAT screens above are from our production cluster, we partly can reproduce this behavior in our loadtest environment (although not going full OOM there), thus I might be able to share a hprof from this non-prod environment if needed.

Thanks a lot.



"
CASSANDRA-15398,Fix system_traces creation timestamp; optimise system keyspace upgrades,"We have introduced changes to system_traces tables in 3.0 (removal of default_time_to_live, lowering of bloom_filter_fp_chance). We did not, however, bump the timestamp with which we add the tables to schema, still defaulting to 0. As a result, for clusters that upgraded from 2.1/2.2, on bounce we would always detect a mismatch between actual and desired table definitions, always try to reconcile it by issuing migration tasks, but have them never override the existing definitions in place.

Additionally, prior to 2.0.2 (CASSANDRA-6016) we’d use a ‘real’ timestamp, so for clusters that started on even earlier versions of C* (say, 1.2), a bump to the timestamp by 1 would be insufficient, and a larger generation is necessary (I picked Jan 1 2020 as cut-off date).

The patch also optimises the process of upgrading replicated system tables. Instead of issuing a migration task for every table that changed for every node, we batch all changes into a single schema migration task."
CASSANDRA-15371,Incorrect messaging service version breaks in-JVM upgrade tests on trunk,"The in-JVM upgrade tests on trunk currently fail because the messaging
 version for internode messaging is selected as {{MessagingService.current_version}},
 a regression from the implementation in CASSANDRA-15078."
CASSANDRA-15368,Failing to flush Memtable without terminating process results in permanent data loss,"{{Memtable}} do not contain records that cover a precise contiguous range of {{ReplayPosition}}, since there are only weak ordering constraints when rolling over to a new {{Memtable}} - the last operations for the old {{Memtable}} may obtain their {{ReplayPosition}} after the first operations for the new {{Memtable}}.

Unfortunately, we treat the {{Memtable}} range as contiguous, and invalidate the entire range on flush.  Ordinarily we only invalidate records when all prior {{Memtable}} have also successfully flushed.  However, in the event of a flush that does not terminate the process (either because of disk failure policy, or because it is a software error), the later flush is able to invalidate the region of the commit log that includes records that should have been flushed in the prior {{Memtable}}

More problematically, this can also occur on restart without any associated flush failure, as we use commit log boundaries written to our flushed sstables to filter {{ReplayPosition}} on recovery, which is meant to replicate our {{Memtable}} flush behaviour above.  However, we do not know that earlier flushes have completed, and they may complete successfully out-of-order.  So any flush that completes before the process terminates, but began after another flush that _doesn’t_ complete before the process terminates, has the potential to cause permanent data loss.
"
CASSANDRA-15367,Memtable memory allocations may deadlock,"* Under heavy contention, we guard modifications to a partition with a mutex, for the lifetime of the memtable.
* Memtables block for the completion of all {{OpOrder.Group}} started before their flush began
* Memtables permit operations from this cohort to fall-through to the following Memtable, in order to guarantee a precise commitLogUpperBound
* Memtable memory limits may be lifted for operations in the first cohort, since they block flush (and hence block future memory allocation)

With very unfortunate scheduling
* A contended partition may rapidly escalate to a mutex
* The system may reach memory limits that prevent allocations for the new Memtable’s cohort (C2) 
* An operation from C2 may hold the mutex when this occurs
* Operations from a prior Memtable’s cohort (C1), for a contended partition, may fall-through to the next Memtable
* The operations from C1 may execute after the above is encountered by those from C2
"
CASSANDRA-15363,Read repair in mixed mode between 2.1 and 3.0 on COMPACT STORAGE tables causes unreadable sstables after upgrade,"if we have a table like this:

{{CREATE TABLE tbl (pk ascii, b boolean, v blob, PRIMARY KEY (pk)) WITH COMPACT STORAGE}}

with a cluster where node1 is 2.1 and node2 is 3.0 (during upgrade):

* node2 coordinates a delete {{DELETE FROM tbl WHERE pk = 'something'}} which node1 does not get
* node1 coordinates a quorum read {{SELECT * FROM tbl WHERE id = 'something'}} which causes a read repair
* this makes node1 flush an sstable like this:
{code}
[
{""key"": ""something"",
 ""metadata"": {""deletionInfo"": {""markedForDeleteAt"":1571388944364000,""localDeletionTime"":1571388944}},
 ""cells"": [[""b"",""b"",1571388944364000,""t"",1571388944],
           [""v"",""v"",1571388944364000,""t"",1571388944]]}
]
{code}
(It has range tombstones which are covered by the partition deletion)

Then, when we upgrade this node to 3.0 and try to read or run upgradesstables, we get this:
{code}
ERROR [node1_CompactionExecutor:1] node1 2019-10-18 10:44:11,325 DebuggableThreadPoolExecutor.java:242 - Error in ThreadPoolExecutor
java.lang.UnsupportedOperationException: null
	at org.apache.cassandra.db.LegacyLayout.extractStaticColumns(LegacyLayout.java:779) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.io.sstable.SSTableSimpleIterator$OldFormatIterator.readStaticRow(SSTableSimpleIterator.java:120) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.<init>(SSTableIdentityIterator.java:57) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1.initializeIterator(BigTableScanner.java:362) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.maybeInit(LazilyInitializedUnfilteredRowIterator.java:48) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.isReverseOrder(LazilyInitializedUnfilteredRowIterator.java:65) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$1.reduce(UnfilteredPartitionIterators.java:103) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$1.reduce(UnfilteredPartitionIterators.java:94) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:442) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$2.hasNext(UnfilteredPartitionIterators.java:144) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:92) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:227) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:190) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.db.compaction.CompactionManager$8.runMayThrow(CompactionManager.java:675) ~[dtest-3.0.19.jar:na]
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[dtest-3.0.19.jar:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_121]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121]
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:83) [dtest-3.0.19.jar:na]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_121]
{code}"
CASSANDRA-15340,Resource leak in CompressedSequentialWriter,"In CompressedSequentialWriter, we reallocate the {{compressed}} buffer if the existing buffer is not large enough. These buffers are usually direct byte buffers, and we don't explicitly release their memory here, which delays release until the buffer is gc'd"
CASSANDRA-15242,Race condition between flushing and compaction stalls compaction indefinitely,"Seen on Cassandra 3.11.4 with OpenJDK 8u212, although I've seen this a few times before, also on 3.11.3. It's a rare issue so I've not bothered with trying to trace it until now.
{noformat}
DEBUG [NativePoolCleaner] 2019-07-18 01:12:41,799 ColumnFamilyStore.java:1325 - Flushing largest CFS(Keyspace='keyspacename', ColumnFamily='tablename') to free up room. Used total: 0.10/0.33, live: 0.10/0.33, flushing: 0.00/0.00, this: 0.09/0.19
DEBUG [NativePoolCleaner] 2019-07-18 01:12:41,800 ColumnFamilyStore.java:935 - Enqueuing flush of tablename: 267.930MiB (9%) on-heap, 575.580MiB (19%) off-heap
DEBUG [PerDiskMemtableFlushWriter_0:204] 2019-07-18 01:12:42,480 Memtable.java:456 - Writing Memtable-tablename@498336646(520.721MiB serialized bytes, 870200 ops, 9%/19% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
INFO  [Service Thread] 2019-07-18 01:12:43,616 GCInspector.java:284 - G1 Young Generation GC in 227ms.  G1 Eden Space: 14713618432 -> 0; G1 Old Gen: 13240876928 -> 13259198848; G1 Survivor Space: 276824064 -> 268435456;
INFO  [Service Thread] 2019-07-18 01:12:56,251 GCInspector.java:284 - G1 Young Generation GC in 206ms.  G1 Eden Space: 14713618432 -> 0; G1 Old Gen: 13259198848 -> 13285123456; G1 Survivor Space: 268435456 -> 285212672;
DEBUG [PerDiskMemtableFlushWriter_0:204] 2019-07-18 01:12:56,693 Memtable.java:485 - Completed flushing /cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db (524.023MiB) for commitlog position CommitLogPosition(segmentId=1563386911266, position=32127822)
DEBUG [MemtableFlushWriter:204] 2019-07-18 01:12:57,620 ColumnFamilyStore.java:1233 - Flushed to [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] (1 sstables, 518.714MiB), biggest 518.714MiB, smallest 518.714MiB
WARN  [CompactionExecutor:1617] 2019-07-18 01:12:57,628 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.
{noformat}
This final line then starts repeating about once per minute:
{noformat}
WARN  [CompactionExecutor:1610] 2019-07-18 01:13:18,898 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1611] 2019-07-18 01:14:18,899 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1622] 2019-07-18 01:15:18,899 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1436] 2019-07-18 01:16:15,073 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1618] 2019-07-18 01:16:18,899 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1611] 2019-07-18 01:17:18,900 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1606] 2019-07-18 01:18:18,900 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1630] 2019-07-18 01:19:18,902 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1627] 2019-07-18 01:20:18,904 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1638] 2019-07-18 01:21:18,904 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1631] 2019-07-18 01:22:18,905 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1636] 2019-07-18 01:22:58,220 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292363-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292342-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292344-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292343-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292340-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292338-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292336-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292335-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292337-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292346-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292349-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.

WARN  [CompactionExecutor:1625] 2019-07-18 01:23:18,905 LeveledCompactionStrategy.java:144 - Could not acquire references for compacting SSTables [BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292363-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292348-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292358-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292342-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292344-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292343-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292340-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292338-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292336-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292335-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292337-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292346-big-Data.db'), BigTableReader(path='/cassandra-data/data/keyspacename/tablename-2c5325e042e911e8a07e9db72d27cf67/md-292349-big-Data.db')] which is not a problem per se,unless it happens frequently, in which case it must be reported. Will retry later.{noformat}
It will keep going like this for days, until restarted, but compaction won't run until then, so sstables pile up."
CASSANDRA-15201,LegacyLayout does not handle paging states that cross a collection column,"{{LegacyLayout.decodeBound}} assumes there is only a single extra component, referring to a column name.  In fact an encoded page boundary may include a collection column, and this occurs as a matter of course when paging a table whose last column is a collection."
CASSANDRA-15193,Add ability to cap max negotiable protocol version,"3.0 and native protocol V4 introduced a change to how PagingState is serialized. Unfortunately that can break requests during upgrades: since paging states are opaque, it's possible for a client to receive a paging state encoded as V3 on a 2.1 node, and then send it to a 3.0 node on a V4 session. The version of the current session will be used to deserialize the paging state, instead of the actual version used to serialize it, and the request will fail.

CASSANDRA-15176 solves half of this problem by enabling 3.0 nodes to serialize mis-versioned PagingStates. To address the other side of the issue, 2.1 nodes receiving V4 PagingStates, we can introduce a property to cap the max native protocol version that the 3.0 nodes will negotiate with clients. If we cap this to V3 during upgrades, no V4 connections will be established and so no incompatible PagingStates will be sent to clients."
CASSANDRA-15176,Fix PagingState deserialization when the state was serialized using protocol version different from current session's,"3.0 and native protocol V4 introduced a change to how {{PagingState}} is serialized. Unfortunately that can break requests during upgrades: since paging states are opaque, it's possible for a client to receive a paging state encoded as V3 on a 2.1 node, and then send it to a 3.0 node on a V4 session. The version of the current session will be used to deserialize the paging state, instead of the actual version used to serialize it, and the request will fail.

This is obviously sub-optimal, but also avoidable. This JIRA fixes one half of the problem: 3.0 failing to deserialize 'mislabeled' paging states. We can do this by inspecting the byte buffer to verify if it's been indeed serialized with the protocol version used by the session, and if not, use the other method of deserialization.

It should be noted that we list this as a 'known limitation' somewhere, but really this is an upgrade-blocking bug for some users of C*."
CASSANDRA-15172,LegacyLayout RangeTombstoneList throws IndexOutOfBoundsException,"Hi All,

This is the first time I open an issue, so apologies if I'm not following the rules properly.

 

After upgrading a node from version 2.1.21 to 3.11.4, we've started seeing a lot of AbstractLocalAwareExecutorService exceptions. This happened right after the node successfully started up with the new 3.11.4 binaries. 
{noformat}
INFO  [main] 2019-06-05 04:41:37,730 Gossiper.java:1715 - No gossip backlog; proceeding
INFO  [main] 2019-06-05 04:41:38,036 NativeTransportService.java:70 - Netty using native Epoll event loop
INFO  [main] 2019-06-05 04:41:38,117 Server.java:155 - Using Netty Version: [netty-buffer=netty-buffer-4.0.44.Final.452812a, netty-codec=netty-codec-4.0.44.Final.452812a, netty-codec-haproxy=netty-codec-haproxy-4.0.44.Final.452812a, netty-codec-http=netty-codec-http-4.0.44.Final.452812a, netty-codec-socks=netty-codec-socks-4.0.44.Final.452812a, netty-common=netty-common-4.0.44.Final.452812a, netty-handler=netty-handler-4.0.44.Final.452812a, netty-tcnative=netty-tcnative-1.1.33.Fork26.142ecbb, netty-transport=netty-transport-4.0.44.Final.452812a, netty-transport-native-epoll=netty-transport-native-epoll-4.0.44.Final.452812a, netty-transport-rxtx=netty-transport-rxtx-4.0.44.Final.452812a, netty-transport-sctp=netty-transport-sctp-4.0.44.Final.452812a, netty-transport-udt=netty-transport-udt-4.0.44.Final.452812a]
INFO  [main] 2019-06-05 04:41:38,118 Server.java:156 - Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...
INFO  [main] 2019-06-05 04:41:38,179 CassandraDaemon.java:556 - Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it
INFO  [Native-Transport-Requests-21] 2019-06-05 04:41:39,145 AuthCache.java:161 - (Re)initializing PermissionsCache (validity period/update interval/max entries) (2000/2000/1000)
INFO  [OptionalTasks:1] 2019-06-05 04:41:39,729 CassandraAuthorizer.java:409 - Converting legacy permissions data
INFO  [HANDSHAKE-/10.10.10.8] 2019-06-05 04:41:39,808 OutboundTcpConnection.java:561 - Handshaking version with /10.10.10.8
INFO  [HANDSHAKE-/10.10.10.9] 2019-06-05 04:41:39,808 OutboundTcpConnection.java:561 - Handshaking version with /10.10.10.9
INFO  [HANDSHAKE-dc1_02/10.10.10.6] 2019-06-05 04:41:39,809 OutboundTcpConnection.java:561 - Handshaking version with dc1_02/10.10.10.6

WARN  [ReadStage-2] 2019-06-05 04:41:39,857 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-2,5,main]: {}
java.lang.ArrayIndexOutOfBoundsException: 1
        at org.apache.cassandra.db.AbstractBufferClusteringPrefix.get(AbstractBufferClusteringPrefix.java:55)
        at org.apache.cassandra.db.LegacyLayout$LegacyRangeTombstoneList.serializedSizeCompound(LegacyLayout.java:2545)
        at org.apache.cassandra.db.LegacyLayout$LegacyRangeTombstoneList.serializedSize(LegacyLayout.java:2522)
        at org.apache.cassandra.db.LegacyLayout.serializedSizeAsLegacyPartition(LegacyLayout.java:565)
        at org.apache.cassandra.db.ReadResponse$Serializer.serializedSize(ReadResponse.java:446)
        at org.apache.cassandra.db.ReadResponse$Serializer.serializedSize(ReadResponse.java:352)
        at org.apache.cassandra.net.MessageOut.payloadSize(MessageOut.java:171)
        at org.apache.cassandra.net.OutboundTcpConnectionPool.getConnection(OutboundTcpConnectionPool.java:77)
        at org.apache.cassandra.net.MessagingService.getConnection(MessagingService.java:802)
        at org.apache.cassandra.net.MessagingService.sendOneWay(MessagingService.java:953)
        at org.apache.cassandra.net.MessagingService.sendReply(MessagingService.java:929)
        at org.apache.cassandra.db.ReadCommandVerbHandler.doVerb(ReadCommandVerbHandler.java:62)
        at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162)
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134)
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:114)
        at java.lang.Thread.run(Thread.java:745)
 {noformat}

 

After several of the above warnings, the following warning appeared as well:

 {noformat}
WARN  [ReadStage-9] 2019-06-05 04:42:04,369 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-9,5,main]: {}
java.lang.ArrayIndexOutOfBoundsException: null
WARN  [ReadStage-11] 2019-06-05 04:42:04,381 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-11,5,main]: {}
java.lang.ArrayIndexOutOfBoundsException: null
WARN  [ReadStage-10] 2019-06-05 04:42:04,396 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-10,5,main]: {}
java.lang.ArrayIndexOutOfBoundsException: null
WARN  [ReadStage-2] 2019-06-05 04:42:04,443 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-2,5,main]: {}
java.lang.ArrayIndexOutOfBoundsException: null

 {noformat}
 

Then suddenly, Validation errors appeared although *no repair was running on any of the nodes*! Checked with {{ps -ef}} command and {{nodetool compactionstats}} on the entire cluster.

 

 {noformat}
ERROR [ValidationExecutor:2] 2019-06-05 04:42:47,979 Validator.java:268 - Failed creating a merkle tree for [repair #e54b4090-876d-11e9-a3f4-c33d22c45471 on ks1/table1, []], /
10.10.10.6 (see log for details)
ERROR [ValidationExecutor:2] 2019-06-05 04:42:47,979 CassandraDaemon.java:228 - Exception in thread Thread[ValidationExecutor:2,1,main]
java.lang.NullPointerException: null
        at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1363)
        at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:83)
        at org.apache.cassandra.db.compaction.CompactionManager$13.call(CompactionManager.java:977)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81)
        at java.lang.Thread.run(Thread.java:745)
 {noformat}
 

Following those, client requests started to fail and NTR tasks started to pile up and get blocked and GC was impacted.

 {noformat}
INFO  [ScheduledTasks:1] 2019-06-05 04:43:11,660 StatusLogger.java:51 - Native-Transport-Requests       128       197         594810        65              2725
 {noformat}

 

FWIW, these are the warnings I found during startup: 

 {noformat}
-WARN in net.logstash.logback.encoder.LogstashEncoder@140e5a13 - Logback version is prior to 1.2.0.  Enabling backwards compatible encoding.  Logback 1.2.1 or greater is recommended.
 {noformat}

 

 {noformat}
WARN  [main] 2019-06-05 08:44:18,568 NativeLibrary.java:187 - Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.
WARN  [main] 2019-06-05 08:44:18,569 StartupChecks.java:136 - jemalloc shared library could not be preloaded to speed up memory allocations

 

WARN  [main] 2019-06-05 08:44:20,225 Optional.java:159 - Legacy auth tables credentials, users, permissions in keyspace system_auth still exist and have not been properly migrated.

WARN  [MessagingService-Outgoing-dc1_03/10.10.10.4-Gossip] 2019-06-05 08:44:49,582 OutboundTcpConnection.java:486 - Seed gossip version is 8; will not connect with that version
WARN  [MessagingService-Outgoing-dc2_02/10.20.20.4-Gossip] 2019-06-05 08:44:49,620 OutboundTcpConnection.java:486 - Seed gossip version is 8; will not connect with that version
WARN  [MessagingService-Outgoing-dc2_01/10.20.20.1-Gossip] 2019-06-05 08:44:49,621 OutboundTcpConnection.java:486 - Seed gossip version is 8; will not connect with that version
WARN  [MessagingService-Outgoing-dc2_03/10.20.20.5-Gossip] 2019-06-05 08:44:49,621 OutboundTcpConnection.java:486 - Seed gossip version is 8; will not connect with that version
WARN  [GossipTasks:1] 2019-06-05 08:44:51,631 FailureDetector.java:278 - Not marking nodes down due to local pause of 30943606906 > 5000000000
 {noformat}

 

We've naturally stopped the upgrade but we still wish to upgrade from 2.1.21 and hopefully find the root cause of this matter. 
I'll be happy to provide additional details if needs be.

 

 "
CASSANDRA-15169,SASI does not compare strings correctly,"In our scenario, we need to query with '>' conditions on string columns. So I created index with  is_literal = false. like the following:

 
{code:java}
CREATE TABLE test (id int primary key, t text);

CREATE CUSTOM INDEX ON test (t) USING 'org.apache.cassandra.index.sasi.SASIIndex' WITH OPTIONS = {'is_literal': 'false'};
{code}
 I also inserted some records and query:

 
{code:java}
insert into test(id,t) values(1,'abc');
select * from test where t > 'ab';
{code}
At first ,it worked. But after flush, the query returned none record.

I have read the code of SASIIndex and found that it is because in the 
{code:java}
Expression.isLowerSatisfiedBy{code}
function,
{code:java}
term.compareTo{code}
was called with parameter checkFully=false, which cause the string 'abc' was only compared with its first 2 characters( length of expression value).

 

I have wrote a UT for this case and fixed it."
CASSANDRA-15164,Overflowed Partition Cell Histograms Can Prevent Compactions from Executing,"Hi, we are running 6 node Cassandra cluster in production with 3 seed node but from last night one of our seed nodes is continuously throwing an error like this;-

cassandra.protocol.ServerError: <Error from server: code=0000 [Server error] message=""java.lang.IllegalStateException: Unable to compute ceiling for max when histogram overflowed"">

For a cluster to be up and running I Drained this node.

Can somebody help me out with this?

 

Any help or lead would be appreciated 

 

Note : We are using Cassandra version 3.7"
CASSANDRA-15158,Wait for schema agreement rather than in flight schema requests when bootstrapping,"Currently when a node is bootstrapping we use a set of latches (org.apache.cassandra.service.MigrationTask#inflightTasks) to keep track of in-flight schema pull requests, and we don't proceed with bootstrapping/stream until all the latches are released (or we timeout waiting for each one). One issue with this is that if we have a large schema, or the retrieval of the schema from the other nodes was unexpectedly slow then we have no explicit check in place to ensure we have actually received a schema before we proceed.

While it's possible to increase ""migration_task_wait_in_seconds"" to force the node to wait on each latche longer, there are cases where this doesn't help because the callbacks for the schema pull requests have expired off the messaging service's callback map (org.apache.cassandra.net.MessagingService#callbacks) after request_timeout_in_ms (default 10 seconds) before the other nodes were able to respond to the new node.

This patch checks for schema agreement between the bootstrapping node and the rest of the live nodes before proceeding with bootstrapping. It also adds a check to prevent the new node from flooding existing nodes with simultaneous schema pull requests as can happen in large clusters.

Removing the latch system should also prevent new nodes in large clusters getting stuck for extended amounts of time as they wait `migration_task_wait_in_seconds` on each of the latches left orphaned by the timed out callbacks.

 
||3.11||
|[PoC|https://github.com/apache/cassandra/compare/cassandra-3.11...vincewhite:check_for_schema]|
|[dtest|https://github.com/apache/cassandra-dtest/compare/master...vincewhite:wait_for_schema_agreement]|

 "
CASSANDRA-15126,Resource leak when queries apply a RowFilter,"RowFilter.CQLFilter optionally removes those partitions that have no matching results, but fails to close the iterator representing that partition’s unfiltered results, leaking resources when this happens."
CASSANDRA-15084,failed compactions in specific cluster version 3.11.2,"We are using Cassandra version 3.11.2

In our biggest cluster, in the biggest table compactions keep failing.

The amount of data in every node is around 900GB.

After we run the compaction, we monitor the process using nodetool compactionstats and can see the progress continue until it reached 99.99% of the progress.

In this point the compaction fail with the error below

In addition, we increased index_summary_capacity_in_mb few times until the size of 4GB, but with no help.

 
ERROR [CompactionExecutor:26976] 2019-04-11 13:55:24,917 CassandraDaemon.java:228 - Exception in thread Thread[CompactionExecutor:26976,1,main]
java.lang.IllegalArgumentException: null
        at java.nio.Buffer.position(Buffer.java:244) ~[na:1.8.0_144]
        at org.apache.cassandra.io.util.SafeMemoryWriter.reallocate(SafeMemoryWriter.java:59) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.io.util.SafeMemoryWriter.setCapacity(SafeMemoryWriter.java:68) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.io.sstable.IndexSummaryBuilder.prepareToCommit(IndexSummaryBuilder.java:250) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.io.sstable.format.big.BigTableWriter$IndexWriter.doPrepare(BigTableWriter.java:524) ~[apache-cassandra-3.11.2.jar:3.11.
2]
        at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173) ~[apache-cassandra-3.11.2.
jar:3.11.2]
        at org.apache.cassandra.io.sstable.format.big.BigTableWriter$TransactionalProxy.doPrepare(BigTableWriter.java:364) ~[apache-cassandra-3.11.2.ja
r:3.11.2]
        at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173) ~[apache-cassandra-3.11.2.
jar:3.11.2]
        at org.apache.cassandra.io.sstable.format.SSTableWriter.prepareToCommit(SSTableWriter.java:281) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.io.sstable.SSTableRewriter.doPrepare(SSTableRewriter.java:379) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173) ~[apache-cassandra-3.11.2.
jar:3.11.2]
        at [org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.doPrepare(CompactionAwareWriter.java:112|http://org.apache.cassandra.db.compaction.writers.compactionawarewriter.doprepare%28compactionawarewriter.java:112/]) ~[apache-cassandra-3.11.2.jar:3.1
1.2]
        at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173) ~[apache-cassandra-3.11.2.
jar:3.11.2]
        at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.finish(Transactional.java:184) ~[apache-cassandra-3.11.2.jar:3.11.
2]
        at [org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.finish(CompactionAwareWriter.java:122|http://org.apache.cassandra.db.compaction.writers.compactionawarewriter.finish%28compactionawarewriter.java:122/]) ~[apache-cassandra-3.11.2.jar:3.11.2
]
        at [org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:220|http://org.apache.cassandra.db.compaction.compactiontask.runmaythrow%28compactiontask.java:220/]) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at [org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:85|http://org.apache.cassandra.db.compaction.compactiontask.executeinternal%28compactiontask.java:85/]) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at [org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61|http://org.apache.cassandra.db.compaction.abstractcompactiontask.execute%28abstractcompactiontask.java:61/]) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at [org.apache.cassandra.db.compaction.CompactionManager$10.runMayThrow(CompactionManager.java:746|http://org.apache.cassandra.db.compaction.compactionmanager%2410.runmaythrow%28compactionmanager.java:746/]) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.11.2.jar:3.11.2]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_144]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_144]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_144]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_144]
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) [apache-cassandra-3.11.2.jar:3.11.2]"
CASSANDRA-15072,Incomplete range results during 2.X -> 3.11.4 upgrade,"Hello

During an upgrade from 2.1.17 to 3.11.4, our application starting getting back incomplete results for range queries. When all nodes were upgraded (before upgrading sstables), we stopped getting incomplete results. I was able to reproduce it and listed steps below. It seems to require the random partitioner and compact storage to reproduce reliably. It also reproduces coming from 2.1.21 and 2.2.14. You seem to get the bad behavior when an old node is your coordinator and it has to talk to an upgraded replica.
{noformat}
ccm create test -v 2.1.17 -n 3
ccm updateconf 'partitioner: org.apache.cassandra.dht.RandomPartitioner'
ccm node1 updateconf 'initial_token: 0'
ccm node2 updateconf 'initial_token: 56713727820156410577229101238628035242'
ccm node3 updateconf 'initial_token: 113427455640312821154458202477256070484'
ccm start

ccm node1 cqlsh <<SCHEMA
CREATE KEYSPACE test WITH REPLICATION = {'class': 'SimpleStrategy', 'replication_factor': 3};
CREATE COLUMNFAMILY test.test (
  id text,
  foo text,
  bar text,
  PRIMARY KEY (id)
) WITH COMPACT STORAGE;
CONSISTENCY QUORUM;
INSERT INTO test.test (id, foo, bar) values ('1', 'hi', 'there');
INSERT INTO test.test (id, foo, bar) values ('2', 'hi', 'there');
SCHEMA

ccm node1 stop
ccm node1 setdir -v 3.11.4
ccm node1 start

ccm node2 stop
ccm node2 setdir -v 3.11.4
ccm node2 start

# here I use 3.X cqlsh to connect to 2.X node so I can lower the page size (to
# allow for simpler test setup)
cqlsh 127.0.0.3 <<QUERY
CONSISTENCY QUORUM;
PAGING 2;
select * from test.test;
QUERY
{noformat}
This results in:
{noformat}
Page size: 2

 id | bar   | foo
----+-------+-----
  2 | there |  hi

(1 rows)
{noformat}
Running it against the upgraded node (node1):
{noformat}
Page size: 2

 id | bar   | foo
----+-------+-----
  2 | there |  hi
  1 | there |  hi

(2 rows)
{noformat}"
CASSANDRA-15069,Tombstone/Partition not purged after gc_grace_seconds,"During a tombstone purge (reducing gc_grace_seconds to zero and running `nodetool garbagecollect`), I noticed that when doing a dump of the SSTable, sometimes, there are a few partitions that do not get completely purged, even with gc_grace_seconds set to zero. I was able to replicate this in a small test dataset, from which I have attached the SSTable files and the schema to this ticket so that you can verify this as well. 
Doing a dump of the mc-51-big-Data.db file, you'll notice the following partition:

{
    ""partition"" : {
      ""key"" : [ ""96"" ],
      ""position"" : 285,
      ""deletion_info"" : { ""marked_deleted"" : ""2019-03-14T21:31:55.244490Z"", ""local_delete_time"" : ""2019-03-14T21:31:55Z"" }
    },
    ""rows"" : [ ]
  },

As you can see, the rows were removed correctly by the garbagecollect, but the partition record, continues there, and never goes away.
From the client side, no data is returned, so it's good there. But regardless of that, this partition should not be present in the SSTable file."
CASSANDRA-15059,Gossiper#markAlive can race with Gossiper#markDead,"The Gossiper class is not threadsafe and assumes all state changes happen in a single thread (the gossip stage). Gossiper#convict, however, can be called from the GossipTasks thread. This creates a race where calls to Gossiper#markAlive and Gossiper#markDead can interleave, corrupting gossip state. Gossiper#assassinateEndpoint has a similar problem, being called from the mbean server thread."
CASSANDRA-15041,UncheckedExecutionException if authentication/authorization query fails,"If cache update for permissions/credentials/roles fails with UnavailableException this comes back to client as UncheckedExecutionException.

Stack trace on server side:
{noformat}
ERROR [Native-Transport-Requests-1] 2019-03-04 16:30:51,537 ErrorMessage.java:384 - Unexpected exception during request
com.google.common.util.concurrent.UncheckedExecutionException: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2203) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache.get(LocalCache.java:3937) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3941) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4824) ~[guava-18.0.jar:na]
        at org.apache.cassandra.auth.AuthCache.get(AuthCache.java:97) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.PermissionsCache.getPermissions(PermissionsCache.java:45) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthenticatedUser.getPermissions(AuthenticatedUser.java:104) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.ClientState.authorize(ClientState.java:439) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.ClientState.checkPermissionOnResourceChain(ClientState.java:368) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.ClientState.ensureHasPermission(ClientState.java:345) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.ClientState.hasAccess(ClientState.java:332) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.ClientState.hasColumnFamilyAccess(ClientState.java:310) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.statements.ModificationStatement.checkAccess(ModificationStatement.java:211) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:222) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:532) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:509) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:146) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:566) [apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.11.4.jar:3.11.4]
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_181]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:114) [apache-cassandra-3.11.4.jar:3.11.4]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]
Caused by: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2203) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache.get(LocalCache.java:3937) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3941) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4824) ~[guava-18.0.jar:na]
        at org.apache.cassandra.auth.AuthCache.get(AuthCache.java:97) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.RolesCache.getRoles(RolesCache.java:44) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.Roles.hasSuperuserStatus(Roles.java:51) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthenticatedUser.isSuper(AuthenticatedUser.java:71) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraAuthorizer.authorize(CassandraAuthorizer.java:81) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.PermissionsCache.lambda$new$0(PermissionsCache.java:37) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthCache$1.load(AuthCache.java:172) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3527) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2319) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2282) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2197) ~[guava-18.0.jar:na]
        ... 26 common frames omitted
Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at org.apache.cassandra.auth.CassandraRoleManager.getRole(CassandraRoleManager.java:518) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.getRoles(CassandraRoleManager.java:283) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.RolesCache.lambda$new$0(RolesCache.java:36) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthCache$1.load(AuthCache.java:172) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3527) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2319) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2282) ~[guava-18.0.jar:na]
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2197) ~[guava-18.0.jar:na]
        ... 40 common frames omitted
Caused by: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at org.apache.cassandra.db.ConsistencyLevel.assureSufficientLiveNodes(ConsistencyLevel.java:334) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.AbstractReadExecutor.getReadExecutor(AbstractReadExecutor.java:162) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy$SinglePartitionReadLifecycle.<init>(StorageProxy.java:1766) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.fetchRows(StorageProxy.java:1728) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.readRegular(StorageProxy.java:1671) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.read(StorageProxy.java:1586) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.db.SinglePartitionReadCommand$Group.execute(SinglePartitionReadCommand.java:1209) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:315) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:285) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.getRoleFromTable(CassandraRoleManager.java:526) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.getRole(CassandraRoleManager.java:508) ~[apache-cassandra-3.11.4.jar:3.11.4]
        ... 47 common frames omitted
{noformat}
Also, if {{x_validity_in_ms}} > {{x_update_interval_in_ms}}, then the background update thread will fail in a similar way:
{noformat}
ERROR [PermissionsCacheRefresh:1] 2019-03-04 16:30:43,541 CassandraDaemon.java:228 - Exception in thread Thread[PermissionsCacheRefresh:1,5,main]
java.lang.RuntimeException: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at org.apache.cassandra.auth.CassandraRoleManager.getRole(CassandraRoleManager.java:518) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.isSuper(CassandraRoleManager.java:307) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.Roles.hasSuperuserStatus(Roles.java:52) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthenticatedUser.isSuper(AuthenticatedUser.java:71) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraAuthorizer.authorize(CassandraAuthorizer.java:81) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.PermissionsCache.lambda$new$0(PermissionsCache.java:37) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.AuthCache$1.lambda$reload$0(AuthCache.java:180) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_181]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_181]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_181]
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) [apache-cassandra-3.11.4.jar:3.11.4]
        at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_181]
Caused by: org.apache.cassandra.exceptions.UnavailableException: Cannot achieve consistency level QUORUM
        at org.apache.cassandra.db.ConsistencyLevel.assureSufficientLiveNodes(ConsistencyLevel.java:334) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.AbstractReadExecutor.getReadExecutor(AbstractReadExecutor.java:162) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy$SinglePartitionReadLifecycle.<init>(StorageProxy.java:1766) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.fetchRows(StorageProxy.java:1728) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.readRegular(StorageProxy.java:1671) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.service.StorageProxy.read(StorageProxy.java:1586) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.db.SinglePartitionReadCommand$Group.execute(SinglePartitionReadCommand.java:1209) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:315) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:285) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.getRoleFromTable(CassandraRoleManager.java:526) ~[apache-cassandra-3.11.4.jar:3.11.4]
        at org.apache.cassandra.auth.CassandraRoleManager.getRole(CassandraRoleManager.java:508) ~[apache-cassandra-3.11.4.jar:3.11.4]
        ... 11 common frames omitted
{noformat}
 "
CASSANDRA-15039,Documentation claims copyright for future years,"See attached patch for details and fix.

 
See also on this topic:
[https://stackoverflow.com/questions/2390230/do-copyright-dates-need-to-be-updated]
 "
CASSANDRA-15035,C* 3.0 sstables w/ UDTs are corrupted in 3.11 + 4.0,"OSS C* 3.0 writes incorrect type information for UDTs into the serialization-header of each sstable.

In C* 3.0, both UDTs and tuple are always frozen. A frozen type must be enclosed in a {{frozen<...>}} via the {{CQL3Type}} hierarchy (resp {{org.apache.cassandra.db.marshal.FrozenType(...)}} via the {{AbstractType}} hierarchy) “bracket” in the schema and serialization-header.

Since CASSANDRA-7423 (committed to C* 3.6) UDTs can also be non-frozen (= multi-cell).

Unfortunately, C* 3.0 does not write the {{org.apache.cassandra.db.marshal.FrozenType(...)}} “bracket” for UDTs into the {{SerializationHeader.Component}} in the {{-Stats.db}} sstable component.

The order in which columns of a row are serialized depends on the concrete {{AbstractType}}. Columns with variable length types (frozen types belong to this category) are serialized before columns with multi-cell types (non-frozen types belong to that category).

If C* 3.6 (or any newer version) reads an sstable written by C* 3.0 (up to 3.5), it will read the type information “non-frozen UDT” from the serialization header, which is technically correct.

This means, that upgrades from C* 3.0 to C* 3.11 and 4.0, using a schema that uses UDTs, result in inaccessible data in those sstables. Reads against 3.0 sstables as well as attempts to scrub these sstables result in a wide variety of errors/exceptions ({{CorruptSSTableException}}, {{EOFExcepiton}}, {{OutOfMemoryError}}, etc etc), as usual in such cases.

Mitigation strategy in the proposed patch:
* Fix the broken serialization-headers automatically when an upgrade from C* 3.0 is detected.
* Enhance {{sstablescrub}} to verify the serialization-header against the schema and allow {{sstablescrub}} to fix the UDT types according to the information in the schema. This does not apply to ""online scrub"" (e.g. nodetool scrub). The behavior of {{sstablescrub}} has been changed to first inspect the serialization-header and verify the type information against the schema. 

Differences between the schema and the sstable serialization-headers cause {{sstablescrub}} to error out and stop - i.e. safety first (there’s a way to opt-out though).

A new class {{SSTableHeaderFix}} can inspect the serialization-header ({{SerializationHeader.Component}}) in the the {{-Statistics.db}} component and fix the type information in those sstables for UDTs according to the schema information.

This new class could be used during verify and before sstables are imported. But changes to “verify” and “import” are out of the scope of this ticket, as the patch is already bigger than I originally expected.

Another issue not tackled by this ticket is that the wrong ‘kind’ is written to the type information in {{system_schema.dropped_columns}} when a non-frozen UDT column is dropped. When a UDT column is dropped, the type of the dropped column is converted from the UDT definition to its “corresponding” tuple type definition. But all versions currently write {{frozen<tuple<...>>}}, but for non-frozen UDTs it should actually just be {{tuple<...>}}. Unfortunately, there is nothing that could be done in this ticket to fix (or even consider) the type information of a dropped column. But for correctness, the tuple type should be a multi-cell one (only accessible for dropped UDTs though - not as something that a user can create as a type).
"
CASSANDRA-15014,Unit tests failure on trunk,"Currently org.apache.cassandra.distributed.test.DistributedReadWritePathTest is failing on trunk with the following error -
{code:java}
[junit-timeout] Picked up JAVA_TOOL_OPTIONS: -Dfile.encoding=UTF8
[junit-timeout] Testsuite: org.apache.cassandra.distributed.test.DistributedReadWritePathTest
[junit-timeout] Exception in thread ""main"" java.lang.OutOfMemoryError: Metaspace
[junit-timeout] Testsuite: org.apache.cassandra.distributed.test.DistributedReadWritePathTest
[junit-timeout] Testsuite: org.apache.cassandra.distributed.test.DistributedReadWritePathTest Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0 sec
[junit-timeout] 
[junit-timeout] Testcase: org.apache.cassandra.distributed.test.DistributedReadWritePathTest:readWithSchemaDisagreement: Caused an ERROR
[junit-timeout] Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
[junit-timeout] junit.framework.AssertionFailedError: Forked Java VM exited abnormally. Please note the time in the report does not reflect the time until the VM exit.
[junit-timeout] at java.util.Vector.forEach(Vector.java:1275)
[junit-timeout] at java.util.Vector.forEach(Vector.java:1275)
[junit-timeout] at java.lang.Thread.run(Thread.java:748)
[junit-timeout] 
[junit-timeout] 
[junit-timeout] Test org.apache.cassandra.distributed.test.DistributedReadWritePathTest FAILED (crashed)
[junitreport] Processing /tmp/cassandra/build/test/TESTS-TestSuites.xml to /tmp/null1041131060
[junitreport] Loading stylesheet jar:file:/usr/share/ant/lib/ant-junit.jar!/org/apache/tools/ant/taskdefs/optional/junit/xsl/junit-frames.xsl
[junitreport] Transform time: 277ms
[junitreport] Deleting: /tmp/null1041131060{code}
I have noticed sporadic failures in the org.apache.cassandra.distributed.test.* suite."
CASSANDRA-15013,Prevent client requests from blocking on executor task queue,"This is a follow-up ticket out of CASSANDRA-14855, to make the Flusher queue bounded, since, in the current state, items get added to the queue without any checks on queue size, nor with any checks on netty outbound buffer to check the isWritable state.
We are seeing this issue hit our production 3.0 clusters quite often."
CASSANDRA-14958,Counters fail to increment in 2.1/2.2 to 3.X mixed version clusters,"The upgrade test for this is failing
https://circleci.com/gh/aweisberg/cassandra/2362#tests/containers/1

I confirmed that this is occurring manually using cqlsh against the cluster constructed by the dtest.
{noformat}
cqlsh> describe schema;

CREATE KEYSPACE ks WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;

CREATE TABLE ks.clicks (
    userid int,
    url text,
    total counter,
    PRIMARY KEY (userid, url)
) WITH COMPACT STORAGE
    AND CLUSTERING ORDER BY (url ASC)
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.1
    AND default_time_to_live = 0
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';

cqlsh> use ks;
cqlsh:ks> UPDATE clicks SET total = total + 1 WHERE userid = 1 AND url = 'http://foo.com';
cqlsh:ks> SELECT total FROM clicks WHERE userid = 1 AND url = 'http://foo.com'
      ... ;

 total
-------
     0

(1 rows)
{noformat}"
CASSANDRA-14952,NPE when using allocate_tokens_for_keyspace and add new DC,"Received following NPE while bootstrapping very first node in the new datacenter with {{allocate_tokens_for_keyspace}} yaml option
{code:java}
INFO  21:44:13 JOINING: getting bootstrap token
Exception (java.lang.NullPointerException) encountered during startup: null
java.lang.NullPointerException
	at org.apache.cassandra.dht.tokenallocator.TokenAllocation.getStrategy(TokenAllocation.java:208)
	at org.apache.cassandra.dht.tokenallocator.TokenAllocation.getStrategy(TokenAllocation.java:170)
	at org.apache.cassandra.dht.tokenallocator.TokenAllocation.allocateTokens(TokenAllocation.java:55)
	at org.apache.cassandra.dht.BootStrapper.allocateTokens(BootStrapper.java:206)
	at org.apache.cassandra.dht.BootStrapper.getBootstrapTokens(BootStrapper.java:173)
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:854)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:666)
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:579)
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:351)
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:586)
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:714)

{code}
Please find reproducible steps here:
 1. Set {{allocate_tokens_for_keyspace}} property with {{Networktopologystrategy}} say {{{{Networktopologystrategy, 'dc1' : 1, 'dc2' : 1}}}}
 2. Start first node in {{dc1}}
 3. Now bootstrap second node in {{dc2,}} it will throw above exception.

RCA:
 [doAddEndpoint|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/locator/TokenMetadata.java#L1325] is invoked from the [bootstrap|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/StorageService.java#L1254] and at this time [local node's rack information|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/locator/TokenMetadata.java#L1276] is available

However with have {{allocate_tokens_for_keyspace}} option, daemon tries to access rack information even before calling [bootstrap|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/StorageService.java#L1241] function, at [this place|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/StorageService.java#L878] which results in NPE

Fix:
 Since this is applicable to only very first node for new dc, we can check for {{null}} as:
{code:java}
diff --git a/src/java/org/apache/cassandra/dht/tokenallocator/TokenAllocation.java b/src/java/org/apache/cassandra/dht/tokenallocator/TokenAllocation.java
index 8d8a6ffeca..e162757d95 100644
--- a/src/java/org/apache/cassandra/dht/tokenallocator/TokenAllocation.java
+++ b/src/java/org/apache/cassandra/dht/tokenallocator/TokenAllocation.java
@@ -205,7 +205,11 @@ public class TokenAllocation
         final int replicas = rs.getReplicationFactor(dc);
 
         Topology topology = tokenMetadata.getTopology();
-        int racks = topology.getDatacenterRacks().get(dc).asMap().size();
+        int racks = 1;
+        if (topology.getDatacenterRacks().get(dc) != null)
+        {
+            racks = topology.getDatacenterRacks().get(dc).asMap().size();
+        }
 
         if (racks >= replicas)
         {
{code}
Let me know your comments."
CASSANDRA-14928,MigrationManager attempts to pull schema from different major version nodes,"MigrationManager will do the version check against nodes it hasn't connected to yet so it doesn't know their messaging service version. We should also check the version in gossip as an additional layer of protection.

This causes many of the upgrade tests to fail."
CASSANDRA-14919,Regression in paging queries in mixed version clusters ,"The changes to handling legacy bounds in CASSANDRA-14568/CASSANDRA-14749/CASSANDRA-14912 break paging queries where the coordinator is a legacy node and the replica is an upgraded node. 

The long-held assumption made by {{LegacyLayout::decodeBound}} that ""There can be more components than the clustering size only in the case this is the bound of a collection range tombstone."" is not true as serialized paged read commands may also include these type of bounds in their {{SliceQueryFilter}}. The additional checks the more recent tickets add cause such queries to error when processed by a 3.0 replica."
CASSANDRA-14903,Nodetool cfstats prints index name twice,"{code:java}
CREATE TABLE test.test (
id int PRIMARY KEY,
data text
);
CREATE INDEX test_data_idx ON test.test (data);

ccm node1 nodetool cfstats test

Total number of tables: 40
----------------
Keyspace : test
Read Count: 0
Read Latency: NaN ms
Write Count: 0
Write Latency: NaN ms
Pending Flushes: 0
Table (index): test.test_data_idxtest.test_data_idx
{code}"
CASSANDRA-14900,DigestMismatchException log messages should be at TRACE,"DigestMismatchException log messages should probably be at TRACE. These log messages about normal digest mismatches that include scary stacktraces:

{noformat}
DEBUG [ReadRepairStage:40] 2017-10-24 19:45:50,349  ReadCallback.java:242 - Digest mismatch:
org.apache.cassandra.service.DigestMismatchException: Mismatch for key DecoratedKey(-786225366477494582, 31302e33322e37382e31332d6765744469736b5574696c50657263656e742d736463) (943070f62d72259e3c25be0c6f76e489 vs f4c7c7675c803e0028992e11e0bbc5a0)
        at org.apache.cassandra.service.DigestResolver.compareResponses(DigestResolver.java:92) ~[cassandra-all-3.11.0.1855.jar:3.11.0.1855]
        at org.apache.cassandra.service.ReadCallback$AsyncRepairRunner.run(ReadCallback.java:233) ~[cassandra-all-3.11.0.1855.jar:3.11.0.1855]
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_121]
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121]
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) [cassandra-all-3.11.0.1855.jar:3.11.0.1855]
        at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_121]
{noformat}"
CASSANDRA-14894,RangeTombstoneList doesn't properly clean up mergeable or superseded rts in some cases,"There are a few scenarios RangeTombstoneList doesn't handle correctly.

If there are 2 overlapping range tombstones with identical timestamps, they should be merged. Instead, they're stored as 2 rts with congruent bounds and identical timestamps.

If a range tombstone supersedes multiple sequential range tombstones, instead of removing them, they cause the superseding rt to be split into multiple rts with congruent bounds and identical timestamps.

When converted to an UnfilteredRowIterator, these become extra boundary markers with the same timestamp on each side. Logically these are noops, but they do cause digest mismatches which will cause unneeded read repairs, and repair overstreaming (since they're also included in flushed sstables).

Also, not sure if this is reachable in practice, but querying RTL with an empty slice that covers a range tombstone causes an rt to be returned with an empty slice. If reachable this might cause extra read repairs as well."
CASSANDRA-14884,"Move TWCS message ""No compaction necessary for bucket size"" to Trace level","When using TWCS, this message sometimes spams the debug logs:

DEBUG [CompactionExecutor:4993|https://datastax.jira.com/wiki/display/CompactionExecutor/4993] 2018-04-20 00:41:13,795 TimeWindowCompactionStrategy.java:304 - No compaction necessary for bucket size 1 , key 1521763200000, now 1524182400000

The similar message is already at trace level for LCS, so this patch changes the message from TWCS to trace as well."
CASSANDRA-14878,Race condition when setting bootstrap flags,"{{StorageService#bootstrap()}} is supposed to wait for bootstrap to finish, but Guava calls the future listeners [after|https://github.com/google/guava/blob/ec2dedebfa359991cbcc8750dc62003be63ec6d3/guava/src/com/google/common/util/concurrent/AbstractFuture.java#L890] unparking its waiters, which causes a race on when the {{bootstrapFinished()}} will be executed, making it non-deterministic."
CASSANDRA-14876,Snapshot name merges with keyspace name shown by nodetool listsnapshots for snapshots with long names,"If snapshot name is long enough, it will merge  keyspace name and the command output will be inconvenient to read for a {{nodetool}} user, e.g.

{noformat}
bin/nodetool listsnapshots
Snapshot Details:
Snapshot name       Keyspace name                Column family name           True size          Size on disk
1541670390886       system_distributed           parent_repair_history        0 bytes            13 bytes
1541670390886       system_distributed           repair_history               0 bytes            13 bytes
1541670390886       system_auth                  roles                        0 bytes            4.98 KB
1541670390886       system_auth                  role_members                 0 bytes            13 bytes
1541670390886       system_auth                  resource_role_permissons_index0 bytes            13 bytes
1541670390886       system_auth                  role_permissions             0 bytes            13 bytes
1541670390886       system_traces                sessions                     0 bytes            13 bytes
1541670390886       system_traces                events                       0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_distributed           parent_repair_history        0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_distributed           repair_history               0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_auth                  roles                        0 bytes            4.98 KB
39_characters_long_name_2017-09-05-11-Usystem_auth                  role_members                 0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_auth                  resource_role_permissons_index0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_auth                  role_permissions             0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_traces                sessions                     0 bytes            13 bytes
39_characters_long_name_2017-09-05-11-Usystem_traces                events                       0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_distributed           parent_repair_history        0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_distributed           repair_history               0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_auth                  roles                        0 bytes            4.98 KB
41_characters_long_name_2017-09-05-11-UTCsystem_auth                  role_members                 0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_auth                  resource_role_permissons_index0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_auth                  role_permissions             0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_traces                sessions                     0 bytes            13 bytes
41_characters_long_name_2017-09-05-11-UTCsystem_traces                events                       0 bytes            13 bytes
{noformat}"
CASSANDRA-14855,"Message Flusher scheduling fell off the event loop, resulting in out of memory","We recently had a production issue where about 10 nodes in a 96 node cluster ran out of heap. 

From heap dump analysis, I believe there is enough evidence to indicate `queued` data member of the Flusher got too big, resulting in out of memory.
Below are specifics on what we found from the heap dump (relevant screenshots attached):
* non-empty ""queued"" data member of Flusher having retaining heap of 0.5GB, and multiple such instances.
* ""running"" data member of Flusher having ""true"" value
* Size of scheduledTasks on the eventloop was 0.

We suspect something (maybe an exception) caused the Flusher running state to continue to be true, but was not able to schedule itself with the event loop.
Could not find any ERROR in the system.log, except for following INFO logs around the incident time.


{code:java}
INFO [epollEventLoopGroup-2-4] 2018-xx-xx xx:xx:xx,592 Message.java:619 - Unexpected exception during request; channel = [id: 0x8d288811, L:/xxx.xx.xxx.xxx:7104 - R:/xxx.xx.x.xx:18886]
io.netty.channel.unix.Errors$NativeIoException: readAddress() failed: Connection timed out
 at io.netty.channel.unix.Errors.newIOException(Errors.java:117) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.unix.Errors.ioResult(Errors.java:138) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.unix.FileDescriptor.readAddress(FileDescriptor.java:175) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.epoll.AbstractEpollChannel.doReadBytes(AbstractEpollChannel.java:238) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:926) ~[netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:397) [netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:302) [netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131) [netty-all-4.0.44.Final.jar:4.0.44.Final]
 at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144) [netty-all-4.0.44.Final.jar:4.0.44.Final]
{code}

I would like to pursue the following proposals to fix this issue:
# ImmediateFlusher: Backport trunk's ImmediateFlusher ( [CASSANDRA-13651|https://issues.apache.org/jira/browse/CASSANDRA-13651] https://github.com/apache/cassandra/commit/96ef514917e5a4829dbe864104dbc08a7d0e0cec)  to 3.0.x and maybe to other versions as well, since ImmediateFlusher seems to be more robust than the existing Flusher as it does not depend on any running state/scheduling.
# Make ""queued"" data member of the Flusher bounded to avoid any potential of causing out of memory due to otherwise unbounded nature.


"
CASSANDRA-14823,Legacy sstables with range tombstones spanning multiple index blocks create invalid bound sequences on 3.0+,"During upgrade from 2.1 to 3.0, reading old sstables in reverse order would generate invalid sequences of range tombstone bounds if their range tombstones spanned multiple column index blocks. The read fails in different ways depending on whether the 2.1 tables were produced by a flush or a compaction."
CASSANDRA-14804,Running repair on multiple nodes in parallel could halt entire repair ,"Possible deadlock if we run repair on multiple nodes at the same time. We have come across a situation in production in which if we repair multiple nodes at the same time then repair hangs forever. Here are the details:

Time t1
 {{node-1}} has issued repair command to {{node-2}} but due to some reason {{node-2}} didn't receive request hence {{node-1}} is awaiting at [prepareForRepair |https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/ActiveRepairService.java#L333] for 1 hour *with lock*

Time t2
 {{node-2}} sent prepare repair request to {{node-1}}, some exception occurred on {{node-1}} and it is trying to cleanup parent session [here|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/repair/RepairMessageVerbHandler.java#L172] but {{node-1}} cannot get lock as 1 hour of time has not yet elapsed (above one)

snippet of jstack on {{node-1}}
{quote}""Thread-888"" #262588 daemon prio=5 os_prio=0 waiting on condition
 java.lang.Thread.State: TIMED_WAITING (parking)
 at sun.misc.Unsafe.park(Native Method)
 - parking to wait for (a java.util.concurrent.CountDownLatch$Sync)
 at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
 at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
 at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
 at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)
 at org.apache.cassandra.service.ActiveRepairService.prepareForRepair(ActiveRepairService.java:332)
 - locked <> (a org.apache.cassandra.service.ActiveRepairService)
 at org.apache.cassandra.repair.RepairRunnable.runMayThrow(RepairRunnable.java:214)
 at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
 at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$9/864248990.run(Unknown Source)
 at java.lang.Thread.run(Thread.java:748)

""AntiEntropyStage:1"" #1789 daemon prio=5 os_prio=0 waiting for monitor entry []
 java.lang.Thread.State: BLOCKED (on object monitor)
 at org.apache.cassandra.service.ActiveRepairService.removeParentRepairSession(ActiveRepairService.java:421)
 - waiting to lock <> (a org.apache.cassandra.service.ActiveRepairService)
 at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:172)
 at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67)
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
 at java.util.concurrent.FutureTask.run(FutureTask.java:266)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
 at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$9/864248990.run(Unknown Source)
 at java.lang.Thread.run(Thread.java:748){quote}
Time t3:
 {{node-2}}(and possibly other nodes {{node-3}}…) sent [prepare request |https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/service/ActiveRepairService.java#L333] to {{node-1}}, but {{node-1}}’s AntiEntropyStage thread is busy awaiting for lock at {{ActiveRepairService.removeParentRepairSession}}, hence {{node-2}}, {{node-3}} (and possibly other nodes) will also go in 1 hour wait *with lock*. This rolling effect continues and stalls repair in entire ring.

If we totally stop triggering repair then system would recover slowly but here are the two major problems with this:
 1. Externally there is no way to decide whether to trigger new repair or wait for system to recover
 2. In this case system recovers eventually but it takes probably {{n}} hours where n = #of repair requests fired, only way to come out of this situation is either to do a rolling restart of entire ring or wait for {{n}} hours before triggering new repair request

Please let me know if my above analysis makes sense or not."
CASSANDRA-14790,LongBufferPoolTest burn test fails assertion,"The LongBufferPoolTest from the burn tests fails with an assertion error.  I added a build target to run individual burn tests, and \{jasobrown} gave a fix for the uninitialized test setup (attached), however the test now fails on an assertion about recycling buffers.

To reproduce (with patch applied)

{{ant burn-testsome -Dtest.name=org.apache.cassandra.utils.memory.LongBufferPoolTest -Dtest.methods=testAllocate}}

Output

{{    [junit] Testcase: testAllocate(org.apache.cassandra.utils.memory.LongBufferPoolTest): FAILED}}

{{    [junit] null}}

{{    [junit] junit.framework.AssertionFailedError}}

{{    [junit] at org.apache.cassandra.utils.memory.BufferPool$Debug.check(BufferPool.java:204)}}

{{    [junit] at org.apache.cassandra.utils.memory.BufferPool.assertAllRecycled(BufferPool.java:181)}}

{{    [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest.testAllocate(LongBufferPoolTest.java:350)}}

{{    [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest.testAllocate(LongBufferPoolTest.java:54)}}

All major branches from 3.0 and later have issues, however the trunk branch also warns about references not being released before the reference is garbage collected.

{{[junit] ERROR [Reference-Reaper:1] 2018-09-25 13:59:54,089 Ref.java:224 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@7f58d19a) to @623704362 was not released before the reference was garbage collected}}
{{ [junit] ERROR [Reference-Reaper:1] 2018-09-25 13:59:54,089 Ref.java:255 - Allocate trace org.apache.cassandra.utils.concurrent.Ref$State@7f58d19a:}}
{{ [junit] Thread[pool-2-thread-24,5,main]}}
{{ [junit] at java.lang.Thread.getStackTrace(Thread.java:1559)}}
{{ [junit] at org.apache.cassandra.utils.concurrent.Ref$Debug.<init>(Ref.java:245)}}
{{ [junit] at org.apache.cassandra.utils.concurrent.Ref$State.<init>(Ref.java:175)}}
{{ [junit] at org.apache.cassandra.utils.concurrent.Ref.<init>(Ref.java:97)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool$Chunk.setAttachment(BufferPool.java:663)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool$Chunk.get(BufferPool.java:803)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool$Chunk.get(BufferPool.java:793)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool$LocalPool.get(BufferPool.java:388)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool.maybeTakeFromPool(BufferPool.java:143)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool.takeFromPool(BufferPool.java:115)}}
{{ [junit] at org.apache.cassandra.utils.memory.BufferPool.get(BufferPool.java:85)}}
{{ [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest$3.allocate(LongBufferPoolTest.java:296)}}
{{ [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest$3.testOne(LongBufferPoolTest.java:246)}}
{{ [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest$TestUntil.call(LongBufferPoolTest.java:399)}}
{{ [junit] at org.apache.cassandra.utils.memory.LongBufferPoolTest$TestUntil.call(LongBufferPoolTest.java:379)}}
{{ [junit] at java.util.concurrent.FutureTask.run(FutureTask.java:266)}}
{{ [junit] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)}}
{{ [junit] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)}}
{{ [junit] at java.lang.Thread.run(Thread.java:748)}}

 

Perhaps the environment is not being set up correctly for the tests.
  "
CASSANDRA-14748,Recycler$WeakOrderQueue occupies Heap,"Heap constantly high on some of the nodes in the cluster, I dump the heap and open it through Eclipse Memory Analyzer, looks like Recycler$WeakOrderQueue occupies most of the heap. 

 
||Package||Retained Heap||Retained Heap, %||# Top Dominators||
|!/jira/icons/i5.gif! <all>|7,078,140,136|100.00%|379,627|
|io|5,665,035,800|80.04%|13,306|
|netty|5,665,035,800|80.04%|13,306|
|util|5,568,107,344|78.67%|2,965|
|Recycler$WeakOrderQueue|4,950,021,544|69.93%|2,169|"
CASSANDRA-14672,"After deleting data in 3.11.3, reads fail with ""open marker and close marker have different deletion times""","We had 3.11.0, then we upgraded to 3.11.3 last week. We routinely perform deletions as the one described below. After upgrading we run the following deletion query:

 
{code:java}
DELETE FROM measurement_events_dbl WHERE measurement_source_id IN ( 9df798a2-6337-11e8-b52b-42010afa015a,  9df7717e-6337-11e8-b52b-42010afa015a, a08b8042-6337-11e8-b52b-42010afa015a, a08e52cc-6337-11e8-b52b-42010afa015a, a08e6654-6337-11e8-b52b-42010afa015a, a08e6104-6337-11e8-b52b-42010afa015a, a08e6c76-6337-11e8-b52b-42010afa015a, a08e5a9c-6337-11e8-b52b-42010afa015a, a08bcc50-6337-11e8-b52b-42010afa015a) AND year IN (2018) AND measurement_time >= '2018-07-19 04:00:00'{code}
 

Immediately after that, trying to read the last value produces an error:
{code:java}
select * FROM measurement_events_dbl WHERE measurement_source_id = a08b8042-6337-11e8-b52b-42010afa015a AND year IN (2018) order by measurement_time desc limit 1;
ReadFailure: Error from server: code=1300 [Replica(s) failed to execute read] message=""Operation failed - received 0 responses and 2 failures"" info={'failures': 2, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}{code}
 

And the following exception: 
{noformat}
WARN [ReadStage-4] 2018-08-29 06:59:53,505 AbstractLocalAwareExecutorService.java:167 - Uncaught exception on thread Thread[ReadStage-4,5,main]: {}
java.lang.RuntimeException: java.lang.IllegalStateException: UnfilteredRowIterator for pvpms_mevents.measurement_events_dbl has an illegal RT bounds sequence: open marker and close marker have different deletion times
 at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2601) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_181]
 at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134) [apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.3.jar:3.11.3]
 at java.lang.Thread.run(Thread.java:748) [na:1.8.0_181]
Caused by: java.lang.IllegalStateException: UnfilteredRowIterator for pvpms_mevents.measurement_events_dbl has an illegal RT bounds sequence: open marker and close marker have different deletion times
 at org.apache.cassandra.db.transform.RTBoundValidator$RowsTransformation.ise(RTBoundValidator.java:103) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.transform.RTBoundValidator$RowsTransformation.applyToMarker(RTBoundValidator.java:81) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:148) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:136) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:92) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:79) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:308) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:187) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:180) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:176) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:76) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:352) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1889) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2597) ~[apache-cassandra-3.11.3.jar:3.11.3]
 ... 5 common frames omitted
 Suppressed: java.lang.IllegalStateException: UnfilteredRowIterator for pvpms_mevents.measurement_events_dbl has an illegal RT bounds sequence: expected all RTs to be closed, but the last one is open
 at org.apache.cassandra.db.transform.RTBoundValidator$RowsTransformation.ise(RTBoundValidator.java:103) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.transform.RTBoundValidator$RowsTransformation.onPartitionClose(RTBoundValidator.java:96) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.transform.BaseRows.runOnClose(BaseRows.java:91) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.transform.BaseIterator.close(BaseIterator.java:86) ~[apache-cassandra-3.11.3.jar:3.11.3]
 at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:309) ~[apache-cassandra-3.11.3.jar:3.11.3]
 ... 12 common frames omitted
 
{noformat}
 

We have 9 nodes ~2TB each, leveled compaction, repairs run daily in sequence.

Table definition is:
{noformat}
CREATE TABLE pvpms_mevents.measurement_events_dbl (
 measurement_source_id uuid,
 year int,
 measurement_time timestamp,
 event_reception_time timestamp,
 quality double,
 value double,
 PRIMARY KEY ((measurement_source_id, year), measurement_time)
) WITH CLUSTERING ORDER BY (measurement_time ASC)
 AND bloom_filter_fp_chance = 0.1
 AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
 AND comment = ''
 AND compaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'}
 AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
 AND crc_check_chance = 1.0
 AND dclocal_read_repair_chance = 0.1
 AND default_time_to_live = 0
 AND gc_grace_seconds = 864000
 AND max_index_interval = 2048
 AND memtable_flush_period_in_ms = 0
 AND min_index_interval = 128
 AND read_repair_chance = 0.0
 AND speculative_retry = '99PERCENTILE';{noformat}
 

We host those on GCE and recreated all the nodes with disk snapshots, and we reproduced the error: after re-running the DELETE with all nodes up and no other queries running, the error was reproduced immediately.

 

We tried so far:

re-running repairs on all nodes and running nodetool garbagecollect with no success.

We downgraded to 3.11.2 for now, no issues so far.

This may be related to CASSANDRA-14515"
CASSANDRA-14649,Index summaries fail when their size gets > 2G and use more space than necessary,"After building a summary, {{IndexSummaryBuilder}} tries to trim the memory writers by calling {{SafeMemoryWriter.setCapacity(capacity())}}. Instead of trimming, this ends up allocating at least as much extra space and failing the {{Buffer.position()}} call when the size is greater than {{Integer.MAX_VALUE}}."
CASSANDRA-14638,Column result order can change in 'SELECT *' results when upgrading from 2.1 to 3.0 causing response corruption for queries using prepared statements when static columns are used,"When performing an upgrade from C* 2.1.20 to 3.0.17 I observed that the order of columns returned from a 'SELECT *' query changes, particularly when static columns are involved.

This may not seem like that much of a problem, however if using Prepared Statements, any clients that remain connected during the upgrade may encounter issues consuming results from these queries, as data is reordered and the client not aware of it.  The result definition is sent in the original prepared statement response, so if order changes the client has no way of knowing (until C* 4.0 via CASSANDRA-10786) without re-preparing, which is non-trivial as most client drivers cache prepared statements.

This could lead to reading the wrong values for columns, which could result in some kind of deserialization exception or if the data types of the switched columns are compatible, the wrong values.  This happens even if the client attempts to retrieve a column value by name (i.e. row.getInt(""colx"")).

Unfortunately I don't think there is an easy fix for this.  If the order was changed back to the previous format, you risk issues for users upgrading from older 3.0 version.  I think it would be nice to add a note in the NEWS file in the 3.0 upgrade section that describes this issue, and how to work around it (specify all column names of interest explicitly in query).

Example schema and code to reproduce:

 
{noformat}
create keyspace ks with replication = {'class': 'SimpleStrategy', 'replication_factor': 1};

create table ks.tbl (p0 text,
  p1 text,
  m map<text, text> static,
  t text,
  u text static,
  primary key (p0, p1)
);

insert into ks.tbl (p0, p1, m, t, u) values ('p0', 'p1', { 'm0' : 'm1' }, 't', 'u');{noformat}
 

When querying with 2.1 you'll observe the following order via cqlsh:
{noformat}
 p0 | p1 | m            | u | t
----+----+--------------+---+---
 p0 | p1 | {'m0': 'm1'} | u | t{noformat}
 

With 3.0, observe that u and m are transposed:

 
{noformat}
 p0 | p1 | u | m            | t
----+----+---+--------------+---
 p0 | p1 | u | {'m0': 'm1'} | t{noformat}
 

 
{code:java}
import com.datastax.driver.core.BoundStatement;
import com.datastax.driver.core.Cluster;
import com.datastax.driver.core.ColumnDefinitions;
import com.datastax.driver.core.PreparedStatement;
import com.datastax.driver.core.ResultSet;
import com.datastax.driver.core.Row;
import com.datastax.driver.core.Session;
import com.google.common.util.concurrent.Uninterruptibles;
import java.util.concurrent.TimeUnit;

public class LiveUpgradeTest {

  public static void main(String args[]) {
    Cluster cluster = Cluster.builder().addContactPoints(""127.0.0.1"").build();
    try {
      Session session = cluster.connect();
      PreparedStatement p = session.prepare(""SELECT * from ks.tbl"");

      BoundStatement bs = p.bind();

      // continually query every 30 seconds
      while (true) {
        try {
          ResultSet r = session.execute(bs);
          Row row = r.one();
          int i = 0;
          // iterate over the result metadata in order printing the
          // index, name, type, and length of the first row of data.
          for (ColumnDefinitions.Definition d : r.getColumnDefinitions()) {
            System.out.println(
                i++
                    + "": ""
                    + d.getName()
                    + "" -> ""
                    + d.getType()
                    + "" -> val = ""
                    + row.getBytesUnsafe(d.getName()).array().length);
          }
        } catch (Throwable t) {
          t.printStackTrace();
        } finally {
          Uninterruptibles.sleepUninterruptibly(30, TimeUnit.SECONDS);
        }
      }
    } finally {
      cluster.close();
    }
  }
}
{code}
To reproduce, set up a cluster, the schema, and run this script.  Then upgrade the cluster to 3.0.17 (with ccm, ccm stop; ccm node1 setdir -v 3.0.17; ccm start works) and observe after the client is able to reconnect that the results are in a different order.  i.e.:

 

With 2.x:

 
{noformat}
0: p0 -> varchar -> val = 2
1: p1 -> varchar -> val = 2
2: m -> map<varchar, varchar> -> val = 16
3: u -> varchar -> val = 1
4: t -> varchar -> val = 1{noformat}
 

With 3.x:

 
{noformat}
0: p0 -> varchar -> val = 2
1: p1 -> varchar -> val = 2
2: m -> map<varchar, varchar> -> val = 1
3: u -> varchar -> val = 16 (<-- the data for 'm' is now at index 3)
4: t -> varchar -> val = 1{noformat}
 

 

 

 "
CASSANDRA-14564, Adding regular column to COMPACT tables without clustering columns should trigger an InvalidRequestException,"I have upgraded my system from cassandra 2.1.16 to 3.11.2. We had some tables with COMPACT STORAGE enabled. We see some weird   behaviour of cassandra while adding a column into it.

Cassandra does not give any error while altering  however the added column is invisible. 

Same behaviour when we create a new table with compact storage and try to alter it. Below is the commands ran in sequence: 

 
{code:java}
x@cqlsh:xuser> CREATE TABLE xuser.employee(emp_id int PRIMARY KEY,emp_name text, emp_city text, emp_sal varint, emp_phone varint ) WITH  COMPACT STORAGE;
x@cqlsh:xuser> desc table xuser.employee ;

CREATE TABLE xuser.employee (
emp_id int PRIMARY KEY,
emp_city text,
emp_name text,
emp_phone varint,
emp_sal varint
) WITH COMPACT STORAGE
AND bloom_filter_fp_chance = 0.01
AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
AND comment = ''
AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
AND crc_check_chance = 1.0
AND dclocal_read_repair_chance = 0.1
AND default_time_to_live = 0
AND gc_grace_seconds = 864000
AND max_index_interval = 2048
AND memtable_flush_period_in_ms = 0
AND min_index_interval = 128
AND read_repair_chance = 0.0
AND speculative_retry = '99PERCENTILE';{code}
Now altering the table by adding a new column:
  
{code:java}
x@cqlsh:xuser>  alter table employee add profile text;
x@cqlsh:xuser> desc table xuser.employee ;

CREATE TABLE xuser.employee (
    emp_id int PRIMARY KEY,
    emp_city text,
    emp_name text,
    emp_phone varint,
    emp_sal varint
) WITH COMPACT STORAGE
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.1
    AND default_time_to_live = 0
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';
{code}
notice that above desc table result does not have newly added column profile. However when i try to add it again it gives column already exist;
{code:java}
x@cqlsh:xuser>  alter table employee add profile text;
InvalidRequest: Error from server: code=2200 [Invalid query] message=""Invalid column name profile because it conflicts with an existing column""
x@cqlsh:xuser> select emp_name,profile from employee;

 emp_name | profile
----------+---------

(0 rows)
x@cqlsh:xuser>
{code}
Inserting also behaves strange:
{code:java}
x@cqlsh:xuser> INSERT INTO employee (emp_id , emp_city , emp_name , emp_phone , emp_sal ,profile) VALUES ( 1, 'ggn', 'john', 123456, 50000, 'SE');
InvalidRequest: Error from server: code=2200 [Invalid query] message=""Some clustering keys are missing: column1""
x@cqlsh:xuser> INSERT INTO employee (emp_id , emp_city , emp_name , emp_phone , emp_sal ,profile,column1) VALUES ( 1, 'ggn', 'john', 123456, 50000, 'SE',null);
x@cqlsh:xuser> select * from employee;

 emp_id | emp_city | emp_name | emp_phone | emp_sal
--------+----------+----------+-----------+---------

(0 rows)
{code}


*How to solve that ticket* ([~blerer])-------------------------------------------------------------------------------------- 
Adding regular columns to non-dense compact tables should be forbidden as it is the case for other column types. To do that {{AlterTableStatement}} should be modified to fire an {{InvalidRequestException}} when a user attempts to add a regular column to a  a COMPACT TABLE without clustering columns.
The fix should include a unit tests for that scenario  "
CASSANDRA-14450,DelimiterAnalyzer: IllegalArgumentException: The key argument was zero-length,"The [DelimiterAnalyzer|https://issues.apache.org/jira/browse/CASSANDRA-14247] can throw an IllegalArgumentException if there is no text between two delimiters. 

{noformat}
ERROR [MutationStage-1] 2018-05-17 13:55:09,734 StorageProxy.java:1417 - Failed to apply mutation locally : {}
java.lang.RuntimeException: The key argument was zero-length for ks: zipkin2, table: span
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1353) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:626) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:470) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:232) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1411) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2650) [apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_171]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:134) [apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]
Caused by: java.lang.IllegalArgumentException: The key argument was zero-length
	at com.googlecode.concurrenttrees.radix.ConcurrentRadixTree.putInternal(ConcurrentRadixTree.java:520) ~[concurrent-trees-2.4.0.jar:na]
	at com.googlecode.concurrenttrees.radix.ConcurrentRadixTree.putIfAbsent(ConcurrentRadixTree.java:123) ~[concurrent-trees-2.4.0.jar:na]
	at org.apache.cassandra.index.sasi.memory.TrieMemIndex$ConcurrentPrefixTrie.putIfAbsent(TrieMemIndex.java:178) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.sasi.memory.TrieMemIndex$ConcurrentTrie.add(TrieMemIndex.java:123) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.sasi.memory.TrieMemIndex.add(TrieMemIndex.java:94) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.sasi.memory.IndexMemtable.index(IndexMemtable.java:65) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.sasi.conf.ColumnIndex.index(ColumnIndex.java:104) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.sasi.SASIIndex$1.insertRow(SASIIndex.java:258) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.onInserted(SecondaryIndexManager.java:915) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:333) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:295) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.utils.btree.BTree.buildInternal(BTree.java:139) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.utils.btree.BTree.build(BTree.java:121) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.utils.btree.BTree.update(BTree.java:178) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:156) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.Memtable.put(Memtable.java:282) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1335) ~[apache-cassandra-3.11.2-SNAPSHOT.jar:3.11.2-SNAPSHOT]
{noformat}"
CASSANDRA-14444,Got NPE when querying Cassandra 3.11.2,"We just upgraded our Cassandra cluster from 2.2.6 to 3.11.2

After upgrading, we immediately got exceptions in Cassandra like this one: 

 
{code}
ERROR [Native-Transport-Requests-1] 2018-05-11 17:10:21,994 QueryMessage.java:129 - Unexpected error during query
java.lang.NullPointerException: null
at org.apache.cassandra.dht.RandomPartitioner.getToken(RandomPartitioner.java:248) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.dht.RandomPartitioner.decorateKey(RandomPartitioner.java:92) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.config.CFMetaData.decorateKey(CFMetaData.java:666) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.service.pager.PartitionRangeQueryPager.<init>(PartitionRangeQueryPager.java:44) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.db.PartitionRangeReadCommand.getPager(PartitionRangeReadCommand.java:268) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.statements.SelectStatement.getPager(SelectStatement.java:475) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:288) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:118) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:224) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:255) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:240) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.11.2.jar:3.11.2]
at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_171]
at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.2.jar:3.11.2]
at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.2.jar:3.11.2]
at java.lang.Thread.run(Thread.java:748) [na:1.8.0_171]
{code}
 

The table schema is like:
{code}
CREATE TABLE example.example_table (
 id bigint,
 hash text,
 json text,
 PRIMARY KEY (id, hash)
) WITH COMPACT STORAGE
{code}
 

The query is something like:
{code}
""select * from example.example_table;"" // (We do know this is bad practise, and we are trying to fix that right now)
{code}
with fetch-size as 200, using DataStax Java driver. 

This table contains about 20k rows. 

 

Actually, the fix is quite simple, 

 
{code}
--- a/src/java/org/apache/cassandra/service/pager/PagingState.java
+++ b/src/java/org/apache/cassandra/service/pager/PagingState.java
@@ -46,7 +46,7 @@ public class PagingState

public PagingState(ByteBuffer partitionKey, RowMark rowMark, int remaining, int remainingInPartition)
 {
- this.partitionKey = partitionKey;
+ this.partitionKey = partitionKey == null ? ByteBufferUtil.EMPTY_BYTE_BUFFER : partitionKey;
 this.rowMark = rowMark;
 this.remaining = remaining;
 this.remainingInPartition = remainingInPartition;
{code}
 

""partitionKey == null ? ByteBufferUtil.EMPTY_BYTE_BUFFER : partitionKey;"" is in 2.2.6 and 2.2.8. But it was removed for some reason. 

The interesting part is that, we have: 
{code}
public final ByteBuffer partitionKey; // Can be null for single partition queries.
{code}
It seems ""partitionKey"" could be null.

Thanks a lot. 

 

 

 "
CASSANDRA-14441,Materialized view is not deleting/updating data when made changes in base table,"we have seen issue in mat view for 3.11.1 where mat view

1) we have inserted a row in test table and the same recored is in test_mat table, with Enabled = true,
 2) when I update the same record with Enabled = False, a new row is created in test_mat table(one with true and one with false) but in test table original record got updated to FALSE.
 3) when I delete the record using Feature UUID then only the record with Fales is getting deleted in both the tables. however I can see the TRUE record in test_mat table.

Issue is not reproducible in 3.11.2
 Steps

CREATE TABLE test ( 
 feature_uuid uuid, 
 namespace text, 
 feature_name text, 
 allocation_type text, 
 description text, 
 enabled boolean, 
 expiration_dt timestamp, 
 last_modified_dt timestamp, 
 last_modified_user text, 
 persist_allocations boolean, 
 rule text, 
 PRIMARY KEY (feature_uuid, namespace, feature_name, allocation_type) 
 ) WITH CLUSTERING ORDER BY (namespace ASC, feature_name ASC, allocation_type ASC) 
 AND bloom_filter_fp_chance = 0.01 
 AND caching = \{'keys': 'ALL', 'rows_per_partition': 'NONE'} 
 AND comment = '' 
 AND compaction = \{'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} 
 AND compression = \{'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} 
 AND crc_check_chance = 1.0 
 AND dclocal_read_repair_chance = 0.3 
 AND default_time_to_live = 63072000 
 AND gc_grace_seconds = 864000 
 AND max_index_interval = 2048 
 AND memtable_flush_period_in_ms = 0 
 AND min_index_interval = 128 
 AND read_repair_chance = 0.3 
 AND speculative_retry = '99PERCENTILE';

CREATE MATERIALIZED VIEW test_mat AS 
 SELECT allocation_type, enabled, feature_uuid, namespace, feature_name, last_modified_dt, last_modified_user, persist_allocations, rule 
 FROM test
 WHERE feature_uuid IS NOT NULL AND allocation_type IS NOT NULL AND namespace IS NOT NULL AND feature_name IS NOT NULL AND enabled IS NOT NULL 
 PRIMARY KEY (allocation_type, enabled, feature_uuid, namespace, feature_name) 
 WITH CLUSTERING ORDER BY (enabled ASC, feature_uuid ASC, namespace ASC, feature_name ASC) 
 AND bloom_filter_fp_chance = 0.01 
 AND caching = \{'keys': 'ALL', 'rows_per_partition': 'NONE'} 
 AND comment = '' 
 AND compaction = \{'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'} 
 AND compression = \{'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'} 
 AND crc_check_chance = 1.0 
 AND dclocal_read_repair_chance = 0.1 
 AND default_time_to_live = 0 
 AND gc_grace_seconds = 864000 
 AND max_index_interval = 2048 
 AND memtable_flush_period_in_ms = 0 
 AND min_index_interval = 128 
 AND read_repair_chance = 0.0 
 AND speculative_retry = '99PERCENTILE';

INSERT INTO test (feature_uuid, namespace, feature_name, allocation_type, description, enabled, expiration_dt, last_modified_dt, last_modified_user, persist_allocations,rule) VALUES (uuid(),'Service','NEW','preallocation','20newproduct',TRUE,'2019-10-02 05:05:05 -0500','2018-08-03 06:06:06 -0500','swapnil',TRUE,'NEW'); 
 UPDATE test SET enabled=FALSE WHERE feature_uuid=b2d5c245-e30e-4ea8-8609-d36b627dbb2a and namespace='Service' and feature_name='NEW' and allocation_type='preallocation' IF EXISTS ; 
 Delete from test where feature_uuid=98e6ebcc-cafd-4889-bf3d-774a746a3298;

 
 "
CASSANDRA-14424,Gossip EchoMessages not being handled somewhere after node restart,"Noticing this behaviour on a brand new 3.11.2 ring:
 # Restart a random node in the ring.
 # When that node comes back up, around 30% of the time it sees a single other node down. No other node in the ring sees that node is down.
 # After 10-20 minutes, the DOWN node suddenly appears UP to the restarted node.

 

After digging through tracing logs, here's what I know:

 

The node seen as DOWN has not gone down, but simply hasn't been seen as UP yet. The restarted node is attempting to `markAlive()` the target node. Relevant logs from the restarted node's POV:

 

{{INFO [GossipStage:1] 2018-04-27 14:03:50,950 Gossiper.java:1053 - Node /10.0.225.147 has restarted, now UP}}
 {{INFO [GossipStage:1] 2018-04-27 14:03:50,969 StorageService.java:2292 - Node /10.0.225.147 state jump to NORMAL}}
 {{INFO [HANDSHAKE-/10.0.225.147] 2018-04-27 14:03:50,976 OutboundTcpConnection.java:560 - Handshaking version with /10.0.225.147}}
 {{INFO [GossipStage:1] 2018-04-27 14:03:50,977 TokenMetadata.java:479 - Updating topology for /10.0.225.147}}
 {{INFO [GossipStage:1] 2018-04-27 14:03:50,977 TokenMetadata.java:479 - Updating topology for /10.0.225.147}}

 

(note that despite the Gossip seeing the DOWN node as 'UP', nodetool status still shows it as 'DOWN', as markAlive has not completed, and will not actually be seen as 'UP' for 20 more minutes)

 

The restarted node is repeatedly sending Echo messages to the DOWN node as part of the `markAlive()` call. The DOWN node is receiving those, and claims to be sending a response. However, the restarted node is not marking the DOWN node as UP even after the DOWN node sends the Echo response.

 

Relevant logs from the restarted node's POV:

 

{{TRACE [GossipStage:1] 2018-04-27 14:11:28,792 MessagingService.java:945 - 10.0.103.45 sending ECHO to 99248@/10.0.225.147}}
{{TRACE [GossipTasks:1] 2018-04-27 14:11:29,792 MessagingService.java:945 - 10.0.103.45 sending GOSSIP_DIGEST_SYN to 99631@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:29,792 MessagingService.java:945 - 10.0.103.45 sending ECHO to 99632@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:29,793 MessagingService.java:945 - 10.0.103.45 sending GOSSIP_DIGEST_ACK2 to 99633@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:29,793 MessagingService.java:945 - 10.0.103.45 sending ECHO to 99635@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:31,794 MessagingService.java:945 - 10.0.103.45 sending ECHO to 100348@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:33,750 MessagingService.java:945 - 10.0.103.45 sending ECHO to 101157@/10.0.225.147}}
{{TRACE [GossipStage:1] 2018-04-27 14:11:35,412 MessagingService.java:945 - 10.0.103.45 sending ECHO to 101753@/10.0.225.147}}

 

 

Relevant logs from the DOWN node's POV:

 

{{TRACE [GossipStage:1] 2018-04-27 14:18:16,500 EchoVerbHandler.java:39 - Sending a EchoMessage reply /10.0.103.45}}
 {{TRACE [GossipStage:1] 2018-04-27 14:18:16,500 MessagingService.java:945 - 10.0.225.147 sending REQUEST_RESPONSE to 328389@/10.0.103.45}}
{{TRACE [GossipStage:1] 2018-04-27 14:18:17,679 EchoVerbHandler.java:39 - Sending a EchoMessage reply /10.0.103.45}}
 {{TRACE [GossipStage:1] 2018-04-27 14:18:17,679 MessagingService.java:945 - 10.0.225.147 sending REQUEST_RESPONSE to 329412@/10.0.103.45}}
{{TRACE [GossipStage:1] 2018-04-27 14:18:18,680 EchoVerbHandler.java:39 - Sending a EchoMessage reply /10.0.103.45}}
 {{TRACE [GossipStage:1] 2018-04-27 14:18:18,680 MessagingService.java:945 - 10.0.225.147 sending REQUEST_RESPONSE to 330185@/10.0.103.45}}

 

 

The metrics on the restarted node show that the MessagingService has a large number of TimeoutsPerHost for the DOWN node, and all other nodes have 0 timeouts.

 

 

Eventually, `realMarkAlive()` is called and the restarted node finally sees DOWN node as coming up, and it spams several UP messages when this happens:

 

 

{{INFO [RequestResponseStage-7] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-12] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-11] 2018-04-27 14:19:27,210 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}
 {{INFO [RequestResponseStage-12] 2018-04-27 14:19:27,211 Gossiper.java:1019 - InetAddress /10.0.225.147 is now UP}}

 

 

 

A tcpdump shows no packet loss or other oddities between these two hosts. The restarted node is sending Echo messages, and the DOWN node is ACKing them.

 

The fact that a burst comes through at the very end suggests to me that perhaps the Echo messages are getting queued up somewhere.

 

The issue happens roughly 30% of the time a given node in the ring is restarted.
"
CASSANDRA-14423,SSTables stop being compacted,"So seeing a problem in 3.11.0 where SSTables are being lost from the view and not being included in compactions/as candidates for compaction. It seems to get progressively worse until there's only 1-2 SSTables in the view which happen to be the most recent SSTables and thus compactions completely stop for that table.

The SSTables seem to still be included in reads, just not compactions.

The issue can be fixed by restarting C*, as it will reload all SSTables into the view, but this is only a temporary fix. User defined/major compactions still work - not clear if they include the result back in the view but is not a good work around.

This also results in a discrepancy between SSTable count and SSTables in levels for any table using LCS.
{code:java}
Keyspace : xxx
Read Count: 57761088
Read Latency: 0.10527088681224288 ms.
Write Count: 2513164
Write Latency: 0.018211106398149903 ms.
Pending Flushes: 0
Table: xxx
SSTable count: 10
SSTables in each level: [2, 0, 0, 0, 0, 0, 0, 0, 0]
Space used (live): 894498746
Space used (total): 894498746
Space used by snapshots (total): 0
Off heap memory used (total): 11576197
SSTable Compression Ratio: 0.6956629530569777
Number of keys (estimate): 3562207
Memtable cell count: 0
Memtable data size: 0
Memtable off heap memory used: 0
Memtable switch count: 87
Local read count: 57761088
Local read latency: 0.108 ms
Local write count: 2513164
Local write latency: NaN ms
Pending flushes: 0
Percent repaired: 86.33
Bloom filter false positives: 43
Bloom filter false ratio: 0.00000
Bloom filter space used: 8046104
Bloom filter off heap memory used: 8046024
Index summary off heap memory used: 3449005
Compression metadata off heap memory used: 81168
Compacted partition minimum bytes: 104
Compacted partition maximum bytes: 5722
Compacted partition mean bytes: 175
Average live cells per slice (last five minutes): 1.0
Maximum live cells per slice (last five minutes): 1
Average tombstones per slice (last five minutes): 1.0
Maximum tombstones per slice (last five minutes): 1
Dropped Mutations: 0
{code}
Also for STCS we've confirmed that SSTable count will be different to the number of SSTables reported in the Compaction Bucket's. In the below example there's only 3 SSTables in a single bucket - no more are listed for this table. Compaction thresholds haven't been modified for this table and it's a very basic KV schema.
{code:java}
Keyspace : yyy
    Read Count: 30485
    Read Latency: 0.06708991307200263 ms.
    Write Count: 57044
    Write Latency: 0.02204061776873992 ms.
    Pending Flushes: 0
        Table: yyy
        SSTable count: 19
        Space used (live): 18195482
        Space used (total): 18195482
        Space used by snapshots (total): 0
        Off heap memory used (total): 747376
        SSTable Compression Ratio: 0.7607394576769735
        Number of keys (estimate): 116074
        Memtable cell count: 0
        Memtable data size: 0
        Memtable off heap memory used: 0
        Memtable switch count: 39
        Local read count: 30485
        Local read latency: NaN ms
        Local write count: 57044
        Local write latency: NaN ms
        Pending flushes: 0
        Percent repaired: 79.76
        Bloom filter false positives: 0
        Bloom filter false ratio: 0.00000
        Bloom filter space used: 690912
        Bloom filter off heap memory used: 690760
        Index summary off heap memory used: 54736
        Compression metadata off heap memory used: 1880
        Compacted partition minimum bytes: 73
        Compacted partition maximum bytes: 124
        Compacted partition mean bytes: 96
        Average live cells per slice (last five minutes): NaN
        Maximum live cells per slice (last five minutes): 0
        Average tombstones per slice (last five minutes): NaN
        Maximum tombstones per slice (last five minutes): 0
        Dropped Mutations: 0 
{code}
{code:java}
Apr 27 03:10:39 cassandra[9263]: TRACE o.a.c.d.c.SizeTieredCompactionStrategy Compaction buckets are [[BigTableReader(path='/var/lib/cassandra/data/yyy/yyy-5f7a2d60e4a811e6868a8fd39a64fd59/mc-67168-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/yyy/yyy-5f7a2d60e4a811e6868a8fd39a64fd59/mc-67167-big-Data.db'), BigTableReader(path='/var/lib/cassandra/data/yyy/yyy-5f7a2d60e4a811e6868a8fd39a64fd59/mc-67166-big-Data.db')]]
{code}
Also for every LCS table we're seeing the following warning being spammed (seems to be in line with anticompaction spam):
{code:java}
Apr 26 21:30:09 cassandra[9263]: WARN  o.a.c.d.c.LeveledCompactionStrategy Live sstable /var/lib/cassandra/data/xxx/xxx-8c3ef9e0e3fc11e6868a8fd39a64fd59/mc-79024-big-Data.db from level 0 is not on corresponding level in the leveled manifest. This is not a problem per se, but may indicate an orphaned sstable due to a failed compaction not cleaned up properly.{code}
This is a vnodes cluster with 256 tokens per node, and the only thing that seems like it could be causing issues is anticompactions.

CASSANDRA-14079 might be related but doesn't quite describe the same issue, and in this case we're using only a single disk for data. Have yet to reproduce but figured worth reporting here first."
CASSANDRA-14415,Performance regression in queries for distinct keys,"Running Cassandra 3.0.16, we observed a major performance regression affecting {{SELECT DISTINCT keys}}-style queries against certain tables.  Based on some investigation (guided by some helpful feedback from Benjamin on the dev list), we tracked the regression down to two problems.
 * One is that Cassandra was reading more data from disk than was necessary to satisfy the query.  This was fixed under CASSANDRA-10657 in a later 3.x release.
 * If the fix for CASSANDRA-10657 is incorporated, the other is this code snippet in {{RebufferingInputStream}}:
{code:java}
    @Override
    public int skipBytes(int n) throws IOException
    {
        if (n < 0)
            return 0;
        int requested = n;
        int position = buffer.position(), limit = buffer.limit(), remaining;
        while ((remaining = limit - position) < n)
        {
            n -= remaining;
            buffer.position(limit);
            reBuffer();
            position = buffer.position();
            limit = buffer.limit();
            if (position == limit)
                return requested - n;
        }
        buffer.position(position + n);
        return requested;
    }
{code}
The gist of it is that to skip bytes, the stream needs to read those bytes into memory then throw them away.  In our tests, we were spending a lot of time in this method, so it looked like the chief drag on performance.

We noticed that the subclass of {{RebufferingInputStream}} in use for our queries, {{RandomAccessReader}} (over compressed sstables), implements a {{seek()}} method.  Overriding {{skipBytes()}} in it to use {{seek()}} instead was sufficient to fix the performance regression.

The performance difference is significant for tables with large values.  It's straightforward to evaluate with very simple key-value tables, e.g.:

{{CREATE TABLE testtable (key TEXT PRIMARY KEY, value BLOB);}}

We did some basic experimentation with the following variations (all in a single-node 3.11.2 cluster with off-the-shelf settings running on a dev workstation):
 * small values (1 KB, 100,000 entries), somewhat larger values (25 KB, 10,000 entries), and much larger values (1 MB, 10,000 entries);
 * compressible data (a single byte repeated) and uncompressible data (output from {{openssl rand $bytes}}); and
 * with and without sstable compression.  (With compression, we use Cassandra's defaults.)

The difference is most conspicuous for tables with large, uncompressible data and sstable decompression (which happens to describe the use case that triggered our investigation).  It is smaller but still readily apparent for tables with effective compression.  For uncompressible data without compression enabled, there is no appreciable difference.

Here's what the performance looks like without our patch for the 1-MB entries (times in seconds, five consecutive runs for each data set, all exhausting the results from a {{SELECT DISTINCT key FROM ...}} query with a page size of 24):
{noformat}
working on compressible
5.21180510521
5.10270500183
5.22311806679
4.6732840538
4.84219098091
working on uncompressible_uncompressed
55.0423607826
0.769015073776
0.850513935089
0.713396072388
0.62596988678
working on uncompressible
413.292617083
231.345913887
449.524993896
425.135111094
243.469946861
{noformat}
and with the fix:
{noformat}
working on compressible
2.86733293533
1.24895811081
1.108907938
1.12742400169
1.04647302628
working on uncompressible_uncompressed
56.4146180153
0.895509958267
0.922824144363
0.772884130478
0.731923818588
working on uncompressible
64.4587619305
1.81325793266
1.52577018738
1.41769099236
1.60442209244
{noformat}
The long initial runs for the uncompressible data presumably come from repeatedly hitting the disk.  In contrast to the runs without the fix, the initial runs seem to be effective at warming the page cache (as lots of data is skipped, so the data that's read can fit in memory), so subsequent runs are faster.

For smaller data sets, {{RandomAccessReader.seek()}} and {{RebufferingInputStream.skipBytes()}} are approximately equivalent in their behavior (reducing to changing the position pointer of an in-memory buffer most of the time), so there isn't much difference.  Here's before the fix for the 1-KB entries:
{noformat}
working on small_compressible
8.34115099907
8.57280993462
8.3534219265
8.55130696297
8.17362189293
working on small_uncompressible_uncompressed
7.85155582428
7.54075288773
7.50106596947
7.39202189445
7.95735621452
working on small_uncompressible
7.89256501198
7.88875198364
7.9013261795
7.76551413536
7.84927678108
{noformat}
and after:
{noformat}
working on small_compressible
8.29225707054
7.57822394371
8.10092878342
8.21332192421
8.19347810745
working on small_uncompressible_uncompressed
7.74823594093
7.81218004227
7.68660092354
7.95432114601
7.77612304688
working on small_uncompressible
8.18260502815
8.21010804176
8.1233921051
7.31543707848
7.91079998016
{noformat}
The effect is similar for the 25-KB entries, which might enjoy a slight performance benefit from the patch (perhaps because they're larger than the default buffer size defined in {{RandomAccessReader}}).  Before:
{noformat}
working on medium_compressible
0.988080978394
1.02464294434
0.977658033371
1.02553391457
0.769363880157
working on medium_uncompressible_uncompressed
1.07718396187
1.08547902107
1.12398791313
1.10300898552
1.08757281303
working on medium_uncompressible
0.940990209579
0.917474985123
0.768013954163
0.871683835983
0.814841985703
{noformat}
and after:
{noformat}
working on medium_compressible
0.829009056091
0.705173015594
0.603646993637
0.820069074631
0.873830080032
working on medium_uncompressible_uncompressed
0.785156965256
0.808106184006
0.848286151886
0.857885837555
0.825689077377
working on medium_uncompressible
0.845101118088
0.913790941238
0.824147939682
0.849114894867
0.85981798172
{noformat}
In short, this looks like a pretty straightforward performance win with negligible cost.  (It's worth noting that for our use case, disabling sstable compression is clearly the _best_ solution, but there's still reasonably clear benefit from this minor fix for data sets with larger, compressible values, as well as presumably data sets with a mix of compressible and uncompressible values in environments where storage is limited.)"
CASSANDRA-14396,Error about JNA on Startup ," 

Hi, all.

I got some error on startup.

this is my own backup server which can't use network.

I just extracted 'apache-cassandra-3.11.2-bin.tar.gz' file to /usr/local/cassandra.

and then ran like this 'cassandra -f'.

but log displayed below's error.

 

I found some way to solve. but it's not working.

after JNA library download, make JNA library symbolic link - not working

can anyone advise to me about this issue?(I attached full logging file)

 

ERROR [main] 2018-04-18 10:44:59,536 NativeLibraryLinux.java:62 - Failed to link the C library against JNA. Native methods will be unavailable.
 java.lang.UnsatisfiedLinkError: /tmp/jna-3506402/jna5682737284440877593.tmp: /tmp/jna-3506402/jna5682737284440877593.tmp: failed to map segment from shared object: Operation not permitted
 at java.lang.ClassLoader$NativeLibrary.load(Native Method) ~[na:1.8.0_152]
 at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941) ~[na:1.8.0_152]
 at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1824) ~[na:1.8.0_152]
 at java.lang.Runtime.load0(Runtime.java:809) ~[na:1.8.0_152]
 at java.lang.System.load(System.java:1086) ~[na:1.8.0_152]
 at com.sun.jna.Native.loadNativeDispatchLibraryFromClasspath(Native.java:851) ~[jna-4.2.2.jar:4.2.2 (b0)]
 at com.sun.jna.Native.loadNativeDispatchLibrary(Native.java:826) ~[jna-4.2.2.jar:4.2.2 (b0)]
 at com.sun.jna.Native.<clinit>(Native.java:140) ~[jna-4.2.2.jar:4.2.2 (b0)]
 at org.apache.cassandra.utils.NativeLibraryLinux.<clinit>(NativeLibraryLinux.java:53) ~[apache-cassandra-3.11.2.jar:3.11.2]
 at org.apache.cassandra.utils.NativeLibrary.<clinit>(NativeLibrary.java:93) [apache-cassandra-3.11.2.jar:3.11.2]
 at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:196) [apache-cassandra-3.11.2.jar:3.11.2]
 at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:602) [apache-cassandra-3.11.2.jar:3.11.2]
 at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:691) [apache-cassandra-3.11.2.jar:3.11.2]
 WARN [main] 2018-04-18 10:44:59,537 StartupChecks.java:136 - jemalloc shared library could not be preloaded to speed up memory allocations
 WARN [main] 2018-04-18 10:44:59,537 StartupChecks.java:169 - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
 ERROR [main] 2018-04-18 10:44:59,539 CassandraDaemon.java:708 - The native library could not be initialized properly."
CASSANDRA-14387,SSTableReaderTest#testOpeningSSTable fails on macOS,"I ran into an issue with {{SSTableReaderTest#testOpeningSSTable}} test failure on macOS. The reason for failure seems that on macOS, the file modification timestamps are at a second granularity (See: https://stackoverflow.com/questions/18403588/how-to-return-millisecond-information-for-file-access-on-mac-os-x-in-java and https://developer.apple.com/legacy/library/technotes/tn/tn1150.html#HFSPlusDates). The fix is simple - bumping up the sleep time to 1 second instead of 10ms.


{noformat}
    [junit] ------------- ---------------- ---------------
    [junit] Testcase: testOpeningSSTable(org.apache.cassandra.io.sstable.SSTableReaderTest):	FAILED
    [junit] Bloomfilter was not recreated
    [junit] junit.framework.AssertionFailedError: Bloomfilter was not recreated
    [junit] 	at org.apache.cassandra.io.sstable.SSTableReaderTest.testOpeningSSTable(SSTableReaderTest.java:421)
    [junit]
    [junit]
    [junit] Test org.apache.cassandra.io.sstable.SSTableReaderTest FAILED
{noformat}

Related issue: CASSANDRA-11163"
CASSANDRA-14384,If fsync fails it's always an issue and continuing execution is suspect,"We can't catch fsync errors and continue so we shouldn't have code that does that in C*. There was a Postgres bug where fsync returned an error and the FS lost data, but subsequent fsyncs succeeded.

The [LastErrorException code in NativeLibrary.trySync|https://github.com/apache/cassandra/commit/be313935e54be450d9aaabda7965a2f266e922c9#diff-4258621cdf765f0fea6770db5d40038fR307] looks a little janky. What's up with that? When would trySync be something we would merely try? If try is good enough why do it at all considering try is the default behavior of a series of unsynced filesystem operations.

Also when we fsync in FD it's not just fsyncing that file the FS is potentially fsyncing other data and the error code we get could be related to that other data so we can't safely ignore it. The filesystem could be internally inconsistent as well. This happens because the FS journaling may force the FS to flush other data as well to preserve the ordering requirements of journaled metadata.

If we ignore fsync errors it needs to be for whitelisted reasons such as a bad FD.

I know we have FSErrorHandler and it makes sense for reads, but I'm not sold on it being the right answer for writes. We don't retry flushing a memtable or writing to the commit log to my knowledge. We could go read only and I need to check if that is w"
CASSANDRA-14377,Returning invalid JSON for NaN and Infinity float values,"After inserting special float values like NaN and Infinity into a table:

{{CREATE TABLE testme (t1 bigint, t2 float, t3 float, PRIMARY KEY (t1));}}
{{INSERT INTO testme (t1, t2, t3) VALUES (7, NaN, Infinity);}}

and returning them as JSON...

{{cqlsh:demodb> select json * from testme;}}
{{ [json]}}
{{--------------------------------------}}
{{ \{""t1"": 7, ""t2"": NaN, ""t3"": Infinity}}}

 

... the result will not be validated (e.g. with [https://jsonlint.com/|https://jsonlint.com/)] ) because neither NaN nor Infinity is a valid JSON value. The consensus seems to be returning JSON's `null` in these cases, based on this article [https://stackoverflow.com/questions/1423081/json-left-out-infinity-and-nan-json-status-in-ecmascript] and other similar ones."
CASSANDRA-14370,Reduce level of log from debug to trace in CommitLogSegmentManager.java,"[{{AbstractCommitLogSegmentManager.java:112}}|https://github.com/apache/cassandra/blob/2402acd47e3bb514981cde742b7330666c564869/src/java/org/apache/cassandra/db/commitlog/AbstractCommitLogSegmentManager.java#L112]
It's changed to trace() in cassandra-3.0 with CASSANDRA-10241:https://github.com/pauloricardomg/cassandra/commit/3ef1b18fa76dce7cd65b73977fc30e51301f3fed#diff-d07279710c482983e537aed26df80400

but not in cassandra-3.11 and trunk. I think it makes sense to make them consistent and downgrade to {{trace()}}."
CASSANDRA-14310,Don't allow nodetool refresh before cfs is opened,There is a potential deadlock in during startup if nodetool refresh is called while sstables are being opened. We should not allow refresh to be called before everything is initialized.
CASSANDRA-14292,Fix batch commitlog sync regression,"Prior to CASSANDRA-13987, in batch commitlog mode, commitlog will be synced to disk right after mutation comes.
 * haveWork semaphore is released in BatchCommitLogService.maybeWaitForSync
 * AbstractCommitlogService will continue and sync to disk

After C-13987, it makes a branch for chain maker flush more frequently in periodic mode. To make sure in batch mode CL still flushes immediately, it added {{syncRequested}} flag.
 Unfortunately, in 3.0 branch, this flag is not being set to true when mutation is waiting.

So in AbstractCommitlogService, it will not execute the CL sync branch until it reaches sync window(2ms)..
{code:java|title=AbstractCommitLogService.java}
if (lastSyncedAt + syncIntervalMillis <= pollStarted || shutdown || syncRequested)
{
    // in this branch, we want to flush the commit log to disk
    syncRequested = false;
    commitLog.sync(shutdown, true);
    lastSyncedAt = pollStarted;
    syncComplete.signalAll();
}
else
{
    // in this branch, just update the commit log sync headers
    commitLog.sync(false, false);
}
{code}"
CASSANDRA-14286,IndexOutOfBoundsException with SELECT JSON using IN and ORDER BY,"When running the following code:

{code}
public class CassandraJsonOrderingBug {
    public static void main(String[] args) {
        Session session = CassandraFactory.getSession();

        session.execute(""CREATE TABLE thebug ( PRIMARY KEY (a, b), a INT, b INT)"");
        try {
            session.execute(""INSERT INTO thebug (a, b) VALUES (20, 30)"");
            session.execute(""INSERT INTO thebug (a, b) VALUES (100, 200)"");
            Statement statement = new SimpleStatement(""SELECT JSON a, b FROM thebug WHERE a IN (20, 100) ORDER BY b"");
            statement.setFetchSize(Integer.MAX_VALUE);
            for (Row w: session.execute(statement)) {
                System.out.println(w.toString());
            }
        } finally {
            session.execute(""DROP TABLE thebug"");
        }
    }
}
{code}

The following exception is thrown server-side:

{noformat}
java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
	at java.util.Collections$SingletonList.get(Collections.java:4815) ~[na:1.8.0_151]
	at org.apache.cassandra.cql3.statements.SelectStatement$SingleColumnComparator.compare(SelectStatement.java:1297) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.cql3.statements.SelectStatement$SingleColumnComparator.compare(SelectStatement.java:1284) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at java.util.TimSort.countRunAndMakeAscending(TimSort.java:355) ~[na:1.8.0_151]
	at java.util.TimSort.sort(TimSort.java:220) ~[na:1.8.0_151]
	at java.util.Arrays.sort(Arrays.java:1512) ~[na:1.8.0_151]
	at java.util.ArrayList.sort(ArrayList.java:1460) ~[na:1.8.0_151]
	at java.util.Collections.sort(Collections.java:175) ~[na:1.8.0_151]
{noformat}

(full traceback attached)

The accessed index is the index of the sorted column in the SELECT JSON fields list.
Similarly, if the select clause is changed to

SELECT JSON b, a FROM thebug WHERE a IN (20, 100) ORDER BY b

then the query finishes, but the output is sorted incorrectly (by textual JSON representation):

{noformat}
Row[{""b"": 200, ""a"": 100}]
Row[{""b"": 30, ""a"": 20}]
{noformat}"
CASSANDRA-14284,Chunk checksum test needs to occur before uncompress to avoid JVM crash,"While checksums are (generally) performed on compressed data, the checksum test when reading is currently (in all variants of C* 2.x, 3.x I've looked at) done [on the compressed data] only after the uncompress operation has completed. 

The issue here is that LZ4_decompress_fast (as documented in e.g. [https://github.com/lz4/lz4/blob/dev/lib/lz4.h#L214)] can result in memory overruns when provided with malformed source data. This in turn can (and does, e.g. in CASSANDRA-13757) lead to JVM crashes during the uncompress of corrupted chunks. The checksum operation would obviously detect the issue, but we'd never get to it if the JVM crashes first.

Moving the checksum test of the compressed data to before the uncompress operation (in cases where the checksum is done on compressed data) will resolve this issue.

-----------------------------

The check-only-after-doing-the-decompress logic appears to be in all current releases.

Here are some samples at different evolution points :

3.11.2:

[https://github.com/apache/cassandra/blob/cassandra-3.11.2/src/java/org/apache/cassandra/io/util/CompressedChunkReader.java#L146]

https://github.com/apache/cassandra/blob/cassandra-3.11.2/src/java/org/apache/cassandra/io/util/CompressedChunkReader.java#L207

 

3.5:

 [https://github.com/apache/cassandra/blob/cassandra-3.5/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java#L135]

[https://github.com/apache/cassandra/blob/cassandra-3.5/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java#L196]

2.1.17:

 [https://github.com/apache/cassandra/blob/cassandra-2.1.17/src/java/org/apache/cassandra/io/compress/CompressedRandomAccessReader.java#L122]"
CASSANDRA-14215,Cassandra does not respect hint window for CAS,"On Cassandra 3.0.9, it was observed that Cassandra continues to write hints even though a node remains down (and does not come up) for longer than the default 3 hour window.

 

After doing ""nodetool setlogginglevel org.apache.cassandra TRACE"", we see the following log line in cassandra (debug) logs:
 StorageProxy.java:2625 - Adding hints for [/10.0.100.84]

 

One possible code path seems to be:

cas -> commitPaxos(proposal, consistencyForCommit, true); -> submitHint (in StorageProxy.java)

 

The ""true"" parameter above explicitly states that a hint should be recorded and ignores the time window calculation performed by the shouldHint method invoked in other code paths. Is there a reason for this behavior?

 

Edit: There are actually two stacks that seem to be producing hints, the ""cas"" and ""syncWriteBatchedMutations"" methods. I have posted them below.

 

A third issue seems to be that Cassandra seems to reset the timer which counts how long a node has been down after a restart. Thus if Cassandra is restarted on a good node, it continues to accumulate hints for a down node over the next three hours.

 

{code:java}
WARN [SharedPool-Worker-14] 2018-02-06 22:15:51,136 StorageProxy.java:2636 - Adding hints for [/10.0.100.84] with stack trace: java.lang.Throwable: at org.apache.cassandra.service.StorageProxy.stackTrace(StorageProxy.java:2608) at org.apache.cassandra.service.StorageProxy.submitHint(StorageProxy.java:2617) at org.apache.cassandra.service.StorageProxy.submitHint(StorageProxy.java:2603) at org.apache.cassandra.service.StorageProxy.commitPaxos(StorageProxy.java:540) at org.apache.cassandra.service.StorageProxy.cas(StorageProxy.java:282) at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithCondition(ModificationStatement.java:432) at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:407) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) at io.netty.channel.AbstractChannelHandlerContext.access$700(AbstractChannelHandlerContext.java:32) at io.netty.channel.AbstractChannelHandlerContext$8.run(AbstractChannelHandlerContext.java:324) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) at java.lang.Thread.run(Thread.java:748) WARN
{code}

{code:java}
[SharedPool-Worker-8] 2018-02-06 22:15:51,153 StorageProxy.java:2636 - Adding hints for [/10.0.100.84] with stack trace: java.lang.Throwable: at org.apache.cassandra.service.StorageProxy.stackTrace(StorageProxy.java:2608) at org.apache.cassandra.service.StorageProxy.submitHint(StorageProxy.java:2617) at org.apache.cassandra.service.StorageProxy.sendToHintedEndpoints(StorageProxy.java:1247) at org.apache.cassandra.service.StorageProxy.syncWriteBatchedMutations(StorageProxy.java:1014) at org.apache.cassandra.service.StorageProxy.mutateAtomically(StorageProxy.java:899) at org.apache.cassandra.service.StorageProxy.mutateWithTriggers(StorageProxy.java:834) at org.apache.cassandra.cql3.statements.BatchStatement.executeWithoutConditions(BatchStatement.java:365) at org.apache.cassandra.cql3.statements.BatchStatement.execute(BatchStatement.java:343) at org.apache.cassandra.cql3.statements.BatchStatement.execute(BatchStatement.java:329) at org.apache.cassandra.cql3.statements.BatchStatement.execute(BatchStatement.java:324) at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) at io.netty.channel.AbstractChannelHandlerContext.access$700(AbstractChannelHandlerContext.java:32) at io.netty.channel.AbstractChannelHandlerContext$8.run(AbstractChannelHandlerContext.java:324) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) at java.lang.Thread.run(Thread.java:748)
{code}

 

 "
CASSANDRA-14204,Remove unrepaired SSTables from garbage collection when only_purge_repaired_tombstones is true to avoid AssertionError in nodetool garbagecollect,"When manually running a garbage collection compaction across a table with unrepaired sstables and only_purge_repaired_tombstones set to true an assertion error is thrown. This is because the unrepaired sstables aren't being removed from the transaction as they are filtered out in filterSSTables().
||3.11||trunk||
|[branch|https://github.com/vincewhite/cassandra/commit/e13c822736edd3df3403c02e8ef90816f158cde2]|[branch|https://github.com/vincewhite/cassandra/commit/cc8828576404e72504d9b334be85f84c90e77aa7]|

The stacktrace:
{noformat}
-- StackTrace --
java.lang.AssertionError
	at org.apache.cassandra.db.compaction.CompactionManager.parallelAllSSTableOperation(CompactionManager.java:339)
	at org.apache.cassandra.db.compaction.CompactionManager.performGarbageCollection(CompactionManager.java:476)
	at org.apache.cassandra.db.ColumnFamilyStore.garbageCollect(ColumnFamilyStore.java:1579)
	at org.apache.cassandra.service.StorageService.garbageCollect(StorageService.java:3069)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:275)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)
	at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:138)
	at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:252)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:819)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:801)
	at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1468)
	at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:76)
	at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1309)
	at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1401)
	at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:829)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:357)
	at sun.rmi.transport.Transport$1.run(Transport.java:200)
	at sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:568)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:826)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:683)
	at java.security.AccessController.doPrivileged(Native Method)
	at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:682)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)


{noformat}"
CASSANDRA-14200,NullPointerException when dumping sstable with null value for timestamp column,"We have an sstable whose schema has a column of type timestamp and it's not part of primary key. When dumping the sstable using sstabledump there is NPE like this:
{code:java}
Exception in thread ""main"" java.lang.NullPointerException
at java.util.Calendar.setTime(Calendar.java:1770)
at java.text.SimpleDateFormat.format(SimpleDateFormat.java:943)
at java.text.SimpleDateFormat.format(SimpleDateFormat.java:936)
at java.text.DateFormat.format(DateFormat.java:345)
at org.apache.cassandra.db.marshal.TimestampType.toJSONString(TimestampType.java:93)
at org.apache.cassandra.tools.JsonTransformer.serializeCell(JsonTransformer.java:442)
at org.apache.cassandra.tools.JsonTransformer.serializeColumnData(JsonTransformer.java:376)
at org.apache.cassandra.tools.JsonTransformer.serializeRow(JsonTransformer.java:280)
at org.apache.cassandra.tools.JsonTransformer.serializePartition(JsonTransformer.java:215)
at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175)
at java.util.Iterator.forEachRemaining(Iterator.java:116)
at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151)
at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174)
at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
at org.apache.cassandra.tools.JsonTransformer.toJson(JsonTransformer.java:104)
at org.apache.cassandra.tools.SSTableExport.main(SSTableExport.java:242){code}

The reason is that we use a null Date when there is no value for this column:
{code}
    public Date deserialize(ByteBuffer bytes)
    {
        return bytes.remaining() == 0 ? null : new Date(ByteBufferUtil.toLong(bytes));
    }
{code}

It seems that we should not deserialize columns with null values."
CASSANDRA-14151,"[TRUNK] TestRepair.test_dead_sync_initiator failed due to ERROR in logs ""SSTableTidier ran with no existing data file for an sstable that was not new""","TestRepair.test_dead_sync_initiator failed due to finding the following unexpected error in the node's logs:

{code}
ERROR [NonPeriodicTasks:1] 2018-01-06 03:38:50,229 LogTransaction.java:347 - SSTableTidier ran with no existing data file for an sstable that was not new
{code}

If this is ""okay/expected"" behavior we should change the log level to something different (which will fix the test) or if it's an actual bug use this JIRA to fix it. I've attached all of the logs from all 3 instances from the dtest run that hit this failure."
CASSANDRA-14113,AssertionError while trying to upgrade 2.2.11 -> 3.11.1,"We're trying to upgrade a test cluster from Cassandra 2.2.11 to Cassandra 3.11.1. The tables have been created using thrift and have supercolumns. When I try to run {{nodetool upgradesstables}} I get the following:
{noformat}error: null
-- StackTrace --
java.lang.AssertionError
	at org.apache.cassandra.db.rows.BufferCell.<init>(BufferCell.java:42)
	at org.apache.cassandra.db.LegacyLayout$CellGrouper.addCell(LegacyLayout.java:1242)
	at org.apache.cassandra.db.LegacyLayout$CellGrouper.addAtom(LegacyLayout.java:1185)
	at org.apache.cassandra.db.UnfilteredDeserializer$OldFormatDeserializer$UnfilteredIterator.readRow(UnfilteredDeserializer.java:498)
	at org.apache.cassandra.db.UnfilteredDeserializer$OldFormatDeserializer$UnfilteredIterator.hasNext(UnfilteredDeserializer.java:472)
	at org.apache.cassandra.db.UnfilteredDeserializer$OldFormatDeserializer.hasNext(UnfilteredDeserializer.java:306)
	at org.apache.cassandra.io.sstable.SSTableSimpleIterator$OldFormatIterator.computeNext(SSTableSimpleIterator.java:188)
	at org.apache.cassandra.io.sstable.SSTableSimpleIterator$OldFormatIterator.computeNext(SSTableSimpleIterator.java:140)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:122)
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:100)
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:32)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.utils.MergeIterator$TrivialOneToOne.computeNext(MergeIterator.java:484)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:499)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:359)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:133)
	at org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:74)
	at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:75)
	at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:26)
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96)
	at org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:233)
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:196)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:85)
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)
	at org.apache.cassandra.db.compaction.CompactionManager$5.execute(CompactionManager.java:428)
	at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:315)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81)
	at java.lang.Thread.run(Thread.java:748)
{noformat}

We also tried to upgrade to 3.0.15 instead and had a different error:
{noformat}
ERROR 11:00:40 Exception in thread Thread[CompactionExecutor:1,1,main]
java.lang.IllegalStateException: [ColumnDefinition{name=key, type=org.apache.cassandra.db.marshal.BytesType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.BytesType,org.apache.cassandra.db.marshal.BytesType), kind=REGULAR, position=-1}] is not a subset of []
    at org.apache.cassandra.db.Columns$Serializer.encodeBitmap(Columns.java:532) ~[main/:na]
    at org.apache.cassandra.db.Columns$Serializer.serializedSubsetSize(Columns.java:484) ~[main/:na]
    at org.apache.cassandra.db.rows.UnfilteredSerializer.serializedRowBodySize(UnfilteredSerializer.java:290) ~[main/:na]
    at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:169) ~[main/:na]
    at org.apache.cassandra.db.rows.UnfilteredSerializer.serialize(UnfilteredSerializer.java:114) ~[main/:na]
    at org.apache.cassandra.db.ColumnIndex$Builder.add(ColumnIndex.java:144) ~[main/:na]
    at org.apache.cassandra.db.ColumnIndex$Builder.build(ColumnIndex.java:112) ~[main/:na]
    at org.apache.cassandra.db.ColumnIndex.writeAndBuildIndex(ColumnIndex.java:52) ~[main/:na]
    at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:149) ~[main/:na]
    at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:125) ~[main/:na]
    at org.apache.cassandra.db.compaction.writers.MaxSSTableSizeWriter.realAppend(MaxSSTableSizeWriter.java:88) ~[main/:na]
    at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.append(CompactionAwareWriter.java:109) ~[main/:na]
    at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:195) ~[main/:na]
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]
    at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89) ~[main/:na]
    at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61) ~[main/:na]
    at org.apache.cassandra.db.compaction.CompactionManager$5.execute(CompactionManager.java:424) ~[main/:na]
    at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:311) ~[main/:na]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_151]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_151]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_151]
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79) [main/:na]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_151]
{noformat}

Attached are a set of sstables that reproduce the issue."
CASSANDRA-14108,Improve commit log chain marker updating,"CASSANDRA-13987 addressed the commit log behavior change that was introduced with CASSANDRA-3578. After that patch was committed, [~aweisberg] did his own review and found a bug as well as having some concerns about the configuration. He and I discussed offline, and agreed on some improvements. 

Instead of requiring users to configure a deep, dark implementation detail like the commit log chained markers (via {{commitlog_marker_period_in_ms}} in the yaml), we decided it is best to eliminate thew configuration and always update the chained markers (when in periodic mode). 

The bug [~aweisberg] found was when the chained marker update is not a value that evenly divides into the periodic sync mode value, we would not sync in an expected manner. For example if the marker interval is 9 seconds, and the sync interval is 10 seconds, we would update the markers at time9, but we would then sleep for another 9 seconds, and when we wake up at time18, it is then that we flush - 8 seconds later than we should have. 
"
CASSANDRA-14096,Cassandra 3.11.1 Repair Causes Out of Memory,"Number of nodes: 9
System resources: 8 Core, 16GB RAM
Replication factor: 3
Number of vnodes: 256

We get out of memory errors while repairing (incremental or full) our keyspace. I had tried to increase node's memory from 16GB to 32GB but result did not change. Repairing tables one by one in our keyspace was not completed successfully for all tables too. 

Only subrange repair with cassandra-reaper worked for me.

Here is the output of heap utils before oom:

{code}

ERROR [MessagingService-Incoming-/192.168.199.121] 2017-12-05 11:38:08,121 JVMStabilityInspector.java:142 - JVM state determined to be unstable.  Exiting forcefully due to:
java.lang.OutOfMemoryError: Java heap space
	at org.apache.cassandra.gms.GossipDigestSerializationHelper.deserialize(GossipDigestSyn.java:66) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.gms.GossipDigestSynSerializer.deserialize(GossipDigestSyn.java:95) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.gms.GossipDigestSynSerializer.deserialize(GossipDigestSyn.java:81) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.net.MessageIn.read(MessageIn.java:123) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:192) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:180) ~[apache-cassandra-3.11.1.jar:3.11.1]
	at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:94) ~[apache-cassandra-3.11.1.jar:3.11.1]
{code}

{code}
 num     #instances         #bytes  class name
----------------------------------------------
   1:      31105265     1493052720  org.apache.cassandra.utils.MerkleTree$Inner
   2:      31134570      996306240  org.apache.cassandra.utils.MerkleTree$Leaf
   3:      31195121      748682904  org.apache.cassandra.dht.Murmur3Partitioner$LongToken
   4:      22885384      667447608  [B
   5:        214550       18357360  [C
   6:        364637       17502576  java.nio.HeapByteBuffer
   7:         46525        9566496  [J
   8:        111024        5306976  [Ljava.lang.Object;
   9:        132674        5306960  org.apache.cassandra.db.rows.BufferCell
  10:        210309        5047416  java.lang.String
  11:         59984        3838976  org.apache.cassandra.utils.btree.BTreeSearchIterator
  12:        101181        3237792  java.util.HashMap$Node
  13:         27158        2719216  [I
  14:         60181        2407240  java.util.TreeMap$Entry
  15:         65998        2111936  org.apache.cassandra.db.rows.BTreeRow
  16:         62387        2023784  [Ljava.nio.ByteBuffer;
  17:         19086        1750464  [Ljava.util.HashMap$Node;
  18:         63466        1523184  javax.management.ObjectName$Property
  19:         61553        1477272  org.apache.cassandra.db.BufferClustering
  20:         29274        1405152  org.apache.cassandra.utils.MerkleTree
  21:         34602        1384080  org.apache.cassandra.db.rows.UnfilteredSerializer$$Lambda$100/78247817
  22:         40972        1311104  java.util.concurrent.ConcurrentHashMap$Node
  23:         39172        1253504  java.util.RandomAccessSubList
  24:         51657        1239768  org.apache.cassandra.db.LivenessInfo
  25:         19013        1216832  java.nio.DirectByteBuffer
  26:         28178        1127120  org.apache.cassandra.db.PreHashedDecoratedKey
  27:         32407        1033120  [Ljavax.management.ObjectName$Property;
  28:         42090        1010160  java.util.EnumMap$EntryIterator$Entry
  29:         40878         981072  java.util.Arrays$ArrayList
  30:         19721         946608  java.util.HashMap
  31:          8359         932600  java.lang.Class
  32:         37277         894648  org.apache.cassandra.dht.Range
  33:         26897         860704  org.apache.cassandra.db.rows.EncodingStats
  34:         19958         798320  org.apache.cassandra.utils.MergeIterator$Candidate
  35:         31281         750744  java.util.ArrayList
  36:         23291         745312  org.apache.cassandra.utils.MerkleTree$TreeRange
  37:         21650         692800  java.util.AbstractList$ListItr
  38:         27675         664200  java.lang.Long
  39:         16204         648160  javax.management.ObjectName
  40:         36873         589968  org.apache.cassandra.utils.WrappedInt
  41:          4100         557600  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$PaddedAtomicReference
  42:         21651         519624  java.util.SubList$1
  43:         12275         491000  java.math.BigInteger
  44:          8657         484792  org.apache.cassandra.utils.memory.BufferPool$Chunk
  45:         14732         471424  java.util.ArrayList$Itr
  46:          5371         429680  java.lang.reflect.Constructor
  47:         12640         404480  com.codahale.metrics.LongAdder
  48:         16156         387744  com.sun.jmx.mbeanserver.NamedObject
  49:         16133         387192  com.sun.jmx.mbeanserver.StandardMBeanSupport
  50:          9536         381440  org.apache.cassandra.db.EmptyIterators$EmptyUnfilteredRowIterator
  51:          6035         337960  org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator
  52:          6031         337736  org.apache.cassandra.db.transform.UnfilteredRows
  53:          8298         331920  org.apache.cassandra.db.rows.BTreeRow$Builder
  54:          5182         331648  sun.security.provider.SHA2$SHA256
  55:         10356         331392  org.apache.cassandra.utils.btree.BTree$$Lambda$192/259279152
  56:          8145         325800  org.apache.cassandra.db.rows.SerializationHelper
  57:          8144         325760  org.apache.cassandra.io.sstable.SSTableIdentityIterator
  58:          8144         325760  org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator
  59:           176         319536  [Ljava.util.concurrent.ConcurrentHashMap$Node;
  60:          9716         310912  java.net.InetAddress$InetAddressHolder
  61:          7770         310800  com.github.benmanes.caffeine.cache.NodeFactory$SStMW
  62:         18470         295520  org.apache.cassandra.db.rows.CellPath$SingleItemCellPath
  63:          2505         276784  [S
  64:          5646         271008  com.codahale.metrics.EWMA
  65:         11258         270192  java.util.concurrent.ConcurrentLinkedDeque$Node
  66:          8248         263936  org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator$1
  67:         10618         254832  java.lang.Double
  68:          7921         253472  org.apache.cassandra.cache.ChunkCache$Buffer
  69:          7773         248736  org.apache.cassandra.cache.ChunkCache$Key
  70:         10296         247104  org.apache.cassandra.dht.Token$KeyBound
  71:          6096         243816  [Lorg.apache.cassandra.db.transform.Transformation;
  72:          6035         241400  org.apache.cassandra.db.rows.Row$Merger
  73:          6034         241360  org.apache.cassandra.db.rows.RangeTombstoneMarker$Merger
  74:          6034         241360  org.apache.cassandra.db.rows.Row$Merger$ColumnDataReducer
  75:          9969         239256  org.apache.cassandra.db.RowIndexEntry
  76:          9699         232776  java.net.Inet4Address
  77:          5750         230000  org.apache.cassandra.utils.concurrent.Ref$State
  78:         13690         219040  java.util.concurrent.atomic.AtomicInteger
  79:          9091         218184  org.apache.cassandra.gms.GossipDigest
  80:         12392         216040  [Ljava.lang.Class;
  81:          5289         211560  org.apache.cassandra.utils.MergeIterator$ManyToOne
  82:         13079         209264  java.lang.Object
  83:          5183         207320  org.apache.cassandra.repair.Validator$CountingDigest
  84:          8157         195768  org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxGauge
  85:          6035         193120  org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator$MergeReducer
  86:          6023         192736  org.apache.cassandra.db.LivenessInfo$ExpiringLivenessInfo
  87:          5745         183840  com.google.common.collect.RegularImmutableList
  88:          6035         180640  [Lorg.apache.cassandra.db.rows.Row;
  89:          6034         180600  [Lorg.apache.cassandra.db.rows.RangeTombstoneMarker;
  90:          6033         180576  [Lorg.apache.cassandra.db.DeletionTime;
  91:          7464         179136  org.apache.cassandra.db.rows.BTreeRow$$Lambda$109/2102075500
  92:          5288         171488  [Lorg.apache.cassandra.utils.MergeIterator$Candidate;
  93:          5331         170592  com.google.common.collect.Iterators$11
  94:          5183         165856  java.security.MessageDigest$Delegate
  95:          5178         165696  com.google.common.collect.Iterators$7
  96:          5157         165024  org.apache.cassandra.utils.MerkleTree$RowHash
  97:           169         163280  [Lio.netty.util.Recycler$DefaultHandle;
  98:          2304         147456  io.netty.buffer.PoolSubpage
  99:          4608         147456  java.util.EnumMap$EntryIterator
 100:          6034         144816  org.apache.cassandra.db.rows.Row$Merger$CellReducer
 101:          1595         140360  java.lang.reflect.Method
 102:          2893         138864  java.util.TreeMap
 103:          5750         138000  org.apache.cassandra.utils.concurrent.Ref
 104:          8453         135248  org.apache.cassandra.db.rows.BTreeRow$Builder$CellResolver
 105:          5613         134712  java.util.concurrent.atomic.AtomicLong
 106:          5509         132216  org.apache.cassandra.utils.btree.BTree$FiltrationTracker
 107:          5179         124296  com.google.common.collect.Iterables$6
 108:          5179         124296  com.google.common.collect.Iterables$8
 109:          5179         124296  com.google.common.collect.Iterators$5
 110:          5179         124296  com.google.common.collect.Iterators$8
 111:          5177         124248  com.google.common.collect.Iterables$2
 112:          5159         123816  sun.security.jca.GetInstance$Instance
 113:          2577         123696  java.util.concurrent.locks.ReentrantReadWriteLock$NonfairSync
 114:          2399         115152  org.apache.cassandra.metrics.DecayingEstimatedHistogramReservoir
 115:          4643         111432  org.apache.cassandra.db.DeletionTime
 116:          4490         107760  org.apache.cassandra.db.Columns
 117:          2673         106920  java.util.EnumMap
 118:          4202         100848  org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxCounter
 119:          6095          97520  org.apache.cassandra.db.transform.BaseIterator$Stop
 120:          4041          96984  java.util.concurrent.ConcurrentLinkedDeque
 121:          4033          96792  org.apache.cassandra.utils.concurrent.Ref$GlobalState
 122:          1882          90336  com.codahale.metrics.Meter
 123:          5596          89536  java.util.concurrent.atomic.AtomicLongArray
 124:          1845          88560  org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxTimer
 125:          5179          82864  com.google.common.collect.Iterables$3
 126:          2050          82000  org.apache.cassandra.utils.btree.BTree$Builder
 127:          1111          71104  java.nio.DirectByteBufferR
 128:          1713          68520  java.util.LinkedHashMap$Entry
 129:          2115          67680  io.netty.util.Recycler$DefaultHandle
 130:          1687          67480  java.lang.ref.SoftReference
 131:          1519          66968  [Ljava.lang.String;
 132:          2724          65376  org.apache.cassandra.db.PartitionColumns
 133:          1598          63920  org.apache.cassandra.io.util.MmappedRegions$State
 134:          2572          61728  java.util.concurrent.locks.ReentrantReadWriteLock
 135:          3736          59776  java.util.concurrent.atomic.AtomicBoolean
 136:           154          59136  io.netty.util.concurrent.FastThreadLocalThread
 137:          1835          58720  org.apache.cassandra.utils.MergeIterator$TrivialOneToOne
 138:          1794          57408  org.apache.cassandra.gms.EndpointState
 139:           896          57344  org.apache.cassandra.config.ColumnDefinition
 140:          1385          55400  sun.misc.Cleaner
 141:          2302          55248  org.apache.cassandra.db.commitlog.CommitLogPosition
 142:          1713          54816  java.io.FileDescriptor
 143:           802          51328  sun.nio.ch.FileChannelImpl
 144:          2137          51288  org.apache.cassandra.db.rows.Row$Deletion
 145:           400          51200  org.apache.cassandra.io.sstable.format.big.BigTableReader
 146:          1584          50688  java.lang.StackTraceElement
 147:          1583          50656  com.googlecode.concurrentlinkedhashmap.ConcurrentHashMapV8$Node
 148:          1583          50656  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$Node
 149:          1579          50528  java.lang.ref.WeakReference
 150:          1563          50016  org.apache.cassandra.io.util.Memory
 151:          1559          49888  java.util.concurrent.locks.ReentrantLock$NonfairSync
 152:            60          48760  [D
 153:           867          48552  java.lang.invoke.MemberName
 154:          1176          47040  org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$LocalSessionWrapper
 155:          1176          47040  org.apache.cassandra.net.MessageIn
 156:          1938          46512  org.apache.cassandra.db.rows.ComplexColumnData
 157:          1157          46280  com.google.common.util.concurrent.AbstractFuture$Sync
 158:          1893          45432  java.util.concurrent.Executors$RunnableAdapter
 159:           400          44800  org.apache.cassandra.io.sstable.metadata.StatsMetadata
 160:           605          43560  java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask
 161:          2713          43408  com.codahale.metrics.Counter
 162:          1794          43056  org.apache.cassandra.gms.HeartBeatState
 163:          1033          41320  org.apache.cassandra.db.rows.BTreeRow$Builder$ComplexColumnDeletion
 164:          2581          41296  java.util.concurrent.locks.ReentrantReadWriteLock$ReadLock
 165:          2581          41296  java.util.concurrent.locks.ReentrantReadWriteLock$Sync$ThreadLocalHoldCounter
 166:          2581          41296  java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock
 167:           616          39424  com.google.common.collect.MapMakerInternalMap$Segment
 168:          1611          38664  com.codahale.metrics.Histogram
 169:          1611          38664  com.codahale.metrics.Timer
 170:          2410          38560  java.util.concurrent.atomic.AtomicReference
 171:           601          38464  java.util.concurrent.ConcurrentHashMap
 172:          1601          38424  org.apache.cassandra.io.util.ChannelProxy
 173:          1587          38088  org.apache.cassandra.cache.KeyCacheKey
 174:          1583          37992  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$WeightedValue
 175:           945          37800  org.apache.cassandra.metrics.LatencyMetrics
 176:          1557          37368  org.apache.cassandra.gms.VersionedValue
 177:          1157          37024  java.lang.ThreadLocal$ThreadLocalMap$Entry
 178:          1540          36960  java.util.concurrent.LinkedBlockingQueue$Node
 179:          1525          36600  org.apache.cassandra.repair.NodePair
 180:           151          36240  org.apache.cassandra.metrics.TableMetrics
 181:          1490          35760  java.util.concurrent.ConcurrentLinkedQueue$Node
 182:          2213          35408  java.util.TreeMap$KeySet
 183:           868          34720  java.util.HashMap$ValueIterator
 184:           863          34520  java.lang.invoke.MethodType
 185:           710          34080  org.apache.cassandra.metrics.RestorableMeter$RestorableEWMA
 186:           418          33696  [Ljava.lang.ThreadLocal$ThreadLocalMap$Entry;
 187:           809          32360  sun.nio.ch.FileChannelImpl$Unmapper
 188:          1344          32256  com.google.common.util.concurrent.ExecutionList
 189:          1342          32208  org.apache.cassandra.utils.Pair
 190:          2012          32192  java.lang.Integer
 191:           800          32000  org.apache.cassandra.io.util.FileHandle
 192:          1333          31992  org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxHistogram
 193:          1324          31776  [Lorg.apache.cassandra.dht.Range;
 194:           948          30336  org.apache.cassandra.db.partitions.AbstractBTreePartition$Holder
 195:          1223          29352  java.lang.StringBuilder
 196:           898          28736  sun.security.util.DerInputBuffer
 197:           898          28736  sun.security.util.DerValue
 198:          1196          28704  javax.management.openmbean.CompositeDataSupport
 199:          1176          28224  org.apache.cassandra.concurrent.ExecutorLocals
 200:          1176          28224  org.apache.cassandra.net.MessageDeliveryTask
 201:           866          27712  java.lang.invoke.MethodType$ConcurrentWeakInternSet$WeakEntry
 202:          1143          27432  org.apache.cassandra.repair.SyncStat
 203:           685          27400  org.apache.cassandra.io.sstable.IndexInfo
 204:          1109          26616  org.apache.cassandra.utils.Interval
 205:           828          26496  org.apache.cassandra.utils.MergeIterator$OneToOne
 206:           816          26112  java.lang.ref.ReferenceQueue
 207:           800          25600  org.apache.cassandra.io.util.FileHandle$Cleanup
 208:           982          23568  java.util.Collections$UnmodifiableRandomAccessList
 209:           716          22912  org.apache.cassandra.db.context.CounterContext$ContextState
 210:           941          22584  org.apache.cassandra.utils.MerkleTrees
 211:           400          22400  org.apache.cassandra.io.compress.CompressionMetadata
 212:           400          22400  org.apache.cassandra.io.sstable.IndexSummary
 213:           400          22400  org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier
 214:           553          22120  org.apache.cassandra.db.SerializationHeader
 215:           389          21784  sun.nio.cs.UTF_8$Encoder
 216:           160          21760  io.netty.util.internal.InternalThreadLocalMap
 217:           898          21552  sun.security.util.DerInputStream
 218:           445          21360  org.apache.cassandra.repair.RepairJob
 219:           885          21240  [Lsun.security.x509.AVA;
 220:           885          21240  sun.security.x509.AVA
 221:           885          21240  sun.security.x509.RDN
 222:           878          21072  org.apache.cassandra.repair.TreeResponse
 223:           855          20520  java.util.concurrent.ConcurrentSkipListMap$Node
 224:           628          20096  java.util.Hashtable$Entry
 225:           349          20024  [Z
 226:           621          19872  java.io.File
 227:          1233          19728  java.util.TreeMap$Values
 228:          1212          19392  java.util.Optional
 229:           404          19392  org.apache.cassandra.io.sstable.Descriptor
 230:           604          19328  [Lcom.codahale.metrics.Histogram;
 231:           802          19248  sun.nio.ch.NativeThreadSet
 232:           801          19224  org.apache.cassandra.io.util.MmappedRegions
 233:           399          19152  org.apache.cassandra.io.sstable.format.big.BigFormat$BigVersion
 234:           798          19152  org.apache.cassandra.io.util.ChannelProxy$Cleanup
 235:           798          19152  org.apache.cassandra.utils.EstimatedHistogram
 236:           788          18912  org.apache.cassandra.metrics.ClearableHistogram
 237:           766          18384  com.google.common.collect.SingletonImmutableList
 238:           762          18288  org.apache.cassandra.gms.GossipDigestSyn
 239:           569          18208  java.nio.DirectByteBuffer$Deallocator
 240:           569          18208  org.apache.cassandra.db.filter.ColumnFilter
 241:           300          18000  [Ljava.lang.ref.SoftReference;
 242:           160          17920  org.apache.cassandra.config.CFMetaData
 243:           744          17856  java.util.concurrent.CopyOnWriteArrayList
 244:           442          17680  java.util.HashMap$EntryIterator
 245:           221          17680  org.apache.cassandra.io.sstable.format.big.BigTableScanner
 246:           225          17464  [Ljava.lang.StackTraceElement;
 247:          1084          17344  java.util.EnumMap$EntrySet
 248:           424          16960  org.apache.cassandra.utils.btree.NodeCursor
 249:            32          16896  [Lcom.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$PaddedAtomicReference;
 250:           300          16800  org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy
 251:             1          16400  [Lcom.googlecode.concurrentlinkedhashmap.ConcurrentHashMapV8$Node;
 252:           512          16384  org.apache.cassandra.repair.RepairJobDesc
 253:           154          16016  com.google.common.collect.MapMakerInternalMap
 254:           500          16000  java.lang.invoke.DirectMethodHandle
 255:           400          16000  org.apache.cassandra.io.sstable.BloomFilterTracker
 256:           998          15968  org.antlr.runtime.BitSet
 257:           664          15936  com.google.common.collect.ImmutableMapEntry$TerminalEntry
 258:           398          15920  java.util.WeakHashMap$Entry
 259:           392          15680  java.lang.ref.Finalizer
 260:           325          15600  java.util.concurrent.ConcurrentSkipListMap
 261:           487          15584  org.apache.cassandra.schema.CompressionParams
 262:           485          15520  sun.security.util.ObjectIdentifier
 263:           483          15456  org.apache.cassandra.db.partitions.AtomicBTreePartition
 264:           161          15456  org.apache.cassandra.schema.TableParams
 265:           170          15440  [Ljava.util.WeakHashMap$Entry;
 266:           384          15360  io.netty.buffer.PoolChunkList
 267:           382          15280  org.apache.cassandra.repair.RemoteSyncTask
 268:           941          15056  org.apache.cassandra.utils.MerkleTrees$TokenRangeComparator
 269:           622          14928  java.util.Collections$1
 270:           622          14928  org.apache.cassandra.db.RowIndexEntry$Serializer
 271:           930          14880  java.util.concurrent.locks.ReentrantLock
 272:           464          14848  org.apache.cassandra.cql3.ColumnIdentifier
 273:           925          14800  java.util.HashSet
 274:           264          14784  java.util.LinkedHashMap
 275:           151          14496  org.apache.cassandra.db.ColumnFamilyStore
 276:           604          14496  org.apache.cassandra.metrics.TableMetrics$TableHistogram
 277:           301          14448  ch.qos.logback.classic.Logger
 278:           355          14200  org.apache.cassandra.metrics.RestorableMeter
 279:           442          14144  org.apache.cassandra.io.util.RandomAccessReader
 280:           430          14056  [Lcom.google.common.collect.ImmutableMapEntry;
 281:           433          13856  com.google.common.collect.MapMakerInternalMap$StrongEntry
 282:           433          13856  com.google.common.collect.MapMakerInternalMap$WeakValueReference
 283:           855          13680  java.nio.channels.spi.AbstractInterruptibleChannel$1
 284:            34          13600  org.apache.cassandra.net.IncomingTcpConnection
 285:           333          13320  com.google.common.collect.RegularImmutableSortedMap
 286:           818          13088  java.lang.ref.ReferenceQueue$Lock
 287:           201          12864  java.net.URL
 288:           803          12848  sun.nio.ch.FileDispatcherImpl
 289:           401          12832  org.apache.cassandra.utils.BloomFilter
 290:           200          12800  java.util.regex.Matcher
 291:           400          12800  org.apache.cassandra.cache.ChunkCache$CachingRebufferer
 292:           400          12800  org.apache.cassandra.io.util.CompressedChunkReader$Mmap
 293:           400          12800  org.apache.cassandra.io.util.MmapRebufferer
 294:           799          12784  org.apache.cassandra.io.util.MmappedRegions$Tidier
 295:           799          12784  org.apache.cassandra.utils.concurrent.WrappedSharedCloseable$Tidy
 296:           399          12768  org.apache.cassandra.io.sstable.format.SSTableReader$GlobalTidy
 297:           797          12752  java.util.Collections$SingletonSet
 298:           396          12672  java.util.UUID
 299:           784          12544  java.util.HashMap$KeySet
 300:           521          12504  java.util.concurrent.ConcurrentLinkedQueue
 301:           154          12320  org.apache.cassandra.db.rows.RowAndDeletionMergeIterator
 302:           170          12240  java.lang.reflect.Field
 303:           507          12168  org.apache.cassandra.db.BufferDecoratedKey
 304:           151          12080  org.apache.cassandra.db.Memtable
 305:           302          12080  org.apache.cassandra.db.compaction.SizeTieredCompactionStrategyOptions
 306:           376          12032  java.lang.invoke.LambdaForm$Name
 307:           213          11928  sun.security.ssl.CipherSuite
 308:            27          11880  org.apache.cassandra.net.OutboundTcpConnection
 309:           738          11808  java.util.HashMap$Values
 310:           208          11648  java.lang.Package
 311:           242          11616  org.apache.cassandra.utils.IntervalTree$IntervalNode
 312:           128          11264  [Lio.netty.buffer.PoolSubpage;
 313:           699          11184  java.util.HashMap$EntrySet
 314:           155          11160  org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater
 315:           344          11008  java.util.concurrent.ConcurrentSkipListMap$HeadIndex
 316:           341          10912  sun.misc.FDBigInteger
 317:           227          10896  sun.security.x509.X500Name
 318:           453          10872  org.apache.cassandra.utils.DefaultValue
 319:           333          10656  com.google.common.collect.RegularImmutableSortedSet
 320:           265          10600  java.util.Formatter$FormatSpecifier
 321:           263          10520  [Ljava.util.Formatter$Flags;
 322:           433          10392  org.apache.cassandra.cql3.ColumnIdentifier$InternedKey
 323:            72          10368  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$PaddedAtomicLong
 324:           324          10368  sun.security.x509.AlgorithmId
 325:           320          10240  io.netty.util.internal.chmv8.LongAdderV8
 326:           633          10128  java.util.concurrent.atomic.AtomicReferenceArray
 327:           180          10080  java.lang.invoke.MethodTypeForm
 328:           156           9984  io.netty.util.Recycler$Stack
 329:           416           9984  java.lang.ThreadLocal$ThreadLocalMap
 330:           622           9952  org.apache.cassandra.dht.Range$1
 331:           154           9856  org.apache.cassandra.cql3.UpdateParameters
 332:           244           9760  java.util.HashMap$KeyIterator
 333:           304           9728  java.util.concurrent.locks.AbstractQueuedSynchronizer$Node
 334:           302           9664  org.apache.cassandra.metrics.TableMetrics$TableMetricNameFactory
 335:           302           9664  org.apache.cassandra.utils.memory.MemtableAllocator$SubAllocator
 336:           400           9600  [Lorg.apache.cassandra.io.util.Memory;
 337:           400           9600  org.apache.cassandra.utils.StreamingHistogram
 338:           399           9576  [Ljava.lang.AutoCloseable;
 339:            25           9400  java.lang.Thread
 340:           195           9360  org.apache.cassandra.net.MessageOut
 341:           292           9344  [Lcom.codahale.metrics.Timer;
 342:            16           9216  io.netty.util.internal.shaded.org.jctools.queues.MpscChunkedArrayQueue
 343:           381           9144  org.apache.cassandra.repair.RepairResult
 344:           362           8688  com.google.common.util.concurrent.ExecutionList$RunnableExecutorPair
 345:            68           8680  [Ljava.util.Hashtable$Entry;
 346:           271           8672  org.apache.cassandra.metrics.CassandraMetricsRegistry$JmxMeter
 347:           108           8640  sun.security.x509.X509CertImpl
 348:           269           8608  javax.management.MBeanAttributeInfo
 349:           215           8600  com.google.common.collect.RegularImmutableMap
 350:           215           8600  org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator
 351:           151           8456  org.apache.cassandra.db.compaction.CompactionStrategyManager
 352:           260           8320  javax.management.MBeanParameterInfo
 353:           142           7952  java.beans.MethodDescriptor
 354:           331           7944  java.util.Collections$SingletonList
 355:           494           7904  com.google.common.base.Present
 356:           164           7872  java.util.WeakHashMap
 357:           227           7768  [Lsun.security.x509.RDN;
 358:           483           7728  org.apache.cassandra.utils.CounterId
 359:           318           7632  java.util.Collections$SetFromMap
 360:           318           7632  java.util.Formatter$FixedString
 361:           156           7488  org.apache.cassandra.utils.concurrent.OpOrder$Group
 362:           187           7480  com.google.common.util.concurrent.ListenableFutureTask
 363:           308           7392  org.apache.cassandra.utils.btree.BTreeSet
 364:           306           7344  java.beans.MethodRef
 365:           304           7296  org.apache.cassandra.io.util.MmappedRegions$Region
 366:           302           7248  org.apache.cassandra.utils.TopKSampler
 367:           151           7248  org.apache.cassandra.utils.memory.SlabAllocator
 368:           148           7104  java.lang.invoke.LambdaForm
 369:           292           7008  org.apache.cassandra.metrics.TableMetrics$TableTimer
 370:           155           6904  [Ljava.lang.invoke.LambdaForm$Name;
 371:           121           6776  jdk.internal.org.objectweb.asm.Item
 372:           169           6760  java.security.AccessControlContext
 373:           280           6720  java.util.Date
 374:           168           6720  java.util.IdentityHashMap
 375:           209           6688  org.apache.cassandra.db.ClusteringComparator
 376:           278           6672  com.google.common.collect.ImmutableSortedAsList
 377:           278           6672  com.google.common.collect.RegularImmutableSortedMap$EntrySet
 378:           278           6672  com.google.common.collect.RegularImmutableSortedMap$EntrySet$1
 379:           404           6464  java.util.concurrent.CopyOnWriteArraySet
 380:           200           6400  java.util.Formatter
 381:           400           6400  org.apache.cassandra.io.sstable.format.SSTableReader$UniqueIdentifier
 382:           399           6384  org.apache.cassandra.utils.obs.OffHeapBitSet
 383:            23           6368  [[S
 384:           394           6304  org.apache.cassandra.db.commitlog.IntervalSet
 385:           262           6288  java.util.concurrent.CopyOnWriteArrayList$COWIterator
 386:           156           6240  org.apache.cassandra.cql3.QueryOptions$DefaultQueryOptions
 387:           111           6216  sun.security.util.MemoryCache$SoftCacheEntry
 388:           155           6200  javax.management.MBeanOperationInfo
 389:           155           6200  org.apache.cassandra.db.Mutation
 390:           155           6200  org.apache.cassandra.db.partitions.PartitionUpdate
 391:           155           6200  org.apache.cassandra.utils.memory.AbstractAllocator$CloningBTreeRowBuilder
 392:           193           6176  org.apache.cassandra.net.OutboundTcpConnection$QueuedMessage
 393:           200           6160  [Ljava.util.Formatter$FormatString;
 394:           154           6160  java.util.Collections$SingletonMap
 395:           154           6160  org.apache.cassandra.db.rows.BTreeRow$$Lambda$122/418553968
 396:           154           6160  org.apache.cassandra.db.rows.UnfilteredSerializer$$Lambda$125/1196438970
 397:           152           6080  org.apache.cassandra.db.lifecycle.View
 398:           253           6072  java.util.concurrent.ConcurrentSkipListMap$Index
 399:           189           6048  org.apache.cassandra.repair.ValidationTask
 400:           108           6048  sun.security.x509.X509CertInfo
 401:           251           6024  javax.management.ImmutableDescriptor
 402:            62           5952  java.util.jar.JarFile$JarFileEntry
 403:            82           5904  java.beans.PropertyDescriptor
 404:           244           5856  org.apache.cassandra.db.rows.ComplexColumnData$$Lambda$111/177399658
 405:           243           5832  org.apache.cassandra.cql3.functions.FunctionName
 406:            52           5824  sun.nio.ch.SocketChannelImpl
 407:            90           5760  com.github.benmanes.caffeine.cache.BoundedLocalCache$$Lambda$99/328488350
 408:           240           5736  [Lorg.apache.cassandra.db.marshal.AbstractType;
 409:           179           5728  org.apache.cassandra.auth.DataResource
 410:            89           5696  org.apache.cassandra.utils.btree.NodeBuilder
 411:           355           5680  org.apache.cassandra.io.sstable.format.SSTableReader$GlobalTidy$1
 412:           229           5496  org.apache.cassandra.db.MutableDeletionInfo
 413:           227           5448  java.security.Provider$ServiceKey
 414:           224           5376  com.google.common.collect.SingletonImmutableSet
 415:            74           5328  ch.qos.logback.classic.spi.LoggingEvent
 416:            95           5320  java.security.Provider$Service
 417:           165           5280  java.lang.invoke.BoundMethodHandle$Species_L
 418:           106           5272  [Ljavax.management.MBeanAttributeInfo;
 419:           109           5232  java.util.concurrent.ThreadPoolExecutor$Worker
 420:           325           5200  org.apache.cassandra.utils.concurrent.WaitQueue
 421:           108           5184  javax.management.MBeanInfo
 422:           210           5040  com.google.common.collect.RegularImmutableAsList
 423:           210           5040  com.google.common.collect.RegularImmutableMap$EntrySet
 424:           208           4992  java.util.concurrent.ConcurrentHashMap$KeySetView
 425:           155           4960  org.apache.cassandra.db.commitlog.CommitLogSegment$Allocation
 426:           154           4928  [Lcom.google.common.collect.MapMakerInternalMap$Segment;
 427:           308           4928  org.apache.cassandra.db.Columns$$Lambda$121/617875913
 428:           154           4928  org.apache.cassandra.db.rows.EncodingStats$Collector
 429:           154           4928  org.apache.cassandra.io.util.DataOutputBufferFixed
 430:           102           4896  java.util.TimSort
 431:           152           4864  org.apache.cassandra.db.lifecycle.Tracker
 432:           202           4848  org.apache.cassandra.db.lifecycle.SSTableIntervalTree
 433:           121           4840  java.io.ObjectStreamField
 434:           151           4832  org.apache.cassandra.db.compaction.CompactionLogger
 435:            99           4752  javax.management.Notification
 436:           198           4752  org.apache.cassandra.db.ClusteringBound
 437:           198           4752  org.apache.cassandra.db.rows.ComplexColumnData$Builder
 438:           180           4744  [Ljava.security.ProtectionDomain;
 439:            63           4536  org.apache.cassandra.db.compaction.CompactionManager$ValidationCompactionIterator
 440:            40           4480  java.net.SocksSocketImpl
 441:           275           4400  java.util.Formatter$Flags
 442:           273           4368  java.lang.Byte
 443:            32           4352  io.netty.buffer.PoolArena$DirectArena
 444:            32           4352  io.netty.buffer.PoolArena$HeapArena
 445:           181           4344  java.lang.invoke.LambdaForm$NamedFunction
 446:             6           4320  [Ljdk.internal.org.objectweb.asm.Item;
 447:            90           4320  com.github.benmanes.caffeine.cache.BoundedLocalCache$$Lambda$313/480779282
 448:           108           4320  org.apache.cassandra.db.CachedHashDecoratedKey
 449:           178           4272  org.apache.cassandra.gms.GossipDigestAck
 450:           177           4248  java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject
 451:           131           4192  com.sun.jmx.mbeanserver.ConvertingMethod
 452:           128           4096  java.lang.NoSuchMethodException
 453:           256           4096  java.lang.Short
 454:            70           3920  sun.misc.URLClassPath$JarLoader
 455:            60           3840  java.util.jar.JarFile
 456:            80           3840  java.util.logging.LogManager$LoggerWeakRef
 457:           160           3840  org.apache.cassandra.db.Serializers
 458:           160           3840  org.apache.cassandra.db.Serializers$NewFormatSerializer
 459:           160           3840  org.apache.cassandra.io.sstable.IndexInfo$Serializer
 460:           160           3840  org.apache.cassandra.schema.Indexes
 461:            53           3816  java.util.regex.Pattern
 462:            95           3800  sun.security.rsa.RSAPublicKeyImpl
 463:           158           3792  com.sun.jmx.mbeanserver.PerInterface$MethodAndSig
 464:            59           3776  java.text.DateFormatSymbols
 465:           155           3720  org.apache.cassandra.utils.memory.ContextAllocator
 466:           154           3696  [Lorg.apache.cassandra.db.Directories$DataDirectory;
 467:           154           3696  com.google.common.collect.Collections2$TransformedCollection
 468:           154           3696  org.apache.cassandra.cql3.statements.UpdatesCollector
 469:           154           3696  org.apache.cassandra.db.filter.ClusteringIndexNamesFilter
 470:           154           3696  org.apache.cassandra.db.rows.Rows$$Lambda$120/877468788
 471:           151           3624  [Ljava.io.File;
 472:           151           3624  org.apache.cassandra.db.Directories
 473:           151           3624  org.apache.cassandra.db.Memtable$ColumnsCollector
 474:           151           3624  org.apache.cassandra.index.SecondaryIndexManager
 475:           151           3624  org.apache.cassandra.metrics.TableMetrics$10
 476:           151           3624  org.apache.cassandra.metrics.TableMetrics$11
 477:           151           3624  org.apache.cassandra.metrics.TableMetrics$12
 478:           151           3624  org.apache.cassandra.metrics.TableMetrics$14
 479:           151           3624  org.apache.cassandra.metrics.TableMetrics$15
 480:           151           3624  org.apache.cassandra.metrics.TableMetrics$16
 481:           151           3624  org.apache.cassandra.metrics.TableMetrics$17
 482:           151           3624  org.apache.cassandra.metrics.TableMetrics$19
 483:           151           3624  org.apache.cassandra.metrics.TableMetrics$2
 484:           151           3624  org.apache.cassandra.metrics.TableMetrics$21
 485:           151           3624  org.apache.cassandra.metrics.TableMetrics$23
 486:           151           3624  org.apache.cassandra.metrics.TableMetrics$24
 487:           151           3624  org.apache.cassandra.metrics.TableMetrics$25
 488:           151           3624  org.apache.cassandra.metrics.TableMetrics$27
 489:           151           3624  org.apache.cassandra.metrics.TableMetrics$29
 490:           151           3624  org.apache.cassandra.metrics.TableMetrics$3
 491:           151           3624  org.apache.cassandra.metrics.TableMetrics$30
 492:           151           3624  org.apache.cassandra.metrics.TableMetrics$31
 493:           151           3624  org.apache.cassandra.metrics.TableMetrics$32
 494:           151           3624  org.apache.cassandra.metrics.TableMetrics$33
 495:           151           3624  org.apache.cassandra.metrics.TableMetrics$34
 496:           151           3624  org.apache.cassandra.metrics.TableMetrics$4
 497:           151           3624  org.apache.cassandra.metrics.TableMetrics$5
 498:           151           3624  org.apache.cassandra.metrics.TableMetrics$6
 499:           151           3624  org.apache.cassandra.metrics.TableMetrics$7
 500:           151           3624  org.apache.cassandra.metrics.TableMetrics$8
 501:           151           3624  org.apache.cassandra.metrics.TableMetrics$9
 502:           113           3616  [Lorg.apache.cassandra.utils.memory.BufferPool$Chunk;
 503:           113           3616  org.apache.cassandra.utils.memory.BufferPool$LocalPoolRef
 504:           225           3600  org.apache.cassandra.cql3.FieldIdentifier
 505:           149           3576  org.apache.cassandra.cql3.restrictions.RestrictionSet
 506:           221           3536  java.util.zip.CRC32
 507:            63           3528  org.apache.cassandra.db.compaction.CompactionManager$ValidationCompactionController
 508:            63           3528  org.apache.cassandra.repair.Validator
 509:            12           3480  [Ljava.util.concurrent.RunnableScheduledFuture;
 510:           108           3456  java.util.Collections$SynchronizedMap
 511:           143           3432  com.google.common.util.concurrent.Futures$CombinedFuture$2
 512:           143           3432  java.util.LinkedList$Node
 513:           107           3424  java.io.IOException
 514:            37           3384  [Lorg.apache.cassandra.io.sstable.IndexInfo;
 515:            60           3360  org.cliffc.high_scale_lib.ConcurrentAutoTable$CAT
 516:           122           3344  [Ljavax.management.MBeanParameterInfo;
 517:           209           3344  org.apache.cassandra.db.ClusteringComparator$$Lambda$31/1914108708
 518:           209           3344  org.apache.cassandra.db.ClusteringComparator$$Lambda$32/1889757798
 519:           209           3344  org.apache.cassandra.db.ClusteringComparator$$Lambda$33/1166106620
 520:           209           3344  org.apache.cassandra.db.ClusteringComparator$$Lambda$34/221861886
 521:            41           3328  [Ljava.lang.invoke.MethodHandle;
 522:            32           3328  java.io.ObjectStreamClass
 523:           208           3328  org.apache.cassandra.utils.concurrent.Refs
 524:            69           3312  com.google.common.util.concurrent.Futures$CombinedFuture
 525:           103           3296  org.apache.cassandra.schema.CompactionParams
 526:           137           3288  java.util.ArrayDeque
 527:            24           3264  com.codahale.metrics.Striped64$Cell
 528:           203           3248  org.apache.cassandra.io.util.DataOutputBuffer$GrowingChannel
 529:           135           3240  com.sun.jmx.remote.internal.ArrayNotificationBuffer$NamedNotification
 530:           101           3232  java.util.Vector
 531:           101           3232  org.apache.cassandra.schema.SpeculativeRetryParam
 532:           132           3168  org.apache.cassandra.db.view.TableViews
 533:            79           3160  com.google.common.collect.SingletonImmutableBiMap
 534:            98           3136  org.xml.sax.helpers.LocatorImpl
 535:            98           3136  sun.security.x509.BasicConstraintsExtension
 536:            78           3120  java.security.ProtectionDomain
 537:           129           3096  com.google.common.collect.RegularImmutableMap$NonTerminalMapEntry
 538:            77           3080  sun.nio.cs.UTF_8$Decoder
 539:            64           3072  org.apache.cassandra.db.compaction.CompactionIterator$Purger
 540:            64           3072  org.apache.cassandra.db.transform.UnfilteredPartitions
 541:            96           3072  sun.security.x509.SubjectKeyIdentifierExtension
 542:            24           3032  [Ljava.beans.MethodDescriptor;
 543:            92           3024  [Ljavax.management.MBeanOperationInfo;
 544:            94           3008  java.util.AbstractList$Itr
 545:            91           2912  com.codahale.metrics.Timer$Context
 546:           121           2904  org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate
 547:            60           2880  java.util.zip.Inflater
 548:            45           2880  javax.management.openmbean.OpenMBeanAttributeInfoSupport
 549:           118           2832  java.util.regex.Pattern$1
 550:           118           2832  sun.reflect.generics.tree.SimpleClassTypeSignature
 551:            88           2816  sun.security.x509.KeyUsageExtension
 552:           175           2800  org.apache.cassandra.gms.GossipDigestAck2
 553:           113           2712  org.apache.cassandra.utils.memory.BufferPool$LocalPool
 554:            37           2664  java.util.logging.Logger
 555:           111           2664  sun.security.util.Cache$EqualByteArray
 556:            55           2640  java.util.Hashtable
 557:           163           2608  java.util.IdentityHashMap$KeySet
 558:           162           2592  org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable
 559:           108           2592  org.apache.cassandra.dht.LocalPartitioner$LocalToken
 560:            18           2592  sun.reflect.MethodAccessorGenerator
 561:           108           2592  sun.security.util.BitArray
 562:           108           2592  sun.security.x509.CertificateValidity
 563:           138           2584  [Lcom.sun.jmx.mbeanserver.MXBeanMapping;
 564:           107           2568  java.net.InetSocketAddress$InetSocketAddressHolder
 565:            64           2560  com.google.common.collect.Multimaps$UnmodifiableMultimap
 566:            64           2560  java.util.ArrayList$SubList
 567:            64           2560  java.util.ArrayList$SubList$1
 568:            64           2560  org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$1
 569:           160           2560  org.apache.cassandra.schema.Triggers
 570:            64           2560  org.apache.cassandra.utils.OverlapIterator
 571:            53           2544  java.util.concurrent.LinkedBlockingQueue
 572:           155           2480  org.apache.cassandra.utils.btree.UpdateFunction$Simple
 573:           155           2480  org.apache.cassandra.utils.concurrent.OpOrder
 574:            44           2464  java.lang.Class$ReflectionData
 575:           154           2464  java.util.concurrent.ConcurrentSkipListSet
 576:           154           2464  org.apache.cassandra.db.partitions.PartitionUpdate$$Lambda$117/1004624941
 577:           154           2464  org.apache.cassandra.db.partitions.PartitionUpdate$$Lambda$119/1364111969
 578:           154           2464  org.apache.cassandra.utils.WrappedBoolean
 579:           102           2448  org.apache.cassandra.schema.CachingParams
 580:            76           2432  java.security.CodeSource
 581:           151           2416  org.apache.cassandra.db.Memtable$StatsCollector
 582:           151           2416  org.apache.cassandra.utils.memory.EnsureOnHeap$NoOp
 583:            75           2400  java.util.LinkedList
 584:            50           2400  org.apache.cassandra.cql3.restrictions.StatementRestrictions
 585:            99           2376  sun.security.x509.CertificateExtensions
 586:            74           2368  java.io.ObjectStreamClass$WeakClassKey
 587:            98           2352  java.lang.Class$AnnotationData
 588:           147           2352  java.util.concurrent.ConcurrentHashMap$ValuesView
 589:            98           2352  java.util.jar.Attributes$Name
 590:            73           2336  java.util.regex.Pattern$Curly
 591:            97           2328  com.google.common.collect.ImmutableMapKeySet
 592:            48           2304  com.google.common.collect.HashMultimap
 593:            96           2304  com.google.common.collect.ImmutableMapKeySet$1
 594:            16           2304  io.netty.channel.epoll.EpollEventLoop
 595:           144           2304  org.apache.cassandra.db.ColumnFamilyStore$3
 596:            96           2304  org.apache.cassandra.metrics.KeyspaceMetrics$17
 597:            72           2304  sun.reflect.ClassFileAssembler
 598:            70           2240  java.util.concurrent.ConcurrentHashMap$ReservationNode
 599:            70           2240  java.util.logging.LogManager$LogNode
 600:            70           2240  org.apache.cassandra.utils.MerkleTree$TreeRangeIterator
 601:            91           2200  [Lcom.github.benmanes.caffeine.cache.RemovalCause;
 602:            91           2184  com.github.benmanes.caffeine.SingleConsumerQueue$Node
 603:            39           2184  org.apache.cassandra.db.marshal.UserType
 604:            90           2160  [Lcom.github.benmanes.caffeine.cache.Node;
 605:           118           2160  [Lsun.reflect.generics.tree.TypeArgument;
 606:            90           2160  com.github.benmanes.caffeine.cache.BoundedLocalCache$AddTask
 607:            90           2160  java.lang.StringBuffer
 608:            67           2144  java.util.TreeMap$ValueIterator
 609:            89           2136  java.lang.RuntimePermission
 610:            89           2136  org.apache.cassandra.io.compress.CompressionMetadata$Chunk
 611:            53           2120  sun.security.ec.NamedCurve
 612:            66           2112  java.io.FilePermission
 613:            66           2112  java.util.zip.ZipCoder
 614:            52           2080  sun.nio.ch.SocketAdaptor
 615:            37           2072  javax.management.MBeanServerNotification
 616:            37           2072  org.apache.cassandra.db.RowIndexEntry$IndexedEntry
 617:            86           2064  javax.management.openmbean.TabularDataSupport
 618:           129           2064  sun.security.x509.KeyIdentifier
 619:            64           2048  com.google.common.util.concurrent.Futures$ChainingListenableFuture
 620:           128           2048  java.lang.Character
 621:            64           2048  org.apache.cassandra.db.partitions.PurgeFunction$$Lambda$104/2021147872
 622:            64           2048  org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$2
 623:            64           2048  sun.misc.FloatingDecimal$ASCIIToBinaryBuffer
 624:            84           2016  java.security.Provider$UString
 625:            18           2016  java.util.GregorianCalendar
 626:            62           1984  org.apache.cassandra.utils.MerkleTrees$TreeRangeIterator
 627:            27           1944  sun.reflect.DelegatingClassLoader
 628:           120           1920  com.codahale.metrics.Striped64$HashCode
 629:            80           1920  java.util.regex.Pattern$GroupTail
 630:            34           1904  org.apache.cassandra.cql3.statements.SelectStatement
 631:            79           1896  com.google.common.collect.ImmutableList$1
 632:            79           1896  java.util.regex.Pattern$GroupHead
 633:            59           1888  java.util.RegularEnumSet
 634:           118           1888  sun.reflect.generics.tree.ClassTypeSignature
 635:           118           1888  sun.security.x509.SerialNumber
 636:            13           1872  java.text.DecimalFormat
 637:            39           1872  sun.util.locale.LocaleObjectCache$CacheEntry
 638:            10           1832  [[B
 639:            57           1824  org.apache.cassandra.cql3.functions.CastFcts$JavaFunctionWrapper
 640:            75           1800  java.util.regex.Pattern$Single
 641:            56           1792  java.lang.Throwable
 642:             8           1792  jdk.internal.org.objectweb.asm.MethodWriter
 643:            74           1776  com.google.common.util.concurrent.Futures$6
 644:           111           1776  java.util.LinkedHashMap$LinkedValues
 645:            44           1760  java.io.ObjectStreamClass$FieldReflectorKey
 646:            36           1728  org.apache.cassandra.concurrent.SEPWorker
 647:            72           1728  sun.reflect.ByteVectorImpl
 648:           108           1728  sun.security.x509.CertificateAlgorithmId
 649:           108           1728  sun.security.x509.CertificateSerialNumber
 650:           108           1728  sun.security.x509.CertificateVersion
 651:           108           1728  sun.security.x509.CertificateX509Key
 652:            18           1728  sun.util.calendar.Gregorian$Date
 653:           107           1712  java.net.InetSocketAddress
 654:             4           1696  [Ljava.lang.Thread;
 655:            53           1696  java.security.spec.EllipticCurve
 656:            30           1688  [Ljava.lang.reflect.Method;
 657:             6           1680  java.util.concurrent.ConcurrentHashMap$CounterCell
 658:            52           1664  java.lang.invoke.DirectMethodHandle$Special
 659:            52           1664  sun.nio.ch.SocketAdaptor$SocketInputStream
 660:            68           1632  org.apache.cassandra.cql3.Constants$Marker
 661:            68           1632  sun.reflect.NativeConstructorAccessorImpl
 662:           101           1616  org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$5/673586830
 663:            40           1600  ch.qos.logback.core.joran.event.StartEvent
 664:            40           1600  com.sun.jmx.mbeanserver.PerInterface
 665:            40           1600  sun.management.DiagnosticCommandArgumentInfo
 666:            99           1584  org.apache.cassandra.db.marshal.AbstractType$$Lambda$4/495702238
 667:            49           1568  java.io.DataOutputStream
 668:            49           1568  java.nio.channels.Channels$1
 669:            65           1560  java.security.spec.ECPoint
 670:            39           1560  org.apache.cassandra.io.util.SafeMemory
 671:            65           1560  org.apache.cassandra.utils.btree.TreeBuilder
 672:            64           1536  org.apache.cassandra.db.compaction.CompactionIterator$GarbageSkipper
 673:            63           1512  com.google.common.util.concurrent.Futures$1
 674:            63           1512  org.apache.cassandra.cql3.restrictions.SingleColumnRestriction$EQRestriction
 675:            63           1512  org.apache.cassandra.db.compaction.CompactionManager$13
 676:            47           1504  org.apache.cassandra.cql3.statements.ParsedStatement$Prepared
 677:            47           1504  org.apache.cassandra.io.util.DataOutputBuffer$1$1
 678:            93           1488  java.util.Collections$UnmodifiableSet
 679:            61           1464  java.util.regex.Pattern$Slice
 680:            60           1440  java.util.zip.ZStreamRef
 681:            51           1408  [Ljava.io.ObjectStreamField;
 682:            16           1392  [Ljava.lang.Byte;
 683:             1           1376  [Lsun.misc.FDBigInteger;
 684:            43           1376  java.util.regex.Pattern$Branch
 685:            43           1376  org.apache.cassandra.concurrent.NamedThreadFactory
 686:            34           1360  ch.qos.logback.core.status.InfoStatus
 687:            17           1360  java.net.URI
 688:            34           1360  org.apache.cassandra.cql3.selection.Selection$SimpleSelection
 689:            61           1352  [Ljava.lang.reflect.Type;
 690:            24           1344  java.util.ResourceBundle$CacheKey
 691:            24           1344  javax.management.openmbean.CompositeType
 692:            72           1336  [Ljavax.management.openmbean.CompositeData;
 693:            33           1320  sun.security.x509.AuthorityKeyIdentifierExtension
 694:            79           1312  [Ljava.security.Principal;
 695:            54           1296  ch.qos.logback.classic.spi.StackTraceElementProxy
 696:            23           1288  java.net.SocketPermission
 697:            39           1280  [Ljava.math.BigInteger;
 698:            40           1280  ch.qos.logback.core.joran.event.EndEvent
 699:            16           1280  com.google.common.cache.LocalCache$Segment
 700:            20           1280  org.apache.cassandra.db.RowIndexEntry$ShallowIndexedEntry
 701:            43           1272  [Ljava.util.regex.Pattern$Node;
 702:            53           1272  sun.nio.ch.Util$BufferCache
 703:            79           1264  java.security.ProtectionDomain$Key
 704:            39           1248  java.lang.Thread$WeakClassKey
 705:            38           1240  [Ljava.lang.reflect.Field;
 706:            14           1232  org.apache.cassandra.concurrent.JMXEnabledThreadPoolExecutor
 707:            38           1216  java.security.Permissions
 708:            50           1200  org.apache.cassandra.cql3.restrictions.ClusteringColumnRestrictions
 709:            50           1200  org.apache.cassandra.cql3.restrictions.IndexRestrictions
 710:            25           1200  org.apache.cassandra.metrics.ClientRequestMetrics
 711:             2           1184  [Lcom.github.benmanes.caffeine.cache.NodeFactory;
 712:            37           1184  java.net.Socket
 713:            49           1176  org.apache.cassandra.cql3.restrictions.PartitionKeySingleRestrictionSet
 714:            21           1176  sun.util.calendar.ZoneInfo
 715:            52           1168  [Lorg.apache.cassandra.cql3.ColumnSpecification;
 716:            24           1152  java.beans.BeanDescriptor
 717:            24           1152  java.lang.management.MemoryUsage
 718:            72           1152  org.apache.cassandra.db.ColumnFamilyStore$1
 719:            36           1152  org.apache.cassandra.io.util.SafeMemory$MemoryTidy
 720:            24           1152  org.hyperic.sigar.FileSystem
 721:            36           1152  sun.reflect.generics.repository.ClassRepository
 722:            20           1120  javax.management.openmbean.ArrayType
 723:            35           1120  org.apache.cassandra.cql3.ResultSet$ResultMetadata
 724:            69           1104  com.google.common.util.concurrent.Futures$8
 725:            69           1104  com.google.common.util.concurrent.Futures$CombinedFuture$1
 726:            46           1104  org.apache.cassandra.metrics.DefaultNameFactory
 727:            69           1104  sun.reflect.DelegatingConstructorAccessorImpl
 728:             3           1080  [Ljava.lang.Integer;
 729:            27           1080  com.google.common.collect.HashBiMap$BiEntry
 730:            27           1080  org.apache.cassandra.utils.CoalescingStrategies$DisabledCoalescingStrategy
 731:            45           1080  sun.reflect.generics.factory.CoreReflectionFactory
 732:            24           1064  [Ljava.beans.PropertyDescriptor;
 733:             2           1056  [Ljava.lang.Long;
 734:             2           1056  [Ljava.lang.Short;
 735:            26           1040  java.math.BigDecimal
 736:            43           1032  io.netty.channel.ChannelOption
 737:            43           1032  java.io.ExpiringCache$Entry
 738:            64           1024  org.apache.cassandra.db.compaction.AbstractCompactionStrategy$ScannerList
 739:            64           1024  org.apache.cassandra.db.compaction.CompactionIterator$1
 740:            64           1024  org.apache.cassandra.repair.RepairJob$3
 741:            63           1008  org.apache.cassandra.repair.RepairJob$2
 742:            12            960  [Lcom.google.common.collect.HashBiMap$BiEntry;
 743:            24            960  java.beans.GenericBeanInfo
 744:            30            960  java.security.Provider$EngineDescription
 745:            40            960  java.util.regex.Pattern$BitClass
 746:            20            960  org.antlr.runtime.CommonToken
 747:            30            960  org.apache.cassandra.cql3.ColumnSpecification
 748:            40            960  org.apache.cassandra.cql3.statements.SelectStatement$Parameters
 749:            60            960  org.cliffc.high_scale_lib.Counter
 750:            20            960  org.cliffc.high_scale_lib.NonBlockingHashMap$CHM
 751:            40            960  org.codehaus.jackson.map.type.ClassKey
 752:            40            960  org.xml.sax.helpers.AttributesImpl
 753:            46            944  [Lsun.reflect.generics.tree.FormalTypeParameter;
 754:            39            936  java.util.regex.Pattern$5
 755:             8            928  [Lorg.apache.cassandra.db.ClusteringBound;
 756:            29            928  java.security.BasicPermissionCollection
 757:            29            928  org.apache.cassandra.io.util.DataInputPlus$DataInputStreamPlus
 758:            23            920  org.codehaus.jackson.map.type.SimpleType
 759:            19            912  sun.management.DiagnosticCommandInfo
 760:            28            896  java.io.DataInputStream
 761:            18            864  net.jpountz.lz4.LZ4BlockOutputStream
 762:            54            864  org.apache.cassandra.config.ColumnDefinition$$Lambda$26/843299092
 763:            54            864  org.apache.cassandra.config.ColumnDefinition$$Lambda$27/605982374
 764:            54            864  org.apache.cassandra.config.ColumnDefinition$1
 765:            18            864  org.apache.cassandra.utils.SlidingTimeRate
 766:            36            864  sun.reflect.Label$PatchInfo
 767:            27            864  sun.reflect.generics.reflectiveObjects.TypeVariableImpl
 768:            36            864  sun.reflect.generics.tree.ClassSignature
 769:            44            856  [Ljavax.management.MBeanConstructorInfo;
 770:            21            840  com.sun.jmx.mbeanserver.MXBeanSupport
 771:            35            840  net.jpountz.xxhash.StreamingXXHash32JNI
 772:            35            840  sun.reflect.generics.scope.ClassScope
 773:            21            840  sun.util.locale.BaseLocale$Key
 774:             2            832  [Lorg.antlr.runtime.BitSet;
 775:            13            832  com.google.common.util.concurrent.SmoothRateLimiter$SmoothBursty
 776:            13            832  java.text.DecimalFormatSymbols
 777:            38            824  [Lsun.reflect.generics.tree.FieldTypeSignature;
 778:            34            816  org.apache.cassandra.cql3.selection.SelectionColumnMapping
 779:             6            816  org.apache.cassandra.metrics.KeyspaceMetrics
 780:            25            800  java.util.PropertyPermission
 781:            20            800  org.cliffc.high_scale_lib.NonBlockingHashMap
 782:            14            784  java.util.HashMap$TreeNode
 783:            14            784  org.apache.cassandra.cql3.statements.UpdateStatement
 784:            32            768  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$IdentityMapping
 785:            32            768  io.netty.channel.unix.FileDescriptor
 786:            16            768  java.util.ResourceBundle$BundleReference
 787:            24            768  java.util.ResourceBundle$LoaderReference
 788:            16            768  net.jpountz.lz4.LZ4BlockInputStream
 789:            32            768  org.apache.cassandra.cql3.functions.CastFcts$CastAsTextFunction
 790:            32            768  sun.reflect.generics.reflectiveObjects.ParameterizedTypeImpl
 791:            24            768  sun.security.x509.OIDMap$OIDInfo
 792:            23            736  javax.management.MBeanConstructorInfo
 793:            23            736  sun.management.MappedMXBeanType$BasicMXBeanType
 794:            30            720  com.google.common.collect.ImmutableEntry
 795:            30            720  java.io.ObjectStreamClass$EntryFuture
 796:            15            720  java.lang.management.PlatformComponent
 797:             9            720  org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor
 798:             9            720  org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor
 799:             1            720  org.apache.cassandra.config.Config
 800:            18            720  org.apache.cassandra.metrics.ThreadPoolMetrics
 801:            22            704  com.sun.jmx.mbeanserver.WeakIdentityHashMap$IdentityWeakReference
 802:            11            704  java.text.SimpleDateFormat
 803:            29            696  org.apache.cassandra.net.MessagingService$Verb
 804:            36            688  [Lsun.reflect.generics.tree.ClassTypeSignature;
 805:            43            688  java.util.regex.Pattern$BranchConn
 806:            17            680  sun.reflect.UnsafeQualifiedStaticLongFieldAccessorImpl
 807:            29            672  [Ljava.lang.reflect.TypeVariable;
 808:            28            672  ch.qos.logback.core.spi.ContextAwareBase
 809:            28            672  java.util.regex.Pattern$Ctype
 810:            28            672  java.util.regex.Pattern$Start
 811:             4            672  jdk.internal.org.objectweb.asm.ClassWriter
 812:            42            672  org.apache.cassandra.config.ColumnDefinition$Raw$Literal
 813:            42            672  org.apache.cassandra.io.sstable.format.big.BigTableScanner$EmptySSTableScanner
 814:            28            672  sun.nio.ch.SocketOptionRegistry$RegistryKey
 815:            12            672  sun.security.ssl.CipherSuite$BulkCipher
 816:            41            656  ch.qos.logback.core.joran.spi.ElementPath
 817:            27            648  java.io.FilePermissionCollection
 818:            27            648  org.apache.cassandra.cql3.selection.RawSelector
 819:            27            648  sun.reflect.generics.tree.FormalTypeParameter
 820:            16            640  io.netty.util.collection.IntObjectHashMap
 821:             8            640  java.util.concurrent.ThreadPoolExecutor
 822:            40            640  java.util.jar.Attributes
 823:             8            640  java.util.zip.ZipEntry
 824:            10            640  jdk.internal.org.objectweb.asm.Label
 825:            20            640  org.apache.cassandra.cql3.functions.BytesConversionFcts$2
 826:            20            640  org.apache.cassandra.db.compaction.OperationType
 827:             3            624  [Ljava.lang.invoke.LambdaForm;
 828:            13            624  java.nio.HeapCharBuffer
 829:            26            624  java.security.spec.ECFieldF2m
 830:            26            624  java.util.regex.Pattern$Ques
 831:            39            624  org.apache.cassandra.serializers.TupleSerializer
 832:            39            624  org.apache.cassandra.serializers.UserTypeSerializer
 833:            27            616  [Ljava.lang.reflect.Constructor;
 834:            19            608  java.io.FileInputStream
 835:            19            608  java.rmi.server.UID
 836:            19            608  java.util.Locale
 837:            19            608  org.apache.cassandra.schema.IndexMetadata
 838:            19            608  sun.management.DiagnosticCommandImpl$Wrapper
 839:            19            608  sun.util.locale.BaseLocale
 840:            15            600  java.lang.ClassNotFoundException
 841:            25            600  java.lang.invoke.Invokers
 842:            25            600  java.util.concurrent.locks.ReentrantReadWriteLock$Sync$HoldCounter
 843:            25            600  org.apache.cassandra.gms.ApplicationState
 844:            25            600  sun.reflect.NativeMethodAccessorImpl
 845:            25            600  sun.reflect.annotation.AnnotationInvocationHandler
 846:            18            576  ch.qos.logback.core.joran.event.BodyEvent
 847:            12            576  java.io.ObjectInputStream$FilterValues
 848:            24            576  jdk.internal.org.objectweb.asm.ByteVector
 849:            12            576  org.apache.cassandra.db.marshal.MapType
 850:             9            576  org.apache.cassandra.metrics.ConnectionMetrics
 851:            24            576  org.apache.cassandra.metrics.ThreadPoolMetricNameFactory
 852:            35            560  ch.qos.logback.core.joran.spi.ElementSelector
 853:            14            560  io.netty.util.Recycler$WeakOrderQueue
 854:            10            560  java.util.zip.ZipFile$ZipFileInflaterInputStream
 855:            10            560  java.util.zip.ZipFile$ZipFileInputStream
 856:            14            560  javax.management.openmbean.SimpleType
 857:            10            560  sun.invoke.util.Wrapper
 858:            23            552  [Ljava.net.InetAddress;
 859:             3            552  [Lorg.apache.cassandra.net.MessagingService$Verb;
 860:            23            552  ch.qos.logback.core.pattern.LiteralConverter
 861:            23            552  io.netty.util.internal.logging.Slf4JLogger
 862:            23            552  org.codehaus.jackson.map.SerializationConfig$Feature
 863:             2            544  [Ljava.lang.Character;
 864:            17            544  io.netty.util.concurrent.DefaultPromise
 865:            34            544  java.io.FilePermission$1
 866:            17            544  java.nio.channels.ClosedChannelException
 867:            17            544  java.util.concurrent.atomic.AtomicIntegerFieldUpdater$AtomicIntegerFieldUpdaterImpl
 868:            34            544  net.jpountz.xxhash.StreamingXXHash32$1
 869:            17            544  org.apache.cassandra.transport.Message$Type
 870:            17            544  sun.reflect.MethodAccessorGenerator$1
 871:            17            544  sun.security.x509.DistributionPoint
 872:            17            544  sun.security.x509.URIName
 873:            22            528  java.net.URLClassLoader$1
 874:            22            528  org.apache.cassandra.cql3.CQL3Type$Native
 875:            33            528  sun.reflect.DelegatingMethodAccessorImpl
 876:            13            520  com.google.common.base.Stopwatch
 877:            13            520  io.netty.channel.unix.Errors$NativeIoException
 878:            13            520  java.lang.invoke.MethodHandleImpl$IntrinsicMethodHandle
 879:            13            520  java.text.DigitList
 880:             4            512  com.google.common.cache.LocalCache
 881:            16            512  io.netty.channel.epoll.IovArray
 882:            16            512  java.lang.NoSuchFieldException
 883:            32            512  java.util.TreeSet
 884:            16            512  java.util.concurrent.Semaphore$NonfairSync
 885:            16            512  sun.security.ssl.CipherSuite$KeyExchange
 886:            21            504  java.util.Locale$LocaleKey
 887:             9            504  java.util.concurrent.ConcurrentHashMap$ValueIterator
 888:            21            504  org.apache.cassandra.cql3.functions.AggregateFcts$24
 889:             9            504  org.apache.cassandra.net.RateBasedBackPressureState
 890:            21            504  sun.security.x509.AVAKeyword
 891:            31            496  sun.security.x509.GeneralName
 892:            19            488  [Lsun.management.DiagnosticCommandArgumentInfo;
 893:            20            480  java.io.ObjectStreamClass$2
 894:            12            480  java.lang.UNIXProcess$ProcessPipeInputStream
 895:            20            480  org.apache.cassandra.cql3.functions.AggregateFcts$22
 896:            20            480  org.apache.cassandra.cql3.functions.AggregateFcts$23
 897:            20            480  org.apache.cassandra.cql3.functions.BytesConversionFcts$1
 898:            20            480  org.apache.cassandra.dht.LocalPartitioner
 899:            15            480  org.apache.cassandra.index.internal.composites.RegularColumnIndex
 900:             6            480  org.apache.cassandra.repair.RepairSession
 901:            20            480  org.yaml.snakeyaml.tokens.Token$ID
 902:             6            480  sun.net.www.protocol.jar.URLJarFile
 903:            30            480  sun.security.x509.GeneralNames
 904:             6            456  [Lsun.invoke.util.Wrapper;
 905:            19            456  ch.qos.logback.classic.spi.ClassPackagingData
 906:            19            456  java.lang.Class$1
 907:            19            456  java.util.regex.Pattern$Dollar
 908:             5            448  [[Ljava.lang.Object;
 909:             7            448  java.security.SecureRandom
 910:            28            448  java.util.LinkedHashSet
 911:             8            448  javax.management.openmbean.OpenMBeanParameterInfoSupport
 912:             8            448  jdk.internal.org.objectweb.asm.AnnotationWriter
 913:            14            448  jdk.internal.org.objectweb.asm.Type
 914:            14            448  sun.security.x509.CRLDistributionPointsExtension
 915:            11            440  java.lang.ClassLoader$NativeLibrary
 916:            11            440  sun.security.ec.ECPublicKeyImpl
 917:             9            432  com.sun.jna.Function
 918:            27            432  java.security.spec.ECFieldFp
 919:            18            432  java.text.DateFormat$Field
 920:            18            432  java.util.Collections$UnmodifiableCollection$1
 921:            18            432  org.apache.cassandra.exceptions.ExceptionCode
 922:            18            432  org.apache.cassandra.io.util.WrappedDataOutputStreamPlus
 923:            18            432  org.apache.cassandra.metrics.ThreadPoolMetrics$1
 924:            18            432  org.apache.cassandra.metrics.ThreadPoolMetrics$2
 925:            18            432  org.apache.cassandra.metrics.ThreadPoolMetrics$3
 926:            18            432  org.apache.cassandra.metrics.ThreadPoolMetrics$4
 927:             9            432  org.apache.cassandra.net.OutboundTcpConnectionPool
 928:            18            432  org.cliffc.high_scale_lib.NonBlockingHashMap$NBHMEntry
 929:            13            416  io.netty.util.Recycler$WeakOrderQueue$Link
 930:            13            416  java.lang.invoke.SimpleMethodHandle
 931:            13            416  java.security.AlgorithmParameters
 932:            13            416  java.util.Stack
 933:             4            416  sun.net.www.protocol.file.FileURLConnection
 934:            17            408  org.apache.cassandra.utils.IntegerInterval
 935:            17            408  org.codehaus.jackson.map.DeserializationConfig$Feature
 936:            10            400  java.io.ObjectStreamClass$FieldReflector
 937:            10            400  java.lang.invoke.DirectMethodHandle$Accessor
 938:            10            400  javax.crypto.CryptoPermission
 939:            10            400  sun.reflect.generics.repository.MethodRepository
 940:             7            392  java.util.Calendar$Builder
 941:             1            392  org.apache.cassandra.utils.memory.MemtableCleanerThread
 942:             8            384  [Lcom.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$PaddedAtomicLong;
 943:             1            384  ch.qos.logback.core.AsyncAppenderBase$Worker
 944:             4            384  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap
 945:            16            384  io.netty.channel.epoll.EpollEventArray
 946:            12            384  java.io.EOFException
 947:             1            384  java.lang.ref.Finalizer$FinalizerThread
 948:             8            384  java.net.SocketInputStream
 949:             8            384  java.net.SocketOutputStream
 950:            12            384  java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue
 951:            12            384  java.util.concurrent.atomic.AtomicLongFieldUpdater$CASUpdater
 952:             1            384  java.util.logging.LogManager$Cleaner
 953:            16            384  javax.management.StandardMBean
 954:            16            384  org.apache.cassandra.cql3.Attributes
 955:            16            384  org.apache.cassandra.cql3.Constants$Setter
 956:            16            384  org.apache.cassandra.cql3.Operations
 957:            12            384  org.apache.cassandra.cql3.SingleColumnRelation
 958:             8            384  org.apache.cassandra.hints.HintsStore
 959:            16            384  org.apache.cassandra.metrics.TableMetrics$35
 960:             1            384  org.apache.cassandra.net.MessagingService$SocketThread
 961:            16            384  org.apache.cassandra.schema.TableParams$Option
 962:             1            384  org.apache.cassandra.thrift.ThriftServer$ThriftServerThread
 963:            16            384  sun.misc.MetaIndex
 964:            16            384  sun.nio.ch.OptionKey
 965:             3            384  sun.nio.fs.UnixFileAttributes
 966:            12            384  sun.nio.fs.UnixPath
 967:             1            376  java.lang.ref.Reference$ReferenceHandler
 968:            16            368  [Ljava.security.cert.Certificate;
 969:            17            368  [Ljavax.management.MBeanNotificationInfo;
 970:            23            368  java.lang.ThreadLocal
 971:             3            360  [Lorg.apache.cassandra.gms.ApplicationState;
 972:            15            360  com.sun.jmx.remote.util.ClassLogger
 973:             9            360  com.sun.org.apache.xerces.internal.utils.XMLSecurityManager$Limit
 974:             9            360  java.io.BufferedInputStream
 975:            15            360  java.io.ObjectStreamClass$ClassDataSlot
 976:            15            360  java.net.InetAddress
 977:             9            360  org.apache.cassandra.db.marshal.SetType
 978:            15            360  org.apache.cassandra.utils.memory.SlabAllocator$Region
 979:            11            352  java.lang.ClassLoader$1
 980:            11            352  java.util.concurrent.SynchronousQueue
 981:            11            352  org.apache.cassandra.db.ConsistencyLevel
 982:             4            352  sun.rmi.transport.ConnectionInputStream
 983:             7            336  [Ljavax.management.openmbean.OpenType;
 984:             7            336  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$CompositeMapping
 985:            14            336  java.lang.invoke.LambdaFormEditor$Transform$Kind
 986:             6            336  java.nio.DirectLongBufferU
 987:            21            336  java.util.Collections$UnmodifiableCollection
 988:             7            336  java.util.Properties
 989:             6            336  org.apache.cassandra.concurrent.SEPExecutor
 990:             6            336  sun.management.MemoryPoolImpl
 991:             5            328  [Ljava.io.ObjectInputStream$HandleTable$HandleList;
 992:            16            328  [Ljava.lang.management.PlatformComponent;
 993:             4            320  [Lio.netty.buffer.PoolArena;
 994:            10            320  [Ljava.lang.invoke.LambdaForm$BasicType;
 995:            10            320  java.io.FileOutputStream
 996:             8            320  java.io.ObjectOutputStream$HandleTable
 997:            10            320  java.lang.OutOfMemoryError
 998:            10            320  java.lang.StringCoding$StringEncoder
 999:            10            320  java.lang.reflect.WeakCache$CacheValue
1000:            10            320  java.security.cert.PolicyQualifierInfo
1001:             8            320  org.apache.cassandra.db.marshal.ListType
1002:            20            320  org.apache.cassandra.dht.LocalPartitioner$1
1003:             8            320  org.apache.cassandra.gms.ArrayBackedBoundedStats
1004:             8            320  org.apache.cassandra.gms.ArrivalWindow
1005:            10            320  sun.reflect.generics.tree.MethodTypeSignature
1006:             8            320  sun.rmi.transport.tcp.TCPTransport$ConnectionHandler
1007:            10            320  sun.security.util.DisabledAlgorithmConstraints$KeySizeConstraint
1008:            13            312  [Ljava.net.InetSocketAddress;
1009:            13            312  com.sun.jna.Pointer
1010:            13            312  java.lang.management.ManagementPermission
1011:            19            304  sun.reflect.BootstrapConstructorAccessorImpl
1012:             1            296  com.github.benmanes.caffeine.SingleConsumerQueue
1013:             1            296  com.github.benmanes.caffeine.cache.BoundedBuffer$RingBuffer
1014:             4            288  [Lch.qos.logback.classic.spi.StackTraceElementProxy;
1015:            12            288  [Lcom.codahale.metrics.Striped64$Cell;
1016:            12            288  ch.qos.logback.core.joran.spi.HostClassAndPropertyDouble
1017:             1            288  com.github.benmanes.caffeine.cache.LocalCacheFactory$SSLiMW
1018:             6            288  com.google.common.collect.HashBiMap
1019:             9            288  com.google.common.collect.RegularImmutableSet
1020:             4            288  com.googlecode.concurrentlinkedhashmap.ConcurrentHashMapV8
1021:            12            288  com.sun.jmx.interceptor.DefaultMBeanServerInterceptor$ListenerWrapper
1022:             6            288  java.io.BufferedReader
1023:            12            288  java.lang.ProcessEnvironment$Variable
1024:             9            288  java.lang.reflect.Proxy$Key1
1025:             9            288  java.util.concurrent.CountDownLatch$Sync
1026:             9            288  java.util.concurrent.SynchronousQueue$TransferStack$SNode
1027:             9            288  java.util.logging.Level
1028:            18            288  java.util.regex.Pattern$Begin
1029:            12            288  org.apache.cassandra.concurrent.Stage
1030:            18            288  org.apache.cassandra.io.util.DataOutputStreamPlus$2
1031:             4            288  org.apache.cassandra.locator.TokenMetadata
1032:             9            288  org.apache.commons.lang3.JavaVersion
1033:             6            288  sun.nio.cs.StreamDecoder
1034:            18            288  sun.reflect.Label
1035:             4            288  sun.rmi.transport.ConnectionOutputStream
1036:             9            288  sun.security.jca.ProviderConfig
1037:             7            280  java.net.SocketTimeoutException
1038:             7            280  org.apache.cassandra.streaming.messages.StreamMessage$Type
1039:             7            280  org.apache.thrift.transport.TTransportException
1040:             7            280  sun.misc.FloatingDecimal$BinaryToASCIIBuffer
1041:             7            280  sun.rmi.transport.tcp.TCPEndpoint
1042:             1            272  [Lorg.codehaus.jackson.sym.Name;
1043:            17            272  com.sun.proxy.$Proxy3
1044:            17            272  net.jpountz.lz4.LZ4HCJNICompressor
1045:            17            272  org.apache.cassandra.cql3.Constants$Value
1046:            17            272  sun.reflect.ClassDefiner$1
1047:            17            272  sun.security.x509.DNSName
1048:             3            264  [[D
1049:            11            264  com.google.common.collect.ImmutableMapValues
1050:            11            264  java.net.StandardSocketOptions$StdSocketOption
1051:            11            264  java.rmi.server.ObjID
1052:            11            264  java.util.regex.Pattern$SliceI
1053:            11            264  org.apache.cassandra.io.sstable.Component
1054:            11            264  org.apache.cassandra.io.sstable.Component$Type
1055:            11            264  org.apache.cassandra.metrics.DroppedMessageMetrics
1056:            11            264  org.apache.cassandra.metrics.TableMetrics$36
1057:            11            264  org.apache.cassandra.net.MessagingService$DroppedMessages
1058:            11            264  sun.rmi.transport.ObjectEndpoint
1059:            11            264  sun.security.util.DisabledAlgorithmConstraints$DisabledConstraint
1060:            10            256  [Ljava.io.ObjectStreamClass$ClassDataSlot;
1061:             8            256  com.google.common.cache.LocalCache$StrongEntry
1062:            16            256  io.netty.channel.epoll.EpollEventLoop$1
1063:            16            256  io.netty.channel.epoll.EpollEventLoop$2
1064:            16            256  io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator
1065:            16            256  io.netty.util.concurrent.SingleThreadEventExecutor$2
1066:            16            256  io.netty.util.concurrent.SingleThreadEventExecutor$DefaultThreadProperties
1067:             8            256  java.util.Collections$UnmodifiableMap
1068:            16            256  java.util.concurrent.Semaphore
1069:             8            256  javax.management.MBeanNotificationInfo
1070:             8            256  org.apache.cassandra.cql3.functions.CastFcts$JavaCounterFunctionWrapper
1071:             8            256  org.apache.cassandra.db.ClusteringPrefix$Kind
1072:             8            256  org.apache.cassandra.repair.messages.RepairMessage$Type
1073:             8            256  sun.management.NotificationEmitterSupport$ListenerInfo
1074:             8            256  sun.misc.ProxyGenerator$PrimitiveTypeInfo
1075:             8            256  sun.misc.URLClassPath$JarLoader$2
1076:             8            256  sun.security.x509.CertificatePoliciesExtension
1077:             6            240  [Ljava.lang.invoke.BoundMethodHandle$SpeciesData;
1078:            10            240  com.sun.org.apache.xerces.internal.impl.XMLScanner$NameType
1079:            10            240  java.io.BufferedOutputStream
1080:             6            240  java.lang.UNIXProcess
1081:            10            240  java.nio.file.StandardOpenOption
1082:            10            240  java.security.CryptoPrimitive
1083:             3            240  java.util.concurrent.ScheduledThreadPoolExecutor
1084:            15            240  java.util.regex.Pattern$Dot
1085:            10            240  org.apache.cassandra.auth.Permission
1086:             5            240  org.apache.cassandra.config.ViewDefinition
1087:             5            240  org.apache.cassandra.db.lifecycle.LogRecord
1088:             5            240  org.apache.cassandra.db.view.View
1089:             6            240  org.apache.cassandra.metrics.SEPMetrics
1090:             6            240  org.apache.cassandra.schema.KeyspaceMetadata
1091:            10            240  org.codehaus.jackson.JsonParser$Feature
1092:            10            240  org.yaml.snakeyaml.events.Event$ID
1093:            15            240  org.yaml.snakeyaml.nodes.Tag
1094:             6            240  sun.management.MemoryPoolImpl$CollectionSensor
1095:             6            240  sun.management.MemoryPoolImpl$PoolSensor
1096:             5            240  sun.misc.URLClassPath
1097:            10            240  sun.reflect.generics.scope.MethodScope
1098:            15            240  sun.reflect.generics.tree.TypeVariableSignature
1099:            10            240  sun.rmi.runtime.Log$LoggerLog
1100:            10            240  sun.security.x509.Extension
1101:             5            240  sun.util.locale.provider.LocaleResources$ResourceReference
1102:             8            232  [Ljava.lang.Boolean;
1103:             2            224  [Lorg.codehaus.jackson.map.SerializationConfig$Feature;
1104:             7            224  [Lsun.nio.fs.NativeBuffer;
1105:             7            224  com.google.common.util.concurrent.MoreExecutors$DirectExecutorService
1106:             4            224  java.io.ObjectInputStream$BlockDataInputStream
1107:            14            224  java.rmi.server.Operation
1108:             7            224  java.util.concurrent.atomic.AtomicReferenceFieldUpdater$AtomicReferenceFieldUpdaterImpl
1109:             7            224  java.util.regex.Pattern$BnM
1110:             7            224  org.codehaus.jackson.JsonGenerator$Feature
1111:             4            224  org.codehaus.jackson.map.introspect.AnnotatedClass
1112:             4            224  org.codehaus.jackson.map.introspect.BasicBeanDescription
1113:             7            224  sun.nio.fs.NativeBuffer
1114:             7            224  sun.reflect.annotation.AnnotationType
1115:             4            224  sun.rmi.transport.Target
1116:             7            224  sun.security.x509.NetscapeCertTypeExtension
1117:             9            216  java.lang.ProcessEnvironment$Value
1118:             9            216  java.util.Collections$SynchronizedSet
1119:             9            216  java.util.logging.Level$KnownLevel
1120:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$1
1121:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$2
1122:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$3
1123:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$4
1124:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$5
1125:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$6
1126:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$7
1127:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$8
1128:             9            216  org.apache.cassandra.metrics.ConnectionMetrics$9
1129:             3            216  sun.security.provider.NativePRNG$RandomIO
1130:             9            216  sun.util.logging.PlatformLogger$Level
1131:             7            208  [Ljava.lang.invoke.LambdaForm$NamedFunction;
1132:             2            208  [Lorg.apache.cassandra.cql3.CQL3Type$Native;
1133:            13            208  com.google.common.util.concurrent.RateLimiter$SleepingStopwatch$1
1134:             2            208  java.lang.invoke.InnerClassLambdaMetafactory
1135:            13            208  sun.nio.ch.SocketAdaptor$2
1136:             2            200  [Ljava.text.DateFormat$Field;
1137:             5            200  io.netty.channel.group.DefaultChannelGroup
1138:             5            200  java.lang.invoke.BoundMethodHandle$SpeciesData
1139:             5            200  java.lang.invoke.DirectMethodHandle$Constructor
1140:             5            200  java.util.stream.StreamOpFlag
1141:             5            200  org.apache.cassandra.cql3.statements.SelectStatement$RawStatement
1142:             5            200  org.apache.cassandra.db.view.ViewBuilder
1143:             5            200  sun.rmi.transport.WeakRef
1144:             6            192  [Ljava.rmi.server.Operation;
1145:             3            192  [Lorg.apache.cassandra.db.ConsistencyLevel;
1146:             4            192  [[Lcom.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$PaddedAtomicReference;
1147:             3            192  ch.qos.logback.classic.PatternLayout
1148:             6            192  ch.qos.logback.core.util.CachingDateFormatter
1149:             8            192  com.google.common.cache.LocalCache$AccessQueue$1
1150:             4            192  com.google.common.collect.TreeMultimap
1151:             6            192  java.lang.ProcessBuilder
1152:             6            192  java.lang.invoke.LambdaForm$BasicType
1153:             8            192  java.lang.invoke.MethodHandleImpl$Intrinsic
1154:             8            192  java.math.RoundingMode
1155:            12            192  java.util.concurrent.ConcurrentSkipListMap$EntrySet
1156:             4            192  java.util.concurrent.locks.ReentrantReadWriteLock$FairSync
1157:             8            192  java.util.regex.Pattern$7
1158:             8            192  javax.crypto.CryptoPermissionCollection
1159:             4            192  javax.management.openmbean.TabularType
1160:             3            192  jdk.internal.org.objectweb.asm.FieldWriter
1161:             4            192  jdk.internal.org.objectweb.asm.Frame
1162:             8            192  jdk.net.SocketFlow$Status
1163:             6            192  org.apache.cassandra.db.Keyspace
1164:             4            192  org.apache.cassandra.db.RangeTombstoneList
1165:             8            192  org.apache.cassandra.db.WriteType
1166:             8            192  org.apache.cassandra.serializers.MapSerializer
1167:             8            192  org.apache.cassandra.serializers.SetSerializer
1168:             8            192  org.apache.cassandra.serializers.UTF8Serializer$UTF8Validator$State
1169:             8            192  org.apache.cassandra.service.StorageService$Mode
1170:             3            192  org.apache.cassandra.utils.MerkleTree$TreeDifference
1171:             6            192  org.apache.commons.lang3.text.StrBuilder
1172:             8            192  org.yaml.snakeyaml.scanner.Constant
1173:            12            192  sun.nio.ch.SocketAdaptor$1
1174:             6            192  sun.rmi.runtime.NewThreadAction
1175:             2            192  sun.security.provider.Sun
1176:             6            192  sun.security.util.MemoryCache
1177:             8            192  sun.security.x509.PolicyInformation
1178:             2            176  [Lorg.apache.cassandra.transport.Message$Type;
1179:             2            176  [Lorg.codehaus.jackson.map.DeserializationConfig$Feature;
1180:            10            176  [Lsun.reflect.generics.tree.TypeSignature;
1181:            11            176  java.text.NumberFormat$Field
1182:            11            176  java.util.LinkedHashMap$LinkedEntrySet
1183:            11            176  java.util.concurrent.SynchronousQueue$TransferStack
1184:             2            176  javax.management.remote.rmi.NoCallStackClassLoader
1185:             2            176  org.apache.cassandra.db.commitlog.MemoryMappedSegment
1186:            11            176  sun.security.ec.ECParameters
1187:             1            168  [[Ljava.math.BigInteger;
1188:             7            168  ch.qos.logback.classic.Level
1189:             3            168  ch.qos.logback.classic.encoder.PatternLayoutEncoder
1190:             7            168  com.google.common.collect.ImmutableEnumSet
1191:             7            168  com.sun.management.VMOption$Origin
1192:             7            168  com.sun.org.apache.xerces.internal.util.FeatureState
1193:             7            168  java.lang.invoke.MethodHandles$Lookup
1194:             7            168  java.net.NetPermission
1195:             7            168  java.util.BitSet
1196:             3            168  javax.management.openmbean.OpenMBeanOperationInfoSupport
1197:             7            168  javax.security.auth.AuthPermission
1198:             7            168  org.apache.cassandra.cql3.Constants$Type
1199:             7            168  org.apache.cassandra.db.Directories$FileAction
1200:             7            168  org.apache.cassandra.utils.concurrent.SimpleCondition
1201:             7            168  org.apache.cassandra.utils.progress.ProgressEventType
1202:             7            168  org.codehaus.jackson.annotate.JsonMethod
1203:             7            168  sun.nio.fs.NativeBuffer$Deallocator
1204:             7            168  sun.rmi.server.LoaderHandler$LoaderKey
1205:             3            168  sun.rmi.transport.tcp.TCPChannel
1206:             3            168  sun.rmi.transport.tcp.TCPConnection
1207:             3            168  sun.security.provider.SHA
1208:             7            168  sun.security.x509.NetscapeCertTypeExtension$MapEntry
1209:             4            160  [F
1210:             2            160  ch.qos.logback.core.rolling.RollingFileAppender
1211:            10            160  io.netty.util.internal.ConcurrentSet
1212:             4            160  java.io.ObjectOutputStream$BlockDataOutputStream
1213:             5            160  java.io.SerializablePermission
1214:             5            160  java.lang.StringCoding$StringDecoder
1215:             5            160  javax.management.StandardEmitterMBean
1216:             5            160  org.apache.cassandra.db.marshal.CompositeType
1217:             5            160  org.apache.cassandra.repair.RepairRunnable$1
1218:             5            160  org.apache.cassandra.transport.ProtocolVersion
1219:             5            160  org.apache.cassandra.transport.messages.ResultMessage$Kind
1220:             5            160  org.apache.cassandra.utils.CassandraVersion
1221:             4            160  org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotV
1222:             5            160  sun.rmi.transport.StreamRemoteCall
1223:             5            160  sun.security.ssl.CipherSuite$MacAlg
1224:            10            160  sun.security.x509.CertificatePolicyId
1225:             5            160  sun.util.locale.provider.LocaleProviderAdapter$Type
1226:             6            144  [Ljava.io.Closeable;
1227:             2            144  [Ljava.math.BigDecimal;
1228:             1            144  [Ljava.util.concurrent.ForkJoinTask$ExceptionNode;
1229:             1            144  [Lorg.codehaus.jackson.sym.CharsToNameCanonicalizer$Bucket;
1230:             3            144  ch.qos.logback.classic.pattern.DateConverter
1231:             3            144  ch.qos.logback.classic.pattern.ExtendedThrowableProxyConverter
1232:             3            144  ch.qos.logback.classic.spi.ThrowableProxy
1233:             6            144  com.google.common.collect.AbstractMultimap$EntrySet
1234:             6            144  com.sun.org.apache.xerces.internal.util.Status
1235:             6            144  java.io.InputStreamReader
1236:             3            144  java.lang.ThreadGroup
1237:             6            144  java.lang.UNIXProcess$$Lambda$15/1221027335
1238:             6            144  java.lang.UNIXProcess$ProcessPipeOutputStream
1239:             9            144  java.util.concurrent.CountDownLatch
1240:             6            144  java.util.regex.Pattern$CharProperty$1
1241:             2            144  org.antlr.runtime.RecognizerSharedState
1242:             6            144  org.apache.cassandra.cql3.CFName
1243:             6            144  org.apache.cassandra.cql3.WhereClause
1244:             6            144  org.apache.cassandra.db.filter.DataLimits$Kind
1245:             6            144  org.apache.cassandra.db.view.ViewManager
1246:             3            144  org.apache.cassandra.locator.SimpleStrategy
1247:             3            144  org.apache.cassandra.metrics.CacheMetrics
1248:             6            144  org.apache.cassandra.metrics.SEPMetrics$1
1249:             6            144  org.apache.cassandra.metrics.SEPMetrics$2
1250:             6            144  org.apache.cassandra.metrics.SEPMetrics$3
1251:             6            144  org.apache.cassandra.metrics.SEPMetrics$4
1252:             6            144  org.apache.cassandra.schema.KeyspaceParams
1253:             6            144  org.apache.cassandra.schema.ReplicationParams
1254:             6            144  org.apache.cassandra.service.ActiveRepairService$1
1255:             6            144  org.apache.cassandra.service.ActiveRepairService$2
1256:             6            144  org.apache.cassandra.streaming.StreamSession$State
1257:             6            144  org.codehaus.jackson.annotate.JsonAutoDetect$Visibility
1258:             6            144  org.github.jamm.MemoryMeter$Guess
1259:             6            144  sun.misc.PerfCounter
1260:             6            144  sun.security.ssl.ProtocolVersion
1261:             6            144  sun.security.util.DisabledAlgorithmConstraints$Constraint$Operator
1262:             4            128  [Lcom.google.common.cache.LocalCache$Segment;
1263:             4            128  [Lcom.google.common.collect.MapMakerInternalMap$EntryFactory;
1264:             2            128  [Lorg.apache.cassandra.concurrent.Stage;
1265:             2            128  [Lorg.apache.cassandra.io.sstable.Component$Type;
1266:             2            128  ch.qos.logback.core.rolling.FixedWindowRollingPolicy
1267:             4            128  ch.qos.logback.core.rolling.helper.FileNamePattern
1268:             8            128  com.google.common.cache.LocalCache$AccessQueue
1269:             8            128  com.google.common.cache.LocalCache$StrongValueReference
1270:             4            128  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$ArrayMapping
1271:             2            128  java.io.ExpiringCache$1
1272:             4            128  java.io.ObjectInputStream$HandleTable
1273:             4            128  java.io.ObjectInputStream$PeekInputStream
1274:             4            128  java.lang.UNIXProcess$Platform
1275:             2            128  java.lang.invoke.InvokerBytecodeGenerator
1276:             4            128  java.util.Random
1277:             4            128  java.util.concurrent.ExecutionException
1278:             4            128  net.jpountz.util.Native$OS
1279:             4            128  org.apache.cassandra.cql3.functions.CastFcts$CassandraFunctionWrapper
1280:             4            128  org.apache.cassandra.db.marshal.ReversedType
1281:             1            128  org.apache.cassandra.io.compress.CompressedSequentialWriter
1282:             1            128  org.apache.cassandra.io.sstable.format.big.BigTableWriter
1283:             4            128  org.apache.cassandra.io.util.SequentialWriterOption
1284:             4            128  org.apache.cassandra.locator.PendingRangeMaps
1285:             2            128  org.apache.cassandra.metrics.CASClientRequestMetrics
1286:             8            128  org.apache.cassandra.serializers.MapSerializer$$Lambda$24/2072313080
1287:             8            128  sun.net.www.ParseUtil
1288:             4            128  sun.rmi.transport.LiveRef
1289:             8            128  sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$292/1509453068
1290:             4            128  sun.security.ssl.CipherSuite$PRF
1291:             4            128  sun.security.x509.ExtendedKeyUsageExtension
1292:             3            120  [Lorg.codehaus.jackson.annotate.JsonMethod;
1293:             1            120  [[Ljava.lang.String;
1294:             5            120  ch.qos.logback.core.pattern.parser.TokenStream$TokenizerState
1295:             5            120  ch.qos.logback.core.subst.Token$Type
1296:             5            120  ch.qos.logback.core.util.AggregationType
1297:             3            120  com.google.common.collect.AbstractMapBasedMultimap$AsMap
1298:             5            120  com.sun.org.apache.xerces.internal.util.PropertyState
1299:             5            120  com.sun.org.apache.xerces.internal.utils.XMLSecurityManager$State
1300:             5            120  com.sun.org.apache.xerces.internal.utils.XMLSecurityPropertyManager$State
1301:             3            120  java.lang.invoke.BoundMethodHandle$Species_LL
1302:             3            120  java.lang.invoke.MethodHandleImpl$AsVarargsCollector
1303:             5            120  java.util.stream.StreamOpFlag$Type
1304:             3            120  org.apache.cassandra.cache.AutoSavingCache
1305:             5            120  org.apache.cassandra.config.Config$DiskFailurePolicy
1306:             5            120  org.apache.cassandra.cql3.VariableSpecifications
1307:             5            120  org.apache.cassandra.cql3.statements.IndexTarget$Type
1308:             5            120  org.apache.cassandra.db.lifecycle.LogRecord$Status
1309:             5            120  org.apache.cassandra.db.lifecycle.LogRecord$Type
1310:             3            120  org.apache.cassandra.db.lifecycle.LogTransaction$SSTableTidier
1311:             3            120  org.apache.cassandra.index.internal.composites.ClusteringColumnIndex
1312:             5            120  org.apache.cassandra.schema.CompactionParams$Option
1313:             1            120  org.apache.cassandra.service.StorageService
1314:             5            120  org.apache.cassandra.utils.NativeLibrary$OSType
1315:             5            120  org.yaml.snakeyaml.DumperOptions$ScalarStyle
1316:             5            120  sun.misc.FloatingDecimal$PreparedASCIIToBinaryBuffer
1317:             5            120  sun.security.jca.ServiceId
1318:             5            120  sun.security.util.DisabledAlgorithmConstraints
1319:             2            112  [Ljava.lang.invoke.MethodType;
1320:             2            112  [Ljava.security.CryptoPrimitive;
1321:             2            112  [Ljava.util.List;
1322:             2            112  [Lorg.apache.cassandra.auth.Permission;
1323:             2            112  [Lorg.apache.cassandra.db.PartitionPosition;
1324:             3            112  [Lorg.apache.cassandra.transport.ProtocolVersion;
1325:             7            112  com.google.common.util.concurrent.MoreExecutors$ListeningDecorator
1326:             2            112  com.sun.management.GcInfo
1327:             2            112  io.netty.buffer.PooledByteBufAllocator
1328:             7            112  java.util.concurrent.ConcurrentHashMap$EntrySetView
1329:             2            112  org.apache.cassandra.cql3.statements.DeleteStatement
1330:             2            112  org.apache.cassandra.db.compaction.LeveledCompactionStrategy
1331:             2            112  org.apache.cassandra.repair.LocalSyncTask
1332:             7            112  org.apache.cassandra.serializers.ListSerializer
1333:             2            112  org.apache.cassandra.utils.memory.MemtablePool$SubPool
1334:             7            112  sun.security.provider.NativePRNG
1335:             1            104  com.codahale.metrics.ThreadLocalRandom
1336:             1            104  io.netty.channel.epoll.EpollServerSocketChannel
1337:             1            104  org.apache.cassandra.db.ColumnIndex
1338:             1            104  sun.rmi.server.LoaderHandler$Loader
1339:             2             96  [Lcom.google.common.cache.LocalCache$EntryFactory;
1340:             6             96  [Ljava.io.ObjectStreamClass$MemberSignature;
1341:             2             96  [Ljava.util.concurrent.TimeUnit;
1342:             1             96  [Lorg.apache.cassandra.db.compaction.OperationType;
1343:             2             96  [Lorg.apache.cassandra.repair.messages.RepairMessage$Type;
1344:             1             96  [Lorg.yaml.snakeyaml.tokens.Token$ID;
1345:             1             96  [[J
1346:             1             96  ch.qos.logback.classic.LoggerContext
1347:             3             96  ch.qos.logback.classic.pattern.FileOfCallerConverter
1348:             3             96  ch.qos.logback.classic.pattern.LevelConverter
1349:             3             96  ch.qos.logback.classic.pattern.LineOfCallerConverter
1350:             3             96  ch.qos.logback.classic.pattern.LineSeparatorConverter
1351:             3             96  ch.qos.logback.classic.pattern.MessageConverter
1352:             3             96  ch.qos.logback.classic.pattern.ThreadConverter
1353:             3             96  ch.qos.logback.core.joran.action.AppenderRefAction
1354:             4             96  ch.qos.logback.core.pattern.parser.Token
1355:             2             96  ch.qos.logback.core.recovery.ResilientFileOutputStream
1356:             2             96  ch.qos.logback.core.rolling.helper.DateTokenConverter
1357:             4             96  ch.qos.logback.core.subst.Token
1358:             2             96  ch.qos.logback.core.util.InvocationGate
1359:             4             96  com.google.common.cache.LocalCache$WriteQueue$1
1360:             4             96  com.google.common.collect.AbstractIterator$State
1361:             4             96  com.google.common.collect.Iterators$12
1362:             4             96  com.googlecode.concurrentlinkedhashmap.LinkedDeque
1363:             3             96  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$EnumMapping
1364:             2             96  com.sun.jmx.mbeanserver.MBeanIntrospector$MBeanInfoMap
1365:             2             96  com.sun.jmx.mbeanserver.MBeanIntrospector$PerInterfaceMap
1366:             1             96  com.sun.net.ssl.internal.ssl.Provider
1367:             3             96  com.sun.org.apache.xerces.internal.utils.XMLSecurityManager$NameMap
1368:             3             96  io.netty.buffer.EmptyByteBuf
1369:             3             96  java.io.ByteArrayInputStream
1370:             6             96  java.io.FileInputStream$1
1371:             4             96  java.io.ObjectOutputStream$ReplaceTable
1372:             6             96  java.lang.UNIXProcess$$Lambda$16/1801942731
1373:             6             96  java.net.Socket$2
1374:             6             96  java.net.Socket$3
1375:             4             96  java.net.URLClassLoader$2
1376:             4             96  java.nio.file.FileVisitResult
1377:             4             96  java.text.Normalizer$Form
1378:             6             96  java.util.LinkedHashMap$LinkedKeySet
1379:             2             96  java.util.concurrent.ArrayBlockingQueue
1380:             3             96  java.util.concurrent.ConcurrentHashMap$ForwardingNode
1381:             3             96  java.util.concurrent.locks.ReentrantLock$FairSync
1382:             4             96  java.util.stream.StreamShape
1383:             4             96  javax.management.NotificationBroadcasterSupport$ListenerInfo
1384:             4             96  org.apache.cassandra.auth.IRoleManager$Option
1385:             4             96  org.apache.cassandra.config.CFMetaData$Flag
1386:             4             96  org.apache.cassandra.config.ColumnDefinition$Kind
1387:             4             96  org.apache.cassandra.config.Config$CommitFailurePolicy
1388:             4             96  org.apache.cassandra.config.Config$DiskAccessMode
1389:             4             96  org.apache.cassandra.config.Config$MemtableAllocationType
1390:             4             96  org.apache.cassandra.config.EncryptionOptions$ServerEncryptionOptions$InternodeEncryption
1391:             1             96  org.apache.cassandra.cql3.Cql_Parser
1392:             4             96  org.apache.cassandra.db.SystemKeyspace$BootstrapState
1393:             2             96  org.apache.cassandra.db.compaction.LeveledManifest
1394:             4             96  org.apache.cassandra.db.context.CounterContext$Relationship
1395:             4             96  org.apache.cassandra.db.lifecycle.LogTransaction$Obsoletion
1396:             4             96  org.apache.cassandra.dht.Bounds
1397:             4             96  org.apache.cassandra.hints.HintsDispatcher$Callback$Outcome
1398:             4             96  org.apache.cassandra.io.sstable.SSTableRewriter$InvalidateKeys
1399:             4             96  org.apache.cassandra.io.sstable.format.SSTableReader$OpenReason
1400:             4             96  org.apache.cassandra.io.sstable.format.SSTableReadsListener$SkippingReason
1401:             4             96  org.apache.cassandra.io.sstable.metadata.MetadataType
1402:             2             96  org.apache.cassandra.io.util.FileHandle$Builder
1403:             2             96  org.apache.cassandra.locator.LocalStrategy
1404:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$1
1405:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$10
1406:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$11
1407:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$12
1408:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$13
1409:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$14
1410:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$15
1411:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$16
1412:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$2
1413:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$3
1414:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$4
1415:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$5
1416:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$6
1417:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$7
1418:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$8
1419:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$9
1420:             6             96  org.apache.cassandra.metrics.KeyspaceMetrics$KeyspaceMetricNameFactory
1421:             6             96  org.apache.cassandra.schema.Functions
1422:             4             96  org.apache.cassandra.schema.SpeculativeRetryParam$Kind
1423:             6             96  org.apache.cassandra.schema.Tables
1424:             6             96  org.apache.cassandra.schema.Views
1425:             4             96  org.apache.cassandra.transport.Event$Type
1426:             1             96  org.apache.cassandra.triggers.CustomClassLoader
1427:             4             96  org.apache.cassandra.utils.AbstractIterator$State
1428:             4             96  org.apache.cassandra.utils.AsymmetricOrdering$Op
1429:             3             96  org.apache.cassandra.utils.NoSpamLogger
1430:             4             96  org.apache.cassandra.utils.SortedBiMultiValMap
1431:             4             96  org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional$State
1432:             2             96  org.codehaus.jackson.map.MapperConfig$Base
1433:             4             96  org.yaml.snakeyaml.nodes.NodeId
1434:             2             96  sun.management.GarbageCollectorImpl
1435:             2             96  sun.management.GcInfoBuilder
1436:             4             96  sun.misc.FormattedFloatingDecimal$Form
1437:             1             96  sun.misc.Launcher$AppClassLoader
1438:             4             96  sun.net.www.MessageHeader
1439:             1             96  sun.nio.ch.ServerSocketChannelImpl
1440:             2             96  sun.nio.cs.StreamEncoder
1441:             6             96  sun.rmi.transport.Transport$$Lambda$295/399097450
1442:             3             96  sun.rmi.transport.Transport$1
1443:             1             96  sun.security.ec.SunEC
1444:             1             96  sun.security.jca.ProviderList$1
1445:             1             96  sun.security.rsa.SunRsaSign
1446:             3             96  sun.security.ssl.ProtocolList
1447:             4             88  [Ljava.util.Map$Entry;
1448:             1             88  [Lnet.jpountz.lz4.LZ4Compressor;
1449:             1             88  [Lorg.apache.cassandra.exceptions.ExceptionCode;
1450:             1             88  [Lsun.security.util.ObjectIdentifier;
1451:             1             88  [[Ljava.lang.Byte;
1452:             1             88  java.util.jar.JarVerifier
1453:             1             88  org.apache.cassandra.concurrent.JMXConfigurableThreadPoolExecutor
1454:             1             88  org.apache.cassandra.db.compaction.CompactionManager$CacheCleanupExecutor
1455:             1             88  org.apache.cassandra.db.compaction.CompactionManager$CompactionExecutor
1456:             1             88  org.apache.cassandra.db.compaction.CompactionManager$ValidationExecutor
1457:             1             88  org.apache.cassandra.gms.Gossiper
1458:             1             88  org.apache.cassandra.io.sstable.IndexSummaryBuilder
1459:             1             88  org.apache.cassandra.io.sstable.metadata.MetadataCollector
1460:             1             88  sun.misc.Launcher$ExtClassLoader
1461:             1             80  [Lio.netty.util.concurrent.SingleThreadEventExecutor;
1462:             2             80  [Ljava.lang.management.MemoryUsage;
1463:             2             80  [Ljava.util.stream.StreamOpFlag$Type;
1464:             5             80  [Lorg.apache.cassandra.config.ColumnDefinition;
1465:             2             80  [Lorg.apache.cassandra.config.Config$DiskFailurePolicy;
1466:             1             80  [Lorg.apache.cassandra.cql3.Operator;
1467:             1             80  [Lorg.apache.cassandra.schema.TableParams$Option;
1468:             2             80  [Lorg.apache.cassandra.transport.messages.ResultMessage$Kind;
1469:             2             80  [Lorg.codehaus.jackson.annotate.JsonAutoDetect$Visibility;
1470:             1             80  [Lsun.security.ssl.CipherSuite$KeyExchange;
1471:             1             80  ch.qos.logback.classic.AsyncAppender
1472:             2             80  ch.qos.logback.classic.filter.ThresholdFilter
1473:             1             80  ch.qos.logback.classic.turbo.ReconfigureOnChangeFilter
1474:             2             80  ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy
1475:             2             80  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$TabularMapping
1476:             1             80  com.sun.jmx.remote.util.ClassLoaderWithRepository
1477:             5             80  com.sun.proxy.$Proxy1
1478:             5             80  io.netty.channel.group.DefaultChannelGroup$1
1479:             2             80  io.netty.channel.unix.Errors$NativeConnectException
1480:             2             80  io.netty.util.Signal
1481:             2             80  java.io.ExpiringCache
1482:             2             80  java.util.Locale$Category
1483:             5             80  java.util.logging.SimpleFormatter
1484:             2             80  java.util.regex.Pattern$Loop
1485:             5             80  javax.security.auth.x500.X500Principal
1486:             1             80  org.apache.cassandra.concurrent.StageManager$TracingExecutor
1487:             1             80  org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager$SMAwareReconfigureOnChangeFilter
1488:             1             80  org.apache.cassandra.db.compaction.writers.DefaultCompactionWriter
1489:             1             80  org.apache.cassandra.io.sstable.SSTableRewriter
1490:             5             80  org.apache.cassandra.repair.RepairSession$1
1491:             2             80  org.codehaus.jackson.sym.CharsToNameCanonicalizer
1492:             2             80  sun.management.MemoryManagerImpl
1493:             2             80  sun.reflect.UnsafeQualifiedStaticObjectFieldAccessorImpl
1494:             1             80  sun.reflect.misc.MethodUtil
1495:             2             80  sun.rmi.server.LoaderHandler$LoaderEntry
1496:             2             80  sun.rmi.server.UnicastServerRef
1497:             2             80  sun.rmi.server.UnicastServerRef2
1498:             2             80  sun.security.provider.DSAPublicKeyImpl
1499:             5             80  sun.security.util.DisabledAlgorithmConstraints$Constraints
1500:             2             80  sun.util.logging.resources.logging
1501:             1             72  [Ljava.lang.invoke.LambdaFormEditor$Transform$Kind;
1502:             4             72  [Ljava.nio.file.LinkOption;
1503:             3             72  [Ljava.util.concurrent.ConcurrentHashMap$CounterCell;
1504:             1             72  [Ljavax.management.openmbean.SimpleType;
1505:             2             72  [Lsun.security.jca.ProviderConfig;
1506:             1             72  ch.qos.logback.core.ConsoleAppender
1507:             3             72  ch.qos.logback.core.joran.action.NOPAction
1508:             3             72  ch.qos.logback.core.joran.action.PropertyAction
1509:             3             72  ch.qos.logback.core.pattern.FormatInfo
1510:             3             72  ch.qos.logback.core.rolling.helper.CompressionMode
1511:             3             72  ch.qos.logback.core.spi.FilterReply
1512:             3             72  ch.qos.logback.core.subst.Tokenizer$TokenizerState
1513:             3             72  com.github.benmanes.caffeine.cache.AccessOrderDeque
1514:             3             72  com.github.benmanes.caffeine.cache.Caffeine$Strength
1515:             3             72  com.google.common.base.CharMatcher$13
1516:             3             72  com.google.common.base.CharMatcher$RangesMatcher
1517:             3             72  com.google.common.collect.AbstractMapBasedMultimap$KeySet
1518:             1             72  io.netty.channel.DefaultChannelHandlerContext
1519:             1             72  io.netty.channel.DefaultChannelPipeline$HeadContext
1520:             1             72  io.netty.channel.DefaultChannelPipeline$TailContext
1521:             1             72  io.netty.channel.epoll.EpollServerSocketChannelConfig
1522:             3             72  java.io.ObjectStreamClass$ExceptionInfo
1523:             3             72  java.lang.UNIXProcess$LaunchMechanism
1524:             3             72  java.lang.annotation.RetentionPolicy
1525:             3             72  java.nio.file.FileTreeWalker$EventType
1526:             3             72  java.rmi.dgc.VMID
1527:             3             72  java.security.SecurityPermission
1528:             3             72  java.util.Base64$Encoder
1529:             1             72  java.util.ResourceBundle$RBClassLoader
1530:             3             72  java.util.concurrent.atomic.AtomicMarkableReference$Pair
1531:             3             72  java.util.jar.Manifest
1532:             1             72  java.util.logging.LogManager$RootLogger
1533:             1             72  java.util.logging.LogRecord
1534:             3             72  java.util.stream.Collector$Characteristics
1535:             3             72  java.util.stream.MatchOps$MatchKind
1536:             3             72  javax.crypto.CryptoPermissions
1537:             1             72  javax.management.remote.rmi.RMIConnectionImpl$CombinedClassLoader
1538:             1             72  javax.management.remote.rmi.RMIConnectionImpl$CombinedClassLoader$ClassLoaderWrapper
1539:             3             72  javax.security.auth.Subject$SecureSet
1540:             3             72  org.apache.cassandra.auth.DataResource$Level
1541:             3             72  org.apache.cassandra.config.ColumnDefinition$ClusteringOrder
1542:             3             72  org.apache.cassandra.config.Config$InternodeCompression
1543:             3             72  org.apache.cassandra.config.Config$UserFunctionTimeoutPolicy
1544:             3             72  org.apache.cassandra.config.ReadRepairDecision
1545:             3             72  org.apache.cassandra.cql3.AssignmentTestable$TestResult
1546:             1             72  org.apache.cassandra.cql3.Cql_Lexer
1547:             3             72  org.apache.cassandra.cql3.ResultSet$Flag
1548:             3             72  org.apache.cassandra.db.Conflicts$Resolution
1549:             3             72  org.apache.cassandra.db.Directories$FileType
1550:             3             72  org.apache.cassandra.db.commitlog.CommitLogSegment$CDCState
1551:             1             72  org.apache.cassandra.db.compaction.CompactionIterator
1552:             3             72  org.apache.cassandra.db.lifecycle.SSTableSet
1553:             3             72  org.apache.cassandra.db.marshal.AbstractType$ComparisonType
1554:             3             72  org.apache.cassandra.db.monitoring.MonitoringState
1555:             3             72  org.apache.cassandra.db.rows.SerializationHelper$Flag
1556:             1             72  org.apache.cassandra.io.util.SequentialWriter
1557:             3             72  org.apache.cassandra.locator.TokenMetadata$Topology
1558:             3             72  org.apache.cassandra.metrics.CacheMetrics$1
1559:             3             72  org.apache.cassandra.metrics.CacheMetrics$6
1560:             3             72  org.apache.cassandra.metrics.CacheMetrics$7
1561:             3             72  org.apache.cassandra.metrics.StreamingMetrics
1562:             3             72  org.apache.cassandra.repair.RepairParallelism
1563:             3             72  org.apache.cassandra.repair.SystemDistributedKeyspace$RepairState
1564:             3             72  org.apache.cassandra.repair.messages.ValidationComplete
1565:             3             72  org.apache.cassandra.schema.CompactionParams$TombstoneOption
1566:             3             72  org.apache.cassandra.schema.IndexMetadata$Kind
1567:             3             72  org.apache.cassandra.service.CacheService$CacheType
1568:             3             72  org.apache.cassandra.streaming.StreamEvent$Type
1569:             3             72  org.apache.cassandra.transport.Server$LatestEvent
1570:             3             72  org.apache.cassandra.utils.BiMultiValMap
1571:             3             72  org.apache.cassandra.utils.NoSpamLogger$Level
1572:             3             72  org.apache.cassandra.utils.memory.MemtableAllocator$LifeCycle
1573:             1             72  org.apache.commons.lang3.builder.ToStringStyle$DefaultToStringStyle
1574:             1             72  org.apache.commons.lang3.builder.ToStringStyle$MultiLineToStringStyle
1575:             1             72  org.apache.commons.lang3.builder.ToStringStyle$NoFieldNameToStringStyle
1576:             1             72  org.apache.commons.lang3.builder.ToStringStyle$ShortPrefixToStringStyle
1577:             1             72  org.apache.commons.lang3.builder.ToStringStyle$SimpleToStringStyle
1578:             1             72  org.apache.thrift.server.TThreadPoolServer$Args
1579:             3             72  org.yaml.snakeyaml.DumperOptions$FlowStyle
1580:             3             72  org.yaml.snakeyaml.DumperOptions$LineBreak
1581:             3             72  org.yaml.snakeyaml.introspector.BeanAccess
1582:             3             72  sun.misc.FloatingDecimal$ExceptionalBinaryToASCIIBuffer
1583:             3             72  sun.misc.ObjectInputFilter$Status
1584:             3             72  sun.misc.Signal
1585:             3             72  sun.nio.fs.UnixFileAttributeViews$Basic
1586:             3             72  sun.rmi.transport.SequenceEntry
1587:             3             72  sun.security.provider.NativePRNG$Variant
1588:             3             72  sun.security.ssl.CipherSuite$CipherType
1589:             3             72  sun.security.ssl.CipherSuiteList
1590:             1             72  sun.util.locale.provider.JRELocaleProviderAdapter
1591:             3             72  sun.util.resources.ParallelListResourceBundle$KeySet
1592:             2             64  [Ljava.lang.UNIXProcess$LaunchMechanism;
1593:             2             64  [Ljava.lang.annotation.RetentionPolicy;
1594:             3             64  [Ljava.security.CodeSigner;
1595:             3             64  [Ljava.security.cert.X509Certificate;
1596:             2             64  [Ljava.util.stream.Collector$Characteristics;
1597:             2             64  [Lorg.apache.cassandra.config.CFMetaData$Flag;
1598:             2             64  [Lorg.apache.cassandra.config.ColumnDefinition$ClusteringOrder;
1599:             2             64  [Lorg.apache.cassandra.config.ColumnDefinition$Kind;
1600:             2             64  [Lorg.apache.cassandra.config.Config$CommitFailurePolicy;
1601:             2             64  [Lorg.apache.cassandra.config.Config$InternodeCompression;
1602:             2             64  [Lorg.apache.cassandra.config.Config$MemtableAllocationType;
1603:             2             64  [Lorg.apache.cassandra.config.EncryptionOptions$ServerEncryptionOptions$InternodeEncryption;
1604:             2             64  [Lorg.apache.cassandra.cql3.ResultSet$Flag;
1605:             2             64  [Lorg.apache.cassandra.db.SystemKeyspace$BootstrapState;
1606:             2             64  [Lorg.apache.cassandra.io.sstable.metadata.MetadataType;
1607:             2             64  [Lorg.apache.cassandra.schema.CompactionParams$TombstoneOption;
1608:             2             64  [Lorg.apache.cassandra.schema.IndexMetadata$Kind;
1609:             2             64  [Lorg.apache.cassandra.transport.Event$Type;
1610:             2             64  [Lorg.yaml.snakeyaml.nodes.NodeId;
1611:             2             64  ch.qos.logback.classic.joran.action.LevelAction
1612:             2             64  ch.qos.logback.core.joran.spi.ConsoleTarget
1613:             2             64  ch.qos.logback.core.rolling.helper.Compressor
1614:             2             64  ch.qos.logback.core.rolling.helper.IntegerTokenConverter
1615:             4             64  ch.qos.logback.core.spi.FilterAttachableImpl
1616:             1             64  com.clearspring.analytics.stream.cardinality.HyperLogLogPlus
1617:             2             64  com.github.benmanes.caffeine.cache.References$WeakKeyReference
1618:             1             64  com.github.benmanes.caffeine.cache.stats.CacheStats
1619:             1             64  com.google.common.cache.CacheStats
1620:             4             64  com.google.common.cache.LocalCache$WriteQueue
1621:             2             64  com.google.common.util.concurrent.Striped$LargeLazyStriped
1622:             4             64  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$BoundedEntryWeigher
1623:             2             64  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$CollectionMapping
1624:             1             64  com.sun.jmx.remote.internal.ArrayNotificationBuffer
1625:             2             64  com.sun.management.GarbageCollectionNotificationInfo
1626:             2             64  com.sun.org.apache.xerces.internal.utils.XMLSecurityPropertyManager$Property
1627:             1             64  io.netty.channel.ChannelOutboundBuffer
1628:             4             64  io.netty.util.concurrent.FastThreadLocal
1629:             4             64  java.io.ObjectInputStream$ValidationList
1630:             2             64  java.io.PrintStream
1631:             2             64  java.lang.ClassValue$Entry
1632:             2             64  java.lang.NoSuchMethodError
1633:             2             64  java.lang.VirtualMachineError
1634:             2             64  java.lang.ref.ReferenceQueue$Null
1635:             2             64  java.net.Inet6Address
1636:             2             64  java.net.Inet6Address$Inet6AddressHolder
1637:             2             64  java.util.ResourceBundle$Control$1
1638:             2             64  java.util.concurrent.ConcurrentLinkedQueue$Itr
1639:             2             64  java.util.jar.Manifest$FastInputStream
1640:             1             64  javax.management.remote.rmi.RMIConnectionImpl
1641:             1             64  javax.management.remote.rmi.RMIConnectorServer
1642:             4             64  javax.security.auth.login.AppConfigurationEntry$LoginModuleControlFlag
1643:             4             64  org.apache.cassandra.concurrent.SEPWorker$Work
1644:             2             64  org.apache.cassandra.cql3.functions.TokenFct
1645:             2             64  org.apache.cassandra.db.commitlog.CommitLogDescriptor
1646:             2             64  org.apache.cassandra.db.lifecycle.LogFile
1647:             2             64  org.apache.cassandra.db.lifecycle.LogTransaction
1648:             2             64  org.apache.cassandra.io.sstable.format.SSTableFormat$Type
1649:             2             64  org.apache.cassandra.io.sstable.metadata.MetadataCollector$MinMaxIntTracker
1650:             2             64  org.apache.cassandra.io.util.SafeMemoryWriter
1651:             1             64  org.apache.cassandra.locator.DynamicEndpointSnitch
1652:             1             64  org.apache.cassandra.metrics.ViewWriteMetrics
1653:             1             64  org.apache.cassandra.net.MessagingService
1654:             2             64  org.apache.cassandra.service.ClientState
1655:             2             64  org.apache.cassandra.service.GCInspector$GCState
1656:             1             64  org.apache.cassandra.service.GCInspector$State
1657:             1             64  org.apache.cassandra.thrift.CustomTThreadPoolServer
1658:             1             64  org.apache.cassandra.utils.SigarLibrary
1659:             4             64  org.apache.cassandra.utils.SortedBiMultiValMap$1
1660:             4             64  org.codehaus.jackson.map.introspect.AnnotationMap
1661:             4             64  sun.net.www.protocol.jar.Handler
1662:             4             64  sun.rmi.server.MarshalOutputStream$1
1663:             2             64  sun.rmi.transport.DGCImpl$LeaseInfo
1664:             2             64  sun.rmi.transport.tcp.TCPTransport
1665:             2             64  sun.security.ssl.EphemeralKeyManager$EphemeralKeyPair
1666:             2             64  sun.security.ssl.SSLSessionContextImpl
1667:             2             64  sun.security.x509.PrivateKeyUsageExtension
1668:             2             64  sun.security.x509.SubjectAlternativeNameExtension
1669:             2             64  sun.util.locale.provider.LocaleServiceProviderPool
1670:             1             56  [Lcom.sun.org.apache.xerces.internal.impl.XMLScanner$NameType;
1671:             1             56  [Lcom.sun.org.apache.xerces.internal.utils.XMLSecurityManager$Limit;
1672:             1             56  [Ljava.lang.Runnable;
1673:             1             56  [Ljava.nio.file.StandardOpenOption;
1674:             2             56  [Ljdk.internal.org.objectweb.asm.Type;
1675:             1             56  [Lorg.apache.commons.lang3.JavaVersion;
1676:             1             56  [Lorg.codehaus.jackson.JsonParser$Feature;
1677:             1             56  [Lorg.yaml.snakeyaml.events.Event$ID;
1678:             1             56  [Lsun.util.logging.PlatformLogger$Level;
1679:             1             56  [[I
1680:             1             56  com.sun.jmx.remote.internal.ServerNotifForwarder
1681:             1             56  io.netty.util.concurrent.ScheduledFutureTask
1682:             1             56  java.lang.invoke.LambdaFormEditor$Transform
1683:             1             56  java.util.concurrent.ConcurrentHashMap$KeyIterator
1684:             1             56  java.util.logging.ConsoleHandler
1685:             1             56  java.util.logging.LogManager
1686:             1             56  javax.management.remote.JMXConnectionNotification
1687:             1             56  javax.management.remote.rmi.RMIJRMPServerImpl
1688:             1             56  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache
1689:             1             56  org.apache.cassandra.config.EncryptionOptions$ClientEncryptionOptions
1690:             1             56  org.apache.cassandra.config.EncryptionOptions$ServerEncryptionOptions
1691:             1             56  org.apache.cassandra.cql3.CqlLexer$DFA1
1692:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA14
1693:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA22
1694:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA24
1695:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA28
1696:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA30
1697:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA37
1698:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA44
1699:             1             56  org.apache.cassandra.cql3.Cql_Lexer$DFA9
1700:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA1
1701:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA15
1702:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA153
1703:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA154
1704:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA172
1705:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA174
1706:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA176
1707:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA178
1708:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA181
1709:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA189
1710:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA194
1711:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA195
1712:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA204
1713:             1             56  org.apache.cassandra.cql3.Cql_Parser$DFA44
1714:             1             56  org.apache.cassandra.db.commitlog.CommitLogSegmentManagerStandard
1715:             1             56  org.apache.cassandra.db.commitlog.PeriodicCommitLogService
1716:             1             56  org.apache.cassandra.db.compaction.CompactionController
1717:             1             56  org.apache.cassandra.db.lifecycle.LifecycleTransaction
1718:             1             56  org.apache.cassandra.io.compress.CompressionMetadata$Writer
1719:             1             56  org.apache.cassandra.metrics.CacheMissMetrics
1720:             1             56  org.codehaus.jackson.map.ObjectMapper
1721:             1             56  org.codehaus.jackson.map.ser.StdSerializerProvider
1722:             1             56  org.codehaus.jackson.sym.BytesToNameCanonicalizer
1723:             1             56  org.hyperic.sigar.SigarLoader
1724:             1             56  sun.rmi.runtime.Log$InternalStreamHandler
1725:             1             48  [Lcom.sun.beans.util.Cache$CacheEntry;
1726:             1             48  [Lcom.sun.management.VMOption$Origin;
1727:             1             48  [Ljava.beans.WeakIdentityMap$Entry;
1728:             3             48  [Ljava.lang.annotation.Annotation;
1729:             1             48  [Ljava.lang.invoke.MethodHandleImpl$Intrinsic;
1730:             1             48  [Ljava.math.RoundingMode;
1731:             2             48  [Ljava.nio.file.FileVisitOption;
1732:             1             48  [Ljdk.net.SocketFlow$Status;
1733:             2             48  [Lorg.apache.cassandra.config.Config$CommitLogSync;
1734:             1             48  [Lorg.apache.cassandra.cql3.Constants$Type;
1735:             1             48  [Lorg.apache.cassandra.db.ClusteringPrefix$Kind;
1736:             1             48  [Lorg.apache.cassandra.db.Directories$FileAction;
1737:             1             48  [Lorg.apache.cassandra.db.WriteType;
1738:             2             48  [Lorg.apache.cassandra.exceptions.RequestFailureReason;
1739:             2             48  [Lorg.apache.cassandra.net.RateBasedBackPressure$Flow;
1740:             1             48  [Lorg.apache.cassandra.serializers.UTF8Serializer$UTF8Validator$State;
1741:             1             48  [Lorg.apache.cassandra.service.StorageService$Mode;
1742:             1             48  [Lorg.apache.cassandra.streaming.messages.StreamMessage$Type;
1743:             1             48  [Lorg.apache.cassandra.utils.progress.ProgressEventType;
1744:             1             48  [Lorg.codehaus.jackson.JsonGenerator$Feature;
1745:             1             48  [Lsun.security.x509.NetscapeCertTypeExtension$MapEntry;
1746:             1             48  ch.qos.logback.classic.jmx.JMXConfigurator
1747:             3             48  ch.qos.logback.classic.pattern.EnsureExceptionHandling
1748:             3             48  ch.qos.logback.classic.spi.PackagingDataCalculator
1749:             1             48  ch.qos.logback.core.joran.action.DefinePropertyAction
1750:             1             48  ch.qos.logback.core.joran.spi.InterpretationContext
1751:             1             48  ch.qos.logback.core.joran.spi.Interpreter
1752:             2             48  ch.qos.logback.core.rolling.helper.RenameUtil
1753:             3             48  ch.qos.logback.core.spi.LogbackLock
1754:             2             48  ch.qos.logback.core.subst.Node$Type
1755:             2             48  ch.qos.logback.core.util.FileSize
1756:             2             48  com.clearspring.analytics.stream.cardinality.HyperLogLogPlus$Format
1757:             3             48  com.google.common.cache.LocalCache$LocalLoadingCache
1758:             1             48  com.google.common.collect.EmptyImmutableListMultimap
1759:             2             48  com.google.common.collect.HashBiMap$Inverse
1760:             1             48  com.google.common.collect.ImmutableListMultimap
1761:             2             48  com.google.common.collect.ImmutableMultimap$Values
1762:             2             48  com.sun.jmx.mbeanserver.ClassLoaderRepositorySupport$LoaderEntry
1763:             1             48  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory$Mappings
1764:             2             48  com.sun.jmx.mbeanserver.WeakIdentityHashMap
1765:             2             48  com.sun.jmx.remote.internal.ServerNotifForwarder$IdAndFilter
1766:             1             48  com.sun.jna.NativeLibrary
1767:             3             48  com.sun.org.apache.xerces.internal.impl.dv.dtd.ListDatatypeValidator
1768:             2             48  io.netty.buffer.PooledByteBufAllocator$PoolThreadLocalCache
1769:             2             48  io.netty.channel.VoidChannelPromise
1770:             2             48  io.netty.util.Recycler$2
1771:             2             48  io.netty.util.UniqueName
1772:             1             48  io.netty.util.concurrent.GlobalEventExecutor
1773:             3             48  io.netty.util.internal.TypeParameterMatcher$ReflectiveMatcher
1774:             2             48  java.io.ByteArrayOutputStream
1775:             2             48  java.io.File$PathStatus
1776:             3             48  java.io.FileOutputStream$1
1777:             2             48  java.io.OutputStreamWriter
1778:             2             48  java.io.SerialCallbackContext
1779:             3             48  java.lang.Boolean
1780:             3             48  java.lang.Float
1781:             3             48  java.lang.InheritableThreadLocal
1782:             1             48  java.lang.invoke.BoundMethodHandle$Species_L4
1783:             2             48  java.lang.invoke.ConstantCallSite
1784:             2             48  java.lang.invoke.InfoFromMemberName
1785:             2             48  java.lang.invoke.InnerClassLambdaMetafactory$ForwardingMethodGenerator
1786:             2             48  java.lang.management.MemoryType
1787:             2             48  java.lang.reflect.ReflectPermission
1788:             2             48  java.net.InetAddress$Cache
1789:             2             48  java.net.InetAddress$Cache$Type
1790:             2             48  java.net.InetAddress$CacheEntry
1791:             1             48  java.net.NetworkInterface
1792:             2             48  java.net.ServerSocket
1793:             2             48  java.net.SocketPermissionCollection
1794:             2             48  java.net.StandardProtocolFamily
1795:             3             48  java.nio.channels.FileChannel$MapMode
1796:             2             48  java.nio.charset.CoderResult
1797:             3             48  java.nio.charset.CodingErrorAction
1798:             2             48  java.rmi.dgc.Lease
1799:             2             48  java.security.AllPermissionCollection
1800:             3             48  java.text.AttributedCharacterIterator$Attribute
1801:             3             48  java.util.Base64$Decoder
1802:             2             48  java.util.PropertyPermissionCollection
1803:             3             48  java.util.TreeMap$EntrySet
1804:             2             48  java.util.concurrent.Executors$DefaultThreadFactory
1805:             3             48  java.util.concurrent.atomic.AtomicMarkableReference
1806:             2             48  java.util.logging.Logger$LoggerBundle
1807:             1             48  java.util.regex.Pattern$GroupCurly
1808:             2             48  java.util.regex.Pattern$Prolog
1809:             2             48  javax.management.MBeanServerInvocationHandler
1810:             1             48  javax.management.remote.rmi.RMIConnectionImpl$RMIServerCommunicatorAdmin
1811:             1             48  javax.security.auth.SubjectDomainCombiner$WeakKeyValueMap
1812:             1             48  org.antlr.runtime.ANTLRStringStream
1813:             2             48  org.apache.cassandra.cache.AutoSavingCache$2
1814:             2             48  org.apache.cassandra.config.Config$CommitLogSync
1815:             2             48  org.apache.cassandra.config.Config$DiskOptimizationStrategy
1816:             2             48  org.apache.cassandra.config.ParameterizedClass
1817:             2             48  org.apache.cassandra.cql3.Sets$Marker
1818:             2             48  org.apache.cassandra.cql3.Sets$Setter
1819:             2             48  org.apache.cassandra.cql3.functions.FunctionCall
1820:             2             48  org.apache.cassandra.cql3.statements.Bound
1821:             2             48  org.apache.cassandra.db.Directories$OnTxnErr
1822:             2             48  org.apache.cassandra.db.Memtable$LastCommitLogPosition
1823:             2             48  org.apache.cassandra.db.ReadCommand$Kind
1824:             2             48  org.apache.cassandra.db.aggregation.AggregationSpecification$Kind
1825:             1             48  org.apache.cassandra.db.commitlog.CommitLogArchiver
1826:             1             48  org.apache.cassandra.db.compaction.CompactionInfo
1827:             2             48  org.apache.cassandra.db.filter.ClusteringIndexFilter$Kind
1828:             2             48  org.apache.cassandra.db.lifecycle.LifecycleTransaction$State
1829:             2             48  org.apache.cassandra.db.lifecycle.LogReplica
1830:             2             48  org.apache.cassandra.db.rows.Unfiltered$Kind
1831:             2             48  org.apache.cassandra.exceptions.RequestFailureReason
1832:             1             48  org.apache.cassandra.gms.FailureDetector
1833:             2             48  org.apache.cassandra.hints.HintsDispatcher$Action
1834:             1             48  org.apache.cassandra.hints.HintsService
1835:             2             48  org.apache.cassandra.io.sstable.format.SSTableReadsListener$SelectionReason
1836:             1             48  org.apache.cassandra.io.sstable.format.big.BigTableWriter$IndexWriter
1837:             1             48  org.apache.cassandra.io.sstable.metadata.MetadataCollector$MinMaxLongTracker
1838:             2             48  org.apache.cassandra.io.util.NIODataInputStream
1839:             1             48  org.apache.cassandra.locator.NetworkTopologyStrategy
1840:             3             48  org.apache.cassandra.metrics.CacheMetrics$2
1841:             3             48  org.apache.cassandra.metrics.CacheMetrics$3
1842:             3             48  org.apache.cassandra.metrics.CacheMetrics$4
1843:             3             48  org.apache.cassandra.metrics.CacheMetrics$5
1844:             2             48  org.apache.cassandra.metrics.TableMetrics$Sampler
1845:             1             48  org.apache.cassandra.net.MessagingService$2
1846:             1             48  org.apache.cassandra.net.RateBasedBackPressure
1847:             2             48  org.apache.cassandra.net.RateBasedBackPressure$Flow
1848:             1             48  org.apache.cassandra.repair.messages.RepairOption
1849:             2             48  org.apache.cassandra.schema.CachingParams$Option
1850:             2             48  org.apache.cassandra.schema.KeyspaceParams$Option
1851:             1             48  org.apache.cassandra.service.ActiveRepairService$ParentRepairSession
1852:             2             48  org.apache.cassandra.streaming.ProgressInfo$Direction
1853:             2             48  org.apache.cassandra.transport.Event$StatusChange$Status
1854:             2             48  org.apache.cassandra.transport.Message$Direction
1855:             2             48  org.apache.cassandra.utils.ChecksumType$3
1856:             2             48  org.apache.cassandra.utils.Throwables$FileOpType
1857:             2             48  org.apache.cassandra.utils.btree.BTree$Dir
1858:             2             48  org.apache.cassandra.utils.concurrent.WaitQueue$RegisteredSignal
1859:             2             48  org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotE
1860:             2             48  org.cliffc.high_scale_lib.NonBlockingHashMap$SnapshotK
1861:             1             48  org.codehaus.jackson.JsonFactory
1862:             1             48  org.codehaus.jackson.map.DeserializationConfig
1863:             1             48  org.codehaus.jackson.map.SerializationConfig
1864:             2             48  org.codehaus.jackson.map.deser.std.CalendarDeserializer
1865:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$BooleanDeserializer
1866:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$ByteDeserializer
1867:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$CharacterDeserializer
1868:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$DoubleDeserializer
1869:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$FloatDeserializer
1870:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$IntegerDeserializer
1871:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$LongDeserializer
1872:             2             48  org.codehaus.jackson.map.deser.std.StdDeserializer$ShortDeserializer
1873:             2             48  org.codehaus.jackson.map.ser.StdSerializers$BooleanSerializer
1874:             1             48  org.hyperic.sigar.FileSystemMap
1875:             1             48  org.hyperic.sigar.Sigar
1876:             2             48  sun.management.ManagementFactoryHelper$1
1877:             2             48  sun.misc.NativeSignalHandler
1878:             2             48  sun.misc.URLClassPath$FileLoader
1879:             3             48  sun.nio.fs.UnixFileAttributes$UnixAsBasicFileAttributes
1880:             2             48  sun.rmi.server.UnicastServerRef$1
1881:             3             48  sun.rmi.server.WeakClassHashMap$ValueCell
1882:             2             48  sun.security.jca.ProviderList
1883:             2             48  sun.security.jca.ProviderList$3
1884:             2             48  sun.security.provider.DSAParameters
1885:             2             48  sun.security.ssl.SSLAlgorithmConstraints
1886:             3             48  sun.security.util.AlgorithmDecomposer
1887:             2             48  sun.security.util.DisabledAlgorithmConstraints$UsageConstraint
1888:             2             48  sun.security.util.DisabledAlgorithmConstraints$jdkCAConstraint
1889:             3             48  sun.security.x509.RFC822Name
1890:             3             48  sun.text.normalizer.NormalizerBase$QuickCheckResult
1891:             1             48  sun.text.resources.FormatData
1892:             1             48  sun.text.resources.en.FormatData_en
1893:             1             48  sun.text.resources.en.FormatData_en_US
1894:             1             40  [Lch.qos.logback.core.pattern.parser.TokenStream$TokenizerState;
1895:             1             40  [Lch.qos.logback.core.subst.Token$Type;
1896:             1             40  [Lch.qos.logback.core.util.AggregationType;
1897:             1             40  [Lcom.google.common.collect.SortedLists$KeyPresentBehavior;
1898:             2             40  [Lcom.sun.jmx.mbeanserver.ClassLoaderRepositorySupport$LoaderEntry;
1899:             1             40  [Lcom.sun.org.apache.xerces.internal.util.Status;
1900:             1             40  [Lcom.sun.org.apache.xerces.internal.utils.XMLSecurityManager$State;
1901:             1             40  [Lcom.sun.org.apache.xerces.internal.utils.XMLSecurityPropertyManager$State;
1902:             1             40  [Ljava.lang.management.MemoryPoolMXBean;
1903:             2             40  [Ljava.util.logging.Handler;
1904:             1             40  [Ljava.util.stream.StreamOpFlag;
1905:             1             40  [Lorg.apache.cassandra.cql3.statements.IndexTarget$Type;
1906:             1             40  [Lorg.apache.cassandra.db.filter.DataLimits$Kind;
1907:             1             40  [Lorg.apache.cassandra.db.lifecycle.LogRecord$Type;
1908:             1             40  [Lorg.apache.cassandra.schema.CompactionParams$Option;
1909:             1             40  [Lorg.apache.cassandra.streaming.StreamSession$State;
1910:             1             40  [Lorg.apache.cassandra.utils.NativeLibrary$OSType;
1911:             1             40  [Lorg.github.jamm.MemoryMeter$Guess;
1912:             1             40  [Lorg.yaml.snakeyaml.DumperOptions$ScalarStyle;
1913:             1             40  [Lsun.security.jca.ServiceId;
1914:             1             40  [Lsun.security.util.DisabledAlgorithmConstraints$Constraint$Operator;
1915:             1             40  [Lsun.util.locale.provider.LocaleProviderAdapter$Type;
1916:             1             40  [[Ljava.lang.invoke.LambdaForm$Name;
1917:             1             40  ch.qos.logback.core.BasicStatusManager
1918:             1             40  ch.qos.logback.core.joran.spi.ConfigurationWatchList
1919:             1             40  com.google.common.collect.AbstractMapBasedMultimap$2
1920:             1             40  com.google.common.collect.AbstractMapBasedMultimap$WrappedSet
1921:             1             40  com.google.common.collect.EmptyImmutableSortedMap
1922:             1             40  com.sun.beans.finder.MethodFinder$1
1923:             1             40  com.sun.jmx.interceptor.DefaultMBeanServerInterceptor
1924:             1             40  com.sun.jmx.mbeanserver.JmxMBeanServer
1925:             1             40  com.sun.jmx.mbeanserver.MBeanServerDelegateImpl
1926:             1             40  io.netty.channel.AbstractChannel$CloseFuture
1927:             1             40  io.netty.channel.DefaultChannelPipeline
1928:             1             40  io.netty.channel.epoll.AbstractEpollServerChannel$EpollServerSocketUnsafe
1929:             1             40  java.beans.WeakIdentityMap$Entry
1930:             1             40  java.lang.reflect.Proxy$Key2
1931:             1             40  java.rmi.NoSuchObjectException
1932:             1             40  java.util.ResourceBundle$1
1933:             1             40  javax.crypto.CryptoAllPermission
1934:             1             40  net.jpountz.lz4.LZ4Factory
1935:             1             40  org.antlr.runtime.CommonTokenStream
1936:             1             40  org.apache.cassandra.concurrent.SharedExecutorPool
1937:             1             40  org.apache.cassandra.config.TransparentDataEncryptionOptions
1938:             1             40  org.apache.cassandra.cql3.CqlLexer
1939:             1             40  org.apache.cassandra.db.commitlog.CommitLog
1940:             1             40  org.apache.cassandra.db.compaction.CompactionTask
1941:             1             40  org.apache.cassandra.exceptions.RepairException
1942:             1             40  org.apache.cassandra.io.sstable.format.big.BigTableWriter$TransactionalProxy
1943:             1             40  org.apache.cassandra.locator.GossipingPropertyFileSnitch
1944:             1             40  org.apache.cassandra.net.MessagingService$1
1945:             1             40  org.apache.cassandra.net.MessagingService$3
1946:             1             40  org.apache.cassandra.streaming.management.StreamEventJMXNotifier
1947:             1             40  org.apache.cassandra.transport.Server
1948:             1             40  org.apache.cassandra.utils.NoSpamLogger$NoSpamLogStatement
1949:             1             40  org.apache.cassandra.utils.memory.SlabPool
1950:             1             40  org.codehaus.jackson.map.util.StdDateFormat
1951:             1             40  sun.management.DiagnosticCommandImpl
1952:             1             40  sun.management.MappedMXBeanType$CompositeDataMXBeanType
1953:             1             40  sun.management.MappedMXBeanType$MapMXBeanType
1954:             1             40  sun.nio.cs.StandardCharsets$Aliases
1955:             1             40  sun.nio.cs.StandardCharsets$Cache
1956:             1             40  sun.nio.cs.StandardCharsets$Classes
1957:             1             40  sun.security.ssl.SSLContextImpl$DefaultSSLContext
1958:             1             32  [Lch.qos.logback.core.rolling.helper.CompressionMode;
1959:             1             32  [Lch.qos.logback.core.spi.FilterReply;
1960:             1             32  [Lch.qos.logback.core.subst.Tokenizer$TokenizerState;
1961:             1             32  [Lcom.github.benmanes.caffeine.cache.Caffeine$Strength;
1962:             1             32  [Lcom.google.common.base.Predicates$ObjectPredicate;
1963:             1             32  [Lcom.google.common.cache.LocalCache$Strength;
1964:             1             32  [Lcom.google.common.collect.AbstractIterator$State;
1965:             1             32  [Lcom.google.common.collect.MapMakerInternalMap$Strength;
1966:             1             32  [Lcom.google.common.collect.SortedLists$KeyAbsentBehavior;
1967:             1             32  [Lcom.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DrainStatus;
1968:             1             32  [Lcom.sun.beans.util.Cache$Kind;
1969:             1             32  [Lcom.sun.org.apache.xerces.internal.utils.XMLSecurityManager$NameMap;
1970:             2             32  [Ljava.lang.Enum;
1971:             1             32  [Ljava.lang.OutOfMemoryError;
1972:             1             32  [Ljava.lang.ThreadGroup;
1973:             1             32  [Ljava.lang.UNIXProcess$Platform;
1974:             1             32  [Ljava.lang.management.MemoryManagerMXBean;
1975:             1             32  [Ljava.nio.file.FileTreeWalker$EventType;
1976:             1             32  [Ljava.nio.file.FileVisitResult;
1977:             1             32  [Ljava.text.Normalizer$Form;
1978:             1             32  [Ljava.util.concurrent.atomic.AtomicReference;
1979:             1             32  [Ljava.util.stream.MatchOps$MatchKind;
1980:             1             32  [Ljava.util.stream.StreamShape;
1981:             1             32  [Lnet.jpountz.util.Native$OS;
1982:             1             32  [Lorg.apache.cassandra.auth.DataResource$Level;
1983:             1             32  [Lorg.apache.cassandra.auth.IRoleManager$Option;
1984:             1             32  [Lorg.apache.cassandra.config.Config$DiskAccessMode;
1985:             1             32  [Lorg.apache.cassandra.config.Config$UserFunctionTimeoutPolicy;
1986:             1             32  [Lorg.apache.cassandra.config.ReadRepairDecision;
1987:             1             32  [Lorg.apache.cassandra.cql3.AssignmentTestable$TestResult;
1988:             1             32  [Lorg.apache.cassandra.cql3.statements.StatementType;
1989:             1             32  [Lorg.apache.cassandra.db.Conflicts$Resolution;
1990:             1             32  [Lorg.apache.cassandra.db.Directories$FileType;
1991:             1             32  [Lorg.apache.cassandra.db.commitlog.CommitLogSegment$CDCState;
1992:             1             32  [Lorg.apache.cassandra.db.context.CounterContext$Relationship;
1993:             1             32  [Lorg.apache.cassandra.db.lifecycle.SSTableSet;
1994:             1             32  [Lorg.apache.cassandra.db.marshal.AbstractType$ComparisonType;
1995:             1             32  [Lorg.apache.cassandra.db.marshal.CollectionType$Kind;
1996:             1             32  [Lorg.apache.cassandra.db.monitoring.MonitoringState;
1997:             1             32  [Lorg.apache.cassandra.db.rows.SerializationHelper$Flag;
1998:             1             32  [Lorg.apache.cassandra.hints.HintsDispatcher$Callback$Outcome;
1999:             1             32  [Lorg.apache.cassandra.io.sstable.format.SSTableReader$OpenReason;
2000:             1             32  [Lorg.apache.cassandra.io.sstable.format.SSTableReadsListener$SkippingReason;
2001:             1             32  [Lorg.apache.cassandra.repair.RepairParallelism;
2002:             1             32  [Lorg.apache.cassandra.repair.SystemDistributedKeyspace$RepairState;
2003:             1             32  [Lorg.apache.cassandra.schema.SpeculativeRetryParam$Kind;
2004:             1             32  [Lorg.apache.cassandra.service.CacheService$CacheType;
2005:             1             32  [Lorg.apache.cassandra.streaming.StreamEvent$Type;
2006:             1             32  [Lorg.apache.cassandra.utils.AbstractIterator$State;
2007:             1             32  [Lorg.apache.cassandra.utils.AsymmetricOrdering$Op;
2008:             1             32  [Lorg.apache.cassandra.utils.NoSpamLogger$Level;
2009:             1             32  [Lorg.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional$State;
2010:             1             32  [Lorg.apache.cassandra.utils.memory.MemtableAllocator$LifeCycle;
2011:             2             32  [Lorg.codehaus.jackson.type.JavaType;
2012:             1             32  [Lorg.yaml.snakeyaml.DumperOptions$FlowStyle;
2013:             1             32  [Lorg.yaml.snakeyaml.DumperOptions$LineBreak;
2014:             1             32  [Lorg.yaml.snakeyaml.introspector.BeanAccess;
2015:             1             32  [Lsun.misc.FormattedFloatingDecimal$Form;
2016:             1             32  [Lsun.misc.ObjectInputFilter$Status;
2017:             1             32  [Lsun.security.provider.NativePRNG$Variant;
2018:             1             32  [Lsun.security.ssl.CipherSuite$CipherType;
2019:             1             32  [Lsun.security.ssl.CipherSuite$PRF;
2020:             1             32  [[Lcom.google.common.collect.MapMakerInternalMap$EntryFactory;
2021:             1             32  ch.qos.logback.classic.joran.JoranConfigurator
2022:             1             32  ch.qos.logback.classic.joran.action.ConfigurationAction
2023:             1             32  ch.qos.logback.classic.joran.action.EvaluatorAction
2024:             1             32  ch.qos.logback.classic.joran.action.LoggerAction
2025:             1             32  ch.qos.logback.classic.joran.action.LoggerContextListenerAction
2026:             1             32  ch.qos.logback.classic.joran.action.ReceiverAction
2027:             1             32  ch.qos.logback.classic.joran.action.RootLoggerAction
2028:             1             32  ch.qos.logback.classic.sift.SiftAction
2029:             1             32  ch.qos.logback.classic.spi.LoggerContextVO
2030:             1             32  ch.qos.logback.core.helpers.CyclicBuffer
2031:             1             32  ch.qos.logback.core.joran.action.AppenderAction
2032:             1             32  ch.qos.logback.core.joran.action.ConversionRuleAction
2033:             1             32  ch.qos.logback.core.joran.action.IncludeAction
2034:             1             32  ch.qos.logback.core.joran.action.NestedBasicPropertyIA
2035:             1             32  ch.qos.logback.core.joran.action.NestedComplexPropertyIA
2036:             1             32  ch.qos.logback.core.joran.action.NewRuleAction
2037:             1             32  ch.qos.logback.core.joran.action.ParamAction
2038:             1             32  ch.qos.logback.core.joran.action.ShutdownHookAction
2039:             1             32  ch.qos.logback.core.joran.action.StatusListenerAction
2040:             1             32  ch.qos.logback.core.joran.action.TimestampAction
2041:             1             32  ch.qos.logback.core.joran.conditional.ElseAction
2042:             1             32  ch.qos.logback.core.joran.conditional.IfAction
2043:             1             32  ch.qos.logback.core.joran.conditional.ThenAction
2044:             1             32  ch.qos.logback.core.joran.spi.SimpleRuleStore
2045:             2             32  ch.qos.logback.core.spi.AppenderAttachableImpl
2046:             1             32  com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalLoadingCache
2047:             1             32  com.github.benmanes.caffeine.cache.FrequencySketch
2048:             2             32  com.google.common.base.Joiner
2049:             2             32  com.google.common.base.Predicates$InPredicate
2050:             1             32  com.google.common.collect.AbstractMapBasedMultimap$NavigableKeySet
2051:             1             32  com.google.common.collect.EmptyImmutableBiMap
2052:             2             32  com.google.common.util.concurrent.Striped$2
2053:             2             32  com.sun.beans.WeakCache
2054:             1             32  com.sun.beans.finder.BeanInfoFinder
2055:             1             32  com.sun.jmx.mbeanserver.Repository
2056:             1             32  com.sun.jmx.remote.internal.ArrayQueue
2057:             1             32  com.sun.jmx.remote.security.JMXSubjectDomainCombiner
2058:             1             32  com.sun.org.apache.xerces.internal.impl.XMLEntityScanner$1
2059:             2             32  com.sun.org.apache.xerces.internal.impl.dv.dtd.ENTITYDatatypeValidator
2060:             2             32  com.sun.proxy.$Proxy5
2061:             1             32  io.netty.bootstrap.ServerBootstrap$ServerBootstrapAcceptor
2062:             1             32  io.netty.channel.epoll.EpollEventLoopGroup
2063:             2             32  io.netty.channel.group.ChannelMatchers$ClassMatcher
2064:             1             32  io.netty.util.concurrent.DefaultThreadFactory
2065:             2             32  io.netty.util.internal.logging.Slf4JLoggerFactory
2066:             1             32  java.beans.ThreadGroupContext
2067:             1             32  java.beans.ThreadGroupContext$1
2068:             2             32  java.io.ObjectStreamClass$1
2069:             2             32  java.io.ObjectStreamClass$3
2070:             2             32  java.io.ObjectStreamClass$4
2071:             2             32  java.io.ObjectStreamClass$5
2072:             1             32  java.io.UnixFileSystem
2073:             1             32  java.lang.ArithmeticException
2074:             1             32  java.lang.ArrayIndexOutOfBoundsException
2075:             1             32  java.lang.ClassCastException
2076:             1             32  java.lang.Exception
2077:             1             32  java.lang.NullPointerException
2078:             2             32  java.lang.Shutdown$Lock
2079:             1             32  java.lang.UnsupportedOperationException
2080:             1             32  java.lang.reflect.WeakCache
2081:             1             32  java.lang.reflect.WeakCache$CacheKey
2082:             2             32  java.nio.ByteOrder
2083:             1             32  java.nio.channels.NotYetConnectedException
2084:             1             32  java.text.DontCareFieldPosition
2085:             2             32  java.util.Hashtable$EntrySet
2086:             1             32  java.util.PriorityQueue
2087:             1             32  java.util.TreeMap$EntryIterator
2088:             1             32  java.util.TreeMap$KeyIterator
2089:             1             32  java.util.concurrent.CancellationException
2090:             1             32  java.util.concurrent.ConcurrentSkipListMap$KeyIterator
2091:             2             32  java.util.concurrent.ConcurrentSkipListMap$KeySet
2092:             1             32  java.util.concurrent.FutureTask
2093:             1             32  java.util.concurrent.ThreadLocalRandom
2094:             2             32  java.util.logging.ErrorManager
2095:             1             32  java.util.logging.LogManager$SystemLoggerContext
2096:             1             32  java.util.regex.Pattern$3
2097:             1             32  javax.crypto.spec.RC5ParameterSpec
2098:             2             32  javax.management.NotificationFilterSupport
2099:             1             32  javax.management.remote.JMXServiceURL
2100:             1             32  javax.security.auth.Subject
2101:             1             32  net.jpountz.xxhash.XXHashFactory
2102:             1             32  org.apache.cassandra.auth.CassandraRoleManager
2103:             1             32  org.apache.cassandra.batchlog.BatchlogManager
2104:             2             32  org.apache.cassandra.cache.ConcurrentLinkedHashCache
2105:             2             32  org.apache.cassandra.cache.ConcurrentLinkedHashCache$1
2106:             1             32  org.apache.cassandra.config.Schema
2107:             1             32  org.apache.cassandra.cql3.QueryOptions$SpecificOptions
2108:             1             32  org.apache.cassandra.cql3.functions.TimeFcts$4
2109:             1             32  org.apache.cassandra.cql3.functions.TimeFcts$5
2110:             2             32  org.apache.cassandra.db.RangeSliceVerbHandler
2111:             1             32  org.apache.cassandra.db.commitlog.SimpleCachedBufferPool
2112:             1             32  org.apache.cassandra.db.compaction.CompactionManager
2113:             2             32  org.apache.cassandra.db.lifecycle.LogReplicaSet
2114:             2             32  org.apache.cassandra.db.lifecycle.LogTransaction$TransactionTidier
2115:             1             32  org.apache.cassandra.db.marshal.AsciiType
2116:             1             32  org.apache.cassandra.db.marshal.PartitionerDefinedOrder
2117:             2             32  org.apache.cassandra.db.rows.CellPath$EmptyCellPath
2118:             2             32  org.apache.cassandra.dht.AbstractBounds$AbstractBoundsSerializer
2119:             1             32  org.apache.cassandra.hints.HintsBuffer
2120:             1             32  org.apache.cassandra.hints.HintsBufferPool
2121:             1             32  org.apache.cassandra.hints.HintsDispatchExecutor
2122:             1             32  org.apache.cassandra.hints.HintsDispatchTrigger
2123:             1             32  org.apache.cassandra.index.internal.composites.CollectionKeyIndex
2124:             1             32  org.apache.cassandra.io.compress.CompressedSequentialWriter$TransactionalProxy
2125:             1             32  org.apache.cassandra.io.compress.LZ4Compressor
2126:             1             32  org.apache.cassandra.io.sstable.IndexSummaryManager
2127:             1             32  org.apache.cassandra.metrics.CQLMetrics
2128:             2             32  org.apache.cassandra.metrics.ClientMetrics$$Lambda$278/1979648826
2129:             1             32  org.apache.cassandra.metrics.CommitLogMetrics
2130:             1             32  org.apache.cassandra.metrics.CompactionMetrics
2131:             2             32  org.apache.cassandra.metrics.TableMetrics$AllTableMetricNameFactory
2132:             2             32  org.apache.cassandra.net.ResponseVerbHandler
2133:             1             32  org.apache.cassandra.repair.RepairRunnable
2134:             2             32  org.apache.cassandra.schema.Types
2135:             1             32  org.apache.cassandra.security.EncryptionContext
2136:             1             32  org.apache.cassandra.service.ActiveRepairService
2137:             1             32  org.apache.cassandra.service.CassandraDaemon
2138:             1             32  org.apache.cassandra.service.NativeTransportService
2139:             1             32  org.apache.cassandra.thrift.TCustomServerSocket
2140:             1             32  org.apache.cassandra.thrift.ThriftServer
2141:             1             32  org.apache.cassandra.utils.ExpiringMap
2142:             2             32  org.apache.cassandra.utils.IntegerInterval$Set
2143:             1             32  org.apache.cassandra.utils.ResourceWatcher$WatchedResource
2144:             1             32  org.apache.cassandra.utils.StreamingHistogram$StreamingHistogramBuilder
2145:             1             32  org.apache.cassandra.utils.btree.BTree$1
2146:             1             32  org.apache.cassandra.utils.btree.TreeBuilder$1
2147:             1             32  org.apache.cassandra.utils.concurrent.WaitQueue$TimedSignal
2148:             1             32  org.apache.cassandra.utils.memory.BufferPool$GlobalPool
2149:             1             32  org.apache.thrift.protocol.TBinaryProtocol$Factory
2150:             2             32  org.cliffc.high_scale_lib.NonBlockingHashMap$2
2151:             2             32  org.cliffc.high_scale_lib.NonBlockingHashMap$3
2152:             1             32  org.codehaus.jackson.map.deser.BeanDeserializerFactory$ConfigImpl
2153:             1             32  org.codehaus.jackson.map.deser.StdDeserializerProvider
2154:             1             32  org.codehaus.jackson.map.introspect.VisibilityChecker$Std
2155:             2             32  org.codehaus.jackson.map.ser.StdSerializers$NumberSerializer
2156:             2             32  org.codehaus.jackson.map.ser.std.StdKeySerializer
2157:             1             32  org.codehaus.jackson.map.type.TypeFactory
2158:             2             32  org.codehaus.jackson.map.util.RootNameLookup
2159:             1             32  org.github.jamm.MemoryMeter
2160:             1             32  sun.instrument.InstrumentationImpl
2161:             1             32  sun.management.GcInfoCompositeData
2162:             1             32  sun.management.MappedMXBeanType$InProgress
2163:             1             32  sun.nio.ch.ServerSocketAdaptor
2164:             2             32  sun.nio.ch.SocketDispatcher
2165:             1             32  sun.nio.cs.StandardCharsets
2166:             1             32  sun.nio.fs.LinuxFileSystem
2167:             1             32  sun.reflect.UnsafeIntegerFieldAccessorImpl
2168:             1             32  sun.reflect.UnsafeQualifiedObjectFieldAccessorImpl
2169:             2             32  sun.rmi.server.UnicastRef
2170:             2             32  sun.rmi.server.UnicastRef2
2171:             2             32  sun.rmi.transport.DGCImpl$1
2172:             1             32  sun.rmi.transport.proxy.RMIMasterSocketFactory
2173:             1             32  sun.rmi.transport.tcp.TCPTransport$AcceptLoop
2174:             1             32  sun.security.provider.SecureRandom
2175:             2             32  sun.security.ssl.SSLAlgorithmDecomposer
2176:             1             32  sun.security.ssl.X509TrustManagerImpl
2177:             1             32  sun.security.validator.SimpleValidator
2178:             1             32  sun.security.x509.AuthorityInfoAccessExtension
2179:             1             32  sun.security.x509.IssuerAlternativeNameExtension
2180:             1             32  sun.security.x509.PolicyMappingsExtension
2181:             1             32  sun.util.locale.provider.LocaleResources
2182:             1             24  [Lch.qos.logback.core.joran.spi.ConsoleTarget;
2183:             1             24  [Lch.qos.logback.core.subst.Node$Type;
2184:             1             24  [Lcom.clearspring.analytics.stream.cardinality.HyperLogLogPlus$Format;
2185:             1             24  [Lcom.github.benmanes.caffeine.cache.Buffer;
2186:             1             24  [Lcom.github.benmanes.caffeine.cache.DisabledTicker;
2187:             1             24  [Lcom.github.benmanes.caffeine.cache.DisabledWriter;
2188:             1             24  [Lcom.github.benmanes.caffeine.cache.SingletonWeigher;
2189:             1             24  [Lcom.github.benmanes.caffeine.cache.stats.DisabledStatsCounter;
2190:             1             24  [Lcom.google.common.base.Functions$IdentityFunction;
2191:             1             24  [Lcom.google.common.cache.CacheBuilder$NullListener;
2192:             1             24  [Lcom.google.common.cache.CacheBuilder$OneWeigher;
2193:             1             24  [Lcom.google.common.collect.GenericMapMaker$NullListener;
2194:             1             24  [Lcom.google.common.collect.Maps$EntryFunction;
2195:             1             24  [Lcom.google.common.util.concurrent.MoreExecutors$DirectExecutor;
2196:             1             24  [Lcom.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DiscardingListener;
2197:             1             24  [Lcom.googlecode.concurrentlinkedhashmap.Weighers$SingletonEntryWeigher;
2198:             1             24  [Lcom.sun.org.apache.xerces.internal.utils.XMLSecurityPropertyManager$Property;
2199:             1             24  [Ljava.io.File$PathStatus;
2200:             1             24  [Ljava.lang.ClassValue$Entry;
2201:             1             24  [Ljava.lang.management.MemoryType;
2202:             1             24  [Ljava.net.InetAddress$Cache$Type;
2203:             1             24  [Ljava.net.InterfaceAddress;
2204:             1             24  [Ljava.net.StandardProtocolFamily;
2205:             1             24  [Ljava.rmi.server.ObjID;
2206:             1             24  [Ljava.util.Comparators$NaturalOrderComparator;
2207:             1             24  [Ljava.util.Locale$Category;
2208:             1             24  [Ljava.util.concurrent.ExecutorService;
2209:             1             24  [Ljava.util.concurrent.ThreadPoolExecutor;
2210:             1             24  [Ljavax.net.ssl.KeyManager;
2211:             1             24  [Ljavax.net.ssl.TrustManager;
2212:             1             24  [Lorg.apache.cassandra.concurrent.ExecutorLocal;
2213:             1             24  [Lorg.apache.cassandra.config.Config$DiskOptimizationStrategy;
2214:             1             24  [Lorg.apache.cassandra.config.Config$RequestSchedulerId;
2215:             1             24  [Lorg.apache.cassandra.cql3.QueryProcessor$InternalStateInstance;
2216:             1             24  [Lorg.apache.cassandra.cql3.Term;
2217:             1             24  [Lorg.apache.cassandra.cql3.statements.Bound;
2218:             1             24  [Lorg.apache.cassandra.db.Directories$OnTxnErr;
2219:             1             24  [Lorg.apache.cassandra.db.ReadCommand$Kind;
2220:             1             24  [Lorg.apache.cassandra.db.aggregation.AggregationSpecification$Kind;
2221:             1             24  [Lorg.apache.cassandra.db.filter.ClusteringIndexFilter$Kind;
2222:             1             24  [Lorg.apache.cassandra.db.rows.Unfiltered$Kind;
2223:             1             24  [Lorg.apache.cassandra.hints.HintsDispatcher$Action;
2224:             1             24  [Lorg.apache.cassandra.io.compress.BufferType;
2225:             1             24  [Lorg.apache.cassandra.io.sstable.format.SSTableFormat$Type;
2226:             1             24  [Lorg.apache.cassandra.io.sstable.format.SSTableReadsListener$SelectionReason;
2227:             1             24  [Lorg.apache.cassandra.metrics.TableMetrics$Sampler;
2228:             1             24  [Lorg.apache.cassandra.schema.CachingParams$Option;
2229:             1             24  [Lorg.apache.cassandra.schema.KeyspaceParams$Option;
2230:             1             24  [Lorg.apache.cassandra.streaming.ProgressInfo$Direction;
2231:             1             24  [Lorg.apache.cassandra.transport.Event$StatusChange$Status;
2232:             1             24  [Lorg.apache.cassandra.transport.Message$Direction;
2233:             1             24  [Lorg.apache.cassandra.utils.ChecksumType;
2234:             1             24  [Lorg.apache.cassandra.utils.Throwables$FileOpType;
2235:             1             24  [Lorg.apache.cassandra.utils.btree.BTree$Dir;
2236:             1             24  [Lsun.launcher.LauncherHelper;
2237:             1             24  [Lsun.security.ssl.EphemeralKeyManager$EphemeralKeyPair;
2238:             1             24  ch.qos.logback.classic.joran.action.ConsolePluginAction
2239:             1             24  ch.qos.logback.classic.joran.action.ContextNameAction
2240:             1             24  ch.qos.logback.classic.joran.action.InsertFromJNDIAction
2241:             1             24  ch.qos.logback.classic.joran.action.JMXConfiguratorAction
2242:             1             24  ch.qos.logback.classic.spi.TurboFilterList
2243:             1             24  ch.qos.logback.classic.util.ContextSelectorStaticBinder
2244:             1             24  ch.qos.logback.classic.util.LogbackMDCAdapter
2245:             1             24  ch.qos.logback.core.joran.action.ContextPropertyAction
2246:             1             24  ch.qos.logback.core.joran.spi.CAI_WithLocatorSupport
2247:             1             24  ch.qos.logback.core.joran.spi.EventPlayer
2248:             1             24  com.clearspring.analytics.stream.cardinality.RegisterSet
2249:             1             24  com.codahale.metrics.MetricRegistry
2250:             1             24  com.github.benmanes.caffeine.cache.BoundedBuffer
2251:             1             24  com.github.benmanes.caffeine.cache.BoundedLocalCache$PerformCleanupTask
2252:             1             24  com.github.benmanes.caffeine.cache.DisabledTicker
2253:             1             24  com.github.benmanes.caffeine.cache.DisabledWriter
2254:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$1
2255:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$10
2256:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$100
2257:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$101
2258:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$102
2259:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$103
2260:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$104
2261:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$105
2262:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$106
2263:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$107
2264:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$108
2265:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$109
2266:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$11
2267:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$110
2268:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$111
2269:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$112
2270:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$113
2271:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$114
2272:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$115
2273:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$116
2274:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$117
2275:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$118
2276:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$119
2277:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$12
2278:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$120
2279:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$121
2280:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$122
2281:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$123
2282:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$124
2283:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$125
2284:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$126
2285:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$127
2286:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$128
2287:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$129
2288:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$13
2289:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$130
2290:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$131
2291:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$132
2292:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$133
2293:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$134
2294:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$135
2295:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$136
2296:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$137
2297:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$138
2298:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$139
2299:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$14
2300:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$140
2301:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$141
2302:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$142
2303:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$143
2304:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$144
2305:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$15
2306:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$16
2307:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$17
2308:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$18
2309:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$19
2310:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$2
2311:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$20
2312:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$21
2313:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$22
2314:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$23
2315:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$24
2316:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$25
2317:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$26
2318:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$27
2319:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$28
2320:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$29
2321:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$3
2322:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$30
2323:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$31
2324:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$32
2325:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$33
2326:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$34
2327:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$35
2328:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$36
2329:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$37
2330:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$38
2331:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$39
2332:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$4
2333:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$40
2334:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$41
2335:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$42
2336:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$43
2337:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$44
2338:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$45
2339:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$46
2340:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$47
2341:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$48
2342:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$49
2343:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$5
2344:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$50
2345:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$51
2346:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$52
2347:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$53
2348:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$54
2349:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$55
2350:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$56
2351:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$57
2352:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$58
2353:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$59
2354:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$6
2355:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$60
2356:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$61
2357:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$62
2358:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$63
2359:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$64
2360:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$65
2361:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$66
2362:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$67
2363:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$68
2364:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$69
2365:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$7
2366:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$70
2367:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$71
2368:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$72
2369:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$73
2370:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$74
2371:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$75
2372:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$76
2373:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$77
2374:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$78
2375:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$79
2376:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$8
2377:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$80
2378:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$81
2379:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$82
2380:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$83
2381:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$84
2382:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$85
2383:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$86
2384:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$87
2385:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$88
2386:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$89
2387:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$9
2388:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$90
2389:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$91
2390:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$92
2391:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$93
2392:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$94
2393:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$95
2394:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$96
2395:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$97
2396:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$98
2397:             1             24  com.github.benmanes.caffeine.cache.NodeFactory$99
2398:             1             24  com.github.benmanes.caffeine.cache.RemovalCause$1
2399:             1             24  com.github.benmanes.caffeine.cache.RemovalCause$2
2400:             1             24  com.github.benmanes.caffeine.cache.RemovalCause$3
2401:             1             24  com.github.benmanes.caffeine.cache.RemovalCause$4
2402:             1             24  com.github.benmanes.caffeine.cache.RemovalCause$5
2403:             1             24  com.github.benmanes.caffeine.cache.SingletonWeigher
2404:             1             24  com.github.benmanes.caffeine.cache.stats.DisabledStatsCounter
2405:             1             24  com.google.common.base.CharMatcher$Or
2406:             1             24  com.google.common.base.Functions$IdentityFunction
2407:             1             24  com.google.common.base.Joiner$1
2408:             1             24  com.google.common.base.Joiner$MapJoiner
2409:             1             24  com.google.common.base.Predicates$ObjectPredicate$1
2410:             1             24  com.google.common.base.Predicates$ObjectPredicate$2
2411:             1             24  com.google.common.base.Predicates$ObjectPredicate$3
2412:             1             24  com.google.common.base.Predicates$ObjectPredicate$4
2413:             1             24  com.google.common.cache.CacheBuilder$NullListener
2414:             1             24  com.google.common.cache.CacheBuilder$OneWeigher
2415:             1             24  com.google.common.cache.LocalCache$EntryFactory$1
2416:             1             24  com.google.common.cache.LocalCache$EntryFactory$2
2417:             1             24  com.google.common.cache.LocalCache$EntryFactory$3
2418:             1             24  com.google.common.cache.LocalCache$EntryFactory$4
2419:             1             24  com.google.common.cache.LocalCache$EntryFactory$5
2420:             1             24  com.google.common.cache.LocalCache$EntryFactory$6
2421:             1             24  com.google.common.cache.LocalCache$EntryFactory$7
2422:             1             24  com.google.common.cache.LocalCache$EntryFactory$8
2423:             1             24  com.google.common.cache.LocalCache$Strength$1
2424:             1             24  com.google.common.cache.LocalCache$Strength$2
2425:             1             24  com.google.common.cache.LocalCache$Strength$3
2426:             1             24  com.google.common.collect.ByFunctionOrdering
2427:             1             24  com.google.common.collect.ConcurrentHashMultiset
2428:             1             24  com.google.common.collect.EmptyImmutableSortedSet
2429:             1             24  com.google.common.collect.GenericMapMaker$NullListener
2430:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$1
2431:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$2
2432:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$3
2433:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$4
2434:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$5
2435:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$6
2436:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$7
2437:             1             24  com.google.common.collect.MapMakerInternalMap$EntryFactory$8
2438:             1             24  com.google.common.collect.MapMakerInternalMap$Strength$1
2439:             1             24  com.google.common.collect.MapMakerInternalMap$Strength$2
2440:             1             24  com.google.common.collect.MapMakerInternalMap$Strength$3
2441:             1             24  com.google.common.collect.Maps$EntryFunction$1
2442:             1             24  com.google.common.collect.Maps$EntryFunction$2
2443:             1             24  com.google.common.collect.Sets$3
2444:             1             24  com.google.common.collect.SortedLists$KeyAbsentBehavior$1
2445:             1             24  com.google.common.collect.SortedLists$KeyAbsentBehavior$2
2446:             1             24  com.google.common.collect.SortedLists$KeyAbsentBehavior$3
2447:             1             24  com.google.common.collect.SortedLists$KeyPresentBehavior$1
2448:             1             24  com.google.common.collect.SortedLists$KeyPresentBehavior$2
2449:             1             24  com.google.common.collect.SortedLists$KeyPresentBehavior$3
2450:             1             24  com.google.common.collect.SortedLists$KeyPresentBehavior$4
2451:             1             24  com.google.common.collect.SortedLists$KeyPresentBehavior$5
2452:             1             24  com.google.common.util.concurrent.Futures$1$1
2453:             1             24  com.google.common.util.concurrent.Futures$ChainingListenableFuture$1
2454:             1             24  com.google.common.util.concurrent.MoreExecutors$DirectExecutor
2455:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentHashMapV8$KeySetView
2456:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DiscardingListener
2457:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DrainStatus$1
2458:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DrainStatus$2
2459:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DrainStatus$3
2460:             1             24  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$KeySet
2461:             1             24  com.googlecode.concurrentlinkedhashmap.Weighers$SingletonEntryWeigher
2462:             1             24  com.sun.beans.util.Cache$Kind$1
2463:             1             24  com.sun.beans.util.Cache$Kind$2
2464:             1             24  com.sun.beans.util.Cache$Kind$3
2465:             1             24  com.sun.jmx.mbeanserver.ClassLoaderRepositorySupport
2466:             1             24  com.sun.jmx.mbeanserver.MXBeanLookup
2467:             1             24  com.sun.jmx.remote.internal.ArrayNotificationBuffer$ShareBuffer
2468:             1             24  com.sun.jna.Structure$3
2469:             1             24  com.sun.org.apache.xerces.internal.impl.Constants$ArrayEnumeration
2470:             1             24  io.netty.buffer.UnpooledByteBufAllocator
2471:             1             24  io.netty.channel.AdaptiveRecvByteBufAllocator
2472:             1             24  io.netty.channel.SucceededChannelFuture
2473:             1             24  io.netty.channel.unix.Socket
2474:             1             24  io.netty.util.concurrent.FailedFuture
2475:             1             24  java.lang.ClassValue$Version
2476:             1             24  java.lang.Package$1
2477:             1             24  java.lang.ProcessEnvironment$StringEnvironment
2478:             1             24  java.lang.invoke.MethodHandleImpl$4
2479:             1             24  java.lang.invoke.MethodType$ConcurrentWeakInternSet
2480:             1             24  java.math.MutableBigInteger
2481:             1             24  java.net.Inet4AddressImpl
2482:             1             24  java.net.InterfaceAddress
2483:             1             24  java.nio.file.FileVisitOption
2484:             1             24  java.nio.file.LinkOption
2485:             1             24  java.security.CodeSigner
2486:             1             24  java.security.Policy$PolicyInfo
2487:             1             24  java.security.Policy$UnsupportedEmptyCollection
2488:             1             24  java.util.Collections$EmptyMap
2489:             1             24  java.util.Collections$UnmodifiableList
2490:             1             24  java.util.Comparators$NaturalOrderComparator
2491:             1             24  java.util.Currency
2492:             1             24  java.util.Locale$Cache
2493:             1             24  java.util.OptionalLong
2494:             1             24  java.util.ResourceBundle$Control$CandidateListCache
2495:             1             24  java.util.Vector$1
2496:             1             24  java.util.concurrent.Executors$DelegatedScheduledExecutorService
2497:             1             24  java.util.concurrent.TimeUnit$1
2498:             1             24  java.util.concurrent.TimeUnit$2
2499:             1             24  java.util.concurrent.TimeUnit$3
2500:             1             24  java.util.concurrent.TimeUnit$4
2501:             1             24  java.util.concurrent.TimeUnit$5
2502:             1             24  java.util.concurrent.TimeUnit$6
2503:             1             24  java.util.concurrent.TimeUnit$7
2504:             1             24  java.util.logging.LogManager$5
2505:             1             24  java.util.logging.LogManager$LoggerContext
2506:             1             24  java.util.logging.LoggingPermission
2507:             1             24  java.util.regex.Pattern$SingleI
2508:             1             24  javax.crypto.spec.RC2ParameterSpec
2509:             1             24  javax.management.NotificationBroadcasterSupport
2510:             1             24  javax.net.ssl.SSLContext
2511:             1             24  org.antlr.runtime.CharStreamState
2512:             1             24  org.apache.cassandra.auth.CassandraAuthorizer
2513:             1             24  org.apache.cassandra.auth.CassandraRoleManager$Role
2514:             1             24  org.apache.cassandra.auth.PasswordAuthenticator
2515:             1             24  org.apache.cassandra.cache.ChunkCache
2516:             1             24  org.apache.cassandra.config.Config$1
2517:             1             24  org.apache.cassandra.config.Config$RequestSchedulerId
2518:             1             24  org.apache.cassandra.config.RequestSchedulerOptions
2519:             1             24  org.apache.cassandra.cql3.Attributes$Raw
2520:             1             24  org.apache.cassandra.cql3.ColumnConditions
2521:             1             24  org.apache.cassandra.cql3.CqlParser
2522:             1             24  org.apache.cassandra.cql3.ErrorCollector
2523:             1             24  org.apache.cassandra.cql3.Lists$Marker
2524:             1             24  org.apache.cassandra.cql3.Maps$DiscarderByKey
2525:             1             24  org.apache.cassandra.cql3.Maps$Marker
2526:             1             24  org.apache.cassandra.cql3.Maps$Setter
2527:             1             24  org.apache.cassandra.cql3.Operator$1
2528:             1             24  org.apache.cassandra.cql3.Operator$10
2529:             1             24  org.apache.cassandra.cql3.Operator$11
2530:             1             24  org.apache.cassandra.cql3.Operator$12
2531:             1             24  org.apache.cassandra.cql3.Operator$13
2532:             1             24  org.apache.cassandra.cql3.Operator$14
2533:             1             24  org.apache.cassandra.cql3.Operator$15
2534:             1             24  org.apache.cassandra.cql3.Operator$2
2535:             1             24  org.apache.cassandra.cql3.Operator$3
2536:             1             24  org.apache.cassandra.cql3.Operator$4
2537:             1             24  org.apache.cassandra.cql3.Operator$5
2538:             1             24  org.apache.cassandra.cql3.Operator$6
2539:             1             24  org.apache.cassandra.cql3.Operator$7
2540:             1             24  org.apache.cassandra.cql3.Operator$8
2541:             1             24  org.apache.cassandra.cql3.Operator$9
2542:             1             24  org.apache.cassandra.cql3.QueryProcessor$InternalStateInstance
2543:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$1
2544:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$10
2545:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$11
2546:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$12
2547:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$13
2548:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$14
2549:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$15
2550:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$16
2551:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$17
2552:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$18
2553:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$19
2554:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$2
2555:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$20
2556:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$21
2557:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$3
2558:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$4
2559:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$5
2560:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$6
2561:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$7
2562:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$8
2563:             1             24  org.apache.cassandra.cql3.functions.AggregateFcts$9
2564:             1             24  org.apache.cassandra.cql3.functions.BytesConversionFcts$3
2565:             1             24  org.apache.cassandra.cql3.functions.BytesConversionFcts$4
2566:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$1
2567:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$10
2568:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$11
2569:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$12
2570:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$2
2571:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$3
2572:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$6
2573:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$7
2574:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$8
2575:             1             24  org.apache.cassandra.cql3.functions.TimeFcts$9
2576:             1             24  org.apache.cassandra.cql3.functions.UuidFcts$1
2577:             1             24  org.apache.cassandra.cql3.restrictions.SingleColumnRestriction$InRestrictionWithMarker
2578:             1             24  org.apache.cassandra.cql3.restrictions.TermSlice
2579:             1             24  org.apache.cassandra.cql3.restrictions.TokenRestriction$SliceRestriction
2580:             1             24  org.apache.cassandra.cql3.statements.StatementType$1
2581:             1             24  org.apache.cassandra.cql3.statements.StatementType$2
2582:             1             24  org.apache.cassandra.cql3.statements.StatementType$3
2583:             1             24  org.apache.cassandra.cql3.statements.StatementType$4
2584:             1             24  org.apache.cassandra.db.BlacklistedDirectories
2585:             1             24  org.apache.cassandra.db.Clustering$1
2586:             1             24  org.apache.cassandra.db.Clustering$2
2587:             1             24  org.apache.cassandra.db.Slice$1
2588:             1             24  org.apache.cassandra.db.commitlog.CommitLog$Configuration
2589:             1             24  org.apache.cassandra.db.compaction.CompactionLogger$CompactionLogSerializer
2590:             1             24  org.apache.cassandra.db.filter.DataLimits$1
2591:             1             24  org.apache.cassandra.db.filter.DataLimits$CQLLimits
2592:             1             24  org.apache.cassandra.db.marshal.AsciiType$1
2593:             1             24  org.apache.cassandra.db.marshal.BooleanType
2594:             1             24  org.apache.cassandra.db.marshal.ByteType
2595:             1             24  org.apache.cassandra.db.marshal.BytesType
2596:             1             24  org.apache.cassandra.db.marshal.CollectionType$Kind$1
2597:             1             24  org.apache.cassandra.db.marshal.CollectionType$Kind$2
2598:             1             24  org.apache.cassandra.db.marshal.CollectionType$Kind$3
2599:             1             24  org.apache.cassandra.db.marshal.CounterColumnType
2600:             1             24  org.apache.cassandra.db.marshal.DecimalType
2601:             1             24  org.apache.cassandra.db.marshal.DoubleType
2602:             1             24  org.apache.cassandra.db.marshal.DurationType
2603:             1             24  org.apache.cassandra.db.marshal.EmptyType
2604:             1             24  org.apache.cassandra.db.marshal.FloatType
2605:             1             24  org.apache.cassandra.db.marshal.InetAddressType
2606:             1             24  org.apache.cassandra.db.marshal.Int32Type
2607:             1             24  org.apache.cassandra.db.marshal.IntegerType
2608:             1             24  org.apache.cassandra.db.marshal.LongType
2609:             1             24  org.apache.cassandra.db.marshal.ShortType
2610:             1             24  org.apache.cassandra.db.marshal.SimpleDateType
2611:             1             24  org.apache.cassandra.db.marshal.TimeType
2612:             1             24  org.apache.cassandra.db.marshal.TimeUUIDType
2613:             1             24  org.apache.cassandra.db.marshal.TimestampType
2614:             1             24  org.apache.cassandra.db.marshal.TypeParser
2615:             1             24  org.apache.cassandra.db.marshal.UTF8Type
2616:             1             24  org.apache.cassandra.db.marshal.UUIDType
2617:             1             24  org.apache.cassandra.db.transform.Stack
2618:             1             24  org.apache.cassandra.dht.Murmur3Partitioner
2619:             1             24  org.apache.cassandra.dht.Murmur3Partitioner$1
2620:             1             24  org.apache.cassandra.hints.HintsCatalog
2621:             1             24  org.apache.cassandra.hints.HintsWriteExecutor
2622:             1             24  org.apache.cassandra.io.compress.BufferType$1
2623:             1             24  org.apache.cassandra.io.compress.BufferType$2
2624:             1             24  org.apache.cassandra.io.util.ChecksumWriter
2625:             1             24  org.apache.cassandra.io.util.SequentialWriter$TransactionalProxy
2626:             1             24  org.apache.cassandra.io.util.SsdDiskOptimizationStrategy
2627:             1             24  org.apache.cassandra.locator.ReconnectableSnitchHelper
2628:             1             24  org.apache.cassandra.metrics.AuthMetrics
2629:             1             24  org.apache.cassandra.metrics.BufferPoolMetrics
2630:             1             24  org.apache.cassandra.metrics.CassandraMetricsRegistry
2631:             1             24  org.apache.cassandra.metrics.CommitLogMetrics$1
2632:             1             24  org.apache.cassandra.metrics.CommitLogMetrics$2
2633:             1             24  org.apache.cassandra.metrics.CommitLogMetrics$3
2634:             1             24  org.apache.cassandra.metrics.CompactionMetrics$3
2635:             1             24  org.apache.cassandra.metrics.HintedHandoffMetrics
2636:             1             24  org.apache.cassandra.metrics.MessagingMetrics
2637:             1             24  org.apache.cassandra.net.MessagingService$Verb$1
2638:             1             24  org.apache.cassandra.net.MessagingService$Verb$10
2639:             1             24  org.apache.cassandra.net.MessagingService$Verb$11
2640:             1             24  org.apache.cassandra.net.MessagingService$Verb$12
2641:             1             24  org.apache.cassandra.net.MessagingService$Verb$13
2642:             1             24  org.apache.cassandra.net.MessagingService$Verb$2
2643:             1             24  org.apache.cassandra.net.MessagingService$Verb$3
2644:             1             24  org.apache.cassandra.net.MessagingService$Verb$4
2645:             1             24  org.apache.cassandra.net.MessagingService$Verb$5
2646:             1             24  org.apache.cassandra.net.MessagingService$Verb$6
2647:             1             24  org.apache.cassandra.net.MessagingService$Verb$7
2648:             1             24  org.apache.cassandra.net.MessagingService$Verb$8
2649:             1             24  org.apache.cassandra.net.MessagingService$Verb$9
2650:             1             24  org.apache.cassandra.service.CacheService
2651:             1             24  org.apache.cassandra.service.GCInspector
2652:             1             24  org.apache.cassandra.service.PendingRangeCalculatorService
2653:             1             24  org.apache.cassandra.service.QueryState
2654:             1             24  org.apache.cassandra.service.StartupChecks
2655:             1             24  org.apache.cassandra.service.StartupChecks$8
2656:             1             24  org.apache.cassandra.streaming.StreamManager
2657:             1             24  org.apache.cassandra.thrift.Cassandra$Processor
2658:             1             24  org.apache.cassandra.tracing.TracingImpl
2659:             1             24  org.apache.cassandra.transport.ConnectionLimitHandler
2660:             1             24  org.apache.cassandra.transport.Frame$Compressor
2661:             1             24  org.apache.cassandra.transport.Frame$Decompressor
2662:             1             24  org.apache.cassandra.transport.Frame$Encoder
2663:             1             24  org.apache.cassandra.transport.Message$Dispatcher
2664:             1             24  org.apache.cassandra.transport.Message$ProtocolDecoder
2665:             1             24  org.apache.cassandra.transport.Message$ProtocolEncoder
2666:             1             24  org.apache.cassandra.transport.RequestThreadPoolExecutor
2667:             1             24  org.apache.cassandra.transport.Server$ConnectionTracker
2668:             1             24  org.apache.cassandra.transport.Server$EventNotifier
2669:             1             24  org.apache.cassandra.transport.Server$Initializer
2670:             1             24  org.apache.cassandra.triggers.TriggerExecutor
2671:             1             24  org.apache.cassandra.utils.ChecksumType$1
2672:             1             24  org.apache.cassandra.utils.ChecksumType$2
2673:             1             24  org.apache.cassandra.utils.ConcurrentBiMap
2674:             1             24  org.apache.cassandra.utils.ExpiringMap$1
2675:             1             24  org.apache.cassandra.utils.HistogramBuilder
2676:             1             24  org.apache.cassandra.utils.IntervalTree
2677:             1             24  org.apache.cassandra.utils.JMXServerUtils$Registry
2678:             1             24  org.apache.cassandra.utils.concurrent.OpOrder$Barrier
2679:             1             24  org.apache.cassandra.utils.memory.BufferPool$Debug
2680:             1             24  org.apache.cassandra.utils.progress.jmx.JMXProgressSupport
2681:             1             24  org.apache.cassandra.utils.progress.jmx.LegacyJMXProgressSupport
2682:             1             24  org.codehaus.jackson.map.deser.BeanDeserializerFactory
2683:             1             24  org.codehaus.jackson.map.ser.BeanSerializerFactory
2684:             1             24  org.codehaus.jackson.map.ser.BeanSerializerFactory$ConfigImpl
2685:             1             24  org.codehaus.jackson.map.ser.impl.FailingSerializer
2686:             1             24  org.codehaus.jackson.map.ser.impl.SerializerCache
2687:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$BooleanArraySerializer
2688:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$DoubleArraySerializer
2689:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$FloatArraySerializer
2690:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$IntArraySerializer
2691:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$LongArraySerializer
2692:             1             24  org.codehaus.jackson.map.ser.std.StdArraySerializers$ShortArraySerializer
2693:             1             24  org.slf4j.helpers.FormattingTuple
2694:             1             24  org.slf4j.impl.StaticLoggerBinder
2695:             1             24  org.yaml.snakeyaml.external.com.google.gdata.util.common.base.PercentEscaper
2696:             1             24  sun.instrument.TransformerManager
2697:             1             24  sun.launcher.LauncherHelper
2698:             1             24  sun.management.CompilationImpl
2699:             1             24  sun.management.GarbageCollectionNotifInfoCompositeData
2700:             1             24  sun.management.MemoryImpl
2701:             1             24  sun.management.OperatingSystemImpl
2702:             1             24  sun.management.RuntimeImpl
2703:             1             24  sun.management.ThreadImpl
2704:             1             24  sun.management.VMManagementImpl
2705:             1             24  sun.misc.JarIndex
2706:             1             24  sun.net.ProgressMonitor
2707:             1             24  sun.net.sdp.SdpProvider
2708:             1             24  sun.net.www.protocol.http.Handler
2709:             1             24  sun.nio.cs.ISO_8859_1
2710:             1             24  sun.nio.cs.US_ASCII
2711:             1             24  sun.nio.cs.UTF_16
2712:             1             24  sun.nio.cs.UTF_16BE
2713:             1             24  sun.nio.cs.UTF_16LE
2714:             1             24  sun.nio.cs.UTF_8
2715:             1             24  sun.rmi.runtime.RuntimeUtil$1
2716:             1             24  sun.rmi.server.LoaderHandler$1
2717:             1             24  sun.rmi.transport.DGCImpl
2718:             1             24  sun.rmi.transport.Target$$Lambda$338/684260999
2719:             1             24  sun.security.provider.certpath.X509CertPath
2720:             1             24  sun.security.ssl.SunX509KeyManagerImpl
2721:             1             24  sun.security.validator.EndEntityChecker
2722:             1             24  sun.security.x509.AccessDescription
2723:             1             24  sun.security.x509.CertificatePolicyMap
2724:             1             24  sun.util.locale.BaseLocale$Cache
2725:             1             24  sun.util.locale.provider.CalendarDataProviderImpl
2726:             1             24  sun.util.locale.provider.CalendarProviderImpl
2727:             1             24  sun.util.locale.provider.CurrencyNameProviderImpl
2728:             1             24  sun.util.locale.provider.DateFormatSymbolsProviderImpl
2729:             1             24  sun.util.locale.provider.DecimalFormatSymbolsProviderImpl
2730:             1             24  sun.util.locale.provider.NumberFormatProviderImpl
2731:             1             24  sun.util.logging.PlatformLogger
2732:             1             24  sun.util.logging.PlatformLogger$JavaLoggerProxy
2733:             1             24  sun.util.resources.LocaleData$1
2734:             1             16  [Lch.qos.logback.classic.spi.ThrowableProxy;
2735:             1             16  [Ljava.beans.EventSetDescriptor;
2736:             1             16  [Ljava.lang.Double;
2737:             1             16  [Ljava.lang.Float;
2738:             1             16  [Ljava.lang.Throwable;
2739:             1             16  [Ljava.net.NetworkInterface;
2740:             1             16  [Ljava.net.URL;
2741:             1             16  [Ljava.nio.file.attribute.FileAttribute;
2742:             1             16  [Ljava.security.Provider;
2743:             1             16  [Ljava.text.FieldPosition;
2744:             1             16  [Ljavax.security.cert.X509Certificate;
2745:             1             16  [Lnet.jpountz.lz4.LZ4JNI;
2746:             1             16  [Lnet.jpountz.lz4.LZ4Utils;
2747:             1             16  [Lnet.jpountz.util.ByteBufferUtils;
2748:             1             16  [Lnet.jpountz.util.Native;
2749:             1             16  [Lnet.jpountz.util.SafeUtils;
2750:             1             16  [Lnet.jpountz.xxhash.XXHashJNI;
2751:             1             16  [Lorg.apache.cassandra.db.rows.Cell;
2752:             1             16  [Lorg.apache.cassandra.db.transform.Stack$MoreContentsHolder;
2753:             1             16  [Lorg.codehaus.jackson.map.AbstractTypeResolver;
2754:             1             16  [Lorg.codehaus.jackson.map.Deserializers;
2755:             1             16  [Lorg.codehaus.jackson.map.KeyDeserializers;
2756:             1             16  [Lorg.codehaus.jackson.map.Serializers;
2757:             1             16  [Lorg.codehaus.jackson.map.deser.BeanDeserializerModifier;
2758:             1             16  [Lorg.codehaus.jackson.map.deser.ValueInstantiators;
2759:             1             16  [Lorg.codehaus.jackson.map.introspect.AnnotationMap;
2760:             1             16  [Lorg.codehaus.jackson.map.ser.BeanSerializerModifier;
2761:             1             16  [Lsun.instrument.TransformerManager$TransformerInfo;
2762:             1             16  ch.qos.logback.classic.selector.DefaultContextSelector
2763:             1             16  ch.qos.logback.core.joran.spi.ConsoleTarget$1
2764:             1             16  ch.qos.logback.core.joran.spi.ConsoleTarget$2
2765:             1             16  ch.qos.logback.core.joran.spi.DefaultNestedComponentRegistry
2766:             1             16  ch.qos.logback.core.joran.util.ConfigurationWatchListUtil
2767:             1             16  com.codahale.metrics.Clock$UserTimeClock
2768:             1             16  com.codahale.metrics.MetricRegistry$MetricBuilder$1
2769:             1             16  com.codahale.metrics.MetricRegistry$MetricBuilder$2
2770:             1             16  com.codahale.metrics.MetricRegistry$MetricBuilder$3
2771:             1             16  com.codahale.metrics.MetricRegistry$MetricBuilder$4
2772:             1             16  com.codahale.metrics.Striped64$ThreadHashCode
2773:             1             16  com.codahale.metrics.ThreadLocalRandom$1
2774:             1             16  com.github.benmanes.caffeine.SingleConsumerQueue$$Lambda$80/692511295
2775:             1             16  com.github.benmanes.caffeine.cache.BoundedLocalCache$$Lambda$79/608770405
2776:             1             16  com.github.benmanes.caffeine.cache.BoundedLocalCache$BoundedLocalLoadingCache$$Lambda$81/1858886571
2777:             1             16  com.github.benmanes.caffeine.cache.BoundedLocalCache$EntrySetView
2778:             1             16  com.github.benmanes.caffeine.cache.BoundedLocalCache$KeySetView
2779:             1             16  com.github.benmanes.caffeine.cache.BoundedWeigher
2780:             1             16  com.github.benmanes.caffeine.cache.Caffeine$$Lambda$77/2064869182
2781:             1             16  com.google.common.base.Absent
2782:             1             16  com.google.common.base.CharMatcher$1
2783:             1             16  com.google.common.base.CharMatcher$15
2784:             1             16  com.google.common.base.CharMatcher$2
2785:             1             16  com.google.common.base.CharMatcher$3
2786:             1             16  com.google.common.base.CharMatcher$4
2787:             1             16  com.google.common.base.CharMatcher$5
2788:             1             16  com.google.common.base.CharMatcher$6
2789:             1             16  com.google.common.base.CharMatcher$7
2790:             1             16  com.google.common.base.CharMatcher$8
2791:             1             16  com.google.common.base.Equivalence$Equals
2792:             1             16  com.google.common.base.Equivalence$Identity
2793:             1             16  com.google.common.base.Predicates$NotPredicate
2794:             1             16  com.google.common.base.Predicates$OrPredicate
2795:             1             16  com.google.common.base.Suppliers$SupplierOfInstance
2796:             1             16  com.google.common.base.Ticker$1
2797:             1             16  com.google.common.cache.CacheBuilder$1
2798:             1             16  com.google.common.cache.CacheBuilder$2
2799:             1             16  com.google.common.cache.CacheBuilder$3
2800:             1             16  com.google.common.cache.LocalCache$1
2801:             1             16  com.google.common.cache.LocalCache$2
2802:             1             16  com.google.common.cache.LocalCache$LocalManualCache
2803:             1             16  com.google.common.collect.ComparatorOrdering
2804:             1             16  com.google.common.collect.EmptyImmutableSet
2805:             1             16  com.google.common.collect.Iterators$1
2806:             1             16  com.google.common.collect.Iterators$2
2807:             1             16  com.google.common.collect.MapMakerInternalMap$1
2808:             1             16  com.google.common.collect.MapMakerInternalMap$2
2809:             1             16  com.google.common.collect.Multisets$5
2810:             1             16  com.google.common.collect.NaturalOrdering
2811:             1             16  com.google.common.collect.ReverseOrdering
2812:             1             16  com.google.common.io.ByteStreams$1
2813:             1             16  com.google.common.util.concurrent.Futures$4
2814:             1             16  com.google.common.util.concurrent.Futures$7
2815:             1             16  com.google.common.util.concurrent.Runnables$1
2816:             1             16  com.google.common.util.concurrent.Striped$5
2817:             1             16  com.googlecode.concurrentlinkedhashmap.ConcurrentLinkedHashMap$DiscardingQueue
2818:             1             16  com.sun.jmx.interceptor.DefaultMBeanServerInterceptor$ResourceContext$1
2819:             1             16  com.sun.jmx.mbeanserver.DefaultMXBeanMappingFactory
2820:             1             16  com.sun.jmx.mbeanserver.DescriptorCache
2821:             1             16  com.sun.jmx.mbeanserver.MBeanAnalyzer$MethodOrder
2822:             1             16  com.sun.jmx.mbeanserver.MBeanInstantiator
2823:             1             16  com.sun.jmx.mbeanserver.MXBeanIntrospector
2824:             1             16  com.sun.jmx.mbeanserver.SecureClassLoaderRepository
2825:             1             16  com.sun.jmx.mbeanserver.StandardMBeanIntrospector
2826:             1             16  com.sun.jmx.remote.internal.ArrayNotificationBuffer$5
2827:             1             16  com.sun.jmx.remote.internal.ArrayNotificationBuffer$BroadcasterQuery
2828:             1             16  com.sun.jmx.remote.internal.ArrayNotificationBuffer$BufferListener
2829:             1             16  com.sun.jmx.remote.internal.ServerCommunicatorAdmin$Timeout
2830:             1             16  com.sun.jmx.remote.internal.ServerNotifForwarder$NotifForwarderBufferFilter
2831:             1             16  com.sun.jmx.remote.protocol.iiop.IIOPProxyImpl
2832:             1             16  com.sun.jmx.remote.security.SubjectDelegator
2833:             1             16  com.sun.jna.Native$1
2834:             1             16  com.sun.jna.Native$2
2835:             1             16  com.sun.jna.Native$7
2836:             1             16  com.sun.jna.Structure$1
2837:             1             16  com.sun.jna.Structure$2
2838:             1             16  com.sun.jna.VarArgsChecker$RealVarArgsChecker
2839:             1             16  com.sun.org.apache.xerces.internal.impl.dv.dtd.IDDatatypeValidator
2840:             1             16  com.sun.org.apache.xerces.internal.impl.dv.dtd.IDREFDatatypeValidator
2841:             1             16  com.sun.org.apache.xerces.internal.impl.dv.dtd.NMTOKENDatatypeValidator
2842:             1             16  com.sun.org.apache.xerces.internal.impl.dv.dtd.NOTATIONDatatypeValidator
2843:             1             16  com.sun.org.apache.xerces.internal.impl.dv.dtd.StringDatatypeValidator
2844:             1             16  com.sun.org.apache.xerces.internal.utils.SecuritySupport
2845:             1             16  com.sun.proxy.$Proxy2
2846:             1             16  com.sun.proxy.$Proxy4
2847:             1             16  com.sun.proxy.$Proxy7
2848:             1             16  io.netty.buffer.ByteBufUtil$1
2849:             1             16  io.netty.buffer.ByteBufUtil$2
2850:             1             16  io.netty.channel.ChannelFutureListener$1
2851:             1             16  io.netty.channel.ChannelFutureListener$2
2852:             1             16  io.netty.channel.ChannelFutureListener$3
2853:             1             16  io.netty.channel.ChannelMetadata
2854:             1             16  io.netty.channel.ChannelOutboundBuffer$1
2855:             1             16  io.netty.channel.DefaultChannelPipeline$1
2856:             1             16  io.netty.channel.DefaultMessageSizeEstimator
2857:             1             16  io.netty.channel.DefaultMessageSizeEstimator$HandleImpl
2858:             1             16  io.netty.channel.DefaultSelectStrategy
2859:             1             16  io.netty.channel.DefaultSelectStrategyFactory
2860:             1             16  io.netty.channel.group.ChannelMatchers$1
2861:             1             16  io.netty.channel.group.ChannelMatchers$InvertMatcher
2862:             1             16  io.netty.util.Recycler$1
2863:             1             16  io.netty.util.Recycler$3
2864:             1             16  io.netty.util.concurrent.DefaultPromise$CauseHolder
2865:             1             16  io.netty.util.concurrent.GlobalEventExecutor$1
2866:             1             16  io.netty.util.concurrent.GlobalEventExecutor$TaskRunner
2867:             1             16  io.netty.util.concurrent.MultithreadEventExecutorGroup$1
2868:             1             16  io.netty.util.concurrent.MultithreadEventExecutorGroup$PowerOfTwoEventExecutorChooser
2869:             1             16  io.netty.util.concurrent.RejectedExecutionHandlers$1
2870:             1             16  io.netty.util.concurrent.SingleThreadEventExecutor$1
2871:             1             16  io.netty.util.internal.NoOpTypeParameterMatcher
2872:             1             16  java.io.DeleteOnExitHook$1
2873:             1             16  java.io.FileDescriptor$1
2874:             1             16  java.io.ObjectInputStream$$Lambda$293/697818519
2875:             1             16  java.io.ObjectInputStream$1
2876:             1             16  java.lang.ApplicationShutdownHooks$1
2877:             1             16  java.lang.CharacterDataLatin1
2878:             1             16  java.lang.ClassValue$Identity
2879:             1             16  java.lang.ProcessBuilder$NullInputStream
2880:             1             16  java.lang.ProcessBuilder$NullOutputStream
2881:             1             16  java.lang.Runtime
2882:             1             16  java.lang.String$CaseInsensitiveComparator
2883:             1             16  java.lang.System$2
2884:             1             16  java.lang.Terminator$1
2885:             1             16  java.lang.UNIXProcess$$Lambda$13/1784131088
2886:             1             16  java.lang.UNIXProcess$$Lambda$14/2143582219
2887:             1             16  java.lang.UNIXProcess$Platform$$Lambda$10/616881582
2888:             1             16  java.lang.invoke.MemberName$Factory
2889:             1             16  java.lang.invoke.MethodHandleImpl$2
2890:             1             16  java.lang.invoke.MethodHandleImpl$3
2891:             1             16  java.lang.management.PlatformComponent$1
2892:             1             16  java.lang.management.PlatformComponent$10
2893:             1             16  java.lang.management.PlatformComponent$11
2894:             1             16  java.lang.management.PlatformComponent$12
2895:             1             16  java.lang.management.PlatformComponent$13
2896:             1             16  java.lang.management.PlatformComponent$14
2897:             1             16  java.lang.management.PlatformComponent$15
2898:             1             16  java.lang.management.PlatformComponent$2
2899:             1             16  java.lang.management.PlatformComponent$3
2900:             1             16  java.lang.management.PlatformComponent$4
2901:             1             16  java.lang.management.PlatformComponent$5
2902:             1             16  java.lang.management.PlatformComponent$6
2903:             1             16  java.lang.management.PlatformComponent$7
2904:             1             16  java.lang.management.PlatformComponent$8
2905:             1             16  java.lang.management.PlatformComponent$9
2906:             1             16  java.lang.ref.Reference$1
2907:             1             16  java.lang.ref.Reference$Lock
2908:             1             16  java.lang.reflect.Proxy$KeyFactory
2909:             1             16  java.lang.reflect.Proxy$ProxyClassFactory
2910:             1             16  java.lang.reflect.ReflectAccess
2911:             1             16  java.math.BigDecimal$1
2912:             1             16  java.net.InetAddress$2
2913:             1             16  java.net.URLClassLoader$7
2914:             1             16  java.nio.Bits$1
2915:             1             16  java.nio.Bits$1$1
2916:             1             16  java.nio.charset.CoderResult$1
2917:             1             16  java.nio.charset.CoderResult$2
2918:             1             16  java.nio.file.Files$AcceptAllFilter
2919:             1             16  java.rmi.server.RMIClassLoader$2
2920:             1             16  java.security.AllPermission
2921:             1             16  java.security.ProtectionDomain$2
2922:             1             16  java.security.ProtectionDomain$JavaSecurityAccessImpl
2923:             1             16  java.text.DontCareFieldPosition$1
2924:             1             16  java.util.Collections$EmptyEnumeration
2925:             1             16  java.util.Collections$EmptyIterator
2926:             1             16  java.util.Collections$EmptyList
2927:             1             16  java.util.Collections$EmptySet
2928:             1             16  java.util.Collections$UnmodifiableMap$UnmodifiableEntrySet
2929:             1             16  java.util.Currency$CurrencyNameGetter
2930:             1             16  java.util.EnumMap$1
2931:             1             16  java.util.ResourceBundle$Control
2932:             1             16  java.util.Spliterators$EmptySpliterator$OfDouble
2933:             1             16  java.util.Spliterators$EmptySpliterator$OfInt
2934:             1             16  java.util.Spliterators$EmptySpliterator$OfLong
2935:             1             16  java.util.Spliterators$EmptySpliterator$OfRef
2936:             1             16  java.util.TreeMap$EntrySpliterator$$Lambda$68/1819038759
2937:             1             16  java.util.WeakHashMap$KeySet
2938:             1             16  java.util.concurrent.Executors$FinalizableDelegatedExecutorService
2939:             1             16  java.util.concurrent.ThreadPoolExecutor$AbortPolicy
2940:             1             16  java.util.jar.JarVerifier$3
2941:             1             16  java.util.jar.JavaUtilJarAccessImpl
2942:             1             16  java.util.logging.LoggingProxyImpl
2943:             1             16  java.util.regex.Pattern$4
2944:             1             16  java.util.regex.Pattern$LastNode
2945:             1             16  java.util.regex.Pattern$Node
2946:             1             16  java.util.stream.Collectors$$Lambda$178/1708585783
2947:             1             16  java.util.stream.Collectors$$Lambda$179/2048467502
2948:             1             16  java.util.stream.Collectors$$Lambda$180/1269763229
2949:             1             16  java.util.stream.Collectors$$Lambda$221/1489469437
2950:             1             16  java.util.stream.Collectors$$Lambda$222/431613642
2951:             1             16  java.util.stream.Collectors$$Lambda$223/1098744211
2952:             1             16  java.util.stream.Collectors$$Lambda$247/1746129463
2953:             1             16  java.util.stream.Collectors$$Lambda$60/1724814719
2954:             1             16  java.util.stream.Collectors$$Lambda$61/1718322084
2955:             1             16  java.util.stream.Collectors$$Lambda$62/24039137
2956:             1             16  java.util.stream.Collectors$$Lambda$63/992086987
2957:             1             16  java.util.stream.LongPipeline$$Lambda$189/1888591113
2958:             1             16  java.util.stream.LongPipeline$$Lambda$325/1014276638
2959:             1             16  java.util.zip.ZipFile$1
2960:             1             16  javax.crypto.JceSecurityManager
2961:             1             16  javax.management.JMX
2962:             1             16  javax.management.MBeanServerBuilder
2963:             1             16  javax.management.NotificationBroadcasterSupport$1
2964:             1             16  javax.management.remote.JMXPrincipal
2965:             1             16  javax.management.remote.rmi.RMIConnectionImpl_Stub
2966:             1             16  javax.management.remote.rmi.RMIServerImpl_Stub
2967:             1             16  javax.xml.parsers.SecuritySupport
2968:             1             16  net.jpountz.lz4.LZ4JNICompressor
2969:             1             16  net.jpountz.lz4.LZ4JNIFastDecompressor
2970:             1             16  net.jpountz.lz4.LZ4JNISafeDecompressor
2971:             1             16  net.jpountz.xxhash.StreamingXXHash32JNI$Factory
2972:             1             16  net.jpountz.xxhash.StreamingXXHash64JNI$Factory
2973:             1             16  net.jpountz.xxhash.XXHash32JNI
2974:             1             16  net.jpountz.xxhash.XXHash64JNI
2975:             1             16  org.apache.cassandra.auth.AllowAllAuthenticator$Negotiator
2976:             1             16  org.apache.cassandra.auth.AllowAllInternodeAuthenticator
2977:             1             16  org.apache.cassandra.auth.AuthCache$1
2978:             1             16  org.apache.cassandra.auth.AuthMigrationListener
2979:             1             16  org.apache.cassandra.auth.CassandraRoleManager$$Lambda$264/195066780
2980:             1             16  org.apache.cassandra.auth.CassandraRoleManager$1
2981:             1             16  org.apache.cassandra.auth.CassandraRoleManager$2
2982:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$265/385180766
2983:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$266/694021194
2984:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$267/767298601
2985:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$268/274090580
2986:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$269/1588510401
2987:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$270/331234425
2988:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$271/996989596
2989:             1             16  org.apache.cassandra.auth.PasswordAuthenticator$CredentialsCache$$Lambda$272/1507030140
2990:             1             16  org.apache.cassandra.batchlog.Batch$Serializer
2991:             1             16  org.apache.cassandra.batchlog.BatchRemoveVerbHandler
2992:             1             16  org.apache.cassandra.batchlog.BatchStoreVerbHandler
2993:             1             16  org.apache.cassandra.batchlog.BatchlogManager$$Lambda$258/2042553130
2994:             1             16  org.apache.cassandra.batchlog.BatchlogManager$$Lambda$290/1638031626
2995:             1             16  org.apache.cassandra.cache.AutoSavingCache$1
2996:             1             16  org.apache.cassandra.cache.ChunkCache$$Lambda$78/420307438
2997:             1             16  org.apache.cassandra.cache.NopCacheProvider$NopCache
2998:             1             16  org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$1
2999:             1             16  org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$1
3000:             1             16  org.apache.cassandra.concurrent.StageManager$1
3001:             1             16  org.apache.cassandra.config.CFMetaData$$Lambda$213/1328645530
3002:             1             16  org.apache.cassandra.config.CFMetaData$$Lambda$214/2107098463
3003:             1             16  org.apache.cassandra.config.CFMetaData$$Lambda$232/1529326426
3004:             1             16  org.apache.cassandra.config.CFMetaData$$Lambda$233/570714518
3005:             1             16  org.apache.cassandra.config.CFMetaData$Builder$$Lambda$30/671596011
3006:             1             16  org.apache.cassandra.config.CFMetaData$Serializer
3007:             1             16  org.apache.cassandra.config.ColumnDefinition$$Lambda$25/207471778
3008:             1             16  org.apache.cassandra.config.DatabaseDescriptor$1
3009:             1             16  org.apache.cassandra.config.Schema$$Lambda$262/956354740
3010:             1             16  org.apache.cassandra.config.Schema$$Lambda$263/2080528880
3011:             1             16  org.apache.cassandra.cql3.ColumnConditions$$Lambda$116/841977955
3012:             1             16  org.apache.cassandra.cql3.Constants$1
3013:             1             16  org.apache.cassandra.cql3.Constants$NullLiteral
3014:             1             16  org.apache.cassandra.cql3.Constants$UnsetLiteral
3015:             1             16  org.apache.cassandra.cql3.Cql_Parser$1
3016:             1             16  org.apache.cassandra.cql3.IfExistsCondition
3017:             1             16  org.apache.cassandra.cql3.IfNotExistsCondition
3018:             1             16  org.apache.cassandra.cql3.QueryOptions$Codec
3019:             1             16  org.apache.cassandra.cql3.QueryProcessor
3020:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$17/951221468
3021:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$18/1046545660
3022:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$19/1545827753
3023:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$20/1611832218
3024:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$21/2027317551
3025:             1             16  org.apache.cassandra.cql3.QueryProcessor$$Lambda$22/273077527
3026:             1             16  org.apache.cassandra.cql3.QueryProcessor$MigrationSubscriber
3027:             1             16  org.apache.cassandra.cql3.ResultSet$Codec
3028:             1             16  org.apache.cassandra.cql3.ResultSet$ResultMetadata$Codec
3029:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$41/1614133563
3030:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$42/839771540
3031:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$43/1751403001
3032:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$44/1756819670
3033:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$45/178604517
3034:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$46/1543518287
3035:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$47/464872674
3036:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$48/1659286984
3037:             1             16  org.apache.cassandra.cql3.functions.CastFcts$$Lambda$49/1793899405
3038:             1             16  org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager
3039:             1             16  org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager$1
3040:             1             16  org.apache.cassandra.cql3.functions.ThreadAwareSecurityManager$2
3041:             1             16  org.apache.cassandra.cql3.restrictions.RestrictionSet$1
3042:             1             16  org.apache.cassandra.cql3.selection.Selection$1
3043:             1             16  org.apache.cassandra.cql3.statements.CreateTableStatement$$Lambda$23/1470868839
3044:             1             16  org.apache.cassandra.db.CBuilder$1
3045:             1             16  org.apache.cassandra.db.Clustering$Serializer
3046:             1             16  org.apache.cassandra.db.ClusteringBoundOrBoundary$Serializer
3047:             1             16  org.apache.cassandra.db.ClusteringPrefix$Serializer
3048:             1             16  org.apache.cassandra.db.ColumnFamilyStore$$Lambda$190/1269783694
3049:             1             16  org.apache.cassandra.db.ColumnFamilyStore$2
3050:             1             16  org.apache.cassandra.db.ColumnFamilyStore$FlushLargestColumnFamily
3051:             1             16  org.apache.cassandra.db.Columns$$Lambda$205/2092785251
3052:             1             16  org.apache.cassandra.db.Columns$Serializer
3053:             1             16  org.apache.cassandra.db.CounterMutation$CounterMutationSerializer
3054:             1             16  org.apache.cassandra.db.CounterMutationVerbHandler
3055:             1             16  org.apache.cassandra.db.DataRange$Serializer
3056:             1             16  org.apache.cassandra.db.DecoratedKey$1
3057:             1             16  org.apache.cassandra.db.DefinitionsUpdateVerbHandler
3058:             1             16  org.apache.cassandra.db.DeletionPurger$$Lambda$105/2116697030
3059:             1             16  org.apache.cassandra.db.DeletionTime$Serializer
3060:             1             16  org.apache.cassandra.db.Directories$3
3061:             1             16  org.apache.cassandra.db.Directories$DataDirectory
3062:             1             16  org.apache.cassandra.db.EmptyIterators$EmptyPartitionIterator
3063:             1             16  org.apache.cassandra.db.HintedHandOffManager
3064:             1             16  org.apache.cassandra.db.Keyspace$1
3065:             1             16  org.apache.cassandra.db.MigrationRequestVerbHandler
3066:             1             16  org.apache.cassandra.db.Mutation$MutationSerializer
3067:             1             16  org.apache.cassandra.db.MutationVerbHandler
3068:             1             16  org.apache.cassandra.db.PartitionPosition$RowPositionSerializer
3069:             1             16  org.apache.cassandra.db.PartitionRangeReadCommand$Deserializer
3070:             1             16  org.apache.cassandra.db.ReadCommand$1
3071:             1             16  org.apache.cassandra.db.ReadCommand$1WithoutPurgeableTombstones$$Lambda$110/208106294
3072:             1             16  org.apache.cassandra.db.ReadCommand$2
3073:             1             16  org.apache.cassandra.db.ReadCommand$3
3074:             1             16  org.apache.cassandra.db.ReadCommand$LegacyPagedRangeCommandSerializer
3075:             1             16  org.apache.cassandra.db.ReadCommand$LegacyRangeSliceCommandSerializer
3076:             1             16  org.apache.cassandra.db.ReadCommand$LegacyReadCommandSerializer
3077:             1             16  org.apache.cassandra.db.ReadCommand$Serializer
3078:             1             16  org.apache.cassandra.db.ReadCommandVerbHandler
3079:             1             16  org.apache.cassandra.db.ReadQuery$1
3080:             1             16  org.apache.cassandra.db.ReadRepairVerbHandler
3081:             1             16  org.apache.cassandra.db.ReadResponse$1
3082:             1             16  org.apache.cassandra.db.ReadResponse$LegacyRangeSliceReplySerializer
3083:             1             16  org.apache.cassandra.db.ReadResponse$Serializer
3084:             1             16  org.apache.cassandra.db.SchemaCheckVerbHandler
3085:             1             16  org.apache.cassandra.db.SerializationHeader$Serializer
3086:             1             16  org.apache.cassandra.db.SinglePartitionReadCommand$Deserializer
3087:             1             16  org.apache.cassandra.db.SinglePartitionReadCommand$Group$$Lambda$106/1952605049
3088:             1             16  org.apache.cassandra.db.SizeEstimatesRecorder
3089:             1             16  org.apache.cassandra.db.Slice$Serializer
3090:             1             16  org.apache.cassandra.db.Slices$SelectAllSlices
3091:             1             16  org.apache.cassandra.db.Slices$SelectAllSlices$1
3092:             1             16  org.apache.cassandra.db.Slices$SelectNoSlices
3093:             1             16  org.apache.cassandra.db.Slices$SelectNoSlices$1
3094:             1             16  org.apache.cassandra.db.Slices$Serializer
3095:             1             16  org.apache.cassandra.db.SnapshotCommandSerializer
3096:             1             16  org.apache.cassandra.db.StorageHook$1
3097:             1             16  org.apache.cassandra.db.SystemKeyspace$$Lambda$186/1473888912
3098:             1             16  org.apache.cassandra.db.TruncateResponse$TruncateResponseSerializer
3099:             1             16  org.apache.cassandra.db.TruncateVerbHandler
3100:             1             16  org.apache.cassandra.db.TruncationSerializer
3101:             1             16  org.apache.cassandra.db.WriteResponse
3102:             1             16  org.apache.cassandra.db.WriteResponse$Serializer
3103:             1             16  org.apache.cassandra.db.aggregation.AggregationSpecification$1
3104:             1             16  org.apache.cassandra.db.aggregation.AggregationSpecification$Serializer
3105:             1             16  org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager$$Lambda$72/500233312
3106:             1             16  org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager$1
3107:             1             16  org.apache.cassandra.db.commitlog.AbstractCommitLogService$1
3108:             1             16  org.apache.cassandra.db.commitlog.CommitLog$$Lambda$227/2024217158
3109:             1             16  org.apache.cassandra.db.commitlog.CommitLogPosition$1
3110:             1             16  org.apache.cassandra.db.commitlog.CommitLogPosition$CommitLogPositionSerializer
3111:             1             16  org.apache.cassandra.db.commitlog.CommitLogReplayer$$Lambda$228/1186545861
3112:             1             16  org.apache.cassandra.db.commitlog.CommitLogReplayer$MutationInitiator
3113:             1             16  org.apache.cassandra.db.commitlog.CommitLogSegment$$Lambda$175/1833918497
3114:             1             16  org.apache.cassandra.db.commitlog.IntervalSet$1
3115:             1             16  org.apache.cassandra.db.commitlog.SimpleCachedBufferPool$1
3116:             1             16  org.apache.cassandra.db.compaction.CompactionController$$Lambda$184/889018651
3117:             1             16  org.apache.cassandra.db.compaction.CompactionController$$Lambda$185/638825183
3118:             1             16  org.apache.cassandra.db.compaction.CompactionController$$Lambda$242/1509719872
3119:             1             16  org.apache.cassandra.db.compaction.CompactionManager$1
3120:             1             16  org.apache.cassandra.db.compaction.CompactionManager$ValidationCompactionController$$Lambda$307/363853319
3121:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$133/1728760599
3122:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$134/703363283
3123:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$172/1546684896
3124:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$85/654029265
3125:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$86/2030162789
3126:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$87/1306548322
3127:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$88/973942848
3128:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$89/558033602
3129:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$90/1361733480
3130:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$91/999951331
3131:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$92/1918201666
3132:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$93/1181004273
3133:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$95/1423931162
3134:             1             16  org.apache.cassandra.db.compaction.CompactionStrategyManager$$Lambda$96/1090942546
3135:             1             16  org.apache.cassandra.db.compaction.LeveledManifest$1
3136:             1             16  org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy$1
3137:             1             16  org.apache.cassandra.db.context.CounterContext
3138:             1             16  org.apache.cassandra.db.filter.AbstractClusteringIndexFilter$FilterSerializer
3139:             1             16  org.apache.cassandra.db.filter.ClusteringIndexNamesFilter$NamesDeserializer
3140:             1             16  org.apache.cassandra.db.filter.ClusteringIndexSliceFilter$SliceDeserializer
3141:             1             16  org.apache.cassandra.db.filter.ColumnFilter$Serializer
3142:             1             16  org.apache.cassandra.db.filter.DataLimits$Serializer
3143:             1             16  org.apache.cassandra.db.filter.RowFilter$CQLFilter
3144:             1             16  org.apache.cassandra.db.filter.RowFilter$Serializer
3145:             1             16  org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$58/435914790
3146:             1             16  org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$59/1273958371
3147:             1             16  org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$64/731243659
3148:             1             16  org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$66/1037955032
3149:             1             16  org.apache.cassandra.db.lifecycle.LogAwareFileLister$$Lambda$70/331596257
3150:             1             16  org.apache.cassandra.db.lifecycle.LogFile$$Lambda$165/1814072734
3151:             1             16  org.apache.cassandra.db.lifecycle.LogFile$$Lambda$203/2022031193
3152:             1             16  org.apache.cassandra.db.lifecycle.LogFile$$Lambda$204/1336053009
3153:             1             16  org.apache.cassandra.db.lifecycle.LogRecord$$Lambda$140/1142908098
3154:             1             16  org.apache.cassandra.db.lifecycle.LogRecord$$Lambda$141/423008343
3155:             1             16  org.apache.cassandra.db.lifecycle.LogRecord$$Lambda$142/88843440
3156:             1             16  org.apache.cassandra.db.lifecycle.LogRecord$$Lambda$177/1035048662
3157:             1             16  org.apache.cassandra.db.lifecycle.LogReplicaSet$$Lambda$162/1676168006
3158:             1             16  org.apache.cassandra.db.lifecycle.LogReplicaSet$$Lambda$166/1882192501
3159:             1             16  org.apache.cassandra.db.lifecycle.LogReplicaSet$$Lambda$168/700891016
3160:             1             16  org.apache.cassandra.db.lifecycle.LogTransaction$LogFilesByName$$Lambda$52/894421232
3161:             1             16  org.apache.cassandra.db.lifecycle.LogTransaction$LogFilesByName$$Lambda$54/276869158
3162:             1             16  org.apache.cassandra.db.lifecycle.Tracker$$Lambda$170/1786214274
3163:             1             16  org.apache.cassandra.db.marshal.CollectionType$CollectionPathSerializer
3164:             1             16  org.apache.cassandra.db.monitoring.ApproximateTime$$Lambda$108/2001863314
3165:             1             16  org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer
3166:             1             16  org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$$Lambda$107/2345640
3167:             1             16  org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer
3168:             1             16  org.apache.cassandra.db.rows.AbstractTypeVersionComparator
3169:             1             16  org.apache.cassandra.db.rows.BTreeRow$$Lambda$118/474868079
3170:             1             16  org.apache.cassandra.db.rows.BTreeRow$$Lambda$123/164389557
3171:             1             16  org.apache.cassandra.db.rows.Cell$$Lambda$101/1913147328
3172:             1             16  org.apache.cassandra.db.rows.Cell$Serializer
3173:             1             16  org.apache.cassandra.db.rows.ColumnData$$Lambda$28/494077446
3174:             1             16  org.apache.cassandra.db.rows.EncodingStats$Serializer
3175:             1             16  org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer
3176:             1             16  org.apache.cassandra.db.rows.UnfilteredSerializer
3177:             1             16  org.apache.cassandra.db.rows.UnfilteredSerializer$$Lambda$194/5263871
3178:             1             16  org.apache.cassandra.db.view.View$$Lambda$219/1557380482
3179:             1             16  org.apache.cassandra.dht.BootStrapper$StringSerializer
3180:             1             16  org.apache.cassandra.dht.Murmur3Partitioner$2
3181:             1             16  org.apache.cassandra.dht.StreamStateStore
3182:             1             16  org.apache.cassandra.dht.Token$TokenSerializer
3183:             1             16  org.apache.cassandra.gms.EchoMessage
3184:             1             16  org.apache.cassandra.gms.EchoMessage$EchoMessageSerializer
3185:             1             16  org.apache.cassandra.gms.EndpointStateSerializer
3186:             1             16  org.apache.cassandra.gms.GossipDigestAck2Serializer
3187:             1             16  org.apache.cassandra.gms.GossipDigestAck2VerbHandler
3188:             1             16  org.apache.cassandra.gms.GossipDigestAckSerializer
3189:             1             16  org.apache.cassandra.gms.GossipDigestAckVerbHandler
3190:             1             16  org.apache.cassandra.gms.GossipDigestSerializer
3191:             1             16  org.apache.cassandra.gms.GossipDigestSynSerializer
3192:             1             16  org.apache.cassandra.gms.GossipDigestSynVerbHandler
3193:             1             16  org.apache.cassandra.gms.GossipShutdownVerbHandler
3194:             1             16  org.apache.cassandra.gms.Gossiper$1
3195:             1             16  org.apache.cassandra.gms.Gossiper$GossipTask
3196:             1             16  org.apache.cassandra.gms.HeartBeatStateSerializer
3197:             1             16  org.apache.cassandra.gms.VersionedValue$VersionedValueFactory
3198:             1             16  org.apache.cassandra.gms.VersionedValue$VersionedValueSerializer
3199:             1             16  org.apache.cassandra.hints.EncodedHintMessage$Serializer
3200:             1             16  org.apache.cassandra.hints.Hint$Serializer
3201:             1             16  org.apache.cassandra.hints.HintMessage$Serializer
3202:             1             16  org.apache.cassandra.hints.HintResponse
3203:             1             16  org.apache.cassandra.hints.HintResponse$Serializer
3204:             1             16  org.apache.cassandra.hints.HintVerbHandler
3205:             1             16  org.apache.cassandra.hints.HintsBuffer$$Lambda$327/1070755303
3206:             1             16  org.apache.cassandra.hints.HintsCatalog$$Lambda$244/955891688
3207:             1             16  org.apache.cassandra.hints.HintsCatalog$$Lambda$245/1579667951
3208:             1             16  org.apache.cassandra.hints.HintsCatalog$$Lambda$246/2099786968
3209:             1             16  org.apache.cassandra.hints.HintsDispatchTrigger$$Lambda$282/2033605821
3210:             1             16  org.apache.cassandra.hints.HintsDispatchTrigger$$Lambda$283/1986677941
3211:             1             16  org.apache.cassandra.hints.HintsDispatchTrigger$$Lambda$284/355640298
3212:             1             16  org.apache.cassandra.hints.HintsService$$Lambda$250/1791992279
3213:             1             16  org.apache.cassandra.hints.HintsService$$Lambda$251/1557383930
3214:             1             16  org.apache.cassandra.hints.HintsService$$Lambda$252/763495689
3215:             1             16  org.apache.cassandra.hints.HintsStore$$Lambda$318/991892116
3216:             1             16  org.apache.cassandra.hints.HintsStore$$Lambda$322/1059094831
3217:             1             16  org.apache.cassandra.hints.HintsWriteExecutor$FsyncWritersTask$$Lambda$289/2053564305
3218:             1             16  org.apache.cassandra.index.Index$CollatedViewIndexBuildingSupport
3219:             1             16  org.apache.cassandra.index.SecondaryIndexManager$$Lambda$152/111521464
3220:             1             16  org.apache.cassandra.index.SecondaryIndexManager$$Lambda$153/118079547
3221:             1             16  org.apache.cassandra.index.SecondaryIndexManager$$Lambda$182/992085984
3222:             1             16  org.apache.cassandra.index.SecondaryIndexManager$$Lambda$188/887656608
3223:             1             16  org.apache.cassandra.index.SecondaryIndexManager$$Lambda$312/1070341018
3224:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$1
3225:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$2
3226:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$3
3227:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$4
3228:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$5
3229:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$6
3230:             1             16  org.apache.cassandra.index.internal.CassandraIndexFunctions$7
3231:             1             16  org.apache.cassandra.index.transactions.UpdateTransaction$1
3232:             1             16  org.apache.cassandra.io.compress.CompressionMetadata$ChunkSerializer
3233:             1             16  org.apache.cassandra.io.compress.SnappyCompressor
3234:             1             16  org.apache.cassandra.io.sstable.Descriptor$$Lambda$71/999647352
3235:             1             16  org.apache.cassandra.io.sstable.IndexSummary$IndexSummarySerializer
3236:             1             16  org.apache.cassandra.io.sstable.IndexSummaryManager$1
3237:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$$Lambda$73/1687768728
3238:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$$Lambda$74/15478307
3239:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$$Lambda$75/1394837936
3240:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$1
3241:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$Operator$Equals
3242:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$Operator$GreaterThan
3243:             1             16  org.apache.cassandra.io.sstable.format.SSTableReader$Operator$GreaterThanOrEqualTo
3244:             1             16  org.apache.cassandra.io.sstable.format.SSTableReadsListener$1
3245:             1             16  org.apache.cassandra.io.sstable.format.SSTableWriter$$Lambda$160/1520196427
3246:             1             16  org.apache.cassandra.io.sstable.format.SSTableWriter$$Lambda$311/1357900831
3247:             1             16  org.apache.cassandra.io.sstable.format.big.BigFormat
3248:             1             16  org.apache.cassandra.io.sstable.format.big.BigFormat$ReaderFactory
3249:             1             16  org.apache.cassandra.io.sstable.format.big.BigFormat$WriterFactory
3250:             1             16  org.apache.cassandra.io.sstable.format.big.BigTableWriter$IndexWriter$$Lambda$150/504911193
3251:             1             16  org.apache.cassandra.io.sstable.format.big.BigTableWriter$IndexWriter$$Lambda$151/451889382
3252:             1             16  org.apache.cassandra.io.sstable.metadata.CompactionMetadata$CompactionMetadataSerializer
3253:             1             16  org.apache.cassandra.io.sstable.metadata.StatsMetadata$StatsMetadataSerializer
3254:             1             16  org.apache.cassandra.io.sstable.metadata.ValidationMetadata$ValidationMetadataSerializer
3255:             1             16  org.apache.cassandra.io.util.DataOutputBuffer$1
3256:             1             16  org.apache.cassandra.io.util.DataOutputStreamPlus$1
3257:             1             16  org.apache.cassandra.io.util.FileHandle$$Lambda$158/795408782
3258:             1             16  org.apache.cassandra.io.util.MmappedRegions$State$$Lambda$197/1396226930
3259:             1             16  org.apache.cassandra.io.util.Rebufferer$1
3260:             1             16  org.apache.cassandra.locator.DynamicEndpointSnitch$1
3261:             1             16  org.apache.cassandra.locator.DynamicEndpointSnitch$2
3262:             1             16  org.apache.cassandra.locator.EndpointSnitchInfo
3263:             1             16  org.apache.cassandra.locator.PendingRangeMaps$1
3264:             1             16  org.apache.cassandra.locator.PendingRangeMaps$2
3265:             1             16  org.apache.cassandra.locator.PendingRangeMaps$3
3266:             1             16  org.apache.cassandra.locator.PendingRangeMaps$4
3267:             1             16  org.apache.cassandra.locator.PropertyFileSnitch
3268:             1             16  org.apache.cassandra.locator.PropertyFileSnitch$1
3269:             1             16  org.apache.cassandra.locator.SimpleSeedProvider
3270:             1             16  org.apache.cassandra.locator.TokenMetadata$1
3271:             1             16  org.apache.cassandra.metrics.BufferPoolMetrics$1
3272:             1             16  org.apache.cassandra.metrics.CQLMetrics$1
3273:             1             16  org.apache.cassandra.metrics.CQLMetrics$2
3274:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$$Lambda$82/1609657810
3275:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$$Lambda$83/2101898459
3276:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$$Lambda$84/342161168
3277:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$1
3278:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$2
3279:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$3
3280:             1             16  org.apache.cassandra.metrics.CacheMissMetrics$4
3281:             1             16  org.apache.cassandra.metrics.ClientMetrics
3282:             1             16  org.apache.cassandra.metrics.CompactionMetrics$1
3283:             1             16  org.apache.cassandra.metrics.CompactionMetrics$2
3284:             1             16  org.apache.cassandra.metrics.HintedHandoffMetrics$1
3285:             1             16  org.apache.cassandra.metrics.HintedHandoffMetrics$2
3286:             1             16  org.apache.cassandra.metrics.TableMetrics$1
3287:             1             16  org.apache.cassandra.metrics.TableMetrics$13
3288:             1             16  org.apache.cassandra.metrics.TableMetrics$18
3289:             1             16  org.apache.cassandra.metrics.TableMetrics$20
3290:             1             16  org.apache.cassandra.metrics.TableMetrics$22
3291:             1             16  org.apache.cassandra.metrics.TableMetrics$26
3292:             1             16  org.apache.cassandra.metrics.TableMetrics$28
3293:             1             16  org.apache.cassandra.metrics.ViewWriteMetrics$1
3294:             1             16  org.apache.cassandra.net.IAsyncCallback$1
3295:             1             16  org.apache.cassandra.net.MessagingService$4
3296:             1             16  org.apache.cassandra.net.MessagingService$5
3297:             1             16  org.apache.cassandra.net.MessagingService$CallbackDeterminedSerializer
3298:             1             16  org.apache.cassandra.notifications.SSTableDeletingNotification
3299:             1             16  org.apache.cassandra.repair.NodePair$NodePairSerializer
3300:             1             16  org.apache.cassandra.repair.RepairJobDesc$RepairJobDescSerializer
3301:             1             16  org.apache.cassandra.repair.RepairMessageVerbHandler
3302:             1             16  org.apache.cassandra.repair.messages.AnticompactionRequest$AnticompactionRequestSerializer
3303:             1             16  org.apache.cassandra.repair.messages.CleanupMessage$CleanupMessageSerializer
3304:             1             16  org.apache.cassandra.repair.messages.PrepareMessage$PrepareMessageSerializer
3305:             1             16  org.apache.cassandra.repair.messages.RepairMessage$RepairMessageSerializer
3306:             1             16  org.apache.cassandra.repair.messages.SnapshotMessage$SnapshotMessageSerializer
3307:             1             16  org.apache.cassandra.repair.messages.SyncComplete$SyncCompleteSerializer
3308:             1             16  org.apache.cassandra.repair.messages.SyncRequest$SyncRequestSerializer
3309:             1             16  org.apache.cassandra.repair.messages.ValidationComplete$ValidationCompleteSerializer
3310:             1             16  org.apache.cassandra.repair.messages.ValidationRequest$ValidationRequestSerializer
3311:             1             16  org.apache.cassandra.scheduler.NoScheduler
3312:             1             16  org.apache.cassandra.schema.CQLTypeParser$$Lambda$207/2843617
3313:             1             16  org.apache.cassandra.schema.CompressionParams$Serializer
3314:             1             16  org.apache.cassandra.schema.Functions$$Lambda$236/1017996482
3315:             1             16  org.apache.cassandra.schema.Functions$$Lambda$237/2135117754
3316:             1             16  org.apache.cassandra.schema.Functions$$Lambda$239/854637578
3317:             1             16  org.apache.cassandra.schema.Functions$$Lambda$240/305461269
3318:             1             16  org.apache.cassandra.schema.Functions$Builder$$Lambda$36/146874094
3319:             1             16  org.apache.cassandra.schema.IndexMetadata$Serializer
3320:             1             16  org.apache.cassandra.schema.LegacySchemaMigrator$$Lambda$132/399524457
3321:             1             16  org.apache.cassandra.schema.SchemaKeyspace$$Lambda$216/2137640552
3322:             1             16  org.apache.cassandra.schema.Types$RawBuilder$$Lambda$206/1399449613
3323:             1             16  org.apache.cassandra.schema.Types$RawBuilder$RawUDT$$Lambda$210/2069170964
3324:             1             16  org.apache.cassandra.schema.Views$$Lambda$50/1348115836
3325:             1             16  org.apache.cassandra.serializers.BooleanSerializer
3326:             1             16  org.apache.cassandra.serializers.ByteSerializer
3327:             1             16  org.apache.cassandra.serializers.BytesSerializer
3328:             1             16  org.apache.cassandra.serializers.DecimalSerializer
3329:             1             16  org.apache.cassandra.serializers.DoubleSerializer
3330:             1             16  org.apache.cassandra.serializers.InetAddressSerializer
3331:             1             16  org.apache.cassandra.serializers.Int32Serializer
3332:             1             16  org.apache.cassandra.serializers.LongSerializer
3333:             1             16  org.apache.cassandra.serializers.TimeUUIDSerializer
3334:             1             16  org.apache.cassandra.serializers.TimestampSerializer
3335:             1             16  org.apache.cassandra.serializers.TimestampSerializer$1
3336:             1             16  org.apache.cassandra.serializers.TimestampSerializer$2
3337:             1             16  org.apache.cassandra.serializers.TimestampSerializer$3
3338:             1             16  org.apache.cassandra.serializers.UTF8Serializer
3339:             1             16  org.apache.cassandra.serializers.UUIDSerializer
3340:             1             16  org.apache.cassandra.service.CacheService$CounterCacheSerializer
3341:             1             16  org.apache.cassandra.service.CacheService$KeyCacheSerializer
3342:             1             16  org.apache.cassandra.service.CacheService$RowCacheSerializer
3343:             1             16  org.apache.cassandra.service.CassandraDaemon$$Lambda$273/1244026033
3344:             1             16  org.apache.cassandra.service.CassandraDaemon$1
3345:             1             16  org.apache.cassandra.service.CassandraDaemon$2
3346:             1             16  org.apache.cassandra.service.CassandraDaemon$NativeAccess
3347:             1             16  org.apache.cassandra.service.ClientState$$Lambda$97/466481125
3348:             1             16  org.apache.cassandra.service.ClientWarn
3349:             1             16  org.apache.cassandra.service.DefaultFSErrorHandler
3350:             1             16  org.apache.cassandra.service.EchoVerbHandler
3351:             1             16  org.apache.cassandra.service.LoadBroadcaster
3352:             1             16  org.apache.cassandra.service.LoadBroadcaster$1
3353:             1             16  org.apache.cassandra.service.MigrationManager
3354:             1             16  org.apache.cassandra.service.MigrationManager$MigrationsSerializer
3355:             1             16  org.apache.cassandra.service.NativeTransportService$$Lambda$277/794251840
3356:             1             16  org.apache.cassandra.service.NativeTransportService$$Lambda$279/1246696592
3357:             1             16  org.apache.cassandra.service.PendingRangeCalculatorService$1
3358:             1             16  org.apache.cassandra.service.SnapshotVerbHandler
3359:             1             16  org.apache.cassandra.service.StartupChecks$$Lambda$1/1204167249
3360:             1             16  org.apache.cassandra.service.StartupChecks$$Lambda$114/1819989346
3361:             1             16  org.apache.cassandra.service.StartupChecks$$Lambda$2/1615780336
3362:             1             16  org.apache.cassandra.service.StartupChecks$1
3363:             1             16  org.apache.cassandra.service.StartupChecks$10
3364:             1             16  org.apache.cassandra.service.StartupChecks$11
3365:             1             16  org.apache.cassandra.service.StartupChecks$12
3366:             1             16  org.apache.cassandra.service.StartupChecks$2
3367:             1             16  org.apache.cassandra.service.StartupChecks$3
3368:             1             16  org.apache.cassandra.service.StartupChecks$4
3369:             1             16  org.apache.cassandra.service.StartupChecks$5
3370:             1             16  org.apache.cassandra.service.StartupChecks$6
3371:             1             16  org.apache.cassandra.service.StartupChecks$7
3372:             1             16  org.apache.cassandra.service.StartupChecks$9
3373:             1             16  org.apache.cassandra.service.StorageProxy
3374:             1             16  org.apache.cassandra.service.StorageProxy$1
3375:             1             16  org.apache.cassandra.service.StorageProxy$2
3376:             1             16  org.apache.cassandra.service.StorageProxy$3
3377:             1             16  org.apache.cassandra.service.StorageProxy$4
3378:             1             16  org.apache.cassandra.service.StorageService$$Lambda$259/1361973748
3379:             1             16  org.apache.cassandra.service.StorageService$1
3380:             1             16  org.apache.cassandra.service.paxos.Commit$CommitSerializer
3381:             1             16  org.apache.cassandra.service.paxos.CommitVerbHandler
3382:             1             16  org.apache.cassandra.service.paxos.PrepareResponse$PrepareResponseSerializer
3383:             1             16  org.apache.cassandra.service.paxos.PrepareVerbHandler
3384:             1             16  org.apache.cassandra.service.paxos.ProposeVerbHandler
3385:             1             16  org.apache.cassandra.streaming.ReplicationFinishedVerbHandler
3386:             1             16  org.apache.cassandra.streaming.StreamHook$1
3387:             1             16  org.apache.cassandra.streaming.StreamRequest$StreamRequestSerializer
3388:             1             16  org.apache.cassandra.streaming.StreamSummary$StreamSummarySerializer
3389:             1             16  org.apache.cassandra.streaming.compress.CompressionInfo$CompressionInfoSerializer
3390:             1             16  org.apache.cassandra.streaming.messages.CompleteMessage$1
3391:             1             16  org.apache.cassandra.streaming.messages.FileMessageHeader$FileMessageHeaderSerializer
3392:             1             16  org.apache.cassandra.streaming.messages.IncomingFileMessage$1
3393:             1             16  org.apache.cassandra.streaming.messages.KeepAliveMessage$1
3394:             1             16  org.apache.cassandra.streaming.messages.OutgoingFileMessage$1
3395:             1             16  org.apache.cassandra.streaming.messages.PrepareMessage$1
3396:             1             16  org.apache.cassandra.streaming.messages.ReceivedMessage$1
3397:             1             16  org.apache.cassandra.streaming.messages.RetryMessage$1
3398:             1             16  org.apache.cassandra.streaming.messages.SessionFailedMessage$1
3399:             1             16  org.apache.cassandra.streaming.messages.StreamInitMessage$StreamInitMessageSerializer
3400:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$add
3401:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$atomic_batch_mutate
3402:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$batch_mutate
3403:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$cas
3404:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_cluster_name
3405:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_keyspace
3406:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_keyspaces
3407:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_local_ring
3408:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_partitioner
3409:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_ring
3410:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_schema_versions
3411:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_snitch
3412:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_splits
3413:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_splits_ex
3414:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_token_map
3415:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$describe_version
3416:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$execute_cql3_query
3417:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$execute_cql_query
3418:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$execute_prepared_cql3_query
3419:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$execute_prepared_cql_query
3420:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get
3421:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_count
3422:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_indexed_slices
3423:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_multi_slice
3424:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_paged_slice
3425:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_range_slices
3426:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$get_slice
3427:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$insert
3428:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$login
3429:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$multiget_count
3430:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$multiget_slice
3431:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$prepare_cql3_query
3432:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$prepare_cql_query
3433:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$remove
3434:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$remove_counter
3435:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$set_cql_version
3436:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$set_keyspace
3437:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_add_column_family
3438:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_add_keyspace
3439:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_drop_column_family
3440:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_drop_keyspace
3441:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_update_column_family
3442:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$system_update_keyspace
3443:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$trace_next_query
3444:             1             16  org.apache.cassandra.thrift.Cassandra$Processor$truncate
3445:             1             16  org.apache.cassandra.thrift.CassandraServer
3446:             1             16  org.apache.cassandra.thrift.CassandraServer$1
3447:             1             16  org.apache.cassandra.transport.CBUtil$1
3448:             1             16  org.apache.cassandra.transport.Message$ExceptionHandler
3449:             1             16  org.apache.cassandra.transport.Server$1
3450:             1             16  org.apache.cassandra.transport.messages.AuthChallenge$1
3451:             1             16  org.apache.cassandra.transport.messages.AuthResponse$1
3452:             1             16  org.apache.cassandra.transport.messages.AuthSuccess$1
3453:             1             16  org.apache.cassandra.transport.messages.AuthenticateMessage$1
3454:             1             16  org.apache.cassandra.transport.messages.BatchMessage$1
3455:             1             16  org.apache.cassandra.transport.messages.CredentialsMessage$1
3456:             1             16  org.apache.cassandra.transport.messages.ErrorMessage$1
3457:             1             16  org.apache.cassandra.transport.messages.EventMessage$1
3458:             1             16  org.apache.cassandra.transport.messages.ExecuteMessage$1
3459:             1             16  org.apache.cassandra.transport.messages.OptionsMessage$1
3460:             1             16  org.apache.cassandra.transport.messages.PrepareMessage$1
3461:             1             16  org.apache.cassandra.transport.messages.QueryMessage$1
3462:             1             16  org.apache.cassandra.transport.messages.ReadyMessage$1
3463:             1             16  org.apache.cassandra.transport.messages.RegisterMessage$1
3464:             1             16  org.apache.cassandra.transport.messages.ResultMessage$1
3465:             1             16  org.apache.cassandra.transport.messages.ResultMessage$Prepared$1
3466:             1             16  org.apache.cassandra.transport.messages.ResultMessage$Rows$1
3467:             1             16  org.apache.cassandra.transport.messages.ResultMessage$SchemaChange$1
3468:             1             16  org.apache.cassandra.transport.messages.ResultMessage$SetKeyspace$1
3469:             1             16  org.apache.cassandra.transport.messages.ResultMessage$Void$1
3470:             1             16  org.apache.cassandra.transport.messages.StartupMessage$1
3471:             1             16  org.apache.cassandra.transport.messages.SupportedMessage$1
3472:             1             16  org.apache.cassandra.utils.AlwaysPresentFilter
3473:             1             16  org.apache.cassandra.utils.AsymmetricOrdering$Reversed
3474:             1             16  org.apache.cassandra.utils.BloomFilter$1
3475:             1             16  org.apache.cassandra.utils.BooleanSerializer
3476:             1             16  org.apache.cassandra.utils.Clock
3477:             1             16  org.apache.cassandra.utils.CoalescingStrategies$1
3478:             1             16  org.apache.cassandra.utils.CoalescingStrategies$2
3479:             1             16  org.apache.cassandra.utils.EstimatedHistogram$EstimatedHistogramSerializer
3480:             1             16  org.apache.cassandra.utils.FBUtilities$1
3481:             1             16  org.apache.cassandra.utils.FastByteOperations$UnsafeOperations
3482:             1             16  org.apache.cassandra.utils.Interval$1
3483:             1             16  org.apache.cassandra.utils.Interval$2
3484:             1             16  org.apache.cassandra.utils.JMXServerUtils$Exporter
3485:             1             16  org.apache.cassandra.utils.JMXServerUtils$JMXPluggableAuthenticatorWrapper
3486:             1             16  org.apache.cassandra.utils.JVMStabilityInspector$Killer
3487:             1             16  org.apache.cassandra.utils.MerkleTree$Hashable$HashableSerializer
3488:             1             16  org.apache.cassandra.utils.MerkleTree$Inner$InnerSerializer
3489:             1             16  org.apache.cassandra.utils.MerkleTree$Leaf$LeafSerializer
3490:             1             16  org.apache.cassandra.utils.MerkleTree$MerkleTreeSerializer
3491:             1             16  org.apache.cassandra.utils.MerkleTrees$MerkleTreesSerializer
3492:             1             16  org.apache.cassandra.utils.NanoTimeToCurrentTimeMillis$$Lambda$255/703776031
3493:             1             16  org.apache.cassandra.utils.NativeLibraryLinux
3494:             1             16  org.apache.cassandra.utils.NoSpamLogger$1
3495:             1             16  org.apache.cassandra.utils.StreamingHistogram$$Lambda$76/244613162
3496:             1             16  org.apache.cassandra.utils.StreamingHistogram$StreamingHistogramBuilder$$Lambda$136/1321552491
3497:             1             16  org.apache.cassandra.utils.StreamingHistogram$StreamingHistogramBuilder$$Lambda$137/732447846
3498:             1             16  org.apache.cassandra.utils.StreamingHistogram$StreamingHistogramSerializer
3499:             1             16  org.apache.cassandra.utils.SystemTimeSource
3500:             1             16  org.apache.cassandra.utils.UUIDGen
3501:             1             16  org.apache.cassandra.utils.UUIDSerializer
3502:             1             16  org.apache.cassandra.utils.btree.BTree$$Lambda$193/1448037571
3503:             1             16  org.apache.cassandra.utils.btree.UpdateFunction$$Lambda$29/24650043
3504:             1             16  org.apache.cassandra.utils.concurrent.Ref$ReferenceReaper
3505:             1             16  org.apache.cassandra.utils.memory.BufferPool$1
3506:             1             16  org.apache.cassandra.utils.memory.BufferPool$2
3507:             1             16  org.apache.cassandra.utils.memory.HeapAllocator
3508:             1             16  org.apache.cassandra.utils.vint.VIntCoding$1
3509:             1             16  org.apache.thrift.TProcessorFactory
3510:             1             16  org.apache.thrift.transport.TFramedTransport$Factory
3511:             1             16  org.cliffc.high_scale_lib.NonBlockingHashMap$Prime
3512:             1             16  org.cliffc.high_scale_lib.NonBlockingHashSet
3513:             1             16  org.codehaus.jackson.map.deser.std.AtomicBooleanDeserializer
3514:             1             16  org.codehaus.jackson.map.deser.std.ClassDeserializer
3515:             1             16  org.codehaus.jackson.map.deser.std.DateDeserializer
3516:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$CurrencyDeserializer
3517:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$InetAddressDeserializer
3518:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$LocaleDeserializer
3519:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$PatternDeserializer
3520:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$TimeZoneDeserializer
3521:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$URIDeserializer
3522:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$URLDeserializer
3523:             1             16  org.codehaus.jackson.map.deser.std.FromStringDeserializer$UUIDDeserializer
3524:             1             16  org.codehaus.jackson.map.deser.std.JavaTypeDeserializer
3525:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers
3526:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$BooleanDeser
3527:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$ByteDeser
3528:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$CharDeser
3529:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$DoubleDeser
3530:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$FloatDeser
3531:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$IntDeser
3532:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$LongDeser
3533:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$ShortDeser
3534:             1             16  org.codehaus.jackson.map.deser.std.PrimitiveArrayDeserializers$StringDeser
3535:             1             16  org.codehaus.jackson.map.deser.std.StdDeserializer$BigDecimalDeserializer
3536:             1             16  org.codehaus.jackson.map.deser.std.StdDeserializer$BigIntegerDeserializer
3537:             1             16  org.codehaus.jackson.map.deser.std.StdDeserializer$NumberDeserializer
3538:             1             16  org.codehaus.jackson.map.deser.std.StdDeserializer$SqlDateDeserializer
3539:             1             16  org.codehaus.jackson.map.deser.std.StdDeserializer$StackTraceElementDeserializer
3540:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$BoolKD
3541:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$ByteKD
3542:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$CharKD
3543:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$DoubleKD
3544:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$FloatKD
3545:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$IntKD
3546:             1             16  org.codehaus.jackson.map.deser.std.StdKeyDeserializer$LongKD
3547:             1             16  org.codehaus.jackson.map.deser.std.StringDeserializer
3548:             1             16  org.codehaus.jackson.map.deser.std.TimestampDeserializer
3549:             1             16  org.codehaus.jackson.map.deser.std.TokenBufferDeserializer
3550:             1             16  org.codehaus.jackson.map.deser.std.UntypedObjectDeserializer
3551:             1             16  org.codehaus.jackson.map.ext.OptionalHandlerFactory
3552:             1             16  org.codehaus.jackson.map.introspect.BasicClassIntrospector
3553:             1             16  org.codehaus.jackson.map.introspect.BasicClassIntrospector$GetterMethodFilter
3554:             1             16  org.codehaus.jackson.map.introspect.BasicClassIntrospector$MinimalMethodFilter
3555:             1             16  org.codehaus.jackson.map.introspect.BasicClassIntrospector$SetterAndGetterMethodFilter
3556:             1             16  org.codehaus.jackson.map.introspect.BasicClassIntrospector$SetterMethodFilter
3557:             1             16  org.codehaus.jackson.map.introspect.JacksonAnnotationIntrospector
3558:             1             16  org.codehaus.jackson.map.ser.StdSerializers$DoubleSerializer
3559:             1             16  org.codehaus.jackson.map.ser.StdSerializers$FloatSerializer
3560:             1             16  org.codehaus.jackson.map.ser.StdSerializers$IntLikeSerializer
3561:             1             16  org.codehaus.jackson.map.ser.StdSerializers$IntegerSerializer
3562:             1             16  org.codehaus.jackson.map.ser.StdSerializers$LongSerializer
3563:             1             16  org.codehaus.jackson.map.ser.StdSerializers$SqlDateSerializer
3564:             1             16  org.codehaus.jackson.map.ser.StdSerializers$SqlTimeSerializer
3565:             1             16  org.codehaus.jackson.map.ser.impl.UnknownSerializer
3566:             1             16  org.codehaus.jackson.map.ser.std.CalendarSerializer
3567:             1             16  org.codehaus.jackson.map.ser.std.DateSerializer
3568:             1             16  org.codehaus.jackson.map.ser.std.NullSerializer
3569:             1             16  org.codehaus.jackson.map.ser.std.StdArraySerializers$ByteArraySerializer
3570:             1             16  org.codehaus.jackson.map.ser.std.StdArraySerializers$CharArraySerializer
3571:             1             16  org.codehaus.jackson.map.ser.std.StringSerializer
3572:             1             16  org.codehaus.jackson.map.ser.std.ToStringSerializer
3573:             1             16  org.codehaus.jackson.map.type.TypeParser
3574:             1             16  org.codehaus.jackson.node.JsonNodeFactory
3575:             1             16  org.github.jamm.MemoryLayoutSpecification$2
3576:             1             16  org.github.jamm.MemoryMeter$1
3577:             1             16  org.github.jamm.NoopMemoryMeterListener
3578:             1             16  org.github.jamm.NoopMemoryMeterListener$1
3579:             1             16  org.slf4j.helpers.NOPLoggerFactory
3580:             1             16  org.slf4j.helpers.SubstituteLoggerFactory
3581:             1             16  org.slf4j.impl.StaticMDCBinder
3582:             1             16  org.xerial.snappy.SnappyNative
3583:             1             16  org.yaml.snakeyaml.constructor.SafeConstructor$ConstructUndefined
3584:             1             16  org.yaml.snakeyaml.external.com.google.gdata.util.common.base.UnicodeEscaper$2
3585:             1             16  sun.management.ClassLoadingImpl
3586:             1             16  sun.management.HotSpotDiagnostic
3587:             1             16  sun.management.ManagementFactoryHelper$PlatformLoggingImpl
3588:             1             16  sun.misc.ASCIICaseInsensitiveComparator
3589:             1             16  sun.misc.FloatingDecimal$1
3590:             1             16  sun.misc.FormattedFloatingDecimal$1
3591:             1             16  sun.misc.Launcher
3592:             1             16  sun.misc.Launcher$Factory
3593:             1             16  sun.misc.ObjectInputFilter$Config$$Lambda$294/1344368391
3594:             1             16  sun.misc.Perf
3595:             1             16  sun.misc.Unsafe
3596:             1             16  sun.net.DefaultProgressMeteringPolicy
3597:             1             16  sun.net.ExtendedOptionsImpl$$Lambda$253/1943122657
3598:             1             16  sun.net.www.protocol.file.Handler
3599:             1             16  sun.net.www.protocol.jar.JarFileFactory
3600:             1             16  sun.nio.ch.EPollSelectorProvider
3601:             1             16  sun.nio.ch.ExtendedSocketOption$1
3602:             1             16  sun.nio.ch.FileChannelImpl$1
3603:             1             16  sun.nio.ch.Net$1
3604:             1             16  sun.nio.ch.Util$1
3605:             1             16  sun.nio.fs.LinuxFileSystemProvider
3606:             1             16  sun.reflect.GeneratedConstructorAccessor12
3607:             1             16  sun.reflect.GeneratedConstructorAccessor18
3608:             1             16  sun.reflect.GeneratedMethodAccessor10
3609:             1             16  sun.reflect.GeneratedMethodAccessor11
3610:             1             16  sun.reflect.GeneratedMethodAccessor12
3611:             1             16  sun.reflect.GeneratedMethodAccessor13
3612:             1             16  sun.reflect.GeneratedMethodAccessor14
3613:             1             16  sun.reflect.GeneratedMethodAccessor15
3614:             1             16  sun.reflect.GeneratedMethodAccessor6
3615:             1             16  sun.reflect.GeneratedMethodAccessor7
3616:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor36
3617:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor37
3618:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor38
3619:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor39
3620:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor40
3621:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor41
3622:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor42
3623:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor43
3624:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor44
3625:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor45
3626:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor46
3627:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor47
3628:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor49
3629:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor50
3630:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor51
3631:             1             16  sun.reflect.GeneratedSerializationConstructorAccessor52
3632:             1             16  sun.reflect.ReflectionFactory
3633:             1             16  sun.reflect.generics.tree.BooleanSignature
3634:             1             16  sun.reflect.generics.tree.BottomSignature
3635:             1             16  sun.reflect.generics.tree.VoidDescriptor
3636:             1             16  sun.rmi.registry.RegistryImpl$$Lambda$8/817299424
3637:             1             16  sun.rmi.registry.RegistryImpl$$Lambda$9/2031951755
3638:             1             16  sun.rmi.registry.RegistryImpl_Skel
3639:             1             16  sun.rmi.registry.RegistryImpl_Stub
3640:             1             16  sun.rmi.runtime.Log$LoggerLogFactory
3641:             1             16  sun.rmi.runtime.RuntimeUtil
3642:             1             16  sun.rmi.server.LoaderHandler$2
3643:             1             16  sun.rmi.server.UnicastServerRef$HashToMethod_Maps
3644:             1             16  sun.rmi.transport.DGCImpl$$Lambda$6/516537656
3645:             1             16  sun.rmi.transport.DGCImpl$2$$Lambda$7/1023268896
3646:             1             16  sun.rmi.transport.DGCImpl_Skel
3647:             1             16  sun.rmi.transport.DGCImpl_Stub
3648:             1             16  sun.rmi.transport.Target$$Lambda$339/2000963151
3649:             1             16  sun.rmi.transport.proxy.RMIDirectSocketFactory
3650:             1             16  sun.rmi.transport.tcp.TCPTransport$1
3651:             1             16  sun.security.rsa.RSAKeyFactory
3652:             1             16  sun.security.ssl.EphemeralKeyManager
3653:             1             16  sun.security.util.ByteArrayLexOrder
3654:             1             16  sun.security.util.ByteArrayTagOrder
3655:             1             16  sun.text.normalizer.NormalizerBase$Mode
3656:             1             16  sun.text.normalizer.NormalizerBase$NFCMode
3657:             1             16  sun.text.normalizer.NormalizerBase$NFDMode
3658:             1             16  sun.text.normalizer.NormalizerBase$NFKCMode
3659:             1             16  sun.text.normalizer.NormalizerBase$NFKDMode
3660:             1             16  sun.util.calendar.Gregorian
3661:             1             16  sun.util.locale.provider.AuxLocaleProviderAdapter$NullProvider
3662:             1             16  sun.util.locale.provider.CalendarDataUtility$CalendarWeekParameterGetter
3663:             1             16  sun.util.locale.provider.SPILocaleProviderAdapter
3664:             1             16  sun.util.resources.LocaleData
3665:             1             16  sun.util.resources.LocaleData$LocaleDataResourceBundleControl
Total     119374210     4034601936
{code}

"
CASSANDRA-14092,Max ttl of 20 years will overflow localDeletionTime,"CASSANDRA-4771 added a max value of 20 years for ttl to protect against [year 2038 overflow bug|https://en.wikipedia.org/wiki/Year_2038_problem] for {{localDeletionTime}}.

It turns out that next year the {{localDeletionTime}} will start overflowing with the maximum ttl of 20 years ({{System.currentTimeMillis() + ttl(20 years) > Integer.MAX_VALUE}}), so we should remove this limitation."
CASSANDRA-14088,Forward slash in role name breaks CassandraAuthorizer,"The standard system authorizer ({{org.apache.cassandra.auth.CassandraAuthorizer}}) stores the permissions granted to each user for a given resource in {{system_auth.role_permissions}}.

A resource like the {{my_keyspace.items}} table is stored as {{""data/my_keyspace/items""}} (note the {{/}} delimiter).

Similarly, role resources (like the {{joe}} role) are stored as {{""roles/joe""}}.

The problem is that roles can be created with {{/}} in their names, which confuses the authorizer when the table is queried.

For example,

{code}
$ bin/cqlsh -u cassandra -p cassandra
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 4.0-SNAPSHOT | CQL spec 3.4.5 | Native protocol v4]
Use HELP for help.
cassandra@cqlsh> CREATE ROLE emperor;
cassandra@cqlsh> CREATE ROLE ""ki/ng"";
cassandra@cqlsh> GRANT ALTER ON ROLE ""ki/ng"" TO emperor;
cassandra@cqlsh> LIST ROLES;

 role      | super | login | options
-----------+-------+-------+---------
 cassandra |  True |  True |        {}
   emperor | False | False |        {}
     ki/ng | False | False |        {}

(3 rows)
cassandra@cqlsh> SELECT * FROM system_auth.role_permissions;

 role      | resource      | permissions
-----------+---------------+--------------------------------
   emperor |   roles/ki/ng |                      {'ALTER'}
 cassandra | roles/emperor | {'ALTER', 'AUTHORIZE', 'DROP'}
 cassandra |   roles/ki/ng | {'ALTER', 'AUTHORIZE', 'DROP'}

(3 rows)
cassandra@cqlsh> LIST ALL PERMISSIONS OF emperor;
ServerError: java.lang.IllegalArgumentException: roles/ki/ng is not a valid role resource name
{code}

Here's the backtrace from the server process:

{code}
ERROR [Native-Transport-Requests-1] 2017-12-01 11:07:52,811 QueryMessage.java:129 - Unexpected error during query
java.lang.IllegalArgumentException: roles/ki/ng is not a valid role resource name
        at org.apache.cassandra.auth.RoleResource.fromName(RoleResource.java:101) ~[main/:na]
        at org.apache.cassandra.auth.Resources.fromName(Resources.java:56) ~[main/:na]
        at org.apache.cassandra.auth.CassandraAuthorizer.listPermissionsForRole(CassandraAuthorizer.java:283) ~[main/:na]
        at org.apache.cassandra.auth.CassandraAuthorizer.list(CassandraAuthorizer.java:263) ~[main/:na]
        at org.apache.cassandra.cql3.statements.ListPermissionsStatement.list(ListPermissionsStatement.java:108) ~[main/:na]
        at org.apache.cassandra.cql3.statements.ListPermissionsStatement.execute(ListPermissionsStatement.java:96) ~[main/:na]
        at org.apache.cassandra.cql3.statements.AuthorizationStatement.execute(AuthorizationStatement.java:48) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:207) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:238) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:223) ~[main/:na]
        at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[main/:na]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [main/:na]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [main/:na]
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:38) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:353) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [main/:na]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [main/:na]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]
ERROR [Native-Transport-Requests-1] 2017-12-01 11:07:52,812 ErrorMessage.java:389 - Unexpected exception during request
java.lang.IllegalArgumentException: roles/ki/ng is not a valid role resource name
        at org.apache.cassandra.auth.RoleResource.fromName(RoleResource.java:101) ~[main/:na]
        at org.apache.cassandra.auth.Resources.fromName(Resources.java:56) ~[main/:na]
        at org.apache.cassandra.auth.CassandraAuthorizer.listPermissionsForRole(CassandraAuthorizer.java:283) ~[main/:na]
        at org.apache.cassandra.auth.CassandraAuthorizer.list(CassandraAuthorizer.java:263) ~[main/:na]
        at org.apache.cassandra.cql3.statements.ListPermissionsStatement.list(ListPermissionsStatement.java:108) ~[main/:na]
        at org.apache.cassandra.cql3.statements.ListPermissionsStatement.execute(ListPermissionsStatement.java:96) ~[main/:na]
        at org.apache.cassandra.cql3.statements.AuthorizationStatement.execute(AuthorizationStatement.java:48) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:207) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:238) ~[main/:na]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:223) ~[main/:na]
        at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[main/:na]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [main/:na]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [main/:na]
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:38) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:353) [netty-all-4.1.14.Final.jar:4.1.14.Final]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [main/:na]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [main/:na]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]
{code}"
CASSANDRA-14087,NPE when CAS encounters empty frozen collection,"When a compare-and-set operation specifying an equality criterion with a non-{{null}} value encounters an empty collection ({{null}} cell), the server throws a {{NullPointerException}} and the query fails.

This does not happen for non-frozen collections.

There's a self-contained test case at [github|https://github.com/incub8/cassandra-npe-in-cas].

The stack trace for 3.11.0 is:

{code}
ERROR [Native-Transport-Requests-1] 2017-11-27 12:59:26,924 QueryMessage.java:129 - Unexpected error during query
java.lang.NullPointerException: null
        at org.apache.cassandra.cql3.ColumnCondition$CollectionBound.appliesTo(ColumnCondition.java:546) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.statements.CQL3CasRequest$ColumnsConditions.appliesTo(CQL3CasRequest.java:324) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.statements.CQL3CasRequest.appliesTo(CQL3CasRequest.java:210) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.service.StorageProxy.cas(StorageProxy.java:265) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.statements.ModificationStatement.executeWithCondition(ModificationStatement.java:441) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.statements.ModificationStatement.execute(ModificationStatement.java:416) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:217) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:248) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:233) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.11.0.jar:3.11.0]
        at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_151]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.0.jar:3.11.0]
        at java.lang.Thread.run(Thread.java:748) [na:1.8.0_151]
{code}
"
CASSANDRA-14010,Fix SStable ordering by max timestamp in SinglePartitionReadCommand,"We have a test environment were we drop and create keyspaces and tables several times within a short time frame. Since upgrading from 3.11.0 to 3.11.1, we are seeing a lot of create statements failing. See the logs below:
{code:java}
2017-11-13T14:29:20.037986449Z WARN Directory /tmp/ramdisk/commitlog doesn't exist
2017-11-13T14:29:20.038009590Z WARN Directory /tmp/ramdisk/saved_caches doesn't exist
2017-11-13T14:29:20.094337265Z INFO Initialized prepared statement caches with 10 MB (native) and 10 MB (Thrift)
2017-11-13T14:29:20.805946340Z INFO Initializing system.IndexInfo
2017-11-13T14:29:21.934686905Z INFO Initializing system.batches
2017-11-13T14:29:21.973914733Z INFO Initializing system.paxos
2017-11-13T14:29:21.994550268Z INFO Initializing system.local
2017-11-13T14:29:22.014097194Z INFO Initializing system.peers
2017-11-13T14:29:22.124211254Z INFO Initializing system.peer_events
2017-11-13T14:29:22.153966833Z INFO Initializing system.range_xfers
2017-11-13T14:29:22.174097334Z INFO Initializing system.compaction_history
2017-11-13T14:29:22.194259920Z INFO Initializing system.sstable_activity
2017-11-13T14:29:22.210178271Z INFO Initializing system.size_estimates
2017-11-13T14:29:22.223836992Z INFO Initializing system.available_ranges
2017-11-13T14:29:22.237854207Z INFO Initializing system.transferred_ranges
2017-11-13T14:29:22.253995621Z INFO Initializing system.views_builds_in_progress
2017-11-13T14:29:22.264052481Z INFO Initializing system.built_views
2017-11-13T14:29:22.283334779Z INFO Initializing system.hints
2017-11-13T14:29:22.304110311Z INFO Initializing system.batchlog
2017-11-13T14:29:22.318031950Z INFO Initializing system.prepared_statements
2017-11-13T14:29:22.326547917Z INFO Initializing system.schema_keyspaces
2017-11-13T14:29:22.337097407Z INFO Initializing system.schema_columnfamilies
2017-11-13T14:29:22.354082675Z INFO Initializing system.schema_columns
2017-11-13T14:29:22.384179063Z INFO Initializing system.schema_triggers
2017-11-13T14:29:22.394222027Z INFO Initializing system.schema_usertypes
2017-11-13T14:29:22.414199833Z INFO Initializing system.schema_functions
2017-11-13T14:29:22.427205182Z INFO Initializing system.schema_aggregates
2017-11-13T14:29:22.427228345Z INFO Not submitting build tasks for views in keyspace system as storage service is not initialized
2017-11-13T14:29:22.652838866Z INFO Scheduling approximate time-check task with a precision of 10 milliseconds
2017-11-13T14:29:22.732862906Z INFO Initializing system_schema.keyspaces
2017-11-13T14:29:22.746598744Z INFO Initializing system_schema.tables
2017-11-13T14:29:22.759649011Z INFO Initializing system_schema.columns
2017-11-13T14:29:22.766245435Z INFO Initializing system_schema.triggers
2017-11-13T14:29:22.778716809Z INFO Initializing system_schema.dropped_columns
2017-11-13T14:29:22.791369819Z INFO Initializing system_schema.views
2017-11-13T14:29:22.839141724Z INFO Initializing system_schema.types
2017-11-13T14:29:22.852911976Z INFO Initializing system_schema.functions
2017-11-13T14:29:22.852938112Z INFO Initializing system_schema.aggregates
2017-11-13T14:29:22.869348526Z INFO Initializing system_schema.indexes
2017-11-13T14:29:22.874178682Z INFO Not submitting build tasks for views in keyspace system_schema as storage service is not initialized
2017-11-13T14:29:23.700250435Z INFO Initializing key cache with capacity of 25 MBs.
2017-11-13T14:29:23.724357053Z INFO Initializing row cache with capacity of 0 MBs
2017-11-13T14:29:23.724383599Z INFO Initializing counter cache with capacity of 12 MBs
2017-11-13T14:29:23.724386906Z INFO Scheduling counter cache save to every 7200 seconds (going to save all keys).
2017-11-13T14:29:23.984408710Z INFO Populating token metadata from system tables
2017-11-13T14:29:24.032687075Z INFO Global buffer pool is enabled, when pool is exhausted (max is 125.000MiB) it will allocate on heap
2017-11-13T14:29:24.214123695Z INFO Token metadata:
2017-11-13T14:29:24.304218769Z INFO Completed loading (14 ms; 8 keys) KeyCache cache
2017-11-13T14:29:24.363978406Z INFO No commitlog files found; skipping replay
2017-11-13T14:29:24.364005238Z INFO Populating token metadata from system tables
2017-11-13T14:29:24.394408476Z INFO Token metadata:
2017-11-13T14:29:24.709411652Z INFO Preloaded 0 prepared statements
2017-11-13T14:29:24.719332880Z INFO Cassandra version: 3.11.1
2017-11-13T14:29:24.719355969Z INFO Thrift API version: 20.1.0
2017-11-13T14:29:24.719359443Z INFO CQL supported versions: 3.4.4 (default: 3.4.4)
2017-11-13T14:29:24.719362103Z INFO Native protocol supported versions: 3/v3, 4/v4, 5/v5-beta (default: 4/v4)
2017-11-13T14:29:24.766102400Z INFO Initializing index summary manager with a memory pool size of 25 MB and a resize interval of 60 minutes
2017-11-13T14:29:24.778800183Z INFO Starting Messaging Service on /172.17.0.2:7000 (eth0)
2017-11-13T14:29:24.783832188Z WARN No host ID found, created 62452b7c-33ae-40e6-859c-1d7c803aaea8 (Note: This should happen exactly once per node).
2017-11-13T14:29:24.897281778Z INFO Loading persisted ring state
2017-11-13T14:29:24.904217782Z INFO Starting up server gossip
2017-11-13T14:29:25.003802973Z INFO This node will not auto bootstrap because it is configured to be a seed node.
2017-11-13T14:29:25.047674499Z INFO Generated random tokens. tokens are [-6736304773851341012, 3437071596424929702, 4372058337604769145, -306854781937968525, -4419476154597297006, 4339837665480866486, 2052026232731139893, -5761537575805252593, -4477540978357776290, 6263754683045286998, 3670054894619378302, -4326549778810780939, 7187409938161102814, 7030537377703307755, -2757270254308154659, -1953637968902719055, -7235425703069930259, 7123794193321014835, 349308827967095711, 997472983569031481, 992257140226393205, -4045122629441468253, 4149955653388319941, -3690032393349188278, 3528068129562283633, -5057394127379238561, -4944743272177354946, 1371473468273321389, -2771267888257678908, -2379074055482922854, 8800628062632970014, 6016352719444925532, -6458243637210081043, -7131512441131507433, -6135681286390467242, -7886878247827491401, -3964432859204941604, -7124853795154335905, 4536647221115220987, 4518363137218750861, -3945920538919881061, -8569890499152898728, -2228677668104169495, -4004623128783039030, -6849460601197629451, -1787645289665343374, -9004089114738085395, -8444847561386064840, -7719025430480017932, -5020575591450775929, -3535144847803187721, 7252524597471726426, -2582131369519057623, 3737595811793840609, -7248797595897252845, -7065188032269288840, -6731826791431802176, -2970075663731571587, -2619987499373344925, -2698285069650269138, -8589822844420136511, 2658120945314344720, -3710290429036098141, 134530136452862749, 3703742438909992913, 3460544540911930621, 8673891706698173777, 2853177281247015813, 13977464647778584, 2404057737490125388, -6759648287860184451, 744453319830059045, -688104893800828924, 3356383003502762348, 9054641886966810357, 2317130729058165506, -5810663910204725460, 2577132949237273515, 6326216055185945365, 1376570278575995967, 8758101809469842945, -2892126907778256351, -1716283861287440286, 3040640159143123724, 4243935966006505554, -6827972097309863039, 3055912546894309570, -3992773844369808712, -4717007910267923035, -846198401308205724, -3924870907185309086, 1746803312676010060, 6821355560067598541, -5786385588878319458, 3085551110635941848, 7832310180114101987, -9149254679798945822, 3124836728424468300, -100875121723899324, -7606007094353527325, 270256410769436649, -3016541299722946307, 6864985654287583845, 8465468836551135602, 7372808321676939792, -2815261206329145311, -2044219183173664775, -5342853768228072396, 3636940711408324184, -2772742494800447004, -8420993393273439531, -1530882172522252534, 8236427746033013128, -8939749738449264357, -571957476330656311, 6462994120934510138, -2744633996286755268, 1001793370994802364, 6170004027360887596, 383603396273760626, 184737756504479596, -4799447088893889554, 1038205033737034383, 2078124248957773983, -5177819727898656480, 1588469358432181111, 2476693400197902714, 246839957213783595, -7804622995667946321, 3516202677463047183, 7649126752776473673, -3286662198144050257, 2592926684883421936, 6953901594207876325, 8920684239689152479, -2427878301857439455, -6527468054932471540, -4117125961852289967, -2833593154725933249, 2548273043767381234, -814886098184093796, -1113961241682560435, -8364806058670744019, -86067309810855914, -7325813350040495905, -2651532619332818109, -3028501296208600216, 2638649530375347897, -3870517833780069551, 3770751443844709295, -7272035856681375921, -6750394828506790417, 3368553496734537183, 8516129492713951191, 4435960977618718666, 638690551817702460, -7462842134093200053, -7312636473795422279, 3825550639500258186, -490674188267611204, 8488259904981422083, 4436678791994058329, 5971819389544487212, 5777643219857256454, 6295906877222880293, -6635403410495817577, -7125973103119231247, 2275471188158109929, -6554337501188391642, -4759608795508681126, -7655250005358224912, 9106670136441382451, -9080117178764089351, 5094764588972879219, -3599769156391426161, 6116955962236377408, -1734768840951819839, 7826627278264825770, -2624139016757063818, -4122417151587476614, -6757251857390630385, 2099124804383862824, -3162332634454027278, 4826222794133551270, 9122652158513265055, 1734656138981660315, 972980826344778639, -1746779194020635548, -3426944282250211269, -3857828063692993065, 1895243495321867610, -8828035583443240909, -4705856469629722102, -8519546521146945353, -2150150551733933931, 8281585304878501119, -2775028105733898661, 2087277989579187052, -4016777313261130077, 2747128117959922334, -1398884803916585873, 7188260080368469340, -3880993098463994199, 3574665846011083154, 5260683239918360122, 5817587463499837044, 38978473621576635, 2680910834841463710, 6083561971466189055, 7236937177408808074, -3600112532662592989, -4559800196660261967, 8276688045060113438, 5496539762676760591, -2999626688519766687, 8917068693185637310, 2348378561310644717, 7605443413072783308, 5729359499569394810, -782345069306605591, 1165004403533704355, -8301882560002322767, 2008499890787626408, -6211027251975593898, 7406423735628820605, -3204398339633370684, -7917412446164112725, -106645076087724250, -1186720400780396653, -8676089669972641821, -1970508303671183113, -7283082875075535628, -3469652138221449481, -3310949358194646693, 6449384223770405185, -3602652844861890703, -7845236015467185307, -4548809972889727666, -8898627491921139823, 5187965699546741544, 295363921125698104, -8013235493809339368, -6747271362503076577, 1102625310233591704, -2543233385033476145, -6197912327393001665, 118165474822979356, -4838870266722406438, -5797141823778124932, -1506683916229985698, 9139710449103348665, -1571612701117454805, 8031141543284728427, 8472337544063987034, 3222463867738580103, 8210687258187437204]
2017-11-13T14:29:25.092248590Z INFO Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@3bc5ed95[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[session_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[client, command, session_id, coordinator, request, started_at, duration, parameters],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@1a296ffd[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[session_id],clusteringColumns=[event_id],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[activity, event_id, session_id, source, thread, source_elapsed],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
2017-11-13T14:29:25.394141160Z INFO Not submitting build tasks for views in keyspace system_traces as storage service is not initialized
2017-11-13T14:29:25.408584506Z INFO Initializing system_traces.events
2017-11-13T14:29:25.424314845Z INFO Initializing system_traces.sessions
2017-11-13T14:29:25.483133136Z INFO Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@2884b38b[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[keyspace_name, columnfamily_name],clusteringColumns=[id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, id, coordinator, finished_at, participants, exception_stacktrace, parent_id, range_end, range_begin, exception_message, keyspace_name, started_at, columnfamily_name],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7fcc80b2[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names options requested_ranges successful_ranges]],partitionKeyColumns=[parent_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[requested_ranges, exception_message, keyspace_name, successful_ranges, started_at, finished_at, options, exception_stacktrace, parent_id, columnfamily_names],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7e500004[cfId=5582b59f-8e4e-35e1-b913-3acada51eb04,ksName=system_distributed,cfName=view_build_status,flags=[COMPOUND],params=TableParams{comment=Materialized View build status, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UUIDType),partitionColumns=[[] | [status]],partitionKeyColumns=[keyspace_name, view_name],clusteringColumns=[host_id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[view_name, status, keyspace_name, host_id],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
2017-11-13T14:29:25.598604284Z INFO Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized
2017-11-13T14:29:25.602132560Z INFO Initializing system_distributed.parent_repair_history
2017-11-13T14:29:25.624580018Z INFO Initializing system_distributed.repair_history
2017-11-13T14:29:25.624605811Z INFO Initializing system_distributed.view_build_status
2017-11-13T14:29:25.682205208Z INFO JOINING: Finish joining ring
2017-11-13T14:29:25.808448539Z INFO Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@3c28c0da[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[role],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[salted_hash, member_of, role, can_login, is_superuser],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@2e0f771e[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[role],clusteringColumns=[member],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, member],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@4fabdebb[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[role],clusteringColumns=[resource],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, resource, permissions],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7103b8de[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[resource],clusteringColumns=[role],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
2017-11-13T14:29:25.934019252Z INFO Not submitting build tasks for views in keyspace system_auth as storage service is not initialized
2017-11-13T14:29:25.953887674Z INFO Initializing system_auth.resource_role_permissons_index
2017-11-13T14:29:25.957358898Z INFO Initializing system_auth.role_members
2017-11-13T14:29:25.967935061Z INFO Initializing system_auth.role_permissions
2017-11-13T14:29:25.995449692Z INFO Initializing system_auth.roles
2017-11-13T14:29:26.193856408Z INFO Netty using native Epoll event loop
2017-11-13T14:29:26.247676724Z INFO Using Netty Version: [netty-buffer=netty-buffer-4.0.44.Final.452812a, netty-codec=netty-codec-4.0.44.Final.452812a, netty-codec-haproxy=netty-codec-haproxy-4.0.44.Final.452812a, netty-codec-http=netty-codec-http-4.0.44.Final.452812a, netty-codec-socks=netty-codec-socks-4.0.44.Final.452812a, netty-common=netty-common-4.0.44.Final.452812a, netty-handler=netty-handler-4.0.44.Final.452812a, netty-tcnative=netty-tcnative-1.1.33.Fork26.142ecbb, netty-transport=netty-transport-4.0.44.Final.452812a, netty-transport-native-epoll=netty-transport-native-epoll-4.0.44.Final.452812a, netty-transport-rxtx=netty-transport-rxtx-4.0.44.Final.452812a, netty-transport-sctp=netty-transport-sctp-4.0.44.Final.452812a, netty-transport-udt=netty-transport-udt-4.0.44.Final.452812a]
2017-11-13T14:29:26.247705469Z INFO Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...
2017-11-13T14:29:26.309591159Z INFO Not starting RPC server as requested. Use JMX (StorageService->startRPCServer()) or nodetool (enablethrift) to start it
2017-11-13T14:29:36.275846037Z INFO Created default superuser role 'cassandra'
2017-11-13T14:29:40.333918591Z INFO Create new Keyspace: KeyspaceMetadata{name=my_keyspace, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
2017-11-13T14:29:40.434399612Z INFO Create new table: org.apache.cassandra.config.CFMetaData@c74a94b[cfId=1572b410-c87f-11e7-9db1-6d2c86545d91,ksName=my_keyspace,cfName=schema_version,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [migration_lock version]],partitionKeyColumns=[id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.Int32Type,columnMetadata=[migration_lock, version, id],droppedColumns={},triggers=[],indexes=[]]
2017-11-13T14:29:40.566922871Z INFO Initializing my_keyspace.schema_version
2017-11-13T14:29:42.719380089Z INFO Drop Keyspace 'my_keyspace'
2017-11-13T14:29:43.124510221Z INFO Create new Keyspace: KeyspaceMetadata{name=my_keyspace, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
2017-11-13T14:29:43.243928493Z INFO Create new table: org.apache.cassandra.config.CFMetaData@1a0616e9[cfId=171e8f50-c87f-11e7-9db1-6d2c86545d91,ksName=my_keyspace,cfName=schema_version,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [migration_lock version]],partitionKeyColumns=[id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.Int32Type,columnMetadata=[migration_lock, version, id],droppedColumns={},triggers=[],indexes=[]]
2017-11-13T14:29:43.284700491Z INFO Initializing my_keyspace.schema_version
2017-11-13T14:29:44.706916652Z INFO Drop Keyspace 'my_keyspace'
2017-11-13T14:29:44.924446999Z INFO Create new Keyspace: KeyspaceMetadata{name=my_keyspace, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
2017-11-13T14:29:44.993983743Z INFO Create new table: org.apache.cassandra.config.CFMetaData@7338ccab[cfId=182996b0-c87f-11e7-9db1-6d2c86545d91,ksName=my_keyspace,cfName=schema_version,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [migration_lock version]],partitionKeyColumns=[id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.Int32Type,columnMetadata=[migration_lock, version, id],droppedColumns={},triggers=[],indexes=[]]
2017-11-13T14:29:45.078407254Z INFO Initializing my_keyspace.schema_version
2017-11-13T14:29:46.244137923Z INFO Drop Keyspace 'my_keyspace'
2017-11-13T14:29:46.500351100Z INFO Create new Keyspace: KeyspaceMetadata{name=my_keyspace, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
2017-11-13T14:29:46.575419551Z INFO Create new table: org.apache.cassandra.config.CFMetaData@229f3694[cfId=191b97d0-c87f-11e7-9db1-6d2c86545d91,ksName=my_keyspace,cfName=schema_version,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@4c3448a7, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [migration_lock version]],partitionKeyColumns=[id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.Int32Type,columnMetadata=[migration_lock, version, id],droppedColumns={},triggers=[],indexes=[]]
2017-11-13T14:29:46.617101680Z ERROR Unexpected error during query
2017-11-13T14:29:46.617126436Z java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
2017-11-13T14:29:46.617130194Z at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:404) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617133358Z at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:549) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617135966Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:356) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617138576Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:341) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617141018Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:321) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617143454Z at org.apache.cassandra.cql3.statements.CreateTableStatement.announceMigration(CreateTableStatement.java:89) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617145953Z at org.apache.cassandra.cql3.statements.SchemaAlteringStatement.execute(SchemaAlteringStatement.java:93) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617148372Z at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:224) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617150806Z at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:255) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617153201Z at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:240) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617155595Z at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617157962Z at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617160377Z at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617162787Z at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.617166295Z at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.617168898Z at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.617171389Z at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.617173808Z at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
2017-11-13T14:29:46.617184008Z at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617186971Z at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617189340Z at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
2017-11-13T14:29:46.617191666Z Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
2017-11-13T14:29:46.617193951Z at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_131]
2017-11-13T14:29:46.617196258Z at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_131]
2017-11-13T14:29:46.617198553Z at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:400) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617200927Z ... 20 common frames omitted
2017-11-13T14:29:46.617203114Z Caused by: java.lang.NullPointerException: null
2017-11-13T14:29:46.617205382Z at org.apache.cassandra.cql3.UntypedResultSet$Row.getBoolean(UntypedResultSet.java:273) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617207766Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspaceParams(SchemaKeyspace.java:956) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617210107Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:943) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617212462Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesOnly(SchemaKeyspace.java:937) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617214868Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1363) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617217261Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1342) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617220404Z at org.apache.cassandra.service.MigrationManager$1.runMayThrow(MigrationManager.java:567) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617222948Z at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617225287Z at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
2017-11-13T14:29:46.617227589Z at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131]
2017-11-13T14:29:46.617229894Z at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]
2017-11-13T14:29:46.617232175Z at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]
2017-11-13T14:29:46.617234514Z at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.617236990Z ... 1 common frames omitted
2017-11-13T14:29:46.621331936Z ERROR Exception in thread Thread[MigrationStage:1,5,main]
2017-11-13T14:29:46.621360645Z java.lang.NullPointerException: null
2017-11-13T14:29:46.621364339Z at org.apache.cassandra.cql3.UntypedResultSet$Row.getBoolean(UntypedResultSet.java:273) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621373614Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspaceParams(SchemaKeyspace.java:956) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621376363Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:943) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621378927Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesOnly(SchemaKeyspace.java:937) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621381395Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1363) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621384992Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1342) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621387567Z at org.apache.cassandra.service.MigrationManager$1.runMayThrow(MigrationManager.java:567) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621390255Z at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621392722Z at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_131]
2017-11-13T14:29:46.621395153Z at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131]
2017-11-13T14:29:46.621397502Z at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]
2017-11-13T14:29:46.621399919Z at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
2017-11-13T14:29:46.621402347Z at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.621404867Z at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
2017-11-13T14:29:46.626625652Z ERROR Unexpected exception during request
2017-11-13T14:29:46.626650886Z java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException
2017-11-13T14:29:46.626654840Z at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:404) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626658003Z at org.apache.cassandra.service.MigrationManager.announce(MigrationManager.java:549) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626660570Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:356) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626663155Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:341) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626665745Z at org.apache.cassandra.service.MigrationManager.announceNewColumnFamily(MigrationManager.java:321) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626676412Z at org.apache.cassandra.cql3.statements.CreateTableStatement.announceMigration(CreateTableStatement.java:89) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626679497Z at org.apache.cassandra.cql3.statements.SchemaAlteringStatement.execute(SchemaAlteringStatement.java:93) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626682051Z at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:224) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626684610Z at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:255) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626687059Z at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:240) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626689495Z at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:116) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626691956Z at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:517) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626694391Z at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:410) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626696869Z at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.626700811Z at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.626703433Z at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.626705926Z at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
2017-11-13T14:29:46.626708464Z at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
2017-11-13T14:29:46.626710858Z at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:162) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626713448Z at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626715868Z at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
2017-11-13T14:29:46.626718281Z Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
2017-11-13T14:29:46.626720647Z at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_131]
2017-11-13T14:29:46.626723006Z at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_131]
2017-11-13T14:29:46.626725392Z at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:400) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626727820Z ... 20 common frames omitted
2017-11-13T14:29:46.626730100Z Caused by: java.lang.NullPointerException: null
2017-11-13T14:29:46.626735106Z at org.apache.cassandra.cql3.UntypedResultSet$Row.getBoolean(UntypedResultSet.java:273) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626737800Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspaceParams(SchemaKeyspace.java:956) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626740362Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspace(SchemaKeyspace.java:943) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626742804Z at org.apache.cassandra.schema.SchemaKeyspace.fetchKeyspacesOnly(SchemaKeyspace.java:937) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626745273Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1363) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626747719Z at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1342) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626750759Z at org.apache.cassandra.service.MigrationManager$1.runMayThrow(MigrationManager.java:567) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626753445Z at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626755900Z at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_131]
2017-11-13T14:29:46.626758684Z at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131]
2017-11-13T14:29:46.626761055Z at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]
2017-11-13T14:29:46.626763436Z at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]
2017-11-13T14:29:46.626765871Z at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81) ~[apache-cassandra-3.11.1.jar:3.11.1]
2017-11-13T14:29:46.626768418Z ... 1 common frames omitted{code}

Steps to reproduce:
1. Start cassandra
2. Start cqlsh and paste the following in quick succession:
{code:java}
USE system;
DROP KEYSPACE IF EXISTS my_keyspace;
CREATE KEYSPACE my_keyspace WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': 1};
USE my_keyspace;
CREATE TABLE schema_version (id int primary key, version int, migration_lock text);
INSERT INTO schema_version (id, version) values (1, 0);{code}
3. Once fourth time or so , we'll see:
{code:java}
cqlsh:system> CREATE KEYSPACE my_keyspace WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': 1};
ServerError: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException{code}
or
{code:java}
cqlsh:my_keyspace> CREATE TABLE schema_version (id int primary key, version int, migration_lock text);
ServerError: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.NullPointerException{code}"
CASSANDRA-13999,Segfault during memtable flush,"We are getting segfaults on a production Cassandra cluster, apparently caused by Memtable flushes to disk.
{code}
Current thread (0x000000000cd77920):  JavaThread ""PerDiskMemtableFlushWriter_0:140"" daemon [_thread_in_Java, id=28952, stack(0x00007f8b7aa53000,0x00007f8b7aa94000)]
{code}

Stack
{code}
Stack: [0x00007f8b7aa53000,0x00007f8b7aa94000],  sp=0x00007f8b7aa924a0,  free space=253k
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
J 21889 C2 org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(Lorg/apache/cassandra/db/rows/UnfilteredRowIterator;)Lorg/apache/cassandra/db/RowIndexEntry; (361 bytes) @ 0x00007f8e9fcf75ac [0x00007f8e9fcf42c0+0x32ec]
J 22464 C2 org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents()V (383 bytes) @ 0x00007f8e9f17b988 [0x00007f8e9f17b5c0+0x3c8]
j  org.apache.cassandra.db.Memtable$FlushRunnable.call()Lorg/apache/cassandra/io/sstable/SSTableMultiWriter;+1
j  org.apache.cassandra.db.Memtable$FlushRunnable.call()Ljava/lang/Object;+1
J 18865 C2 java.util.concurrent.FutureTask.run()V (126 bytes) @ 0x00007f8e9d3c9540 [0x00007f8e9d3c93a0+0x1a0]
J 21832 C2 java.util.concurrent.ThreadPoolExecutor.runWorker(Ljava/util/concurrent/ThreadPoolExecutor$Worker;)V (225 bytes) @ 0x00007f8e9f16856c [0x00007f8e9f168400+0x16c]
J 6720 C1 java.util.concurrent.ThreadPoolExecutor$Worker.run()V (9 bytes) @ 0x00007f8e9def73c4 [0x00007f8e9def72c0+0x104]
J 22079 C2 java.lang.Thread.run()V (17 bytes) @ 0x00007f8e9e67c4ac [0x00007f8e9e67c460+0x4c]
v  ~StubRoutines::call_stub
V  [libjvm.so+0x691d16]  JavaCalls::call_helper(JavaValue*, methodHandle*, JavaCallArguments*, Thread*)+0x1056
V  [libjvm.so+0x692221]  JavaCalls::call_virtual(JavaValue*, KlassHandle, Symbol*, Symbol*, JavaCallArguments*, Thread*)+0x321
V  [libjvm.so+0x6926c7]  JavaCalls::call_virtual(JavaValue*, Handle, KlassHandle, Symbol*, Symbol*, Thread*)+0x47
V  [libjvm.so+0x72da50]  thread_entry(JavaThread*, Thread*)+0xa0
V  [libjvm.so+0xa76833]  JavaThread::thread_main_inner()+0x103
V  [libjvm.so+0xa7697c]  JavaThread::run()+0x11c
V  [libjvm.so+0x927568]  java_start(Thread*)+0x108
C  [libpthread.so.0+0x7de5]  start_thread+0xc5
{code}

For further details, we attached:
* JVM error file with all details
* cassandra config file (we are using offheap_buffers as memtable_allocation_method)
* some lines printed in debug.log when the JVM error file was created and process died

h5. Reproducing the issue
So far we have been unable to reproduce it. It happens once/twice a week on single nodes. It happens either during high load or low load times. We have seen that when we replace EC2 instances and bootstrap new ones, due to compactions happening on source nodes before stream starts, sometimes more than a single node was affected by this, letting us with 2 out of 3 replicas out and UnavailableExceptions in the cluster.

This issue might have relation with CASSANDRA-12590 (Segfault reading secondary index) even this is the write path. Can someone confirm if both issues could be related? 

h5. Specifics of our scenario:
* Cassandra 3.9 on Amazon Linux (previous to this, we were running Cassandra 2.0.9 and there are no records of this also happening, even I was not working on Cassandra)
* 12 x i3.2xlarge EC2 instances (8 core, 64GB RAM)
* a total of 176 keyspaces (there is a per-customer pattern)
** Some keyspaces have a single table, while others have 2 or 5 tables
** There is a table that uses standard Secondary Indexes (""emailindex"" on ""user_info"" table)
* It happens on both Oracle JDK 1.8.0_112 and 1.8.0_131
* It happens in both kernel 4.9.43-17.38.amzn1.x86_64 and 3.14.35-28.38.amzn1.x86_64


h5. Possible workarounds/solutions that we have in mind (to be validated yet)
* switching to heap_buffers (in case offheap_buffers triggers the bug), even we are still pending to measure performance degradation under that scenario.
* removing secondary indexes in favour of Materialized Views for this specific case, even we are concerned too about the fact that using MVs introduces new issues that may be present in our current Cassandra 3.9
* Upgrading to 3.11.1 is an option, but we are trying to keep it as last resort given that the cost of migrating is big and we don't have any guarantee that new bugs that affects nodes availability are not introduced."
CASSANDRA-13987,Multithreaded commitlog subtly changed durability,"When multithreaded commitlog was introduced in CASSANDRA-3578, we subtly changed the way that commitlog durability worked. Everything still gets written to an mmap file. However, not everything is replayable from the mmaped file after a process crash, in periodic mode.

In brief, the reason this changesd is due to the chained markers that are required for the multithreaded commit log. At each msync, we wait for outstanding mutations to serialize into the commitlog, and update a marker before and after the commits that have accumluated since the last sync. With those markers, we can safely replay that section of the commitlog. Without the markers, we have no guarantee that the commits in that section were successfully written, thus we abandon those commits on replay.

If you have correlated process failures of multiple nodes at ""nearly"" the same time (see [""There Is No Now""|http://queue.acm.org/detail.cfm?id=2745385]), it is possible to have data loss if none of the nodes msync the commitlog. For example, with RF=3, if quorum write succeeds on two nodes (and we acknowledge the write back to the client), and then the process on both nodes OOMs (say, due to reading the index for a 100GB partition), the write will be lost if neither process msync'ed the commitlog. More exactly, the commitlog cannot be fully replayed. The reason why this data is silently lost is due to the chained markers that were introduced with CASSANDRA-3578.

The problem we are addressing with this ticket is incrementally improving 'durability' due to process crash, not host crash. (Note: operators should use batch mode to ensure greater durability, but batch mode in it's current implementation is a) borked, and b) will burn through, *very* rapidly, SSDs that don't have a non-volatile write cache sitting in front.) 

The current default for {{commitlog_sync_period_in_ms}} is 10 seconds, which means that a node could lose up to ten seconds of data due to process crash. The unfortunate thing is that the data is still avaialble, in the mmap file, but we can't replay it due to incomplete chained markers.

ftr, I don't believe we've ever had a stated policy about commitlog durability wrt process crash. Pre-2.0 we naturally piggy-backed off the memory mapped file and the fact that every mutation was acquired a lock and wrote into the mmap buffer, and the ability to replay everything out of it came for free. With CASSANDRA-3578, that was subtly changed. 

Something [~jjirsa] pointed out to me is that [MySQL provides a way to adjust the durability guarantees|https://dev.mysql.com/doc/refman/5.6/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit] of each commit in innodb via the {{innodb_flush_log_at_trx_commit}}. I'm using that idea as a loose springboard for what to do here."
CASSANDRA-13948,Reload compaction strategies when JBOD disk boundary changes,"The thread dump below shows a race between an sstable replacement by the {{IndexSummaryRedistribution}} and {{AbstractCompactionTask.getNextBackgroundTask}}:

{noformat}
Thread 94580: (state = BLOCKED)
 - sun.misc.Unsafe.park(boolean, long) @bci=0 (Compiled frame; information may be imprecise)
 - java.util.concurrent.locks.LockSupport.park(java.lang.Object) @bci=14, line=175 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt() @bci=1, line=836 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireQueued(java.util.concurrent.locks.AbstractQueuedSynchronizer$Node, int) @bci=67, line=870 (Compiled frame)
 - java.util.concurrent.locks.AbstractQueuedSynchronizer.acquire(int) @bci=17, line=1199 (Compiled frame)
 - java.util.concurrent.locks.ReentrantReadWriteLock$WriteLock.lock() @bci=5, line=943 (Compiled frame)
 - org.apache.cassandra.db.compaction.CompactionStrategyManager.handleListChangedNotification(java.lang.Iterable, java.lang.Iterable) @bci=359, line=483 (Interpreted frame)
 - org.apache.cassandra.db.compaction.CompactionStrategyManager.handleNotification(org.apache.cassandra.notifications.INotification, java.lang.Object) @bci=53, line=555 (Interpreted frame)
 - org.apache.cassandra.db.lifecycle.Tracker.notifySSTablesChanged(java.util.Collection, java.util.Collection, org.apache.cassandra.db.compaction.OperationType, java.lang.Throwable) @bci=50, line=409 (Interpreted frame)
 - org.apache.cassandra.db.lifecycle.LifecycleTransaction.doCommit(java.lang.Throwable) @bci=157, line=227 (Interpreted frame)
 - org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.commit(java.lang.Throwable) @bci=61, line=116 (Compiled frame)
 - org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.commit() @bci=2, line=200 (Interpreted frame)
 - org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.finish() @bci=5, line=185 (Interpreted frame)
 - org.apache.cassandra.io.sstable.IndexSummaryRedistribution.redistributeSummaries() @bci=559, line=130 (Interpreted frame)
 - org.apache.cassandra.db.compaction.CompactionManager.runIndexSummaryRedistribution(org.apache.cassandra.io.sstable.IndexSummaryRedistribution) @bci=9, line=1420 (Interpreted frame)
 - org.apache.cassandra.io.sstable.IndexSummaryManager.redistributeSummaries(org.apache.cassandra.io.sstable.IndexSummaryRedistribution) @bci=4, line=250 (Interpreted frame)
 - org.apache.cassandra.io.sstable.IndexSummaryManager.redistributeSummaries() @bci=30, line=228 (Interpreted frame)
 - org.apache.cassandra.io.sstable.IndexSummaryManager$1.runMayThrow() @bci=4, line=125 (Interpreted frame)
 - org.apache.cassandra.utils.WrappedRunnable.run() @bci=1, line=28 (Interpreted frame)
 - org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run() @bci=4, line=118 (Compiled frame)
 - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, line=511 (Compiled frame)
 - java.util.concurrent.FutureTask.runAndReset() @bci=47, line=308 (Compiled frame)
 - java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask) @bci=1, line=180 (Compiled frame)
 - java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run() @bci=37, line=294 (Compiled frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1149 (Compiled frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=624 (Interpreted frame)
 - org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(java.lang.Runnable) @bci=1, line=81 (Interpreted frame)
 - org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$8.run() @bci=4 (Interpreted frame)
 - java.lang.Thread.run() @bci=11, line=748 (Compiled frame)
{noformat}

{noformat}
Thread 94573: (state = IN_JAVA)
 - java.util.HashMap$HashIterator.nextNode() @bci=95, line=1441 (Compiled frame; information may be imprecise)
 - java.util.HashMap$KeyIterator.next() @bci=1, line=1461 (Compiled frame)
 - org.apache.cassandra.db.lifecycle.View$3.apply(org.apache.cassandra.db.lifecycle.View) @bci=20, line=268 (Compiled frame)
 - org.apache.cassandra.db.lifecycle.View$3.apply(java.lang.Object) @bci=5, line=265 (Compiled frame)
 - org.apache.cassandra.db.lifecycle.Tracker.apply(com.google.common.base.Predicate, com.google.common.base.Function) @bci=13, line=133 (Compiled frame)
 - org.apache.cassandra.db.lifecycle.Tracker.tryModify(java.lang.Iterable, org.apache.cassandra.db.compaction.OperationType) @bci=31, line=99 (Compiled frame)
 - org.apache.cassandra.db.compaction.LeveledCompactionStrategy.getNextBackgroundTask(int) @bci=84, line=139 (Compiled frame)
 - org.apache.cassandra.db.compaction.CompactionStrategyManager.getNextBackgroundTask(int) @bci=105, line=119 (Interpreted frame)
 - org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run() @bci=84, line=265 (Interpreted frame)
 - java.util.concurrent.Executors$RunnableAdapter.call() @bci=4, line=511 (Compiled frame)
 - java.util.concurrent.FutureTask.run() @bci=42, line=266 (Compiled frame)
 - java.util.concurrent.ThreadPoolExecutor.runWorker(java.util.concurrent.ThreadPoolExecutor$Worker) @bci=95, line=1149 (Compiled frame)
 - java.util.concurrent.ThreadPoolExecutor$Worker.run() @bci=5, line=624 (Interpreted frame)
 - org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(java.lang.Runnable) @bci=1, line=81 (Interpreted frame)
 - org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$8.run() @bci=4 (Interpreted frame)
 - java.lang.Thread.run() @bci=11, line=748 (Compiled frame)
{noformat}

This particular node remain in this state forever, indicating {{LeveledCompactionStrategyTask.getNextBackgroundTask}} was looping indefinitely.

What happened is that sstable references were replaced on the tracker by the {{IndexSummaryRedistribution}} thread, so the {{AbstractCompactionStrategy.getNextBackgroundTask}} could not create the transaction with the old references, and the {{IndexSummaryRedistribution}} could not update the sstable reference in the compaction strategy because {{AbstractCompactionStrategy.getNextBackgroundTask}} was holding the {{CompactionStrategyManager}} lock."
CASSANDRA-13939,Mishandling of cells for removed/dropped columns when reading legacy files,"The tl;dr is that there is a bug in reading legacy files that can manifests itself with a trace looking like this:
{noformat}
Exception (java.lang.IllegalStateException) encountered during startup: One row required, 2 found
java.lang.IllegalStateException: One row required, 2 found
    at org.apache.cassandra.cql3.UntypedResultSet$FromResultSet.one(UntypedResultSet.java:84)
    at org.apache.cassandra.schema.LegacySchemaMigrator.readTableTimestamp(LegacySchemaMigrator.java:254)
    at org.apache.cassandra.schema.LegacySchemaMigrator.readTable(LegacySchemaMigrator.java:244)
    at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readTables$7(LegacySchemaMigrator.java:238)
    at org.apache.cassandra.schema.LegacySchemaMigrator$$Lambda$126/591203139.accept(Unknown Source)
    at java.util.ArrayList.forEach(ArrayList.java:1249)
    at org.apache.cassandra.schema.LegacySchemaMigrator.readTables(LegacySchemaMigrator.java:238)
    at org.apache.cassandra.schema.LegacySchemaMigrator.readKeyspace(LegacySchemaMigrator.java:187)
    at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readSchema$4(LegacySchemaMigrator.java:178)
    at org.apache.cassandra.schema.LegacySchemaMigrator$$Lambda$123/1612073393.accept(Unknown Source)
    at java.util.ArrayList.forEach(ArrayList.java:1249)
    at org.apache.cassandra.schema.LegacySchemaMigrator.readSchema(LegacySchemaMigrator.java:178)
{noformat}

The reason this can happen has to do with the handling of legacy files. Legacy files are cell based while the 3.0 storage engine is primarily row based, so we group those cells into rows early in the deserialization process (in {{UnfilteredDeserializer.OldFormatDeserializer}}), but in doing so, we can only consider a row finished when we've either reach the end of the partition/file, or when we've read a cell that doesn't belong to that row.  That second case means that when the deserializer returns a given row, the underlying file pointer may actually not positioned at the end of that row, but rather it may be past the first cell of the next row (which the deserializer remembers for future use). Long story short, when we try to detect if we're logically past our current index block in {{AbstractIterator.IndexState#isPastCurrentBlock(}}), we can't simply rely on the file pointer, which again may be a bit more advanced that we logically are, and that's the reason for the ""correction"" in that method. That correction is really just the amount of bytes remembered but not yet used in the deserializer.

That ""correction"" is sometimes wrong however and that's due to the fact that in {{LegacyLayout#readLegacyAtom}}, if we get a cell for an dropped or removed cell, we ignore that cell (which, in itself, is fine). Problem is that this skipping is done within the {{LegacyLayout#readLegacyAtom}} method but without {{UnfilteredDeserializer.OldFormatDeserializer}} knowing about it. As such, the size of the skipped cell ends up being accounted in the ""correction"" bytes for the next cell we read. Lo and behold, if such cell for a removed/dropped column is both the last cell of a CQL row and just before an index boundary (pretty unlikely in general btw, but definitively possible), then the deserializer will count its size with the first cell of the next row, which happens to also be the first cell of the next index block.  And when the code then tries to figure out if it crossed an index boundary, it will over-correct. That is, the {{indexState.updateBlock()}} call at the start of {{SSTableIterator.ForwardIndexedReader#computeNext}} will not work correctly.  This can then make the code return a row that is after the requested slice end (and should thus not be returned) because it doesn't compare that row to said requested end due to thinking it's not on the last index block to read, even though it genuinely is.

Anyway, the whole explanation is a tad complex, but the fix isn't: we need to move the skipping of cells for removed/dropped column a level up so the deserializer knows about it and don't silently count their size in the next atom size."
CASSANDRA-13935,Indexes and UDTs creation should have IF NOT EXISTS on its String representation,"I came across something that bothers me a lot. I'm using snapshots to backup data from my Cassandra cluster in case something really bad happens (like dropping a table or a keyspace).

Exercising the recovery actions from those backups, I discover that the schema put on the file ""schema.cql"" as a result of the snapshot has the ""CREATE IF NOT EXISTS"" for the table, but not for the indexes.

When restoring from snapshots, and relying on the execution of these schemas to build up the table structure, everything seems fine for tables without secondary indexes, but for the ones that make use of them, the execution of these statements fail miserably.

Here I paste a generated schema.cql content for a table with indexes:

CREATE TABLE IF NOT EXISTS keyspace1.table1 (
	id text PRIMARY KEY,
	content text,
	last_update_date date,
	last_update_date_time timestamp)
	WITH ID = f1045fc0-2f59-11e7-95ec-295c3c064920
	AND bloom_filter_fp_chance = 0.01
	AND dclocal_read_repair_chance = 0.1
	AND crc_check_chance = 1.0
	AND default_time_to_live = 8640000
	AND gc_grace_seconds = 864000
	AND min_index_interval = 128
	AND max_index_interval = 2048
	AND memtable_flush_period_in_ms = 0
	AND read_repair_chance = 0.0
	AND speculative_retry = '99PERCENTILE'
	AND caching = { 'keys': 'NONE', 'rows_per_partition': 'NONE' }
	AND compaction = { 'max_threshold': '32', 'min_threshold': '4', 'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy' }
	AND compression = { 'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor' }
	AND cdc = false
	AND extensions = {  };
CREATE INDEX table1_last_update_date_idx ON keyspace1.table1 (last_update_date);

I think the last part should be:

CREATE INDEX IF NOT EXISTS table1_last_update_date_idx ON keyspace1.table1 (last_update_date);

// edit by Stefan Miklosovic

PR: https://github.com/apache/cassandra/pull/731

I have added UDTs as part of this patch as well."
CASSANDRA-13929,BTree$Builder / io.netty.util.Recycler$Stack leaking memory,"Different to CASSANDRA-13754, there seems to be another memory leak in 3.11.0+ in BTree$Builder / io.netty.util.Recycler$Stack.

* heap utilization increase after upgrading to 3.11.0 => cassandra_3.11.0_min_memory_utilization.jpg
* No difference after upgrading to 3.11.1 (snapshot build) => cassandra_3.11.1_snapshot_heaputilization.png; thus most likely after fixing CASSANDRA-13754, more visible now
* MAT shows io.netty.util.Recycler$Stack as top contributing class => cassandra_3.11.1_mat_dominator_classes.png
* With -Xmx8G (CMS) and our load pattern, we have to do a rolling restart after ~ 72 hours

Verified the following fix, namely explicitly unreferencing the _recycleHandle_ member (making it non-final). In _org.apache.cassandra.utils.btree.BTree.Builder.recycle()_
{code}
        public void recycle()
        {
            if (recycleHandle != null)
            {
                this.cleanup();
                builderRecycler.recycle(this, recycleHandle);
                recycleHandle = null; // ADDED
            }
        }
{code}

Patched a single node in our loadtest cluster with this change and after ~ 10 hours uptime, no sign of the previously offending class in MAT anymore => cassandra_3.11.1_mat_dominator_classes_FIXED.png

Can' say if this has any other side effects etc., but I doubt."
CASSANDRA-13897,"nodetool compact and flush fail with ""error: null""","{{nodetool flush}} and {{nodetool compact}} return an error message that is not clear. This could probably be improved. Both of my two nodes return this error.

{{nodetool flush}} Will return this error the first 2-3 times you invoke it, then the error temporarily disappears. {{nodetool compress}} always returns this error message no matter how many times you invoke it.

I have tried deleting saved_caches, commit logs, doing nodetool compact/rebuild/scrub, and nothing seems to remove the error. 

{noformat}
cass@s5:~/apache-cassandra-3.11.0$ nodetool compact
error: null
-- StackTrace --
java.lang.AssertionError
	at org.apache.cassandra.cache.ChunkCache$CachingRebufferer.<init>(ChunkCache.java:222)
	at org.apache.cassandra.cache.ChunkCache.wrap(ChunkCache.java:175)
	at org.apache.cassandra.io.util.FileHandle$Builder.maybeCached(FileHandle.java:412)
	at org.apache.cassandra.io.util.FileHandle$Builder.complete(FileHandle.java:381)
	at org.apache.cassandra.io.util.FileHandle$Builder.complete(FileHandle.java:331)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.openFinal(BigTableWriter.java:333)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.openFinalEarly(BigTableWriter.java:318)
	at org.apache.cassandra.io.sstable.SSTableRewriter.switchWriter(SSTableRewriter.java:322)
	at org.apache.cassandra.io.sstable.SSTableRewriter.doPrepare(SSTableRewriter.java:370)
	at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173)
	at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.doPrepare(CompactionAwareWriter.java:111)
	at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.prepareToCommit(Transactional.java:173)
	at org.apache.cassandra.utils.concurrent.Transactional$AbstractTransactional.finish(Transactional.java:184)
	at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.finish(CompactionAwareWriter.java:121)
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:220)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:85)
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)
	at org.apache.cassandra.db.compaction.CompactionManager$10.runMayThrow(CompactionManager.java:733)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:81)
	at java.lang.Thread.run(Thread.java:748)

{noformat}
"
CASSANDRA-13880,Fix short read protection for tables with no clustering columns,"CASSANDRA-12872 fixed counting replica rows, so that we do now fetch more than one extra row if necessary.

Fixing the issue caused consistency_test.py:TestConsistency.test_13747 to start failing, by exposing a bug in the way we handle empty clusterings.

When {{moreContents()}} asks for another row and {{lastClustering}} is {{EMPTY}}, the response again (and again) contains the row with {{EMPTY}} clustering.

SRP assumes it’s a new row, counts it as one, gets confused and keeps asking for more, in a loop, again and again.

Arguably, a response to a read command with the following non-inclusive {{ClusteringIndexFilter}}:

{code}
command.clusteringIndexFilter(partitionKey).forPaging(metadata.comparator, Clustering.EMPTY, false);
{code}

... should return nothing at all rather than a row with an empty clustering.

Also arguably, SRP should not even attempt to fetch more rows if {{lastClustering == Clustering.EMPTY}}. In a partition key only column
we shouldn’t expect any more rows.

This JIRA is to fix the latter issue on SRP side - to modify SRP logic to short-circuit execution if {{lastClustering}} was an {{EMPTY}} one instead of querying pointlessly for non-existent extra rows."
CASSANDRA-13873,Ref bug in Scrub,"I'm hitting a Ref bug when many scrubs run against a node.  This doesn't happen on 3.0.X.  I'm not sure if/if not this happens with compactions too but I suspect it does.

I'm not seeing any Ref leaks or double frees.

To Reproduce:

{quote}
./tools/bin/cassandra-stress write n=10m -rate threads=100
./bin/nodetool scrub
#Ctrl-C
./bin/nodetool scrub
#Ctrl-C
./bin/nodetool scrub
#Ctrl-C
./bin/nodetool scrub
{quote}

Eventually in the logs you get:
WARN  [RMI TCP Connection(4)-127.0.0.1] 2017-09-14 15:51:26,722 NoSpamLogger.java:97 - Spinning trying to capture readers [BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-5-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-32-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-31-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-29-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-27-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-26-big-Data.db'), BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-20-big-Data.db')],
*released: [BigTableReader(path='/home/jake/workspace/cassandra2/data/data/keyspace1/standard1-2eb5c780998311e79e09311efffdcd17/mc-5-big-Data.db')],* 

This released table has a selfRef of 0 but is in the Tracker
"
CASSANDRA-13869,AbstractTokenTreeBuilder#serializedSize returns wrong value when there is a single leaf and overflow collisions,In the extremely rare case where a small token tree (< 248 values) has overflow collisions the size returned by AbstractTokenTreeBuilder#serializedSize is incorrect because it fails to account for the overflow collisions. 
CASSANDRA-13849,GossipStage blocks because of race in ActiveRepairService,"Bad luck caused a kernel panic in a cluster, and that took another node with it because GossipStage stopped responding.

I think it's pretty obvious what's happening, here are the relevant excerpts from the stack traces :

{noformat}
""Thread-24004"" #393781 daemon prio=5 os_prio=0 tid=0x00007efca9647400 nid=0xe75c waiting on condition [0x00007efaa47fe000]
   java.lang.Thread.State: TIMED_WAITING (parking)
    at sun.misc.Unsafe.park(Native Method)
    - parking to wait for  <0x000000052b63a7e8> (a java.util.concurrent.CountDownLatch$Sync)
    at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1037)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1328)
    at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:277)
    at org.apache.cassandra.service.ActiveRepairService.prepareForRepair(ActiveRepairService.java:332)
    - locked <0x00000002e6bc99f0> (a org.apache.cassandra.service.ActiveRepairService)
    at org.apache.cassandra.repair.RepairRunnable.runMayThrow(RepairRunnable.java:211)
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)                                                                                                           at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
    at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$3/1498438472.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:748)

""GossipTasks:1"" #367 daemon prio=5 os_prio=0 tid=0x00007efc5e971000 nid=0x700b waiting for monitor entry [0x00007dfb839fe000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.cassandra.service.ActiveRepairService.removeParentRepairSession(ActiveRepairService.java:421)
    - waiting to lock <0x00000002e6bc99f0> (a org.apache.cassandra.service.ActiveRepairService)
    at org.apache.cassandra.service.ActiveRepairService.convict(ActiveRepairService.java:776)
    at org.apache.cassandra.gms.FailureDetector.interpret(FailureDetector.java:306)
    at org.apache.cassandra.gms.Gossiper.doStatusCheck(Gossiper.java:775)                                                                                                                at org.apache.cassandra.gms.Gossiper.access$800(Gossiper.java:67)
    at org.apache.cassandra.gms.Gossiper$GossipTask.run(Gossiper.java:187)
    at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:118)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
    at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$3/1498438472.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:748)

""GossipStage:1"" #320 daemon prio=5 os_prio=0 tid=0x00007efc5b9f2c00 nid=0x6fcd waiting for monitor entry [0x00007e260186a000]
   java.lang.Thread.State: BLOCKED (on object monitor)
    at org.apache.cassandra.service.ActiveRepairService.removeParentRepairSession(ActiveRepairService.java:421)
    - waiting to lock <0x00000002e6bc99f0> (a org.apache.cassandra.service.ActiveRepairService)                                                                                          at org.apache.cassandra.service.ActiveRepairService.convict(ActiveRepairService.java:776)
    at org.apache.cassandra.service.ActiveRepairService.onRestart(ActiveRepairService.java:744)
    at org.apache.cassandra.gms.Gossiper.handleMajorStateChange(Gossiper.java:1049)
    at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:1143)
    at org.apache.cassandra.gms.GossipDigestAck2VerbHandler.doVerb(GossipDigestAck2VerbHandler.java:49)
    at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
    at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$3/1498438472.run(Unknown Source)                                                                                       at java.lang.Thread.run(Thread.java:748)
{noformat}

iow, org.apache.cassandra.service.ActiveRepairService.prepareForRepair holds a lock until the repair is prepared, which means waiting for other nodes to respond, which may die at exactly that moment, so they won't complete. Gossip will at the same time try to mark the node as down, but it requires that same lock :)"
CASSANDRA-13808,Integer overflows with Amazon Elastic File System (EFS),"Integer overflow issue was fixed for cassandra 2.2, but in 3.8 new property was introduced in config that also derives from disk size  {{cdc_total_space_in_mb}}, see CASSANDRA-8844

It should be updated too https://github.com/apache/cassandra/blob/6b7d73a49695c0ceb78bc7a003ace606a806c13a/src/java/org/apache/cassandra/config/DatabaseDescriptor.java#L484"
CASSANDRA-13801,CompactionManager sometimes wrongly determines that a background compaction is running for a particular table,"Sometimes after writing different rows to a table, then doing a blocking flush, if you alter the compaction strategy, then run background compaction and wait for it to finish, {{CompactionManager}} may decide that there's an ongoing compaction for that same table.
This may happen even though logs don't indicate that to be the case (compaction may still be running for system_schema tables)."
CASSANDRA-13791,unable to install apache-cassandra-3.11.0 in linux  box,"While  installing the Cassandra in linux serverr,  I am getting below error . could you please look int it and provide suggestions. PFA atttached log for more information.

[cassdb@alsc_dev_db bin]$ sh /u01/Cassandra_home/apache-cassandra-3.11.0/bin/cassandra

Error:

ERROR [main] 2017-08-23 09:48:21,467 NativeLibraryLinux.java:62 - Failed to link the C library against JNA. Native methods will be unavailable.
java.lang.UnsatisfiedLinkError: /tmp/jna--1367560132/jna4859101025087222330.tmp: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /tmp/jna--1367560132/jna4859101025087222330.tmp)
        at java.lang.ClassLoader$NativeLibrary.load(Native Method) ~[na:1.8.0_71]
        at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1938) ~[na:1.8.0_71]
       at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1821) ~[na:1.8.0_71]
        at java.lang.Runtime.load0(Runtime.java:809) ~[na:1.8.0_71]
        at java.lang.System.load(System.java:1086) ~[na:1.8.0_71]
        at com.sun.jna.Native.loadNativeDispatchLibraryFromClasspath(Native.java:947) ~[jna-4.4.0.jar:4.4.0 (b0)]
        at com.sun.jna.Native.loadNativeDispatchLibrary(Native.java:922) ~[jna-4.4.0.jar:4.4.0 (b0)]
        at com.sun.jna.Native.<clinit>(Native.java:190) ~[jna-4.4.0.jar:4.4.0 (b0)]
        at org.apache.cassandra.utils.NativeLibraryLinux.<clinit>(NativeLibraryLinux.java:53) ~[apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.utils.NativeLibrary.<clinit>(NativeLibrary.java:93) [apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:196) [apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:600) [apache-cassandra-3.11.0.jar:3.11.0]
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:689) [apache-cassandra-3.11.0.jar:3.11.0]
WARN  [main] 2017-08-23 09:48:21,468 StartupChecks.java:127 - jemalloc shared library could not be preloaded to speed up memory allocations
WARN  [main] 2017-08-23 09:48:21,469 StartupChecks.java:160 - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
ERROR [main] 2017-08-23 09:48:21,470 CassandraDaemon.java:706 - The native library could not be initialized properly
"
CASSANDRA-13787,RangeTombstoneMarker and PartitionDeletion is not properly included in MV,"Found two problems related to MV tombstone. 

1. Range-tombstone-Marker being ignored after shadowing first row, subsequent base rows are not shadowed in TableViews.

    If the range tombstone was not flushed, it was used as deleted row to shadow new updates. It works correctly.
    After range tombstone was flushed, it was used as RangeTombstoneMarker and being skipped after shadowing first update. The bound of RangeTombstoneMarker seems wrong, it contained full clustering, but it should contain range or it should be multiple RangeTombstoneMarkers for multiple slices(aka. new updates)

-2. Partition tombstone is not used when no existing live data, it will resurrect deleted cells. It was found in 11500 and included in that patch.- (Merged in CASSANDRA-11500)


In order not to make 11500 patch more complicated, I will try fix range/partition tombstone issue here.


{code:title=Tests to reproduce}
    @Test
    public void testExistingRangeTombstoneWithFlush() throws Throwable
    {
        testExistingRangeTombstone(true);
    }

    @Test
    public void testExistingRangeTombstoneWithoutFlush() throws Throwable
    {
        testExistingRangeTombstone(false);
    }

    public void testExistingRangeTombstone(boolean flush) throws Throwable
    {
        createTable(""CREATE TABLE %s (k1 int, c1 int, c2 int, v1 int, v2 int, PRIMARY KEY (k1, c1, c2))"");

        execute(""USE "" + keyspace());
        executeNet(protocolVersion, ""USE "" + keyspace());

        createView(""view1"",
                   ""CREATE MATERIALIZED VIEW view1 AS SELECT * FROM %%s WHERE k1 IS NOT NULL AND c1 IS NOT NULL AND c2 IS NOT NULL PRIMARY KEY (k1, c2, c1)"");

        updateView(""DELETE FROM %s USING TIMESTAMP 10 WHERE k1 = 1 and c1=1"");


        if (flush)
            Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()).forceBlockingFlush();

        String table = KEYSPACE + ""."" + currentTable();
        updateView(""BEGIN BATCH "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 0, 0, 0, 0) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 0, 1, 0, 1) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 1, 0, 1, 0) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 1, 1, 1, 1) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 1, 2, 1, 2) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 1, 3, 1, 3) USING TIMESTAMP 5; "" +
                ""INSERT INTO "" + table + "" (k1, c1, c2, v1, v2) VALUES (1, 2, 0, 2, 0) USING TIMESTAMP 5; "" +
                ""APPLY BATCH"");

        assertRowsIgnoringOrder(execute(""select * from %s""),
                                row(1, 0, 0, 0, 0),
                                row(1, 0, 1, 0, 1),
                                row(1, 2, 0, 2, 0));
        assertRowsIgnoringOrder(execute(""select k1,c1,c2,v1,v2 from view1""),
                                row(1, 0, 0, 0, 0),
                                row(1, 0, 1, 0, 1),
                                row(1, 2, 0, 2, 0));
    }

    @Test
    public void testExistingParitionDeletionWithFlush() throws Throwable
    {
        testExistingParitionDeletion(true);
    }

    @Test
    public void testExistingParitionDeletionWithoutFlush() throws Throwable
    {
        testExistingParitionDeletion(false);
    }

    public void testExistingParitionDeletion(boolean flush) throws Throwable
    {
        // for partition range deletion, need to know that existing row is shadowed instead of not existed.
        createTable(""CREATE TABLE %s (a int, b int, c int, d int, PRIMARY KEY (a))"");

        execute(""USE "" + keyspace());
        executeNet(protocolVersion, ""USE "" + keyspace());

        createView(""mv_test1"",
                   ""CREATE MATERIALIZED VIEW %s AS SELECT * FROM %%s WHERE a IS NOT NULL AND b IS NOT NULL PRIMARY KEY (a, b)"");

        Keyspace ks = Keyspace.open(keyspace());
        ks.getColumnFamilyStore(""mv_test1"").disableAutoCompaction();

        execute(""INSERT INTO %s (a, b, c, d) VALUES (?, ?, ?, ?) using timestamp 0"", 1, 1, 1, 1);
        if (flush)
            FBUtilities.waitOnFutures(ks.flush());

        assertRowsIgnoringOrder(execute(""SELECT * FROM mv_test1""), row(1, 1, 1, 1));

        // remove view row
        updateView(""UPDATE %s using timestamp 1 set b = null WHERE a=1"");
        if (flush)
            FBUtilities.waitOnFutures(ks.flush());

        assertRowsIgnoringOrder(execute(""SELECT * FROM mv_test1""));
        // remove base row, no view updated generated.
        updateView(""DELETE FROM %s using timestamp 2 where a=1"");
        if (flush)
            FBUtilities.waitOnFutures(ks.flush());

        assertRowsIgnoringOrder(execute(""SELECT * FROM mv_test1""));

        // restor view row with b,c column. d is still tombstone
        updateView(""UPDATE %s using timestamp 3 set b = 1,c = 1 where a=1""); // upsert
        if (flush)
            FBUtilities.waitOnFutures(ks.flush());

        assertRowsIgnoringOrder(execute(""SELECT * FROM mv_test1""), row(1, 1, 1, null));
    }
{code}"
CASSANDRA-13782,Cassandra RPM has wrong owner for /usr/share directories,"Some Cassandra RPM directories are owned by cassandra user against the fedora package guidelines.

Offending lines: https://github.com/apache/cassandra/blob/trunk/redhat/cassandra.spec#L135-L136

""Permissions on files MUST be set properly. Inside of /usr, files should be owned by root:root unless a more specific user or group is needed for security.""
- https://fedoraproject.org/wiki/Packaging:Guidelines?rd=Packaging/Guidelines#File_Permissions"
CASSANDRA-13776,Adding a field to an UDT can corrupte the tables using it,"Adding a field to an UDT which is used as a {{Set}} element or as a {{Map}} element can corrupt the table.
The problem can be reproduced using the following test case:
{code}
    @Test
    public void testReadAfterAlteringUserTypeNestedWithinSet() throws Throwable
    {
        String ut1 = createType(""CREATE TYPE %s (a int)"");
        String columnType = KEYSPACE + ""."" + ut1;

        try
        {
            createTable(""CREATE TABLE %s (x int PRIMARY KEY, y set<frozen<"" + columnType + "">>)"");
            disableCompaction();

            execute(""INSERT INTO %s (x, y) VALUES(1, ?)"", set(userType(1), userType(2)));
            assertRows(execute(""SELECT * FROM %s""), row(1, set(userType(1), userType(2))));
            flush();

            assertRows(execute(""SELECT * FROM %s WHERE x = 1""),
                       row(1, set(userType(1), userType(2))));

            execute(""ALTER TYPE "" + KEYSPACE + ""."" + ut1 + "" ADD b int"");
            execute(""UPDATE %s SET y = y + ? WHERE x = 1"",
                    set(userType(1, 1), userType(1, 2), userType(2, 1)));

            flush();
            assertRows(execute(""SELECT * FROM %s WHERE x = 1""),
                           row(1, set(userType(1),
                                      userType(1, 1),
                                      userType(1, 2),
                                      userType(2),
                                      userType(2, 1))));

            compact();

            assertRows(execute(""SELECT * FROM %s WHERE x = 1""),
                       row(1, set(userType(1),
                                  userType(1, 1),
                                  userType(1, 2),
                                  userType(2),
                                  userType(2, 1))));
        }
        finally
        {
            enableCompaction();
        }
    }
{code} 

There are in fact 2 problems:
# When the {{sets}} from the 2 versions are merged the {{ColumnDefinition}} being picked up can be the older one. In which case when the tuples are sorted it my lead to an {{IndexOutOfBoundsException}}.
# During compaction, the old column definition can be the one being kept for the SSTable metadata. If it is the case the SSTable will not be readable any more and will be marked as {{corrupted}}.

If one of the tables using the type has a Materialized View attached to it, the MV updates can also fail with {{IndexOutOfBoundsException}}.

This problem can be reproduced using the following test:
{code}
    @Test
    public void testAlteringUserTypeNestedWithinSetWithView() throws Throwable
    {
        String columnType = typeWithKs(createType(""CREATE TYPE %s (a int)""));

        createTable(""CREATE TABLE %s (pk int, c int, v int, s set<frozen<"" + columnType + "">>, PRIMARY KEY (pk, c))"");
        execute(""CREATE MATERIALIZED VIEW "" + keyspace() + "".view1 AS SELECT c, pk, v FROM %s WHERE pk IS NOT NULL AND c IS NOT NULL AND v IS NOT NULL PRIMARY KEY (c, pk)"");

        execute(""INSERT INTO %s (pk, c, v, s) VALUES(?, ?, ?, ?)"", 1, 1, 1, set(userType(1), userType(2)));
        flush();

        execute(""ALTER TYPE "" + columnType + "" ADD b int"");
        execute(""UPDATE %s SET s = s + ?, v = ? WHERE pk = ? AND c = ?"",
                set(userType(1, 1), userType(1, 2), userType(2, 1)), 2, 1, 1);


        assertRows(execute(""SELECT * FROM %s WHERE pk = ? AND c = ?"", 1, 1),
                       row(1, 1, 2, set(userType(1),
                                        userType(1, 1),
                                        userType(1, 2),
                                        userType(2),
                                        userType(2, 1))));
    }
{code}      "
CASSANDRA-13756,StreamingHistogram is not thread safe,"When we test C*3 in shadow cluster, we notice after a period of time, several data node suddenly run into 100% cpu and stop process query anymore.

After investigation, we found that threads are stuck on the sum() in streaminghistogram class. Those are jmx threads that working on expose getTombStoneRatio metrics (since jmx is kicked off every 3 seconds, there is a chance that multiple jmx thread is access streaminghistogram at the same time).  

After further investigation, we find that the optimization in CASSANDRA-13038 led to a spool flush every time when we call sum(). Since TreeMap is not thread safe, threads will be stuck when multiple threads visit sum() at the same time.

There are two approaches to solve this issue. 

The first one is to add a lock to the flush in sum() which will introduce some extra overhead to streaminghistogram.

The second one is to avoid streaminghistogram to be access by multiple threads. For our specific case, is to remove the metrics we added.  "
CASSANDRA-13754,BTree.Builder memory leak,"After a chronic bout of {{OutOfMemoryError}} in our development environment, a heap analysis is showing that more than 10G of our 12G heaps are consumed by the {{threadLocals}} members (instances of {{java.lang.ThreadLocalMap}}) of various {{io.netty.util.concurrent.FastThreadLocalThread}} instances.  Reverting [cecbe17|https://git-wip-us.apache.org/repos/asf?p=cassandra.git;a=commit;h=cecbe17e3eafc052acc13950494f7dddf026aa54] fixes the issue."
CASSANDRA-13740,Orphan hint file gets created while node is being removed from cluster,"I have found this new issue during my test, whenever node is being removed then hint file for that node gets written and stays inside the hint directory forever. I debugged the code and found that it is due to the race condition between [HintsWriteExecutor.java::flush | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsWriteExecutor.java#L195] and [HintsWriteExecutor.java::closeWriter | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsWriteExecutor.java#L106]
. 
 
*Time t1* Node is down, as a result Hints are being written by [HintsWriteExecutor.java::flush | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsWriteExecutor.java#L195]
*Time t2* Node is removed from cluster as a result it calls [HintsService.java-exciseStore | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsService.java#L327] which removes hint files for the node being removed
*Time t3* Mutation stage keeps pumping Hints through [HintService.java::write | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsService.java#L145] which again calls [HintsWriteExecutor.java::flush | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsWriteExecutor.java#L215] and new orphan file gets created

I was writing a new dtest for {CASSANDRA-13562, CASSANDRA-13308} and that helped me reproduce this new bug. I will submit patch for this new dtest later.

I also tried following to check how this orphan hint file responds:
1. I tried {{nodetool truncatehints <node>}} but it fails as node is no longer part of the ring
2. I then tried {{nodetool truncatehints}}, that still doesn’t remove hint file because it is not yet included in the [dispatchDequeue | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsStore.java#L53]


Reproducible steps:
Please find dTest python file {{gossip_hang_test.py}} attached which reproduces this bug.

Solution:
This is due to race condition as mentioned above. Since {{HintsWriteExecutor.java}} creates thread pool with only 1 worker, so solution becomes little simple. Whenever we [HintService.java::excise | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsService.java#L303] a host, just store it in-memory, and check for already evicted host inside [HintsWriteExecutor.java::flush | https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/hints/HintsWriteExecutor.java#L215]. If already evicted host is found then ignore hints.

Jaydeep"
CASSANDRA-13700,Heartbeats can cause gossip information to go permanently missing on certain nodes,"In {{Gossiper.getStateForVersionBiggerThan}}, we add the {{HeartBeatState}} from the corresponding {{EndpointState}} to the {{EndpointState}} to send. When we're getting state for ourselves, this means that we add a reference to the local {{HeartBeatState}}. Then, once we've built a message (in either the Syn or Ack handler), we send it through the {{MessagingService}}. In the case that the {{MessagingService}} is sufficiently slow, the {{GossipTask}} may run before serialization of the Syn or Ack. This means that when the {{GossipTask}} acquires the gossip {{taskLock}}, it may increment the {{HeartBeatState}} version of the local node as stored in the endpoint state map. Then, when we finally serialize the Syn or Ack, we'll follow the reference to the {{HeartBeatState}} and serialize it with a higher version than we saw when constructing the Ack or Ack2.

Consider the case where we see {{HeartBeatState}} with version 4 when constructing an Ack and send it through the {{MessagingService}}. Then, we add some piece of state with version 5 to our local {{EndpointState}}. If {{GossipTask}} runs and increases the {{HeartBeatState}} version to 6 before the {{MessageOut}} containing the Ack is serialized, the node receiving the Ack will believe it is current to version 6, despite the fact that it has never received a message containing the {{ApplicationState}} tagged with version 5.

I've reproduced in this in several versions; so far, I believe this is possible in all versions."
CASSANDRA-13694,sstabledump does not show full precision of timestamp columns,"Create a table:

CREATE TABLE test_table (
    unit_no bigint,
    event_code text,
    active_time timestamp,
    ack_time timestamp,
    PRIMARY KEY ((unit_no, event_code), active_time)
) WITH CLUSTERING ORDER BY (active_time DESC)

Insert a row:

INSERT INTO test_table (unit_no, event_code, active_time, ack_time)
                  VALUES (1234, 'TEST EVENT', toTimestamp(now()), toTimestamp(now()));

Verify that it is in the database with a full timestamp:

cqlsh:pentaho> select * from test_table;

 unit_no | event_code | active_time                     | ack_time
---------+------------+---------------------------------+---------------------------------
    1234 | TEST EVENT | 2017-07-14 14:52:39.919000+0000 | 2017-07-14 14:52:39.919000+0000

(1 rows)


Write file:

nodetool flush
nodetool compact pentaho

Use sstabledump:

treeves@ubuntu:~$ sstabledump /var/lib/cassandra/data/pentaho/test_table-99ba228068a311e7ac30953b79ac2c3e/mb-2-big-Data.db
[
  {
    ""partition"" : {
      ""key"" : [ ""1234"", ""TEST EVENT"" ],
      ""position"" : 0
    },
    ""rows"" : [
      {
        ""type"" : ""row"",
        ""position"" : 38,
        ""clustering"" : [ ""2017-07-14 15:52+0100"" ],
        ""liveness_info"" : { ""tstamp"" : ""2017-07-14T14:52:39.888701Z"" },
        ""cells"" : [
          { ""name"" : ""ack_time"", ""value"" : ""2017-07-14 15:52+0100"" }
        ]
      }
    ]
  }
]

treeves@ubuntu:~$ 

The timestamp in the cluster key, and the regular column, are both truncated to the minute.
"
CASSANDRA-13691,Fix incorrect [2.1 <— 3.0] serialization of counter cells with pre-2.1 local shards,"We stopped generating local shards in C* 2.1, after CASSANDRA-6504 (Counters 2.0). But it’s still possible to have counter cell values
around, remaining from 2.0 times, on 2.1, 3.0, 3.11, and even trunk nodes, if they’ve never been overwritten.

In 2.1, we used two classes for two kinds of counter columns:
{{CounterCell}} class to store counters - internally as collections of {{CounterContext}} blobs, encoding collections of (host id, count, clock) tuples
{{CounterUpdateCell}} class to represent unapplied increments - essentially a single long value; this class was never written to commit log, memtables, or sstables, and was only used inside {{Mutation}} object graph - in memory, and marshalled over network in cases when counter write coordinator and counter write leader were different nodes
3.0 got rid of {{CounterCell}} and {{CounterUpdateCell}}, among other {{Cell}} classes. In order to represent these unapplied increments - equivalents of 2.1 {{CounterUpdateCell}} - in 3.0 we encode them as regular counter columns, with a ‘special’ {{CounterContext}} value. I.e. a counter context with a single local shard. We do that so that we can reuse local shard reconcile logic (summing up) to seamlessly support counters with same names collapsing to single increments in batches. See {{UpdateParameters.addCounter()}} method comments [here|https://github.com/apache/cassandra/blob/cassandra-3.0.14/src/java/org/apache/cassandra/cql3/UpdateParameters.java#L157-L171] for details. It also assumes that nothing else can generate a counter with local shards.

It works fine in pure 3.0 clusters, and in mixed 2.1/3.0 clusters, assuming that there are no counters with legacy local shards remaining from 2.0 era. It breaks down badly if there are.

{{LegacyLayout.serializeAsLegacyPartition()}} and consequently {{LegacyCell.isCounterUpdate()}} - classes responsible for serializing and deserialising in 2.1 format for compatibility - use the following logic to tell if a cell of {{COUNTER}} kind is a regular final counter or an unapplied increment:

{code}
private boolean isCounterUpdate()
{
    // See UpdateParameters.addCounter() for more details on this
    return isCounter() && CounterContext.instance().isLocal(value);
}
{code}

{{CounterContext.isLocal()}} method here looks at the first shard of the collection of tuples and returns true if it’s a local one.

This method would correctly identify a cell generated by {{UpdateParameters.addCounter()}} as a counter update and serialize it correctly as a 2.1 {{CounterUpdateCell}}. However, it would also incorrectly flag any regular counter cell that just so happens to have a local shard as the first tuple of the counter context as a counter update. If a 2.1 node as a coordinator of a read requests fetches such a value from a 3.0 node, during a rolling upgrade, instead of the expected {{CounterCell}} object it will receive a {{CounterUpdateCell}}, breaking all the things. In the best case scenario it will cause an assert in {{AbstractCell.reconcileCounter()}} to be raised.

To fix the problem we must find an unambiguous way, without false positives or false negatives, to represent and identify unapplied counter updates on 3.0 side. "
CASSANDRA-13669,Error when starting cassandra: Unable to make UUID from 'aa' (SASI index),"Recently I experienced a problem that prevents me to restart cassandra.
I narrowed it down to SASI Index when added on uuid field.



Steps to reproduce:
1. start cassandra (./bin/cassandra -f)
2. create keyspace, table, index and add data:

{noformat}
CREATE KEYSPACE testkeyspace
WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'} 
           AND durable_writes = true;

use testkeyspace ;

CREATE TABLE testtable (
   col1 uuid,
   col2 uuid,
   ts timeuuid,
   col3 uuid,
   PRIMARY KEY((col1, col2), ts) ) with clustering order by (ts desc);

CREATE CUSTOM INDEX col3_testtable_idx ON testtable(col3)
USING 'org.apache.cassandra.index.sasi.SASIIndex'
WITH OPTIONS = {'analyzer_class': 'org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer', 'mode': 'PREFIX'};

INSERT INTO testtable(col1, col2, ts, col3)
VALUES(898e0014-6161-11e7-b9b7-238ea83bd70b,
               898e0014-6161-11e7-b9b7-238ea83bd70b,
               now(), 898e0014-6161-11e7-b9b7-238ea83bd70b);
{noformat}

3. restart cassandra

It crashes with an error (sorry it's huge):
{noformat}
DEBUG 09:09:20 Writing Memtable-testtable@1005362073(0.075KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
ERROR 09:09:20 Exception in thread Thread[PerDiskMemtableFlushWriter_0:1,5,main]
org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at org.apache.cassandra.db.marshal.UUIDType.fromString(UUIDType.java:118) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer.hasNext(StandardAnalyzer.java:168) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.add(PerSSTableIndexWriter.java:208) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.lambda$nextUnfilteredCluster$0(PerSSTableIndexWriter.java:132) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.Collections$SingletonSet.forEach(Collections.java:4767) ~[na:1.8.0_131]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.nextUnfilteredCluster(PerSSTableIndexWriter.java:119) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnIndex.lambda$add$1(ColumnIndex.java:233) ~[apache-cassandra-3.9.jar:3.9]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_131]
	at org.apache.cassandra.db.ColumnIndex.add(ColumnIndex.java:233) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnIndex.buildRowIndex(ColumnIndex.java:107) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:169) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.append(SimpleSSTableMultiWriter.java:48) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:458) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:493) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:380) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Exception (java.lang.RuntimeException) encountered during startup: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at org.apache.cassandra.utils.Throwables.maybeFail(Throwables.java:51)
ERROR 09:09:20 Exception encountered during startup
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at org.apache.cassandra.utils.Throwables.maybeFail(Throwables.java:51) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:391) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.commitlog.CommitLogReplayer.blockForWrites(CommitLogReplayer.java:168) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.commitlog.CommitLog.recoverFiles(CommitLog.java:188) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:167) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:323) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:601) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730) [apache-cassandra-3.9.jar:3.9]
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_131]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_131]
	at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:384) ~[apache-cassandra-3.9.jar:3.9]
	... 6 common frames omitted
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at org.apache.cassandra.utils.Throwables.maybeFail(Throwables.java:51) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:391) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1122) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1084) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_131]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_131]
	at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:384) ~[apache-cassandra-3.9.jar:3.9]
	... 5 common frames omitted
Caused by: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
	at org.apache.cassandra.db.marshal.UUIDType.fromString(UUIDType.java:118) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer.hasNext(StandardAnalyzer.java:168) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.add(PerSSTableIndexWriter.java:208) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.lambda$nextUnfilteredCluster$0(PerSSTableIndexWriter.java:132) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.Collections$SingletonSet.forEach(Collections.java:4767) ~[na:1.8.0_131]
	at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.nextUnfilteredCluster(PerSSTableIndexWriter.java:119) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnIndex.lambda$add$1(ColumnIndex.java:233) ~[apache-cassandra-3.9.jar:3.9]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_131]
	at org.apache.cassandra.db.ColumnIndex.add(ColumnIndex.java:233) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnIndex.buildRowIndex(ColumnIndex.java:107) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:169) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.append(SimpleSSTableMultiWriter.java:48) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:458) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:493) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:380) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_131]
	... 3 common frames omitted
at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:391)
at org.apache.cassandra.db.commitlog.CommitLogReplayer.blockForWrites(CommitLogReplayer.java:168)
at org.apache.cassandra.db.commitlog.CommitLog.recoverFiles(CommitLog.java:188)
at org.apache.cassandra.db.commitlog.CommitLog.recoverSegmentsOnDisk(CommitLog.java:167)
at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:323)
at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:601)
at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730)
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:384)
... 6 more
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at org.apache.cassandra.utils.Throwables.maybeFail(Throwables.java:51)
at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:391)
at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1122)
at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1084)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.ExecutionException: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at java.util.concurrent.FutureTask.report(FutureTask.java:122)
at java.util.concurrent.FutureTask.get(FutureTask.java:192)
at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:384)
... 5 more
Caused by: org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at org.apache.cassandra.db.marshal.UUIDType.fromString(UUIDType.java:118)
at org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer.hasNext(StandardAnalyzer.java:168)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.add(PerSSTableIndexWriter.java:208)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.lambda$nextUnfilteredCluster$0(PerSSTableIndexWriter.java:132)
at java.util.Collections$SingletonSet.forEach(Collections.java:4767)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.nextUnfilteredCluster(PerSSTableIndexWriter.java:119)
at org.apache.cassandra.db.ColumnIndex.lambda$add$1(ColumnIndex.java:233)
at java.lang.Iterable.forEach(Iterable.java:75)
at org.apache.cassandra.db.ColumnIndex.add(ColumnIndex.java:233)
at org.apache.cassandra.db.ColumnIndex.buildRowIndex(ColumnIndex.java:107)
at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:169)
at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.append(SimpleSSTableMultiWriter.java:48)
at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:458)
at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:493)
at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:380)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
... 3 more
{noformat}

When I do ""nodetool flush"" I also get:
{noformat}
$  ./bin/nodetool flush
objc[35941]: Class JavaLaunchHelper is implemented in both /Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/bin/java (0x1052a34c0) and /Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre/lib/libinstrument.dylib (0x10536b4e0). One of the two will be used. Which one is undefined.
error: Unable to make UUID from 'aa'
-- StackTrace --
org.apache.cassandra.serializers.MarshalException: Unable to make UUID from 'aa'
at org.apache.cassandra.db.marshal.UUIDType.fromString(UUIDType.java:118)
at org.apache.cassandra.index.sasi.analyzer.StandardAnalyzer.hasNext(StandardAnalyzer.java:168)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter$Index.add(PerSSTableIndexWriter.java:208)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.lambda$nextUnfilteredCluster$0(PerSSTableIndexWriter.java:132)
at java.util.Collections$SingletonSet.forEach(Collections.java:4767)
at org.apache.cassandra.index.sasi.disk.PerSSTableIndexWriter.nextUnfilteredCluster(PerSSTableIndexWriter.java:119)
at org.apache.cassandra.db.ColumnIndex.lambda$add$1(ColumnIndex.java:233)
at java.lang.Iterable.forEach(Iterable.java:75)
at org.apache.cassandra.db.ColumnIndex.add(ColumnIndex.java:233)
at org.apache.cassandra.db.ColumnIndex.buildRowIndex(ColumnIndex.java:107)
at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:169)
at org.apache.cassandra.io.sstable.SimpleSSTableMultiWriter.append(SimpleSSTableMultiWriter.java:48)
at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:458)
at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:493)
at org.apache.cassandra.db.Memtable$FlushRunnable.call(Memtable.java:380)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:748)
{noformat}

Any ideas how to solve it?
I can keep col3 as text, I figured it out, but I already have bunch of data on production and I basically can't do anything with any of nodes, because I won't be able to start them again.

Thanks,
Lukasz"
CASSANDRA-13666,Secondary index query on partition key columns might not return partitions with only static data,"The problem can be reproduced with the following test in {{3.0}}:
{code}
   @Test
    public void testIndexOnPartitionKeyWithPartitionWithoutRows() throws Throwable
    {
        createTable(""CREATE TABLE %s (pk1 int, pk2 int, c int, s int static, v int, PRIMARY KEY((pk1, pk2), c))"");
        createIndex(""CREATE INDEX ON %s (pk2)"");

        execute(""INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)"", 1, 1, 1, 9, 1);
        execute(""INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)"", 1, 1, 2, 9, 2);
        execute(""INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)"", 3, 1, 1, 9, 1);
        execute(""INSERT INTO %s (pk1, pk2, c, s, v) VALUES (?, ?, ?, ?, ?)"", 4, 1, 1, 9, 1);
        flush();

        assertRows(execute(""SELECT * FROM %s WHERE pk2 = ?"", 1),
                   row(1, 1, 1, 9, 1),
                   row(1, 1, 2, 9, 2),
                   row(3, 1, 1, 9, 1),
                   row(4, 1, 1, 9, 1));

        execute(""DELETE FROM %s WHERE pk1 = ? AND pk2 = ? AND c = ?"", 3, 1, 1);

        assertRows(execute(""SELECT * FROM %s WHERE pk2 = ?"", 1),
                   row(1, 1, 1, 9, 1),
                   row(1, 1, 2, 9, 2),
                   row(3, 1, null, 9, null),  // This row will not be returned
                   row(4, 1, 1, 9, 1));
    }
{code}

The problem seems to be that the index entries for the static data are inserted with an empty clustering key. When the first {{SELECT}} is executed those entries are removed by {{CompositesSearcher::filterStaleEntries}} which consider that those entries are stales. When the second {{SELECT}} is executed the index ignore the (3, 1) partition as there is not entry for it anymore."
CASSANDRA-13652,Deadlock in AbstractCommitLogSegmentManager,"AbstractCommitLogManager uses LockSupport.(un)park incorreclty. It invokes unpark without checking if manager thread was parked in approriate place. 
For example, logging frameworks uses queues and queues uses ReadWriteLock's that uses LockSupport. Therefore AbstractCommitLogManager.wakeManager can wake thread inside Lock and manager thread will sleep forever at park() method (because unpark permit was already consumed inside lock).

For examle stack traces:
{code}
""MigrationStage:1"" id=412 state=WAITING
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
    at org.apache.cassandra.utils.concurrent.WaitQueue$AbstractSignal.awaitUninterruptibly(WaitQueue.java:279)
    at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.awaitAvailableSegment(AbstractCommitLogSegmentManager.java:263)
    at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.advanceAllocatingFrom(AbstractCommitLogSegmentManager.java:237)
    at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager.forceRecycleAll(AbstractCommitLogSegmentManager.java:279)
    at org.apache.cassandra.db.commitlog.CommitLog.forceRecycleAllSegments(CommitLog.java:210)
    at org.apache.cassandra.config.Schema.dropView(Schema.java:708)
    at org.apache.cassandra.schema.SchemaKeyspace.lambda$updateKeyspace$23(SchemaKeyspace.java:1361)
    at org.apache.cassandra.schema.SchemaKeyspace$$Lambda$382/1123232162.accept(Unknown Source)
    at java.util.LinkedHashMap$LinkedValues.forEach(LinkedHashMap.java:608)
    at java.util.Collections$UnmodifiableCollection.forEach(Collections.java:1080)
    at org.apache.cassandra.schema.SchemaKeyspace.updateKeyspace(SchemaKeyspace.java:1361)
    at org.apache.cassandra.schema.SchemaKeyspace.mergeSchema(SchemaKeyspace.java:1332)
    at org.apache.cassandra.schema.SchemaKeyspace.mergeSchemaAndAnnounceVersion(SchemaKeyspace.java:1282)
      - locked java.lang.Class@cc38904
    at org.apache.cassandra.db.DefinitionsUpdateVerbHandler$1.runMayThrow(DefinitionsUpdateVerbHandler.java:51)
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
    at org.apache.cassandra.concurrent.DebuggableThreadPoolExecutor$LocalSessionWrapper.run(DebuggableThreadPoolExecutor.java:322)
    at com.ringcentral.concurrent.executors.MonitoredRunnable.run(MonitoredRunnable.java:36)
    at MON_R_MigrationStage.run(NamedRunnableFactory.java:67)
    at com.ringcentral.concurrent.executors.MonitoredThreadPoolExecutor$MdcAwareRunnable.run(MonitoredThreadPoolExecutor.java:114)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
    at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$61/1733339045.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)

""COMMIT-LOG-ALLOCATOR:1"" id=80 state=WAITING
    at sun.misc.Unsafe.park(Native Method)
    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
    at org.apache.cassandra.db.commitlog.AbstractCommitLogSegmentManager$1.runMayThrow(AbstractCommitLogSegmentManager.java:128)
    at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
    at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
    at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$61/1733339045.run(Unknown Source)
    at java.lang.Thread.run(Thread.java:745)
{code}

Solution is to use Semaphore instead of low-level LockSupport."
CASSANDRA-13622,Better config validation/documentation,"There are a number of properties in the yaml that are ""in_mb"", however resolve to bytes when calculated in {{DatabaseDescriptor.java}}, but are stored in int's. This means that their maximum values are 2047, as any higher when converted to bytes overflows the int.

Where possible/reasonable we should convert these to be long's, and stored as long's. If there is no reason for the value to ever be >2047 we should at least document that as the max value, or better yet make it error if set higher than that. Noting that although it's bad practice to increase a lot of them to such high values, there may be cases where it is necessary and in which case we should handle it appropriately rather than overflowing and surprising the user. That is, causing it to break but not in the way the user expected it to :)

Following are functions that currently could be at risk of the above:

{code:java|title=DatabaseDescriptor.java}
getThriftFramedTransportSize()
getMaxValueSize()
getCompactionLargePartitionWarningThreshold()
getCommitLogSegmentSize()
getNativeTransportMaxFrameSize()
# These are in KB so max value of 2096128
getBatchSizeWarnThreshold()
getColumnIndexSize()
getColumnIndexCacheSize()
getMaxMutationSize()
{code}

Note we may not actually need to fix all of these, and there may be more. This was just from a rough scan over the code."
CASSANDRA-13619,java.nio.BufferOverflowException: null while flushing hints,"I'm seeing the following exception running Cassandra 3.0.11 on 21 node cluster in two AWS regions when half of the nodes in one region go down, and the load is high on the rest of the nodes:

{code}
WARN  [SharedPool-Worker-10] 2017-06-14 12:57:15,017 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[SharedPool-Worker-10,5,main]: {}
java.lang.RuntimeException: java.nio.BufferOverflowException
        at org.apache.cassandra.service.StorageProxy$HintRunnable.run(StorageProxy.java:2549) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0-zing_17.03.1.0]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.11.jar:3.0.11]
        at java.lang.Thread.run(Thread.java:745) [na:1.8.0-zing_17.03.1.0]
Caused by: java.nio.BufferOverflowException: null
        at org.apache.cassandra.io.util.DataOutputBufferFixed.doFlush(DataOutputBufferFixed.java:52) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.io.util.BufferedDataOutputStreamPlus.write(BufferedDataOutputStreamPlus.java:195) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.io.util.BufferedDataOutputStreamPlus.writeUnsignedVInt(BufferedDataOutputStreamPlus.java:258) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.utils.ByteBufferUtil.writeWithVIntLength(ByteBufferUtil.java:296) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.Columns$Serializer.serialize(Columns.java:405) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.SerializationHeader$Serializer.serializeForMessaging(SerializationHeader.java:407) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:120) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer.serialize(UnfilteredRowIteratorSerializer.java:87) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.serialize(PartitionUpdate.java:625) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.db.Mutation$MutationSerializer.serialize(Mutation.java:305) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.hints.Hint$Serializer.serialize(Hint.java:141) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.hints.HintsBuffer$Allocation.write(HintsBuffer.java:251) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.hints.HintsBuffer$Allocation.write(HintsBuffer.java:230) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.hints.HintsBufferPool.write(HintsBufferPool.java:61) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.hints.HintsService.write(HintsService.java:154) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.service.StorageProxy$11.runMayThrow(StorageProxy.java:2627) ~[apache-cassandra-3.0.11.jar:3.0.11]
        at org.apache.cassandra.service.StorageProxy$HintRunnable.run(StorageProxy.java:2545) ~[apache-cassandra-3.0.11.jar:3.0.11]
        ... 5 common frames omitted
{code}

Relevant configurations from cassandra.yaml:

{code}
-cassandra_hinted_handoff_throttle_in_kb: 1024
 cassandra_max_hints_delivery_threads: 4
-cassandra_hints_flush_period_in_ms: 10000
-cassandra_max_hints_file_size_in_mb: 512
{code}

When I reduce -cassandra_hints_flush_period_in_ms: 10000 to 5000, the number of exceptions lowers significantly, but they are still present."
CASSANDRA-13600,sstabledump possible problem,"h2. Possible bug in sstabledump

{noformat}
cqlsh> show version
[cqlsh 5.0.1 | Cassandra 3.10 | CQL spec 3.4.4 | Native protocol v4]
{noformat}

h2. Execute script in cqlsh in new keyspace

{noformat}
CREATE TABLE IF NOT EXISTS test_data (   
    // partitioning key
    PK TEXT, 

    // data
    Data TEXT,
    
    PRIMARY KEY (PK)
);

insert into test_data(PK,Data) values('0','aaaa');
insert into test_data(PK,Data) values('1','bbbb');
insert into test_data(PK,Data) values('2','cccc');
delete from test_data where PK='1';
insert into test_data(PK,Data) values('1','dddd');
{noformat}

h2. Execute the following commands

{noformat}
nodetool flush
nodetool compact
sstabledump mc-2-big-Data.db
sstabledump -d mc-2-big-Data.db
{noformat}

h3. default dump - missing data for partiotion key = ""1""

{noformat}
[
  {
    ""partition"" : {
      ""key"" : [ ""0"" ],
      ""position"" : 0
    },
    ""rows"" : [
      {
        ""type"" : ""row"",
        ""position"" : 15,
        ""liveness_info"" : { ""tstamp"" : ""2017-06-14T12:23:13.529389Z"" },
        ""cells"" : [
          { ""name"" : ""data"", ""value"" : ""aaaa"" }
        ]
      }
    ]
  },
  {
    ""partition"" : {
      ""key"" : [ ""2"" ],
      ""position"" : 26
    },
    ""rows"" : [
      {
        ""type"" : ""row"",
        ""position"" : 41,
        ""liveness_info"" : { ""tstamp"" : ""2017-06-14T12:23:13.544132Z"" },
        ""cells"" : [
          { ""name"" : ""data"", ""value"" : ""cccc"" }
        ]
      }
    ]
  },
  {
    ""partition"" : {
      ""key"" : [ ""1"" ],
      ""position"" : 53,
      ""deletion_info"" : { ""marked_deleted"" : ""2017-06-14T12:23:13.545988Z"", ""local_delete_time"" : ""2017-06-14T12:23:13Z"" }
    }
  }
]
{noformat}

h3. dump with -d option - correct data for partiotion key = ""1""

{noformat}
[0]@0 Row[info=[ts=1497442993529389] ]:  | [data=aaaa ts=1497442993529389]
[2]@26 Row[info=[ts=1497442993544132] ]:  | [data=cccc ts=1497442993544132]
[1]@53 deletedAt=1497442993545988, localDeletion=1497442993
[1]@53 Row[info=[ts=1497442993550159] ]:  | [data=dddd ts=1497442993550159]
{noformat}
"
CASSANDRA-13595,Implement short read protection on partition boundaries,"It seems that short read protection doesn't work when the short read is done at the end of a partition in a range query. The final assertion of this dtest fails:
{code}
def short_read_partitions_delete_test(self):
        cluster = self.cluster
        cluster.set_configuration_options(values={'hinted_handoff_enabled': False})
        cluster.set_batch_commitlog(enabled=True)
        cluster.populate(2).start(wait_other_notice=True)
        node1, node2 = self.cluster.nodelist()

        session = self.patient_cql_connection(node1)
        create_ks(session, 'ks', 2)
        session.execute(""CREATE TABLE t (k int, c int, PRIMARY KEY(k, c)) WITH read_repair_chance = 0.0"")

        # we write 1 and 2 in a partition: all nodes get it.
        session.execute(SimpleStatement(""INSERT INTO t (k, c) VALUES (1, 1)"", consistency_level=ConsistencyLevel.ALL))
        session.execute(SimpleStatement(""INSERT INTO t (k, c) VALUES (2, 1)"", consistency_level=ConsistencyLevel.ALL))

        # we delete partition 1: only node 1 gets it.
        node2.flush()
        node2.stop(wait_other_notice=True)
        session = self.patient_cql_connection(node1, 'ks', consistency_level=ConsistencyLevel.ONE)
        session.execute(SimpleStatement(""DELETE FROM t WHERE k = 1""))
        node2.start(wait_other_notice=True)

        # we delete partition 2: only node 2 gets it.
        node1.flush()
        node1.stop(wait_other_notice=True)
        session = self.patient_cql_connection(node2, 'ks', consistency_level=ConsistencyLevel.ONE)
        session.execute(SimpleStatement(""DELETE FROM t WHERE k = 2""))
        node1.start(wait_other_notice=True)

        # read from both nodes
        session = self.patient_cql_connection(node1, 'ks', consistency_level=ConsistencyLevel.ALL)
        assert_none(session, ""SELECT * FROM t LIMIT 1"")
{code}
However, the dtest passes if we remove the {{LIMIT 1}}.

Short read protection [uses a {{SinglePartitionReadCommand}}|https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/DataResolver.java#L484], maybe it should use a {{PartitionRangeReadCommand}} instead?"
CASSANDRA-13592,Null Pointer exception at SELECT JSON statement,"A Nulll pointer exception appears when the command

{code}
SELECT JSON * FROM examples.basic;

---MORE---
<Error from server: code=0000 [Server error] message=""java.lang.NullPointerException"">

Examples.basic has the following description (DESC examples.basic;):
CREATE TABLE examples.basic (
    key frozen<tuple<uuid, int>> PRIMARY KEY,
    wert text
) WITH bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.1
    AND default_time_to_live = 0
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';
{code}

The error appears after the ---MORE--- line.

The field ""wert"" has a JSON formatted string."
CASSANDRA-13587,Deadlock during CommitLog replay when Cassandra restarts,"Possible deadlock found when Cassandra is replaying commit log and at the same time Mutation gets triggered by SSTableReader(SystemKeyspace.persistSSTableReadMeter). As a result Cassandra restart hangs forever

Please find details of stack trace here:

*Frame#1* This thread is trying to apply {{persistSSTableReadMeter}} mutation and as a result it has called {{writeOrder.start()}} in {{Keyspace.java:533}}
but there are no Commitlog Segments available because {{createReserveSegments (CommitLogSegmentManager.java)}} is not yet {{true}} 

Hence this thread is blocked on {{createReserveSegments}} to become {{true}}, please note this thread has already started {{writeOrder}}

{quote}
""pool-11-thread-1"" #251 prio=5 os_prio=0 tid=0x00007fe128478400 nid=0x1b274 waiting on condition [0x00007fe1389a0000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at org.apache.cassandra.utils.concurrent.WaitQueue$AbstractSignal.awaitUninterruptibly(WaitQueue.java:279)
        at org.apache.cassandra.db.commitlog.CommitLogSegmentManager.advanceAllocatingFrom(CommitLogSegmentManager.java:277)
        at org.apache.cassandra.db.commitlog.CommitLogSegmentManager.allocate(CommitLogSegmentManager.java:196)
        at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:260)
        at org.apache.cassandra.db.Keyspace.applyInternal(Keyspace.java:540)
        at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:421)
        at org.apache.cassandra.db.Mutation.apply(Mutation.java:210)
        at org.apache.cassandra.db.Mutation.apply(Mutation.java:215)
        at org.apache.cassandra.db.Mutation.apply(Mutation.java:224)
        at org.apache.cassandra.cql3.statements.ModificationStatement.executeInternalWithoutCondition(ModificationStatement.java:566)
        at org.apache.cassandra.cql3.statements.ModificationStatement.executeInternal(ModificationStatement.java:556)
        at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:295)
        at org.apache.cassandra.db.SystemKeyspace.persistSSTableReadMeter(SystemKeyspace.java:1181)
        at org.apache.cassandra.io.sstable.format.SSTableReader$GlobalTidy$1.run(SSTableReader.java:2202)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)
{quote}

*Frame#2* This thread is trying to recover commit logs and as a result it tries to flush Memtable by calling following code:
{{futures.add(Keyspace.open(SystemKeyspace.NAME).getColumnFamilyStore(SystemKeyspace.BATCHES).forceFlush());}}
As a result Frame#3 (below) gets created

{quote}
""main"" #1 prio=5 os_prio=0 tid=0x00007fe1c64ec400 nid=0x1af29 waiting on condition [0x00007fe1c94a1000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
parking to wait for  <0x00000006370da0c0> (a com.google.common.util.concurrent.ListenableFutureTask)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429)
        at java.util.concurrent.FutureTask.get(FutureTask.java:191)
        at org.apache.cassandra.utils.FBUtilities.waitOnFutures(FBUtilities.java:383)
        at org.apache.cassandra.db.commitlog.CommitLogReplayer.blockForWrites(CommitLogReplayer.java:207)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:182)
        at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:161)
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:295)
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:569)
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:697)
{quote}

*Frame#3* This thread is waiting at {{writeBarrier.await();}} in {{ColumnFamilyStore.java:1027}} 
but {{writeBarrier}} is locked by thread in Frame#1, and Frame#1 thread is waiting for more CommitlogSegements to be available. 
Frame#1 thread will not get new segment because variable {{createReserveSegments(CommitLogSegmentManager.java)}} is not yet {{true}}. 
This variable gets set to {{true}} after successful execution of Frame#2.

Here we can see Frame#3 and Frame#1 are in deadlock state and Cassandra restart hangs forever.
 
{quote}
""MemtableFlushWriter:5"" #433 daemon prio=5 os_prio=0 tid=0x00007e7a4b8b0400 nid=0x1dea8 waiting on condition [0x00007e753c2ca000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at org.apache.cassandra.utils.concurrent.WaitQueue$AbstractSignal.awaitUninterruptibly(WaitQueue.java:279)
        at org.apache.cassandra.utils.concurrent.OpOrder$Barrier.await(OpOrder.java:419)
        at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1027)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
        at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$4/1527007086.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:745)


""MemtablePostFlush:3"" #432 daemon prio=5 os_prio=0 tid=0x00007e7a4b8b0000 nid=0x1dea7 waiting on condition [0x00007e753c30b000]
   java.lang.Thread.State: WAITING (parking)
        at sun.misc.Unsafe.park(Native Method)
 parking to wait for  <0x00000006370d9cd0> (a java.util.concurrent.CountDownLatch$Sync)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
        at org.apache.cassandra.db.ColumnFamilyStore$PostFlush.call(ColumnFamilyStore.java:941)
        at org.apache.cassandra.db.ColumnFamilyStore$PostFlush.call(ColumnFamilyStore.java:924)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
        at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$4/1527007086.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:745)
{quote}

*Reproducible steps*: Reproducing this problem is tricky as it involves multiple conditions to happen at the same time and is timing bases, so I have done some small code change to reproduce this:
1. Create a Keyspace and table
2. Inject data until there are few SSTables generated and CommitLog available
3. Kill Cassandra process
4. Use the custom code (in the attached file ""Reproduce_CASSANDRA-13587.txt"") on top of 3.0.14 branch 
5. Build Cassandra jar and use this custom jar
6. Restart Cassandra
    Here you will see Cassandra is hanging forever
7. Now apply this fix on top of ""Reproduce_CASSANDRA-13587.txt"", and repeat step-6
    Here you should see Cassandra is starting normally

*Solution*: I am proposing that we should enable variable {{createReserveSegments(CommitLogSegmentManager.java)}} before recovering any CommitLogs in CommitLog.java file
so this will not block Frame#1 from acquiring new segment as a result Frame#1 will finish and then Frame#2 will also finish.
Please note, this variable {{createReserveSegments}} has been removed from the trunk branch as part of (https://issues.apache.org/jira/browse/CASSANDRA-10202), also in the trunk branch CommitLog segments gets created when needed. So as per my understanding enabling this variable before CommitLog recovery should not create any other side effect, please let me know your comments.
"
CASSANDRA-13559,Schema version id mismatch while upgrading to 3.0.13,"As the order of SchemaKeyspace is changed ([6991556 | https://github.com/apache/cassandra/commit/6991556e431a51575744248a4c484270c4f918c9], CASSANDRA-12213), the result of function [{{calculateSchemaDigest}}|https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/schema/SchemaKeyspace.java#L311] is also changed for the same schema. Which causes schema mismatch while upgrading 3.0.x -> 3.0.13.
It could cause cassandra fail to start because Unknown CF exception. And streaming will fail:
{noformat}
ERROR [main] 2017-05-26 18:58:57,572 CassandraDaemon.java:709 - Exception encountered during startup
java.lang.IllegalArgumentException: Unknown CF 83c8eae0-3a65-11e7-9a27-e17fd11571e3
{noformat}
{noformat}
WARN  [MessagingService-Incoming-/IP] 2017-05-26 19:27:11,523 IncomingTcpConnection.java:101 - UnknownColumnFamilyException reading from socket; closing
org.apache.cassandra.db.UnknownColumnFamilyException: Couldn't find table for cfId 922b7940-3a65-11e7-adf3-a3ff55d9bcf1. If a table was just created, this is likely due to the schema not being fully propagated.  Please wait for schema agreement on table creation.
{noformat}

Restart the new node will cause:
{noformat}
Exception (java.lang.NoSuchFieldError) encountered during startup: ALL
java.lang.NoSuchFieldError: ALL
        at org.apache.cassandra.service.ClientState.<clinit>(ClientState.java:67)
        at org.apache.cassandra.cql3.QueryProcessor$InternalStateInstance.<init>(QueryProcessor.java:155)
        at org.apache.cassandra.cql3.QueryProcessor$InternalStateInstance.<clinit>(QueryProcessor.java:149)
        at org.apache.cassandra.cql3.QueryProcessor.internalQueryState(QueryProcessor.java:163)
        at org.apache.cassandra.cql3.QueryProcessor.prepareInternal(QueryProcessor.java:286)
        at org.apache.cassandra.cql3.QueryProcessor.executeInternal(QueryProcessor.java:294)
        at org.apache.cassandra.db.SystemKeyspace.checkHealth(SystemKeyspace.java:900)
        at org.apache.cassandra.service.StartupChecks$9.execute(StartupChecks.java:354)
        at org.apache.cassandra.service.StartupChecks.verify(StartupChecks.java:110)
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:179)
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:569)
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:697)
{noformat}

I would suggest to have the older list back for digest calculation and release 3.0.14."
CASSANDRA-13557,allow different NUMACTL_ARGS to be passed in,"Currently in bin/cassandra the following is hardcoded:
NUMACTL_ARGS=""--interleave=all""
Ideally users of cassandra/bin could pass in a different set of NUMACTL_ARGS if they wanted to say bind the process to a socket for cpu/memory reasons, rather than having to comment out/modify this line in the deployed cassandra/bin. e.g as described in:
https://tobert.github.io/pages/als-cassandra-21-tuning-guide.html

This could be done by just having the default be set to ""--interleave=all"" but pickup any value which has already been set for the variable NUMACTL_ARGS."
CASSANDRA-13533,ColumnIdentifier object size wrong when tables are not flushed,"It turns out that the object size of {{ColumnIdentifier}} is wrong when *cassandra.test.flush_local_schema_changes: false*. This looks like stuff is being wrongly reused when no flush is happening.

We only noticed this because we were using the prepared stmt cache and noticed that prepared statements would account for *1-6mb* when *cassandra.test.flush_local_schema_changes: false*. With *cassandra.test.flush_local_schema_changes: true* (which is the default) those would be around *5000 bytes*.

Attached is a test that reproduces the problem and also a fix.

Also after talking to [~jkni] / [~blerer] we shouldn't probably take {{ColumnDefinition}} into account when measuring object sizes with {{MemoryMeter}}
"
CASSANDRA-13464,Failed to create Materialized view with a specific token range,"Failed to create Materialized view with a specific token range.

Example :

{code:java}
$ ccm create ""MaterializedView"" -v 3.0.13
$ ccm populate  -n 3
$ ccm start
$ ccm status
Cluster: 'MaterializedView'
---------------------------
node1: UP
node3: UP
node2: UP
$ccm node1 cqlsh
Connected to MaterializedView at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 3.0.13 | CQL spec 3.4.0 | Native protocol v4]
Use HELP for help.
cqlsh> CREATE KEYSPACE test WITH replication = {'class':'SimpleStrategy', 'replication_factor':3};
cqlsh> CREATE TABLE test.test ( id text PRIMARY KEY , value1 text , value2 text, value3 text);

$ccm node1 ring test 
Datacenter: datacenter1
==========
Address    Rack        Status State   Load            Owns                Token
                                                                          3074457345618258602
127.0.0.1  rack1       Up     Normal  64.86 KB        100.00%             -9223372036854775808
127.0.0.2  rack1       Up     Normal  86.49 KB        100.00%             -3074457345618258603
127.0.0.3  rack1       Up     Normal  89.04 KB        100.00%             3074457345618258602

$ ccm node1 cqlsh
cqlsh> INSERT INTO test.test (id, value1 , value2, value3 ) VALUES ('aaa', 'aaa', 'aaa' ,'aaa');
cqlsh> INSERT INTO test.test (id, value1 , value2, value3 ) VALUES ('bbb', 'bbb', 'bbb' ,'bbb');
cqlsh> SELECT token(id),id,value1 FROM test.test;

 system.token(id)     | id  | value1
----------------------+-----+--------
 -4737872923231490581 | aaa |    aaa
 -3071845237020185195 | bbb |    bbb

(2 rows)

cqlsh> CREATE MATERIALIZED VIEW test.test_view AS SELECT value1, id FROM test.test WHERE id IS NOT NULL AND value1 IS NOT NULL AND TOKEN(id) > -9223372036854775808 AND TOKEN(id) < -3074457345618258603 PRIMARY KEY(value1, id) WITH CLUSTERING ORDER BY (id ASC);
ServerError: java.lang.ClassCastException: org.apache.cassandra.cql3.TokenRelation cannot be cast to org.apache.cassandra.cql3.SingleColumnRelation
{code}

Stacktrace :
{code:java}
INFO  [MigrationStage:1] 2017-04-19 18:32:48,131 ColumnFamilyStore.java:389 - Initializing test.test
WARN  [SharedPool-Worker-1] 2017-04-19 18:44:07,263 FBUtilities.java:337 - Trigger directory doesn't exist, please create it and try again.
ERROR [SharedPool-Worker-1] 2017-04-19 18:46:10,072 QueryMessage.java:128 - Unexpected error during query
java.lang.ClassCastException: org.apache.cassandra.cql3.TokenRelation cannot be cast to org.apache.cassandra.cql3.SingleColumnRelation
	at org.apache.cassandra.db.view.View.relationsToWhereClause(View.java:275) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.statements.CreateViewStatement.announceMigration(CreateViewStatement.java:219) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.statements.SchemaAlteringStatement.execute(SchemaAlteringStatement.java:93) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) [apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) [apache-cassandra-3.0.13.jar:3.0.13]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_121]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) [apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.13.jar:3.0.13]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
ERROR [SharedPool-Worker-1] 2017-04-19 18:46:10,073 ErrorMessage.java:349 - Unexpected exception during request
java.lang.ClassCastException: org.apache.cassandra.cql3.TokenRelation cannot be cast to org.apache.cassandra.cql3.SingleColumnRelation
	at org.apache.cassandra.db.view.View.relationsToWhereClause(View.java:275) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.statements.CreateViewStatement.announceMigration(CreateViewStatement.java:219) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.statements.SchemaAlteringStatement.execute(SchemaAlteringStatement.java:93) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:206) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:237) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.cql3.QueryProcessor.process(QueryProcessor.java:222) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.messages.QueryMessage.execute(QueryMessage.java:115) ~[apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:513) [apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:407) [apache-cassandra-3.0.13.jar:3.0.13]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext.access$600(AbstractChannelHandlerContext.java:35) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at io.netty.channel.AbstractChannelHandlerContext$7.run(AbstractChannelHandlerContext.java:348) [netty-all-4.0.44.Final.jar:4.0.44.Final]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_121]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) [apache-cassandra-3.0.13.jar:3.0.13]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-3.0.13.jar:3.0.13]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
INFO  [IndexSummaryManager:1] 2017-04-19 19:20:43,246 IndexSummaryRedistribution.java:74 - Redistributing index summaries
{code}


I don't know if it is a bug.
I want to create materialized view with a specific token range.
"
CASSANDRA-13422,CompactionStrategyManager should take write not read lock when handling remove notifications,"{{getNextBackgroundTask}} in various compaction strategies (definitely {{LCS}}) rely on checking the result of {{DataTracker.getCompacting()}} to avoid accessing data and metadata related to tables that have already head their resources released.

There is a race where this check is unreliable and will claim a table that has its resources already released is not compacting resulting in use after free.

[{{LeveledCompactionStrategy.findDroppableSSTable}}|https://github.com/apache/cassandra/blob/c794d2bed7ca1d10e13c4da08a3d45f5c755c1d8/src/java/org/apache/cassandra/db/compaction/LeveledCompactionStrategy.java#L504] for instance has this three part logical && condition where the first check is against the compacting set before calling {{worthDroppingTombstones}} which fails if the table has been released.

The order of events is basically that CompactionStrategyManager acquires the read lock in getNextBackgroundTask(), then proceeds eventually to findDroppableSSTable and acquires a set of SSTables from the manifest. While the manifest is thread safe it's not accessed atomically WRT to other operations. Once it has acquired the set of tables it acquires (not atomically) the set of compacting SSTables and iterates checking the former against the latter.

Meanwhile other compaction threads are marking tables obsolete or compacted and releasing their references. Doing this removes them from {{DataTracker}} and publishes a notification to the strategies, but this notification only requires the read lock. After the compaction thread has published the notifications it eventually marks the table as not compacting in {{DataTracker}} or removes it entirely.

The race is then that the compaction thread generating a new background task acquires the sstables from the manifest on the stack. Any table in that set that was compacting at that time must remain compacting so that it can be skipped. Another compaction thread finishes a compaction and is able to remove the table from the manifest and then remove it from the compacting set. The thread generating the background task then acquires the list of compacting tables which doesn't include the table it is supposed to skip.

The simple fix appears to be to require threads to acquire the write lock in order to publish notifications of tables being removed from compaction strategies. While holding the write lock it won't be possible for someone to see a view of tables in the manifest where tables that are compacting aren't compacting in the view."
CASSANDRA-13410,nodetool upgradesstables/scrub/compact ignores system tables,"CASSANDRA-11627 changed the behavior of nodetool commands that work across all keyspaces. Sometimes it's OK (not compacting system.peers when you call compact probably isn't going to anger anyone), but sometimes it's not (disableautocompaction, flush, upgradesstables, etc).

"
CASSANDRA-13389,Possible NPE on upgrade to 3.0/3.X in case of IO errors,"There is a NPE on upgrade to 3.0/3.X if a data directory contains directories that generate IO errors, for example if the cassandra process does not have permission to read them.

Here is the exception:

{code}
ERROR [main] 2017-03-06 16:41:30,678  CassandraDaemon.java:710 - Exception encountered during startup
java.lang.NullPointerException: null
	at org.apache.cassandra.io.util.FileUtils.delete(FileUtils.java:372) ~[cassandra-all-3.0.11.1564.jar:3.0.11.1564]
	at org.apache.cassandra.db.SystemKeyspace.migrateDataDirs(SystemKeyspace.java:1359) ~[cassandra-all-3.0.11.1564.jar:3.0.11.1564]
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:190) ~[cassandra-all-3.0.11.1564.jar:3.0.11.1564]
{code}

This is caused by {{File.listFiles()}}, which returns null in case of an IO error."
CASSANDRA-13363,Fix racy read command serialization,"Constantly see this error in the log without any additional information or a stack trace.

{code}
Exception in thread Thread[MessagingService-Incoming-/10.0.1.26,5,main]
{code}

{code}
java.lang.ArrayIndexOutOfBoundsException: null
{code}

Logger: org.apache.cassandra.service.CassandraDaemon
Thrdead: MessagingService-Incoming-/10.0.1.12
Method: uncaughtException
File: CassandraDaemon.java
Line: 229"
CASSANDRA-13348,Duplicate tokens after bootstrap,"This one is a bit scary, and probably results in data loss. After a bootstrap of a few new nodes into an existing cluster, two new nodes have chosen some overlapping tokens.

In fact, of the 256 tokens chosen, 51 tokens were already in use on the other node.

Node 1 log :
{noformat}
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,461 StorageService.java:1160 - JOINING: waiting for ring information
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,461 StorageService.java:1160 - JOINING: waiting for schema information to complete
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,461 StorageService.java:1160 - JOINING: schema complete, ready to bootstrap
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,462 StorageService.java:1160 - JOINING: waiting for pending range calculation
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,462 StorageService.java:1160 - JOINING: calculation complete, ready to bootstrap
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,462 StorageService.java:1160 - JOINING: getting bootstrap token
WARN  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,564 TokenAllocation.java:61 - Selected tokens [............, 2959334889475814712, 3727103702384420083, 7183119311535804926, 6013900799616279548, -1222135324851761575, 1645259890258332163, -1213352346686661387, 7604192574911909354]
WARN  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,729 TokenAllocation.java:65 - Replicated node load in datacentre before allocation max 1.00 min 1.00 stddev 0.0000
WARN  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,729 TokenAllocation.java:66 - Replicated node load in datacentre after allocation max 1.00 min 1.00 stddev 0.0000
WARN  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:43,729 TokenAllocation.java:70 - Unexpected growth in standard deviation after allocation.
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:42:44,150 StorageService.java:1160 - JOINING: sleeping 30000 ms for pending range setup
INFO  [RMI TCP Connection(107)-127.0.0.1] 2017-03-09 07:43:14,151 StorageService.java:1160 - JOINING: Starting to bootstrap...
{noformat}

Node 2 log:
{noformat}
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:51,937 StorageService.java:971 - Joining ring by operator request
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,513 StorageService.java:1160 - JOINING: waiting for ring information
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,513 StorageService.java:1160 - JOINING: waiting for schema information to complete
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,513 StorageService.java:1160 - JOINING: schema complete, ready to bootstrap
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,513 StorageService.java:1160 - JOINING: waiting for pending range calculation
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,514 StorageService.java:1160 - JOINING: calculation complete, ready to bootstrap
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,514 StorageService.java:1160 - JOINING: getting bootstrap token
WARN  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,630 TokenAllocation.java:61 - Selected tokens [......, 2890709530010722764, -2416006722819773829, -5820248611267569511, -5990139574852472056, 1645259890258332163, 9135021011763659240, -5451286144622276797, 7604192574911909354]
WARN  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,794 TokenAllocation.java:65 - Replicated node load in datacentre before allocation max 1.02 min 0.98 stddev 0.0000
WARN  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:52,795 TokenAllocation.java:66 - Replicated node load in datacentre after allocation max 1.00 min 1.00 stddev 0.0000
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:55:53,149 StorageService.java:1160 - JOINING: sleeping 30000 ms for pending range setup
INFO  [RMI TCP Connection(380)-127.0.0.1] 2017-03-17 15:56:23,149 StorageService.java:1160 - JOINING: Starting to bootstrap...
{noformat}

eg. 7604192574911909354 has been chosen by both.

The joins were eight days apart, so I don't think it's a race :)"
CASSANDRA-13347,dtest failure in upgrade_tests.upgrade_through_versions_test.TestUpgrade_current_2_2_x_To_indev_3_0_x.rolling_upgrade_test,"example failure:

http://cassci.datastax.com/job/cassandra-3.0_large_dtest/58/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_2_x_To_indev_3_0_x/rolling_upgrade_test

{code}
Error Message

Subprocess ['nodetool', '-h', 'localhost', '-p', '7100', ['upgradesstables', '-a']] exited with non-zero status; exit status: 2; 
stderr: error: null
-- StackTrace --
java.lang.AssertionError
	at org.apache.cassandra.db.rows.Rows.collectStats(Rows.java:70)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter$StatsCollector.applyToRow(BigTableWriter.java:197)
	at org.apache.cassandra.db.transform.BaseRows.applyOne(BaseRows.java:116)
	at org.apache.cassandra.db.transform.BaseRows.add(BaseRows.java:107)
	at org.apache.cassandra.db.transform.UnfilteredRows.add(UnfilteredRows.java:41)
	at org.apache.cassandra.db.transform.Transformation.add(Transformation.java:156)
	at org.apache.cassandra.db.transform.Transformation.apply(Transformation.java:122)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:147)
	at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:125)
	at org.apache.cassandra.db.compaction.writers.DefaultCompactionWriter.realAppend(DefaultCompactionWriter.java:57)
	at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.append(CompactionAwareWriter.java:109)
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:195)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89)
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)
	at org.apache.cassandra.db.compaction.CompactionManager$5.execute(CompactionManager.java:415)
	at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:307)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
	at java.lang.Thread.run(Thread.java:745)
{code}{code}
Stacktrace

  File ""/usr/lib/python2.7/unittest/case.py"", line 329, in run
    testMethod()
  File ""/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py"", line 279, in rolling_upgrade_test
    self.upgrade_scenario(rolling=True)
  File ""/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py"", line 345, in upgrade_scenario
    self.upgrade_to_version(version_meta, partial=True, nodes=(node,))
  File ""/home/automaton/cassandra-dtest/upgrade_tests/upgrade_through_versions_test.py"", line 446, in upgrade_to_version
    node.nodetool('upgradesstables -a')
  File ""/home/automaton/venv/local/lib/python2.7/site-packages/ccmlib/node.py"", line 789, in nodetool
    return handle_external_tool_process(p, ['nodetool', '-h', 'localhost', '-p', str(self.jmx_port), cmd.split()])
  File ""/home/automaton/venv/local/lib/python2.7/site-packages/ccmlib/node.py"", line 2002, in handle_external_tool_process
    raise ToolError(cmd_args, rc, out, err)
{code}

Related failures:

http://cassci.datastax.com/job/cassandra-3.0_large_dtest/58/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_1_x_To_indev_3_0_x/rolling_upgrade_with_internode_ssl_test/

http://cassci.datastax.com/job/cassandra-3.0_large_dtest/58/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_2_x_To_indev_3_0_x/rolling_upgrade_with_internode_ssl_test/

http://cassci.datastax.com/job/cassandra-3.0_large_dtest/58/testReport/upgrade_tests.upgrade_through_versions_test/TestUpgrade_current_2_1_x_To_indev_3_0_x/rolling_upgrade_test/"
CASSANDRA-13337,"Dropping column results in ""corrupt"" SSTable","It seems like dropping a column can make SSTables containing rows with writes to only the dropped column will become uncompactable.

Also Cassandra <= 3.9 and <= 3.0.11 will even refuse to start with the same stack trace

{code}
cqlsh -e ""create keyspace test with replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }""
cqlsh -e ""create table test.test(pk text primary key, x text, y text)""

cqlsh -e ""update test.test set x='1' where pk='1'""
nodetool flush

cqlsh -e ""update test.test set x='1', y='1' where pk='1'""
nodetool flush
cqlsh -e ""alter table test.test drop x""

nodetool compact test test
error: Corrupt empty row found in unfiltered partition
-- StackTrace --
java.io.IOException: Corrupt empty row found in unfiltered partition
	at org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(UnfilteredSerializer.java:382)
	at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:87)
	at org.apache.cassandra.io.sstable.SSTableSimpleIterator$CurrentFormatIterator.computeNext(SSTableSimpleIterator.java:65)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.doCompute(SSTableIdentityIterator.java:123)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.computeNext(SSTableIdentityIterator.java:100)
	at org.apache.cassandra.io.sstable.SSTableIdentityIterator.computeNext(SSTableIdentityIterator.java:30)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:95)
	at org.apache.cassandra.db.rows.LazilyInitializedUnfilteredRowIterator.computeNext(LazilyInitializedUnfilteredRowIterator.java:32)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:369)
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.advance(MergeIterator.java:189)
	at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:158)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:509)
	at org.apache.cassandra.db.rows.UnfilteredRowIterators$UnfilteredRowMergeIterator.computeNext(UnfilteredRowIterators.java:369)
	at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47)
	at org.apache.cassandra.db.transform.BaseRows.hasNext(BaseRows.java:129)
	at org.apache.cassandra.db.transform.UnfilteredRows.isEmpty(UnfilteredRows.java:58)
	at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:67)
	at org.apache.cassandra.db.partitions.PurgeFunction.applyToPartition(PurgeFunction.java:26)
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96)
	at org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:227)
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:190)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89)
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)
	at org.apache.cassandra.db.compaction.CompactionManager$8.runMayThrow(CompactionManager.java:610)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
	at java.lang.Thread.run(Thread.java:745)

{code}"
CASSANDRA-13326,Support unaligned memory access for AArch64,ARMv8 (AArch64)  supports unaligned memory access. The patch will enable it and will improve performance on AArch64
CASSANDRA-13323,IncomingTcpConnection closed due to one bad message,"We got this exception:
{code}
WARN  [MessagingService-Incoming-/****] 2017-02-14 17:33:33,177 IncomingTcpConnection.java:101 - UnknownColumnFamilyException reading from socket; closing
org.apache.cassandra.db.UnknownColumnFamilyException: Couldn't find table for cfId 2a3ab630-df74-11e6-9f81-b56251e1559e. If a table was just created, this is likely due to the schema not being fully propagated.  Please wait for schema agreement on table creation.
    at org.apache.cassandra.config.CFMetaData$Serializer.deserialize(CFMetaData.java:1336) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize30(PartitionUpdate.java:660) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.db.partitions.PartitionUpdate$PartitionUpdateSerializer.deserialize(PartitionUpdate.java:635) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.service.paxos.Commit$CommitSerializer.deserialize(Commit.java:131) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.service.paxos.Commit$CommitSerializer.deserialize(Commit.java:113) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.net.MessageIn.read(MessageIn.java:98) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.net.IncomingTcpConnection.receiveMessage(IncomingTcpConnection.java:201) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.net.IncomingTcpConnection.receiveMessages(IncomingTcpConnection.java:178) ~[apache-cassandra-3.0.10.jar:3.0.10]
    at org.apache.cassandra.net.IncomingTcpConnection.run(IncomingTcpConnection.java:92) ~[apache-cassandra-3.0.10.jar:3.0.10]
{code}

Also we saw this log in another host indicating it needs to re-connect:
{code}
INFO  [HANDSHAKE-/****] 2017-02-21 13:37:50,216 OutboundTcpConnection.java:515 - Handshaking version with /****
{code}

The reason is that the node was receiving hinted data for a dropped table. This may happen with other messages as well. On Cassandra side, IncomingTcpConnection shouldn't close on just one bad message, even though it will be restarted soon later by SocketThread in MessagingService."
CASSANDRA-13320,upgradesstables fails after upgrading from 2.1.x to 3.0.11,"I tried to execute {{nodetool upgradesstables}} after upgrading cluster from 2.1.16 to 3.0.11, but it fails when upgrading a table with 2i.

This problem can be reproduced as follows.
{code}
$ ccm create test -v 2.1.16 -n 1 -s
$ ccm node1 cqlsh  -e ""CREATE KEYSPACE test WITH replication = {'class':'SimpleStrategy', 'replication_factor':1}""
$ ccm node1 cqlsh  -e ""CREATE TABLE test.test(k1 text, k2 text, PRIMARY KEY( k1 ));""
$ ccm node1 cqlsh  -e ""CREATE INDEX k2 ON test.test(k2);""
 
$ ccm node1 cqlsh  -e ""INSERT INTO test.test (k1, k2 ) VALUES ( 'a', 'a') ;""
$ ccm node1 cqlsh  -e ""INSERT INTO test.test (k1, k2 ) VALUES ( 'a', 'b') ;""
 
$ ccm node1 nodetool flush
 
$ for i in `seq 1 `; do ccm node${i} stop; ccm node${i} setdir -v3.0.11;ccm node${i} start; done
$ ccm node1 nodetool upgradesstables test test
Traceback (most recent call last):
  File ""/home/y/bin/ccm"", line 86, in <module>
    cmd.run()
  File ""/home/y/lib/python2.7/site-packages/ccmlib/cmds/node_cmds.py"", line 267, in run
    stdout, stderr = self.node.nodetool("" "".join(self.args[1:]))
  File ""/home/y/lib/python2.7/site-packages/ccmlib/node.py"", line 742, in nodetool
    raise NodetoolError("" "".join(args), exit_status, stdout, stderr)
ccmlib.node.NodetoolError: Nodetool command '/home/zzheng/.ccm/repository/3.0.11/bin/nodetool -h localhost -p 7100 upgradesstables test test' failed; exit status: 2; stderr: WARN  06:29:08 Only 10476 MB free across all data volumes. Consider adding more capacity to your cluster or removing obsolete snapshots
error: null
-- StackTrace --
java.lang.AssertionError
	at org.apache.cassandra.db.rows.Rows.collectStats(Rows.java:70)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter$StatsCollector.applyToRow(BigTableWriter.java:197)
	at org.apache.cassandra.db.transform.BaseRows.applyOne(BaseRows.java:116)
	at org.apache.cassandra.db.transform.BaseRows.add(BaseRows.java:107)
	at org.apache.cassandra.db.transform.UnfilteredRows.add(UnfilteredRows.java:41)
	at org.apache.cassandra.db.transform.Transformation.add(Transformation.java:156)
	at org.apache.cassandra.db.transform.Transformation.apply(Transformation.java:122)
	at org.apache.cassandra.io.sstable.format.big.BigTableWriter.append(BigTableWriter.java:147)
	at org.apache.cassandra.io.sstable.SSTableRewriter.append(SSTableRewriter.java:125)
	at org.apache.cassandra.db.compaction.writers.DefaultCompactionWriter.realAppend(DefaultCompactionWriter.java:57)
	at org.apache.cassandra.db.compaction.writers.CompactionAwareWriter.append(CompactionAwareWriter.java:109)
	at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:195)
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28)
	at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:89)
	at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:61)
	at org.apache.cassandra.db.compaction.CompactionManager$5.execute(CompactionManager.java:415)
	at org.apache.cassandra.db.compaction.CompactionManager$2.call(CompactionManager.java:307)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$0(NamedThreadFactory.java:79)
	at java.lang.Thread.run(Thread.java:745)
{code}

The result of dumping the 2i sstable is as follows.
{code}
[
{""key"": ""a"",
 ""cells"": [[""61"",1488961273,1488961269822817,""d""]]},
{""key"": ""b"",
 ""cells"": [[""61"","""",1488961273015759]]}
]
{code}

This problem is occurred by the tombstone row. When this row is processed in {{LegacyLayout.java}}, it will be treated as a row maker.
https://github.com/apache/cassandra/blob/cassandra-3.0/src/java/org/apache/cassandra/db/LegacyLayout.java#L1195
Then the deletion info will be lost.

As a result, the row will be a empty row, which causes the assertion error.

To avoid this, I added the code to add row deletion info when the row is a tombstone and *not* a row marker, and it works as I expect, which means that {{upgradesstables}} succeeds and row deletion info is remained.

However I don't understand whether this change will cause another problem. Anyway, I submit my patch as a reference."
CASSANDRA-13308,"Gossip breaks, Hint files not being deleted on nodetool decommission","How to reproduce the issue I'm seeing:
Shut down Cassandra on one node of the cluster and wait until we accumulate a ton of hints. Start Cassandra on the node and immediately run ""nodetool decommission"" on it.

The node streams its replicas and marks itself as DECOMMISSIONED, but other nodes do not seem to see this message. ""nodetool status"" shows the decommissioned node in state ""UL"" on all other nodes (it is also present in system.peers), and Cassandra logs show that gossip tasks on nodes are not proceeding (number of pending tasks keeps increasing). Jstack suggests that a gossip task is blocked on hints dispatch (I can provide traces if this is not obvious). Because the cluster is large and there are a lot of hints, this is taking a while. 

On inspecting ""/var/lib/cassandra/hints"" on the nodes, I see a bunch of hint files for the decommissioned node. Documentation seems to suggest that these hints should be deleted during ""nodetool decommission"", but it does not seem to be the case here. This is the bug being reported.

To recover from this scenario, if I manually delete hint files on the nodes, the hints dispatcher threads throw a bunch of exceptions and the decommissioned node is now in state ""DL"" (perhaps it missed some gossip messages?). The node is still in my ""system.peers"" table

Restarting Cassandra on all nodes after this step does not fix the issue (the node remains in the peers table). In fact, after this point the decommissioned node is in state ""DN"""
CASSANDRA-13307,The specification of protocol version in cqlsh means the python driver doesn't automatically downgrade protocol version.,"Hi,
Looks like we've regressed on the issue described in:
https://issues.apache.org/jira/browse/CASSANDRA-9467
In that we're no longer able to connect from newer cqlsh versions
(e.g trunk) to older versions of Cassandra with a lower version of the protocol (e.g 2.1 with protocol version 3)

The problem seems to be that we're relying on the ability for the client to automatically downgrade protocol version implemented in Cassandra here:
https://issues.apache.org/jira/browse/CASSANDRA-12838
and utilised in the python client here:
https://datastax-oss.atlassian.net/browse/PYTHON-240

The problem however comes when we implemented:
https://datastax-oss.atlassian.net/browse/PYTHON-537
""Don't downgrade protocol version if explicitly set"" 
(included when we bumped from 3.5.0 to 3.7.0 of the python driver as part of fixing: https://issues.apache.org/jira/browse/CASSANDRA-11534)

Since we do explicitly specify the protocol version in the bin/cqlsh.py.

I've got a patch which just adds an option to explicitly specify the protocol version (for those who want to do that) and then otherwise defaults to not setting the protocol version, i.e using the protocol version from the client which we ship, which should by default be the same protocol as the server.
Then it should downgrade gracefully as was intended. 
Let me know if that seems reasonable.
Thanks,
Matt
"
CASSANDRA-13302,last row of previous page == first row of next page while querying data using SASI index,"Apologies if this is a duplicate (couldn't track down an existing bug).

Similarly to [CASSANDRA-11208], it appears it is possible to retrieve duplicate rows when paging using a SASI index as documented in [JAVA-1413|https://datastax-oss.atlassian.net/browse/JAVA-1413], the following test demonstrates that data is repeated while querying using a SASI index:

{code:java}
public class TestPagingBug
{
	public static void main(String[] args)
	{
		Cluster.Builder builder = Cluster.builder();
		Cluster c = builder.addContactPoints(""192.168.98.190"").build();		
		Session s = c.connect();
		
		s.execute(""CREATE KEYSPACE IF NOT EXISTS test WITH replication = { 'class' : 'SimpleStrategy', 'replication_factor' : 3 }"");
		s.execute(""CREATE TABLE IF NOT EXISTS test.test_table_sec(sec BIGINT PRIMARY KEY, id INT)"");
                //create secondary index on ID column, used for select statement
                String index = ""CREATE CUSTOM INDEX test_table_sec_idx ON test.test_table_sec (id) USING 'org.apache.cassandra.index.sasi.SASIIndex' ""
                + ""WITH OPTIONS = { 'mode': 'PREFIX' }"";
                s.execute(index);
		
		PreparedStatement insert = s.prepare(""INSERT INTO test.test_table_sec (id, sec) VALUES (1, ?)"");		
		for (int i = 0; i < 1000; i++)
			s.execute(insert.bind((long) i));
		
		PreparedStatement select = s.prepare(""SELECT sec FROM test.test_table_sec WHERE id = 1"");
		
		long lastSec = -1;		
		for (Row row : s.execute(select.bind().setFetchSize(300)))
		{
			long sec = row.getLong(""sec"");
			if (sec == lastSec)
				System.out.println(String.format(""Duplicated id %d"", sec));
			
			lastSec = sec;
		}
		System.exit(0);
	}
}
{code}

The program outputs the following:

{noformat}
Duplicated id 23
Duplicated id 192
Duplicated id 684
{noformat}

Note that the simple primary key is required to reproduce this."
CASSANDRA-13274,Fix code to not exchange schema across major versions,"A rolling upgrade from 3.* to 4.0 (messaging version {{11}}) unveils a regression caused by CASSANDRA-11128.

Generally, we store all possible options/attributes including the default values in the schema. This causes (expected) schema-version-mismatches during rolling upgrades and therefore we prevent schema pulls/pushes in this situation, which has been broken by CASSANDRA-11128."
CASSANDRA-13247,index on udt built failed and no data could be inserted,"index on udt built failed and no data could be inserted

steps to reproduce:

CREATE KEYSPACE ks1 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '2'}  AND durable_writes = true;

CREATE TYPE ks1.address (
    street text,
    city text,
    zip_code int,
    phones set<text>
);

CREATE TYPE ks1.fullname (
    firstname text,
    lastname text
);

CREATE TABLE ks1.users (
    id uuid PRIMARY KEY,
    addresses map<text, frozen<address>>,
    age int,
    direct_reports set<frozen<fullname>>,
    name fullname
) WITH bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.1
    AND default_time_to_live = 0
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';


SELECT * FROM users where name = { firstname : 'first' , lastname : 'last'} allow filtering;
ReadFailure: Error from server: code=1300 [Replica(s) failed to execute read] message=""Operation failed - received 0 responses and 1 failures"" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}

WARN  [ReadStage-2] 2017-02-22 16:59:33,392 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[ReadStage-2,5,main]: {}
java.lang.AssertionError: Only CONTAINS and CONTAINS_KEY are supported for 'complex' types
	at org.apache.cassandra.db.filter.RowFilter$SimpleExpression.isSatisfiedBy(RowFilter.java:683) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToRow(RowFilter.java:303) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.BaseRows.applyOne(BaseRows.java:120) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.BaseRows.add(BaseRows.java:110) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.UnfilteredRows.add(UnfilteredRows.java:41) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.Transformation.add(Transformation.java:162) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.Transformation.apply(Transformation.java:128) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToPartition(RowFilter.java:292) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.filter.RowFilter$CQLFilter$1IsSatisfiedFilter.applyToPartition(RowFilter.java:281) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:96) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$Serializer.serialize(UnfilteredPartitionIterators.java:289) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ReadResponse$LocalDataResponse.build(ReadResponse.java:145) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:138) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ReadResponse$LocalDataResponse.<init>(ReadResponse.java:134) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ReadResponse.createDataResponse(ReadResponse.java:76) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ReadCommand.createResponse(ReadCommand.java:323) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1803) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2486) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_121]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.9.jar:3.9]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]


CREATE INDEX users_name_idx ON ks1.users (name);

ERROR [CompactionExecutor:776] 2017-02-22 16:49:41,934 CassandraDaemon.java:226 - Exception in thread Thread[CompactionExecutor:776,1,main]
java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.SecondaryIndexManager.lambda$indexPartition$17(SecondaryIndexManager.java:552) ~[apache-cassandra-3.9.jar:3.9]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_121]
	at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:552) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Keyspace.indexPartition(Keyspace.java:566) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:70) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.compaction.CompactionManager$12.run(CompactionManager.java:1468) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_121]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
Caused by: java.nio.BufferUnderflowException: null
	at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~[na:1.8.0_121]
	at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~[na:1.8.0_121]
	at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~[na:1.8.0_121]
	at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~[apache-cassandra-3.9.jar:3.9]
	... 16 common frames omitted
ERROR [SecondaryIndexManagement:3] 2017-02-22 16:49:41,934 CassandraDaemon.java:226 - Exception in thread Thread[SecondaryIndexManagement:3,5,main]
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:403) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.buildBlocking(CassandraIndex.java:715) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.lambda$getBuildIndexTask$5(CassandraIndex.java:685) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_121]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_121]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_121]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_121]
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:399) ~[apache-cassandra-3.9.jar:3.9]
	... 6 common frames omitted
Caused by: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.SecondaryIndexManager.lambda$indexPartition$17(SecondaryIndexManager.java:552) ~[apache-cassandra-3.9.jar:3.9]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_121]
	at org.apache.cassandra.index.SecondaryIndexManager.indexPartition(SecondaryIndexManager.java:552) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Keyspace.indexPartition(Keyspace.java:566) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CollatedViewIndexBuilder.build(CollatedViewIndexBuilder.java:70) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.compaction.CompactionManager$12.run(CompactionManager.java:1468) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_121]
	... 4 common frames omitted
Caused by: java.nio.BufferUnderflowException: null
	at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~[na:1.8.0_121]
	at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~[na:1.8.0_121]
	at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~[na:1.8.0_121]
	at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~[apache-cassandra-3.9.jar:3.9]
	... 16 common frames omitted


SELECT * FROM users where name = { firstname : 'first' , lastname : 'last'};
ReadFailure: Error from server: code=1300 [Replica(s) failed to execute read] message=""Operation failed - received 0 responses and 1 failures"" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}

WARN  [ReadStage-2] 2017-02-22 16:55:43,139 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[ReadStage-2,5,main]: {}
java.lang.RuntimeException: org.apache.cassandra.index.IndexNotAvailableException: The secondary index 'users_name_idx' is not yet available
	at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2490) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_121]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.9.jar:3.9]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
Caused by: org.apache.cassandra.index.IndexNotAvailableException: The secondary index 'users_name_idx' is not yet available
	at org.apache.cassandra.db.ReadCommand.executeLocally(ReadCommand.java:390) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$LocalReadRunnable.runMayThrow(StorageProxy.java:1801) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2486) ~[apache-cassandra-3.9.jar:3.9]
	... 5 common frames omitted


insert into users (id, name) values (uuid(), {firstname: 'a', lastname: 'b'});
WriteFailure: Error from server: code=1500 [Replica(s) failed to execute write] message=""Operation failed - received 0 responses and 1 failures"" info={'failures': 1, 'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}

ERROR [MutationStage-2] 2017-02-22 17:04:34,355 StorageProxy.java:1353 - Failed to apply mutation locally : {}
java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx for ks: ks1, table: users
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:526) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:396) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Mutation.applyFuture(Mutation.java:215) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:227) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Mutation.apply(Mutation.java:241) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$8.runMayThrow(StorageProxy.java:1347) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:2539) [apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_121]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.9.jar:3.9]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_121]
Caused by: java.lang.RuntimeException: null for ks: ks1, table: users.users_name_idx
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1316) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.insert(CassandraIndex.java:531) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex.access$100(CassandraIndex.java:72) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCell(CassandraIndex.java:444) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.indexCells(CassandraIndex.java:436) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.internal.CassandraIndex$1.insertRow(CassandraIndex.java:386) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.index.SecondaryIndexManager$WriteTimeTransaction.onInserted(SecondaryIndexManager.java:808) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:335) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition$RowUpdater.apply(AtomicBTreePartition.java:295) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.utils.btree.BTree.buildInternal(BTree.java:137) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.utils.btree.BTree.build(BTree.java:119) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.utils.btree.BTree.update(BTree.java:175) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.partitions.AtomicBTreePartition.addAllWithSizeDelta(AtomicBTreePartition.java:156) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.Memtable.put(Memtable.java:258) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~[apache-cassandra-3.9.jar:3.9]
	... 12 common frames omitted
Caused by: java.nio.BufferUnderflowException: null
	at java.nio.Buffer.nextGetIndex(Buffer.java:506) ~[na:1.8.0_121]
	at java.nio.HeapByteBuffer.getInt(HeapByteBuffer.java:361) ~[na:1.8.0_121]
	at org.apache.cassandra.db.marshal.TupleType.compareCustom(TupleType.java:109) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.marshal.AbstractType.compare(AbstractType.java:159) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:139) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.dht.LocalPartitioner$LocalToken.compareTo(LocalPartitioner.java:120) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:85) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.DecoratedKey.compareTo(DecoratedKey.java:39) ~[apache-cassandra-3.9.jar:3.9]
	at java.util.concurrent.ConcurrentSkipListMap.cpr(ConcurrentSkipListMap.java:655) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:794) ~[na:1.8.0_121]
	at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1546) ~[na:1.8.0_121]
	at org.apache.cassandra.db.Memtable.put(Memtable.java:234) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.db.ColumnFamilyStore.apply(ColumnFamilyStore.java:1303) ~[apache-cassandra-3.9.jar:3.9]
	... 26 common frames omitted





"
CASSANDRA-13229,dtest failure in topology_test.TestTopology.size_estimates_multidc_test,"example failure:

http://cassci.datastax.com/job/trunk_novnode_dtest/508/testReport/topology_test/TestTopology/size_estimates_multidc_test

{code}
Standard Output

Unexpected error in node1 log, error: 
ERROR [MemtablePostFlush:1] 2017-02-15 16:07:33,837 CassandraDaemon.java:211 - Exception in thread Thread[MemtablePostFlush:1,5,main]
java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.ArrayList.rangeCheck(ArrayList.java:653) ~[na:1.8.0_45]
	at java.util.ArrayList.get(ArrayList.java:429) ~[na:1.8.0_45]
	at org.apache.cassandra.dht.Splitter.splitOwnedRangesNoPartialRanges(Splitter.java:92) ~[main/:na]
	at org.apache.cassandra.dht.Splitter.splitOwnedRanges(Splitter.java:59) ~[main/:na]
	at org.apache.cassandra.service.StorageService.getDiskBoundaries(StorageService.java:5180) ~[main/:na]
	at org.apache.cassandra.db.Memtable.createFlushRunnables(Memtable.java:312) ~[main/:na]
	at org.apache.cassandra.db.Memtable.flushRunnables(Memtable.java:304) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1150) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1115) ~[main/:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$290(NamedThreadFactory.java:81) [main/:na]
	at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$5/1321203216.run(Unknown Source) [main/:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]
Unexpected error in node1 log, error: 
ERROR [MigrationStage:1] 2017-02-15 16:07:33,853 CassandraDaemon.java:211 - Exception in thread Thread[MigrationStage:1,5,main]
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:401) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace.lambda$flush$496(SchemaKeyspace.java:284) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace$$Lambda$222/1949434065.accept(Unknown Source) ~[na:na]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_45]
	at org.apache.cassandra.schema.SchemaKeyspace.flush(SchemaKeyspace.java:284) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace.applyChanges(SchemaKeyspace.java:1265) ~[main/:na]
	at org.apache.cassandra.schema.Schema.merge(Schema.java:577) ~[main/:na]
	at org.apache.cassandra.schema.Schema.mergeAndAnnounceVersion(Schema.java:564) ~[main/:na]
	at org.apache.cassandra.schema.MigrationManager$1.runMayThrow(MigrationManager.java:402) ~[main/:na]
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_45]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_45]
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$290(NamedThreadFactory.java:81) [main/:na]
	at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$5/1321203216.run(Unknown Source) [main/:na]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_45]
Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_45]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_45]
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:397) ~[main/:na]
	... 16 common frames omitted
Caused by: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.ArrayList.rangeCheck(ArrayList.java:653) ~[na:1.8.0_45]
	at java.util.ArrayList.get(ArrayList.java:429) ~[na:1.8.0_45]
	at org.apache.cassandra.dht.Splitter.splitOwnedRangesNoPartialRanges(Splitter.java:92) ~[main/:na]
	at org.apache.cassandra.dht.Splitter.splitOwnedRanges(Splitter.java:59) ~[main/:na]
	at org.apache.cassandra.service.StorageService.getDiskBoundaries(StorageService.java:5180) ~[main/:na]
	at org.apache.cassandra.db.Memtable.createFlushRunnables(Memtable.java:312) ~[main/:na]
	at org.apache.cassandra.db.Memtable.flushRunnables(Memtable.java:304) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1150) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1115) ~[main/:na]
	... 5 common frames omitted
Unexpected error in node1 log, error: 
ERROR [main] 2017-02-15 16:07:33,857 CassandraDaemon.java:663 - Exception encountered during startup
java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:401) ~[main/:na]
	at org.apache.cassandra.schema.MigrationManager.announce(MigrationManager.java:384) ~[main/:na]
	at org.apache.cassandra.schema.MigrationManager.announceNewKeyspace(MigrationManager.java:176) ~[main/:na]
	at org.apache.cassandra.service.StorageService.maybeAddKeyspace(StorageService.java:1066) ~[main/:na]
	at org.apache.cassandra.service.StorageService.maybeAddOrUpdateKeyspace(StorageService.java:1091) ~[main/:na]
	at org.apache.cassandra.service.StorageService.doAuthSetup(StorageService.java:1048) ~[main/:na]
	at org.apache.cassandra.service.StorageService.finishJoiningRing(StorageService.java:1043) ~[main/:na]
	at org.apache.cassandra.service.StorageService.joinTokenRing(StorageService.java:966) ~[main/:na]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:649) ~[main/:na]
	at org.apache.cassandra.service.StorageService.initServer(StorageService.java:581) ~[main/:na]
	at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:364) [main/:na]
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:557) [main/:na]
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:646) [main/:na]
Caused by: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_45]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_45]
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:397) ~[main/:na]
	... 12 common frames omitted
Caused by: java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:401) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace.lambda$flush$496(SchemaKeyspace.java:284) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace$$Lambda$222/1949434065.accept(Unknown Source) ~[na:na]
	at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_45]
	at org.apache.cassandra.schema.SchemaKeyspace.flush(SchemaKeyspace.java:284) ~[main/:na]
	at org.apache.cassandra.schema.SchemaKeyspace.applyChanges(SchemaKeyspace.java:1265) ~[main/:na]
	at org.apache.cassandra.schema.Schema.merge(Schema.java:577) ~[main/:na]
	at org.apache.cassandra.schema.Schema.mergeAndAnnounceVersion(Schema.java:564) ~[main/:na]
	at org.apache.cassandra.schema.MigrationManager$1.runMayThrow(MigrationManager.java:402) ~[main/:na]
	at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[main/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_45]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_45]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_45]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_45]
	at org.apache.cassandra.concurrent.NamedThreadFactory.lambda$threadLocalDeallocator$290(NamedThreadFactory.java:81) ~[main/:na]
	at org.apache.cassandra.concurrent.NamedThreadFactory$$Lambda$5/1321203216.run(Unknown Source) ~[na:na]
	at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_45]
Caused by: java.util.concurrent.ExecutionException: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_45]
	at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_45]
	at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:397) ~[main/:na]
	... 16 common frames omitted
Caused by: java.lang.IndexOutOfBoundsException: Index: 3, Size: 3
	at java.util.ArrayList.rangeCheck(ArrayList.java:653) ~[na:1.8.0_45]
	at java.util.ArrayList.get(ArrayList.java:429) ~[na:1.8.0_45]
	at org.apache.cassandra.dht.Splitter.splitOwnedRangesNoPartialRanges(Splitter.java:92) ~[main/:na]
	at org.apache.cassandra.dht.Splitter.splitOwnedRanges(Splitter.java:59) ~[main/:na]
	at org.apache.cassandra.service.StorageService.getDiskBoundaries(StorageService.java:5180) ~[main/:na]
	at org.apache.cassandra.db.Memtable.createFlushRunnables(Memtable.java:312) ~[main/:na]
	at org.apache.cassandra.db.Memtable.flushRunnables(Memtable.java:304) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.flushMemtable(ColumnFamilyStore.java:1150) ~[main/:na]
	at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:1115) ~[main/:na]
	... 5 common frames omitted
Unexpected error in node1 log, error: 
ERROR [StorageServiceShutdownHook] 2017-02-15 16:07:35,972 AbstractCommitLogSegmentManager.java:311 - Failed to force-recycle all segments; at least one segment is still in use with dirty CFs.
{code}"
CASSANDRA-13216,testall failure in org.apache.cassandra.net.MessagingServiceTest.testDroppedMessages,"example failure:

http://cassci.datastax.com/job/cassandra-3.11_testall/81/testReport/org.apache.cassandra.net/MessagingServiceTest/testDroppedMessages

{code}
Error Message

expected:<... dropped latency: 27[30 ms and Mean cross-node dropped latency: 2731] ms> but was:<... dropped latency: 27[28 ms and Mean cross-node dropped latency: 2730] ms>
{code}{code}
Stacktrace

junit.framework.AssertionFailedError: expected:<... dropped latency: 27[30 ms and Mean cross-node dropped latency: 2731] ms> but was:<... dropped latency: 27[28 ms and Mean cross-node dropped latency: 2730] ms>
	at org.apache.cassandra.net.MessagingServiceTest.testDroppedMessages(MessagingServiceTest.java:83)
{code}"
CASSANDRA-13209,test failure in cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest.test_bulk_round_trip_blogposts_with_max_connections,"example failure:

http://cassci.datastax.com/job/cassandra-2.1_dtest/528/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_bulk_round_trip_blogposts_with_max_connections

{noformat}
Error Message

errors={'127.0.0.4': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.4
-------------------- >> begin captured logging << --------------------
dtest: DEBUG: cluster ccm directory: /tmp/dtest-792s6j
dtest: DEBUG: Done setting configuration options:
{   'initial_token': None,
    'num_tokens': '32',
    'phi_convict_threshold': 5,
    'range_request_timeout_in_ms': 10000,
    'read_request_timeout_in_ms': 10000,
    'request_timeout_in_ms': 10000,
    'truncate_request_timeout_in_ms': 10000,
    'write_request_timeout_in_ms': 10000}
dtest: DEBUG: removing ccm cluster test at: /tmp/dtest-792s6j
dtest: DEBUG: clearing ssl stores from [/tmp/dtest-792s6j] directory
dtest: DEBUG: cluster ccm directory: /tmp/dtest-uNMsuW
dtest: DEBUG: Done setting configuration options:
{   'initial_token': None,
    'num_tokens': '32',
    'phi_convict_threshold': 5,
    'range_request_timeout_in_ms': 10000,
    'read_request_timeout_in_ms': 10000,
    'request_timeout_in_ms': 10000,
    'truncate_request_timeout_in_ms': 10000,
    'write_request_timeout_in_ms': 10000}
cassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
cassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.3 datacenter1> discovered
cassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 datacenter1> discovered
cassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.5 datacenter1> discovered
cassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.4 datacenter1> discovered
dtest: DEBUG: Running stress with user profile /home/automaton/cassandra-dtest/cqlsh_tests/blogposts.yaml
--------------------- >> end captured logging << ---------------------
Stacktrace

  File ""/usr/lib/python2.7/unittest/case.py"", line 329, in run
    testMethod()
  File ""/home/automaton/cassandra-dtest/dtest.py"", line 1090, in wrapped
    f(obj)
  File ""/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py"", line 2571, in test_bulk_round_trip_blogposts_with_max_connections
    copy_from_options={'NUMPROCESSES': 2})
  File ""/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py"", line 2500, in _test_bulk_round_trip
    num_records = create_records()
  File ""/home/automaton/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py"", line 2473, in create_records
    ret = rows_to_list(self.session.execute(count_statement))[0][0]
  File ""/home/automaton/src/cassandra-driver/cassandra/cluster.py"", line 1998, in execute
    return self.execute_async(query, parameters, trace, custom_payload, timeout, execution_profile, paging_state).result()
  File ""/home/automaton/src/cassandra-driver/cassandra/cluster.py"", line 3784, in result
    raise self._final_exception
""errors={'127.0.0.4': 'Client request timeout. See Session.execute[_async](timeout)'}, last_host=127.0.0.4\n-------------------- >> begin captured logging << --------------------\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-792s6j\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ndtest: DEBUG: removing ccm cluster test at: /tmp/dtest-792s6j\ndtest: DEBUG: clearing ssl stores from [/tmp/dtest-792s6j] directory\ndtest: DEBUG: cluster ccm directory: /tmp/dtest-uNMsuW\ndtest: DEBUG: Done setting configuration options:\n{   'initial_token': None,\n    'num_tokens': '32',\n    'phi_convict_threshold': 5,\n    'range_request_timeout_in_ms': 10000,\n    'read_request_timeout_in_ms': 10000,\n    'request_timeout_in_ms': 10000,\n    'truncate_request_timeout_in_ms': 10000,\n    'write_request_timeout_in_ms': 10000}\ncassandra.policies: INFO: Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.3 datacenter1> discovered\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.2 datacenter1> discovered\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.5 datacenter1> discovered\ncassandra.cluster: INFO: New Cassandra host <Host: 127.0.0.4 datacenter1> discovered\ndtest: DEBUG: Running stress with user profile /home/automaton/cassandra-dtest/cqlsh_tests/blogposts.yaml\n--------------------- >> end captured logging << ---------------------""
{noformat}"
CASSANDRA-13204,Thread Leak in OutboundTcpConnection,"We found threads leaking from OutboundTcpConnection to machines which are not part of the cluster and still in Gossip for some reason. There are two issues here, this JIRA will cover the second one which is most important. 



1) First issue is that Gossip has information about machines not in the ring which has been replaced out. It causes Cassandra to connect to those machines but due to internode auth, it wont be able to connect to them at the socket level.  

2) Second issue is a race between creating a connection and closing a connections which is triggered by the gossip bug explained above. Let me try to explain it using the code

In OutboundTcpConnection, we are calling closeSocket(true) which will set isStopped=true and also put a close sentinel into the queue to exit the thread. On the ack connection, Gossip tries to send a message which calls connect() which will block for 10 seconds which is RPC timeout. The reason we will block is because Cassandra might not be running there or internode auth will not let it connect. During this 10 seconds, if Gossip calls closeSocket, it will put close sentinel into the queue. When we return from the connect method after 10 seconds, we will clear the backlog queue causing this thread to leak. 

Proofs from the heap dump of the affected machine which is leaking threads 
1. Only ack connection is leaking and not the command connection which is not used by Gossip. 
2. We see thread blocked on the backlog queue, isStopped=true and backlog queue is empty. This is happening on the threads which have already leaked. 
3. A running thread was blocked on the connect waiting for timeout(10 seconds) and we see backlog queue to contain the close sentinel. Once the connect will return false, we will clear the backlog and this thread will have leaked.  


Interesting bits from j stack 
1282 number of threads for ""MessagingService-Outgoing-/<IP-Address>""

Thread which is about to leak:
""MessagingService-Outgoing-/<IP Address>"" 
   java.lang.Thread.State: RUNNABLE
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:454)
	at sun.nio.ch.Net.connect(Net.java:446)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:648)
	- locked <> (a java.lang.Object)
	- locked <> (a java.lang.Object)
	- locked <> (a java.lang.Object)
	at org.apache.cassandra.net.OutboundTcpConnectionPool.newSocket(OutboundTcpConnectionPool.java:137)
	at org.apache.cassandra.net.OutboundTcpConnectionPool.newSocket(OutboundTcpConnectionPool.java:119)
	at org.apache.cassandra.net.OutboundTcpConnection.connect(OutboundTcpConnection.java:381)
	at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:217)

Thread already leaked:
""MessagingService-Outgoing-/<IP Address>""
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.cassandra.utils.CoalescingStrategies$DisabledCoalescingStrategy.coalesceInternal(CoalescingStrategies.java:482)
	at org.apache.cassandra.utils.CoalescingStrategies$CoalescingStrategy.coalesce(CoalescingStrategies.java:213)
	at org.apache.cassandra.net.OutboundTcpConnection.run(OutboundTcpConnection.java:190)
"
CASSANDRA-13172,compaction_large_partition_warning_threshold_mb not working properly when set to high value,"compaction_large_partition_warning_threshold_mb has been set either by mistake or as an attempt to disable warnings completely to high value 512000
However system started to produce warning no matter what the partition size is:

 Compacting large partition system/compactions_in_progress:e631fe20-e488-11e6-bcd7-bf6151c7fa28 (32 bytes)

When looking into the code:
{code}
 public static int getCompactionLargePartitionWarningThreshold() { return conf.compaction_large_partition_warning_threshold_mb * 1024 * 1024; }
{code}
which is called in 
{code}
private void maybeLogLargePartitionWarning(DecoratedKey key, long rowSize)
    {
        if (rowSize > DatabaseDescriptor.getCompactionLargePartitionWarningThreshold())
        {
            String keyString = metadata().partitionKeyType.getString(key.getKey());
            logger.warn(""Writing large partition {}/{}:{} ({}) to sstable {}"", metadata.keyspace, metadata.name, keyString, FBUtilities.prettyPrintMemory(rowSize), getFilename());
        }
}
{code}
it looks like 512000 is multiplied by 1M and returned as int so being out of range... Maybe it would be better to use long  as it is used for rowSize


"
CASSANDRA-13163,NPE in StorageService.excise,"{code}
    private void excise(Collection<Token> tokens, InetAddress endpoint)
    {
        logger.info(""Removing tokens {} for {}"", tokens, endpoint);

        if (tokenMetadata.isMember(endpoint))
            HintsService.instance.excise(tokenMetadata.getHostId(endpoint));

{code}

The check for TMD.isMember() is not enough to guarantee that TMD.getHostId() will not return null. If HintsService.excise() is called with null you get an NPE in a map lookup."
CASSANDRA-13153,Reappeared Data when Mixing Incremental and Full Repairs,"This happens for both LeveledCompactionStrategy and SizeTieredCompactionStrategy.  I've only tested it on Cassandra version 2.2 but it most likely also affects all Cassandra versions after 2.2, if they have anticompaction with full repair.

When mixing incremental and full repairs, there are a few scenarios where the Data SSTable is marked as unrepaired and the Tombstone SSTable is marked as repaired.  Then if it is past gc_grace, and the tombstone and data has been compacted out on other replicas, the next incremental repair will push the Data to other replicas without the tombstone.

Simplified scenario:
3 node cluster with RF=3
Intial config:
	Node 1 has data and tombstone in separate SSTables.
	Node 2 has data and no tombstone.
	Node 3 has data and tombstone in separate SSTables.

Incremental repair (nodetool repair -pr) is run every day so now we have tombstone on each node.
Some minor compactions have happened since so data and tombstone get merged to 1 SSTable on Nodes 1 and 3.
	Node 1 had a minor compaction that merged data with tombstone. 1 SSTable with tombstone.
	Node 2 has data and tombstone in separate SSTables.
	Node 3 had a minor compaction that merged data with tombstone. 1 SSTable with tombstone.

Incremental repairs keep running every day.
Full repairs run weekly (nodetool repair -full -pr). 
Now there are 2 scenarios where the Data SSTable will get marked as ""Unrepaired"" while Tombstone SSTable will get marked as ""Repaired"".

Scenario 1:
        Since the Data and Tombstone SSTable have been marked as ""Repaired"" and anticompacted, they have had minor compactions with other SSTables containing keys from other ranges.  During full repair, if the last node to run it doesn't own this particular key in it's partitioner range, the Data and Tombstone SSTable will get anticompacted and marked as ""Unrepaired"".  Now in the next incremental repair, if the Data SSTable is involved in a minor compaction during the repair but the Tombstone SSTable is not, the resulting compacted SSTable will be marked ""Unrepaired"" and Tombstone SSTable is marked ""Repaired"".

Scenario 2:
        Only the Data SSTable had minor compaction with other SSTables containing keys from other ranges after being marked as ""Repaired"".  The Tombstone SSTable was never involved in a minor compaction so therefore all keys in that SSTable belong to 1 particular partitioner range. During full repair, if the last node to run it doesn't own this particular key in it's partitioner range, the Data SSTable will get anticompacted and marked as ""Unrepaired"".   The Tombstone SSTable stays marked as Repaired.

Then it’s past gc_grace.  Since Node’s #1 and #3 only have 1 SSTable for that key, the tombstone will get compacted out.
	Node 1 has nothing.
	Node 2 has data (in unrepaired SSTable) and tombstone (in repaired SSTable) in separate SSTables.
	Node 3 has nothing.

Now when the next incremental repair runs, it will only use the Data SSTable to build the merkle tree since the tombstone SSTable is flagged as repaired and data SSTable is marked as unrepaired.  And the data will get repaired against the other two nodes.
	Node 1 has data.
	Node 2 has data and tombstone in separate SSTables.
	Node 3 has data.
If a read request hits Node 1 and 3, it will return data.  If it hits 1 and 2, or 2 and 3, however, it would return no data.

Tested this with single range tokens for simplicity.
"
