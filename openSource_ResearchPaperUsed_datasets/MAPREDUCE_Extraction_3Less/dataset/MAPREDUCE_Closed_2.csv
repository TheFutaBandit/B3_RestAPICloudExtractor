Bug_ID,Bug_Summary,Bug_Description
MAPREDUCE-7478,[Decommission]Show Info Log for Repeated Useless refreshNode Operation,https://github.com/apache/hadoop/pull/6921
MAPREDUCE-7475,Fix non-idempotent unit tests,"2 tests are not idempotent and fails upon repeated execution within the same JVM instance due to self-induced state pollution. Specifically, these tests try to make the directory TEST_ROOT_DIR and write to it. The tests do not clean up (remove) the directory after execution. Therefore, in the second execution, TEST_ROOT_DIR would already exist and the exception `Could not create test dir` would be thrown. Below are the 2 non-idempotent tests:
 * org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner
 * org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner"
MAPREDUCE-7474,[ABFS] Improve commit resilience and performance in Manifest Committer,"* Manifest committer is not resilient to rename failures on task commit without HADOOP-18012 rename recovery enabled. 
* large burst of delete calls noted: are they needed?


relates to HADOOP-19093 but takes a more minimal approach with goal of changes in manifest committer only.

Initial proposed changes
* retry recovery on task commit rename, always (repeat save, delete, rename)
* audit delete use and see if it can be pruned"
MAPREDUCE-7470,multi-thread mapreduce v1 FileOutputcommitter,"In cloud environment, such as aws, aliyun etc., the internet delay is non-trival when we commit thounds of files.

In our situation, the ping delay is about 0.03ms in IDC, but when move to Coud, the ping delay is about 3ms, which is roughly 100x slower. We found that, committing tens thounds of files will cost a few tens of minutes. The more files there are, the logger it takes.

So we propose a new committer algorithm, which is a variant of committer algorithm version 1, called 3. In this new algorithm 3, in order to decrease the committer time, we use a thread pool to commit job's final output.

Our test result in Cloud production shows that, the new algorithm 3 has decrease the committer time by serveral tens of times."
MAPREDUCE-7469,NNBench createControlFiles should use thread pool to improve performance.,NNBench is a good tool for NN performance test. And with multiples maps it will wait long time in createControlFiles.  This can use thread pool to increase concurrency.
MAPREDUCE-7468,Change add-opens flag's default value from true to false,"To support avoid issues when a newer JobClient is used with Hadoop versions without MAPREDUCE-7449 the default value of mapreduce.jvm.add-opens-as-default should be false. Currently it's true, this can cause if a newer JobClient is used to submit apps, as the placeholder replacement won't happen during a container launch, resulting in a failed submission."
MAPREDUCE-7463,Fix missing comma in  HistoryServerRest.html response body," the /ws/v1/history/mapreduce/jobs Response Body is missing a comma 

!image-2023-12-11-15-55-09-196.png|width=448,height=336!

 "
MAPREDUCE-7462,Use thread pool to improve the speed of creating control files in TestDFSIO,"When we use TestDFSIO tool to test the throughouts of HDFS clusters, we found it is so slow in the creating controll files stage. 

After refering to the source code, we found that method createControlFile try to create control files serially. It can be improved by using thread pool."
MAPREDUCE-7459,Fixed TestHistoryViewerPrinter flakiness during string comparison ,"The test {{_org.apache.hadoop.mapreduce.jobhistory.TestHistoryViewerPrinter#testHumanPrinterAll_}}

can fail due to flakiness. These flakiness occurs because the test utilizes Hashmaps values and converts the values to string to perform the comparision and the order of the objects returned may not be necessarily maintained. 

The stack trace is as follows:

testHumanPrinterAll(org.apache.hadoop.mapreduce.jobhistory.TestHistoryViewerPrinter)  Time elapsed: 0.297 s  <<< FAILURE!
org.junit.ComparisonFailure:
expected:<...8501754_0001_m_00000[7    6-Oct-2011 19:15:09    6-Oct-2011 19:15:16 (7sec)

SUCCEEDED MAP task list for job_1317928501754_0001
TaskId        StartTime    FinishTime    Error    InputSplits
====================================================
task_1317928501754_0001_m_000006    6-Oct-2011 19:15:08    6-Oct-2011 19:15:14 (6sec)

...

/tasklog?attemptid=attempt_1317928501754_0001_m_000003]_1

REDUCE task list...> but was:<...8501754_0001_m_00000[5    6-Oct-2011 19:15:07    6-Oct-2011 19:15:12 (5sec)

SUCCEEDED MAP task list for job_1317928501754_0001
TaskId        StartTime    FinishTime    Error    InputSplits
====================================================
task_1317928501754_0001_m_000006    6-Oct-2011 19:15:08    6-Oct-2011 19:15:14 (6sec)

SUCCEEDED MAP task list for job_1317928501754_0001
TaskId        StartTime    FinishTime    Error    InputSplits
====================================================
task_1317928501754_0001_m_000004    6-Oct-2011 19:15:06    6-Oct-2011 19:15:10 (4sec)

SUCCEEDED MAP task list for job_1317928501754_0001
TaskId        StartTime    FinishTime    Error    InputSplits
====================================================
task_1317928501754_0001_m_000007    6-Oct-2011 19:15:09    6-Oct-2011 19:15:16 (7sec)

...

/tasklog?attemptid=attempt_1317928501754_0001_m_000006]_1"
MAPREDUCE-7457,Limit number of spill files getting created,"Hi,

 

We have been facing some issues where many of our cluster node disks go full because of some rogue applications creating a lot of spill data

We wanted to fail the app if more than a threshold amount of spill files are written

Please let us know if any such capability is supported

 

If the capability is not there, we are proposing it to support it via a config, we have added a PR for the same: [https://github.com/apache/hadoop/pull/6155]  please let us know your thoughts on it"
MAPREDUCE-7456,Extend add-opens flag to container launch commands on JDK17 nodes,"There was a previous ticket for adding add-opens flag to container launch to be able to run them on JDK17 nodes: https://issues.apache.org/jira/browse/MAPREDUCE-7449

As testing discovered, this should be extended with ""{_}-add-exports=java.base/sun.net.dns=ALL-UNNAMED{_}"" and ""{_}-add-exports=java.base/sun.net.util=ALL-UNNAMED{_}"" options to be able to run containers on Isilon."
MAPREDUCE-7453,Revert HADOOP-18649,"Since HADOOP-18649, in container-log4j.properties, log4j.appender.\{APPENDER}.MaxFileSize is set to ${yarn.app.container.log.filesize}, but yarn.app.container.log.filesize is 0 in default. So log is missing. This log is always rolling and only show the latest log.

This is the running log like below:
{code:java}
Log Type: syslog
Log Upload Time: Fri Sep 08 11:36:09 +0800 2023
Log Length: 0

Log Type: syslog.1
Log Upload Time: Fri Sep 08 11:36:09 +0800 2023
Log Length: 179
2023-09-08 11:31:34,494 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Got an error when resolve hostNames. Falling back to /default-rack for all.  {code}
Note: log4j.appender.\{APPENDER}.MaxFileSize is not set before, then use default value 10M, so no problem before HADOOP-18649"
MAPREDUCE-7451,review TrackerDistributedCacheManager.checkPermissionOfOther,TrackerDistributedCacheManager.checkPermissionOfOther() doesn't seem to work reliably
MAPREDUCE-7449,Add add-opens flag to container launch commands on JDK17 nodes,"To allow containers to launch on JDK17 nodes the add-opens flag should be added to the container launch commands if the node has JDK17+, and it shouldn't on previous JDKs. This behaviour should be configurable."
MAPREDUCE-7446,NegativeArraySizeException when running MR jobs with large data size,"We are using bit shifting to double the byte array in IFile's [nextRawValue|https://github.infra.cloudera.com/CDH/hadoop/blob/bef14a39c7616e3b9f437a6fb24fc7a55a676b57/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/IFile.java#L437] method to store the byte values in it. With large dataset it can easily happen that we shift the leftmost bit when we are calculating the size of the array, which can lead to a negative number as the array size, causing the NegativeArraySizeException.

It would be safer to expand the backing array with a 1.5x factor, and have a check not to extend Integer's max value during that."
MAPREDUCE-7442,exception message is not intusive when accessing the job configuration web UI,"I launched a Teragen job on hadoop-3.3.4 cluster. 

The web occured an error when I clicked the link of Configuration of Job. The error page said ""HTTP ERROR 500 java.lang.IllegalArgumentException: RFC6265 Cookie values may not contain character: [ ]"", and I can't find any solution by this error message.

I found some additional stacks in the log of AM, and those stacks reflect yarn did not have the permission of stagging directory. When I give permission to yarn I can access configuration page.

I think the problem is that the error page does not provide useful or meaningful prompts.

It's better if there are  message about ""yarn does not have hdfs permission"" in the error page.

The snapshot of error page is as follows:
!image-2023-07-14-11-23-10-762.png!

The error logs of am are as folllows:
{code:java}
2023-07-14 11:20:08,218 ERROR [qtp1379757019-43] org.apache.hadoop.yarn.webapp.View: Error while reading hdfs://dmp/user/ubd_dmp_test/.staging/job_1689296289020_0006/job.xml
org.apache.hadoop.security.AccessControlException: Permission denied: user=yarn, access=EXECUTE, inode=""/user/ubd_dmp_test/.staging"":ubd_dmp_test:ubd_dmp_test:drwx------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:506)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:422)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:333)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:713)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1892)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1910)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:727)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getBlockLocations(FSDirStatAndListingOp.java:154)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:2089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:762)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:458)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:902)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:889)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:878)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1046)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:373)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:60)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:670)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:874)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:870)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:876)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.loadConfFile(JobImpl.java:2287)
	at org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfInfo.<init>(ConfInfo.java:45)
	at org.apache.hadoop.mapreduce.v2.app.webapp.ConfBlock.render(ConfBlock.java:71)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:69)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)
	at org.apache.hadoop.yarn.webapp.View.render(View.java:243)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)
	at org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl$EImp._v(HamletImpl.java:117)
	at org.apache.hadoop.yarn.webapp.hamlet2.Hamlet$TD.__(Hamlet.java:848)
	at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)
	at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:216)
	at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.conf(AppController.java:324)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:171)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287)
	at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277)
	at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182)
	at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:941)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)
	at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)
	at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)
	at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:57)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:179)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1764)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.FilterHolder.doFilter(FilterHolder.java:193)
	at org.eclipse.jetty.servlet.ServletHandler$Chain.doFilter(ServletHandler.java:1601)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:548)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:602)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1434)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:501)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1349)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:388)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:633)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:380)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:386)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.lang.Thread.run(Thread.java:748)
{code}
"
MAPREDUCE-7441,Race condition in closing FadvisedFileRegion,"This issue is similar to the one described in MAPREDUCE-7095, just for FadvisedFileRegion.transferSuccessful. There are warning messages when multiple threads are calling the transferSuccessful method:

{code:java}
2023-05-25 08:41:57,288 WARN org.apache.hadoop.mapred.FadvisedFileRegion: Failed to manage OS cache for /hadoop/data04/yarn/nm/usercache/hive/appcache/application_1684916804740_8245/output/attempt_1684916804740_8245_1_00_001154_0_10003/file.out
EBADF: Bad file descriptor
at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:271)
at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:148)
at org.apache.hadoop.mapred.FadvisedFileRegion.transferSuccessful(FadvisedFileRegion.java:163)
at org.apache.hadoop.mapred.ShuffleChannelHandler.lambda$sendMapOutput$0(ShuffleChannelHandler.java:516)
at io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:590)
at io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:557)


{code}
"
MAPREDUCE-7438,Support removal of only selective node states in untracked removal flow,"Currently inactive nodes are removed from the Yarn local memory irrespective of which state they are in. This makes the node removal process not too much configurable

After this patch: https://issues.apache.org/jira/browse/YARN-10854

If autoscaling is enabled, lot many nodes go into DECOMMISSIONED state but still other states like LOST, SHUTDOWN are very less and systems might want them to be still visible on UI for better tracking

The proposal is to introduce a new config, which when set, will allow only selective node states to be removed after going into untracked state.

 

Attaching PR for reference: https://github.com/apache/hadoop/pull/5680

Any thoughts/suggestions/feedbacks are welcome!"
MAPREDUCE-7437,MR Fetcher class to use an AtomicInteger to generate IDs.,"I'm having to do this to get MAPREDUCE-7435 through the build; spotbugs is complaining about the Fetcher constructor incrementing a non-static shared counter. Which is true, just odd it has only just surfaced.

going to fix as a standalone patch but include that in the commit chain of that PR too"
MAPREDUCE-7435,ManifestCommitter OOM on azure job,"I've got some reports of spark jobs OOM if the manifest committer is used through abfs.

either the manifests are using too much memory, or something is not working with azure stream memory use (or both).

before proposing a solution, first step should be to write a test to load many, many manifests, each with lots of dirs and files to see what breaks.

note: we did have OOM issues with the s3a committer, on teragen but those structures have to include every etag of every block, so the manifest size is O(blocks); the new committer is O(files + dirs).

{code}
java.lang.OutOfMemoryError: Java heap space
at org.apache.hadoop.fs.azurebfs.services.AbfsInputStream.readOneBlock(AbfsInputStream.java:314)
at org.apache.hadoop.fs.azurebfs.services.AbfsInputStream.read(AbfsInputStream.java:267)
at java.io.DataInputStream.read(DataInputStream.java:149)
at com.fasterxml.jackson.core.json.ByteSourceJsonBootstrapper.ensureLoaded(ByteSourceJsonBootstrapper.java:539)
at com.fasterxml.jackson.core.json.ByteSourceJsonBootstrapper.detectEncoding(ByteSourceJsonBootstrapper.java:133)
at com.fasterxml.jackson.core.json.ByteSourceJsonBootstrapper.constructParser(ByteSourceJsonBootstrapper.java:256)
at com.fasterxml.jackson.core.JsonFactory._createParser(JsonFactory.java:1656)
at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:1085)
at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3585)
at org.apache.hadoop.util.JsonSerialization.fromJsonStream(JsonSerialization.java:164)
at org.apache.hadoop.util.JsonSerialization.load(JsonSerialization.java:279)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.files.TaskManifest.load(TaskManifest.java:361)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.impl.ManifestStoreOperationsThroughFileSystem.loadTaskManifest(ManifestStoreOperationsThroughFileSystem.java:133)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.AbstractJobOrTaskStage.lambda$loadManifest$6(AbstractJobOrTaskStage.java:493)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.AbstractJobOrTaskStage$$Lambda$231/1813048085.apply(Unknown Source)
at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.invokeTrackingDuration(IOStatisticsBinding.java:543)
at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.lambda$trackDurationOfOperation$5(IOStatisticsBinding.java:524)
at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding$$Lambda$217/489150849.apply(Unknown Source)
at org.apache.hadoop.fs.statistics.impl.IOStatisticsBinding.trackDuration(IOStatisticsBinding.java:445)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.AbstractJobOrTaskStage.loadManifest(AbstractJobOrTaskStage.java:492)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.LoadManifestsStage.fetchTaskManifest(LoadManifestsStage.java:170)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.LoadManifestsStage.processOneManifest(LoadManifestsStage.java:138)
at org.apache.hadoop.mapreduce.lib.output.committer.manifest.stages.LoadManifestsStage$$Lambda$229/137752948.run(Unknown Source)
at org.apache.hadoop.util.functional.TaskPool$Builder.lambda$runParallel$0(TaskPool.java:410)
at org.apache.hadoop.util.functional.TaskPool$Builder$$Lambda$230/467893357.run(Unknown Source)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:750)

{code}

"
MAPREDUCE-7434,Fix ShuffleHandler tests,"https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java8-linux-x86_64/1143/testReport/junit/org.apache.hadoop.mapred/TestShuffleHandler/testMapFileAccess/

{code}
Error Message
Server returned HTTP response code: 500 for URL: http://127.0.0.1:13562/mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0
Stacktrace
java.io.IOException: Server returned HTTP response code: 500 for URL: http://127.0.0.1:13562/mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1902)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1500)
	at org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess(TestShuffleHandler.java:292)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:750)
Standard Output
12:04:17.466 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleConnections with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of current shuffle connections])
12:04:17.466 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Shuffle output in bytes])
12:04:17.466 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputsFailed with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of failed shuffle outputs])
12:04:17.466 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputsOK with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of succeeeded shuffle outputs])
12:04:17.466 [Time-limited test] DEBUG o.a.h.m.impl.MetricsSystemImpl - ShuffleMetrics, Shuffle output metrics
12:04:17.467 [Time-limited test] DEBUG o.a.hadoop.service.AbstractService - Service: mapreduce_shuffle entered state INITED
12:04:17.477 [Time-limited test] DEBUG o.a.hadoop.service.AbstractService - Config has been overridden during init
12:04:17.478 [Time-limited test] INFO  org.apache.hadoop.mapred.IndexCache - IndexCache created with max memory = 10485760
12:04:17.479 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleConnections with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of current shuffle connections])
12:04:17.479 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterLong org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputBytes with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[Shuffle output in bytes])
12:04:17.479 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputsFailed with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of failed shuffle outputs])
12:04:17.479 [Time-limited test] DEBUG o.a.h.m.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableCounterInt org.apache.hadoop.mapred.ShuffleHandler$ShuffleMetrics.shuffleOutputsOK with annotation @org.apache.hadoop.metrics2.annotation.Metric(always=false, sampleName=Ops, valueName=Time, about=, interval=10, type=DEFAULT, value=[# of succeeeded shuffle outputs])
12:04:17.479 [Time-limited test] DEBUG o.a.h.m.impl.MetricsSystemImpl - ShuffleMetrics, Shuffle output metrics
12:04:17.482 [Time-limited test] INFO  o.a.hadoop.mapred.ShuffleHandler - mapreduce_shuffle listening on port 13562
12:04:17.482 [Time-limited test] DEBUG o.a.hadoop.service.AbstractService - Service mapreduce_shuffle is started
12:04:17.483 [Time-limited test] INFO  o.a.hadoop.mapred.ShuffleHandler - Added token for job_1111111111111_0001
12:04:17.486 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - ShuffleChannelInitializer init; channel='a9df992f'
12:04:17.487 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Executing channelActive; channel='a9df992f'
12:04:17.487 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Added channel: [id: 0xa9df992f, L:/127.0.0.1:13562 - R:/127.0.0.1:53014], channel id: a9df992f. Accepted number of connections=1
12:04:17.489 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Received HTTP request: HttpObjectAggregator$AggregatedFullHttpRequest(decodeResult: success, version: HTTP/1.1, content: CompositeByteBuf(ridx: 0, widx: 0, cap: 0, components=0))
GET /mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0 HTTP/1.1
name: mapreduce
version: 1.0.0
UrlHash: +OVYyZ3+ni316LsqZvZcFqgV/H8=
User-Agent: Java/1.8.0_352
Host: 127.0.0.1:13562
Accept: text/html, image/gif, image/jpeg, *; q=.2, */*; q=.2
Connection: keep-alive
content-length: 0, channel='a9df992f'
12:04:17.489 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Received from request header: ShuffleVersion=1.0.0 header name=mapreduce, channel id: a9df992f
12:04:17.489 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - RECV: /mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0
  mapId: [attempt_1111111111111_0001_m_000001_0]
  reduceId: [0]
  jobId: [job_1111111111111_0001]
  keepAlive: false
  channel id: a9df992f
12:04:17.489 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Verifying request. encryptedURL:13562/mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0, hash:sqZvZcFqgV/H8, channel id: a9df992f
12:04:17.490 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Fetcher request verified. encryptedURL: 13562/mapOutput?job=job_1111111111111_0001&reduce=0&map=attempt_1111111111111_0001_m_000001_0, reply: ii/HLwQUsdwdA, channel id: a9df992f
12:04:17.491 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Retrieved pathInfo for AttemptPathIdentifier{attemptId='attempt_1111111111111_0001_m_000001_0', jobId='job_1111111111111_0001'} check for corresponding loaded messages to determine whether it was loaded or cached
12:04:17.491 [ShuffleHandler Netty Worker #0] DEBUG org.apache.hadoop.mapred.IndexCache - IndexCache MISS: MapId attempt_1111111111111_0001_m_000001_0 not found
12:04:17.492 [ShuffleHandler Netty Worker #0] DEBUG o.a.h.f.s.i.IOStatisticsContextIntegration - Created instance IOStatisticsContextImpl{id=5, threadId=136, ioStatistics=counters=();
gauges=();
minimums=();
maximums=();
means=();
}
12:04:17.493 [ShuffleHandler Netty Worker #0] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Got UserName jenkins for ID 910 from the native implementation
12:04:17.494 [ShuffleHandler Netty Worker #0] DEBUG o.apache.hadoop.io.nativeio.NativeIO - Got GroupName jenkins for ID 910 from the native implementation
12:04:17.498 [ShuffleHandler Netty Worker #0] ERROR o.a.hadoop.mapred.ShuffleHandler - Shuffle error while populating headers. Channel id: a9df992f
java.io.IOException: Error Reading IndexFile
	at org.apache.hadoop.mapred.IndexCache.readIndexFileToCache(IndexCache.java:123) ~[hadoop-mapreduce-client-core-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.mapred.IndexCache.getIndexInformation(IndexCache.java:68) ~[hadoop-mapreduce-client-core-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.mapred.ShuffleChannelHandler.getMapOutputInfo(ShuffleChannelHandler.java:360) [classes/:na]
	at org.apache.hadoop.mapred.ShuffleChannelHandler.populateHeaders(ShuffleChannelHandler.java:381) [classes/:na]
	at org.apache.hadoop.mapred.ShuffleChannelHandler.channelRead0(ShuffleChannelHandler.java:275) [classes/:na]
	at org.apache.hadoop.mapred.ShuffleChannelHandler.channelRead0(ShuffleChannelHandler.java:130) [classes/:na]
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:99) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) [netty-codec-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.CombinedChannelDuplexHandler$DelegatingChannelHandlerContext.fireChannelRead(CombinedChannelDuplexHandler.java:436) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:327) [netty-codec-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:299) [netty-codec-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.CombinedChannelDuplexHandler.channelRead(CombinedChannelDuplexHandler.java:251) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:166) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:722) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:658) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:584) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:496) [netty-transport-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995) [netty-common-4.1.77.Final.jar:4.1.77.Final]
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) [netty-common-4.1.77.Final.jar:4.1.77.Final]
	at java.lang.Thread.run(Thread.java:750) [na:1.8.0_352]
Caused by: java.io.IOException: Owner 'jenkins' for path /tmp/test-shuffle-channel-handler1169959588626711767/job_1111111111111_0001/testUser/attempt_1111111111111_0001_m_000001_0/index did not match expected owner 'testUser'
	at org.apache.hadoop.io.SecureIOUtils.checkStat(SecureIOUtils.java:299) ~[hadoop-common-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.io.SecureIOUtils.forceSecureOpenFSDataInputStream(SecureIOUtils.java:183) ~[hadoop-common-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.io.SecureIOUtils.openFSDataInputStream(SecureIOUtils.java:161) ~[hadoop-common-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:71) ~[hadoop-mapreduce-client-core-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:62) ~[hadoop-mapreduce-client-core-3.4.0-SNAPSHOT.jar:na]
	at org.apache.hadoop.mapred.IndexCache.readIndexFileToCache(IndexCache.java:119) ~[hadoop-mapreduce-client-core-3.4.0-SNAPSHOT.jar:na]
	... 32 common frames omitted
12:04:17.502 [Time-limited test] DEBUG o.a.hadoop.service.AbstractService - Service: mapreduce_shuffle entered state STOPPED
12:04:17.503 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - Executing channelInactive; channel='a9df992f'
12:04:17.503 [ShuffleHandler Netty Worker #0] DEBUG o.a.hadoop.mapred.ShuffleHandler - New value of Accepted number of connections=0
{code}"
MAPREDUCE-7433,Remove unused mapred/LoggingHttpResponseEncoder.java,It's no longer needed after MAPREDUCE-7431 (I forgot to include the removal in the previous PR).
MAPREDUCE-7432,Make Manifest Committer the default for abfs and gcs,"Switch to the manifest committer as default for abfs and gcs

* abfs: needed for performance, scale and resilience under some failure modes
* gcs: provides correctness through atomic task commit and better job commit performance"
MAPREDUCE-7431,ShuffleHandler is not working correctly in SSL mode after the Netty 4 upgrade,"HADOOP-15327 introduced some regressions in the ShuffleHandler.
h3. 1. a memory leak
{code:java}
ERROR io.netty.util.ResourceLeakDetector: LEAK: ByteBuf.release() was not called before it's garbage-collected. See https://netty.io/wiki/reference-counted-objects.html for more information.
{code}
 
The Shuffle's channelRead didn't release the message properly, the fix would be this:
{code:java}
      try {
        // ....
      } finally {
        ReferenceCountUtil.release(msg);
      }
{code}
Or even simpler:
{code:java}
extends SimpleChannelInboundHandler<FullHttpRequest>
{code}
h3. 1. a bug in SSL mode with more than 1 reducers

It manifested in multiple errors:
{code:java}
ERROR org.apache.hadoop.mapred.ShuffleHandler: Future is unsuccessful. Cause:
java.io.IOException: Broken pipe

ERROR org.apache.hadoop.mapred.ShuffleHandler: Future is unsuccessful. Cause:
java.nio.channels.ClosedChannelException

// if the reducer memory was not enough, then even this:
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#2
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:136)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:377)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1898)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
Caused by: java.lang.OutOfMemoryError: Java heap space
	at org.apache.hadoop.io.compress.BlockDecompressorStream.getCompressedData(BlockDecompressorStream.java:123)
	at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:98)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:105)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.doShuffle(InMemoryMapOutput.java:91)
{code}
*Configuration* - mapred-site.xml
{code:java}
mapreduce.shuffle.ssl.enabled=true
{code}
Alternative is to build a custom jar where *FadvisedFileRegion* is replaced with *FadvisedChunkedFile* in {*}sendMapOutput{*}.

*Reproduction*
{code:java}
hdfs dfs -rm -r -skipTrash /tmp/sort_input
hdfs dfs -rm -r -skipTrash /tmp/sort_output
yarn jar hadoop-3.4.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.0-SNAPSHOT.jar randomwriter ""-Dmapreduce.randomwriter.totalbytes=10000000000"" /tmp/sort_input
yarn jar hadoop-3.4.0-SNAPSHOT/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.4.0-SNAPSHOT.jar sort -Dmapreduce.job.reduce.slowstart.completedmaps=1 -r 40 /tmp/sort_input /tmp/sort_output | tee sort_app_output.txt
{code}
h3. ShuffleHandler's protocol
{code:java}
// HTTP Request
GET /mapOutput?job=job_1672901779104_0001&reduce=0&map=attempt_1672901779104_0001_m_000003_0,attempt_1672901779104_0001_m_000002_0,attempt_1672901779104_0001_m_000001_0,attempt_1672901779104_0001_m_000000_0,attempt_1672901779104_0001_m_000005_0,attempt_1672901779104_0001_m_000012_0,attempt_1672901779104_0001_m_000009_0,attempt_1672901779104_0001_m_000010_0,attempt_1672901779104_0001_m_000007_0,attempt_1672901779104_0001_m_000011_0,attempt_1672901779104_0001_m_000008_0,attempt_1672901779104_0001_m_000013_0,attempt_1672901779104_0001_m_000014_0,attempt_1672901779104_0001_m_000015_0,attempt_1672901779104_0001_m_000019_0,attempt_1672901779104_0001_m_000018_0,attempt_1672901779104_0001_m_000016_0,attempt_1672901779104_0001_m_000017_0,attempt_1672901779104_0001_m_000020_0,attempt_1672901779104_0001_m_000023_0 HTTP/1.1
+ keep alive headers

// HTTP Response Headers
content-length=sum(serialised ShuffleHeader in bytes + MapOutput size)
+ keep alive headers

// Response Data (transfer-encoding=chunked)
serialised ShuffleHeader
content of the MapOutput file (start offset - length)
serialised ShuffleHeader
content of the MapOutput file (start offset - length)
serialised ShuffleHeader
content of the MapOutput file (start offset - length)
serialised ShuffleHeader
content of the MapOutput file (start offset - length)
...
LastHttpContent
// close socket if no keep-alive
{code}
h3. Issues
 - {*}setResponseHeaders{*}: did not always set the the content-length, also the transfer-encoding=chunked header was missing.
 - {*}ReduceMapFileCount.operationComplete{*}: messed up the futures on the LastHttpContent
 - {*}ChannelGroup accepted{*}: is only used to close the channels, no need for that magic 5. See the details [here|https://netty.io/4.0/api/io/netty/channel/group/ChannelGroup.html].
 - {*}bossGroup{*}: should have only 1 thread for accepting connections.
 - {*}Shuffle{*}: is unnecessarily Sharable, the 3 async sendMap / channel (see below) caused future errors when using FadvisedChunkedFile

h3. Max session open files is not an optimisation, it's actually wasting resources
{code:java}
    // by default maxSessionOpenFiles = 3
    for (int i = 0; i < Math.min(handlerCtx.maxSessionOpenFiles, mapIds.size()); i++) {
      ChannelFuture nextMap = sendMap(reduceContext);
      if(nextMap == null) {
        return;
      }
    }
{code}
!sendMapPipeline.png!

At the end of the day, we create a http chunked stream, there is no need to run 3 sendMap async, the futures will finish one-by-one sequentially. The osCache magic from the FAdvised classes won't happen either, because the first readChunk will be called only later.

So this can be simplified a lot:
{code:java}
sendMap(reduceContext);
{code}
h3. My proposal

Some refactoring: ShuffleHandler is split into multiple classes to make it possible to remove the sharable annotation.
 - ShuffleChannel
 - ShuffleChannelInitializer
 - ShuffleChannelHandlerContext
 - ShuffleChannelHandler

TODO:
 - fix/drop/refactor the existing unit tests
 - add proper unit test that tests SSL/non-SSL mode where the response data is properly verified
 - documentation about the protocol

WIP: [github.com/tomicooler/hadoop|https://github.com/tomicooler/hadoop/commit/3bc027598aea4a3b02a1997fe5d485b9a6e5c41e]
h3. Netty useful docs
 * [User guide for 4.x|https://netty.io/wiki/user-guide-for-4.x.html]
 * [New and noteworthy in 4.0|https://netty.io/wiki/new-and-noteworthy-in-4.0.html]
 * [Reference counted objects|https://netty.io/wiki/reference-counted-objects.html]   (it will be changed in [Netty 5|https://netty.io/wiki/new-and-noteworthy-in-5.0.html])
 * HttpStaticFileServer [example|https://github.com/netty/netty/blob/4.1/example/src/main/java/io/netty/example/http/file/HttpStaticFileServerHandler.java]"
MAPREDUCE-7428,Fix failures related to Junit 4 to Junit 5 upgrade in org.apache.hadoop.mapreduce.v2.app.webapp,"Few test are getting failed due to Junit 4 to Junit 5 upgrade in org.apache.hadoop.mapreduce.v2.app.webapp 

[https://ci-hadoop.apache.org/view/Hadoop/job/hadoop-qbt-trunk-java8-linux-x86_64/1071/testReport/]"
MAPREDUCE-7426,Fix typo in class StartEndTImesBase,"While going through the code , found some typo in the code related to naming variables 

- +slowTaskRelativeTresholds+ spells wrong can be fixed to +slowTaskRelativeThresholds+"
MAPREDUCE-7425,Document Fix for yarn.app.mapreduce.client-am.ipc.max-retries,"The document of *yarn.app.mapreduce.client-am.ipc.max-retries* and *yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts* is not detailed and complete. *yarn.app.mapreduce.client-am.ipc.max-retries* is used to *overwrite ipc.client.connect.max.retries* in ClientServiceDelegate.java. So, the document is suggested to fix as: (refer to yarn.client.failover-retries)

 
{code:java}
// mapred-default.xml
<property>
  <name>yarn.app.mapreduce.client-am.ipc.max-retries</name>
  <value>3</value>
  <description>The number of client retries to the AM - before reconnecting
-    to the RM to fetch Application Status.</description>
+    to the RM to fetch Application Status. 
+    In other words, it is the ipc.client.connect.max.retries to be used during
+    reconnecting to the RM and fetching Application Status.</description>
</property> {code}
 

 

 "
MAPREDUCE-7422,Upgrade Junit 4 to 5 in hadoop-mapreduce-examples,Upgrade Junit 4 to 5 in hadoop-mapreduce-examples
MAPREDUCE-7419,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-common,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-common
MAPREDUCE-7417,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-uploader,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-uploader
MAPREDUCE-7413,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-hs-plugins,Upgrade Junit 4 to 5 in hadoop-mapreduce-client-hs-plugins
MAPREDUCE-7412,I oder headset but I didn't get. ,
MAPREDUCE-7411,Use secure XML parser utils in MapReduce,"Uptake of HADOOP-18469

If anyone is landing on this page following any security scanner alert, know that there is no known issue here, just a centralisation of all construction of XML parsers with lockdown of all the features."
MAPREDUCE-7409,Make shuffle key length configurable,FIPS-compliant HMAC-SHA1 algorithms require secret keys to be at least 112 bits long. [https://github.com/apache/hadoop/blob/231a4468cdb83f9c2ff8897e70fe7c3d23b58cf4/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmitter.java#L180] could be made configurable in order to remain FIPS-compliant.
MAPREDUCE-7407,Avoid stopContainer() on dead node,"If a container failed to launch earlier due to terminated instances, it has already been removed from the container hash map. Avoiding the kill() for CONTAINER_REMOTE_CLEANUP will avoid wasting 15min per container on retries/timeout."
MAPREDUCE-7403,Support spark dynamic partitioning in the Manifest Committer,"
Currently the spark integration with PathOutputCommitters rejects attempt to instantiate them if dynamic partitioning is enabled. That is because the spark partitioning code assumes that
# file rename works as a fast and safe commit algorithm
# the working directory is in the same FS as the final directory

Assumption 1 doesn't hold on s3a, and #2 isn't true for the staging committers.


The new abfs/gcs manifest committer and the target stores do meet both requirements. So we no longer need to reject the operation, provided the spark side binding-code can can identify when all is good.


Proposed: add a new hasCapability() probe which, if, a committer implements StreamCapabilities can be used to see if the committer will work. ManifestCommitter will declare that it holds. As the API has existed since 2.10, it will be immediately available.

spark's PathOutputCommitProtocol to query the committer in setupCommitter, and fail if dynamicPartitionOverwrite is requested but not available.

BindingParquetOutputCommitter to implement and forward StreamCapabilities.hasCapability. "
MAPREDUCE-7401,Optimize liststatus for better performance by using recursive listing,This change adds recursive listing APIs to FileSystem. The purpose is to enable different FileSystem implementations optimize on the listStatus calls if they can. Default implementation is provided for normal FileSystem implementation which does level by level listing for each directory.
MAPREDUCE-7391,TestLocalDistributedCacheManager failing after HADOOP-16202,"After HADOOP-16202, TestLocalDistributedCacheManager.testDownload is failing with an NPE"
MAPREDUCE-7390,Remove WhiteBox in mapreduce module.,"WhiteBox is deprecated, try to remove this method in hadoop-mapreduce."
MAPREDUCE-7389,"Typo in description of ""mapreduce.application.classpath"" in mapred-default.xml","There is a small typo for {variable} in the description of ""mapreduce.application.classpath"" in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml.

{noformat}
If mapreduce.app-submission.cross-platform is false, platform-specific
environment vairable expansion syntax would be used to construct the default
CLASSPATH entries.
{noformat}

I just stumbled upon that and will open a PR over at github.com."
MAPREDUCE-7387,Fix TestJHSSecurity#testDelegationToken AssertionError due to HDFS-16563,"During the processing of HADOOP-18284. Fix Repeated Semicolons., PR#4422 was submitted, and an error was reported in hadoop.mapreduce.security.TestJHSSecurity#testDelegationToken in the test report.
{code:java}
[ERROR] testDelegationToken(org.apache.hadoop.mapreduce.security.TestJHSSecurity)  Time elapsed: 16.344 s  <<< FAILURE!
java.lang.AssertionError
	at org.junit.Assert.fail(Assert.java:87)
	at org.junit.Assert.assertTrue(Assert.java:42)
	at org.junit.Assert.assertTrue(Assert.java:53)
	at org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken(TestJHSSecurity.java:163)
.....{code}
It can be found that HDFS-16563 is causing this problem.

The reason is because HDFS-16563 changed error msg, which made MR's Jinit Test assertion fail."
MAPREDUCE-7386,Maven parallel builds (skipping tests) fail,"Running a parallel build fails during assembly with the following error when running either package or install:
{code:java}
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-assembly-plugin:2.4:single (package-mapreduce) on project hadoop-mapreduce: Failed to create assembly: Artifact: org.apache.hadoop:hadoop-mapreduce-client-core:jar:3.4.0-SNAPSHOT (included by module) does not have an artifact with a file. Please ensure the package phase is run before the assembly is generated. {code}
{code:java}
Caused by: org.apache.maven.plugin.MojoExecutionException: Failed to create assembly: Artifact: org.apache.hadoop:hadoop-mapreduce-client-core:jar:3.4.0-SNAPSHOT (included by module) does not have an artifact with a file. Please ensure the package phase is run before the assembly is generated.  {code}
The command executed was:
{code:java}
$ mvn -nsu clean install -Pdist,native -DskipTests -Dtar -Dmaven.javadoc.skip=true -T 2C {code}
Adding dependencies to the assembly plugin configuration addresses the issue "
MAPREDUCE-7385,impove JobEndNotifier#httpNotification With recommended methods,"JobEndNotifier#httpNotification's DefaultHttpClient has been Deprecated, use the recommended method instead

JobEndNotifier#httpNotification
{code:java}
private static int httpNotification(String uri, int timeout)
      throws IOException, URISyntaxException {
    DefaultHttpClient client = new DefaultHttpClient();
    client.getParams()
        .setIntParameter(CoreConnectionPNames.SO_TIMEOUT, timeout)
        .setLongParameter(ClientPNames.CONN_MANAGER_TIMEOUT, (long) timeout);
    HttpGet httpGet = new HttpGet(new URI(uri));
    httpGet.setHeader(""Accept"", ""*/*"");
    return client.execute(httpGet).getStatusLine().getStatusCode();
  } {code}
 * CoreConnectionPNames.SO_TIMEOUT
 * Use RequestConfig.setSocketTimeout instead

{code:java}
Deprecated.Defines the socket timeout (SO_TIMEOUT) in milliseconds, which is the timeout for waiting for data or, put differently, a maximum period inactivity between two consecutive data packets). A timeout value of zero is interpreted as an infinite timeout. {code}
 
 * ClientPNames.CONN_MANAGER_TIMEOUT
 * Use RequestConfig.setConnectionRequestTimeout instead

{code:java}
Deprecated. Defines the timeout in milliseconds used when retrieving an instance of ManagedClientConnection from the ClientConnectionManager. {code}
 
 

 "
MAPREDUCE-7384,impove import * In MapReduce Project,"Directly using * to reference does not conform to the code specification, adjust it and refer to the specified package."
MAPREDUCE-7379,RMContainerRequestor#makeRemoteRequest has confusing log message,"org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor#makeRemoteRequest has this log: 

{code:java}
if (ask.size() > 0 || release.size() > 0) {
      LOG.info(""getResources() for "" + applicationId + "":"" + "" ask=""
          + ask.size() + "" release= "" + release.size() + "" newContainers=""
          + allocateResponse.getAllocatedContainers().size()
          + "" finishedContainers="" + numCompletedContainers
          + "" resourcelimit="" + availableResources + "" knownNMs=""
          + clusterNmCount);
    }
{code}
The reason why ""getResources()"" is printed because org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator#getResources invokes makeRemoteRequest. This is not too informative and error-prone as name of getResources could change over time and the log will be outdated. Moreover, it's not a good idea to print a method name from a method below the current one in the stack.
"
MAPREDUCE-7378,An error occurred while concurrently writing to a path,"When we use FileOutputCommitter as the base class of Job Committer for other components, we may meet an concurrently writing problem.

Like HadoopMapReduceCommitProtocol in Spark, when there have multiple application to write data in same path, they will commit job and task in the ""_temporary"" dir. Once a Job finished ,it will delete the ""_temporary"" dir, make the other jobs failed.

 

error message:
{code:java}
// code placeholder

21/11/04 19:01:21 ERROR Utils: Aborting task ExitCodeException exitCode=1: chmod: cannot access '/data/spark-examples/spark-warehouse/test/temporary/0/_temporary/attempt_202111041901182933014038999149736_0001_m_000001 4/dt=2021-11-03/hour=10/.part-00001-95895b03-45d2-4ac6-806b-b76fd1dfa3dc.c000.snappy.parquet.crc': No such file or directory at org.apache.hadoop.util.Shell.runCommand(Shell.java:1008) at org.apache.hadoop.util.Shell.run(Shell.java:901) at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213) at org.apache.hadoop.util.Shell.execCommand(Shell.java:1307) at org.apache.hadoop.util.Shell.execCommand(Shell.java:1289) at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978) at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:324) at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294) at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428) at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459) at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521) at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195) at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175) at org.apache.parquet.hadoop.util.HadoopOutputFile.create(HadoopOutputFile.java:74) at org.apache.parquet.hadoop.ParquetFileWriter.<init>(ParquetFileWriter.java:329) at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:482) at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:420) at org.apache.parquet.hadoop.ParquetOutputFormat.getRecordWriter(ParquetOutputFormat.java:409) at org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.<init>(ParquetOutputWriter.scala:36) at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$$anon$1.newInstance(ParquetFileFormat.scala:150) at org.apache.spark.sql.execution.datasources.BaseDynamicPartitionDataWriter.renewCurrentWriter(FileFormatDataWriter.scala:290) at org.apache.spark.sql.execution.datasources.DynamicPartitionDataSingleWriter.write(FileFormatDataWriter.scala:357) at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithMetrics(FileFormatDataWriter.scala:85) at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:92) at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304) at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496) at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311) at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:131) at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 21/11/04 19:01:21 WARN FileOutputCommitter: Could not delete file:/data/spark-examples/spark-warehouse/test/temporary/0/_temporary/attempt_202111041901182933014038999149736 0001_m_000001_4

{code}
 

The spark Issue is [SPARK-37210](https://issues.apache.org/jira/browse/SPARK-37210)"
MAPREDUCE-7377,Remove unused imports in MapReduce project,"h3. Optimize Imports to keep code clean
 # Remove any unused imports"
MAPREDUCE-7376,AggregateWordCount fetches wrong results,"AggregateWordCount rather than counting  the words, gives a single line output counting the number of rows
Wrong Result Looks Like:

{noformat}
hadoop-3.4.0-SNAPSHOT % bin/hdfs dfs -cat /testOut1/part-r-00000    
record_count 2
{noformat}

Correct Should Look Like:

{noformat}
hadoop-3.4.0-SNAPSHOT % bin/hdfs dfs -cat /testOut1/part-r-00000                                                                                           
Bye	1
Goodbye	1
Hadoop	2
Hello	2
World	2
{noformat}

"
MAPREDUCE-7375,JobSubmissionFiles don't set right permission after mkdirs,"JobSubmissionFiles provide getStagingDir to get Staging Directory.If stagingArea missing, method will create new directory with this.
{quote}fs.mkdirs(stagingArea, new FsPermission(JOB_DIR_PERMISSION));{quote}
It seems create new directory with JOB_DIR_PERMISSION,but this permission will be apply by umask.If umask too strict , this permission may be 000(if umask is 700).So we should change permission after create."
MAPREDUCE-7373,Building MapReduce NativeTask fails on Fedora 34+,"Fedora 34 adopted GCC 11, in which C++17 features are enabled by default.
https://gcc.gnu.org/projects/cxx-status.html#cxx17

Building MapReduce NativeTask with it leads to the following error.
(I found it on branch-3.2, but it's supposed to be the same as trunk)

{code}
$ mvn package -Pdist,native -DskipTests -Dtar -Dmaven.javadoc.skip=true

...

[WARNING] In file included from /home/vagrant/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/MapOutputCollector.h:30,
[WARNING]                  from /home/vagrant/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/handler/MCollectorOutputHandler.cc:24:
[WARNING] /home/vagrant/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/PartitionBucket.h:127:36: error: ISO C++17 does not allow dynamic exception specifications
[WARNING]   127 |   void spill(IFileWriter * writer) throw (IOException, UnsupportException);
[WARNING]       |                                    ^~~~~
[WARNING] make[2]: *** [CMakeFiles/nativetask_static.dir/build.make:160: CMakeFiles/nativetask_static.dir/main/native/src/handler/MCollectorOutputHandler.cc.o] Error 1
[WARNING] make[1]: *** [CMakeFiles/Makefile2:115: CMakeFiles/nativetask_static.dir/all] Error 2
[WARNING] make: *** [Makefile:91: all] Error 2

...

[INFO] Apache Hadoop MapReduce HistoryServer Plugins ...... SUCCESS [  0.570 s]
[INFO] Apache Hadoop MapReduce NativeTask ................. FAILURE [ 11.016 s]
[INFO] Apache Hadoop MapReduce Uploader ................... SKIPPED
[INFO] Apache Hadoop MapReduce Examples ................... SKIPPED
[INFO] Apache Hadoop MapReduce ............................ SKIPPED
[INFO] Apache Hadoop MapReduce Streaming .................. SKIPPED
[INFO] Apache Hadoop Distributed Copy ..................... SKIPPED
[INFO] Apache Hadoop Archives ............................. SKIPPED
[INFO] Apache Hadoop Archive Logs ......................... SKIPPED
[INFO] Apache Hadoop Rumen ................................ SKIPPED
[INFO] Apache Hadoop Gridmix .............................. SKIPPED
[INFO] Apache Hadoop Data Join ............................ SKIPPED
[INFO] Apache Hadoop Extras ............................... SKIPPED
[INFO] Apache Hadoop Pipes ................................ SKIPPED
[INFO] Apache Hadoop OpenStack support .................... SKIPPED
[INFO] Apache Hadoop Amazon Web Services support .......... SKIPPED
[INFO] Apache Hadoop Kafka Library support ................ SKIPPED
[INFO] Apache Hadoop Azure support ........................ SKIPPED
[INFO] Apache Hadoop Aliyun OSS support ................... SKIPPED
[INFO] Apache Hadoop Client Aggregator .................... SKIPPED
[INFO] Apache Hadoop Scheduler Load Simulator ............. SKIPPED
[INFO] Apache Hadoop Resource Estimator Service ........... SKIPPED
[INFO] Apache Hadoop Azure Data Lake support .............. SKIPPED
[INFO] Apache Hadoop Tools Dist ........................... SKIPPED
[INFO] Apache Hadoop Tools ................................ SKIPPED
[INFO] Apache Hadoop Client API ........................... SKIPPED
[INFO] Apache Hadoop Client Runtime ....................... SKIPPED
[INFO] Apache Hadoop Client Packaging Invariants .......... SKIPPED
[INFO] Apache Hadoop Client Test Minicluster .............. SKIPPED
[INFO] Apache Hadoop Client Packaging Invariants for Test . SKIPPED
[INFO] Apache Hadoop Client Packaging Integration Tests ... SKIPPED
[INFO] Apache Hadoop Distribution ......................... SKIPPED
[INFO] Apache Hadoop Client Modules ....................... SKIPPED
[INFO] Apache Hadoop Cloud Storage ........................ SKIPPED
[INFO] Apache Hadoop Cloud Storage Project ................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  04:10 min
[INFO] Finished at: 2022-03-30T01:49:59Z
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:3.2.4-SNAPSHOT:cmake-compile (cmake-compile) on project hadoop-mapreduce-client-nativetask: make failed with error code 2 -> [Help 1]
{code}"
MAPREDUCE-7372,MapReduce set permission too late in copyJar method,"while execute copyJar in JobResourceUploader .the setPermission running after setReplication,but setReplication need permission first.So if we set restrict umask in project such as 0600, the mapreduce process will fail.

In patch file , I put setPermisson before setReplication."
MAPREDUCE-7371,DistributedCache alternative APIs should not use DistributedCache APIs internally,"DistributedCache has been deprecated long back and it's still being used as of today. However, all the alternative Job APIs (for deprecated DistributedCache APIs) still internally use DistributedCache APIs only, this is a deadlock and it leaves no room for removal of DistributedCache APIs in future. We should move core logic to Job or JobContext as required and let deprecated DistributedCache APIs point to the right alternatives internally."
MAPREDUCE-7370,Parallelize MultipleOutputs#close call,"This call takes more time when there are lot of files to close and there is a high latency to close. Parallelize MultipleOutputs#close call to improve the speed.

{code}
  public void close() throws IOException {
    for (RecordWriter writer : recordWriters.values()) {
      writer.close(null);
    }
  }
{code}

Idea is from [~stevel@apache.org]"
MAPREDUCE-7369,MapReduce tasks timing out when spends more time on MultipleOutputs#close,"MapReduce tasks timing out when spends more time on MultipleOutputs#close. MultipleOutputs#closes takes more time when there are multiple files to be closed & there is a high latency in closing a stream.

{code}
2021-11-01 02:45:08,312 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1634949471086_61268_m_001115_0: AttemptID:attempt_1634949471086_61268_m_001115_0 Timed out after 300 secs
{code}

MapReduce task timeout can be increased but it is tough to set the right timeout value. The timeout can be disabled with 0 but that might lead to hanging tasks not getting killed.

The tasks are sending the ping every 3 seconds which are not honored by ApplicationMaster. It expects the status information which won't be send during MultipleOutputs#close. This jira is to add a config which considers the ping from task as part of Task Liveliness Check in the ApplicationMaster.




"
MAPREDUCE-7368,DBOutputFormat.DBRecordWriter#write must throw exception when it fails,"When the [DBRecordWriter#write|https://github.com/apache/hadoop/blob/91af256a5b44925e5dfdf333293251a19685ba2a/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/db/DBOutputFormat.java#L120] fails with an {{SQLException}} the problem is not propagated but printed in {{System.err}} instead. 

{code:java}
public void write(K key, V value) throws IOException {
      try {
        key.write(statement);
        statement.addBatch();
      } catch (SQLException e) {
        e.printStackTrace();
      }
    }
{code}

The consumer of this API has no way to tell that the write failed. Moreover, the exception is not present in the logs which makes the problem very hard debug and can easily lead to data corruption since clients can easily assume that everything went well."
MAPREDUCE-7366,FileOutputCommitter Enable Concurrent Writes ,"is it possible to make `{{PENDING_DIR_NAME}}` configurable? 
That will enable concurrent writes to same location. current if two spark processes write same destination one of them is failing.

current
{code:java}
 public static final String PENDING_DIR_NAME = ""_temporary"";{code}

new:
{code:java}
PENDING_DIR_NAME = conf.get(""mapreduce.fileoutputcommitter.pending.dir"", ""_temporary"");{code}

here is custom commiter doing it: https://gist.github.com/ismailsimsek/33c55d8e1fcfc79160483c38a978edbd"
MAPREDUCE-7365,AppMaster register  UAM can lost application priority in subCluster,"AppMaster register uam to subCluster can lost application priority in yarn federation cluster.Which make the subCluster's RM allocate resouce to application use default priority regardless of the application's real priority.

By analyzing the code, I found that the appMaster submitApplication to subCluster did't set the priority to ApplicationSubmissionContext. As follows:

 
{code:java}
private void submitUnmanagedApp(ApplicationId appId)
 throws YarnException, IOException {
 SubmitApplicationRequest submitRequest =
 this.recordFactory.newRecordInstance(SubmitApplicationRequest.class);
ApplicationSubmissionContext context = this.recordFactory
 .newRecordInstance(ApplicationSubmissionContext.class);
context.setApplicationId(appId);
 context.setApplicationName(APP_NAME + ""-"" + appNameSuffix);
 if (StringUtils.isBlank(this.queueName)) {
 context.setQueue(this.conf.get(DEFAULT_QUEUE_CONFIG,
 YarnConfiguration.DEFAULT_QUEUE_NAME));
 } else {
 context.setQueue(this.queueName);
 }
ContainerLaunchContext amContainer =
 this.recordFactory.newRecordInstance(ContainerLaunchContext.class);
 Resource resource = BuilderUtils.newResource(1024, 1);
 context.setResource(resource);
 context.setAMContainerSpec(amContainer);
 submitRequest.setApplicationSubmissionContext(context);
context.setUnmanagedAM(true);
 context.setKeepContainersAcrossApplicationAttempts(
 this.keepContainersAcrossApplicationAttempts);
LOG.info(""Submitting unmanaged application {}"", appId);
 this.rmClient.submitApplication(submitRequest);
 }
{code}
Finnally, I fixed this by set application's priority to the ApplicationSubmissionContext.  The priority which from the homeCluster's response when register appMaster to homeCluster's RM.

 "
MAPREDUCE-7363,Rename JobClientUnitTest to TestJobClient,
MAPREDUCE-7356,Remove few duplicate dependencies from mapreduce-client's child poms,Few dependencies are redundant in hadoop-mapreduce-client's child projects as they are already inherited from parent pom.
MAPREDUCE-7354,Use empty array constants present in TaskCompletionEvent to avoid creating redundant objects,"As per one of the suggestions over PR#3115 (HDFS-16075), we should use empty array constant present in TaskCompletionEvent to avoid creating redundant objects."
MAPREDUCE-7353,Mapreduce job fails when NM is stopped,"Job fails as task fail due to too many fetch failures 
{code:java}
Line 48048: 2021-06-02 16:25:02,002 | INFO  | ContainerLauncher #6 | Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_e03_1622107691213_1054_01_000005 taskAttempt attempt_1622107691213_1054_m_000000_0 | ContainerLauncherImpl.java:394
	Line 48053: 2021-06-02 16:25:02,002 | INFO  | ContainerLauncher #6 | KILLING attempt_1622107691213_1054_m_000000_0 | ContainerLauncherImpl.java:209
	Line 58026: 2021-06-02 16:26:34,034 | INFO  | AsyncDispatcher event handler | TaskAttempt killed because it ran on unusable node node-group-1ZYEq0002:26009. AttemptId:attempt_1622107691213_1054_m_000000_0 | JobImpl.java:1401
	Line 58030: 2021-06-02 16:26:34,034 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_KILL | TaskAttemptImpl.java:1390
	Line 58035: 2021-06-02 16:26:34,034 | INFO  | RMCommunicator Allocator | Killing taskAttempt:attempt_1622107691213_1054_m_000000_0 because it is running on unusable node:node-group-1ZYEq0002:26009 | RMContainerAllocator.java:1066
	Line 58043: 2021-06-02 16:26:34,034 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_KILL | TaskAttemptImpl.java:1390
	Line 58054: 2021-06-02 16:26:34,034 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_DIAGNOSTICS_UPDATE | TaskAttemptImpl.java:1390
	Line 58055: 2021-06-02 16:26:34,034 | INFO  | AsyncDispatcher event handler | Diagnostics report from attempt_1622107691213_1054_m_000000_0: Container released on a *lost* node | TaskAttemptImpl.java:2649
	Line 58057: 2021-06-02 16:26:34,034 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_KILL | TaskAttemptImpl.java:1390
	Line 60317: 2021-06-02 16:26:57,057 | INFO  | AsyncDispatcher event handler | Too many fetch-failures for output of task attempt: attempt_1622107691213_1054_m_000000_0 ... raising fetch failure to map | JobImpl.java:2005
	Line 60319: 2021-06-02 16:26:57,057 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_TOO_MANY_FETCH_FAILURE | TaskAttemptImpl.java:1390
	Line 60320: 2021-06-02 16:26:57,057 | INFO  | AsyncDispatcher event handler | attempt_1622107691213_1054_m_000000_0 transitioned from state SUCCESS_CONTAINER_CLEANUP to FAILED, event type is TA_TOO_MANY_FETCH_FAILURE and nodeId=node-group-1ZYEq0002:26009 | TaskAttemptImpl.java:1411
	Line 69487: 2021-06-02 16:30:02,002 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_DIAGNOSTICS_UPDATE | TaskAttemptImpl.java:1390
	Line 69527: 2021-06-02 16:30:02,002 | INFO  | AsyncDispatcher event handler | Diagnostics report from attempt_1622107691213_1054_m_000000_0: cleanup failed for container container_e03_1622107691213_1054_01_000005 : java.net.ConnectException: Call From node-group-1ZYEq0001/192.168.0.66 to node-group-1ZYEq0002:26009 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	Line 69607: 2021-06-02 16:30:02,002 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_CONTAINER_CLEANED | TaskAttemptImpl.java:1390
	Line 69609: 2021-06-02 16:30:02,002 | DEBUG | AsyncDispatcher event handler | Processing attempt_1622107691213_1054_m_000000_0 of type TA_CONTAINER_CLEANED | TaskAttemptImpl.java:1390
	Line 73645: 2021-06-02 16:23:56,056 | DEBUG | fetcher#9 | Fetcher 9 going to fetch from node-group-1ZYEq0002:26008 for: [attempt_1622107691213_1054_m_000000_0] | Fetcher.java:318
	Line 73646: 2021-06-02 16:23:56,056 | DEBUG | fetcher#9 | MapOutput URL for node-group-1ZYEq0002:26008 -> http://node-group-1ZYEq0002:26008/mapOutput?job=job_1622107691213_1054&reduce=4&map=attempt_1622107691213_1054_m_000000_0 | Fetcher.java:686
	Line 74093: 2021-06-02 16:26:56,056 | INFO  | fetcher#9 | Reporting fetch failure for attempt_1622107691213_1054_m_000000_0 to MRAppMaster. | ShuffleSchedulerImpl.java:349
{code}

As we can see from logs that RM reported AM about node update at 16:26:34 but event was skipped as KILL event is ignored when TaskAttemptImpl is in SUCCESS_CONTAINER_CLEANUP state. So next we receive TA_TOO_MANY_FETCH_FAILURE event which will lead to task fail. 
 "
MAPREDUCE-7352,ArithmeticException in some MapReduce tests,"There are some ArithmeticException failures in certain MapReduce test cases, for example:

{noformat}
2021-06-14 14:14:20,078 INFO  [main] service.AbstractService (AbstractService.java:noteFailure(267)) - Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state STARTED
java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:304)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1015)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:141)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1544)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1263)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:301)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:285)
	at org.apache.hadoop.mapreduce.v2.app.TestMRApp.testUpdatedNodes(TestMRApp.java:223)
{noformat}

We have to set {{detailsInterval}} when the async dispatcher is spied. For some reason, despite the fact that {{serviceInit()}} is called, this variable remains zero."
MAPREDUCE-7351,CleanupJob during handle of SIGTERM signal,"Currently MR CleanupJob happens when the job is either successful or fail. But during kill, it is not handled. This leaves all the temporary folders under the output path."
MAPREDUCE-7350,Replace Guava Lists usage by Hadoop's own Lists in hadoop-mapreduce-project,
MAPREDUCE-7348,TestFrameworkUploader#testNativeIO fails,"TestFrameworkUploader#testNativeIO fails.
{noformat}
[INFO] Running org.apache.hadoop.mapred.uploader.TestFrameworkUploader
[ERROR] Tests run: 16, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 8.038 s <<< FAILURE! - in org.apache.hadoop.mapred.uploader.TestFrameworkUploader
[ERROR] testNativeIO(org.apache.hadoop.mapred.uploader.TestFrameworkUploader)  Time elapsed: 0.026 s  <<< ERROR!
org.apache.commons.io.IOExceptionList: 2 exceptions: [java.io.IOException: Unable to delete file: /home/jenkins/jenkins-home/workspace/hadoop-qbt-trunk-java8-linux-x86_64/sourcedir/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target/test-dir/3575932722382085229/symlinkToTarget2.txt, java.io.IOException: Unable to delete file: /home/jenkins/jenkins-home/workspace/hadoop-qbt-trunk-java8-linux-x86_64/sourcedir/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/target/test-dir/3575932722382085229/symlinkToTarget.txt]
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:345)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1206)
	at org.apache.hadoop.mapred.uploader.TestFrameworkUploader.testNativeIO(TestFrameworkUploader.java:480)
{noformat}
https://ci-hadoop.apache.org/job/hadoop-qbt-trunk-java8-linux-x86_64/518/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-uploader.txt
"
MAPREDUCE-7343,Increase the job name max length in mapred job -list ,"Presently the job name length is capped at 20, But in many cases(One being Hive). The length gets crossed in too many cases and post that it doesn't fetch much value.

 

Propose to increase the length limit from 20->35 here:
{code:java}
writer.printf(dataPattern, job.getJobID().toString(),
    job.getJobName().substring(0, jobNameLength > 20 ? 20 : jobNameLength),
{code}
 

 "
MAPREDUCE-7342,Stop RMService in TestClientRedirect.testRedirect(),"The test *{{*org.apache.hadoop.mapred.TestClientRedirect.testRedirect}}** is not idempotent and fail if run twice in the same JVM, because it pollutes some states shared among tests. It may be good to clean this state pollution so that some other tests do not fail in the future due to the shared state polluted by this test.
h3. Detail

Running *{{TestClientRedirect.testRedirect}}* twice would result in the second run failing due to the following assertion error:
{noformat}
INFO  [main] service.AbstractService (AbstractService.java:noteFailure(267)) - Service test failed in state STARTED
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.BindException: 

Problem binding to [0.0.0.0:8054] java.net.BindException: Address already in use
{noformat}
The root cause is that the RM server listening on port 8054) is started in the first run of this test, but hasn't been stopped when the test finishes. In the second run, when the test is trying to start the RMService, it fails because port 8054 is already in use, leading to the exception.

PR link: https://github.com/apache/hadoop/pull/2968"
MAPREDUCE-7341,Add a task-manifest output committer for Azure and GCS,"Add a task-manifest output committer for Azure and GCS

The S3A committers are very popular in Spark on S3, as they are both correct and fast.

The classic FileOutputCommitter v1 and v2 algorithms are all that is available for Azure ABFS and Google GCS, and they have limitations. 

The v2 algorithm isn't safe in the presence of failed task attempt commits, so we
recommend the v1 algorithm for Azure. But that is slow because it sequentially lists
then renames files and directories, one-by-one. The latencies of list
and rename make things slow.

Google GCS lacks the atomic directory rename required for v1 correctness;
v2 can be used (which doesn't have the job commit performance limitations),
but it's not safe.

Proposed

* Add a new FileOutputFormat committer which uses an intermediate manifest to
  pass the list of files created by a TA to the job committer.
* Job committer to parallelise reading these task manifests and submit all the
  rename operations into a pool of worker threads. (also: mkdir, directory deletions on cleanup)
* Use the committer plugin mechanism added for s3a to make this the default committer for ABFS
  (i.e. no need to make any changes to FileOutputCommitter)
* Add lots of IOStatistics instrumentation + logging of operations in the JobCommit
  for visibility of where delays are occurring.
* Reuse the S3A committer _SUCCESS JSON structure to publish IOStats & other data
  for testing/support.  

This committer will be faster than the V1 algorithm because of the parallelisation, and
because a manifest written by create-and-rename will be exclusive to a single task
attempt, delivers the isolation which the v2 committer lacks.

This is not an attempt to do an iceberg/hudi/delta-lake style manifest-only format
for describing the contents of a table; the final output is still a directory tree
which must be scanned during query planning.
As such the format is still suboptimal for cloud storage -but at least we will have
faster job execution during the commit phases.
  
Note: this will also work on HDFS, where again, it should be faster than
the v1 committer. However the target is very much Spark with ABFS and GCS; no plans to worry about MR as that simplifies the challenge of dealing with job restart (i.e. you don't have to)"
MAPREDUCE-7334,TestJobEndNotifier fails,"[https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2775/8/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt]
{quote}
[INFO] Running org.apache.hadoop.mapred.TestJobEndNotifier
[ERROR] Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 47.81 s <<< FAILURE! - in org.apache.hadoop.mapred.TestJobEndNotifier
[ERROR] testNotificationTimeout(org.apache.hadoop.mapred.TestJobEndNotifier)  Time elapsed: 47.322 s  <<< ERROR!
java.util.concurrent.TimeoutException
	at org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:130)
	at org.eclipse.jetty.util.FutureCallback.get(FutureCallback.java:30)
	at org.eclipse.jetty.server.handler.AbstractHandlerContainer.doShutdown(AbstractHandlerContainer.java:175)
	at org.eclipse.jetty.server.Server.doStop(Server.java:447)
	at org.eclipse.jetty.util.component.AbstractLifeCycle.stop(AbstractLifeCycle.java:94)
	at org.apache.hadoop.http.HttpServer2.stop(HttpServer2.java:1499)
	at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
{quote}
 "
MAPREDUCE-7332,Fix SpillCallBackPathsFinder to use JDK7 on branch-2.10,"I mistakenly uploaded a patch for branch-2.10 that uses JDK8.

Yetus did not fail though. It should be investigated why it was not failing if JDK8+ is used in the code."
MAPREDUCE-7329,HadoopPipes task may fail when linux kernel version change from 3.x to 4.x,"{color:#FF0000}*Hadoop Pipes Ping implement has a bug*{color}. Recently, we upgrade linux kernel version from 3.x to 4.x. And we find hadoop pipe task exit with connect timeout which is implemented by PingThread in HadoopPipes.cc.

!image-2021-03-15-14-37-32-184.png!

After a deep research, we finally find that current ping server won't accept ping client created socket, which may cause critical problem: 
 *  it will cause tcp accept queue full(default 50)
 *  when client close socket, server socket won't call close method, which will leave too many CLOSE_WAIT socket fd existed(default 2h), and accept queue never cleared.
 * Even worse, in 4.x linux kernel version, it will cause tcp drop packet directly which makes ping client connect time out. While In 3.x linux kernel version, when accept queue full, client can also make half connection till sync queue full (default 2048), so from client side, ping will aslo work till sync queue full. And after 3 hours, task will also exit with connect timeout exception.

To fix this bug, we introduced a PingSocketCleaner thread, which will continuously accept ping socket connect from ping client. When socket close from client,  cleaner thread will detecte closed inputStream reading, then finally close socket from sever side.

Refrenced by linux kernel patch: [https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=5ea8ea2cb7]

 "
MAPREDUCE-7326,Mapred/YARN job fails due to kms-dt can't be found in cache with LoadBalancingKMSClientProvider + Kerberos,"I deployed Hadoop 3.2.2 cluster with KMS in HA using LoadBalancingKMSClientProvider with Kerberos authentication. KMS instances are configured with ZooKeeper for storing the shared secret.

I have created an encryption key and an encryption zone in `/test` directory and executed `randomtextwriter` from mapreduce examples passing it a sub-directory in the encryption zone:
{code:java}
hadoop jar hadoop-mapreduce-examples-3.2.2.jar randomtextwriter /test/randomtextwriter
{code}
Unfortunately the job keeps failing with errors like:
{code:java}
java.io.IOException: org.apache.hadoop.security.authentication.client.AuthenticationException: org.apache.hadoop.security.token.SecretManager$InvalidToken: token (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615146155993, maxDate=1615750955993, sequenceNumber=1, masterKeyId=2) can't be found in cache
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.decryptEncryptedKey(LoadBalancingKMSClientProvider.java:363)
	at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.decryptEncryptedKey(KeyProviderCryptoExtension.java:532)
	at org.apache.hadoop.hdfs.HdfsKMSUtil.decryptEncryptedDataEncryptionKey(HdfsKMSUtil.java:212)
	at org.apache.hadoop.hdfs.DFSClient.createWrappedOutputStream(DFSClient.java:972)
	at org.apache.hadoop.hdfs.DFSClient.createWrappedOutputStream(DFSClient.java:952)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:536)
	at org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:530)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:544)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:471)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)
	at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1168)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:285)
	at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:542)
	at org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat.getSequenceWriter(SequenceFileOutputFormat.java:64)
	at org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat.getRecordWriter(SequenceFileOutputFormat.java:75)
	at org.apache.hadoop.mapred.MapTask$NewDirectOutputCollector.<init>(MapTask.java:659)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:779)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
Caused by: org.apache.hadoop.security.authentication.client.AuthenticationException: org.apache.hadoop.security.token.SecretManager$InvalidToken: token (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615146155993, maxDate=1615750955993, sequenceNumber=1, masterKeyId=2) can't be found in cache
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.HttpExceptionUtils.validateResponse(HttpExceptionUtils.java:154)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:592)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:540)
	at org.apache.hadoop.crypto.key.kms.KMSClientProvider.decryptEncryptedKey(KMSClientProvider.java:833)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$5.call(LoadBalancingKMSClientProvider.java:356)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$5.call(LoadBalancingKMSClientProvider.java:352)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:174)
	at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.decryptEncryptedKey(LoadBalancingKMSClientProvider.java:352)
{code}
 

I've injected a few logs on my own and it seems that the client gets 403 on ""decrypt"" request:
{code:java}
2021-03-07 21:26:23,009 INFO [main] org.apache.hadoop.hdfs.HdfsKMSUtil: DD: decrypting encrypted data encryption key
2021-03-07 21:26:23,012 INFO [main] org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider: DD: decryptEncryptedKey called
2021-03-07 21:26:23,012 INFO [main] org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider: DD: trying out all providers providers.length=2
2021-03-07 21:26:23,012 INFO [main] org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider: DD: Trying out provider=0, i=0
2021-03-07 21:26:23,028 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: Current UGI: packer (auth:SIMPLE)
2021-03-07 21:26:23,028 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: mapreduce.job, Service: 10.9.4.227:38684, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@6b5966e1)
2021-03-07 21:26:23,028 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: HDFS_DELEGATION_TOKEN, Service: 10.9.4.140:8020, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:sacluster, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: HDFS_DELEGATION_TOKEN, Service: 10.9.4.175:8020, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: Login UGI: packer (auth:SIMPLE)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: mapreduce.job, Service: 10.9.4.227:38684, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@65e61854)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:sacluster, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42)
2021-03-07 21:26:23,029 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: +token:Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:26:23,030 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: Searching for KMS delegation token in user packer (auth:SIMPLE)'s credentials
2021-03-07 21:26:23,030 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: selected by alias=10.9.4.175:16000 token=Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:26:23,031 DEBUG [main] org.apache.hadoop.security.UserGroupInformation: PrivilegedAction as:packer (auth:SIMPLE) from:org.apache.hadoop.crypto.key.kms.KMSClientProvider.createConnection(KMSClientProvider.java:506)
2021-03-07 21:26:23,037 DEBUG [main] org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL: Connecting to url http://node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt with token  as null
2021-03-07 21:26:23,038 DEBUG [main] org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticatedURL: Token not set, looking for delegation token. Creds:[Kind: mapreduce.job, Service: 10.9.4.227:38684, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@674c583e), Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:sacluster, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42), Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)], size:3
2021-03-07 21:26:23,039 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: Looking for delegation token. creds: [Kind: mapreduce.job, Service: 10.9.4.227:38684, Ident: (org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier@25f7391e), Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:sacluster, Ident: (token for packer: HDFS_DELEGATION_TOKEN owner=packer/node-10-9-4-175.bdcluster@SOME_REALM, renewer=packer, realUser=, issueDate=1615152335661, maxDate=1615757135661, sequenceNumber=23, masterKeyId=42), Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)]
2021-03-07 21:26:23,039 DEBUG [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: selected by alias=10.9.4.175:16000 token=Kind: kms-dt, Service: kms://http@node-10-9-4-175.bdcluster;node-10-9-4-140.bdcluster:16000/kms, Ident: (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:26:23,039 DEBUG [main] org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticator: Authenticated from delegation token. url=http://node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt, token=
2021-03-07 21:26:23,057 INFO [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: DD: calling decrypt key at http://node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt
2021-03-07 21:26:27,325 INFO [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: DD: Got response to url=http://node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt, code=403, message=Forbidden
2021-03-07 21:26:27,326 INFO [main] org.apache.hadoop.crypto.key.kms.KMSClientProvider: DD: Validating response
2021-03-07 21:26:27,346 ERROR [main] org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider: DD: Re-throwing: 
org.apache.hadoop.security.authentication.client.AuthenticationException: org.apache.hadoop.security.token.SecretManager$InvalidToken: token (kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2) can't be found in cache
{code}
and the exception is thrown from: 
{code:java}
org.apache.hadoop.crypto.key.kms.KMSClientProvider#call(java.net.HttpURLConnection, java.lang.Object, int, java.lang.Class<T>, int)
   ...
   LOG.info(""DD: Validating response"");
   HttpExceptionUtils.validateResponse(conn, expectedResponse);
   LOG.info(""DD: Response passed validation"");
   ...{code}
It seems that the delegation token is not shared between both KMS instances and when the request hits the KMS instance that does not have the delegation token it responds with `AuthenticationException`, from:
{code:java}
org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler#authenticate
{code}
which makes the client not retry the request with the other KMS instance.

 

Here are a few relevant lines from the failing KMS log:
{code:java}
2021-03-07 21:28:18,823 DEBUG AuthenticationFilter - Request [http://node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt] triggering authentication. handler: class org.apache.hadoop.security.token.delegation
.web.KerberosDelegationTokenAuthenticationHandler
2021-03-07 21:28:18,824 DEBUG DelegationTokenAuthenticationHandler - Authenticating with dt param: IAAGcGFja2VyBnBhY2tlcgCKAXgOlNA2igF4MqFUNgECFNcBZ7fbjrLRO4-ekukipzAQdh1DBmttcy1kdEhrbXM6Ly9odHRwQG5vZGUtMTAtOS00LTE3NS5iZGNsdXN0ZXI7bm9kZS0xMC05LTQtMTQwLmJk
Y2x1c3RlcjoxNjAwMC9rbXM
2021-03-07 21:28:18,824 DEBUG ManagedSelector - Destroyed SocketChannelEndPoint@343bb301{/10.9.4.140:52258<->/10.9.4.175:16000,CLOSED,fill=-,flush=-,to=705/1000}{io=0/0,kio=-1,kro=-1}->HttpConnection@4ff601bb[p=HttpParser{s=CLOSED,0 of -1},g=HttpGenerator
@26bc00ff{s=START}]=>HttpChannelOverHttp@11f7d1d3{r=1,c=false,c=false/false,a=IDLE,uri=null,age=0}
2021-03-07 21:28:18,827 DEBUG AbstractDelegationTokenSecretManager - DD: Looking for token id=(kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:28:18,827 DEBUG HttpConnection - HttpConnection@4ff601bb::SocketChannelEndPoint@343bb301{/10.9.4.140:52258<->/10.9.4.175:16000,CLOSED,fill=-,flush=-,to=705/1000}{io=0/0,kio=-1,kro=-1}->HttpConnection@4ff601bb[p=HttpParser{s=CLOSED,0 of -1},g
=HttpGenerator@26bc00ff{s=START}]=>HttpChannelOverHttp@11f7d1d3{r=1,c=false,c=false/false,a=IDLE,uri=null,age=0} parsed false HttpParser{s=CLOSED,0 of -1}
2021-03-07 21:28:18,828 DEBUG HttpChannel - sendResponse info=null content=DirectByteBuffer@7daa9fd5[p=0,l=413,c=32768,r=413]={<<<{\n  ""RemoteExcept...xception""\n  }\n}>>>z-6-ZywrRKw"",\n   ...hdfs_root_dir_k} complete=true committing=true callback=Blocker
@119c9686{null}
2021-03-07 21:28:18,829 DEBUG HttpChannel - COMMIT for /kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek on HttpChannelOverHttp@47d8dfbe{r=1,c=true,c=false/false,a=DISPATCHED,uri=//node-10-9-4-175.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_di
r_key%400/_eek?eek_op=decrypt,age=53}
403 null HTTP/1.1
Date: Sun, 07 Mar 2021 21:28:18 GMT
Cache-Control: no-cache
Expires: Sun, 07 Mar 2021 21:28:18 GMT
Date: Sun, 07 Mar 2021 21:28:18 GMT
Pragma: no-cache
Content-Type: application/json
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block

{code}
and here are corresponding lines from succeeding KMS log:
{code:java}
2021-03-07 21:27:43,639 DEBUG AuthenticationFilter - Request [http://node-10-9-4-140.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt] triggering authentication. handler: class org.apache.hadoop.security.token.delegation
.web.KerberosDelegationTokenAuthenticationHandler
2021-03-07 21:27:43,640 DEBUG DelegationTokenAuthenticationHandler - Authenticating with dt param: IAAGcGFja2VyBnBhY2tlcgCKAXgOlNA2igF4MqFUNgECFNcBZ7fbjrLRO4-ekukipzAQdh1DBmttcy1kdEhrbXM6Ly9odHRwQG5vZGUtMTAtOS00LTE3NS5iZGNsdXN0ZXI7bm9kZS0xMC05LTQtMTQwLmJk
Y2x1c3RlcjoxNjAwMC9rbXM
2021-03-07 21:27:43,648 DEBUG AbstractDelegationTokenSecretManager - DD: Looking for token id=(kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:27:43,648 DEBUG AbstractDelegationTokenSecretManager - DD: token id=(kms-dt owner=packer, renewer=packer, realUser=, issueDate=1615152336950, maxDate=1615757136950, sequenceNumber=1, masterKeyId=2)
2021-03-07 21:27:43,668 DEBUG AuthenticationFilter - Request [http://node-10-9-4-140.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt] user [packer] authenticated
2021-03-07 21:27:43,668 DEBUG ServletHandler - call filter MDCFilter@5a7fe64f==org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter,inst=true,async=false
2021-03-07 21:27:43,687 DEBUG ServletHandler - call servlet webservices-driver@79e80ea3==com.sun.jersey.spi.container.servlet.ServletContainer,jsp=null,order=1,inst=true,async=false
2021-03-07 21:27:44,252 DEBUG IdleTimeout - SocketChannelEndPoint@78a5b977{/10.9.4.227:34860<->/10.9.4.140:16000,OPEN,fill=-,flush=-,to=1039/1000}{io=0/0,kio=0,kro=1}->HttpConnection@4ef7005[p=HttpParser{s=CONTENT,0 of 122},g=HttpGenerator@51540fee{s=STAR
T}]=>HttpChannelOverHttp@661cde57{r=1,c=false,c=false/false,a=DISPATCHED,uri=//node-10-9-4-140.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt,age=758} idle timeout check, elapsed: 1039 ms, remaining: -39 ms
2021-03-07 21:27:44,260 DEBUG IdleTimeout - SocketChannelEndPoint@78a5b977{/10.9.4.227:34860<->/10.9.4.140:16000,OPEN,fill=-,flush=-,to=1041/1000}{io=0/0,kio=0,kro=1}->HttpConnection@4ef7005[p=HttpParser{s=CONTENT,0 of 122},g=HttpGenerator@51540fee{s=START}]=>HttpChannelOverHttp@661cde57{r=1,c=false,c=false/false,a=DISPATCHED,uri=//node-10-9-4-140.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt,age=759} idle timeout expired
2021-03-07 21:27:44,264 DEBUG FillInterest - onFail FillInterest@51ba8df5{null}
java.util.concurrent.TimeoutException: Idle timeout expired: 1039/1000 ms
...
2021-03-07 21:27:44,527 DEBUG KMSACLs - User: [packer], OpType: DECRYPT_EEK, KeyName: dotdata_hdfs_root_dir_key Result: true
2021-03-07 21:27:44,607 DEBUG PerformanceAdvisory - Crypto codec org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec is not available.
2021-03-07 21:27:44,652 DEBUG PerformanceAdvisory - Using crypto codec org.apache.hadoop.crypto.JceAesCtrCryptoCodec.
2021-03-07 21:27:44,768 DEBUG HttpChannel - sendResponse info=null content=DirectByteBuffer@2d84038a[p=0,l=107,c=32768,r=107]={<<<{\n  ""material"" : ...nName"" : ""EK""\n}>>>""><doc xmlns:jers...hdfs_root_dir_k} complete=true committing=true callback=Blocker@1e52a824{null}
2021-03-07 21:27:44,768 DEBUG HttpChannel - COMMIT for /kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek on HttpChannelOverHttp@661cde57{r=1,c=true,c=false/false,a=DISPATCHED,uri=//node-10-9-4-140.bdcluster:16000/kms/v1/keyversion/dotdata_hdfs_root_dir_key%400/_eek?eek_op=decrypt,age=1274}
200 OK HTTP/1.1
Date: Sun, 07 Mar 2021 21:27:43 GMT
Cache-Control: no-cache
Expires: Sun, 07 Mar 2021 21:27:43 GMT
Date: Sun, 07 Mar 2021 21:27:43 GMT
Pragma: no-cache
Content-Type: application/json
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block{code}
When I shutdown one of the KMS instances before launching the job then the job succeeds.

I thought it might have something to do with https://issues.apache.org/jira/browse/HADOOP-16199 so I tried the same setup with 3.3.0 but, unfortunately, with the same result.

I also run exactly the same job on CDH 5.16.1, which is my current deployment and which I am considering to replace with 3.2.2. The job did succeed on CDH 5.16.1.

I can provide more logs if that is needed, the issue is deterministic in my environment."
MAPREDUCE-7325,Intermediate data encryption is broken in LocalJobRunner,"With enabling intermediate encryption, running a job using LocalJobRunner with multiple reducers fails with the following error:

 
{code:bash}
2021-02-23 18:18:05,145 WARN  [Thread-2381] mapred.LocalJobRunner (LocalJobRunner.java:run(590)) - job_local1344328673_0004
java.lang.Exception: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#5
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:136)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:377)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.hadoop.fs.ChecksumException: Checksum Error
	at org.apache.hadoop.mapred.IFileInputStream.doRead(IFileInputStream.java:229)
	at org.apache.hadoop.mapred.IFileInputStream.read(IFileInputStream.java:153)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:210)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.doShuffle(InMemoryMapOutput.java:91)
	at org.apache.hadoop.mapreduce.task.reduce.IFileWrappedMapOutput.shuffle(IFileWrappedMapOutput.java:63)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:156)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:103)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:86)
{code}

The bug can be reproduced with any test unit like TestLocalJobSubmission.

Another way to reproduce the bug is to run {{LargeSorter}} with multiple reducers.


{code:java}
Configuration config = new Configuration();
// set all the necessary configurations
config.setInt(LargeSorter.NUM_REDUCE_TASKS,2);
String[] args = new String[] {""output-dir""};
int res = ToolRunner.run(config, new LargeSorter(), args);
{code}
"
MAPREDUCE-7324,ClientHSSecurityInfo class is in wrong META-INF file,"{{ClientHSSecurityInfo}} is located in 
{noformat}
./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/resources/META-INF/services/org.apache.hadoop.security.SecurityInfo
{noformat} 

But the actual class exists in
{noformat}
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common
{noformat}

Because of this issue, there is an ordering dependency between the client-jobclient and client-common that can cause failures if the ordering is not correct. Namely, if client-common is in the classpath _after_ client-jobclient, the JVM won't find {{ClientHSSecurityInfo}}"
MAPREDUCE-7323,Remove job_history_summary.py,"Fix the following syntax error in Python 3:
{noformat}
aajisaka@b23b6a126ee7:~/hadoop$ python3 hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/job_history_summary.py
  File ""hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/job_history_summary.py"", line 73
    print ""Name reduce-output-bytes shuffle-finish reduce-finish""
          ^
SyntaxError: Missing parentheses in call to 'print'. Did you mean print(""Name reduce-output-bytes shuffle-finish reduce-finish"")?
{noformat}"
MAPREDUCE-7322,revisiting TestMRIntermediateDataEncryption ,"I was reviewing {{TestMRIntermediateDataEncryption}}. The unit test has actually little to do with encryption.
I have the following conclusion:
* Enabling/Disabling {{MRJobConfig.MR_ENCRYPTED_INTERMEDIATE_DATA}} does not change the behavior of the unit test.
* There are no spill files generated by either mappers/reducers
* Wrapping I/O streams with Crypto never happens during the execution of the unit test.

Unless I misunderstand the purpose of that unit test, I suggest that it gets re-implemented so that it validates encryption in spilled intermediate data."
MAPREDUCE-7321,TestMRIntermediateDataEncryption does not cleanup data folders,"The data generated by the {{TestMRIntermediateDataEncryption}} does not get deleted after Completing the tests. This contributes to Hadoop taking large disk spaces to build and run tests.
 The following folders need to be removed:
 * folders of the DFSCluster and the YarnCluster
 * Files used to submit jobs in the test-dir folder"
MAPREDUCE-7320,ClusterMapReduceTestCase does not clean directories,"Running Junits that extend {{ClusterMapReduceTestCase}} generate lots of directories and folders without cleaning them up.

For example:
{code:bash}
men test -Dtest=TestMRJobClient{code}
generates the following directories:
{code:bash}
- target
   -+ ConfigurableMiniMRCluster_315090884
   -+ ConfigurableMiniMRCluster_1335188990
   -+ ConfigurableMiniMRCluster_1973037511
   -+ test-dir
        -+ dfs
        -+ hadopp-XYZ-01
        -+ hadopp-XYZ-02 
        -+ hadopp-XYZ-03
{code}"
MAPREDUCE-7319,Log list of mappers at trace level in ShuffleHandler audit log,"[MAPREDUCE-6958] added the content length to ShuffleHandler audit log, which is logged at DEBUG level.  After enabling it, we found that the list of mappers for large jobs was filling up our audit logs.  It would be good to move the list of mappers to TRACE level to reduce the logging impact without disabling the log message entirely.

For example a log message like this:
{noformat}
2018-01-25 23:43:02,669 [New I/O worker #1] DEBUG ShuffleHandler.audit: shuffle for job_1512479762132_1318600 reducer 241 length 482072 mappers: [attempt_1512479762132_1318600_1_00_004852_0_10003,
attempt_1512479762132_1318600_1_00_004190_0_10003, attempt_1512479762132_1318600_1_00_004393_0_10003, attempt_1512479762132_1318600_1_00_005057_0_10003, attempt_1512479762132_1318600_1_00_004855_0_10002,
attempt_1512479762132_1318600_1_00_003976_0_10003, attempt_1512479762132_1318600_1_00_004058_0_10003, attempt_1512479762132_1318600_1_00_004355_0_10003, attempt_1512479762132_1318600_1_00_004436_0_10002,
attempt_1512479762132_1318600_1_00_004854_0_10003, attempt_1512479762132_1318600_1_00_005174_0_10004, attempt_1512479762132_1318600_1_00_003972_0_10002, attempt_1512479762132_1318600_1_00_004853_0_10002,
attempt_1512479762132_1318600_1_00_004856_0_10002]
{noformat}
Would become this with {{log4j.logger.org.apache.hadoop.mapred.ShuffleHandler.audit=DEBUG}}:
{noformat}
2018-01-25 23:43:02,669 [New I/O worker #1] DEBUG ShuffleHandler.audit: shuffle for job_1512479762132_1318600 reducer 241 length 482072
{noformat}
And this with {{log4j.logger.org.apache.hadoop.mapred.ShuffleHandler.audit=TRACE}}:
{noformat}
2018-01-25 23:43:02,669 [New I/O worker #1] DEBUG ShuffleHandler.audit: shuffle for job_1512479762132_1318600 reducer 241 length 482072
2018-01-25 23:43:02,669 [New I/O worker #1] TRACE ShuffleHandler.audit: shuffle for job_1512479762132_1318600 mappers: [attempt_1512479762132_1318600_1_00_004852_0_10003,
attempt_1512479762132_1318600_1_00_004190_0_10003, attempt_1512479762132_1318600_1_00_004393_0_10003, attempt_1512479762132_1318600_1_00_005057_0_10003, attempt_1512479762132_1318600_1_00_004855_0_10002,
attempt_1512479762132_1318600_1_00_003976_0_10003, attempt_1512479762132_1318600_1_00_004058_0_10003, attempt_1512479762132_1318600_1_00_004355_0_10003, attempt_1512479762132_1318600_1_00_004436_0_10002,
attempt_1512479762132_1318600_1_00_004854_0_10003, attempt_1512479762132_1318600_1_00_005174_0_10004, attempt_1512479762132_1318600_1_00_003972_0_10002, attempt_1512479762132_1318600_1_00_004853_0_10002,
attempt_1512479762132_1318600_1_00_004856_0_10002]
{noformat}
One question is whether there are any downstream consumers of this audit log that might have a problem with this change?
"
MAPREDUCE-7317,Add latency information in FileOutputCommitter.mergePaths,"We have been observed some occurrences of huge delay from file output committer V1, where file output committer V2 is not an option.

While the root cause should have investigated on our side, there's another issue that there's insufficient information to debug. Most likely the huge delay comes from mergePaths, but the class only provides the ""debug"" log message to log the call itself with parameters, nothing else. mergePaths has been called recursively which is harder to trace how much latency specific directory takes to merge.

It would be nice and not intrusive to add latency info in mergePath, so that we can see how much latency specific directory takes to merge, only when debug log is enabled.

(Ideally it'd be nice if we can log warn message when the call takes huge time to process, but I don't have the proper threshold for the ""huge time"", so I'd avoid dealing with it altogether here.)"
MAPREDUCE-7315,LocatedFileStatusFetcher to collect/publish IOStatistics,"
Part of HADOOP-16830: if a FileSystem's RemoteIterators implement IOStatisticsSource, then collect these and serve through the IOStatisticsSource API.

If the iterators don't (only S3A does, but ABFS will too), then nothing is collected"
MAPREDUCE-7311,Fix non-idempotent test in TestTaskProgressReporter,"The test {{`org.apache.hadoop.mapred.TestTaskProgressReporter.testBytesWrittenRespectingLimit`}} is not idempotent and fails if run twice in the same JVM, because it pollutes state shared among tests. It may be good to clean this state pollution so that some other tests do not fail in the future due to the shared state polluted by this test.
h3. Details

Running {{`TestTaskProgressReporter.testBytesWrittenRespectingLimit`}} twice would result in the second run failing with the following assertion:
{noformat}
Assert.assertEquals(failFast, threadExited)
{noformat}
The root cause for this is that when`testBytesWrittenRespectingLimit` writes some bytes on the local file system, some counters are being incremented. The problem is that, after the test is done, the counter is not reset. With this polluted shared state, assumptions are broken, resulting in test failure in the second run.

PR link: https://github.com/apache/hadoop/pull/2500"
MAPREDUCE-7310,Clear the fileMap in JHEventHandlerForSigtermTest,"The test '{{org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testSigTermedFunctionality'}} is not idempotent and fails if run twice in the same JVM, because it pollutes state shared among tests. It may be good to clean this state pollution so that some other tests do not fail in the future due to the shared state polluted by this test.
h3. Details

Running `TestJobHistoryEventHandler.testSigTermedFunctionality` twice would result in the second run failing due to `NullPointerException`shown in the following:
{noformat}
 java.lang.NullPointerException
 at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:460)
 at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
 at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testSigTermedFunctionality(TestJobHistoryEventHandler.java:933)
{noformat}
The root cause of this is that running '{{TestJobHistoryEventHandler.testSigTermedFunctionality'}} results in some entries to be added to the static '{{JobHistoryEventHandler.fileMap'}}. The entries in the '{{fileMap'}} are not cleaned up when the test is done, resulting in a NullPointerException in the second run as the stale object(added in the first run) in the 'fileMap' is accessed.

 

PR link: https://github.com/apache/hadoop/pull/2499"
MAPREDUCE-7309,Improve performance of reading resource request for mapper/reducers from config,"This is an issue could affect all the releases which includes YARN-6927. 

Basically, we use regex match repeatedly when we read mapper/reducer resource request from config files. When we have large config file, and large number of splits, it could take a long time.  

We saw AM could take hours to parse config when we have 200k+ splits, with a large config file (hundreds of kbs). 

The problematic part is this:
{noformat}
  private void populateResourceCapability(TaskType taskType) {
    String resourceTypePrefix =
        getResourceTypePrefix(taskType);
    boolean memorySet = false;
    boolean cpuVcoresSet = false;

    if (resourceTypePrefix != null) {
      List<ResourceInformation> resourceRequests =
          ResourceUtils.getRequestedResourcesFromConfig(conf,
              resourceTypePrefix);
{noformat}

Inside {{ResourceUtils.getRequestedResourcesFromConfig()}}, we call {{Configuration.getValByRegex()}} which goes through all property keys that come from the MapReduce job configuration (jobconf.xml). If the job config is large (eg. due to being part of an MR pipeline and it was populated by an earlier job), then this results in running a regexp match unnecessarily for all properties over and over again. This is not necessary, because all mappers and reducers will have the same config, respectively.

We should do proper caching for pre-configured resource requests."
MAPREDUCE-7307,Potential thread leak in LocatedFileStatusFetcher,"We see that when using LocatedFileStatusFetcher to get file infos In parallel, if the listStatus thread is interrupted,  the  executor service in LocatedFileStatusFetcher is left unclosed,  the thread stack will like this:
{noformat}
""GetFileInfo #63"" #125 daemon prio=5 os_prio=0 tid=0x00007f6198106800 nid=0x881 waiting on condition [0x00007f60d9fde000]
java.lang.Thread.State: WAITING (parking)
at sun.misc.Unsafe.park(Native Method)
- parking to wait for <0x0000000082e810a8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748){noformat}
This caused by if condition.await() throws InterruptedException,  the method `shutDownNow` for the executor service would not be called as a result, should move such resource releasing call into the finally block."
MAPREDUCE-7305,[JDK 11] TestMRJobsWithProfiler fails,"https://ci-hadoop.apache.org/job/hadoop-qbt-trunk-java11-linux-x86_64/56/testReport/junit/org.apache.hadoop.mapreduce.v2/TestMRJobsWithProfiler/testDefaultProfiler/
{noformat}
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
[ERROR] Tests run: 2, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 85.232 s <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
[ERROR] testDefaultProfiler(org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler)  Time elapsed: 30.901 s  <<< FAILURE!
java.lang.AssertionError: expected:<4> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfilerInternal(TestMRJobsWithProfiler.java:212)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDefaultProfiler(TestMRJobsWithProfiler.java:111)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)

[ERROR] testDifferentProfilers(org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler)  Time elapsed: 27.956 s  <<< FAILURE!
java.lang.AssertionError: expected:<4> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:834)
	at org.junit.Assert.assertEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:631)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfilerInternal(TestMRJobsWithProfiler.java:212)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDifferentProfilers(TestMRJobsWithProfiler.java:117)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
{noformat}"
MAPREDUCE-7304,Enhance the map-reduce Job end notifier to be able to notify the given URL via a custom class,"Currently {color:#0747a6}{{*org.apache.hadoop.mapreduce.v2.app.JobEndNotifier*}}{color} allows a very limited configuration on how the given Job end notification URL should be notified. We should enhance this, but instead of adding more *{color:#0747A6}{{mapreduce.job.end-notification.*}}{color}* properties to be able to configure the underlying HttpURLConnection, we should add a new property so users can use their own notifier class."
MAPREDUCE-7302,Upgrading to JUnit 4.13 causes testcase TestFetcher.testCorruptedIFile() to fail,"See related ticket YARN-10460. JUnit 4.13 causes the same failure:


{noformat}
[ERROR] Tests run: 16, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.851 s <<< FAILURE! - in org.apache.hadoop.mapreduce.task.reduce.TestFetcher
[ERROR] testCorruptedIFile(org.apache.hadoop.mapreduce.task.reduce.TestFetcher)  Time elapsed: 0.15 s  <<< ERROR!
java.lang.IllegalThreadStateException
	at java.lang.ThreadGroup.addUnstarted(ThreadGroup.java:867)
	at java.lang.Thread.init(Thread.java:405)
	at java.lang.Thread.init(Thread.java:349)
	at java.lang.Thread.<init>(Thread.java:678)
	at java.util.concurrent.Executors$DefaultThreadFactory.newThread(Executors.java:613)
	at org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder$1.newThread(ThreadFactoryBuilder.java:163)
	at java.util.concurrent.ThreadPoolExecutor$Worker.<init>(ThreadPoolExecutor.java:619)
	at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:932)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367)
	at org.apache.hadoop.io.ReadaheadPool.submitReadahead(ReadaheadPool.java:159)
	at org.apache.hadoop.io.ReadaheadPool.readaheadStream(ReadaheadPool.java:141)
	at org.apache.hadoop.mapred.IFileInputStream.doReadahead(IFileInputStream.java:159)
	at org.apache.hadoop.mapred.IFileInputStream.<init>(IFileInputStream.java:88)
	at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile(TestFetcher.java:587)
{noformat}"
MAPREDUCE-7301,Expose Mini MR Cluster attribute for testing,"After MAPREDUCE-6521, applications using MiniMRYarnCluster need to explicitly set the config ""yarn.app.mapreduce.am.staging-dir"" which ll include cluster name in it. 

 

In order to get the cluster name, some getters on corresponding attributes are needed to be available."
MAPREDUCE-7300,PathOutputCommitter to add method failedTaskAttemptCommitRecoverable(),"Related to MAPREDUCE-7282 a variant solution

# we add a new method for committers to declare whether they can recover from a task attempt commit failure
# default = true; v2 and (external) EMR spark committers can return false

execution engine - MR, Spark, can look at this after a task attempt fails to commit and decide what to do

recoverable: execute/commit another task attempt

non-recoverable, one of (Configured)
* warn and continue
* abort the job

with the job abort  option, users would be confident that if a failure happened during the commit phase, they'd know about it and choose how to recover.

I'd use a long/unusual name, so that in, say, Spark, reflection to could be used to find and call the method & so compile against older releases"
MAPREDUCE-7298,Distcp doesn't close the job after the job is completed,"Distcp doesn't close the job after the job is completed. This leads to leaked Truststore Reloader Threads.

The fix is to close the job once it is complete. job.close internally calls yarnClient.close(), which then calls timelineConnector.serviceStop() . This destroys the sslFactory cleaning up the ReloadingX509TrustManager.

Without the patch for each distcp job, a new ReloadingX509TrustManager is created which creates a new thread. These threads are never killed and they remain like that till HS2 is restarted. With the close, the thread will be cleaned up once the job is completed."
MAPREDUCE-7294,Only application master should upload resource to Yarn Shared Cache,"The design of yarn shared cache manager is only to allow application master should upload the jar/files/resource. However, there was a bug in the code since 2.9.0. Every node manager that take the job task will try to upload the jar/resources. Let's say one job have 5000 tasks. Then there will be up to 5000 NMs try to upload the jar. This is like DDOS and create a snowball effect. It will end up with inavailability of yarn shared cache manager. It wil cause time out in localization and lead to job failure."
MAPREDUCE-7293,All pages in JHS should honor yarn.webapp.filter-entity-list-by-user,"Currently only HsJobsBlock checks for the access. If user who doesn't have permission to access job page is able to do it which is wrong. So we need to have below check in HsJobBlock,HsTasksBlock and HsTaskPage

{code:java}
      if (isFilterAppListByUserEnabled && ugi != null && !aclsManager
          .checkAccess(ugi, JobACL.VIEW_JOB, job.getUserName(), null)) {
        
      }
{code}
"
MAPREDUCE-7289,Fix wrong comment in LongLong.java,"{code:title=LongLong.java}
  /** Shift right operation (<<). */
{code}
Right shift is {{>>}}.

Found when reviewing MAPREDUCE-7288"
MAPREDUCE-7288,Fix TestLongLong#testRightShift,In the testRightShift method is not implements the right verify operations.
MAPREDUCE-7287,"Distcp will delete existing file ,  If we use ""-delete and -update"" options and distcp file.","hdfs://ns1/tmp/a is an existing file, hdfs://ns2/tmp/a is also an existing file.

When I run this command, 
{code:java}
hadoop distcp -delete -update hdfs://ns1/tmp/a hdfs://ns2/tmp/a

{code}
I Found hdfs://ns2/tmp/a is deleted unpectectedly."
MAPREDUCE-7286,Fix findbugs warnings in hadoop-mapreduce-project on branch-2.10,"{noformat}
$ find . -name findbugsXml.xml | xargs -n 1 /opt/findbugs-3.0.1/bin/convertXmlToText -longBugCodes
M D NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE NP: Possible null pointer dereference in org.apache.hadoop.examples.pi.Parser.parse(File, Map) due to return value of called method  Dereferenced at Parser.java:[line 70]
H P DM_BOXED_PRIMITIVE_FOR_COMPARE Bx: Primitive is boxed to call Long.compareTo(Long): use Long.compare(long, long) instead  At JVMId.java:[line 101]
M B ME_MUTABLE_ENUM_FIELD ME: org.apache.hadoop.mapred.Operation.jobACLNeeded field is public and mutable  In Operation.java
M B ME_MUTABLE_ENUM_FIELD ME: org.apache.hadoop.mapred.Operation.qACLNeeded field is public and mutable  In Operation.java
M D UC_USELESS_OBJECT UC: Useless object stored in variable paths of method org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone()  At HistoryFileManager.java:[line 416]
M D NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE NP: Possible null pointer dereference in new org.apache.hadoop.mapred.LocalContainerLauncher(AppContext, TaskUmbilicalProtocol, ClassLoader) due to return value of called method  Dereferenced at LocalContainerLauncher.java:[line 124]
M D NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE NP: Possible null pointer dereference in org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.relocalize() due to return value of called method  Dereferenced at LocalContainerLauncher.java:[line 524]
M D NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE NP: Possible null pointer dereference in org.apache.hadoop.mapreduce.v2.app.MRAppMaster.isJobNamePatternMatch(JobConf, String) due to return value of called method  Dereferenced at MRAppMaster.java:[line 560]
{noformat}
"
MAPREDUCE-7285,Junit class missing from hadoop-mapreduce-client-jobclient-*-tests jar,"{noformat}
[ebadger@foo bin]$ $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-*-tests.jar sleep -Dyarn.app.mapreduce.am.env=""HADOOP_MAPRED_HOME=$HADOOP_HOME"" -Dmapreduce.admin.user.env=""HADOOP_MAPRED_HOME=$HADOOP_HOME"" -mt 1 -rt 1 -m 1 -r 1
WARNING: HADOOP_PREFIX has been replaced by HADOOP_HOME. Using value of HADOOP_PREFIX.
java.lang.NoClassDefFoundError: junit/framework/TestCase
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:763)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.apache.hadoop.test.MapredTestDriver.<init>(MapredTestDriver.java:109)
	at org.apache.hadoop.test.MapredTestDriver.<init>(MapredTestDriver.java:61)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.lang.ClassNotFoundException: junit.framework.TestCase
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 21 more
{noformat}

The sleep job continues to run after the error and succeeds successfully, but the error shouldn't be there. Something must have removed a jar or added an unfulfilled dependency on junit"
MAPREDUCE-7284,TestCombineFileInputFormat#testMissingBlocks fails,"o.a.h.mapreduce.lib.input.TestCombineFileInputFormat#testMissingBlocks fails on trunk:
{noformat}
[INFO] Running org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
[ERROR] Tests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 30.916 s <<< FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
[ERROR] testMissingBlocks(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat)  Time elapsed: 0.59 s  <<< ERROR!
java.lang.ClassCastException: org.apache.hadoop.hdfs.DistributedFileSystem cannot be cast to org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat$MissingBlockFileSystem
	at org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testMissingBlocks(TestCombineFileInputFormat.java:1655)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
{noformat}"
MAPREDUCE-7282,MR v2 commit algorithm should be deprecated and not the default,"The v2 MR commit algorithm moves files from the task attempt dir into the dest dir on task commit -one by one

It is therefore not atomic

# if a task commit fails partway through and another task attempt commits -unless exactly the same filenames are used, output of the first attempt may be included in the final result
# if a worker partitions partway through task commit, and then continues after another attempt has committed, it may partially overwrite the output -even when the filenames are the same

Both MR and spark assume that task commits are atomic. Either they need to consider that this is not the case, we add a way to probe for a committer supporting atomic task commit, and the engines both add handling for task commit failures (probably fail job)

Better: we remove this as the default, maybe also warn when it is being used
"
MAPREDUCE-7281,Fix NoClassDefFoundError on 'mapred minicluster',"{noformat}
$ bin/mapred minicluster
2020-06-17 12:01:29,133 INFO mapreduce.MiniHadoopClusterManager: Updated 0 configuration settings from command line.
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/junit/Assert
	at org.apache.hadoop.test.GenericTestUtils.assertExists(GenericTestUtils.java:298)
	at org.apache.hadoop.test.GenericTestUtils.getTestDir(GenericTestUtils.java:242)
	at org.apache.hadoop.test.GenericTestUtils.getTestDir(GenericTestUtils.java:251)
	at org.apache.hadoop.hdfs.MiniDFSCluster.getBaseDirectory(MiniDFSCluster.java:2982)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.<init>(MiniDFSCluster.java:224)
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start(MiniHadoopClusterManager.java:157)
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.run(MiniHadoopClusterManager.java:132)
	at org.apache.hadoop.mapreduce.MiniHadoopClusterManager.main(MiniHadoopClusterManager.java:320)
Caused by: java.lang.ClassNotFoundException: org.junit.Assert
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 8 more
{noformat}
"
MAPREDUCE-7280,"MiniMRYarnCluster has hard-coded timeout waiting to start history server, with no way to disable","Over in HBase, we've been chasing intermittent Jenkins failures in tests involving  MiniMRYarnCluster. In the latest incantion, HBASE-24493, we finally tracked this down to a hard-coded 60sec timeout in MiniMRYarnCluster on bringing up the JobHistoryServer... a feature we cannot disable for the purpose of this test. We've had to disable running these tests for the time being, which is less than ideal.

Would be great for MiniMRYarnCluster to (1) make JHS optional and/or (2) make this timeout duration configurable."
MAPREDUCE-7278,Speculative execution behavior is observed even when mapreduce.map.speculative and mapreduce.reduce.speculative are false,"When a failed task attempt container is stuck in FAIL_FINISHING_CONTAINER state for some time, we observe two task attempts are launched simultaneously even when speculative execution is disabled.

This results in the below message shown in the killed attempts, indicating speculation has occurred. This is an issue for jobs which require speculative execution to be strictly disabled.

  !Screen Shot 2020-04-30 at 8.04.27 PM.png!

 

 "
MAPREDUCE-7275,hadoop output to ftp gives rename error on FileOutputCommitter.mergePaths,"i'm using spark in kubernetes cluster mode and trying to write read data from DB and write in parquet format to ftp server. I'm using hadoop ftp filesystem for writing. When the task completes, it tries to rename /sensor_values/1585353600000/_temporary/0/_temporary/attempt_20200414075519_0000_m_000021_21/part-00021-d7cef14e-151b-4c3b-a8d8-4e9ab33e80f9-c000.snappy.parquet
to 
/sensor_values/1585353600000/part-00021-d7cef14e-151b-4c3b-a8d8-4e9ab33e80f9-c000.snappy.parquet

But the problem is it gives the following error:

```
Lost task 21.0 in stage 0.0 (TID 21, 10.233.90.137, executor 3): org.apache.spark.SparkException: Task failed while writing rows.
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:257)
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:170)
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)
 at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
 at org.apache.spark.scheduler.Task.run(Task.scala:123)
 at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
 at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
 at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
 at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Cannot rename source: ftp://user:pass@host/sensor_values/1585353600000/_temporary/0/_temporary/attempt_20200414075519_0000_m_000021_21/part-00021-d7cef14e-151b-4c3b-a8d8-4e9ab33e80f9-c000.snappy.parquet to ftp://user:pass@host/sensor_values/1585353600000/part-00021-d7cef14e-151b-4c3b-a8d8-4e9ab33e80f9-c000.snappy.parquet -only same directory renames are supported
 at org.apache.hadoop.fs.ftp.FTPFileSystem.rename(FTPFileSystem.java:674)
 at org.apache.hadoop.fs.ftp.FTPFileSystem.rename(FTPFileSystem.java:613)
 at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:472)
 at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.mergePaths(FileOutputCommitter.java:486)
 at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:597)
 at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitTask(FileOutputCommitter.java:560)
 at org.apache.spark.mapred.SparkHadoopMapRedUtil$.performCommit$1(SparkHadoopMapRedUtil.scala:50)
 at org.apache.spark.mapred.SparkHadoopMapRedUtil$.commitTask(SparkHadoopMapRedUtil.scala:77)
 at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitTask(HadoopMapReduceCommitProtocol.scala:225)
 at org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:78)
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:247)
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:242)
 at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)
 at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:248)
 ... 10 more
```

I have done the same thing on Azure filesystem using same spark and hadoop implimentation. 
Is there any configuration in hadoop or spark that needs to be changed or is it just not supported in hadoop ftp file System?
Thanks a lot!!"
MAPREDUCE-7273,JHS: make sure that Kerberos relogin is performed when KDC becomes offline then online again,"In JHS, if the KDC goes offline, the IPC layer does try to relogin, but it's not always enough. You have to wait for 60 seconds for the next retry. In the meantime, if the KDC comes back, the following error might occur:

{noformat}
2020-04-09 03:27:52,075 DEBUG ipc.Server (Server.java:processSaslToken(1952)) - Have read input token of size 708 for processing by saslServer.evaluateResponse()
2020-04-09 03:27:52,077 DEBUG ipc.Server (Server.java:saslProcess(1829)) - javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: Failure unspecified at GSS-API level (Mechanism level: Invalid argument (400) - Cannot find key of appropriate type to decrypt AP REP - AES128 CTS mode with HMAC SHA1-96)]
        at com.sun.security.sasl.gsskerb.GssKrb5Server.evaluateResponse(GssKrb5Server.java:199)
...
{noformat}

When this happens, JHS has to be restarted."
MAPREDUCE-7272,TaskAttemptListenerImpl excessive log messages,"{{TaskAttemptListenerImpl.statusUpdate()}} causes a bloating in log files. One every call, the listener uses {{LOG.info()}} to printout the progress of the {{TaskAttempt}}.
{code:java}
taskAttemptStatus.progress = taskStatus.getProgress();
    LOG.info(""Progress of TaskAttempt "" + taskAttemptID + "" is : ""
        + taskStatus.getProgress());
{code}
 
{code:bash}
2020-04-07 10:20:50,708 INFO [IPC Server handler 17 on 43926] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1586003420099_716645_m_007783_0 is : 0.40713295
2020-04-07 10:20:50,717 INFO [IPC Server handler 7 on 43926] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1586003420099_716645_m_020681_0 is : 0.55573714
2020-04-07 10:20:50,717 INFO [IPC Server handler 26 on 43926] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1586003420099_716645_m_024371_0 is : 0.54190344
2020-04-07 10:20:50,738 INFO [IPC Server handler 15 on 43926] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1586003420099_716645_m_033182_0 is : 0.50264555
2020-04-07 10:20:50,748 INFO [IPC Server handler 3 on 43926] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1586003420099_716645_m_022375_0 is : 0.5495565
{code}
After discussing this issue with [~nroberts], [~ebadger], and [~epayne], we thought that while it is helpful to have a log print of task progress, it is still excessive to log the progress in every update.
 This Jira is to suppress the excessive logging from TaskAttemptListener without affecting the frequency of progress updates. 
 There are two flags:
 * {{-Dmapreduce.task.log.progress.delta.threshold=0.10}}: means that the task progress will be logged every 10% of delta progress. Default is 5%.
 * {{-Dmapreduce.task.log.progress.wait.interval-seconds=120}}: means that if the listener will log the progress every 2 minutes. This is helpful for long running tasks that take long time to achieve the delta threshold. Default is 1 minute.

The listener will long whichever of {{delta.threshold}} and {{wait.interval-seconds}} is reached first. 
   Enabling {{LOG.DEBUG}} for  {{TaskAttemptListenerImpl}} will override those two flags and log the task progress on every update."
MAPREDUCE-7270,TestHistoryViewerPrinter could be failed when the locale isn't English.,"Both of testHumanPrinter and testHumanPrinterAll have expected string for assertion.

But the actual result includes the Dateformat which can be different depends on Locale."
MAPREDUCE-7269,TestNetworkedJob fails,"https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/1460/artifact/out/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient.txt
{noformat}
[INFO] Running org.apache.hadoop.mapred.TestNetworkedJob
[ERROR] Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 20.981 s <<< FAILURE! - in org.apache.hadoop.mapred.TestNetworkedJob
[ERROR] testNetworkedJob(org.apache.hadoop.mapred.TestNetworkedJob)  Time elapsed: 4.588 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[]default> but was:<[root.]default>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob(TestNetworkedJob.java:250)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
{noformat}"
MAPREDUCE-7268,Fix TestMapreduceConfigFields,More info see [https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/1452/testReport/junit/org.apache.hadoop.mapreduce/TestMapreduceConfigFields/testCompareXmlAgainstConfigurationClass/]
MAPREDUCE-7266,historyContext doesn't need to be a class attribute inside JobHistoryServer,"""historyContext"" class attribute at https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java#L67 is assigned a cast of another class attribute - ""jobHistoryService"" - https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java#L131, however it does not need to be stored separately because it is only ever used once in the class, and that too as an argument while instantiating the HistoryClientService class at https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java#L155.

Therefore, we could just delete the lines at https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java#L67 and https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/JobHistoryServer.java#L131 completely and instantiate the HistoryClientService as follows:

{code}
  @VisibleForTesting
  protected HistoryClientService createHistoryClientService() {
    return new HistoryClientService((HistoryContext)jobHistoryService, 
        this.jhsDTSecretManager);
  }
{code}"
MAPREDUCE-7263,Remove obsolete validateTargetPath() from FrameworkUploader,"The following piece of code has been in the FrameworkUploader class for a while:
{code:java}
  private void validateTargetPath() throws UploaderException {
    if (!target.startsWith(""hdfs:/"") &&
        !target.startsWith(""file:/"")) {
      throw new UploaderException(""Target path is not hdfs or local "" + target);
    }
  }
{code}

As parts of MR and YARN has evolved, you can run YARN with OzoneFS as storage for instance - so HDFS (or local) is not a requirement anymore. Also it does not make sense to add other suitable filesystems when they're tested against the MR framework, so I'm suggesting to remove the check."
MAPREDUCE-7262,MRApp helpers block for long intervals (500ms),"MRApp has a set of methods used as helpers in test cases such as: {{waitForInternalState(TA)}}, {{waitForState(TA)}}, {{waitForState(Job)}}..etc

When the condition fails, the thread sleeps for a minimum of 500ms before rechecking the new state of the Job/TA.
Example:


{code:java}
  public void waitForState(Task task, TaskState finalState) throws Exception {
    int timeoutSecs = 0;
    TaskReport report = task.getReport();
    while (!finalState.equals(report.getTaskState()) &&
        timeoutSecs++ < 20) {
      System.out.println(""Task State for "" + task.getID() + "" is : ""
          + report.getTaskState() + "" Waiting for state : "" + finalState
          + ""   progress : "" + report.getProgress());
      report = task.getReport();
      Thread.sleep(500);
    }
    System.out.println(""Task State is : "" + report.getTaskState());
    Assert.assertEquals(""Task state is not correct (timedout)"", finalState,
        report.getTaskState());
  }
{code}

I suggest to reduce the interval 500 to 50, while incrementing the number of retries to 200. this will potentially make the test cases run faster. Also, the {{System.out}} calls need to be removed because they are not adding information dumping the current state on every iteration.

A tentative list of Junits affected by the change:


{code:bash}
Method
    waitForInternalState(JobImpl, JobStateInternal)
Found usages  (12 usages found)
    org.apache.hadoop.mapreduce.v2.app  (10 usages found)
        TestJobEndNotifier  (3 usages found)
            testNotificationOnLastRetry(boolean)  (1 usage found)
                214 app.waitForInternalState(job, JobStateInternal.SUCCEEDED);
            testAbsentNotificationOnNotLastRetryUnregistrationFailure()  (1 usage found)
                256 app.waitForInternalState(job, JobStateInternal.REBOOT);
            testNotificationOnLastRetryUnregistrationFailure()  (1 usage found)
                289 app.waitForInternalState(job, JobStateInternal.REBOOT);
        TestKill  (5 usages found)
            testKillJob()  (1 usage found)
                70 app.waitForInternalState((JobImpl) job, JobStateInternal.RUNNING);
            testKillTask()  (1 usage found)
                108 app.waitForInternalState((JobImpl) job, JobStateInternal.RUNNING);
            testKillTaskWait()  (1 usage found)
                219 app.waitForInternalState((JobImpl) job, JobStateInternal.KILLED);
            testKillTaskWaitKillJobAfterTA_DONE()  (1 usage found)
                266 app.waitForInternalState((JobImpl)job, JobStateInternal.KILLED);
            testKillTaskWaitKillJobBeforeTA_DONE()  (1 usage found)
                316 app.waitForInternalState((JobImpl)job, JobStateInternal.KILLED);
        TestMRApp  (2 usages found)
            testJobSuccess()  (1 usage found)
                494 app.waitForInternalState(job, JobStateInternal.SUCCEEDED);
            testJobRebootOnLastRetryOnUnregistrationFailure()  (1 usage found)
                542 app.waitForInternalState((JobImpl) job, JobStateInternal.REBOOT);
    org.apache.hadoop.mapreduce.v2.app.rm  (2 usages found)
        TestRMContainerAllocator  (2 usages found)
            testReportedAppProgress()  (1 usage found)
                1050 mrApp.waitForInternalState((JobImpl) job, JobStateInternal.RUNNING);
            testReportedAppProgressWithOnlyMaps()  (1 usage found)
                1202 mrApp.waitForInternalState((JobImpl)job, JobStateInternal.RUNNING);


--------------------------------------------------------------------------------------

Method
    waitForState(TaskAttempt, TaskAttemptState)
Found usages  (72 usages found)
    org.apache.hadoop.mapreduce.v2  (2 usages found)
        TestSpeculativeExecutionWithMRApp  (2 usages found)
            testSpeculateSuccessfulWithoutUpdateEvents()  (1 usage found)
                212 app.waitForState(taskAttempt.getValue(), TaskAttemptState.SUCCEEDED);
            testSpeculateSuccessfulWithUpdateEvents()  (1 usage found)
                275 app.waitForState(taskAttempt.getValue(), TaskAttemptState.SUCCEEDED);
    org.apache.hadoop.mapreduce.v2.app  (67 usages found)
        TestAMInfos  (1 usage found)
            testAMInfosWithoutRecoveryEnabled()  (1 usage found)
                58 app.waitForState(taskAttempt, TaskAttemptState.RUNNING);
        TestFetchFailure  (11 usages found)
            testFetchFailure()  (3 usages found)
                77 app.waitForState(mapAttempt1, TaskAttemptState.RUNNING);
                109 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
                130 app.waitForState(mapAttempt2, TaskAttemptState.RUNNING);
            testFetchFailureWithRecovery()  (3 usages found)
                209 app.waitForState(mapAttempt1, TaskAttemptState.RUNNING);
                230 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
                262 app.waitForState(mapAttempt1, TaskAttemptState.RUNNING);
            testFetchFailureMultipleReduces()  (5 usages found)
                304 app.waitForState(mapAttempt1, TaskAttemptState.RUNNING);
                327 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
                333 app.waitForState(reduceAttempt2, TaskAttemptState.RUNNING);
                338 app.waitForState(reduceAttempt3, TaskAttemptState.RUNNING);
                372 app.waitForState(mapAttempt2, TaskAttemptState.RUNNING);
        TestKill  (6 usages found)
            testKillTaskWait()  (2 usages found)
                204 app.waitForState(mapAttempt, TaskAttemptState.RUNNING);
                206 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
            testKillTaskWaitKillJobAfterTA_DONE()  (2 usages found)
                242 app.waitForState(mapAttempt, TaskAttemptState.RUNNING);
                244 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
            testKillTaskWaitKillJobBeforeTA_DONE()  (2 usages found)
                290 app.waitForState(mapAttempt, TaskAttemptState.RUNNING);
                292 app.waitForState(reduceAttempt, TaskAttemptState.RUNNING);
        TestMRApp  (7 usages found)
            testCommitPending()  (3 usages found)
                114 app.waitForState(attempt, TaskAttemptState.RUNNING);
                123 app.waitForState(attempt, TaskAttemptState.COMMIT_PENDING);
                132 app.waitForState(attempt, TaskAttemptState.COMMIT_PENDING);
            testCompletedMapsForReduceSlowstart()  (2 usages found)
                169 app.waitForState(task1Attempt, TaskAttemptState.RUNNING);
                170 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
            testUpdatedNodes()  (2 usages found)
                287 app.waitForState(task1Attempt, TaskAttemptState.KILLED);
                288 app.waitForState(task2Attempt, TaskAttemptState.KILLED);
        TestMRClientService  (2 usages found)
            test()  (1 usage found)
                90 app.waitForState(attempt, TaskAttemptState.RUNNING);
            testViewAclOnlyCannotModify()  (1 usage found)
                215 app.waitForState(attempt, TaskAttemptState.RUNNING);
        TestRecovery  (40 usages found)
            testCrashed()  (8 usages found)
                165 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                166 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                176 app.waitForState(task1Attempt1, TaskAttemptState.FAILED);
                197 app.waitForState(task1Attempt2, TaskAttemptState.FAILED);
                210 app.waitForState(task1Attempt3, TaskAttemptState.RUNNING);
                218 app.waitForState(task1Attempt3, TaskAttemptState.KILLED);
                232 app.waitForState(task1Attempt4, TaskAttemptState.RUNNING);
                278 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
            testCrashOfMapsOnlyJob()  (4 usages found)
                382 app.waitForState(task1Attempt, TaskAttemptState.RUNNING);
                383 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                384 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
                435 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
            testRecoverySuccessUsingCustomOutputCommitter()  (4 usages found)
                527 app.waitForState(task1Attempt, TaskAttemptState.RUNNING);
                528 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                529 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
                581 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
            testRecoveryWithSpillEncryption()  (3 usages found)
                621 app.waitForState(mapAttempt, TaskAttemptState.RUNNING);
                647 app.waitForState(mapAttempt, TaskAttemptState.RUNNING);
                654 app.waitForState(redAttempt, TaskAttemptState.RUNNING);
            testRecoveryFailsUsingCustomOutputCommitter()  (4 usages found)
                706 app.waitForState(task1Attempt, TaskAttemptState.RUNNING);
                707 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                708 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
                760 app.waitForState(task3Attempt, TaskAttemptState.RUNNING);
            testMultipleCrashes()  (3 usages found)
                821 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                822 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                869 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
            testOutputRecovery()  (2 usages found)
                946 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                1013 app.waitForState(reduce2Attempt, TaskAttemptState.RUNNING);
            testOutputRecoveryMapsOnly()  (2 usages found)
                1123 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                1177 app.waitForState(task2Attempt1, TaskAttemptState.RUNNING);
            testRecoveryWithOldCommiter()  (2 usages found)
                1237 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                1304 app.waitForState(reduce2Attempt, TaskAttemptState.RUNNING);
            testSpeculative()  (5 usages found)
                1382 app.waitForState(task1Attempt1, TaskAttemptState.RUNNING);
                1383 app.waitForState(task1Attempt2, TaskAttemptState.RUNNING);
                1384 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                1394 app.waitForState(task1Attempt1, TaskAttemptState.SUCCEEDED);
                1432 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
            testRecoveryWithoutShuffleSecret()  (3 usages found)
                1511 app.waitForState(task1Attempt, TaskAttemptState.RUNNING);
                1512 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
                1555 app.waitForState(task2Attempt, TaskAttemptState.RUNNING);
    org.apache.hadoop.mapreduce.v2.app.job.impl  (3 usages found)
        TestTaskAttempt  (3 usages found)
            verifyMillisCounters(Resource, int)  (2 usages found)
                370 app.waitForState(mta, TaskAttemptState.RUNNING);
                371 app.waitForState(rta, TaskAttemptState.RUNNING);
            testTaskAttemptAssignedKilledHistory(FailingAttemptsDuringAssignedMRApp)  (1 usage found)
                488 app.waitForState(attempt, TaskAttemptState.KILLED);

-------------------------------------------

Method
    waitForState(Task, TaskState)
Found usages  (155 usages found)
    org.apache.hadoop.mapreduce.v2  (2 usages found)
        TestSpeculativeExecutionWithMRApp  (2 usages found)
            testSpeculateSuccessfulWithoutUpdateEvents()  (1 usage found)
                179 app.waitForState(taskIter.next(), TaskState.RUNNING);
            testSpeculateSuccessfulWithUpdateEvents()  (1 usage found)
                241 app.waitForState(taskIter.next(), TaskState.RUNNING);
    org.apache.hadoop.mapreduce.v2.app  (145 usages found)
        TestAMInfos  (1 usage found)
            testAMInfosWithoutRecoveryEnabled()  (1 usage found)
                56 app.waitForState(mapTask, TaskState.RUNNING);
        TestFail  (1 usage found)
            testTaskFailWithUnusedContainer()  (1 usage found)
                192 app.waitForState(task, TaskState.SCHEDULED);
        TestFetchFailure  (18 usages found)
            testFetchFailure()  (5 usages found)
                75 app.waitForState(mapTask, TaskState.RUNNING);
                85 app.waitForState(mapTask, TaskState.SUCCEEDED);
                106 app.waitForState(reduceTask, TaskState.RUNNING);
                117 app.waitForState(mapTask, TaskState.RUNNING);
                137 app.waitForState(mapTask, TaskState.SUCCEEDED);
            testFetchFailureWithRecovery()  (6 usages found)
                207 app.waitForState(mapTask, TaskState.RUNNING);
                217 app.waitForState(mapTask, TaskState.SUCCEEDED);
                227 app.waitForState(reduceTask, TaskState.RUNNING);
                238 app.waitForState(mapTask, TaskState.RUNNING);
                260 app.waitForState(mapTask, TaskState.RUNNING);
                270 app.waitForState(mapTask, TaskState.SUCCEEDED);
            testFetchFailureMultipleReduces()  (7 usages found)
                302 app.waitForState(mapTask, TaskState.RUNNING);
                312 app.waitForState(mapTask, TaskState.SUCCEEDED);
                322 app.waitForState(reduceTask, TaskState.RUNNING);
                323 app.waitForState(reduceTask2, TaskState.RUNNING);
                324 app.waitForState(reduceTask3, TaskState.RUNNING);
                354 app.waitForState(mapTask, TaskState.RUNNING);
                379 app.waitForState(mapTask, TaskState.SUCCEEDED);
        TestKill  (9 usages found)
            testKillTaskWait()  (3 usages found)
                201 app.waitForState(mapTask, TaskState.RUNNING);
                202 app.waitForState(reduceTask, TaskState.RUNNING);
                213 app.waitForState(mapTask, TaskState.SUCCEEDED);
            testKillTaskWaitKillJobAfterTA_DONE()  (2 usages found)
                239 app.waitForState(mapTask, TaskState.RUNNING);
                240 app.waitForState(reduceTask, TaskState.RUNNING);
            testKillTaskWaitKillJobBeforeTA_DONE()  (2 usages found)
                287 app.waitForState(mapTask, TaskState.RUNNING);
                288 app.waitForState(reduceTask, TaskState.RUNNING);
            testKillTaskAttempt()  (2 usages found)
                380 app.waitForState(task1, TaskState.SCHEDULED);
                381 app.waitForState(task2, TaskState.SCHEDULED);
        TestMRApp  (24 usages found)
            testCommitPending()  (1 usage found)
                112 app.waitForState(task, TaskState.RUNNING);
            testCompletedMapsForReduceSlowstart()  (4 usages found)
                161 app.waitForState(mapTask1, TaskState.RUNNING);
                162 app.waitForState(mapTask2, TaskState.RUNNING);
                183 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                187 app.waitForState(reduceTask, TaskState.RUNNING);
            testUpdatedNodes()  (16 usages found)
                233 app.waitForState(mapTask1, TaskState.RUNNING);
                234 app.waitForState(mapTask2, TaskState.RUNNING);
                257 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                258 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                310 app.waitForState(mapTask1, TaskState.RUNNING);
                311 app.waitForState(mapTask2, TaskState.RUNNING);
                325 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                326 app.waitForState(mapTask2, TaskState.RUNNING);
                362 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                363 app.waitForState(mapTask2, TaskState.RUNNING);
                385 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                400 app.waitForState(reduceTask1, TaskState.RUNNING);
                401 app.waitForState(reduceTask2, TaskState.RUNNING);
                410 app.waitForState(reduceTask1, TaskState.SUCCEEDED);
                416 app.waitForState(reduceTask1, TaskState.SUCCEEDED);
                425 app.waitForState(reduceTask2, TaskState.SUCCEEDED);
            testJobError()  (1 usage found)
                478 app.waitForState(task, TaskState.RUNNING);
            testJobRebootNotLastRetryOnUnregistrationFailure()  (1 usage found)
                511 app.waitForState(task, TaskState.RUNNING);
            testJobRebootOnLastRetryOnUnregistrationFailure()  (1 usage found)
                536 app.waitForState(task, TaskState.RUNNING);
        TestMRClientService  (2 usages found)
            test()  (1 usage found)
                88 app.waitForState(task, TaskState.RUNNING);
            testViewAclOnlyCannotModify()  (1 usage found)
                213 app.waitForState(task, TaskState.RUNNING);
        TestRecovery  (90 usages found)
            testCrashed()  (8 usages found)
                157 app.waitForState(mapTask1, TaskState.RUNNING);
                158 app.waitForState(mapTask2, TaskState.RUNNING);
                168 app.waitForState(reduceTask, TaskState.RUNNING);
                243 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                271 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                273 app.waitForState(mapTask2, TaskState.RUNNING);
                287 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                290 app.waitForState(reduceTask, TaskState.RUNNING);
            testCrashOfMapsOnlyJob()  (9 usages found)
                369 app.waitForState(mapTask1, TaskState.RUNNING);
                370 app.waitForState(mapTask2, TaskState.RUNNING);
                371 app.waitForState(mapTask3, TaskState.RUNNING);
                399 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                400 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                427 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                428 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                430 app.waitForState(mapTask3, TaskState.RUNNING);
                446 app.waitForState(mapTask3, TaskState.SUCCEEDED);
            testRecoverySuccessUsingCustomOutputCommitter()  (9 usages found)
                514 app.waitForState(mapTask1, TaskState.RUNNING);
                515 app.waitForState(mapTask2, TaskState.RUNNING);
                516 app.waitForState(mapTask3, TaskState.RUNNING);
                544 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                545 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                573 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                574 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                576 app.waitForState(mapTask3, TaskState.RUNNING);
                591 app.waitForState(mapTask3, TaskState.SUCCEEDED);
            testRecoveryWithSpillEncryption()  (5 usages found)
                619 app.waitForState(mapper, TaskState.RUNNING);
                624 app.waitForState(mapper, TaskState.SUCCEEDED);
                645 app.waitForState(mapper, TaskState.RUNNING);
                650 app.waitForState(mapper, TaskState.SUCCEEDED);
                657 app.waitForState(reducer, TaskState.SUCCEEDED);
            testRecoveryFailsUsingCustomOutputCommitter()  (9 usages found)
                693 app.waitForState(mapTask1, TaskState.RUNNING);
                694 app.waitForState(mapTask2, TaskState.RUNNING);
                695 app.waitForState(mapTask3, TaskState.RUNNING);
                723 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                724 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                752 app.waitForState(mapTask1, TaskState.RUNNING);
                753 app.waitForState(mapTask2, TaskState.RUNNING);
                755 app.waitForState(mapTask3, TaskState.RUNNING);
                784 app.waitForState(mapTask3, TaskState.SUCCEEDED);
            testMultipleCrashes()  (9 usages found)
                813 app.waitForState(mapTask1, TaskState.RUNNING);
                814 app.waitForState(mapTask2, TaskState.RUNNING);
                835 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                862 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                864 app.waitForState(mapTask2, TaskState.RUNNING);
                878 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                905 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                906 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                909 app.waitForState(reduceTask, TaskState.RUNNING);
            testOutputRecovery()  (8 usages found)
                939 app.waitForState(mapTask1, TaskState.RUNNING);
                955 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                960 app.waitForState(reduceTask1, TaskState.RUNNING);
                973 app.waitForState(reduceTask1, TaskState.SUCCEEDED);
                998 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1005 app.waitForState(reduceTask1, TaskState.SUCCEEDED); 
                1007 app.waitForState(reduceTask2, TaskState.RUNNING);
                1022 app.waitForState(reduceTask2, TaskState.SUCCEEDED);
            testOutputRecoveryMapsOnly()  (7 usages found)
                1116 app.waitForState(mapTask1, TaskState.RUNNING);
                1136 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1164 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1170 app.waitForState(mapTask2, TaskState.RUNNING);
                1186 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                1191 app.waitForState(reduceTask1, TaskState.RUNNING);
                1204 app.waitForState(reduceTask1, TaskState.SUCCEEDED);
            testRecoveryWithOldCommiter()  (8 usages found)
                1230 app.waitForState(mapTask1, TaskState.RUNNING);
                1246 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1251 app.waitForState(reduceTask1, TaskState.RUNNING);
                1264 app.waitForState(reduceTask1, TaskState.SUCCEEDED);
                1289 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1296 app.waitForState(reduceTask1, TaskState.SUCCEEDED); 
                1298 app.waitForState(reduceTask2, TaskState.RUNNING);
                1313 app.waitForState(reduceTask2, TaskState.SUCCEEDED);
            testSpeculative()  (8 usages found)
                1352 app.waitForState(mapTask1, TaskState.RUNNING);
                1353 app.waitForState(mapTask2, TaskState.RUNNING);
                1386 app.waitForState(reduceTask, TaskState.RUNNING);
                1397 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1425 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1427 app.waitForState(mapTask2, TaskState.RUNNING);
                1441 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                1444 app.waitForState(reduceTask, TaskState.RUNNING);
            testRecoveryWithoutShuffleSecret()  (10 usages found)
                1503 app.waitForState(mapTask1, TaskState.RUNNING);
                1504 app.waitForState(mapTask2, TaskState.RUNNING);
                1514 app.waitForState(reduceTask, TaskState.RUNNING);
                1523 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1549 app.waitForState(mapTask1, TaskState.RUNNING);
                1550 app.waitForState(mapTask2, TaskState.RUNNING);
                1564 app.waitForState(mapTask2, TaskState.SUCCEEDED);
                1567 app.waitForState(mapTask1, TaskState.RUNNING);
                1576 app.waitForState(mapTask1, TaskState.SUCCEEDED);
                1579 app.waitForState(reduceTask, TaskState.RUNNING);
    org.apache.hadoop.mapreduce.v2.app.job.impl  (3 usages found)
        TestTaskAttempt  (3 usages found)
            verifyMillisCounters(Resource, int)  (2 usages found)
                361 app.waitForState(mTask, TaskState.RUNNING);
                363 app.waitForState(rTask, TaskState.RUNNING);
            testTaskAttemptAssignedKilledHistory(FailingAttemptsDuringAssignedMRApp)  (1 usage found)
                485 app.waitForState(task, TaskState.SCHEDULED);
    org.apache.hadoop.mapreduce.v2.app.launcher  (1 usage found)
        TestContainerLauncher  (1 usage found)
            testSlowNM()  (1 usage found)
                296 app.waitForState(task, TaskState.SCHEDULED);
    org.apache.hadoop.mapreduce.v2.app.rm  (4 usages found)
        TestRMContainerAllocator  (4 usages found)
            testReportedAppProgress()  (2 usages found)
                1072 mrApp.waitForState(t, TaskState.RUNNING);
                1109 mrApp.waitForState(t, TaskState.RUNNING);
            finishTask(DrainDispatcher, MockNM, MRApp, Task)  (1 usage found)
                1152 mrApp.waitForState(task, TaskState.SUCCEEDED);
            testReportedAppProgressWithOnlyMaps()  (1 usage found)
                1221 mrApp.waitForState(t, TaskState.RUNNING);

--------------------------------------------------------------------------------------


Method
    waitForState(Job, JobState)
Found usages  (121 usages found)
    org.apache.hadoop.mapreduce.v2  (2 usages found)
        TestSpeculativeExecutionWithMRApp  (2 usages found)
            testSpeculateSuccessfulWithoutUpdateEvents()  (1 usage found)
                172 app.waitForState(job, JobState.RUNNING);
            testSpeculateSuccessfulWithUpdateEvents()  (1 usage found)
                234 app.waitForState(job, JobState.RUNNING);
    org.apache.hadoop.mapreduce.v2.app  (89 usages found)
        TestAMInfos  (2 usages found)
            testAMInfosWithoutRecoveryEnabled()  (2 usages found)
                49 app.waitForState(job, JobState.RUNNING);
                73 app.waitForState(job, JobState.RUNNING);
        TestFail  (8 usages found)
            testFailTask()  (1 usage found)
                71 app.waitForState(job, JobState.SUCCEEDED);
            testMapFailureMaxPercent()  (2 usages found)
                101 app.waitForState(job, JobState.FAILED);
                115 app.waitForState(job, JobState.SUCCEEDED);
            testReduceFailureMaxPercent()  (2 usages found)
                132 app.waitForState(job, JobState.FAILED);
                148 app.waitForState(job, JobState.SUCCEEDED);
            testTimedOutTask()  (1 usage found)
                162 app.waitForState(job, JobState.FAILED);
            testTaskFailWithUnusedContainer()  (2 usages found)
                188 app.waitForState(job, JobState.RUNNING);
                203 app.waitForState(job, JobState.FAILED);
        TestFetchFailure  (7 usages found)
            testFetchFailure()  (2 usages found)
                66 app.waitForState(job, JobState.RUNNING);
                144 app.waitForState(job, JobState.SUCCEEDED);
            testFetchFailureWithRecovery()  (3 usages found)
                198 app.waitForState(job, JobState.RUNNING);
                251 app.waitForState(job, JobState.RUNNING);
                278 app.waitForState(job, JobState.SUCCEEDED);
            testFetchFailureMultipleReduces()  (2 usages found)
                291 app.waitForState(job, JobState.RUNNING);
                396 app.waitForState(job, JobState.SUCCEEDED);
        TestJobEndNotifier  (3 usages found)
            testAbsentNotificationOnNotLastRetryUnregistrationFailure()  (2 usages found)
                253 app.waitForState(job, JobState.RUNNING);
                261 app.waitForState(job, JobState.RUNNING);
            testNotificationOnLastRetryUnregistrationFailure()  (1 usage found)
                286 app.waitForState(job, JobState.RUNNING);
        TestKill  (7 usages found)
            testKillJob()  (1 usage found)
                80 app.waitForState(job, JobState.KILLED);
            testKillTask()  (1 usage found)
                124 app.waitForState(job, JobState.SUCCEEDED);
            testKillTaskWait()  (1 usage found)
                196 app.waitForState(job, JobState.RUNNING);
            testKillTaskWaitKillJobAfterTA_DONE()  (1 usage found)
                234 app.waitForState(job, JobState.RUNNING);
            testKillTaskWaitKillJobBeforeTA_DONE()  (1 usage found)
                282 app.waitForState(job, JobState.RUNNING);
            testKillTaskAttempt()  (2 usages found)
                371 app.waitForState(job, JobState.RUNNING);
                393 app.waitForState(job, JobState.SUCCEEDED);
        TestMRApp  (19 usages found)
            testMapReduce()  (1 usage found)
                84 app.waitForState(job, JobState.SUCCEEDED);
            testZeroMaps()  (1 usage found)
                93 app.waitForState(job, JobState.SUCCEEDED);
            testZeroMapReduces()  (1 usage found)
                101 app.waitForState(job, JobState.SUCCEEDED);
            testCommitPending()  (2 usages found)
                108 app.waitForState(job, JobState.RUNNING);
                140 app.waitForState(job, JobState.SUCCEEDED);
            testCompletedMapsForReduceSlowstart()  (2 usages found)
                152 app.waitForState(job, JobState.RUNNING);
                199 app.waitForState(job, JobState.SUCCEEDED);
            testUpdatedNodes()  (3 usages found)
                226 app.waitForState(job1, JobState.RUNNING);
                353 app.waitForState(job2, JobState.RUNNING);
                440 app.waitForState(job2, JobState.SUCCEEDED);
            testJobError()  (2 usages found)
                474 app.waitForState(job, JobState.RUNNING);
                486 app.waitForState(job, JobState.ERROR);
            testJobSuccess()  (1 usage found)
                499 app.waitForState(job, JobState.SUCCEEDED);
            testJobRebootNotLastRetryOnUnregistrationFailure()  (2 usages found)
                507 app.waitForState(job, JobState.RUNNING);
                519 app.waitForState(job, JobState.RUNNING);
            testJobRebootOnLastRetryOnUnregistrationFailure()  (2 usages found)
                532 app.waitForState(job, JobState.RUNNING);
                545 app.waitForState(job, JobState.RUNNING);
            testCountersOnJobFinish()  (1 usage found)
                570 app.waitForState(job, JobState.SUCCEEDED);
            testContainerPassThrough()  (1 usage found)
                617 app.waitForState(job, JobState.SUCCEEDED);
        TestMRAppComponentDependencies  (1 usage found)
            testComponentStopOrder()  (1 usage found)
                47 app.waitForState(job, JobState.SUCCEEDED);
        TestMRClientService  (3 usages found)
            test()  (2 usages found)
                84 app.waitForState(job, JobState.RUNNING);
                186 app.waitForState(job, JobState.SUCCEEDED);
            testViewAclOnlyCannotModify()  (1 usage found)
                209 app.waitForState(job, JobState.RUNNING);
        TestRecovery  (38 usages found)
            testCrashed()  (3 usages found)
                146 app.waitForState(job, JobState.RUNNING);
                261 app.waitForState(job, JobState.RUNNING);
                297 app.waitForState(job, JobState.SUCCEEDED);
            testCrashOfMapsOnlyJob()  (3 usages found)
                359 app.waitForState(job, JobState.RUNNING);
                418 app.waitForState(job, JobState.RUNNING);
                448 app.waitForState(job, JobState.SUCCEEDED);
            testRecoverySuccessUsingCustomOutputCommitter()  (3 usages found)
                504 app.waitForState(job, JobState.RUNNING);
                564 app.waitForState(job, JobState.RUNNING);
                593 app.waitForState(job, JobState.SUCCEEDED);
            testRecoveryWithSpillEncryption()  (3 usages found)
                613 app.waitForState(jobAttempt1, JobState.RUNNING);
                639 app.waitForState(jobAttempt2, JobState.RUNNING);
                660 app.waitForState(jobAttempt2, JobState.SUCCEEDED);
            testRecoveryFailsUsingCustomOutputCommitter()  (3 usages found)
                683 app.waitForState(job, JobState.RUNNING);
                743 app.waitForState(job, JobState.RUNNING);
                786 app.waitForState(job, JobState.SUCCEEDED);
            testMultipleCrashes()  (4 usages found)
                803 app.waitForState(job, JobState.RUNNING);
                852 app.waitForState(job, JobState.RUNNING);
                895 app.waitForState(job, JobState.RUNNING);
                916 app.waitForState(job, JobState.SUCCEEDED);
            testOutputRecovery()  (3 usages found)
                931 app.waitForState(job, JobState.RUNNING);
                989 app.waitForState(job, JobState.RUNNING);
                1024 app.waitForState(job, JobState.SUCCEEDED);
            testPreviousJobOutputCleanedWhenNoRecovery()  (2 usages found)
                1042 app.waitForState(job, JobState.RUNNING);
                1052 app.waitForState(job, JobState.RUNNING);
            testPreviousJobIsNotCleanedWhenRecovery()  (2 usages found)
                1077 app.waitForState(job, JobState.RUNNING);
                1087 app.waitForState(job, JobState.RUNNING);
            testOutputRecoveryMapsOnly()  (3 usages found)
                1107 app.waitForState(job, JobState.RUNNING);
                1155 app.waitForState(job, JobState.RUNNING);
                1206 app.waitForState(job, JobState.SUCCEEDED);
            testRecoveryWithOldCommiter()  (3 usages found)
                1222 app.waitForState(job, JobState.RUNNING);
                1280 app.waitForState(job, JobState.RUNNING);
                1315 app.waitForState(job, JobState.SUCCEEDED);
            testSpeculative()  (3 usages found)
                1340 app.waitForState(job, JobState.RUNNING);
                1415 app.waitForState(job, JobState.RUNNING);
                1452 app.waitForState(job, JobState.SUCCEEDED);
            testRecoveryWithoutShuffleSecret()  (3 usages found)
                1493 app.waitForState(job, JobState.RUNNING);
                1540 app.waitForState(job, JobState.RUNNING);
                1586 app.waitForState(job, JobState.SUCCEEDED);
        TestStagingCleanup  (1 usage found)
            testStagingCleanupOrder()  (1 usage found)
                591 app.waitForState(job, JobState.SUCCEEDED);
    org.apache.hadoop.mapreduce.v2.app.job.impl  (12 usages found)
        TestMapReduceChildJVM  (7 usages found)
            testCommandLine()  (1 usage found)
                56 app.waitForState(job, JobState.SUCCEEDED);
            testReduceCommandLine(Configuration)  (1 usage found)
                112 app.waitForState(job, JobState.SUCCEEDED);
            testCommandLineWithLog4JConifg()  (1 usage found)
                161 app.waitForState(job, JobState.SUCCEEDED);
            testAutoHeapSize(int, int, String)  (1 usage found)
                230 app.waitForState(job, JobState.SUCCEEDED);
            testEnvironmentVariables()  (3 usages found)
                288 app.waitForState(job, JobState.SUCCEEDED);
                304 app.waitForState(job, JobState.SUCCEEDED);
                318 app.waitForState(job, JobState.SUCCEEDED);
        TestTaskAttempt  (5 usages found)
            verifyMillisCounters(Resource, int)  (2 usages found)
                356 app.waitForState(job, JobState.RUNNING);
                380 app.waitForState(job, JobState.SUCCEEDED);
            testMRAppHistory(MRApp)  (1 usage found)
                446 app.waitForState(job, JobState.FAILED);
            testTaskAttemptAssignedFailHistory(FailingAttemptsDuringAssignedMRApp)  (1 usage found)
                472 app.waitForState(job, JobState.FAILED);
            testTaskAttemptAssignedKilledHistory(FailingAttemptsDuringAssignedMRApp)  (1 usage found)
                482 app.waitForState(job, JobState.RUNNING);
    org.apache.hadoop.mapreduce.v2.app.launcher  (2 usages found)
        TestContainerLauncher  (2 usages found)
            testSlowNM()  (2 usages found)
                290 app.waitForState(job, JobState.RUNNING);
                307 app.waitForState(job, JobState.FAILED);
    org.apache.hadoop.mapreduce.v2.app.webapp  (4 usages found)
        TestAMWebApp  (4 usages found)
            testMRWebAppSSLDisabled()  (1 usage found)
                229 app.waitForState(job, JobState.SUCCEEDED);
            testMRWebAppSSLEnabled()  (1 usage found)
                286 app.waitForState(job, JobState.SUCCEEDED);
            testMRWebAppSSLEnabledWithClientAuth()  (1 usage found)
                357 app.waitForState(job, JobState.SUCCEEDED);
            testMRWebAppRedirection()  (1 usage found)
                411 app.waitForState(job, JobState.SUCCEEDED);
    org.apache.hadoop.mapreduce.v2.hs  (12 usages found)
        TestJobHistoryEvents  (3 usages found)
            testHistoryEvents()  (1 usage found)
                62 app.waitForState(job, JobState.SUCCEEDED);
            testEventsFlushOnStop()  (1 usage found)
                123 app.waitForState(job, JobState.SUCCEEDED);
            testAssignedQueue()  (1 usage found)
                171 app.waitForState(job, JobState.SUCCEEDED);
        TestJobHistoryParsing  (8 usages found)
            checkHistoryParsing(int, int, int)  (1 usage found)
                176 app.waitForState(job, JobState.SUCCEEDED);
            testHistoryParsingForFailedAttempts()  (1 usage found)
                416 app.waitForState(job, JobState.SUCCEEDED);
            testHistoryParsingForKilledAndFailedAttempts()  (1 usage found)
                492 app.waitForState(job, JobState.SUCCEEDED);
            testCountersForFailedTask()  (1 usage found)
                551 app.waitForState(job, JobState.FAILED);
            testDiagnosticsForKilledJob()  (1 usage found)
                614 app.waitForState(job, JobState.KILLED);
            testScanningOldDirs()  (1 usage found)
                674 app.waitForState(job, JobState.SUCCEEDED);
            testDeleteFileInfo()  (1 usage found)
                833 app.waitForState(job, JobState.SUCCEEDED);
            testJobHistoryMethods()  (1 usage found)
                888 app.waitForState(job, JobState.SUCCEEDED);
        TestJobHistoryServer  (1 usage found)
            testReports()  (1 usage found)
                106 app.waitForState(job, JobState.SUCCEEDED);

--------------------------------------------------------------------------------------

Method
    waitForState(STATE)
Found usages  (12 usages found)
    org.apache.hadoop.mapreduce.v2.app  (1 usage found)
        TestKill  (1 usage found)
            testKillJob()  (1 usage found)
                83 app.waitForState(Service.STATE.STOPPED);
    org.apache.hadoop.mapreduce.v2.hs  (11 usages found)
        TestJobHistoryEvents  (3 usages found)
            testHistoryEvents()  (1 usage found)
                65 app.waitForState(Service.STATE.STOPPED);
            testEventsFlushOnStop()  (1 usage found)
                126 app.waitForState(Service.STATE.STOPPED);
            testAssignedQueue()  (1 usage found)
                174 app.waitForState(Service.STATE.STOPPED);
        TestJobHistoryParsing  (8 usages found)
            checkHistoryParsing(int, int, int)  (1 usage found)
                179 app.waitForState(Service.STATE.STOPPED);
            testHistoryParsingForFailedAttempts()  (1 usage found)
                419 app.waitForState(Service.STATE.STOPPED);
            testHistoryParsingForKilledAndFailedAttempts()  (1 usage found)
                495 app.waitForState(Service.STATE.STOPPED);
            testCountersForFailedTask()  (1 usage found)
                554 app.waitForState(Service.STATE.STOPPED);
            testDiagnosticsForKilledJob()  (1 usage found)
                617 app.waitForState(Service.STATE.STOPPED);
            testScanningOldDirs()  (1 usage found)
                677 app.waitForState(Service.STATE.STOPPED);
            testDeleteFileInfo()  (1 usage found)
                836 app.waitForState(Service.STATE.STOPPED);
            testJobHistoryMethods()  (1 usage found)
                890 app.waitForState(Service.STATE.STOPPED);


--------------------------------------------------------------------------------------

Method
    waitForState(STATE)
Found usages  (12 usages found)
    org.apache.hadoop.mapreduce.v2.app  (1 usage found)
        TestKill  (1 usage found)
            testKillJob()  (1 usage found)
                83 app.waitForState(Service.STATE.STOPPED);
    org.apache.hadoop.mapreduce.v2.hs  (11 usages found)
        TestJobHistoryEvents  (3 usages found)
            testHistoryEvents()  (1 usage found)
                65 app.waitForState(Service.STATE.STOPPED);
            testEventsFlushOnStop()  (1 usage found)
                126 app.waitForState(Service.STATE.STOPPED);
            testAssignedQueue()  (1 usage found)
                174 app.waitForState(Service.STATE.STOPPED);
        TestJobHistoryParsing  (8 usages found)
            checkHistoryParsing(int, int, int)  (1 usage found)
                179 app.waitForState(Service.STATE.STOPPED);
            testHistoryParsingForFailedAttempts()  (1 usage found)
                419 app.waitForState(Service.STATE.STOPPED);
            testHistoryParsingForKilledAndFailedAttempts()  (1 usage found)
                495 app.waitForState(Service.STATE.STOPPED);
            testCountersForFailedTask()  (1 usage found)
                554 app.waitForState(Service.STATE.STOPPED);
            testDiagnosticsForKilledJob()  (1 usage found)
                617 app.waitForState(Service.STATE.STOPPED);
            testScanningOldDirs()  (1 usage found)
                677 app.waitForState(Service.STATE.STOPPED);
            testDeleteFileInfo()  (1 usage found)
                836 app.waitForState(Service.STATE.STOPPED);
            testJobHistoryMethods()  (1 usage found)
                890 app.waitForState(Service.STATE.STOPPED);
{code}



"
MAPREDUCE-7260,Cross origin request support for Job history server web UI,"The major web UIs in YARN support configuring the header, but somehow for the JHS web UI there wasn't any use case. We need it in YARN-10029, so let's implement it."
MAPREDUCE-7259,testSpeculateSuccessfulWithUpdateEvents fails Intermittently  ,"{{TestSpeculativeExecutionWithMRApp.testSpeculateSuccessfulWithUpdateEvents}} fails Intermittently with the exponential estimator. The problem happens because assertion fails waiting for the MRApp to stop.
There maybe a need to redesign the test case because it does not work very well because of the racing and the timing between the speculator and the tasks. It works fine for the legacy estimator because the estimate is based on start-end rate. "
MAPREDUCE-7258,"HistoryServerRest.html#Task_Counters_API, modify the jobTaskCounters's itemName from ""taskcounterGroup"" to ""taskCounterGroup"".","HistoryServerRest.html#Task_Counters_API, modify the jobTaskCounters's itemName from taskcounterGroup to taskCounterGroup.
 !image-2020-01-16-14-05-30-007.png|width=452,height=251!

!image-2020-01-16-14-32-02-183.png|width=447,height=254!"
MAPREDUCE-7257,Fix incorrect javadoc format,"`mvn package -Pdist -DskipTests` fails.
{noformat}
[ERROR] /Users/aajisaka/git/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/forecast/SimpleExponentialSmoothing.java:134: error: bad use of '>'
[ERROR]    * @return true if we have number of samples > kMinimumReads and the record
{noformat}"
MAPREDUCE-7256,Fix javadoc error in SimpleExponentialSmoothing,"{{-Pdist}} build fails due to javadoc error on SimpleExponentialSmoothing.java.

{noformat}
[ERROR] /ext/srcs/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/speculate/forecast/SimpleExponentialSmoothing.java:134: error: bad use of '>'
[ERROR]    * @return true if we have number of samples > kMinimumReads and the record
[ERROR]                                                ^
{noformat}
"
MAPREDUCE-7255,Fix typo in MapReduce documentaion example,"There is a typo in MapReduce example output.
On line 1100 it should be *world* instead of *horld*"
MAPREDUCE-7254,sqoop on hadoop3.1 doesn't work,"    I have a mysql table called admin with ""linyouquan"". And I want to import data from mysql to local filesystem. I chose sqoop for this thing. sqoop on hadoop2.6 works, but sqoop on hadoop3.1 doesn't work.

    The following is my operation and error information of sqoop on hadoop3.1.
 # my operation

{code:java}
export HADOOP_HOME=/home/linyouquan/hadoop3-hadoop-pack
{code}
{code:java}
sqoop import ""-Dorg.apache.sqoop.splitter.allow_text_splitter=true"" --connect jdbc:mysql://dbHost:dbPort/dbName --username dbUser --password dbPasswd --table admin --target-dir sqoop_import_user
{code}
 # error information of sqoop on hadoop3.1

{code:java}
Warning: /home/linyouquan/yarn/YARN/sqoop-1.4.7.bin__hadoop-2.6.0/bin/../../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /home/linyouquan/yarn/YARN/sqoop-1.4.7.bin__hadoop-2.6.0/bin/../../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /home/linyouquan/yarn/YARN/sqoop-1.4.7.bin__hadoop-2.6.0/bin/../../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /home/linyouquan/yarn/YARN/sqoop-1.4.7.bin__hadoop-2.6.0/bin/../../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
2019-12-24 18:29:55,473 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
2019-12-24 18:29:55,509 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
2019-12-24 18:29:55,623 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
2019-12-24 18:29:55,623 INFO tool.CodeGenTool: Beginning code generation
2019-12-24 18:29:56,087 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `admin` AS t LIMIT 1
2019-12-24 18:29:56,110 INFO manager.SqlManager: Executing SQL statement: SELECT t.* FROM `admin` AS t LIMIT 1
2019-12-24 18:29:56,116 INFO orm.CompilationManager: HADOOP_MAPRED_HOME is /home/linyouquan/hadoop3-hadoop-pack
Note: /tmp/sqoop-linyouquan/compile/cf7897369f7ede4babaf39adfd2e55aa/admin.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
2019-12-24 18:29:57,451 INFO orm.CompilationManager: Writing jar file: /tmp/sqoop-linyouquan/compile/cf7897369f7ede4babaf39adfd2e55aa/admin.jar
2019-12-24 18:29:57,464 WARN manager.MySQLManager: It looks like you are importing from mysql.
2019-12-24 18:29:57,464 WARN manager.MySQLManager: This transfer can be faster! Use the --direct
2019-12-24 18:29:57,464 WARN manager.MySQLManager: option to exercise a MySQL-specific fast path.
2019-12-24 18:29:57,464 INFO manager.MySQLManager: Setting zero DATETIME behavior to convertToNull (mysql)
2019-12-24 18:29:57,468 INFO mapreduce.ImportJobBase: Beginning import of admin
2019-12-24 18:29:57,469 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-12-24 18:29:57,639 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
2019-12-24 18:29:57,770 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
2019-12-24 18:29:58,051 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2019-12-24 18:29:58,117 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2019-12-24 18:29:58,117 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2019-12-24 18:29:58,244 INFO db.DBInputFormat: Using read commited transaction isolation
2019-12-24 18:29:58,260 INFO mapreduce.JobSubmitter: number of splits:1
2019-12-24 18:29:58,378 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1105755779_0001
2019-12-24 18:29:58,380 INFO mapreduce.JobSubmitter: Executing with tokens: []
2019-12-24 18:29:58,599 INFO mapred.LocalDistributedCacheManager: Creating symlink: /tmp/hadoop-linyouquan/mapred/local/1577183398474/libjars <- /home/linyouquan/yarn/YARN/libjars/*
2019-12-24 18:29:58,601 WARN fs.FileUtil: Command 'ln -s /tmp/hadoop-linyouquan/mapred/local/1577183398474/libjars /home/linyouquan/yarn/YARN/libjars/*' failed 1 with: ln: creating symbolic link `/home/linyouquan/yarn/YARN/libjars/*': No such file or directory2019-12-24 18:29:58,601 WARN mapred.LocalDistributedCacheManager: Failed to create symlink: /tmp/hadoop-linyouquan/mapred/local/1577183398474/libjars <- /home/linyouquan/yarn/YARN/libjars/*
2019-12-24 18:29:58,602 INFO mapred.LocalDistributedCacheManager: Localized file:/tmp/hadoop/mapred/staging/linyouquan1105755779/.staging/job_local1105755779_0001/libjars as file:/tmp/hadoop-linyouquan/mapred/local/1577183398474/libjars
2019-12-24 18:29:58,673 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2019-12-24 18:29:58,674 INFO mapreduce.Job: Running job: job_local1105755779_0001
2019-12-24 18:29:58,674 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2019-12-24 18:29:58,682 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-12-24 18:29:58,682 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-12-24 18:29:58,682 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2019-12-24 18:29:58,701 INFO mapred.LocalJobRunner: Waiting for map tasks
2019-12-24 18:29:58,701 INFO mapred.LocalJobRunner: Starting task: attempt_local1105755779_0001_m_000000_0
2019-12-24 18:29:58,725 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
2019-12-24 18:29:58,725 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-12-24 18:29:58,739 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2019-12-24 18:29:58,744 INFO db.DBInputFormat: Using read commited transaction isolation
2019-12-24 18:29:58,748 INFO mapred.MapTask: Processing split: 1=1 AND 1=1
2019-12-24 18:29:58,754 INFO mapred.LocalJobRunner: map task executor complete.
2019-12-24 18:29:58,755 WARN mapred.LocalJobRunner: job_local1105755779_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class admin not found
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:552)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class admin not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2597)
	at org.apache.sqoop.mapreduce.db.DBConfiguration.getInputClass(DBConfiguration.java:403)
	at org.apache.sqoop.mapreduce.db.DataDrivenDBInputFormat.createDBRecordReader(DataDrivenDBInputFormat.java:270)
	at org.apache.sqoop.mapreduce.db.DBInputFormat.createRecordReader(DBInputFormat.java:266)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:534)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:777)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:348)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: Class admin not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2501)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2595)
	... 12 more
2019-12-24 18:29:59,678 INFO mapreduce.Job: Job job_local1105755779_0001 running in uber mode : false
2019-12-24 18:29:59,679 INFO mapreduce.Job:  map 0% reduce 0%
2019-12-24 18:29:59,682 INFO mapreduce.Job: Job job_local1105755779_0001 failed with state FAILED due to: NA
2019-12-24 18:29:59,689 INFO mapreduce.Job: Counters: 0
2019-12-24 18:29:59,693 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2019-12-24 18:29:59,695 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 1.913 seconds (0 bytes/sec)
2019-12-24 18:29:59,695 WARN mapreduce.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
2019-12-24 18:29:59,695 INFO mapreduce.ImportJobBase: Retrieved 0 records.
2019-12-24 18:29:59,695 ERROR tool.ImportTool: Import failed: Import job failed!
{code}"
MAPREDUCE-7252,Handling 0 progress in SimpleExponential task runtime estimator,"The simple exponential runtime estimator (added in MAPREDUCE-7208) seems not to handle the corner cases where the delta progress is 0. As a result, the forecast will be NaN or Inf which messes up the subsequent forecast values."
MAPREDUCE-7250,FrameworkUploader: skip replication check entirely if timeout == 0,"The framework uploader tool has this piece of code which makes sure that all block of the uploaded mapreduce tarball has been replicated:

{noformat}
      while(endTime - startTime < timeout * 1000 &&
           currentReplication < acceptableReplication) {
        Thread.sleep(1000);
        endTime = System.currentTimeMillis();
        currentReplication = getSmallestReplicatedBlockCount();
      }
{noformat}

There are cases, however, when we don't want to wait for this (eg. we want to speed up Hadoop installation).

I suggest adding {{--skiprelicationcheck}} switch which disables this replication test."
MAPREDUCE-7249,Invalid event TA_TOO_MANY_FETCH_FAILURE at SUCCESS_CONTAINER_CLEANUP causes job failure ,"Same issue as in MAPREDUCE-7240 but this one has a different state in which the Exception {{TA_TOO_MANY_FETCH_FAILURE}} event is received:
{code}
2019-11-18 23:03:40,270 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1568654141590_630203_m_003108_1
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_CONTAINER_CLEANUP
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1183)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:148)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1388)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1380)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:182)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)
{code}

The stack trace is from a CDH release which is highly patched 2.6 release. "
MAPREDUCE-7247,"Modify HistoryServerRest.html content,change The job attempt id‘s datatype from string to int","The Job Attempts API http://history-server-http-address:port/ws/v1/history/mapreduce/jobs/\{jobid}/jobattempts document, In http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/HistoryServerRest.html#Job_Attempts_API, change The job attempt id‘s datatype from string to int.

!image-2019-10-29-14-46-17-354.png|width=508,height=126!

!image-2019-10-29-14-46-49-929.png|width=465,height=315!"
MAPREDUCE-7246," In MapredAppMasterRest#Mapreduce_Application_Master_Info_API, the datatype of appId should be ""string"".","In hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredAppMasterRest#Mapreduce_Application_Master_Info_API, URI http://proxy-http-address:port/proxy/\{appid}/ws/v1/mapreduce, the datatype of appId should be ""string"".
  !image-2019-10-28-16-37-32-588.png|width=462,height=289!
!image-2019-10-28-16-37-49-465.png!"
MAPREDUCE-7241,FileInputFormat listStatus with less memory footprint,"This case sometimes sees in hive when user issues queries over all partitions by mistakes. The file status cached when listing status could accumulate to over 3g.  After digging into the  dumped memory, the LocatedBlock occupies about 50%(sometimes over 60%) memory that retained by LocatedFileStatus, as shows followed,

!filestatus.png!

Right now we only extract the block locations info from LocatedFileStatus,  the datanode infos(types) or block token are not taken into account. So there is no need to cache LocatedBlock, as do like this:

BlockLocation[] blockLocations = dedup(stat.getBlockLocations());
 LocatedFileStatus shrink = new LocatedFileStatus(stat, blockLocations);

private static BlockLocation[] dup(BlockLocation[] blockLocations) {
     BlockLocation[] copyLocs = new BlockLocation[blockLocations.length];
     int i = 0;
     for (BlockLocation location : blockLocations)

{         copyLocs[i++] = new BlockLocation(location);     }

    return copyLocs;
 }

 "
MAPREDUCE-7240,Exception ' Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_FINISHING_CONTAINER' cause job error,"*log in appmaster*
{noformat}
2019-09-03 17:18:43,090 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1566552310686_260041_m_000052_0 ... raising fetch failure to map
2019-09-03 17:18:43,091 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1566552310686_260041_m_000049_0 ... raising fetch failure to map
2019-09-03 17:18:43,091 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1566552310686_260041_m_000051_0 ... raising fetch failure to map
2019-09-03 17:18:43,091 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1566552310686_260041_m_000050_0 ... raising fetch failure to map
2019-09-03 17:18:43,091 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1566552310686_260041_m_000053_0 ... raising fetch failure to map
2019-09-03 17:18:43,092 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1566552310686_260041_m_000052_0 transitioned from state SUCCEEDED to FAILED, event type is TA_TOO_MANY_FETCH_FAILURE and nodeId=yarn095:45454
2019-09-03 17:18:43,092 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1566552310686_260041_m_000049_0
org.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_FINISHING_CONTAINER
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1206)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1458)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1450)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)
	at java.lang.Thread.run(Thread.java:745)
2019-09-03 17:18:43,093 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1566552310686_260041_m_000051_0
org.apache.hadoop.yarn.state.InvalidStateTransitionException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_FINISHING_CONTAINER
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1206)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1458)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1450)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:184)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:110)
	at java.lang.Thread.run(Thread.java:745)
2019-09-03 17:18:43,093 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1566552310686_260041_m_000050_0 transitioned from state SUCCEEDED to FAILED, event type is TA_TOO_MANY_FETCH_FAILURE and nodeId=yarn095:45454
2019-09-03 17:18:43,093 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1566552310686_260041_m_000053_0 transitioned from state SUCCEEDED to FAILED, event type is TA_TOO_MANY_FETCH_FAILURE and nodeId=yarn095:45454
2019-09-03 17:18:43,094 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1566552310686_260041_m_000052 Task Transitioned from SUCCEEDED to SCHEDULED
2019-09-03 17:18:43,096 FATAL [IPC Server handler 27 on 35972] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1566552310686_260041_r_000005_0 - exited : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#22
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1961)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkReducerHealth(ShuffleSchedulerImpl.java:367)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:289)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:355)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)

2019-09-03 17:18:43,096 INFO [IPC Server handler 27 on 35972] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Diagnostics report from attempt_1566552310686_260041_r_000005_0: Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#22
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1961)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:169)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkReducerHealth(ShuffleSchedulerImpl.java:367)
	at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:289)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:355)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)

2019-09-03 17:18:43,097 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1566552310686_260041Job Transitioned from RUNNING to ERROR
2019-09-03 17:18:43,099 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job

{noformat}
  

nodemanager's  log is like same with log in  MAPREDUCE-6869.

the code in TaskAttemptImpl indicate the Invalid event: TA_TOO_MANY_FETCH_FAILURE at SUCCESS_FINISHING_CONTAINER cause the job state turn into error; what i confused is 
 # what cause the appmater  handle the TA_TOO_MANY_FETCH_FAILURE  event on SUCCESS_FINISHING_CONTAINER，illegal event on this state.  but some other can successfully transitioned from state SUCCEEDED to FAILED on TA_TOO_MANY_FETCH_FAILURE  event.
 # restart the nodemanager would solve the error in nm; the shuffle error would fix too. what cause this phenomenon.

Correct me if I am wrong."
MAPREDUCE-7239,test,
MAPREDUCE-7237,Supports config the shuffle's path cache related parameters,Nowadays the ShuffleHandler#Shuffle#pathCache's related parameters is hard coding. We should support config these.
MAPREDUCE-7234,Fix spelling of isSplitable() to isSplitabble(),method *isSplitable* ---> isSplittable
MAPREDUCE-7231,hadoop-mapreduce-client-jobclient fails with timeout,"hadoop-mapreduce-client-jobclient fails with timeout

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:3.0.0-M1:test (default-test) on project hadoop-mapreduce-client-jobclient: There was a timeout or other error in the fork -> [Help 1]
{code}"
MAPREDUCE-7230,TestHSWebApp.testLogsViewSingle fails,"TestHSWebApp.testLogsViewSingle fails.

{code}
[ERROR] testLogsViewSingle(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHSWebApp)  Time elapsed: 0.294 s  <<< FAILURE!
Argument(s) are different! Wanted:
printWriter.write(
    ""Logs not available for container_10_0001_01_000001. Aggregation may not be complete, Check back later or try the nodemanager at localhost:1234""
);
-> at org.apache.hadoop.mapreduce.v2.hs.webapp.TestHSWebApp.testLogsViewSingle(TestHSWebApp.java:234)
Actual invocations have different arguments:
printWriter.print(
    ""<!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01//EN"" ""http://www.w3.org/TR/html4/strict.dtd"">""
);
-> at org.apache.hadoop.yarn.webapp.view.TextView.echoWithoutEscapeHtml(TextView.java:62)
printWriter.write(
    ""<!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01//EN"" ""http://www.w3.org/TR/html4/strict.dtd"">""
);
-> at java.io.PrintWriter.print(PrintWriter.java:617)
printWriter.write(
    ""<!DOCTYPE html PUBLIC ""-//W3C//DTD HTML 4.01//EN"" ""http://www.w3.org/TR/html4/strict.dtd"">"",
    0,
    90
);
-> at java.io.PrintWriter.write(PrintWriter.java:473)
printWriter.println(
    
);
-> at org.apache.hadoop.yarn.webapp.view.TextView.putWithoutEscapeHtml(TextView.java:81)
printWriter.print(
    ""<html""
);
-> at org.apache.hadoop.yarn.webapp.hamlet2.HamletImpl.printStartTag(HamletImpl.java:273)
printWriter.write(
    ""<html""
);
-> at java.io.PrintWriter.print(PrintWriter.java:603)
printWriter.write(
    ""<html"",
    0,
    5
);
{code}"
MAPREDUCE-7228,Refactor ActionExecutorTestCase to not extend HCatTestCase,"{{ActionExecutorTestCase}} extends {{HCatTestCase}} but there are only two test cases where we need HCatalog related settings as well. 

Let's try to refactor this part and make the ActionExecturTestCase independent from the HCatalog part."
MAPREDUCE-7225,Fix broken current folder expansion during MR job start,"Starting a sleep job giving ""."" as files that should be localized is working fine up until 2.9.0, but after that the user is given an IllegalArgumentException. This change is a side-effect of HADOOP-12747 where {{GenericOptionsParser#validateFiles}} function got modified.

Can be reproduced by starting a sleep job with ""-files ."" given as extra parameter. Log:
{noformat}
sudo -u hdfs hadoop jar hadoop-mapreduce-client-jobclient-3.0.0.jar sleep -files . -m 1 -r 1 -rt 2000 -mt 2000
WARNING: Use ""yarn jar"" to launch YARN applications.
19/07/17 08:13:26 INFO client.ConfiguredRMFailoverProxyProvider: Failing over to rm21
19/07/17 08:13:26 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /user/hdfs/.staging/job_1563349475208_0017
19/07/17 08:13:26 INFO mapreduce.JobSubmitter: Cleaning up the staging area /user/hdfs/.staging/job_1563349475208_0017
java.lang.IllegalArgumentException: Can not create a Path from an empty string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:168)
	at org.apache.hadoop.fs.Path.<init>(Path.java:180)
	at org.apache.hadoop.fs.Path.<init>(Path.java:125)
	at org.apache.hadoop.mapreduce.JobResourceUploader.copyRemoteFiles(JobResourceUploader.java:686)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:262)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:203)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1726)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.hadoop.mapreduce.SleepJob.run(SleepJob.java:273)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.mapreduce.SleepJob.main(SleepJob.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:139)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:147)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:313)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:227)
{noformat}"
MAPREDUCE-7224,Could not find or load main class org.apache.hadoop.yarn.server.nodemanager.containermanager.loca lizer.ContainerLocalizer when  yarn on kerberos ," 

cat /etc/container-executor.cfg

yarn.nodemanager.linux-container-executor.group=hadoop#
banned.users=#comma separated list of users who can not run applications
min.user.id=1#Prevent other super-users
allowed.system.users=jingwei.shi#

 

cat  yarn-site.xml

<property>
 <name>yarn.resourcemanager.keytab</name>
 <value>/var/kerberos/krb5/user/hadoop.keytab</value>
 </property>

<property>
 <name>yarn.resourcemanager.principal</name>
 <value>hadoop/_HOST@HADOOP.COM</value>
 </property>

<property>
 <name>yarn.nodemanager.keytab</name>
 <value>/var/kerberos/krb5/user/hadoop.keytab</value>
 </property>

<property>
 <name>yarn.nodemanager.principal</name>
 <value>hadoop/_HOST@HADOOP.COM</value>
 </property>

<property>
 <name>yarn.nodemanager.default-container-executor.log-dirs.permissions</name>
 <value>777</value>
 </property>

<property>
 <name>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users</name>
 <value>false</value>
 </property>

<property>
 <name>yarn.nodemanager.container-executor.class</name>
 <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
 <!--value>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</value-->
 </property>

<property>
 <name>yarn.nodemanager.linux-container-executor.group</name>
 <value>hadoop</value>
 </property>

<property>
 <name>yarn.nodemanager.local-dirs</name>
 <value>/tmp/userlogs</value>
 </property>

<property>
 <name>yarn.nodemanager.log-dirs</name>
 <value>/tmp/userlogs</value>
 </property>

++++++++++++++++++++++++++++++++++

klist 
 Ticket cache: FILE:/tmp/krb5cc_1000
 Default principal: hadoop/bj-jd-dc-namenode-prod-0003.tendcloud.com@HADOOP.COM

Valid starting Expires Service principal
 07/12/2019 16:05:00 07/13/2019 16:05:00 krbtgt/HADOOP.COM@HADOOP.COM
 renew until 07/26/2019 16:05:00

Hadoop user submitted tasks successfully ；

————————————————————————————————

while other user submitted tasks showed that no classes were found .

klist 
 Ticket cache: FILE:/tmp/krb5cc_1000
 Default principal: jingwei.shi/datanode-prod-0011.tendcloud.com@HADOOP.COM

Valid starting Expires Service principal
 07/12/2019 14:50:37 07/13/2019 14:50:24 krbtgt/HADOOP.COM@HADOOP.COM
 renew until 07/26/2019 14:50:24

2019-07-12 15:28:01,225 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService: Localizer failed for container_e28_1562916339074_0001_02_000001
 java.io.IOException: Application application_1562916339074_0001 initialization failed (exitCode=1) with output: main : command provided 0
 main : run as user is jingwei.shi
 main : requested yarn user is jingwei.shi

at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.startLocalizer(LinuxContainerExecutor.java:411)
 at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:1245)
 Caused by: org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=1: Error: Could not find or load main class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer"
MAPREDUCE-7222,Map tasks' outputs can not be recovered  when ApplicationMaster relaunched,"When AM crashes, Yarn would launch a new AM instance and recover all its scheduled tasks. However mapper tasks's committed output files are not recovered when the number of reducers > 0. In my application which output files from mapper and make use of reducer to collect statistics not able to fully recover from the AM crash, and resulting in data from the previous completed mapper tasks get lost in the final output dir."
MAPREDUCE-7218,Remove unused pieces related to mapreduce.reduce.merge.inmem.threshold,"Due to `mapreduce.reduce.merge.inmem.threshold` is invalid, so we need to remove it."
MAPREDUCE-7214,Remove unused pieces related to `mapreduce.job.userlog.retain.hours`,"Due to `mapreduce.job.userlog.retain.hours` is invalid, so we need to remove it."
MAPREDUCE-7212,Remove unused pieces related to mapreduce.job.jvm.numtasks,"Due to `mapreduce.job.jvm.numtasks` is invalid, so we need to remove it."
MAPREDUCE-7210,Replace `mapreduce.job.counters.limit` with `mapreduce.job.counters.max` in mapred-default.xml,"Because the `mapreduce.job.counters.limit` is deprecated, the new property name is `mapreduce.job.counter.max`, so we need update the `mapred-default.xml`."
MAPREDUCE-7208,Tuning TaskRuntimeEstimator ,"By default, MR uses LegacyTaskRuntimeEstimator to get an estimate of the runtime.  The estimator does not adjust dynamically to the progress rate of the tasks. On the other hand, the existing alternative ""ExponentiallySmoothedTaskRuntimeEstimator"" behavior in unpredictable.

 

There are several dimensions to improve the exponential implementation:
 # Exponential shooting needs a warmup period. Otherwise, the estimate will be affected by the initial values.
 # Using a single smoothing factor (Lambda) does not work well for all the tasks. To increase the level of smoothing across the majority of tasks, we need to give a range of flexibility to dynamically adjust the smoothing factor based on the history of the task progress.
 # Design wise, it is better to separate between the statistical model and the MR interface. We need to have a way to evaluate estimators statistically, without the need to run MR. For example, an estimator can be evaluated as a black box by using a stream of raw data as input and testing the accuracy of the generated stream of estimates.
 # The exponential estimator speculates frequently and fails to detect slowing tasks. It does not detect slowing tasks. As a result, a taskAttempt that does not do any progress won't trigger a new speculation.

 

The file [^smoothing-exponential.md] describes how Simple Exponential smoothing factor works.

 

 "
MAPREDUCE-7206,ShuffleHandler cannot access file.out ,"i am running HDP 3.1 (3.1.0.0-78) , i have 10 data nodes , Hive execution engine is TEZ, when i run a query i get this error,
{code:java}
ERROR : FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex failed, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00, diagnostics=[Vertex vertex_1557754551780_1091_2_00 [Map 1] killed/failed due to:OWN_TASK_FAILURE, Vertex vertex_1557754551780_1091_2_00 [Map 1] failed as task task_1557754551780_1091_2_00_000001 failed after vertex succeeded.]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0
INFO : Completed executing command(queryId=hive_20190516161715_09090e6d-e513-4fcc-9c96-0b48e9b43822); Time taken: 17.935 seconds
Error: Error while processing statement: FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.tez.TezTask. Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex re-running, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00Vertex failed, vertexName=Map 1, vertexId=vertex_1557754551780_1091_2_00, diagnostics=[Vertex vertex_1557754551780_1091_2_00 [Map 1] killed/failed due to:OWN_TASK_FAILURE, Vertex vertex_1557754551780_1091_2_00 [Map 1] failed as task task_1557754551780_1091_2_00_000001 failed after vertex succeeded.]DAG did not succeed due to VERTEX_FAILURE. failedVertices:1 killedVertices:0 (state=08S01,code=2)
{code}
when i traced the logs, for example the application id is *application_1557754551780_1091* 

checked the node manager logs
{code:java}
2019-05-16 16:19:05,801 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
2019-05-16 16:19:05,818 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
2019-05-16 16:19:05,821 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
2019-05-16 16:19:05,822 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
2019-05-16 16:19:05,824 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
2019-05-16 16:19:05,826 INFO mapred.ShuffleHandler (ShuffleHandler.java:sendMapOutput(1268)) - /var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003/file.out not found
{code}
i checked the path where the output of the Map will be there in ( */var/lib/hadoop/yarn/local/usercache/hive/appcache/application_1557754551780_1091/output/attempt_1557754551780_1091_2_00_000000_0_10003* )

 
{code:java}
drwx--x---. 3 hive hadoop 16 May 16 16:16 filecache
drwxr-s---. 3 hive hadoop 60 May 16 16:16 output
{code}
inside the output : 

 

 
{code:java}
-rw-------. 1 hive hadoop 28 May 16 16:17 file.out
-rw-r-----. 1 hive hadoop 32 May 16 16:17 file.out.index
{code}
 

so the *file.out* is not readable by other users in same group (switched to yarn user and tried to open this file and got permission denied) 

 

 

 

 "
MAPREDUCE-7205,Treat container scheduler kill exit code as a task attempt killing event,"MR needs to recognize the special exit code value of -108 and interpret it as a container being killed instead of a container failure.

-108: Container was terminated by the ContainerScheduler to make room for another container..."
MAPREDUCE-7201,Make Job History File Permissions configurable,Job History File Permissions are hardcoded to 770. MAPREDUCE-7010 allows to configure the intermediate user directory permission but still the jhist file permission are not changed.
MAPREDUCE-7200,Remove stale eclipse templates,"In {{./hadoop-mapreduce-project/.eclipse.templates}} directory, JobTracker.launch and TaskTracker.launch should be removed. In addition, probably there is no one using the directory. Let's remove it."
MAPREDUCE-7199,HsJobsBlock reuse JobACLsManager for checkAccess,"Reuse JobAclManager.checkAccess

{code} 
 private boolean checkAccess(String userName) {
    if(!areAclsEnabled) {
      return true;
    }

    // User could see its own job.
    if (ugi.getShortUserName().equals(userName)) {
      return true;
    }

    // Admin could also see all jobs
    if (adminAclList != null && adminAclList.isUserAllowed(ugi)) {
      return true;
    }
    return false;
  }
{code} 

{code}
jobACLsManager
          .checkAccess(ugi, JobACL.VIEW_JOB, ..
              new AccessControlList()))
{code}"
MAPREDUCE-7198,mapreduce.task.timeout=0 configuration used to disable timeout doesn't work,"mapreduce.task.timeout=0 configuration used to disable timeout doesn't work after MAPREDUCE-6190. If the task timeout is configured as zero the task fails with stuck timeout, if the TaskStatus is null.
{code}
          if (sendProgress) {
            // we need to send progress update
            updateCounters();
            checkTaskLimits();
            taskStatus.statusUpdate(taskProgress.get(),
                                    taskProgress.toString(),
                                    counters);
            amFeedback = umbilical.statusUpdate(taskId, taskStatus);
            taskFound = amFeedback.getTaskFound();
            taskStatus.clearStatus();
          }
          else {
            // send ping 
            amFeedback = umbilical.statusUpdate(taskId, null);
            taskFound = amFeedback.getTaskFound();
          }
{code}
This issue is reported by [~bibinchundatt]."
MAPREDUCE-7192,JobHistoryServer attempts page support jump to  containers log page in NM when logAggregation is disable,"when yarn.log-aggregation-enable is false, we can not view containers' logs even through there are log files of container in the NM in HistoryServer. Web page is below when clicking logs url.
  !container_log_page.png! 

This patch can jump to containers log url of NM when  yarn.log-aggregation-enable=false"
MAPREDUCE-7191,JobHistoryServer should log exception when loading/parsing history file failed,"I'm test rolling 2.7.2 to 3.2.0. 
RM& NM has upgrade to 3.2.0, JobHistoryServer is still 2.7.2.
When submitting MR job using 3.2.0 client I found JobHistory URL could not open, and in webpage showing ""Could not load history file hdfs://NameNode:8020/tmp/hadoop-yarn/staging/history3/done/2019/03/06/000000/job_1551697798944_0020****.jhist""

There are only loading log just like following and no exception info in log file of  JobHistoryServer.
{code:java}
2019-03-06 16:24:19,489 INFO org.apache.hadoop.mapreduce.v2.hs.CompletedJob: Loading job: job_1551697798944_0020 from file: hdfs://NameNode:8020/tmp/hadoop-yarn/staging/history3/done/2019/03/06/000000/job_1551697798944_0020****.jhist
2019-03-06 16:24:19,489 INFO org.apache.hadoop.mapreduce.v2.hs.CompletedJob: Loading history file: [hdfs://NameNode:8020/tmp/hadoop-yarn/staging/history3/done/2019/03/06/000000/job_1551697798944_0020****.jhist]
{code}

After I add some log when loading history file failed I get following exception. 3.2.0 write jhist files using *binary* format,  but 2.7.2 using *json* format. After I set mapreduce.jobhistory.jhist.format=json in 3.2.0 client configuration, I can get job info from jhs.

There is still no log in Hadoop-3.2.0, I think it's very helpful to add some log to debug.

Loading jhist file Exception is follows:
{code:java}
2019-03-06 16:51:55,664 WARN org.apache.hadoop.mapreduce.v2.hs.CompletedJob: Could not load history file hdfs://NameNode:8020/tmp/hadoop-yarn/staging/history3/done/2019/03/06/000000/job_1551697798944_0020****.jhist
java.io.IOException: Incompatible event log version: Avro-Binary
        at org.apache.hadoop.mapreduce.jobhistory.EventReader.<init>(EventReader.java:71)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:139)
        at org.apache.hadoop.mapreduce.v2.hs.CompletedJob.loadFullHistoryData(CompletedJob.java:347)
        at org.apache.hadoop.mapreduce.v2.hs.CompletedJob.<init>(CompletedJob.java:101)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.loadJob(HistoryFileManager.java:450)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.loadJob(CachedHistoryStorage.java:180)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.access$000(CachedHistoryStorage.java:52)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage$1.load(CachedHistoryStorage.java:103)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage$1.load(CachedHistoryStorage.java:100)
        at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3568)
        at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2350)
        at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2313)
        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2228)
        at com.google.common.cache.LocalCache.get(LocalCache.java:3965)
        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3969)
        at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4829)
        at com.google.common.cache.LocalCache$LocalManualCache.getUnchecked(LocalCache.java:4834)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getFullJob(CachedHistoryStorage.java:193)
        at org.apache.hadoop.mapreduce.v2.hs.JobHistory.getJob(JobHistory.java:217)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.requireJob(AppController.java:381)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.job(AppController.java:108)
        at org.apache.hadoop.mapreduce.v2.hs.webapp.HsController.job(HsController.java:104)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
{code}
"
MAPREDUCE-7190,Add SleepJob additional parameter to make parallel runs distinguishable,"In our testing framework, we use SleepJobs for test scheduling and to check different resource types are assigned properly to containers. Sometimes we start multiple jobs in parallel, and if one fails, we have to track which one was that. It is not too hard to find out that information, but would have been much more convenient if it was written in the name of the job.

Proposal: additional parameter to SleepJob, so that its name can be changed from default ""Sleep job."" to something like ""Sleep job - _additional info_""."
MAPREDUCE-7188,[Clean-up] Remove NULL check before instanceof and fix checkstyle issue in TaskResult,
MAPREDUCE-7184,TestJobCounters byte counters omitting crc file bytes read,"TestJobCounters test cases are failing in trunk while validating the input files size with BYTES_READ by the job. The crc files are considered in getFileSize whereas the job FileInputFormat -ignores them.- has stopped reading the CRC counters

"
MAPREDUCE-7182,MapReduce input format/record readers to support S3 select queries,"HADOOP-15229 adds S3 select through the (new) async openFile API, but the classic RecordReader &c can't handle it because

# the files are shorter than they are in a getFileStatus, and the readers assume that an EOFException is an error in that situation
# everything assumes plain text is splitable
# if a file has a gz extension, the gunzip codec should be used. So breaks transcoded/uncompressed data

to handle s3 select data sources  we need to be able to address them, either through changes to the existing code (danger?) or some new readers"
MAPREDUCE-7177,Disable speculative execution in TestDFSIO,"When TestDFSIO runs in a certain environment where a subset of mappers are slow, the speculative execution can start.  In the write phase, this will make existing mapper to fail in next addBlock() since the output files are overwritten.

To make the benchmark more predictable and repeatable, speculation must be implicitly disabled in TestDFSIO itself. "
MAPREDUCE-7175,JobSubmitter: validateFilePath() throws an exception because it requests a local FS unnecessarily,"After a security fix, we receive the following exception in Oozie if we want to use {{mapreduce.job.log4j-properties-file}}
{noformat}
org.apache.oozie.action.ActionExecutorException: UnsupportedOperationException: Accessing local file system is not allowed
at org.apache.oozie.action.ActionExecutor.convertException(ActionExecutor.java:446)
at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:1246)
at org.apache.oozie.action.hadoop.JavaActionExecutor.start(JavaActionExecutor.java:1424)
at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:232)
at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:63)
at org.apache.oozie.command.XCommand.call(XCommand.java:286)
at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:332)
at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:261)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:179)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.UnsupportedOperationException: Accessing local file system is not allowed
at org.apache.hadoop.fs.RawLocalFileSystem.initialize(RawLocalFileSystem.java:48)
at org.apache.hadoop.fs.LocalFileSystem.initialize(LocalFileSystem.java:47)
at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2816)
at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:98)
at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2853)
at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2835)
at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:387)
at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:358)
at org.apache.hadoop.mapreduce.JobResourceUploader.validateFilePath(JobResourceUploader.java:303)
at org.apache.hadoop.mapreduce.JobResourceUploader.copyLog4jPropertyFile(JobResourceUploader.java:248)
at org.apache.hadoop.mapreduce.JobResourceUploader.addLog4jToDistributedCache(JobResourceUploader.java:223)
at org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:175)
at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:99)
at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:194)
at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1307)
at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1304)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)
at org.apache.hadoop.mapreduce.Job.submit(Job.java:1304)
at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:578)
at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:573)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:422)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1924)
at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:573)
at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:564)
at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:1231)
... 11 more{noformat}
 

Note that this happens even if the scheme is {{hdfs://}}. The solution is what mentioned in MAPREDUCE-6052: move
{noformat}
FileSystem localFs = FileSystem.getLocal(conf);{noformat}
inside the {{if}} block."
MAPREDUCE-7174,MapReduce example wordmedian should handle generic options,"For example, if we run wordmedian by  'wordmedian -Dmapreduce.job.queuename=xxx arg1 arg2', found that  mapreduce.job.queuename=xxx was not passed to jobconf. "
MAPREDUCE-7170,Doc typo in PluggableShuffleAndPluggableSort.md," 
{code:java}
<property>
    <name>yarn.nodemanager.aux-services.AuxServiceFromHDFS.class&lt;/name>
    <value>org.apache.auxtest.AuxServiceFromHDFS2</value>
</property>
{code}"
MAPREDUCE-7166,map-only job should ignore node lost event when task is already succeeded,"When node lost, all mappers on this node will be rescheduled, but it's unnecessary for succeeded map only task because map only job has no reducer, and map output has been written to HDFS when it become succeeded, so we can ignore this node lost event."
MAPREDUCE-7165,mapred-site.xml is misformatted in single node setup document,"In https://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-common/SingleCluster.html#YARN_on_a_Single_Node, there are two configuration tags in mapred-site.xml."
MAPREDUCE-7164,FileOutputCommitter does not report progress while merging paths.,"In cases where the rename and merge path logic takes more time than usual, the committer does not report progress and can cause job failure. This behavior was not present in Hadoop 1.x. This JIRA will fix it so that the old behavior for 1.x is restored."
MAPREDUCE-7162,TestEvents#testEvents fails,"Mapreduce unit test is broken by https://issues.apache.org/jira/browse/MAPREDUCE-7158 . 

*I think we should keep the data consistent to avoid corruption when output, so I roll back the previous code and attach the patch.*

Broken location _is org.apache.hadoop.mapreduce.jobhistory.TestEvents#testEvents._
{code:java}
org.codehaus.jackson.JsonParseException: Illegal unquoted character ((CTRL-CHAR, code 10)): has to be escaped using backslash to be included in name
at [Source: java.io.DataInputStream@25618e91; line: 23, column: 418]

at org.codehaus.jackson.JsonParser._constructError(JsonParser.java:1433)
at org.codehaus.jackson.impl.JsonParserMinimalBase._reportError(JsonParserMinimalBase.java:521)
at org.codehaus.jackson.impl.JsonParserMinimalBase._throwUnquotedSpace(JsonParserMinimalBase.java:482)
at org.codehaus.jackson.impl.Utf8StreamParser.parseEscapedFieldName(Utf8StreamParser.java:1446)
at org.codehaus.jackson.impl.Utf8StreamParser.parseFieldName(Utf8StreamParser.java:1410)
at org.codehaus.jackson.impl.Utf8StreamParser._parseFieldName(Utf8StreamParser.java:1283)
at org.codehaus.jackson.impl.Utf8StreamParser.nextToken(Utf8StreamParser.java:495)
at org.apache.avro.io.JsonDecoder.doArrayNext(JsonDecoder.java:367)
at org.apache.avro.io.JsonDecoder.arrayNext(JsonDecoder.java:361)
at org.apache.avro.io.ValidatingDecoder.arrayNext(ValidatingDecoder.java:189)
at org.apache.avro.generic.GenericDatumReader.readArray(GenericDatumReader.java:222)
at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:153)
at org.apache.avro.generic.GenericDatumReader.readField(GenericDatumReader.java:193)
at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:183)
at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:151)
at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:155)
at org.apache.avro.generic.GenericDatumReader.readField(GenericDatumReader.java:193)
at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:183)
at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:151)
at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:142)
at org.apache.hadoop.mapreduce.jobhistory.EventReader.getNextEvent(EventReader.java:101)
at org.apache.hadoop.mapreduce.jobhistory.TestEvents.testEvents(TestEvents.java:177)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:498)
at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.lang.Thread.run(Thread.java:748)
{code}"
MAPREDUCE-7159,FrameworkUploader: ensure proper permissions of generated framework tar.gz if restrictive umask is used,"Using certain umask values (like 027) makes files unreadable to ""others"". This causes problems if the FrameworkUploader (https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-uploader/src/main/java/org/apache/hadoop/mapred/uploader/FrameworkUploader.java) is used - it's necessary that the compressed MR framework is readable by all users, otherwise they won't be able to run MR jobs."
MAPREDUCE-7158,Inefficient Flush Logic in JobHistory EventWriter,"In HDFS, if the flush is implemented to send server request to actually commit the pending writes on the storage service side, we could observe in the benchmark runs that the MR jobs are taking much longer. From investigation we see the current implementation for writing events doesn't look right:
EventWriter# write()
This flush is redundant and this statement should be removed. It defeats the purpose of having a separate flush function itself.
Encoder.flush calls flush of the underlying output stream
After patching with the fix the MR jobs could complete normally, please kindly find the patch in attached."
MAPREDUCE-7156,NullPointerException when reaching max shuffle connections," When you hit the max number of shuffle connections, you can get a lot of NullPointerExceptions from Netty:

{noformat}
2018-07-17 10:47:36,311 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 10:47:36,311 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 10:47:36,312 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 10:47:36,316 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,317 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0x71187405, /10.17.226.11:44330 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,317 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,317 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0x71187405, /10.17.226.11:44330 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,317 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,317 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0x71187405, /10.17.226.11:44330 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,329 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl: Skipping monitoring container container_e22_1531424278071_55040_01_002295 since CPU usage is not yet available.
2018-07-17 10:47:36,340 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,340 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0xea8afd26, /10.17.202.18:43810 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,349 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,349 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0xea8afd26, /10.17.202.18:43810 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,349 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
2018-07-17 10:47:36,349 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error [id: 0xea8afd26, /10.17.202.18:43810 => /10.17.202.21:13562] EXCEPTION: java.lang.NullPointerException
2018-07-17 10:47:36,361 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 10:47:36,390 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 10:47:36,395 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
{noformat}

{noformat}
2018-07-17 13:58:28,263 INFO org.apache.hadoop.mapred.ShuffleHandler: Current number of shuffle connections (360) is greater than or equal to the max allowed shuffle connections (360)
2018-07-17 13:58:28,264 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error:
java.lang.NullPointerException
        at org.jboss.netty.handler.timeout.IdleStateHandler.writeComplete(IdleStateHandler.java:302)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:73)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.writeComplete(SimpleChannelUpstreamHandler.java:233)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:73)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:142)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.writeComplete(SimpleChannelUpstreamHandler.java:233)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:73)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.writeComplete(SimpleChannelUpstreamHandler.java:233)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:73)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.writeComplete(SimpleChannelUpstreamHandler.java:233)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:73)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
        at org.jboss.netty.channel.Channels.fireWriteComplete(Channels.java:324)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(AbstractNioWorker.java:299)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:146)
        at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.handleAcceptedSocket(NioServerSocketPipelineSink.java:99)
        at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:36)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)
        at org.jboss.netty.channel.Channels.write(Channels.java:725)
        at org.jboss.netty.channel.Channels.write(Channels.java:686)
        at org.jboss.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:1110)
        at org.jboss.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1252)
        at org.jboss.netty.handler.ssl.SslHandler.decode(SslHandler.java:852)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:425)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)
{noformat}

Solutions seems to be an one-liner: you have to call {{super.channelOpen(ctx, evt);}} in {{Shuffle.channelOpen()}} in both cases. If we don't do this, then {{IdleStateHandler}} will not be initialized properly and will get a null attachment object when executing {{writeComplete()}}."
MAPREDUCE-7154,TokenCache.obtainTokensForNamenodes() to get DTs even when security is off,"Currently {{TokenCache.obtainTokensForNamenodes()}} returns immediately if security  disabled. This works when DTs are only built from Kerberos creds, but means that filesystems which serve up credentials which don't need kerberos (HADOOP-14556 for S3A, ABFS and WASB can also be enhanced to do this), don't get picked up

The token cache can just ask each FS for any tokens, relying on them to return null if they aren't generating/forwarding any"
MAPREDUCE-7152,LD_LIBRARY_PATH is always passed from MR AM to tasks,"{{LD_LIBRARY_PATH}} is set to {{$HADOOP_COMMON_HOME/lib/native}} by default in Hadoop (as part of {{mapreduce.admin.user.env}} and {{yarn.app.mapreduce.am.user.env}}), and passed as an environment variable from AM container to task containers in the container launch context.

In cases where {{HADOOP_COMMON_HOME}} is different in AM node and task node, tasks will fail to load native library. A reliable way to fix this is to add {{LD_LIBRARY_PATH}} in {{yarn.nodemanager.admin-env}} instead.

Another approach is to perform a lazy evaluation of {{LD_LIBRARY_PATH}} on the NM side."
MAPREDUCE-7151,RMContainerAllocator#handleJobPriorityChange expects application_priority always,"As per yarn_service.proto {{AllocateResponseProto}} *application_priority* is *optional* field.
But {{RMContainerAllocator#handleJobPriorityChange}} expects to have application priority always in response which is not mandatory.

{code}
  private void handleJobPriorityChange(AllocateResponse response) {
    Priority priorityFromResponse = Priority.newInstance(response
        .getApplicationPriority().getPriority());

    // Update the job priority to Job directly.
    getJob().setJobPriority(priorityFromResponse);
  }
{code}

{code}
message AllocateResponseProto {
..
  optional hadoop.common.TokenProto am_rm_token = 12;
  optional PriorityProto application_priority = 13;
  optional CollectorInfoProto collector_info = 14;
..
}
{code}"
MAPREDUCE-7150,Optimize collections used by MR JHS to reduce its memory,"We analyzed, using jxray (www.jxray.com) a heap dump of JHS running with big heap in a large clusters, handling large MapReduce jobs. The heap is large (over 32GB) and 21.4% of it is wasted due to various suboptimal Java collections, mostly maps and lists that are either empty or contain only one element. In such under-populated collections considerable amount of memory is still used by just the internal implementation objects. See the attached excerpt from the jxray report for the details. If certain collections are almost always empty, they should be initialized lazily. If others almost always have just 1 or 2 elements, they should be initialized with the appropriate initial capacity of 1 or 2 (the default capacity is 16 for HashMap and 10 for ArrayList).

Based on the attached report, we should do the following:
 # {{FileSystemCounterGroup.map}} - initialize lazily
 # {{CompletedTask.attempts}} - initialize with  capacity 2, given most tasks only have one or two attempts
 # {{JobHistoryParser$TaskInfo.attemptsMap}} - initialize with capacity
 # {{CompletedTaskAttempt.diagnostics}} - initialize with capacity 1 since it contains one diagnostic message most of the time
 # {{CompletedTask.reportDiagnostics}} - switch to ArrayList (no reason to use the more wasteful LinkedList here) and initialize with capacity 1."
MAPREDUCE-7149,javadocs for FileInputFormat and OutputFormat to mention DT collection,"the fact that DTs are collected for a job in {{FileInputFormat.listStatus(JobConf job)}}  and {{OutputFormat.checkOutputSpecs}} is not something mentioned in the javadocs, or that obvious when you look @ the API.

Add a sentence to the javadocs of the relevant methods to make clear ""the job you pass in is altered; anyone subclassing needs call their superclass or do something similar"
MAPREDUCE-7148,Fast fail jobs when exceeds dfs quota limitation,"We are running hive jobs with a DFS quota limitation per job(3TB). If a job hits DFS quota limitation, the task that hit it will fail and there will be a few task reties before the job actually fails. The retry is not very helpful because the job will always fail anyway. In some worse cases, we have a job which has a single reduce task writing more than 3TB to HDFS over 20 hours, the reduce task exceeds the quota limitation and retries 4 times until the job fails in the end thus consuming a lot of unnecessary resource. This ticket aims at providing the feature to let a job fail fast when it writes too much data to the DFS and exceeds the DFS quota limitation. The fast fail feature is introduced in MAPREDUCE-7022 and MAPREDUCE-6489 ."
MAPREDUCE-7142,"[JDK9] Add ""--add-modules java.activation"" to java option if the Java version is 9 or upper.","In Java 9, MapReduce job fails due to missing java.activation module, so we need to configure mapred-site.xml as follows to run MapReduce job:
{code}
<property name=""yarn.app.mapreduce.am.admin-command-opts"" value=""--add-modules java.activation""/>
<property name=""mapreduce.map.java.opts"" value=""--add-modules java.activation""/>
<property name=""mapreduce.reduce.java.opts"" value=""--add-modules java.activation""/>
{code}
I'm thinking it's better to add ""--add-modules java.activation"" automatically."
MAPREDUCE-7140,Refactoring TaskAttemptInfo to separate Map and Reduce tasks,Filed as a separate improvement per conversation in MAPREDUCE-7133.
MAPREDUCE-7138,ThrottledContainerAllocator in MRAppBenchmark should implement RMHeartbeatHandler,"MRAppBenchmark#benchmark2 test fails with the following exception:
{noformat}
java.lang.ClassCastException: org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark$ThrottledMRApp$ThrottledContainerAllocator cannot be cast to org.apache.hadoop.mapreduce.v2.app.rm.RMHeartbeatHandler

	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.getRMHeartbeatHandler(MRAppMaster.java:718)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.createCommitterEventHandler(MRApp.java:665)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceInit(MRAppMaster.java:391)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.serviceInit(MRApp.java:266)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:294)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:279)
	at org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark.run(MRAppBenchmark.java:69)
	at org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark.benchmark2(MRAppBenchmark.java:268)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
{noformat}
since ThrottledContainerAllocator doesn't implement RMHeartbeatHandler interface."
MAPREDUCE-7137,MRAppBenchmark.benchmark1() fails with NullPointerException,"MRAppBenchmark.benchmark1() fails with NullPointerException:
1. We do not set any queue for this test. As the result we got the following exception:
{noformat}
2018-09-10 17:04:23,486 ERROR [Thread-0] rm.RMCommunicator (RMCommunicator.java:register(177)) - Exception while registering
java.lang.NullPointerException
at org.apache.avro.util.Utf8$2.toUtf8(Utf8.java:123)
at org.apache.avro.util.Utf8.getBytesFor(Utf8.java:172)
at org.apache.avro.util.Utf8.<init>(Utf8.java:39)
at org.apache.hadoop.mapreduce.jobhistory.JobQueueChangeEvent.<init>(JobQueueChangeEvent.java:35)
at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.setQueueName(JobImpl.java:1167)
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.register(RMCommunicator.java:174)
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStart(RMCommunicator.java:122)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStart(RMContainerAllocator.java:280)
at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1293)
at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:301)
at org.apache.hadoop.mapreduce.v2.app.MRApp.submit(MRApp.java:285)
at org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark.run(MRAppBenchmark.java:72)
at org.apache.hadoop.mapreduce.v2.app.MRAppBenchmark.benchmark1(MRAppBenchmark.java:194)

{noformat}
2. We override createSchedulerProxy method and do not set application priority that was added later by MAPREDUCE-6515. We got the following error:
{noformat}
java.lang.NullPointerException
 at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.handleJobPriorityChange(RMContainerAllocator.java:1025)
 at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:880)
 at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:286)
 at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$AllocatorRunnable.run(RMCommunicator.java:280)
 at java.lang.Thread.run(Thread.java:748)
{noformat}
In both cases, the job never will be run and the test stuck and will not be finished."
MAPREDUCE-7136,TestMRAppMetrics should shutdown DefaultMetricsSystem after completion,"TestMRAppMetrics should invoke shutdown method in DefaultMetricsSystem after completion. Since it can lead to failing other tests. For example, TestRMContainerAllocator#testReportedAppProgress fails when run after TestMRAppMetrics#testNames with the following error:
{noformat}
org.apache.hadoop.metrics2.MetricsException: Metrics source MRAppMetrics already exists!
{noformat}
!image-2018-09-10-14-39-57-992.png!

We do not catch this on the trunk since the test TestRMContainerAllocator#testUnsupportedMapContainerRequirement run first and ""DefaultMetricsSystem.shutdown();"" invokes after completion. But since JUnit does not guarantee the order of the tests we should fix it. 
 Also, this is affected by previous versions which run testReportedAppProgress first (I faced it on 2.7.0 version). And reproduced on the trunk."
MAPREDUCE-7135,TestTaskAttemptContainerRequest should reset UserGroupInformation,"TestTaskAttemptContainerRequest should reset UserGroupInformation after end since this test cache UserGroupInformation and can be cause of other test fail. For example, all test in TestRMContainerAllocator will be failed if we run these tests after TestTaskAttemptContainerRequest (or we can change ""UserGroupInformation.setLoginUser(null)"" with UserGroupInformation.reset() in this class).

Also, I think the WARNING message in TestTaskAttemptContainerRequest can be removed since we can reset UserGroupInformation after each test."
MAPREDUCE-7133,History Server task attempts REST API returns invalid data,"When we send a request to History Server with headers : Accept: application/json [https://nodename:19888/ws/v1/history/mapreduce/jobs/job_1535363926925_0040/tasks/task_1535363926925_0040_r_000003/attempts|https://192.168.121.199:19890/ws/v1/history/mapreduce/jobs/job_1535363926925_0040/tasks/task_1535363926925_0040_r_000003/attempts] 
we get the following JSON:
{code:java}
{
""taskAttempts"": {
""taskAttempt"": [{
""type"": ""reduceTaskAttemptInfo"",
""startTime"": 1535372984638,
""finishTime"": 1535372986149,
""elapsedTime"": 1511,
""progress"": 100.0,
""id"": ""attempt_1535363926925_0040_r_000003_0"",
""rack"": ""/default-rack"",
""state"": ""SUCCEEDED"",
""status"": ""reduce > reduce"",
""nodeHttpAddress"": ""node2.cluster.com:8044"",
""diagnostics"": """",
""type"": ""REDUCE"",
""assignedContainerId"": ""container_e01_1535363926925_0040_01_000006"",
""shuffleFinishTime"": 1535372986056,
""mergeFinishTime"": 1535372986075,
""elapsedShuffleTime"": 1418,
""elapsedMergeTime"": 19,
""elapsedReduceTime"": 74
}]
}
}
{code}
As you can see ""type"" property has duplicates:
""type"": ""reduceTaskAttemptInfo""

""type"": ""REDUCE""

It's lead to an error during parsing response body as JSON is not valid.

When we use application/xml we get the following response:
{code:java}
<taskAttempts>
<taskAttempt xmlns:xsi=""[http://www.w3.org/2001/XMLSchema-instance]"" xsi:type=""reduceTaskAttemptInfo""><startTime>1535372984638</startTime><finishTime>1535372986149</finishTime><elapsedTime>1511</elapsedTime><progress>100.0</progress><id>attempt_1535363926925_0040_r_000003_0</id><rack>/default-rack</rack><state>SUCCEEDED</state><status>reduce > reduce</status><nodeHttpAddress>[node2.cluster.com:8044|http://node2.cluster.com:8044]</nodeHttpAddress><diagnostics/><type>REDUCE</type><assignedContainerId>container_e01_1535363926925_0040_01_000006</assignedContainerId><shuffleFinishTime>1535372986056</shuffleFinishTime><mergeFinishTime>1535372986075</mergeFinishTime><elapsedShuffleTime>1418</elapsedShuffleTime><elapsedMergeTime>19</elapsedMergeTime><elapsedReduceTime>74</elapsedReduceTime></taskAttempt>
</taskAttempts>
{code}
Take a look at the following string:
{code:java}
<taskAttempt xmlns:xsi=""[http://www.w3.org/2001/XMLSchema-instance]"" xsi:type=""reduceTaskAttemptInfo"">
{code}
We got ""xsi:type"" attribute which incorectly marshall later to duplicated field if we use JSON format.

It acceptable only to REDUCE task. For MAP task we get xml without ""xsi:type"" attribute.
{code:java}
<taskAttempts>
<taskAttempt>
<startTime>1535370756528</startTime>
<finishTime>1535370760318</finishTime>
<elapsedTime>3790</elapsedTime>
<progress>100.0</progress>
<id>attempt_1535363926925_0029_m_000001_0</id>
<rack>/default-rack</rack>
<state>SUCCEEDED</state>
<status>map > sort</status>
<nodeHttpAddress>[node2.cluster.com:8044|http://node2.cluster.com:8044]</nodeHttpAddress>
<diagnostics/>
<type>MAP</type>
<assignedContainerId>container_e01_1535363926925_0029_01_000003</assignedContainerId>
</taskAttempt>
</taskAttempts>

{code}
This happens since we have two different hierarchical classes for MAP ->TaskAttemptInfo and REDUCE- > ReduceTaskAttemptInfo tasks.

ReduceTaskAttemptInfo extends TaskAttemptInfo, later we marshal all tasks (map and reduce) by TaskAttemptsInfo.getTaskAttempt(). In this place, we do not have any information about ReduceTaskAttemptInfo type as we store all tasks in ArrayList<TaskAttemptInfo>. 

During marshaling we see that actual type of task ReduceTaskAttemptInfo instead of TaskAttemptsInfo and add meta information for this. That's why we get duplicated fields.

Unfortunately we do not catch it before in TestHsWebServicesAttempts since we use 

org.codehaus.jettison.json.JSONObject library which overrides duplicated fields. Even when we use Postman to do request we get valid JSON. Only when we change represent type to Raw we can notice this issue. Also, we able to reproduce this bug by using ""org.json:json"" lib:

Something like this:
{code:java}
BufferedReader inReader = new BufferedReader( new InputStreamReader(connection.getInputStream() ) );
 String inputLine;
 StringBuilder response = new StringBuilder();

while ( (inputLine = inReader.readLine()) != null ) {
 response.append(inputLine);
 }

inReader.close();

JSONObject o = new JSONObject(response.toString());
{code}"
MAPREDUCE-7132,"JobSplitWriter prints unnecessary warnings if EC(RS10,4) is used","Currently, {{JobSplitWriter}} compares the number of hosts for a certain block against a static value that comes from {{mapreduce.job.max.split.locations}}. The default value of this property is 10.

However, an EC schema like RS-10-4 requires at least 14 hosts. In this case, 14 block locations will be returned and {{JobSplitWriter}} prints a warning, which can confuse users.

A possible solution could check whether EC is enabled for a block and increase this value dynamically if needed. A simpler one is to simply increase the default value to a sensible number like 15.

 "
MAPREDUCE-7131,Job History Server has race condition where it moves files from intermediate to finished but thinks file is in intermediate,"This is the race condition that can occur:

# during the first *scanIntermediateDirectory()*, *HistoryFileInfo.moveToDone()* is scheduled for job j1
# during the second *scanIntermediateDirectory()*, j1 is found again and put in the *fileStatusList* to process
# *HistoryFileInfo.moveToDone()* is processed in another thread and history files are moved to the finished directory
# the *HistoryFileInfo* for j1 is removed from *jobListCache*
# the j1 in *fileStatusList* is processed and a new *HistoryFileInfo* for j1 is created (history, conf, and summary files will point to the intermediate user directory, and state will be IN_INTERMEDIATE) and added to the *jobListCache*
# *moveToDone()* is scheduled for this new j1
# *moveToDone()* fails during *moveToDoneNow()* for the history file because the source path in the intermediate directory does not exist

From this point on, while the new j1 *HistoryFileInfo* is in the *jobListCache*, the JobHistoryServer will think the history file is in the intermediate directory. If a user queries this job in the JobHistoryServer UI, they will get

{code}
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Could not load history file <scheme>://<host>:<port>/mr-history/intermediate/<user>/job_1529348381246_27275711-1535123223269-<user>-<jobname>-1535127026668-1-0-SUCCEEDED-<queue>-1535126980787.jhist
{code}

Noticed this issue while running 2.7.4, but the race condition seems to still exist in trunk."
MAPREDUCE-7130,Rumen crashes trying to handle MRAppMaster recovery events,"In the event of an MRAppMaster recovery, the Job History file gets an event of the following form:

{code:json}
{""type"":""JOB_KILLED"",""event"":\{""org.apache.hadoop.mapreduce.jobhistory.JobUnsuccessfulCompletion"":{""jobid"":""job_1532048817013_xxxx"",""finishTime"":1534521962641,""finishedMaps"":0,""finishedReduces"":0,""jobStatus"":""SUCCEEDED"",""diagnostics"":{""string"":""Job commit succeeded in a prior MRAppMaster attempt before it crashed. Recovering.""},""failedMaps"":0,""failedReduces"":0,""killedMaps"":0,""killedReduces"":0}}}
{code}

The issue seems to be around the SUCCEEDED job status for a JobUnsuccessfulCompletion:
https://github.com/apache/hadoop/blob/e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/JobBuilder.java#L609

Which fails to find the enum here:
https://github.com/apache/hadoop/blob/e0f6ffdbad6f43fd43ec57fb68ebf5275b8b9ba0/hadoop-tools/hadoop-rumen/src/main/java/org/apache/hadoop/tools/rumen/Pre21JobHistoryConstants.java#L50

I'm not sure if this is an error with the Rumen parser or if the job history file is getting into an invalid state.

"
MAPREDUCE-7125,JobResourceUploader creates LocalFileSystem when it's not necessary ,"When the property {{mapreduce.job.log4j-properties-file}} is set a local filesystem is created even if it's never used:
https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobResourceUploader.java#L858-L866

The localFS should only be created when required."
MAPREDUCE-7123,AM Failed with Communication error to RM,"During the restart of nodemanagers in 300 node cluster some jobs failed with the following exceptions.

But the nodes where the AM launched is not the part of cluster.

FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread java.lang.NullPointerException at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$UpdatedNodesTransition.transition(JobImpl.java:2146) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$UpdatedNodesTransition.transition(JobImpl.java:2139) at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362) at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302) at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46) at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:998) at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:138) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1346) at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1342) at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183) at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109) at java.lang.Thread.run(Thread.java:745) 2018-07-14 12:34:53,425 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: ERROR IN CONTACTING RM. java.lang.NullPointerException at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.handleUpdatedNodes(RMContainerAllocator.java:875) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:776) at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:256) at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$AllocatorRunnable.run(RMCommunicator.java:281) at java.lang.Thread.run(Thread.java:745) 2018-07-14 12:34:53,427 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye.."
MAPREDUCE-7118,Distributed cache conflicts breaks backwards compatability,"MAPREDUCE-4503 made distributed cache conflicts break job submission, but this was quickly downgraded to a warning in MAPREDUCE-4549.  Unfortunately the latter did not go into trunk, so the fix is only in 0.23 and 2.x.  When Oozie, Pig, and other downstream projects that can occasionally generate distributed cache conflicts move to Hadoop 3.x the workflows that used to work on 0.23 and 2.x no longer function."
MAPREDUCE-7116,UT failure in TestMRTimelineEventHandling#testMRNewTimelineServiceEventHandling -Hadoop-3.1,unit test failure in TestMRTimelineEventHandling#testMRNewTimelineServiceEventHandling due to timeline server issue......due to Java.io.IOException : Job din't finish in 30 seconds at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:659)
MAPREDUCE-7114,Make FrameworkUploader symlink ignore improvement,"/dir1/dir2/./hadoop-common.jar style symlinks are not ignored, even if they link to a file within the same directory."
MAPREDUCE-7113,"Typos in test names in TestTaskAttempt: ""testAppDiognostic""","These two methods need to be renamed: 
 * testAppDiognosticEventOnUnassignedTask
 * testAppDiognosticEventOnNewTask"
MAPREDUCE-7112,When load job history webpage we do not need make cache firstly,"It's very slow to load job history page because of making cache firstly. Obviously, we should skip this."
MAPREDUCE-7111,TestNameNodeMetrics fails on Windows,"_TestNameNodeMetrics_ fails on Windows

 

Problem:

This is because in _testVolumeFailures_, it tries to call _DataNodeTestUtils.injectDataDirFailure_ on a volume folder. What _injectDataDirFailure_ does is actually modifying the folder name from _volume_name_ to _volume_name_._origin_ and create a new file named as _volume_name_. Inside the folder, it has two things: 1. a directory named as ""_current_"", 2. a file named as ""_in_use.lock_"". Windows behaves different from Linux when renaming the parent folder of a locked file. Windows prevent you from renaming while Linux allows.

Fix:

So in order to inject data failure on to the volume. Instead of renaming the volume folder itself. Rename the folder inside it which doesn't hold a lock. Since the folder inside the volume is ""_current_"". Then we only need to inject data failure to _volume_name/current_."
MAPREDUCE-7108,TestFileOutputCommitter fails on Windows,"TestFileOutputCommitter.java fails on Windows.

Reason:

This is because in testMapFileOutputCommitterInternal, after executing MapFileOutputFormat.getReaders(outDir, conf), the readers are not properly closed. So other apis that attempt to delete the existing file fails due to the file handler already being used.

 

Solution:

Close all readers after call MapFileOutputFormat.getReaders(outDir, conf);"
MAPREDUCE-7105,Fix TestNativeCollectorOnlyHandler.testOnCall on Windows because of the path format,"Fix TestNativeCollectorOnlyHandler.testOnCall on Windows because of the path format.

Test failed [here|https://builds.apache.org/job/hadoop-trunk-win/487/testReport/org.apache.hadoop.mapred.nativetask.handlers/TestNativeCollectorOnlyHandler/testOnCall/]."
MAPREDUCE-7104,TestHistoryViewerPrinter fails on windows.,All tests in [TestHistoryViewerPrinter|https://builds.apache.org/job/hadoop-trunk-win/485/testReport/org.apache.hadoop.mapreduce.jobhistory/TestHistoryViewerPrinter/testHumanPrinter/] are failing in Windows due to difference in line separator on Windows.
MAPREDUCE-7103,Fix TestHistoryViewerPrinter on windows due to a mismatch line separator ,Fix TestHistoryViewerPrinter on windows due to a mismatch line separator.
MAPREDUCE-7102,Fix TestJavaSerialization for Windows due a mismatch line separator ,"TestJavaSerialization#testWriteToSequencefile and testMapReduceJob fails on Windows.

testWriteToSequencefile fails due to a missing InputStream.close() [link|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/org.apache.hadoop.mapred/TestJavaSerialization/testWriteToSequencefile/] of the test result.

testMapReduceJob fails due to a mismatch on line separator. System.getProperty(""line.separator"") in Windows is /r/n while in Linux is only /n. "
MAPREDUCE-7101,Add config parameter to allow JHS to alway scan user dir irrespective of modTime,"Currently, the JHS scan directory if the modification of *directory* changed: 

{code} 
    public synchronized void scanIfNeeded(FileStatus fs) {
      long newModTime = fs.getModificationTime();
      if (modTime != newModTime) {
        <... omitted some logics ...>
        // reset scanTime before scanning happens
        scanTime = System.currentTimeMillis();
        Path p = fs.getPath();
        try {
          scanIntermediateDirectory(p);
{code}

This logic relies on an assumption that, the directory's modification time will be updated if a file got placed under the directory.

However, the semantic of directory's modification time is not consistent in different FS implementations. For example, MAPREDUCE-6680 fixed some issues of truncated modification time. And HADOOP-12837 mentioned on S3, the directory's modification time is always 0.

I think we need to revisit behavior of this logic to make it to more robustly work on different file systems."
MAPREDUCE-7098,Upgrade common-langs version to 3.7 in hadoop-mapreduce-project,"commons-lang 2.6 is widely used. Let's upgrade to 3.6.

This jira is separated from HADOOP-10783."
MAPREDUCE-7097,MapReduce JHS should honor yarn.webapp.filter-entity-list-by-user,"When this config is on, MR JHS should filter the app list based on authenticated user."
MAPREDUCE-7096,Distcp cannot copy files of the same name in different directories,"When I tested distcp, I found that I could not copy files with the same name in different directories，here is my test case：

source：
/user/hadoop/dir1/a.txt
/user/hadoop/dir2/a.txt

target
/tmp/dist-cp/


hadoop distcp -m 2 -overwrite /user/hadoop/dir* /tmp/dist-cp/

result： failed


source：
/user/hadoop/dir1/a.txt
/user/hadoop/dir2/b.txt

target：
/tmp/dist-cp/


hadoop distcp -m 2 -overwrite /user/hadoop/dir* /tmp/dist-cp/

result： success"
MAPREDUCE-7095,Race conditions in closing FadvisedChunkedFile ,"When a file is closed multiple times by multiple threads, all but the first close will generate a WARNING message.
{code:java}
11:04:33.605 AM	WARN	FadvisedChunkedFile	
Failed to manage OS cache for /var/run/100/yarn/nm/usercache/systest/appcache/application_1521665017379_0062/output/attempt_1521665017379_0062_m_012797_0/file.out
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.mapred.FadvisedChunkedFile.close(FadvisedChunkedFile.java:76)
	at org.jboss.netty.handler.stream.ChunkedWriteHandler.closeInput(ChunkedWriteHandler.java:303)
	at org.jboss.netty.handler.stream.ChunkedWriteHandler.discard(ChunkedWriteHandler.java:163)
	at org.jboss.netty.handler.stream.ChunkedWriteHandler.flush(ChunkedWriteHandler.java:192)
	at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:137)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.channelClosed(SimpleChannelUpstreamHandler.java:225)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.cleanup(ReplayingDecoder.java:570)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.channelClosed(FrameDecoder.java:371)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.cleanup(FrameDecoder.java:493)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.channelClosed(FrameDecoder.java:371)
	at org.jboss.netty.handler.ssl.SslHandler.channelClosed(SslHandler.java:1667)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireChannelClosed(Channels.java:468)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.close(AbstractNioWorker.java:375)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:93)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748){code}"
MAPREDUCE-7094,"LocalDistributedCacheManager leaves classloaders open, which leaks FDs","When a user starts a local mapred task from Hive's beeline, it will leave open file descriptors on the HS2 process (which runs the mapred task).

I debugged this and saw that it is caused by LocalDistributedCacheManager class, which creates a new URLClassLoader, with a classpath for the two jars seen below. Somewhere down the line Loaders will be created in this URLClassLoader for these files effectively creating the FD's on the OS level.

This is never cleaned up after execution, although LocalDistributedCacheManager removes the files, it will not close the ClassLoader, so FDs are left open although they point to deleted files at that time:
{code:java}
[root@host-1 ~]# lsof -p 14439 | grep hadoop-hive
java    14439 hive  DEL       REG                8,1             3348748 /tmp/hadoop-hive/mapred/local/1525789796610/hive-exec-core.jar
java    14439 hive  DEL       REG                8,1             3348750 /tmp/hadoop-hive/mapred/local/1525789796609/hive-exec-1.1.0-cdh5.13.4-SNAPSHOT-core.jar
java    14439 hive  649r      REG                8,1   8112438   3348750 /tmp/hadoop-hive/mapred/local/1525789796609/hive-exec-1.1.0-cdh5.13.4-SNAPSHOT-core.jar (deleted)
java    14439 hive  650r      REG                8,1   8112438   3348748 /tmp/hadoop-hive/mapred/local/1525789796610/hive-exec-core.jar (deleted)

{code}"
MAPREDUCE-7093,Use assertEquals instead of assertTrue(a == b) in TestMapReduceJobControlWithMocks,"For example:{code}
    assertTrue(job1.getJobState() == ControlledJob.State.SUCCESS);
{code}
should be
{code}
    assertEquals(ControlledJob.State.SUCCESS, job1.getJobState());
{code}"
MAPREDUCE-7092,MR examples to work better against cloud stores,"Some of the MR examples either don't work or underperform on cloud infrastructure, all straightforward to fix. Of course, that means the cloud connectors all get an opportunity to add more integration tests..."
MAPREDUCE-7091,Terasort on S3A to switch to new committers,"Terasort is very slow on S3, because it still uses the classic rename-to-commit algorithm on the sort, even while teragen and the reporting can use the new committer

Reason: {{org.apache.hadoop.examples.terasort.TeraOutputFormat}} has overriden {{getOutputCommitter}} even though it doesn't need to."
MAPREDUCE-7090,BigMapOutput example doesn't work with paths off cluster fs,"You can't pass an object store path to bigmapoutput, because it uses the default fs, not the path FS, to work with the directories."
MAPREDUCE-7086,Add config to allow FileInputFormat to ignore directories when recursive=false,"We are trying to create a split in Hive that will only read files in a directory and not subdirectories.
That fails with the below error.
Given how this error comes about (two pieces of code interact, one explicitly adding directories to results without failing, and one failing on any directories in results), this seems like a bug.

{noformat}
Caused by: java.io.IOException: Not a file: file:/,...warehouse/simple_to_mm_text/delta_0000001_0000001_0000
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:329) ~[hadoop-mapreduce-client-core-3.1.0.jar:?]
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.addSplitsForGroup(HiveInputFormat.java:553) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:754) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
	at org.apache.hadoop.hive.ql.exec.tez.HiveSplitGenerator.initialize(HiveSplitGenerator.java:203) ~[hive-exec-3.1.0-SNAPSHOT.jar:3.1.0-SNAPSHOT]
{noformat}

This code, when recursion is disabled, adds directories to results 
{noformat} 
if (recursive && stat.isDirectory()) {
              result.dirsNeedingRecursiveCalls.add(stat);
            } else {
              result.locatedFileStatuses.add(stat);
            }
{noformat} 
However the getSplits code after that computes the size like this
{noformat}
long totalSize = 0;                           // compute total size
    for (FileStatus file: files) {                // check we have valid files
      if (file.isDirectory()) {
        throw new IOException(""Not a file: ""+ file.getPath());
      }
      totalSize +=
{noformat}
which would always fail combined with the above code."
MAPREDUCE-7081,Default speculator won't speculate the last several submitted reduced task if the total task num is large,"DefaultSpeculator speculates a task one time.  By default, the number of speculators is max(max(10, 0.01 * tasks.size), 0.1 * running tasks).

I  set mapreduce.job.reduce.slowstart.completedmaps = 1 to start reduce after all the map tasks are finished. The cluster has 1000 vcores, and the Job has 5000 reduce jobs. At first, 1000 reduces tasks can run simultaneously, number of speculators can speculator at most is 0.1 * 1000 = 100 tasks. Reduce tasks with less data can over shortly, and speculator will speculator a task per second by default. The task be speculated execution may be because the more data to be processed. It will speculator  100 tasks within 100 seconds. When 4900 reduces is over, If a reduce is executed with a lot of  data be processed and is put on a slow machine. The speculate opportunity is running out, it will not be speculated. It can increase the execution time of job significantly.

In short, it may waste the speculate opportunity at first only because the execution time of  reduce with less data to be processed as average time. At  end of job, there is no speculate opportunity available, especially last several running tasks, judged the number of the running tasks .  

In my opinion, the number of running tasks should not determine the number of speculate opportunity .The number of tasks be speculated can be judged by square of finished task percent. Take an example, if ninety percent of  the task is finished, only 0.9*0.9 = 0.81 speculate opportunity can be used. It will leave enough opportunity for latter tasks."
MAPREDUCE-7080,Default speculator won't sepculate the last several submitted reduced task if the total task num is large,"DefaultSpeculator speculates a task one time. 

By default, the number of speculators is max(max(10, 0.01 * tasks.size), 0.1 * running tasks)

I  set mapreduce.job.reduce.slowstart.completedmaps = 1 to start reduce after all the map tasks are finished.

The cluster has 1000 vcores, and the Job has 5000 reduce jobs.

At first, 1000 reduces tasks can run simultaneously, number of speculators can speculator at most is 0.1 * 1000 = 100 tasks. Reduce tasks with less data can over shortly, and speculator will speculator a task per second by default. The task be speculated execution may be because the more data to be processed. It will speculator  100 tasks within 100 seconds.

When 4900 reduces is over, If a reduce is executed with a lot of  data be processed and is put on a slow machine. The speculate opportunity is running out, it will not be speculated. It can increase the execution time of job significantly.

In short, it may waste the speculate opportunity at first only because the execution time of  reduce with less data to be processed as average time. At  end of job, there is no speculate opportunity available, especially last several running tasks, judged the number of the running tasks .

 

In my opinion, the number of tasks be speculated can be judged by square of finished task percent. Take an example, if ninety percent of  the task is finished, only 0.9*0.9 = 0.81 speculate opportunity can be used. It will leave enough opportunity for latter tasks.

 "
MAPREDUCE-7079,JobHistory#ServiceStop implementation is incorrect,"{{JobHistory.serviceStop}} skips waiting for the thread pool to terminate. The problem is due to incorrect while condition that will evaluate to false on the iteration of the loop.

{code:java}
     scheduledExecutor.shutdown();
      boolean interrupted = false;
      long currentTime = System.currentTimeMillis();
      while (!scheduledExecutor.isShutdown()
          && System.currentTimeMillis() > currentTime + 1000l && !interrupted) {
        try {
          Thread.sleep(20);
        } catch (InterruptedException e) {
          interrupted = true;
        }
      }
{code}

The expression ""{{System.currentTimeMillis() > currentTime + 1000L}}"" is false because currentTime was just initialized with {{System.currentTimeMillis()}}. As a result the the thread won't wait until the executor is terminated. Instead, it will force a shutdown immediately.

*TestMRIntermediateDataEncryption is failing in precommit builds*

TestMRIntermediateDataEncryption is either timing out or tearing down the JVM which causes the unit tests in jobclient to not pass cleanly during precommit builds. From sample precommit console output, note the lack of a test results line when the test is run:
{noformat}
[INFO] Running org.apache.hadoop.mapred.TestSequenceFileInputFormat
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 4.976 s - in org.apache.hadoop.mapred.TestSequenceFileInputFormat
[INFO] Running org.apache.hadoop.mapred.TestMRIntermediateDataEncryption
[INFO] Running org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath
[INFO] Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 16.659 s - in org.apache.hadoop.mapred.TestSpecialCharactersInOutputPath
[...]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 02:14 h
[INFO] Finished at: 2018-04-12T04:27:06+00:00
[INFO] Final Memory: 24M/594M
[INFO] ------------------------------------------------------------------------
[WARNING] The requested profile ""parallel-tests"" could not be activated because it does not exist.
[WARNING] The requested profile ""native"" could not be activated because it does not exist.
[WARNING] The requested profile ""yarn-ui"" could not be activated because it does not exist.
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.21.0:test (default-test) on project hadoop-mapreduce-client-jobclient: There was a timeout or other error in the fork -> [Help 1]
{noformat}
"
MAPREDUCE-7077,Pipe mapreduce job fails with Permission denied for jobTokenPassword,"Steps:

Launch wordcount example with pipe
{code}
/usr/hdp/current/hadoop-client/bin/hadoop pipes ""-Dhadoop.pipes.java.recordreader=true"" ""-Dhadoop.pipes.java.recordwriter=true"" -input pipeInput -output pipeOutput -program bin/wordcount{code}

The application fails with below stacktrace
{code:title=AM}
attempt_1517534613368_0041_r_000000_2 is : 0.0

2018-02-02 02:40:51,071 ERROR [IPC Server handler 16 on 43391] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1517534613368_0041_r_000000_2 - exited : java.io.FileNotFoundException: /grid/0/hadoop/yarn/local/usercache/hrt_qa/appcache/application_1517534613368_0041/jobTokenPassword (Permission denied)

 at java.io.FileOutputStream.open0(Native Method)

 at java.io.FileOutputStream.open(FileOutputStream.java:270)

 at java.io.FileOutputStream.<init>(FileOutputStream.java:213)

 at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:236)

 at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:219)

 at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:318)

 at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:307)

 at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:338)

 at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)

 at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)

 at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)

 at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1169)

 at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1149)

 at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1038)

 at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1026)

 at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:703)

 at org.apache.hadoop.mapred.pipes.Application.writePasswordToLocalFile(Application.java:173)

 at org.apache.hadoop.mapred.pipes.Application.<init>(Application.java:109)

 at org.apache.hadoop.mapred.pipes.PipesReducer.startApplication(PipesReducer.java:87)

 at org.apache.hadoop.mapred.pipes.PipesReducer.reduce(PipesReducer.java:65)

 at org.apache.hadoop.mapred.pipes.PipesReducer.reduce(PipesReducer.java:38)

 at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:445)

 at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:393)

 at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)

 at java.security.AccessController.doPrivileged(Native Method)

 at javax.security.auth.Subject.doAs(Subject.java:422)

 at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)

 at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
{code}
"
MAPREDUCE-7076,TestNNBench#testNNBenchCreateReadAndDelete failing in our internal build,"TestNNBench#testNNBenchCreateReadAndDelete failed couple of times in our internal jenkins build.
{noformat}
java.lang.AssertionError: create_write should create the file
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.hdfs.TestNNBench.testNNBenchCreateReadAndDelete(TestNNBench.java:55)
{noformat}
Below is my analysis for why it didn't create the file.
{code:java|title=NNBench.java|borderStyle=solid}
// Some comments here
  public void map(Text key, 
            LongWritable value,
            OutputCollector<Text, Text> output,
            Reporter reporter) throws IOException {
      if (barrier()) {
        String fileName = ""file_"" + value;
        if (op.equals(OP_CREATE_WRITE)) {
          startTimeTPmS = System.currentTimeMillis();
          doCreateWriteOp(fileName, reporter);
        } ...
      } else {
        output.collect(new Text(""l:latemaps""), new Text(""1""));
      }
  // Below are the relevant parts of barrier() method
  private boolean barrier() {
    ..
    // If the sleep time is greater than 0, then sleep and return
    ...
    LOG.info(""Waiting in barrier for: "" + sleepTime + "" ms"");
    return retVal;
  }
  // Below are the relevant parts of the doCreateWriteOp
  private void doCreateWriteOp(String name,
                                 Reporter reporter) {
    FSDataOutputStream out;
    byte[] buffer = new byte[bytesToWrite];  
    for (long l = 0l; l < numberOfFiles; l++) {
      Path filePath = new Path(new Path(baseDir, dataDirName), 
              name + ""_"" + l);
    }
  ....
  }
{code}
This file {{BASE_DIR/data/file_0_0}} is getting created only if the map task starts before the time mentioned by {{startTime}}.
 Refer the chunk which I pasted above.
 {{map(..)}} --> {{barrier()}} and *only if* {{barrier()}} evaluates to true it will call {{doCreateWriteOp}} which will eventually create the file.
 In test case, the delay value is 3 seconds as per {{""-startTime"", """" + (Time.now() / 1000 + 3)}}
 In this failing test case, I can see the task starting minimum 6 seconds after the test case started.
{noformat}
2017-01-27 03:11:15,387 INFO  [Thread-4] mapreduce.JobSubmitter (JobSubmitter.java:printTokens(289)) - Submitting tokens for job: job_local1711545156_0001
2017-01-27 03:11:23,405 INFO  [Thread-4] mapreduce.Job (Job.java:submit(1345)) - The url to track the job: http://localhost:8080/
{noformat}
Also when I run this test on my laptop, I see the following line being printed.
{noformat}
2017-01-27 17:09:27,982 INFO  [LocalJobRunner Map Task Executor #0] hdfs.NNBench (NNBench.java:barrier(676)) - Waiting in barrier for: 1018 ms
{noformat}
This line will be printed only in {{barrier()}} method and I don't see this line in the logs of failed test.

 
 In our environment, the jenkins server was very slow and it took more than 6 seconds to launch a map task.
 The correct fix in my opinion would be to return true in case there is no sleep in {{barrier() method}}. Only in exception, it should return false."
MAPREDUCE-7073,Optimize TokenCache#obtainTokensForNamenodesInternal,"{{FileInputFormat#listStatus}} is too slow file system cache is disabled. 

{{TokenCache#obtainTokensForNamenodesInternal}} for every filesystem instance {{Master.getMasterPrincipal(conf)}} is caled which reloads YarnConfiguration .
For fileInput with 1k file will reload YarnConfiguration 1k times.

{{Master.getMasterPrincipal(conf)}} can be passed for  {{obtainTokensForNamenodesInternal}} per filesystem call.
"
MAPREDUCE-7072,mapred job -history prints duplicate counter in human output," 'mapred job -history' command prints duplicate entries for counters only for the human output format. It does not do this for the JSON format.

mapred job -history /user/history/somefile.jhist -format human
{code}
....
|Job Counters |Total megabyte-seconds taken by all map tasks|0 |0 |268,288,000
...
|Job Counters |Total megabyte-seconds taken by all map tasks|0 |0 |268,288,000
....
{code}"
MAPREDUCE-7069,Add ability to specify user environment variables individually,"As reported in YARN-6830, it is currently not possible to specify an environment variable that contains commas via {{mapreduce.map.env}}, mapreduce.reduce.env, or {{mapreduce.admin.user.env}}.

To address this, [~aw] proposed in [YARN-6830] that we add the ability to specify environment variables individually:
{quote}e.g, mapreduce.map.env.[foo]=bar gets turned into foo=bar
{quote}"
MAPREDUCE-7066,TestQueue fails on Java9,"{noformat}
[INFO] Running org.apache.hadoop.mapred.TestQueue
[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.353 s <<< FAILURE! - in org.apache.hadoop.mapred.TestQueue
[ERROR] testQueue(org.apache.hadoop.mapred.TestQueue)  Time elapsed: 1.186 s  <<< FAILURE!
org.junit.ComparisonFailure: expected:<...roperties"":[{""key"":""[capacity"",""value"":""20""},{""key"":""user-limit"",""value"":""3]0""}],""children"":[]}]...> but was:<...roperties"":[{""key"":""[user-limit"",""value"":""30""},{""key"":""capacity"",""value"":""2]0""}],""children"":[]}]...>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapred.TestQueue.testQueue(TestQueue.java:156)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:564)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

{noformat}"
MAPREDUCE-7064,Flaky test TestTaskAttempt#testReducerCustomResourceTypes,"The test {{TestTaskAttempt#testReducerCustomResourceType}} can occasionally fail with the following error:

{noformat}
org.apache.hadoop.yarn.exceptions.ResourceNotFoundException: Unknown resource 'a-custom-resource'. Known resources are [name: memory-mb, units: Mi, type: COUNTABLE, value: 0, minimum allocation: 0, maximum allocation: 9223372036854775807, name: vcores, units: , type: COUNTABLE, value: 0, minimum allocation: 0, maximum allocation: 9223372036854775807]
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.createReduceTaskAttemptImplForTest(TestTaskAttempt.java:434)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.testReducerCustomResourceTypes(TestTaskAttempt.java:1535)
{noformat}

The root cause seems to be an interference from previous tests that start instance(s) of {{FailingAttemptsMRApp}} or {{FailingAttemptsDuringAssignedMRApp}}. When I disabled these tests, {{testReducerCustomResourceTypes}} always passed."
MAPREDUCE-7063,Fix log level inconsistency in CombineFileInputFormat.java,"[https://github.com/apache/hadoop/blob/178751ed8c9d47038acf8616c226f1f52e884feb/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/input/CombineFileInputFormat.java#L428-L429]

 
{code:java}
LOG.info(""DEBUG: Terminated node allocation with : CompletedNodes: ""
+ completedNodes.size() + "", size left: "" + totalLength);
{code}

# Use SLF4J Parameterized logging
# The message literal string contains the word ""DEBUG"" but this is _INFO_ level logging.  Remove the word ""DEBUG"" and set the logging level to _DEBUG_"
MAPREDUCE-7062,Update mapreduce.job.tags description for making use for ATSv2 purpose.,"When applications are submitted to YARN, tags are generated in the format 
 TIMELINE_FLOW_NAME_TAG:\{flow_name},TIMELINE_FLOW_VERSION_TAG:\{flow_version},TIMELINE_FLOW_RUN_ID_TAG:\{flow_run_id}

However, MR applications don't follow this format and the tags submitted via the property mapreduce.job.tags are of the format,
{flow_name} ,\{flow_version},\{flow_run_id}

Due to this, YARN falls back to default values for flow name, flow version and flow run id which in turn are used in ATSv2.

There are 2 approaches that could be taken to make MR tags compatible with ATSv2,

Fix in the MR code
 -------------------------
 Prefix any tags specified with the ones needed by the YARN Timeline Service v2. But MR is legacy code and hence these changes could affect how users are using these tags.

Add a note in mapred-default.xml
 --------------------------------------------
 Add notes in the property name, mapreduce.job.tags mentioning that for purposes of ATSv2, prefixes need to be added to the tag names."
MAPREDUCE-7061,SingleCluster setup document needs to be updated,"The following document needs an update:
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

We need to set mapreduce.application.classpath, without that we cannot launch MR jobs using yarn.

  CLASSPATH for MR applications. A comma-separated list of CLASSPATH entries. If mapreduce.application.framework is set then this must specify the appropriate classpath for that archive, and the name of the archive must be present in the classpath. If mapreduce.app-submission.cross-platform is false, platform-specific environment vairable expansion syntax would be used to construct the default CLASSPATH entries.

 

So, add the default value for the tarball download setup."
MAPREDUCE-7060,Cherry Pick PathOutputCommitter class/factory to branch-3.0,"It's easier for downstream apps like Spark to pick up the new PathOutputCommitter superclass if it is there on 2.10+, even if the S3A committer isn't there. 

Adding the interface & binding stuff of MAPREDUCE-6956 allows for third party committers to be deployed. 

I'm not proposing a backport of the HADOOP-13786 committer: that's Java 8, S3Guard, etc. Too traumatic. All I want here is to allow downstream code to be able to pick up the new interface and so be able to support it and other store committers when available"
MAPREDUCE-7059,Downward Compatibility issue: MR job fails because of unknown setErasureCodingPolicy method from 3.x client to HDFS 2.x cluster,"Running teragen failed in the version of hadoop-3.1, and hdfs server is 2.8.
{code:java}
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0-SNAPSHOT.jar  teragen  100000 /teragen
{code}

The reason of failing is 2.8 HDFS does not have setErasureCodingPolicy.

one  solution is parsing RemoteException in JobResourceUploader#disableErasure like this:
{code:java}
private void disableErasureCodingForPath(FileSystem fs, Path path)
      throws IOException {
    try {
      if (jtFs instanceof DistributedFileSystem) {
        LOG.info(""Disabling Erasure Coding for path: "" + path);
        DistributedFileSystem dfs = (DistributedFileSystem) jtFs;
        dfs.setErasureCodingPolicy(path,
            SystemErasureCodingPolicies.getReplicationPolicy().getName());
      }
    } catch (RemoteException e) {
      if (!e.getClassName().equals(RpcNoSuchMethodException.class.getName())) {
        throw e;
      } else {
        LOG.warn(
            ""hdfs server does not have method disableErasureCodingForPath,"" 
                + "" and skip disableErasureCodingForPath"", e);
      }
    }
  }
{code}

Does anyone have better solution?

The detailed exception trace is:
{code:java}
2018-02-26 11:22:53,178 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/hadoop/.staging/job_1518615699369_0006
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.RpcNoSuchMethodException): Unknown method setErasureCodingPolicy called on org.apache.hadoop.hdfs.protocol.ClientProtocol protocol.
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:436)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:846)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:789)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1804)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2457)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1437)
	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy11.setErasureCodingPolicy(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setErasureCodingPolicy(ClientNamenodeProtocolTranslatorPB.java:1583)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy12.setErasureCodingPolicy(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.setErasureCodingPolicy(DFSClient.java:2678)
	at org.apache.hadoop.hdfs.DistributedFileSystem$63.doCall(DistributedFileSystem.java:2665)
	at org.apache.hadoop.hdfs.DistributedFileSystem$63.doCall(DistributedFileSystem.java:2662)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.setErasureCodingPolicy(DistributedFileSystem.java:2680)
	at org.apache.hadoop.mapreduce.JobResourceUploader.disableErasureCodingForPath(JobResourceUploader.java:882)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:174)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:131)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.hadoop.examples.terasort.TeraGen.run(TeraGen.java:304)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.terasort.TeraGen.main(TeraGen.java:308)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:304)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:218)
{code}
"
MAPREDUCE-7058,Race Condition When Stopping DelegationTokenRenewer,"[https://github.com/apache/hadoop/blob/69fa81679f59378fd19a2c65db8019393d7c05a2/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/security/DelegationTokenRenewer.java]
{code:java}
  private ThreadPoolExecutor renewerService;

  private void processDelegationTokenRenewerEvent(
      DelegationTokenRenewerEvent evt) {
    serviceStateLock.readLock().lock();
    try {
      if (isServiceStarted) {
        renewerService.execute(new DelegationTokenRenewerRunnable(evt));
      } else {
        pendingEventQueue.add(evt);
      }
    } finally {
      serviceStateLock.readLock().unlock();
    }
  }

  @Override
  protected void serviceStop() {
    if (renewalTimer != null) {
      renewalTimer.cancel();
    }
    appTokens.clear();
    allTokens.clear();
    this.renewerService.shutdown();
{code}
{code:java}
2018-02-21 11:18:16,253  FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread
java.util.concurrent.RejectedExecutionException: Task org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer$DelegationTokenRenewerRunnable@39bddaf2 rejected from java.util.concurrent.ThreadPoolExecutor@5f71637b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 15487]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2048)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:821)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1372)
	at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.processDelegationTokenRenewerEvent(DelegationTokenRenewer.java:196)
	at org.apache.hadoop.yarn.server.resourcemanager.security.DelegationTokenRenewer.applicationFinished(DelegationTokenRenewer.java:734)
	at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.finishApplication(RMAppManager.java:199)
	at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:424)
	at org.apache.hadoop.yarn.server.resourcemanager.RMAppManager.handle(RMAppManager.java:65)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:177)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)
	at java.lang.Thread.run(Thread.java:745)
{code}
What I think is going on here is that the {{serviceStop}} method is not setting the {{isServiceStarted}} flag to 'false'.

Please update so that the {{serviceStop}} method grabs the {{serviceStateLock}} and sets {{isServiceStarted}} to _false_, before shutting down the {{renewerService}} thread pool, to avoid this condition."
MAPREDUCE-7055,MR jobs are failing with Could not find or load main class for MRAppMaster,"It is observed that MR jobs are failing with *Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster"" even though HADOOP_MAPRED_HOME is set in mapred-site.xml

Tried building tar.gz in branch-3.0 and seems works fine with same configurations. But in branch-3.1 and trunk, it is failing. I got launch_container.sh for both  and compared classpath  exported before launching AM. Both classpath entries are same, but AM launching is failing with above mentioned error. 

Its better to confirm as 3.1 release is going to happen soon."
MAPREDUCE-7053,Timed out tasks can fail to produce thread dump,"TestMRJobs#testThreadDumpOnTaskTimeout has been failing sporadically recently.  When the AM times out a task it immediately removes it from the list of known tasks and then connects to the NM to request a thread dump followed by a kill.  If the task heartbeats in after the task has been removed from the list of known tasks but before the thread dump signal arrives then the task can exit with a ""org.apache.hadoop.mapred.Task: Parent died."" message and no thread dump."
MAPREDUCE-7052,TestFixedLengthInputFormat#testFormatCompressedIn is flaky,"Sometimes the test case TestFixedLengthInputFormat#testFormatCompressedIn can fail with the following error:

{noformat}
java.lang.OutOfMemoryError: Requested array size exceeds VM limit
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(TestFixedLengthInputFormat.java:322)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.testFormatCompressedIn(TestFixedLengthInputFormat.java:90)
{noformat}

*Root cause:* under special circumstances, the following line can return a huge number:

{noformat}
          // Test a split size that is less than record len
          numSplits = (int)(fileSize/Math.floor(recordLength/2));
{noformat}

For example, let {{seed}} be 2026428718. This causes {{recordLength}} to be 1 at iteration 19. {{Math.floor()}} returns negative Infinity, which becomes positve infinity after the divison. Casting it to {{int}} yields {{Integer.MAX_VALUE}}. Eventually we get an OOME because the test wants to create a huge {{InputSplit}} array."
MAPREDUCE-7051,Fix typo in MultipleOutputFormat,"In org.apache.hadoop.mapred.lib.MultipleOutputFormat, there is a typo for the java doc of getInputFileBasedOutputFileName method. 

""the outfile name based on a given anme and the input file name"" should be ""the outfile name based on a given name and the input file name"""
MAPREDUCE-7049,Testcase TestMRJobs#testJobClassloaderWithCustomClasses fails ,"The testcase TestMRJobs#testJobClassloaderWithCustomClasses fails consistently with this error:

{noformat}
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapreduce.v2.TestMRJobs
[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 54.325 s <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestMRJobs
[ERROR] testJobClassloaderWithCustomClasses(org.apache.hadoop.mapreduce.v2.TestMRJobs)  Time elapsed: 10.531 s  <<< FAILURE!
java.lang.AssertionError: 
Job status: Application application_1517928628935_0001 failed 2 times due to AM Container for appattempt_1517928628935_0001_000002 exited with  exitCode: 1
Failing this attempt.Diagnostics: [2018-02-06 15:50:38.688]Exception from container-launch.
Container id: container_1517928628935_0001_02_000001
Exit code: 1

[2018-02-06 15:50:38.693]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapreduce.v2.app.MRAppMaster).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.


[2018-02-06 15:50:38.694]Container exited with a non-zero exit code 1. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapreduce.v2.app.MRAppMaster).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.


For more detailed output, check the application tracking page: http://ubuntu:46235/cluster/app/application_1517928628935_0001 Then click on links to logs of each attempt.
. Failing the application.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloader(TestMRJobs.java:529)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testJobClassloaderWithCustomClasses(TestMRJobs.java:477)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

Today I found the offending commit with {{git bisect}} and this failure is caused by {{YARN-2185}}.

The application master fails because of the following error:

{noformat}
2018-02-05 17:15:18,530 DEBUG [main] org.apache.hadoop.util.ExitUtil: Exiting with status 1: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
1: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:265)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1694)
Caused by: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$3.call(MRAppMaster.java:554)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$3.call(MRAppMaster.java:534)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.callWithJobClassLoader(MRAppMaster.java:1802)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createOutputCommitter(MRAppMaster.java:534)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceInit(MRAppMaster.java:311)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$6.run(MRAppMaster.java:1760)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1965)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1757)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1691)
Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$3.call(MRAppMaster.java:550)
        ... 11 more
Caused by: java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
        ... 12 more
Caused by: java.lang.ExceptionInInitializerError: incorrect classloader used
        at org.apache.hadoop.mapreduce.v2.TestMRJobs$CustomOutputFormat.verifyClassLoader(TestMRJobs.java:551)
        at org.apache.hadoop.mapreduce.v2.TestMRJobs$CustomOutputFormat.<init>(TestMRJobs.java:535)
        ... 17 more
{noformat}

The test expects the class {{CustomOutputFormat}} to be loaded by {{ApplicationClassLoader}}. After YARN-2185 however, the class is loaded by the system classloader. This class was supposed to be loaded from {{job.jar}} but apparently is picked from a different place."
MAPREDUCE-7048,Uber AM can crash due to unknown task in statusUpdate,"The testcase TestUberAM#testThreadDumpOnTaskTimeout was supposed to be fixed by MAPREDUCE-7020. However, it still fails, see: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/7325/testReport/junit/org.apache.hadoop.mapreduce.v2/TestMRJobs/testThreadDumpOnTaskTimeout/ (note: other tests failed as well, but those look unrelated).

When I tried to reproduce it locally, it failed again, although with a slightly different error message (it was actually the same as before):

{noformat}
[INFO] -------------------------------------------------------
[INFO]  T E S T S
[INFO] -------------------------------------------------------
[INFO] Running org.apache.hadoop.mapreduce.v2.TestUberAM
[ERROR] Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 128.192 s <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestUberAM
[ERROR] testThreadDumpOnTaskTimeout(org.apache.hadoop.mapreduce.v2.TestUberAM)  Time elapsed: 79.539 s  <<< FAILURE!
java.lang.AssertionError: No AppMaster log found! expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout(TestMRJobs.java:1228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}

*Root cause:* {{System.exit()}} is still invoked at {{Task.statusUpdate()}}

{noformat}
  public void statusUpdate(TaskUmbilicalProtocol umbilical) 
  throws IOException {
    int retries = MAX_RETRIES;
    while (true) {
      try {
        if (!umbilical.statusUpdate(getTaskID(), taskStatus).getTaskFound()) {
          LOG.warn(""Parent died.  Exiting ""+taskId);
          System.exit(66);
        }
        taskStatus.clearStatus();
        return;
        ...
{noformat}

At this point, the task was not found and return value of {{umbilical.statusUpdate()}} is false. Checking whether we run in uber mode seems to solve the problem."
MAPREDUCE-7047,Make HAR tool support IndexedLogAggregtionController,"In https://issues.apache.org/jira/browse/MAPREDUCE-6415, we have created a tool to combine aggregated logs into HAR files which currently only work for TFileLogAggregationFileController. We should make it support IndexedLogAggregtionController as well."
MAPREDUCE-7043,Make EventHubs system configs compatible with Samza standalone,"EventHubs configs are using the old style configs (system.*.streams.*.config).

It needs to be moved to the new stream-id configs."
MAPREDUCE-7042,Killed MR job data does not move to mapreduce.jobhistory.done-dir when ATS v2 is enabled,"Steps:
1) Start a mapreduce job
{code}
hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-3.0.0.3.0.0.0-751-tests.jar sleep ""-Dmapreduce.job.user.name=hrt_qa""   -m 10 -r 1 -mt 1000  -rt 1000{code}
2) kill job
3) Validate job is present at mapreduce.jobhistory.done-dir

mapreduce.jobhistory.done-dir dir does not have job_1516776025831_0048 entry."
MAPREDUCE-7041,MR should not try to clean up at first job attempt,"These tests fails in trunk now. MAPREDUCE-6984 may be related.
{noformat}
hadoop.mapreduce.v2.TestMROldApiJobs.testJobSucceed
hadoop.mapred.TestJobCleanup.testCustomAbort
hadoop.mapreduce.lib.output.TestJobOutputCommitter.testCustomAbort
{noformat}"
MAPREDUCE-7038,JHS uses service config to identify local hostname,"In JobHistoryServer.doSecureLogin(), the local hostname is got by calling getBindAddress() which gets the hostname that is defined by the config yarn.mapreduce.jobhistory.address. This is a bug and doSecureLogin should just get local host name directly instead of this way.

 "
MAPREDUCE-7036,ASF License warning in hadoop-mapreduce-client,"it occurred in MAPREDUCE-7021 and MAPREDUCE-7034.

{noformat}

Lines that start with ????? in the ASF License report indicate files that do not have an Apache license header: !????? /testptch/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/jobTokenPassword

{noformat}"
MAPREDUCE-7035,Skip javadoc build for auto-generated sources in hadoop-mapreduce-client,"Auto-generated code in map-reduce client throws many javadoc warnings.

The warnings are thrown for the following auto-generated sources
{code:java}
hadoop-mapreduce-client-core/pom.xml
target/generated-sources/avro/

hadoop-mapreduce-client-common/pom.xml
org.apache.hadoop.yarn.proto
org.apache.hadoop.mapreduce.v2.proto
org.apache.hadoop.mapreduce.v2.hs.proto

hadoop-mapreduce-client-shuffle/pom.xml
org.apache.hadoop.mapred.proto{code}
 "
MAPREDUCE-7034,Moving logging APIs over to slf4j the rest of all in hadoop-mapreduce,"It seems there are some left.
{noformat}
find hadoop-mapreduce-project -name ""*.java"" | xargs grep ""import org.apache.commons.logging.Log"" | wc -l
       7
{noformat}"
MAPREDUCE-7033,Map outputs implicitly rely on permissive umask for shuffle,"Map tasks do not explicitly set the permissions of their output files for shuffle.  In a secure cluster the shuffle service is running as a different user than the map task, so the output files require group readability in order to serve up the data during the shuffle phase.  If the user's UNIX umask is too restrictive (e.g.: 077) then the map task's file.out and file.out.index permissions can be too restrictive to allow the shuffle handler to access them."
MAPREDUCE-7032,Add the ability to specify a delayed replication count,Setting the delayed replication count is more robust
MAPREDUCE-7030,Uploader tool should ignore symlinks to the same directory,
MAPREDUCE-7029,FileOutputCommitter is slow on filesystems lacking recursive delete,"I ran a Spark job that outputs thousands of parquet files (aka there are thousands of reducers), and it hung for several minutes in the driver after all tasks were complete. Here is a very simple repro of the job (to be run in a spark-shell):

{code:scala}
spark.range(1L << 20).repartition(1 << 14).write.save(""gs://some/path"")
{code}

Spark actually calls into Mapreduce's FileOuputCommitter. Job committing (specifically cleanupJob()) recursively deletes the job temporary directory, which is something like ""gs://some/path/_temporary"". If I understand correctly, on HDFS, this would be O(1), but on GCS (and every HCFS I know), this requires a full file tree walk. Deleting tens of thousands of objects in GCS takes several minutes.

I propose that commitTask() recursively deletes its the task attempt temp directory (something like ""gs://some/path/_temporary/attempt1/task1""). On HDFS, this is O(1) per task, so this is very little overhead per task. On GCS (and other HCFSs), this adds parallelism for deleting the job temp directory.

With the attached patch, the repro above went from taking ~10 minutes to taking ~5 minutes, and task time did not significantly change.

Side note: I found this issue with Spark, but I assume it applies to a Mapreduce job with thousands of reducers as well."
MAPREDUCE-7028,Concurrent task progress updates causing NPE in Application Master,"Concurrent task progress updates can cause a NullPointerException in the Application Master (stack trace is with code at current trunk):

{quote}
2017-12-20 06:49:42,369 INFO [IPC Server handler 9 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883
2017-12-20 06:49:42,369 INFO [IPC Server handler 13 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883
2017-12-20 06:49:42,383 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread
java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:2450)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:2433)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$500(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:487)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1362)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:154)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1543)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1535)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:197)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:126)
        at java.lang.Thread.run(Thread.java:748)
2017-12-20 06:49:42,385 INFO [IPC Server handler 13 on 39501] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1513780867907_0001_m_000002_0 is : 0.02677883
2017-12-20 06:49:42,386 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..
{quote}

This happened naturally in several big wordcount runs, and I could reproduce this reliably by artificially making task updates more frequent."
MAPREDUCE-7027,HadoopArchiveLogs shouldn't delete the original logs if the HAR creation fails,"If the hadoop archive command fails for any reason (for example because of an OutOfMemoryError) the HadoopArchiveLogs tool will still delete the original log files, so all the logs will be lost."
MAPREDUCE-7025,Avg and Max of memory could be record in TaskCount,"MapReduce Counter is very helpful tool to do statistics, analysis and tuning in industry. One popular way is analysing job historical status of running to optimise continuously. But when the job completed, the memory usage in counter is a snapshot value {{PHYSICAL_MEMORY_BYTES}}. So if we can also record the average value and the max value instead of only the last snapshot value, it could be much helpful.

If you think it' ok. I will contribute the code."
MAPREDUCE-7023,TestHadoopArchiveLogs.testCheckFilesAndSeedApps fails on rerun,"Since the test doesn't clean up the created ""logs"" dir, when rerunning it fails on this line:
{code}
Assert.assertEquals(0, hal.eligibleApplications.size());
hal.checkFilesAndSeedApps(fs, rootLogDir, suffix);
 >>> Assert.assertEquals(1, hal.eligibleApplications.size());

java.lang.AssertionError: 
Expected :1
Actual   :2 (or more for consecutive reruns)
{code}"
MAPREDUCE-7022,Fast fail rogue jobs based on task scratch dir size,"With the introduction of MAPREDUCE-6489 there are some options to kill rogue tasks based on writes to local disk writes. In our environment are we mainly run Hive based jobs we noticed that this counter and the size of the local scratch dirs were very different. We had tasks where BYTES_WRITTEN counter were at 300Gb and where it was at 10Tb both producing around 200Gb on local disk, so it didn't help us much. So to extend this feature tasks should monitor local scratchdir size and fail if they pass the limit. In these cases the tasks should not be retried either but instead the job should fast fail."
MAPREDUCE-7020,Task timeout in uber mode can crash AM,"TestUberAM is failing
{noformat}
java.lang.AssertionError: No AppMaster log found! expected:<1> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testThreadDumpOnTaskTimeout(TestMRJobs.java:1228)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{noformat}
https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/614/testReport/junit/org.apache.hadoop.mapreduce.v2/TestUberAM/testThreadDumpOnTaskTimeout/"
MAPREDUCE-7019,java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 2,
MAPREDUCE-7018,Apply erasure coding properly to framework tarball and support plain tar,"{code}
2017-12-01 17:54:51,753 INFO uploader.FrameworkUploader: Disabling Erasure Coding for path: hdfs://machine:9000/tmp/mr-framework.tar.gz
2017-12-01 17:54:51,779 ERROR uploader.FrameworkUploader: Error in execution Attempt to set an erasure coding policy for a file /tmp/mr-framework.tar.gz
	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.setErasureCodingPolicyXAttr(FSDirErasureCodingOp.java:147)
	at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.setErasureCodingPolicy(FSDirErasureCodingOp.java:127)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setErasureCodingPolicy(FSNamesystem.java:7291)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setErasureCodingPolicy(NameNodeRpcServer.java:2115)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setErasureCodingPolicy(ClientNamenodeProtocolServerSideTranslatorPB.java:1552)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:869)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:815)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1962)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2675)
{code}
"
MAPREDUCE-7015,Possible race condition in JHS if the job is not loaded,"There could be a race condition inside JHS. In our build environment, {{TestMRJobClient.testJobClient()}} failed with this exception:

{noformat}
ava.io.FileNotFoundException: File does not exist: hdfs://localhost:32836/tmp/hadoop-yarn/staging/history/done_intermediate/jenkins/job_1509975084722_0001_conf.xml
	at org.apache.hadoop.hdfs.DistributedFileSystem$20.doCall(DistributedFileSystem.java:1266)
	at org.apache.hadoop.hdfs.DistributedFileSystem$20.doCall(DistributedFileSystem.java:1258)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1258)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:340)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:292)
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2123)
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2092)
	at org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2068)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:460)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.mapreduce.TestMRJobClient.runTool(TestMRJobClient.java:94)
	at org.apache.hadoop.mapreduce.TestMRJobClient.testConfig(TestMRJobClient.java:551)
	at org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient(TestMRJobClient.java:167)
{noformat}

Root cause:
1. MapReduce job completes
2. CLI calls {{cluster.getJob(jobid)}}
3. The job is finished and the client side gets redirected to JHS
4. The job data is missing from {{CachedHistoryStorage}} so JHS tries to find the job
5. First it scans the intermediate directory and finds the job
6. The call {{moveToDone()}} is scheduled for execution on a separate thread inside {{moveToDoneExecutor}} and it starts to run immediately
7. RPC invocation returns with the path pointing to {{/tmp/hadoop-yarn/staging/history/done_intermediate}}
8. The call to {{moveToDone()}} completes which moves the contents of {{done_intermediate}} to {{done}}
9. Hadoop CLI tries to download the config file from done_intermediate but it's no longer there

Usually step #6 is slow enough to complete after #7, but sometimes it's faster, causing this race condition."
MAPREDUCE-7014,Fix java doc errors in jdk1.8,Trunk compilation fails with Java Doc errors. 
MAPREDUCE-7011,TestClientDistributedCacheManager::testDetermineCacheVisibilities assumes all parent dirs set other exec,"{{TestClientDistributedCacheManager}} sets up some local directories to check the visibility set for dependencies, given their filesystem permissions. However, if it is run in an environment where the scratch directory is not itself PUBLIC ({{ClientDistributedCacheManager::isPublic}}), then it will fail."
MAPREDUCE-7010,Make Job History File Permissions configurable,"Currently the mapreduce job history files are written with 770 permissions which can be accessed by job user or other user part of hadoop group.
There might be users who are not part of the hadoop group but want to access these history files. We should provide ability to change the default permissions for staging files.
The default should remain 770."
MAPREDUCE-7006,mapreduce.application.framework.path localizes into the private directory,Mapreduce has a feature to localize the entire framework into distributed cache from HDFS using mapreduce.application.framework.path. This tarball should be public and not private as it is now.
MAPREDUCE-7001,Moving logging APIs over to slf4j in hadoop-mapreduce-client-shuffle,
MAPREDUCE-7000,Moving logging APIs over to slf4j in hadoop-mapreduce-client-nativetask,
MAPREDUCE-6999,"Fix typo ""onf"" in DynamicInputChunk.java","Modify the wrong word ""onf"" to ""on"""
MAPREDUCE-6998,Moving logging APIs over to slf4j in hadoop-mapreduce-client-jobclient,
MAPREDUCE-6997,Moving logging APIs over to slf4j in hadoop-mapreduce-client-hs,
MAPREDUCE-6995,Uploader tool for Distributed Cache Deploy documentation,
MAPREDUCE-6994,Uploader tool for Distributed Cache Deploy code changes,The proposal is to create a tool that collects all available jars in the Hadoop classpath and adds them to a single tarball file. It then uploads the resulting archive to an HDFS directory. This saves the cluster administrator from having to set this up manually for Distributed Cache Deploy.
MAPREDUCE-6992,Race for temp dir in LocalDistributedCacheManager.java,"When localizing distributed cache files in ""local"" mode, LocalDistributedCacheManager.java chooses a ""unique"" directory based on a millisecond time stamp. When running code with some parallelism, it's possible to run into this.

The error message looks like 
{code}
bq. java.io.FileNotFoundException: jenkins/mapred/local/1508958341829_tmp does not exist
{code}

I ran into this in Impala's data loading. There, we run a HiveServer2 which runs in MapReduce. If multiple queries are submitted simultaneously to the HS2, they conflict on this directory. Googling found that StreamSets ran into something very similar looking at https://issues.streamsets.com/browse/SDC-5473.

I believe the buggy code is (link: https://github.com/apache/hadoop/blob/2da654e34a436aae266c1fbdec5c1067da8d854e/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java#L94)
{code}
    // Generating unique numbers for FSDownload.
    AtomicLong uniqueNumberGenerator =
        new AtomicLong(System.currentTimeMillis());
{code}

Notably, a similar code path uses an actual random number generator ({{LocalJobRunner.java}}, https://github.com/apache/hadoop/blob/2da654e34a436aae266c1fbdec5c1067da8d854e/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalJobRunner.java#L912).
{code}
  public String getStagingAreaDir() throws IOException {
    Path stagingRootDir = new Path(conf.get(JTConfig.JT_STAGING_AREA_ROOT,
        ""/tmp/hadoop/mapred/staging""));
    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
    String user;
    randid = rand.nextInt(Integer.MAX_VALUE);
{code}"
MAPREDUCE-6989,[Umbrella] Uploader tool for Distributed Cache Deploy of the mapreduce framework and dependencies,The proposal is to create a tool that collects all available jars in the Hadoop classpath and adds them to a single tarball file. It then uploads the resulting archive to an HDFS directory. This saves the cluster administrator from having to set this up manually for Distributed Cache Deploy.
MAPREDUCE-6987,JHS Log Scanner and Cleaner blocked,"{code}
""Log Scanner/Cleaner #1"" #81 prio=5 os_prio=0 tid=0x00007fd6c010f000 nid=0x11db waiting on condition [0x00007fd6aa859000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000d6c88a80> (a java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:47)
	at org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor.afterExecute(HadoopScheduledThreadPoolExecutor.java:69)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1150)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

""Log Scanner/Cleaner #0"" #80 prio=5 os_prio=0 tid=0x00007fd6c010c800 nid=0x11da waiting on condition [0x00007fd6aa95a000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000d6c80000> (a java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
	at java.util.concurrent.FutureTask.awaitDone(FutureTask.java:429)
	at java.util.concurrent.FutureTask.get(FutureTask.java:191)
	at org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:47)
	at org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor.afterExecute(HadoopScheduledThreadPoolExecutor.java:69)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1150)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{code}

Both threads waiting on {{FutureTask.get()}} for infinite time after first execution"
MAPREDUCE-6984,MR AM to clean up temporary files from previous attempt in case of no recovery,"When the MR AM restarts, the &#123;outputDir&#125;/_temporary/&#123;appAttemptNumber&#125; directory remains on HDFS, even though this directory is not used during the next attempt if the restart has been done without recovery. So if recovery is not used for the AM restart, then the deletion of this directory can be done earlier (at the start of the next attempt). The benefit is that more free HDFS space is available for the next attempt."
MAPREDUCE-6983,Moving logging APIs over to slf4j in hadoop-mapreduce-client-core,
MAPREDUCE-6982,Containers on lost nodes are considered failed after a too long time.,"Containers on lost nodes (nodemanager being unavailable or server being unavailable) are considered failed after a too long time.
This is due to the AppMaster trying to cleanup the container on the unavailable node.
The proposed path will limit the impact of this timeout by managing NodeManager lost events on AM as described below:
*     on nodemanager service unavailibility (crash, oom ...):
    When receiving lost NodeManager events, it failed the impacted attempt and do not go through the cleanup stage.
*     on nodemanager server unavailibility with default settings AM detect first that the attempt is in timeout and try to cleanup the attempt:
When receiving lost NodeManager events, it stop the cleanup process on the impacted container and failed the attempt.

This reduce the duration of the timeout to the timeout for detecting a NodeManager down.

Similar issue than [MAPREDUCE-6659|https://issues.apache.org/jira/browse/MAPREDUCE-6659] on which I can't attached the patch."
MAPREDUCE-6979,CLONE - MR task counters deserialized through RPC throws OutOfBoundsException if Counter enum class version not match,"Environment:
NM1 TaskCounter.class old version; 
NM2 TaskCounter.class new version (new Enumeration values appended); 

Result:
When an MR app's AM running on NM1, and it's containers on NM2; the containers on NM2 will all failed, AM cause OutOfBoundsException;

Reason:
When app running, containers will report their counters to AM through RPC, while the Container with new version TaskCounter.class will write more Counter values to RPC; however, the AM with old version TaskCounter.class which can not read them correctly from RPC."
MAPREDUCE-6978,MR task counters deserialized through RPC throws OutOfBoundsException if Counter enum class version not match,"Environment:
NM1 TaskCounter.class old version; 
NM2 TaskCounter.class new version (new Enumeration values appended); 

Result:
When an MR app's AM running on NM1, and it's containers on NM2; the containers on NM2 will all failed, AM cause OutOfBoundsException;

Reason:
When app running, containers will report their counters to AM through RPC, while the Container with new version TaskCounter.class will write more Counter values to RPC; however, the AM with old version TaskCounter.class which can not read them correctly from RPC."
MAPREDUCE-6977,Moving logging APIs over to slf4j in hadoop-mapreduce-client-common,"committed to trunk; slight merge conflict in imports of MRApps.java to resolve, nothing significant. did a clean rebuilt to make sure all was well"
MAPREDUCE-6975,Logging task counters ,Logging counters for each task at the end of it's syslog will make debug easier with just application logs. 
MAPREDUCE-6974,"Add standard configuration keys for HTrace values, propagate across to MR committers if set","HDFS &c support HTrace logging; HBase sets up spans.

What doesn't do spans is MR jobs or other frameworks with use the MR committers.

That can be addressed by defining some standard configuration keys for HTrace hi/low numbers, setting them in job submission, then passing them over the wire in the Configuration, where setupJob and setupTask can extract them & use for the tracing span. They could also add their own span for taskCommit and jobCommit for performance measurement there.

Although the core code would be in MR, I'd propose putting the keys into Hadoop common,
 with some code in {{org.apache.hadoop.tracing.TraceUtils}}, to set it up. That way its possible to use more broadly."
MAPREDUCE-6973,Fix comments on creating _SUCCESS file.,"I went through couple of old JIRA issues and understood that earlier app was creating ""_done"" file on job has completed successfully. After some conversation by group decided to create ""_SUCCESS"" instead of ""_done"". However, while learning the code, I found there is one comment has reference of ""_done"" and would like to start with small contribution to fix it. 

Note: I would like to work on this trivial issue so can get opportunity to follow standard process of contribution steps, that will myself to come on track quickly for future contribution that I would like to do. "
MAPREDUCE-6972,Enable try-with-resources for RecordReader,"{{org.apache.hadoop.mapred.RecordReader}} has a close method; but doesn't implement closeable; it would be nice to add that - it would enable to use:

{code}
try( org.apache.hadoop.mapred.RecordReader<?, ?> recordReader = inputFormat.getRecordReader(... )   ){
 [...]
}
{code}

...supporting t-w-r makes it easier to throw exceptions more safely"
MAPREDUCE-6971,Moving logging APIs over to slf4j in hadoop-mapreduce-client-app,
MAPREDUCE-6968,Staging directory erasure coding config property has a typo,"TestMapreduceConfigFields has been failing since MAPREDUCE-6954. MRJobConfig#MR_AM_STAGING_DIR_ERASURECODING_ENABLED is defined as ""yarn.app.mapreduce.am.staging-direrasurecoding.enabled""  but the property is listed as ""yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled"" in mapred-default.xml."
MAPREDUCE-6967,gridmix/SleepReducer should use Time.monotonicNow for measuring durations,
MAPREDUCE-6966,DistSum should use Time.monotonicNow for measuring durations,Sub-task for HADOOP-14713
MAPREDUCE-6965,QuasiMonteCarlo should use Time.monotonicNow for measuring durations,
MAPREDUCE-6964,BaileyBorweinPlouffe should use Time.monotonicNow for measuring durations,
MAPREDUCE-6962,Remove unused settings from log4j.properties,"{noformat:title=hadoop-common-project/hadoop-common/src/main/conf/log4j.properties}
#Default values
hadoop.tasklog.taskid=null
hadoop.tasklog.iscleanup=false
hadoop.tasklog.noKeepSplits=4
hadoop.tasklog.totalLogFileSize=100
hadoop.tasklog.purgeLogSplits=true
hadoop.tasklog.logsRetainHours=12
{noformat}
hadoop.tasklog.noKeepSplits, purgeLogSplits, and logsRetainHours are not used anywhere and can be removed. These parameters were removed by HADOOP-1553 10 years ago."
MAPREDUCE-6961,Pull up FileOutputCommitter.getOutputPath to PathOutputCommitter,"SPARK-21549 has shown that downstream code is relying on the internal property 

if we pulled {{FileOutputCommitter.getOutputPath}} to the {{PathOutputCommitter}} of MAPREDUCE-6956, then there'd be a public/stable way to get this. Admittedly, it does imply that the committer will always have *some* output path, but FileOutputFormat depends on that anyway."
MAPREDUCE-6960,Shuffle Handler prints disk error stack traces for every read failure.,"{code}
 } catch (IOException e) {
          LOG.error(""Shuffle error :"", e);
{code}
In cases where the read from a disk fails and throws a DiskErrorException, the shuffle handler prints the entire stack trace for each and every one of the failures causing the nodemanager logs to quickly fill up the disk. "
MAPREDUCE-6959,Understanding on process to start contribution,"I was trying to find process/steps to start with contribution into following repo i.e. https://github.com/apache/hadoop-mapreduce. Can someone please help with the detail so that I can create appropriate git/jira issue and start woking on it?

Any direction would be really appreciated!

Thanks,
Mehul"
MAPREDUCE-6958,Shuffle audit logger should log size of shuffle transfer,"The shuffle audit logger currently logs the job ID and reducer ID but nothing about the size of the requested transfer.  It calculates this as part of the HTTP response headers, so it would be trivial to log the response size.  This would be very valuable for debugging network traffic storms from the shuffle handler.
"
MAPREDUCE-6957,shuffle hangs after a node manager connection timeout,"After a connection failure from the reducer to the node manager, shuffles started to hang with the following message:

{code}
org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
{code}

There are two problems that leads to the hang.

Problem 1.
When a reducer has an issue connecting to the node manager, copyFromHost may call putBackKnownMapOutput on the same task attempt multiple times.

There are two call sites of putBackKnownMapOutput in copyFromHost since MAPREDUCE-6303:
1. In the finally block of copyFromHost
2. In the catch block of openShuffleUrl.

When openShuffleUrl fails to connect from the catch block in copyFromHost, it returns null.
By the time openShuffleUrl returns null, putBackKnownMapOutput would have been called already for all remaining map outputs.
However, the finally block calls putBackKnownMapOutput one more time on the map outputs.

Problem 2. Problem 1 causes a leak in MergeManager.
The problem occurs when multiple fetchers get the same set of map attempt outputs to fetch.
Different fetchers reserves memory from MergeManager in Fetcher.copyMapOutput for the same map outputs.
When the fetch succeeds, only the first map output gets committed through ShuffleSchedulerImpl.copySucceeded -> InMemoryMapOutput.commit, because commit() is gated by !finishedMaps[mapIndex].
This may lead to a condition where usedMemory > memoryLimit, while commitMemory < mergeThreshold.
This gets the MergeManager into a deadlock where a merge is never triggered while MergeManager cannot reserve additional space for map outputs."
MAPREDUCE-6956,FileOutputCommitter to gain abstract superclass PathOutputCommitter,"This is the initial step of MAPREDUCE-6823, which proposes a factory behind {{FileOutputFormat}} to create different committers for different filesystems, if so configured..

This patch simply adds the new abstract superclass of {{FileOutputCommitter}}, {{PathOutputCommitter extends OutputCommitter}}. This abstract class adds the {{getWorkPath()}} method as an abstract method, with {{FIleOutputCommitter}} being the implementation..

{{FileOutputFormat}} then relaxes its requirement of any committer returned by {{getOutputCommitter()}}, so that instead of requiring a  {{FileOutputCommitter}} or subclass, it only needs a {{PathOutputCommitter}}, using {{PathOutputCommitter.getWorkPath()}} to get the work path.

What does that do?

It allows people to implement subclasses of {{FileOutputFormat}} which can provide their own committers *which don't need to inherit the complexity that FileOutputCommitter has acquired over time*

Currently anyone implementing a new committer (example: Netflix S3 committer) needs to subclass {{FileOutputCommitter}}, which is too complex to understand except under a debugger with co-recursive routines, lots of methods which need to be overwritten to guarantee a safe subclass, and, because of its critical role and known subclassing, something which isn't ever going to be cleaned up.

A new, lean, parent class which {{FileOutputFormat}} can handle allows people to write new committers which don't have to worry about implementation details of {{FileOutputCommitter}}, but instead how well they implement the semantics of committing work.

The full MAPREDUCE-6823 goes beyond this with a change to {{FileOutputFormat}} for a factory for creating FS-specific {{PathOutputCommitter}} instances. This patch doesn't include that, as that is something which needs to be reviewed in the context of HADOOP-13786 and ideally 1+ committer for another store, so people can say ""this factory model works"".

All I'm proposing here is: tune the committer class hierarchy in MRv2 so that people can more easily implement committers, and when that factory is done, for it to be switched to easily. And I'd like this in branch-3 from the outset, so existing code which calls {{FileOutputFormat.getCommitter()}} to get a {{FileOutputCommitter}} *just to call getWorkPath()* can move to the new interface across all of Hadoop 3."
MAPREDUCE-6955,remove unnecessary dependency from hadoop-mapreduce-client-app to hadoop-mapreduce-client-shuffle,
MAPREDUCE-6954,Disable erasure coding for files that are uploaded to the MR staging area,"Depending on the encoder/decoder used and the type or MR workload, EC might negatively affect the performance of an MR job if too many files are localized.

In such a scenario, users might want to disable EC in the staging area to speed up the execution."
MAPREDUCE-6953,Skip the testcase testJobWithChangePriority if FairScheduler is used,"We run the unit tests with Fair Scheduler downstream. FS does not support priorities at the moment, so TestMRJobs#testJobWithChangePriority fails.

Just add {{Assume.assumeFalse(usingFairScheduler);}} and JUnit will skip the test."
MAPREDUCE-6951,Improve exception message when mapreduce.jobhistory.webapp.address is in wrong format,"MapReduce jobs fails with below exception when mapreduce.jobhistory.webapp.address is in wrong format instead of host:port, example user has set to 19888

{code}
java.util.NoSuchElementException 
at com.google.common.base.AbstractIterator.next(AbstractIterator.java:75) 
at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithoutScheme(MRWebAppUtil.java:130) 
at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(MRWebAppUtil.java:156) 
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.doUnregistration(RMCommunicator.java:218) 
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister(RMCommunicator.java:188) 
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStop(RMCommunicator.java:268) 
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStop(RMContainerAllocator.java:297) 
at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221) 
at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52) 
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStop(MRAppMaster.java:888) 
at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221) 
at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52) 
at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80) 
at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157) 
at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131) 
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1667) 
at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221) 
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1168) 
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:603) 
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$1.run(MRAppMaster.java:651)
{code}


"
MAPREDUCE-6949,yarn.app.mapreduce.am.log.level is not documented in mapred-default.xml,
MAPREDUCE-6948,TestJobImpl.testUnusableNodeTransition failed,"*Error Message*
expected:<SUCCEEDED> but was:<ERROR>

*Stacktrace*
java.lang.AssertionError: expected:<SUCCEEDED> but was:<ERROR>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.assertJobState(TestJobImpl.java:1041)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.testUnusableNodeTransition(TestJobImpl.java:615)


*Standard out*
{code}
2017-08-30 10:12:21,928 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2017-08-30 10:12:21,939 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl$StubbedJob
2017-08-30 10:12:21,940 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$79f96ebf
2017-08-30 10:12:21,940 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$79f96ebf
2017-08-30 10:12:21,940 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$79f96ebf
2017-08-30 10:12:21,941 INFO  [Thread-49] impl.JobImpl (JobImpl.java:setup(1534)) - Adding job token for job_1234567890000_0001 to jobTokenSecretManager
2017-08-30 10:12:21,941 WARN  [Thread-49] impl.JobImpl (JobImpl.java:setup(1540)) - Shuffle secret key missing from job credentials. Using job token secret as shuffle secret.
2017-08-30 10:12:21,944 INFO  [Thread-49] impl.JobImpl (JobImpl.java:makeUberDecision(1305)) - Not uberizing job_1234567890000_0001 because: not enabled;
2017-08-30 10:12:21,944 INFO  [Thread-49] impl.JobImpl (JobImpl.java:createMapTasks(1562)) - Input size for job job_1234567890000_0001 = 0. Number of splits = 2
2017-08-30 10:12:21,945 INFO  [Thread-49] impl.JobImpl (JobImpl.java:createReduceTasks(1579)) - Number of reduces for job job_1234567890000_0001 = 1
2017-08-30 10:12:21,945 INFO  [Thread-49] impl.JobImpl (JobImpl.java:handle(1017)) - job_1234567890000_0001Job Transitioned from NEW to INITED
2017-08-30 10:12:21,946 INFO  [Thread-49] impl.JobImpl (JobImpl.java:handle(1017)) - job_1234567890000_0001Job Transitioned from INITED to SETUP
2017-08-30 10:12:21,954 INFO  [CommitterEvent Processor #0] commit.CommitterEventHandler (CommitterEventHandler.java:run(231)) - Processing the event EventType: JOB_SETUP
2017-08-30 10:12:21,978 INFO  [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(1017)) - job_1234567890000_0001Job Transitioned from SETUP to RUNNING
2017-08-30 10:12:21,983 INFO  [Thread-49] event.AsyncDispatcher (AsyncDispatcher.java:register(209)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskAttemptEventType for class org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl$5
2017-08-30 10:12:22,000 INFO  [Thread-49] impl.JobImpl (JobImpl.java:transition(1953)) - Num completed Tasks: 1
2017-08-30 10:12:22,029 INFO  [Thread-49] impl.JobImpl (JobImpl.java:transition(1953)) - Num completed Tasks: 2
2017-08-30 10:12:22,032 INFO  [Thread-49] impl.JobImpl (JobImpl.java:actOnUnusableNode(1354)) - TaskAttempt killed because it ran on unusable node Mock for NodeId, hashCode: 1280187896. AttemptId:attempt_1234567890000_0001_m_000000_0
2017-08-30 10:12:22,032 INFO  [Thread-49] impl.JobImpl (JobImpl.java:transition(1953)) - Num completed Tasks: 3
2017-08-30 10:12:22,032 INFO  [Thread-49] impl.JobImpl (JobImpl.java:handle(1017)) - job_1234567890000_0001Job Transitioned from RUNNING to COMMITTING
2017-08-30 10:12:22,032 ERROR [Thread-49] impl.JobImpl (JobImpl.java:handle(1009)) - Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at COMMITTING
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1007)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.testUnusableNodeTransition(TestJobImpl.java:609)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2017-08-30 10:12:22,035 INFO  [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(1017)) - job_1234567890000_0001Job Transitioned from COMMITTING to ERROR
2017-08-30 10:12:22,039 INFO  [CommitterEvent Processor #1] commit.CommitterEventHandler (CommitterEventHandler.java:run(231)) - Processing the event EventType: JOB_COMMIT
{code}"
MAPREDUCE-6947, Moving logging APIs over to slf4j in hadoop-mapreduce-examples,
MAPREDUCE-6945,TestMapFileOutputFormat missing @after annotation,TestMapFileOutputFormat missing @after annotation. 
MAPREDUCE-6941,The default setting doesn't work for MapReduce job,"On the deployment of hadoop 3 cluster (based on current trunk branch) with default settings, the MR job will get failed as following exceptions:
{noformat}
2017-08-16 13:00:03,846 INFO mapreduce.Job: Job job_1502913552390_0001 running in uber mode : false
2017-08-16 13:00:03,847 INFO mapreduce.Job:  map 0% reduce 0%
2017-08-16 13:00:03,864 INFO mapreduce.Job: Job job_1502913552390_0001 failed with state FAILED due to: Application application_1502913552390_0001 failed 2 times due to AM Container for appattempt_1502913552390_0001_000002 exited with  exitCode: 1
Failing this attempt.Diagnostics: [2017-08-16 13:00:02.963]Exception from container-launch.
Container id: container_1502913552390_0001_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1:
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:994)
	at org.apache.hadoop.util.Shell.run(Shell.java:887)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1212)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:295)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:455)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:275)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:90)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

{noformat}

This is because mapreduce related jar are not added into yarn setup by default. To make MR job run successful, we need to add following configurations to yarn-site.xml now:
{noformat}
    <property>
      <name>yarn.application.classpath</name>
      <value>
        ...
        <HADOOP_HOME>/share/hadoop/mapreduce/*,
        <HADOOP_HOME>/share/hadoop/mapreduce/lib/*
        ...
      </value>
{noformat}
But this config is not necessary for previous version of Hadoop. We should fix this issue before beta release otherwise it will be a regression for configuration changes.

This could be more like a YARN issue (if so, we should move), depends on how we fix it finally."
MAPREDUCE-6940,Copy-paste error in the TaskAttemptUnsuccessfulCompletionEvent constructor,"This constructor seems to be copy-pasted from another one, but it doesn't pass allSplits parameter as expected.

Lines 126-133:

{code:java}
  public TaskAttemptUnsuccessfulCompletionEvent
      (TaskAttemptID id, TaskType taskType,
       String status, long finishTime,
       String hostname, int port, String rackName,
       String error, int[][] allSplits) {
    this(id, taskType, status, finishTime, hostname, port,
        rackName, error, EMPTY_COUNTERS, null);
  }
{code}
"
MAPREDUCE-6938,Question,"I need 2 helps.

1) need a Java map reducer sample program where multiple parameters 
are passed from mapper to reducer.
2) need a Java map reducer program where there is a write to a file inside 
hdfs filesystem as well as a read from a file inside hdfs other than 
the normal input file and output file mentioned in the mapper and reducer."
MAPREDUCE-6937,Backport MAPREDUCE-6870 to branch-2 while preserving compatibility,"To maintain compatibility we need to disable this by default per discussion on MAPREDUCE-6870.

Using a separate JIRA to correctly track incompatibilities."
MAPREDUCE-6936,Remove unnecessary dependency of hadoop-yarn-server-common from hadoop-mapreduce-client-common ,"The dependency of hadoop-yarn-server-common in hadoop-mapreduce-client-common seems unnecessary, as 
it is not using as of the classes from hadoop-yarn-server-common. "
MAPREDUCE-6934,downlink.data is written to CWD,"When using Pipes, the downlink.data stream is written to the current working directory.  This is a big of a problem when running MR jobclient tests in parallel as the file is written outside of target."
MAPREDUCE-6933,Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILLED,"When I run a job on 0.23.1, I found a InvalidStateTransitonException:

{code:java}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILLED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:926)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:870)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:862)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
        at java.lang.Thread.run(Thread.java:745)
{code}
After I manually analyse the code of 3.0.0,I think this error may still exists."
MAPREDUCE-6931,"Remove TestDFSIO ""Total Throughput"" calculation","The new ""Total Throughput"" line added in https://issues.apache.org/jira/browse/HDFS-9153 is currently calculated as {{toMB(size) / ((float)execTime)}} and claims to be in units of ""MB/s"", but {{execTime}} is in milliseconds; thus, the reported number is 1/1000x the actual value:

{code:java}
    String resultLines[] = {
        ""----- TestDFSIO ----- : "" + testType,
        ""            Date & time: "" + new Date(System.currentTimeMillis()),
        ""        Number of files: "" + tasks,
        "" Total MBytes processed: "" + df.format(toMB(size)),
        ""      Throughput mb/sec: "" + df.format(size * 1000.0 / (time * MEGA)),
        ""Total Throughput mb/sec: "" + df.format(toMB(size) / ((float)execTime)),
        "" Average IO rate mb/sec: "" + df.format(med),
        ""  IO rate std deviation: "" + df.format(stdDev),
        ""     Test exec time sec: "" + df.format((float)execTime / 1000),
        """" };
{code}

The different calculated fields can also use toMB and a shared milliseconds-to-seconds conversion to make it easier to keep units consistent."
MAPREDUCE-6930,mapreduce.map.cpu.vcores and mapreduce.reduce.cpu.vcores are both present twice in mapred-default.xml,The second set should be deleted.
MAPREDUCE-6929,TimelineV2Client hangs MR AM,"I happened to misconfigure ATSv2 settings, that is, I enabled emitting to ATSv2 in MR and did not start YARN with ATSv2. The job was stuck after it finished all its work. 

Noticed that in MRAppMaster, TimelineClient is never added as a service, which I think is why the AM was hanging. "
MAPREDUCE-6927,MR job should only set tracking url if history was successfully written,"Currently the RMCommunicator will set the tracking url during unregistration once a job has finished, regardless of whether it actually wrote history or not. If the write to history failed for whatever reason, we should leave the tracking url as null so that we get redirected to the AHS instead of getting a job not found on the JHS. "
MAPREDUCE-6926,Allow MR jobs to opt out of oversubscription,
MAPREDUCE-6924,Revert MAPREDUCE-6199 MAPREDUCE-6286 and MAPREDUCE-5875,Filing this JIRA so the reverts show up in the changelog.
MAPREDUCE-6923,Optimize MapReduce Shuffle I/O for small partitions,"When a job configuration results in small partitions read by each reducer from each mapper (e.g. 65 kilobytes as in my setup: a [TeraSort|https://github.com/apache/hadoop/blob/branch-2.7.3/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/terasort/TeraSort.java] of 256 gigabytes using 2048 mappers and reducers each), and setting

{code:xml}
<property>
  <name>mapreduce.shuffle.transferTo.allowed</name>
  <value>false</value>
</property>
{code}

then the default setting of

{code:xml}
<property>
  <name>mapreduce.shuffle.transfer.buffer.size</name>
  <value>131072</value>
</property>
{code}

results in almost 100% overhead in reads during shuffle in YARN, because for each 65K needed, 128K are read.

I propose a fix in [FadvisedFileRegion.java|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/FadvisedFileRegion.java#L114] as follows:

{code:java}
ByteBuffer byteBuffer = ByteBuffer.allocate(Math.min(this.shuffleBufferSize, trans > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) trans));
{code}

e.g. [here|https://github.com/apache/hadoop/compare/branch-2.7.3...robert-schmidtke:adaptive-shuffle-buffer]. This sets the shuffle buffer size to the minimum value of the shuffle buffer size specified in the configuration (128K by default), and the actual partition size (65K on average in my setup). In my benchmarks this reduced the read overhead in YARN from about 100% (255 additional gigabytes as described above) down to about 18% (an additional 45 gigabytes). The runtime of the job remained the same in my setup."
MAPREDUCE-6922,MapReduce jobs may fail during rolling upgrade due to MAPREDUCE-6829,"MAPREDUCE-6829 should be reverted from branch-2 because rolling upgrade fails.
{code}
2017-06-08 17:43:37,173 WARN [Socket Reader #1 for port 41187] org.apache.hadoop.ipc.Server: Unable to read call parameters for client 10.17.242.22on connection protocol org.apache.hadoop.mapred.TaskUmbilicalProtocol for rpcKind RPC_WRITABLE
java.lang.ArrayIndexOutOfBoundsException: 23
	at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.readFields(FrameworkCounterGroup.java:261)
	at org.apache.hadoop.mapred.Counters$Group.readFields(Counters.java:324)
	at org.apache.hadoop.mapreduce.counters.AbstractCounters.readFields(AbstractCounters.java:306)
	at org.apache.hadoop.mapred.TaskStatus.readFields(TaskStatus.java:489)
	at org.apache.hadoop.mapred.MapTaskStatus.readFields(MapTaskStatus.java:88)
	at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:285)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invocation.readFields(WritableRpcEngine.java:160)
	at org.apache.hadoop.ipc.Server$Connection.processRpcRequest(Server.java:1909)
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1841)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1600)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:820)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:693)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:664)
{code}
"
MAPREDUCE-6921,TestUmbilicalProtocolWithJobToken#testJobTokenRpc fails,"The test fails consistently without the error below :
{code}
java.lang.ExceptionInInitializerError: null
	at org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken.<clinit>(TestUmbilicalProtocolWithJobToken.java:76)
{code}
"
MAPREDUCE-6918,ShuffleMetrics.ShuffleConnections Gauge Metric Climbs Infinitely,"We recently noticed that the {{mapred.ShuffleMetrics.ShuffleConnections}} metric seems to climb infinitely, up to many millions (see attached graph), despite being supposedly a gauge measure of the number of open connections:
{code:title=ShuffleHandler.java}
    @Metric(""# of current shuffle connections"")
        MutableGaugeInt shuffleConnections;
{code}

It seems that shuffleConnections gets incremented once for every map fetched, but only decremented once for every request. It seems to me it should be modified to only be incremented once for every request rather than for every map fetched, but I'm not familiar with the original intent."
MAPREDUCE-6914,Tests use assertTrue(....equals(...)) instead of assertEquals(),
MAPREDUCE-6911,TestMapreduceConfigFields.testCompareXmlAgainstConfigurationClass fails consistently,"{noformat}
mapred-default.xml has 2 properties missing in  interface org.apache.hadoop.mapreduce.MRJobConfig  interface org.apache.hadoop.mapreduce.MRConfig  class org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig  class org.apache.hadoop.mapred.ShuffleHandler  class org.apache.hadoop.mapreduce.lib.output.FileOutputFormat  class org.apache.hadoop.mapreduce.lib.input.FileInputFormat  class org.apache.hadoop.mapreduce.Job  class org.apache.hadoop.mapreduce.lib.input.NLineInputFormat  class org.apache.hadoop.mapred.JobConf  class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter

  mapreduce.jobtracker.system.dir
  mapreduce.jobtracker.staging.root.dir
{noformat}"
MAPREDUCE-6910,MapReduceTrackingUriPlugin can not return the right URI of history server with HTTPS,"When the {{MapReduceTrackingUriPlugin}} enabled, the URI requests from proxy server or RM UI which are also out of {{yarn.resourcemanager.max-completed-applications}} should be redirect to the history server URI.
But when I access a HTTPS history server with the properties: 
{quote}
    <property>
        <name>mapreduce.jobhistory.http.policy</name>
        <value>HTTPS_ONLY</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.https.address</name>
        <value>history.example.com:12345</value>
    </property>
{quote}

The {{MapReduceTrackingUriPlugin}} still returns a default HTTP URI:
{{http://0.0.0.0:19888}}
or
{{http://history.example.com:67890}}
if {{mapreduce.jobhistory.webapp.address}} is engaged at same time.
{quote}
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>history.example.com:67890</value>
    </property>
{quote}"
MAPREDUCE-6909,LocalJobRunner fails when run on a node from multiple users,"MAPREDUCE-5762 removed mapreduce.jobtracker.staging.root.dir from mapred-default.xml but the property is still being used by LocalJobRunner and the code default value does *not* match the value that was removed from mapred-default.xml.  This broke the use case where multiple users are running local mode jobs on the same node, since they now default to the same directory in /tmp."
MAPREDUCE-6908,Remove Superfluous Collection Allocations From CombineFileInputFormat,"Remove superfluous collection creations from {{org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat<K, V>}}

Use {{StringBuilder}} instead of synchronized {{StringBuffer}}"
MAPREDUCE-6905,Fix meaningless operations in TestDFSIO in some situation.,"When run TestDFSIO in write mode with 2 million nrFiles, it will *takes hours* to create control files and get IOException as last because of directory item limit is exceeded. And, it will leave over 1 million useless files which will be deleted when run TestDFSIO again with acceptable nrFiles.   
{quote}
17/06/21 09:12:16 INFO fs.TestDFSIO: creating control file: 1024 bytes, 2000000 files
java.io.IOException: The directory item limit of /benchmarks/TestDFSIO/io_control is exceeded: limit=1048576 items=1048576
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxDirItems(FSDirectory.java:2033)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addChild(FSDirectory.java:2084)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:2053)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1873)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addFile(FSDirectory.java:327)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2750)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2632)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2520)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:579)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2036)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1656)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2034)
	at org.apache.hadoop.fs.TestDFSIO.createControlFile(TestDFSIO.java:302)
	at org.apache.hadoop.fs.TestDFSIO.run(TestDFSIO.java:751)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.fs.TestDFSIO.main(TestDFSIO.java:650)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:118)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:126)
{quote}

In brief, we'd better check the parameter of nrFiles before it waste our time and hurt our feelings."
MAPREDUCE-6904,HADOOP_JOB_HISTORY_OPTS should be HADOOP_JOB_HISTORYSERVER_OPTS in mapred-config.sh,"After HADOOP-13341, {{HADOOP_JOB_HISTORY_OPTS}} is deprecated in favor of {{MAPRED_HISTORYSERVER_OPTS}}, but still works.  However, the property is actually supposed to be {{HADOOP_JOB_HISTORYSERVER_OPTS}}."
MAPREDUCE-6898,TestKill.testKillTask is flaky,"TestKill.testKillTask() can fail if the async dispatcher thread is slower than the test's thread.

{noformat}
2017-05-26 11:43:26,532 INFO  [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(1006)) - job_0_0000Job Transitioned from INITED to SETUP
Job State is : RUNNING
Job State is : RUNNING Waiting for state : SUCCEEDED   map progress : 0.0   reduce progress : 0.0
2017-05-26 11:43:26,538 INFO  [CommitterEvent Processor #0] commit.CommitterEventHandler (CommitterEventHandler.java:run(231)) - Processing the event EventType: JOB_SETUP
2017-05-26 11:43:26,540 INFO  [AsyncDispatcher event handler] impl.TaskImpl (TaskImpl.java:handle(661)) - task_0_0000_m_000000 Task Transitioned from NEW to KILLED
2017-05-26 11:43:26,540 ERROR [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(998)) - Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SETUP
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:996)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:138)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1366)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1362)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:182)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)
	at java.lang.Thread.run(Thread.java:745)
2017-05-26 11:43:26,541 INFO  [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(1006)) - job_0_0000Job Transitioned from SETUP to ERROR
2017-05-26 11:43:26,542 INFO  [AsyncDispatcher event handler] app.MRAppMaster (MRAppMaster.java:serviceStop(978)) - Skipping cleaning up the staging dir. assuming AM will be retried.
{noformat}

We have to wait until the job's internal state is {{JobInternalState.RUNNING}} and not {{JobInternalState.SETUP}}."
MAPREDUCE-6897,Add Unit Test to make sure Job end notification get sent even appMaster stop get YarnRuntimeException,"In MAPREDUCE-6895, we fix the issue that Job end notification not send due to YarnRuntimeException throw in appMaster stop. We need to add unit test to make sure we won't run into the same issue again in future."
MAPREDUCE-6896,Document wrong spelling in usage of MapredTestDriver tools.,"When the user run performance test of MapredTestDriver, a spelling mistake seems exposed to user: 
{quote}
./hadoop org.apache.hadoop.test.MapredTestDriver
An example program must be given as the first argument.
Valid program names are:
......
timelineperformance: A job that launches mappers to test *timline* service performance.
{quote}"
MAPREDUCE-6895,Job end notification not send due to YarnRuntimeException,"MRAppMaster.this.stop() throw out YarnRuntimeException as below log shows, it caused job end notification not send.
{quote}
2017-05-24 12:14:02,165 WARN [Thread-693] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Graceful stop failed
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:531)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:360)
        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
        at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
        at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
        at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)
        at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1476)
        at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1090)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:554)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$1.run(MRAppMaster.java:605)
Caused by: java.nio.channels.ClosedChannelException
        at org.apache.hadoop.hdfs.DFSOutputStream.checkClosed(DFSOutputStream.java:1528)
        at org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:98)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:58)
        at java.io.DataOutputStream.write(DataOutputStream.java:107)
        at org.codehaus.jackson.impl.Utf8Generator._flushBuffer(Utf8Generator.java:1754)
        at org.codehaus.jackson.impl.Utf8Generator.flush(Utf8Generator.java:1088)
        at org.apache.avro.io.JsonEncoder.flush(JsonEncoder.java:67)
        at org.apache.hadoop.mapreduce.jobhistory.EventWriter.write(EventWriter.java:67)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$MetaInfo.writeEvent(JobHistoryEventHandler.java:886)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:520)
        ... 11 more
2017-05-24 12:14:02,165 INFO [Thread-693] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Exiting MR AppMaster..GoodBye!
{quote}"
MAPREDUCE-6894,License error in TestMRCredentials.java,license is not at the top of the class.
MAPREDUCE-6892,Issues with the count of failed/killed tasks in the jhist file,"Recently we encountered some issues with the value of failed tasks. After parsing the jhist file, {{JobInfo.getFailedMaps()}} returned 0, but actually there were failures. 

Another minor thing is that you cannot get the number of killed tasks (although this can be calculated).

The root cause is that {{JobUnsuccessfulCompletionEvent}} contains only the successful map/reduce task counts. Number of failed (or killed) tasks are not stored."
MAPREDUCE-6891,TextInputFormat: duplicate records with custom delimiter,"When using a custom delimiter for TextInputFormat, the resulting blocks are not correct under some circumstances. It happens that the total number of records is wrong and some entries are duplicated.

I have created a reproducible test case: 

Generate a File
{code:bash}
for i in $(seq 1 10000000); do 
  echo -n $i >> long_delimiter-1to10000000-with_newline.txt;
  echo ""--------------------------------------------"" >> long_delimiter-1to10000000-with_newline.txt; 
done
{code} 

Java-Test to reproduce the error
{code:java}
public static void longDelimiterBug(JavaSparkContext sc) {
	Configuration hadoopConf = new Configuration();
	String delimitedFile = ""long_delimiter-1to10000000-with_newline.txt"";
	hadoopConf.set(""textinputformat.record.delimiter"", ""--------------------------------------------\n"");
	JavaPairRDD<LongWritable, Text> input = sc.newAPIHadoopFile(delimitedFile, TextInputFormat.class,
			LongWritable.class, Text.class, hadoopConf);

	List<String> values = input.map(t -> t._2.toString()).collect();

	Assert.assertEquals(10000000, values.size());
	for (int i = 0; i < 10000000; i++) {
		boolean correct = values.get(i).equals(Integer.toString(i + 1));
		if (!correct) {
			logger.error(""Wrong value for index {}: expected {} -> got {}"", i, i + 1, values.get(i));
		} else {
			logger.info(""Correct value for index {}: expected {} -> got {}"", i, i + 1, values.get(i));
		}
		Assert.assertTrue(correct);
	}
}
{code}

This example fails with the error 
{quote}
java.lang.AssertionError: expected:<10000000> but was:<10042616>
{quote}

when commenting out the Assert about the size of the collection, my log output ends like this: 
{quote}
[main] INFO  edu.udo.cs.schaefer.testspark.Main  - Correct value for index 663244: expected 663245 -> got 663245
[main] ERROR edu.udo.cs.schaefer.testspark.Main  - Wrong value for index 663245: expected 663246 -> got 660111
{quote}

After the the wrong value for index 663245 the values are sorted again an a continuing with 660112, 660113, ....

The error is not reproducible with _\n_ as delimiter, i.e. when not using a custom delimiter. "
MAPREDUCE-6890,Backport MAPREDUCE-6304 to branch 2.7: Specifying node labels when submitting MR jobs,As per discussussion in [mailling list|http://mail-archives.apache.org/mod_mbox/hadoop-mapreduce-dev/201705.mbox/browser] backport MAPREDUCE-6304 to branch-2.7. 
MAPREDUCE-6889,Add Job#close API to shutdown MR client services.,"ATS1.5 uses FileSystemTimelineWriter which creates FS object on every writer initialization. If writer is not closed, then there is possibility of OOM see YARN-5438 fixes closing FS object. 

TimelineClient is used by YarnClient. So all the user who uses YarnClient with ATS1.5 need to stop service properly. Otherwise there is big chance of FS object leak. 

Of course MR uses YARN client submit job. If MR do not stop YarnClient then there is FS object leak. 

JobClient provides a API to stop all these service using *JobClient#close*. But many MR clients uses *Job* object to submit a job. But  do not stop started services by default. 

So, provide a API *Job#close* to shutdown MR client services. This API can be utilized by caller explicitly to stop service which avoids FS leak. "
MAPREDUCE-6887,Modifier 'static' is redundant for inner enums,"  Java enumeration type is a static constant, implicitly modified with static final,Modifier 'static' is redundant for inner enums less.So I suggest deleting the 'static' modifier."
MAPREDUCE-6886,Job History File Permissions configurable,Currently the mapreduce job history files are written with 770 permissions which can be accessed by job user or other user part of hadoop group. Customers has users who are not part of the hadoop group but want to access these history files. We can make it configurable like 770 (Strict) or 755 (All) permissions with default 770.
MAPREDUCE-6883,AuditLogger and TestAuditLogger are dead code,The {{AuditLogger}} and {{TestAuditLogger}} classes appear to be dead code.  I can't find anything that uses or references {{AuditLogger}}.  No one has touched the code 2011.  I think it's safe to remove.
MAPREDUCE-6882,Increase MapReduce test timeouts from 1 second to 10 seconds,1 second test timeouts are susceptible to failure on overloaded or otherwise slow machines
MAPREDUCE-6881,Fix warnings from Spotbugs in hadoop-mapreduce,Fix warnings from Spotbugs in hadoop-mapreduce since switched from findbugs to spotbugs.
MAPREDUCE-6879,TestDFSIO#sequentialTest throws java.lang.NullPointerException due to uninitialized IOStream,"When I use {color:red} -seq {color} arg to write files, TestDFSIO#sequentialTest throws java.lang.NullPointerException due to uninitialized stream inherited from IOMapperBase:

{code}
[root@7b65290f2609 hadoop-3.0.0-alpha3-SNAPSHOT]# bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha3-SNAPSHOT-tests.jar TestDFSIO -seq -write
2017-04-20 15:50:43,505 INFO fs.TestDFSIO: TestDFSIO.1.8
2017-04-20 15:50:43,510 INFO fs.TestDFSIO: nrFiles = 1
2017-04-20 15:50:43,510 INFO fs.TestDFSIO: nrBytes (MB) = 1.0
2017-04-20 15:50:43,510 INFO fs.TestDFSIO: bufferSize = 1000000
2017-04-20 15:50:43,510 INFO fs.TestDFSIO: baseDir = /benchmarks/TestDFSIO
2017-04-20 15:50:43,655 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
java.lang.NullPointerException
	at org.apache.hadoop.fs.TestDFSIO$WriteMapper.doIO(TestDFSIO.java:427)
	at org.apache.hadoop.fs.TestDFSIO$WriteMapper.doIO(TestDFSIO.java:395)
	at org.apache.hadoop.fs.TestDFSIO.sequentialTest(TestDFSIO.java:722)
	at org.apache.hadoop.fs.TestDFSIO.run(TestDFSIO.java:846)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:90)
	at org.apache.hadoop.fs.TestDFSIO.main(TestDFSIO.java:731)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:136)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:144)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
{code}"
MAPREDUCE-6875,Rename mapred-site.xml.template to mapred-site.xml,mapred-site.xml file needs a license.
MAPREDUCE-6874,Make DistributedCache check if the content of a directory has changed,"DistributedCache does not check recursively if the content a directory has changed when adding files to it with {{DistributedCache.addCacheFile()}}. 

h5. Background
I have an Oozie workflow on HDFS:
{code}
example_workflow
├── job.properties
├── lib
│   ├── components
│   │   ├── sub-component.sh
│   │   └── subsub
│   │       └── subsub.sh
│   ├── main.sh
│   └── sub.sh
└── workflow.xml
{code}
Executed the workflow; then made some changes in {{subsub.sh}}. Replaced the file on HDFS. When I re-ran the workflow, DistributedCache did not notice the changes as the timestamp on the {{components}} directory did not change. As a result, the old script was materialized.

This behaviour might be related to [determineTimestamps() |https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/filecache/ClientDistributedCacheManager.java#L84].
In order to use the new script during workflow execution, I had to update the whole {{components}} directory.


h6. Some more info:
In Oozie, [DistributedCache.addCacheFile() |https://github.com/apache/oozie/blob/master/core/src/main/java/org/apache/oozie/action/hadoop/JavaActionExecutor.java#L625] is used to add files to the distributed cache."
MAPREDUCE-6873,MR Job Submission Fails if MR framework application path not on defaultFS,"{{JobSubmitter#addMRFrameworkPathToDistributedCache()}} assumes that {{mapreduce.framework.application.path}} has a FS which matches {{fs.defaultFS}} which may not always be true. This is just a consequence of using {{FileSystem.get(Configuration)}} instead of {{FileSystem.get(URI, Configuration)}}. "
MAPREDUCE-6871,Allow users to specify racks and nodes for strict locality for AMs,"YARN-6050 fixed the YARN API to allow multiple {{ResourceRequest}}'s when submitting an AM so that you can actually do rack or node locality.  We should allow MapReduce users to take advantage of this by exposing this functionality in some way.  The raw YARN API allows for a lot of flexibility (e.g. different resources per request, etc), but we don't necessarily want to allow the user to do too much here so they don't shoot themselves in the foot and we don't make this overly complicated.  

I propose we allow users to specify racks and nodes for strict locality.  This would allow users to restrict an MR AM to specific racks and/or nodes.  We could add a new property, {{mapreduce.job.am.resource-request.strict.locality}}, which takes a comma-separated list of entries like:
- {{/<rack>}}
- {{/<rack>/<node>}}
- {{<node>}} (assumes /default-rack)

MapReduce would then use this information to create the corresponding {{ResourceRequest}}'s.  

For example, {{mapreduce.job.am.resource-request.strict.locality=/rack1/node1}} would create the following {{ResourceRequest}}'s:
- resourceName=ANY, relaxLocality=false, capability=<X,Y>
- resourceName=/rack1, relaxLocality=false, capability=<X,Y>
- resourceName=node1, relaxLocality=true, capability=<X,Y>

By default, the property would be unset, and you'd get the normal {{ANY}} {{ResourceRequest}}."
MAPREDUCE-6870,Add configuration for MR job to finish when all reducers are complete (even with unfinished mappers),"Even with MAPREDUCE-5817, there could still be cases where mappers get scheduled before all reducers are complete, but those mappers run for long time, even after all reducers are complete. This could hurt the performance of large MR jobs.

In some cases, mappers don't have any materialize-able outcome other than providing intermediate data to reducers. In that case, the job owner should have the config option to finish the job once all reducers are complete."
MAPREDUCE-6869,org.apache.hadoop.mapred.ShuffleHandler: Shuffle error in populating headers :,"nodemanager log
2017-03-25 21:07:03,071 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error in populating headers :
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find usercache/master/appcache/application_1489067586592_930490/output/attempt_1489067586592_930490_m_002811_0/file.out.index in any of the configured local directories
        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:488)
        at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:165)
        at org.apache.hadoop.mapred.ShuffleHandler$Shuffle.getMapOutputInfo(ShuffleHandler.java:1000)
        at org.apache.hadoop.mapred.ShuffleHandler$Shuffle.populateHeaders(ShuffleHandler.java:1022)
        at org.apache.hadoop.mapred.ShuffleHandler$Shuffle.messageReceived(ShuffleHandler.java:908)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)
        at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:142)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)
        at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:148)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)
        at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
        at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)
        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
        at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
        at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)
        at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:555)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
        at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
        at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)
        at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)
        at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)
        at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
        at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
        at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)


reduce log
2017-03-25 05:40:33,919 WARN [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Invalid map id 
java.lang.IllegalArgumentException: TaskAttemptId string : TTP/1.1 500 Internal Server Error
Content-Type: text/plain; charset=UTF is not properly formed
	at org.apache.hadoop.mapreduce.TaskAttemptID.forName(TaskAttemptID.java:201)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:485)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)"
MAPREDUCE-6868,License check for jdiff output files should be ignored,"The following commits added jdiff output for Hadoop 2.8.0 but ASF license header is missing.
* https://github.com/apache/hadoop/commit/6df029db36412b7219b64313dcbe1874dc1c8b0c
* https://github.com/apache/hadoop/commit/d174c06b01e1f743d3111b9b760a9824d8106b86

hadoop-mapreduce-project module does not have a setting to ignore the jdiff output files, so the license check fails."
MAPREDUCE-6866,Fix getNumMapTasks() documentation in JobConf,"The original description of the getNumMapTasks() method in JobConf was invalid, because it referenced to the number of reducer tasks instead of the map tasks.

 from: Get configured the number of reduce tasks for this job.
  to: Get the configured number of map tasks for this job.

It was maybe the result of a tricky copy-paste ;-)

Github PR: https://github.com/apache/hadoop/pull/205"
MAPREDUCE-6865,Fix typo in javadoc for DistributedCache ,"There are some typos in the javadoc for DistributedCache. For example:

{{DistributedCache.addCacheArchive(new URI(""/myapp/map.zip"", job);}}
should be
{{DistributedCache.addCacheArchive(new URI(""/myapp/map.zip""), job);}}"
MAPREDUCE-6862,Fragments are not handled correctly by resource limit checking,"If a user specifies a fragment for a libjar, files, archives path via generic options parser and resource limit checking is enabled, the client crashes with a FileNotFoundException:
{noformat}
java.io.FileNotFoundException: File file:/home/mapred/test.txt#testFrag.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:638)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:864)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:628)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:442)
	at org.apache.hadoop.mapreduce.JobResourceUploader.getFileStatus(JobResourceUploader.java:413)
	at org.apache.hadoop.mapreduce.JobResourceUploader.explorePath(JobResourceUploader.java:395)
	at org.apache.hadoop.mapreduce.JobResourceUploader.checkLocalizationLimits(JobResourceUploader.java:304)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:103)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1892)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1362)
	at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)
	at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
{noformat}"
MAPREDUCE-6861,Add metrics tags for ShuffleClientMetrics,Metrics tags were unintentionally removed by MAPREDUCE-6526. Let's add them back.
MAPREDUCE-6860,User intermediate-done-dir permissions should use history permissions configuration,
MAPREDUCE-6859,hadoop-mapreduce-client-jobclient.jar sets a main class that isn't in the JAR,"The manifest for hadoop-mapreduce-client-jobclient.jar points to {{org.apache.hadoop.test.MapredTestDriver}}, which is in the test JAR.  Without the test JAR in the class path, running the jobclient JAR will fail with a class not found exception."
MAPREDUCE-6856,TestRecovery.testSpeculative fails if testCrashed fails,"The test {{testSpeculative}} in {{org.apache.hadoop.mapreduce.v2.app.TestRecovery}} is unstable.

Based on my findings, the test itself is not problematic. It only fails if {{testCrashed}} in the same class fails before it.

The reason is not completely clear to me, but I whenever I explicitly stop the MRAppMaster in {{testCrashed}} in a finally block, then the issue disappears. I think the reason is that both tests uses the same folder for staging.

Solution: wrap logic in {{testCrashed}} in a try-finally block and then stop the MRAppMaster."
MAPREDUCE-6855,Specify charset when create String in CredentialsTestJob,"{code}
      String secretValueStr = new String (secretValue);
{code}
should be
{code}
      String secretValueStr = new String(secretValue, StandardCharsets.UTF_8);
{code}"
MAPREDUCE-6852,Job#updateStatus() failed with NPE due to race condition,"Like MAPREDUCE-6762, we found this issue in a cluster where Pig query occasionally failed on NPE - ""Pig uses JobControl API to track MR job status, but sometimes Job History Server failed to flush job meta files to HDFS which caused the status update failed."" Beside NPE in o.a.h.mapreduce.Job.getJobName, we also get NPE in Job.updateStatus() and the exception is as following:
{noformat}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:323)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:320)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1833)
	at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:320)
	at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:604)
{noformat}
We found state here is null. However, we already check the job state to be RUNNING as code below:
{noformat}
  public boolean isComplete() throws IOException {
    ensureState(JobState.RUNNING);
    updateStatus();
    return status.isJobComplete();
  }
{noformat}
The only possible reason here is two threads are calling here for the same time: ensure state first, then one thread update the state to null while the other thread hit NPE issue here.
We should fix this NPE exception."
MAPREDUCE-6850,Shuffle Handler keep-alive connections are closed from the server side,"When performance testing tez shuffle handler (TEZ-3334), it was noticed the keep-alive connections are closed from the server-side. The client silently recovers and logs the connection as keep-alive, despite reestablishing a connection. This jira aims to remove the close from the server side, fixing the bug preventing keep-alive connections."
MAPREDUCE-6847,Job history server should release jobs from cache after a fixed duration,"We found history server is consuming a lot of memory when there are large jobs (with more than 100k of tasks in a single job). Currently JHS cache only evicts entries with size, it's better to add the time expiration as well to reduce heap usage if job has no one accessing for sometime."
MAPREDUCE-6846,Fragments specified for libjar paths are not handled correctly,"If a user specifies a fragment for a libjars path via generic options parser, the client crashes with a FileNotFoundException:
{noformat}
java.io.FileNotFoundException: File file:/home/mapred/test.txt#testFrag.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:638)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:864)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:628)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:442)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:363)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:314)
	at org.apache.hadoop.mapreduce.JobResourceUploader.copyRemoteFiles(JobResourceUploader.java:387)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadLibJars(JobResourceUploader.java:154)
	at org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:105)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:102)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:197)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1344)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1892)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1341)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1362)
	at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)
	at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:359)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:367)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:239)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:153)
{noformat}

This is actually inconsistent with the behavior for files and archives. Here is a table showing the current behavior for each type of path and resource:
| || Qualified path (i.e. file://home/mapred/test.txt#frag.txt) || Absolute path (i.e. /home/mapred/test.txt#frag.txt) || Relative path (i.e. test.txt#frag.txt) ||
|| -libjars | FileNotFound | FileNotFound|FileNotFound|
|| -files | (/) | (/) | (/) |
|| -archives | (/) | (/) | (/) |"
MAPREDUCE-6845,"Job history server requires admin permission when accessing container log in secure environment, which is not correct","A typical url of container log in job history server is like this:
{code}
http://{job history server address}:19888/jobhistory/logs/{node manager address}:{port}/{container id}/{entity id}/{app owner}
{code}
When accessing it in secure environment, it requires authorization.
Because the parent path {{/logs}} has {{AdminAuthorizedServlet}} defined in {{HttpServer2.java}}, the container log url will execute AdminAuthorizedServlet  in the servlet chain and requires admin permission, which is wrong.
The container log url has it own authorization mechanism, besides, If the user is the owner of the container but it doesn't belong to admins, then the user will not be allowed to access the container log url, and it is not reasonable.

There are two ways to fix this defect:
* change the parent path of container log url, for example, use ""/clogs"" instead of ""/logs""
* stop executing {{AdminAuthorizedServlet}} when accessing the child path of ""/logs"" in job history server.
"
MAPREDUCE-6842,Update the links in PiEstimator document,"In the package-info.html, There are links to 
* http://developer.yahoo.net/blogs/hadoop/2009/05/hadoop_sorts_a_petabyte_in_162.html
* http://developer.yahoo.net/blogs/hadoop/2009/05/hadoop_computes_the_10151st_bi.html

The pages were moved to
* http://yahoohadoop.tumblr.com/post/98338791001/hadoop-sorts-a-petabyte-in-1625-hours-and-a
* http://yahoohadoop.tumblr.com/post/98338598026/hadoop-computes-the-10-15-1st-bit-of-%CF%80"
MAPREDUCE-6841,Fix dead link in MapReduce tutorial document,"{noformat:title=MapReduceTutorial.md}
([FileOutputFormat.setOutputPath(Path)](../../api/org/apache/hadoop/mapreduce/lib/input/FileOutputFormat.html)).
{noformat}
input should be output."
MAPREDUCE-6839,TestRecovery.testCrashed failed,"TestRecovery#testCrashed is a flaky test.

Error Message: 
Reduce Task state not correct expected:<RUNNING> but was:<SCHEDULED>

Stack Trace:
java.lang.AssertionError: Reduce Task state not correct expected:<RUNNING> but was:<SCHEDULED> 
        at org.junit.Assert.fail(Assert.java:88) 
        at org.junit.Assert.failNotEquals(Assert.java:743) 
        at org.junit.Assert.assertEquals(Assert.java:118) 
        at org.apache.hadoop.mapreduce.v2.app.TestRecovery.testCrashed(TestRecovery.java:164)"
MAPREDUCE-6838,[ATSv2 Security] Add timeline delegation token received in allocate response to UGI,
MAPREDUCE-6836,exception thrown when accessing the job configuration web UI,"When I navigate the MR job web UI and click the configuration link, the AM shows an exception:
{noformat}
2017-01-25 11:40:55,521 ERROR [qtp2126664214-26] org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /mapreduc
e/conf/job_1485372765455_0002
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:162)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
        at com.google.inject.servlet.ServletDefinition.doServiceImpl(ServletDefinition.java:287)
        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:277)
        at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:182)
        at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:85)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:941)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:82)
        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:119)
        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:133)
        at com.google.inject.servlet.GuiceFilter$1.call(GuiceFilter.java:130)
        at com.google.inject.servlet.GuiceFilter$Context.call(GuiceFilter.java:203)
        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:130)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
        at org.apache.hadoop.security.http.XFrameOptionsFilter.doFilter(XFrameOptionsFilter.java:57)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
        at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:179)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
        at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1458)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
        at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)
        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
        at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
        at org.eclipse.jetty.server.Server.handle(Server.java:524)
        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:319)
        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:253)
        at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)
        at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)
        at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
        at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.yarn.webapp.WebAppException: Error rendering block: nestLevel=6 expected 5
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:72)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:79)
        at org.apache.hadoop.yarn.webapp.View.render(View.java:235)
        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:49)
        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:848)
        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:71)
        at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:82)
        at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:212)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.conf(AppController.java:323)
        ... 52 more
{noformat}

The web page itself renders fine."
MAPREDUCE-6831,Flaky test TestJobImpl.testKilledDuringKillAbort,"The test case TestJobImpl.testKilledDuringKillAbort() is flaky.

Example of a failure:

{noformat:title=Error Message}
expected:<SETUP> but was:<RUNNING>
{noformat}
{noformat:title=Stack Trace}
java.lang.AssertionError: expected:<SETUP> but was:<RUNNING>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.assertJobState(TestJobImpl.java:978)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.testKilledDuringKillAbort(TestJobImpl.java:516)
{noformat}
{noformat:title=Standard Output}
2016-12-12 00:26:29,724 INFO  [Thread-12] event.AsyncDispatcher (AsyncDispatcher.java:register(202)) - Registering class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventType for class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler
2016-12-12 00:26:29,729 INFO  [Thread-12] event.AsyncDispatcher (AsyncDispatcher.java:register(202)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobEventType for class org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl$StubbedJob
2016-12-12 00:26:29,729 INFO  [Thread-12] event.AsyncDispatcher (AsyncDispatcher.java:register(202)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.TaskEventType for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$2a4993a5
2016-12-12 00:26:29,730 INFO  [Thread-12] event.AsyncDispatcher (AsyncDispatcher.java:register(202)) - Registering class org.apache.hadoop.mapreduce.jobhistory.EventType for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$2a4993a5
2016-12-12 00:26:29,730 INFO  [Thread-12] event.AsyncDispatcher (AsyncDispatcher.java:register(202)) - Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.yarn.event.EventHandler$$EnhancerByMockitoWithCGLIB$$2a4993a5
2016-12-12 00:26:29,730 INFO  [Thread-12] impl.JobImpl (JobImpl.java:setup(1523)) - Adding job token for job_1234567890000_0001 to jobTokenSecretManager
2016-12-12 00:26:29,731 WARN  [Thread-12] impl.JobImpl (JobImpl.java:setup(1529)) - Shuffle secret key missing from job credentials. Using job token secret as shuffle secret.
2016-12-12 00:26:29,733 INFO  [Thread-12] impl.JobImpl (JobImpl.java:makeUberDecision(1294)) - Not uberizing job_1234567890000_0001 because: not enabled;
2016-12-12 00:26:29,734 INFO  [Thread-12] impl.JobImpl (JobImpl.java:createMapTasks(1551)) - Input size for job job_1234567890000_0001 = 0. Number of splits = 2
2016-12-12 00:26:29,734 INFO  [Thread-12] impl.JobImpl (JobImpl.java:createReduceTasks(1568)) - Number of reduces for job job_1234567890000_0001 = 1
2016-12-12 00:26:29,734 INFO  [Thread-12] impl.JobImpl (JobImpl.java:handle(1006)) - job_1234567890000_0001Job Transitioned from NEW to INITED
2016-12-12 00:26:29,736 INFO  [CommitterEvent Processor #0] commit.CommitterEventHandler (CommitterEventHandler.java:run(231)) - Processing the event EventType: JOB_SETUP
2016-12-12 00:26:29,737 INFO  [Thread-12] impl.JobImpl (JobImpl.java:handle(1006)) - job_1234567890000_0001Job Transitioned from INITED to SETUP
2016-12-12 00:26:29,738 INFO  [AsyncDispatcher event handler] impl.JobImpl (JobImpl.java:handle(1006)) - job_1234567890000_0001Job Transitioned from SETUP to RUNNING
{noformat}

Reproduction: insert a {{Thread.sleep(50);}} after {{job.handle(new JobStartEvent(jobId));}}"
MAPREDUCE-6829,Add peak memory usage counter for each task,"Each task has counters PHYSICAL_MEMORY_BYTES and VIRTUAL_MEMORY_BYTES, which are snapshots of memory usage of that task. They are not sufficient for users to understand peak memory usage by that task, e.g. in order to diagnose task failures, tune job parameters or change application design. This new feature will add two more counters for each task: PHYSICAL_MEMORY_BYTES_MAX and VIRTUAL_MEMORY_BYTES_MAX.

This JIRA has the same feature from MAPREDUCE-4710.  I file this new YARN JIRA since MAPREDUCE-4710 is pretty old one from MR 1.x era, it more or less assumes a branch-1 architecture, should be close at this point."
MAPREDUCE-6827,Failed to traverse Iterable values the second time in reduce() method,"Failed to traverse Iterable values the second time in reduce() method

The following code is a reduce() method (of WordCount):
{code:title=WordCount.java|borderStyle=solid}
	public static class WcReducer extends Reducer<Text, IntWritable, Text, IntWritable> {

		@Override
		protected void reduce(Text key, Iterable<IntWritable> values, Context context)
				throws IOException, InterruptedException {

			// print some logs
			List<String> vals = new LinkedList<>();
			for(IntWritable i : values) {
				vals.add(i.toString());
			}
			System.out.println(String.format("">>>> reduce(%s, [%s])"",
					key, String.join("", "", vals)));

			// sum of values
			int sum = 0;
			for(IntWritable i : values) {
				sum += i.get();
			}
			System.out.println(String.format("">>>> reduced(%s, %s)"",
					key, sum));
			
			context.write(key, new IntWritable(sum));
		}			
	}
{code}
After running it, we got the result that all sums were zero!

After debugging, it was found that the second foreach-loop was not executed, and the root cause was the returned value of Iterable.iterator(), it returned the same instance in the two calls called by foreach-loop. In general, Iterable.iterator() should return a new instance in each call, such as ArrayList.iterator().

"
MAPREDUCE-6826,Job fails with InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED/COMMITTING,"This happens if a container is preempted by scheduler after job starts committing.
And this exception in turn leads to application being marked as FAILED in YARN.
I think we can probably ignore JOB_TASK_COMPLETED event while JobImpl state is COMMITTING or SUCCEEDED as job is in the process of finishing.
Also is there any point in attempting to scheduler another task attempt if job is already in COMMITTING or SUCCEEDED state.

{noformat}
2016-12-23 09:10:38,642 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1482404625971_23910_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2016-12-23 09:10:38,642 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 5
2016-12-23 09:10:38,643 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1482404625971_23910Job Transitioned from RUNNING to COMMITTING
2016-12-23 09:10:38,644 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_e55_1482404625971_23910_01_000010 taskAttempt attempt_1482404625971_23910_m_000004_1
2016-12-23 09:10:38,644 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1482404625971_23910_m_000004_1
2016-12-23 09:10:38,644 INFO [ContainerLauncher #5] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : linux-19:26009
2016-12-23 09:10:38,644 INFO [CommitterEvent Processor #4] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2016-12-23 09:10:38,724 INFO [IPC Server handler 0 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1482404625971_23910_m_60473139527690 asked for a task
2016-12-23 09:10:38,724 INFO [IPC Server handler 0 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1482404625971_23910_m_60473139527690 is invalid and will be killed.
2016-12-23 09:10:38,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2016-12-23 09:10:38,797 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1482404625971_23910Job Transitioned from COMMITTING to SUCCEEDED
2016-12-23 09:10:38,798 INFO [Thread-93] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Job finished cleanly, recording last MRAppMaster retry
2016-12-23 09:10:38,798 INFO [Thread-93] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2016-12-23 09:10:38,798 INFO [Thread-93] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2016-12-23 09:10:38,799 INFO [Thread-93] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2016-12-23 09:10:38,799 INFO [Thread-93] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2016-12-23 09:10:38,799 INFO [Thread-93] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2016-12-23 09:10:38,800 INFO [Thread-93] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 1
2016-12-23 09:10:38,989 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:8 ContRel:0 HostLocal:0 RackLocal:0
2016-12-23 09:10:38,993 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_e55_1482404625971_23910_01_000010
2016-12-23 09:10:38,993 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:8 ContRel:0 HostLocal:0 RackLocal:0
2016-12-23 09:10:38,993 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1482404625971_23910_m_000004_1: Container preempted by scheduler
2016-12-23 09:10:38,994 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_1 TaskAttempt Transitioned from SUCCEEDED to KILLED
2016-12-23 09:10:38,995 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1482404625971_23910_m_000004 Task Transitioned from SUCCEEDED to SCHEDULED
2016-12-23 09:10:38,996 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_2 TaskAttempt Transitioned from NEW to UNASSIGNED
2016-12-23 09:10:39,044 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:8 ContRel:0 HostLocal:0 RackLocal:0
2016-12-23 09:10:39,050 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1482404625971_23910: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:0, vCores:0> knownNMs=11
2016-12-23 09:10:40,053 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 1
2016-12-23 09:10:40,055 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_e55_1482404625971_23910_01_000011 to attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:40,055 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:1 AssignedReds:0 CompletedMaps:5 CompletedReds:0 ContAlloc:9 ContRel:0 HostLocal:0 RackLocal:0
2016-12-23 09:10:40,056 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_2 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2016-12-23 09:10:40,056 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for container container_e55_1482404625971_23910_01_000011 taskAttempt attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:40,056 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:40,056 INFO [ContainerLauncher #6] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : linux-17:26009
2016-12-23 09:10:40,068 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1482404625971_23910_m_000004_2 : 26008
2016-12-23 09:10:40,074 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1482404625971_23910_m_000004_2] using containerId: [container_e55_1482404625971_23910_01_000011 on NM: [linux-17:26009]
2016-12-23 09:10:40,074 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_2 TaskAttempt Transitioned from ASSIGNED to RUNNING
2016-12-23 09:10:40,075 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1482404625971_23910_m_000004 Task Transitioned from SCHEDULED to RUNNING
2016-12-23 09:10:40,108 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for application_1482404625971_23910: ask=1 release= 0 newContainers=0 finishedContainers=0 resourcelimit=<memory:0, vCores:0> knownNMs=11
2016-12-23 09:10:42,949 INFO [Socket Reader #1 for port 27113] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1482404625971_23910 (auth:SIMPLE)
2016-12-23 09:10:42,995 INFO [IPC Server handler 6 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1482404625971_23910_m_60473139527691 asked for a task
2016-12-23 09:10:42,995 INFO [IPC Server handler 6 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1482404625971_23910_m_60473139527691 given task: attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:46,163 INFO [IPC Server handler 29 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:46,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_2 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2016-12-23 09:10:46,165 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1482404625971_23910_m_000004_2 given a go for committing the task output.
2016-12-23 09:10:46,166 INFO [IPC Server handler 9 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:46,167 INFO [IPC Server handler 9 on 27113] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1482404625971_23910_m_000004_2:true
2016-12-23 09:10:46,265 INFO [IPC Server handler 20 on 27113] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:46,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1482404625971_23910_m_000004_2 TaskAttempt Transitioned from COMMIT_PENDING to SUCCEEDED
2016-12-23 09:10:46,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1482404625971_23910_m_000004_2
2016-12-23 09:10:46,267 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1482404625971_23910_m_000004 Task Transitioned from RUNNING to SUCCEEDED
2016-12-23 09:10:46,267 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:997)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:139)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1399)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1395)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:192)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:118)
	at java.lang.Thread.run(Thread.java:745)
2016-12-23 09:10:46,270 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1482404625971_23910Job Transitioned from SUCCEEDED to ERROR
2016-12-23 09:10:46,271 INFO [Thread-97] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2016-12-23 09:10:46,271 INFO [Thread-97] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: RMCommunicator notified that shouldUnregistered is: true
2016-12-23 09:10:46,271 INFO [Thread-97] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2016-12-23 09:10:46,271 INFO [Thread-97] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2016-12-23 09:10:46,271 INFO [Thread-97] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
{noformat}"
MAPREDUCE-6825,YARNRunner#createApplicationSubmissionContext method is longer than 150 lines,"bq. ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/main/java/org/apache/hadoop/mapred/YARNRunner.java:341: public ApplicationSubmissionContext createApplicationSubmissionContext(:3: Method length is 249 lines (max allowed is 150).

{{YARNRunner#createApplicationSubmissionContext}} is longer than 150 lines and needs to be refactored."
MAPREDUCE-6824,TaskAttemptImpl#createCommonContainerLaunchContext is longer than 150 lines,"bq. ./hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/impl/TaskAttemptImpl.java:752: private static ContainerLaunchContext createCommonContainerLaunchContext(:3: Method length is 172 lines (max allowed is 150).

{{TaskAttemptImpl#createCommonContainerLaunchContext}} is longer than 150 lines and needs to be refactored."
MAPREDUCE-6823,FileOutputFormat to support configurable PathOutputCommitter factory,"In HADOOP-13786 I'm adding a custom subclass for FileOutputFormat, one which can talk direct to the S3A Filesystem for more efficient operations, better failure modes, and, most critically, as part of HADOOP-13345, atomic commit of output. The normal committer relies on directory rename() being atomic for this; for S3 we don't have that luxury.

To support a custom committer, we need to be able to tell FileOutputFormat (and implicitly, all subclasses which don't have their own custom committer), to use our new {{S3AOutputCommitter}}.

I propose: 

# {{FileOutputFormat}} takes a factory to create committers.
# The factory to take a URI and {{TaskAttemptContext}} and return a committer
# the default implementation always returns a {{FileOutputCommitter}}
# A configuration option allows a new factory to be named
# An {{S3AOutputCommitterFactory}} to return a  {{FileOutputCommitter}} or new {{S3AOutputCommitter}} depending upon the URI of the destination.

Note that MRv1 already supports configurable committers; this is only the V2 API"
MAPREDUCE-6822,should set HADOOP_JOB_HISTORYSERVER_HEAPSIZE only if it's empty on branch2,"In mapred-env, set HADOOP_JOB_HISTORYSERVER_HEAPSIZE 1000 by default, That is incorrect.
We should set it 1000 by default only if it's empty. 
Because if you run  'HADOOP_JOB_HISTORYSERVER_HEAPSIZE =512 $HADOOP_HOME/sbin/mr-jobhistory-daemon.sh start historyserver', HADOOP_JOB_HISTORYSERVER_HEAPSIZE  will be set 1000, rather than 512."
MAPREDUCE-6821,Fix javac warning related to the deprecated APIs after upgrading Jackson,"We should update the deprecated APIs after Jackson upgraded. This issue is similar to HDFS-11233. In MAPREDUCE, there is just one place using deprecated API. We can updated the code here.
{code}
class JobSubmitter {
  protected static final Log LOG = LogFactory.getLog(JobSubmitter.class);
  private static final ObjectReader READER =
      new ObjectMapper().reader(Map.class);
{code}"
MAPREDUCE-6820,Fix dead links in Job relevant classes,"There are some dead links in Job relevant classes. For example in class {{JobConf}}

{code}
* input files is treated as an upper bound for input splits. A lower bound 
    * on the split size can be set via 
    * <a href=""{@docRoot}/../mapred-default.html#mapreduce.input.fileinputformat.split.minsize"">
    * mapreduce.input.fileinputformat.split.minsize</a>.</p>
{code}

Here the link is not correct. We should make a fix."
MAPREDUCE-6819,Replace UTF8 with Text in MRBench,UTF8 class has been deprecated for a long time. We can use Text class instead of UTF8 in MRBench.java.
MAPREDUCE-6818,Remove direct reference to TimelineClientImpl,"[~sjlee0]'s quick audit shows that things that are referencing TimelineClientImpl directly today:

JobHistoryFileReplayMapperV1 (MR)
SimpleEntityWriterV1 (MR)
TestDistributedShell (DS)
TestDSAppMaster (DS)
TestNMTimelinePublisher (node manager)
TestTimelineWebServicesWithSSL (AHS)

This is not the right way to use TimelineClient and we should avoid direct reference to TimelineClientImpl as much as possible. 

Any newcomers to the community are more than welcome to take this. If this remains unassigned for ~24hrs I'll jump in and do a quick fix. "
MAPREDUCE-6817,The format of job start time in JHS is different from those of submit and finish time,
MAPREDUCE-6816,Progress bars in Web UI always at 100% ,"YARN web UI always shows progress bars at 100% (see screenshot, progress of the reduce step is roughly at 40.00%). I opened the HTML source code to check (also see screenshot), and it seems the problem is that it uses ""%%"" ,which cannot be recognized. This is due to the output of {{StringUtils.format()}} contains '%', while in *Block.java use  {{join()}} add an extra '%'."
MAPREDUCE-6815,Fix flaky TestKill.testKillTask(),"Error Message
Job state is not correct (timedout) expected:<SUCCEEDED> but was:<ERROR>
Stacktrace
java.lang.AssertionError: Job state is not correct (timedout) expected:<SUCCEEDED> but was:<ERROR>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:118)
at org.apache.hadoop.mapreduce.v2.app.MRApp.waitForState(MRApp.java:416)
at org.apache.hadoop.mapreduce.v2.app.TestKill.testKillTask(TestKill.java:124)"
MAPREDUCE-6811,TestPipeApplication#testSubmitter fails after HADOOP-13802,"{noformat}
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(TestPipeApplication.java:302)
{noformat}

 *Reference* 

https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/226/
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6811/testReport/"
MAPREDUCE-6810,hadoop-mapreduce-client-nativetask compilation broken on GCC-6.2.1,"I recently upgraded from Fedora 22 to Fedora 25 (I'm assuming this means the latest and greatest compilers, cmake etc.) My trunk build failed with this error:
{code}
[WARNING] /home/raviprak/Code/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/Log.h:35:67: error: unable to find string literal operator ‘operator""""_fmt_’ with ‘const char [37]’, ‘long unsigned int’ arguments
[WARNING]      fprintf(LOG_DEVICE, ""%02d/%02d/%02d %02d:%02d:%02d INFO ""_fmt_""\n"", \
{code}

https://access.redhat.com/documentation/en-US/Red_Hat_Developer_Toolset/3/html/User_Guide/sect-Changes_in_Version_3.0-GCC.html
bq.This applies to any string literal followed without white space by some macro. To fix this, add some white space between the string literal and the macro name. "
MAPREDUCE-6809,Create ContainerRequestor interface and refactor RMContainerRequestor to use it,"As per the discussion in MAPREDUCE-6773, create a ContainerRequestor interface and refactor RMContainerRequestor to use this interface."
MAPREDUCE-6808,Log map attempts as part of shuffle handler audit log,"With the introduction tez, multiple unrelated reducers in the same job will have the same id. The audit log won't be able to distinguish which map attempt the reduce was fetching. This jira is to discuss the  possibility to add map attempts logging to distinguish between the two."
MAPREDUCE-6805,Negative Array Exception while reducer fetch mapper output,"MapReduce job stuck with a Negative Array Size exception thrown by the reducer,lead to MR job failed
stack trace:
{quote}
2016-10-28 08:01:16,882 WARN [main] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:web_vr (auth:SIMPLE) cause:org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3
2016-10-28 08:01:16,883 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:164)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1930)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NegativeArraySizeException
	at org.apache.hadoop.io.BoundedByteArrayOutputStream.<init>(BoundedByteArrayOutputStream.java:56)
	at org.apache.hadoop.io.BoundedByteArrayOutputStream.<init>(BoundedByteArrayOutputStream.java:46)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.<init>(InMemoryMapOutput.java:63)
	at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.unconditionalReserve(MergeManagerImpl.java:305)
	at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:295)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:514)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)
{quote}"
MAPREDUCE-6804,Add timeout when starting JobHistoryServer in MiniMRYarnCluster,"This JIRA is to follow up a TODO in MiniMRYarnCluster.
{{//TODO Add a timeout. State.STOPPED check ?}}
I think State.STOPPED check is not needed. I do not see the value to check STOPPED state here."
MAPREDUCE-6802,TestKill.testKillJob() fails intermittently on Power,"Running org.apache.hadoop.mapreduce.v2.app.TestKill
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 9.86 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestKill
testKillJob(org.apache.hadoop.mapreduce.v2.app.TestKill)  Time elapsed: 0.377 sec  <<< FAILURE!
java.lang.AssertionError: Task state not correct expected:<KILLED> but was:<NEW>
       at org.junit.Assert.fail(Assert.java:88)
       at org.junit.Assert.failNotEquals(Assert.java:743)
       at org.junit.Assert.assertEquals(Assert.java:118)
       at org.apache.hadoop.mapreduce.v2.app.TestKill.testKillJob(TestKill.java:99)


Results :

Failed tests:
 TestKill.testKillJob:99 Task state not correct expected:<KILLED> but was:<NEW>

Tests run: 5, Failures: 1, Errors: 0, Skipped: 0"
MAPREDUCE-6801,Fix flaky TestKill.testKillJob(),"TestKill.testKillJob often fails for the same reason with the following error message:

{code}
1 tests failed.
FAILED:  org.apache.hadoop.mapreduce.v2.app.TestKill.testKillJob

Error Message:
Task state not correct expected:<KILLED> but was:<NEW/SCHEDULED/RUNNING>

Stack Trace:
java.lang.AssertionError: Task state not correct expected:<KILLED> but was:<NEW/SCHEDULED/RUNNING>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.apache.hadoop.mapreduce.v2.app.TestKill.testKillJob(TestKill.java:84)
{code}
The root cause is that when the job is in KILLED state from an external view, TaskKillEvents and TaskAttemptKillEvents placed on the event loop queue may not have been processed by the dispatcher thread."
MAPREDUCE-6799,Document mapreduce.jobhistory.webapp.https.address in mapred-default.xml,"The default port number is 19890 but it is not documented.
{code:title=JHAdminConfig.java}
  public static final String MR_HISTORY_WEBAPP_HTTPS_ADDRESS =
      MR_HISTORY_PREFIX + ""webapp.https.address"";
  public static final int DEFAULT_MR_HISTORY_WEBAPP_HTTPS_PORT = 19890;
{code}"
MAPREDUCE-6798,Fix intermittent failure of TestJobHistoryParsing.testJobHistoryMethods(),"TestJobHistoryParsing.testJobHistoryMethods() failed.

expected:<1> but was:<0>
java.lang.AssertionError: expected:<1> but was:<0>
at org.junit.Assert.fail(Assert.java:88)
at org.junit.Assert.failNotEquals(Assert.java:743)
at org.junit.Assert.assertEquals(Assert.java:118)
at org.junit.Assert.assertEquals(Assert.java:555)
at org.junit.Assert.assertEquals(Assert.java:542)
at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testJobHistoryMethods(TestJobHistoryParsing.java:779)"
MAPREDUCE-6797,"Job history server scans can become blocked on a single, slow entry","There is one more piece of code in HistoryFileManager where Synchronized keyword on HistoryFileInfo need to be removed. The JobHistoryServer contention issue is hit on our environment where stacktrace (attached) shows the HistoryFileManager$JobListCache.addIfAbsent unnecessarily waiting to lock on HistoryFileInfo.

Synchronized on isMovePending and didMoveFail has been removed by Mapreduce-6684.

{code}
HistoryFileInfo firstValue = cache.get(key);
    synchronized(firstValue) {  ---------------> Synchronized is not needed here
              if (firstValue.isMovePending()) {
                if(firstValue.didMoveFail() && 
                    firstValue.jobIndexInfo.getFinishTime() <= cutoff) {
                  cache.remove(key);
                  //Now lets try to delete it
                  try {
                    firstValue.delete();
                  } catch (IOException e) {
                    LOG.error(""Error while trying to delete history files"" +
                    "" that could not be moved to done."", e);
                  }
                } else {
                  LOG.warn(""Waiting to remove "" + key
                      + "" from JobListCache because it is not in done yet."");
                }
              } else {
                cache.remove(key);
              }
            }

{code}


{code}

Note: stacktrace is from hadoop-2.4.0 version and the problem exists in latest hadoop as well

""2144820863@qtp-313351300-38156"" daemon prio=10 tid=0x0000000001e13800 nid=0xf133 waiting for monitor entry [0x00007f7c1d8dd000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$JobListCache.addIfAbsent(HistoryFileManager.java:226)
        - waiting to lock <0x000000040145c4d8> (a org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(HistoryFileManager.java:825)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$200(HistoryFileManager.java:82)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$UserLogDir.scanIfNeeded(HistoryFileManager.java:280)
        - locked <0x0000000400375388> (a org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$UserLogDir)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(HistoryFileManager.java:792)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getAllFileInfo(HistoryFileManager.java:920)
        at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getAllPartialJobs(CachedHistoryStorage.java:156)
        at org.apache.hadoop.mapreduce.v2.hs.JobHistory.getAllJobs(JobHistory.java:235)
{code}"
MAPREDUCE-6796,Remove unused properties from JTConfig.java,"JobTracker-side of MAPREDUCE-6794.
There are many unused properties in JTConfig.java. Let's remove them."
MAPREDUCE-6795,Update the document for JobConf#setNumReduceTasks,"The following document is for MRv1. We should update the document for MapReduce on YARN.
{code:title=JobConf.java}
   * <b id=""NoOfReduces"">How many reduces?</b>
   * 
   * <p>The right number of reduces seems to be <code>0.95</code> or 
   * <code>1.75</code> multiplied by (&lt;<i>no. of nodes</i>&gt; * 
   * <a href=""{@docRoot}/../mapred-default.html#mapreduce.tasktracker.reduce.tasks.maximum"">
   * mapreduce.tasktracker.reduce.tasks.maximum</a>).
   * </p>
{code}"
MAPREDUCE-6794,Remove unused properties from TTConfig.java,There are many unused properties in TTConfig.java. Let's remove them.
MAPREDUCE-6793,io.sort.factor code default and mapred-default.xml values inconsistent,"The actual default value in mapred-default.xml:
{code}
<property>
  <name>mapreduce.task.io.sort.factor</name>
  <value>10</value>
  <description>The number of streams to merge at once while sorting
  files.  This determines the number of open file handles.</description>
</property>
{code}

However, MapTask and MergeManagerImpl, are coded with:
{code}       
 int mergeFactor = job.getInt(JobContext.IO_SORT_FACTOR, 100);
{code}

"
MAPREDUCE-6792,Allow user's full principal name as owner of MapReduce staging directory in JobSubmissionFiles#JobStagingDir(),"Background - 
Currently, {{JobSubmissionFiles#JobStagingDir()}} assumes that file owner returned as part of {{FileSystem#getFileStatus()}} is always user's short principal name, which is true for HDFS. But, some file systems which are HDFS compatible like [Azure Data Lake Store (ADLS) |https://azure.microsoft.com/en-in/services/data-lake-store/] and work in multi tenant environment can have users with same names belonging to different domains. For example, {{user1@company1.com}} and {{user1@company2.com}}. It will be ambiguous, if {{FileSystem#getFileStatus()}} returns only the user's short principal name (without domain name) as the owner of the file/directory. 

The following code block allows only short user principal name as owner. It simply fails saying that ownership on the staging directory is not as expected, if owner returned by the {{FileStatus#getOwner()}} is not equal to short principal name of the current user.
{code}
    String realUser;
    String currentUser;
    UserGroupInformation ugi = UserGroupInformation.getLoginUser();
    realUser = ugi.getShortUserName();
    currentUser = UserGroupInformation.getCurrentUser().getShortUserName();
    if (fs.exists(stagingArea)) {
      FileStatus fsStatus = fs.getFileStatus(stagingArea);
      String owner = fsStatus.getOwner();
      if (!(owner.equals(currentUser) || owner.equals(realUser))) {
         throw new IOException(""The ownership on the staging directory "" +
                      stagingArea + "" is not as expected. "" +
                      ""It is owned by "" + owner + "". The directory must "" +
                      ""be owned by the submitter "" + currentUser + "" or "" +
                      ""by "" + realUser);
      }
	  {code}
The proposal is to remove the strict restriction on short principal name by allowing the user's full principal name as owner of staging area directory in {{JobSubmissionFiles#JobStagingDir()}}."
MAPREDUCE-6791,remove unnecessary dependency from hadoop-mapreduce-client-jobclient to hadoop-mapreduce-client-shuffle,
MAPREDUCE-6790,Update jackson from 1.9.13 to 2.x in hadoop-mapreduce,Sub-task of HADOOP-13332.
MAPREDUCE-6789,Fix TestAMWebApp failure,"TestAMWebApp.testMRWebAppRedirection fails.
{noformat}
Running org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp
Tests run: 12, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 27.337 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp
testMRWebAppRedirection(org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp)  Time elapsed: 0.854 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<...ttp://9.9.9.9/proxy/[]application_0_0000/m...> but was:<...ttp://9.9.9.9/proxy/[redirect/]application_0_0000/m...>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.testMRWebAppRedirection(TestAMWebApp.java:253)
{noformat}"
MAPREDUCE-6787,Allow job_conf.xml to be downloadable on the job overview page in JHS,"The job overview page in JHS provides the path to the job.xml file, but it is not a link that users can click on to download the job xml file directly from JHS. We could provide a download link in JHS for better usability."
MAPREDUCE-6785,ContainerLauncherImpl support for reusing the containers,Add support to Container Launcher for reuse of the containers.
MAPREDUCE-6783,Default setting 'inheritParentEnv=false' caused mr executor failed to initialize,"MR default classpath depend on the ""HADOOP_MAPRED_HOME"" , defined at MRJobConfig#DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH.
On 3.0.0.alpha1 , contain ""Remove parent's env vars from child processes "" which commit by [#Robert Kanter] ,but it's seem not found in jira or release note. DefaultContainerExecutor & DefaultLinuxContinerExecutor default the 'inheritParentEnv' as false,there is no any approach to set the ""HADOOP_MAPRED_HOME"" ,the AM failed by ""Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster""
"
MAPREDUCE-6782,JHS task page search based on each individual column not working,"Submit mapreduce pi job with 10 maps
In Jobs history server selection completed job
Select maps to Task Page for job
Search in individual column fields


*Expected*
Search should be working fine in task page for individual columns

*Actual*
Search not working for individual column in task page
In Attempts page the same search is working fine



{noformat}
jquery.dataTables.min.js:109
 Uncaught TypeError: Cannot read property 'oFeatures' of null
fnFilter @ jquery.dataTables.min.js:109(anonymous function) @ m:49dispatch
 @ jquery-1.8.2.min.js:2h @ jquery-1.8.2.min.js:2
{noformat}"
MAPREDUCE-6780,Add support for striping files in benchmarking of TeraGen and TeraSort,"So far, HDFS file with erasure code policy doesn't support hflush and hsync operation. This task is going to find a way to support writing data to erasure code policy files in TeraGen and TeraSort."
MAPREDUCE-6777,Typos in 4 log messages,"I am conducting research on log related bugs. I tried to make a tool to fix repetitive yet simple patterns of bugs that are related to logs. Typos in log messages are one of the reoccurring bugs. Therefore, I made a tool find typos in log statements. During my experiments, I managed to find the following typos in Hadoop MapReduce:

In file /hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/TaskAttemptListenerImpl.java, LOG.info(""Done acknowledgement from "" + taskAttemptID.toString()), 
acknowledgement should be acknowledgment

In file /hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java, LOG.info(""Exception while cancelling delayed flush timer. ""+ ""Likely caused by a failed flush "" + e.getMessage()), 
cancelling should be canceling

In file /hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java, LOG.info(""Runnning cleanup for the task""), 
Runnning should be Running

In file /hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java, LOG.info(""Storing state DB schedma version info "" + getCurrentVersion()), 
schedma should be schema"
MAPREDUCE-6776,yarn.app.mapreduce.client.job.max-retries should have a more useful default,"The default is 0, so any communication failure results in a client failure.  Oozie doesn't like that.  If the RM is failing over and Oozie gets a communication failure, it assumes the target job has failed.  I propose raising the default to something modest like 3 or 5.  The default retry interval is 2s."
MAPREDUCE-6775,Fix MapReduce failures caused by default RPC engine changing,"HADOOP-13218 changed the default RPC engine, which isn't inappropriate because MAPREDUCE-6706 isn't solved yet, supporting TaskUmbilicalProtocol to use ProtobufRPCEngine.

[~jlowe] reported the following errors:
{noformat}
2016-09-07 17:51:56,296 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.reflect.UndeclaredThrowableException
	at com.sun.proxy.$Proxy10.getTask(Unknown Source)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:137)
Caused by: com.google.protobuf.ServiceException: Too many or few parameters for request. Method: [getTask], Expected: 2, Actual: 1
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:199)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	... 2 more
{noformat}"
MAPREDUCE-6774,Add support for HDFS erasure code policy to TestDFSIO,HDFS erasure code policy allows user to store directory and file to predefined erasure code policies. Currently only 3x replication is supported in TestDFSIO implementation. This is going to add an new option to enable tests of files with erasure code policy enabled. 
MAPREDUCE-6773,Implement RM Container Reuse Requestor to handle the reuse containers for resource requests,Add RM Container Reuse Requestor which handles the reuse containers against the Job reource requests.
MAPREDUCE-6772,Add MR Job Configurations for Containers reuse,This task adds configurations required for MR AM Container reuse feature.
MAPREDUCE-6771,RMContainerAllocator sends container diagnostics event after corresponding completion event,"Task containers can go over their resource limit, and killed by Node Manager. Then MR AM gets notified of the container status and diagnostics information through its heartbeat with RM.  However, it is possible that the diagnostics information never gets into .jhist file, so when the job completes, the diagnostics information associated with the failed task attempts is empty.  This makes it hard for users to root cause job failures that are often caused by memory leak."
MAPREDUCE-6769,"Fix forgotten conversion from ""slave"" to ""worker"" in mapred script","In HADOOP-13209 (commit 23c3ff85a9e73d8f0755e14f12cc7c89b72acddd), ""slaves"" was replaced with ""workers"" including the function name change from hadoop_common_slave_mode_execute to hadoop_common_worker_mode_execute and environment variable name change from HADOOP_SLAVE_MODE to HADOOP_WORKER_MODE.

It appears this change was forgotten in hadoop-mapred-project/bin/mapred.

Github pull request with fix to be sent shortly.
"
MAPREDUCE-6768,TestRecovery.testSpeculative failed with NPE,"1 tests failed.
REGRESSION:  org.apache.hadoop.mapreduce.v2.app.TestRecovery.testSpeculative

Error Message:
null

Stack Trace:
java.lang.NullPointerException: null
        at org.apache.hadoop.mapreduce.v2.app.TestRecovery.testSpeculative(TestRecovery.java:1201)"
MAPREDUCE-6767,TestSlive fails after a common change,It looks like this was broken after HADOOP-12726.
MAPREDUCE-6765,MR should not schedule container requests in cases where reducer or mapper containers demand resource larger than the maximum supported,"When mapper or reducer containers request resource larger than the maxResourceRequest in the cluster, job is to be killed. In such cases, it is unnecessary to still schedule container requests.  "
MAPREDUCE-6764,Teragen LOG initialization bug,
MAPREDUCE-6763,Shuffle server listen queue is too small,"ShuffleHandler doesn't specify a listen queue length for the server port, so it ends up getting the default listen queue length of 50.  This is too small to handle bursts of shuffle traffic on large clusters.  It's also inconsistent with the default Hadoop uses for RPC servers (default=128)."
MAPREDUCE-6762,ControlledJob#toString failed with NPE when job status is not successfully updated,"This issue was found from a cluster where Pig query occasionally failed on NPE. Pig uses JobControl API to track MR job status, but sometimes Job History Server failed to flush job meta files to HDFS which caused the status update failed. Then we get NPE in {{org.apache.hadoop.mapreduce.Job.getJobName}}. The result of this situation is quite confusing: Pig query failed, job history is missing, but the job status on Yarn is succeed."
MAPREDUCE-6761,Regression when handling providers - invalid configuration ServiceConfiguration causes Cluster initialization failure,"When a rogue org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider defines a provider that is not on classpath, then the initialization is failed with the following exception:

java.util.ServiceConfigurationError: org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider: Provider org.apache.hadoop.mapred.YarnClientProtocolProvider not found
	at java.util.ServiceLoader.fail(ServiceLoader.java:239)
	at java.util.ServiceLoader.access$300(ServiceLoader.java:185)
	at java.util.ServiceLoader$LazyIterator.nextService(ServiceLoader.java:372)
	at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:404)
	at java.util.ServiceLoader$1.next(ServiceLoader.java:480)
	at org.apache.hadoop.mapreduce.Cluster.initProviderList(Cluster.java:84)
	at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:114)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:108)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:101)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:477)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:455)

This regression is caused by MAPREDUCE-6473"
MAPREDUCE-6753,Variable in byte printed directly in mapreduce client,"Similar to the fix for HBASE-623, in file:

hadoop-rel-release-2.7.2/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/security/CredentialsTestJob.java

in line 61, the system out print a byte variable secretValue.
{code}
System.out.println(secretValue);
{code}



"
MAPREDUCE-6751,Add debug log message when splitting is not possible due to unsplittable compression,There should be a message logged in case of the mapreduce will only spam one mapper since the source file is compressed with an unsplitable algorithm
MAPREDUCE-6750,TestHSAdminServer.testRefreshSuperUserGroups is failing,HADOOP-13442 changed {{AccessControlList}} to call {{getGroups()}} instead of {{getGroupNames()}}. It should work if the mocks are updated to stub the right method and return the right type.
MAPREDUCE-6748,Enhance logging for Cluster.java around InetSocketAddress,"We need to add more logging for cluster.java class around "" initialize(InetSocketAddress jobTrackAddr, Configuration conf) "" method to give better logging like about the source of the property."
MAPREDUCE-6746,Replace org.apache.commons.io.Charsets with java.nio.charset.StandardCharsets,MapReduce side of HADOOP-13444. IO-422 deprecated org.apache.commons.io.Charsets in commons-io 2.5. We should use java.nio.charset.StandardCharsets instead.
MAPREDUCE-6744,Increase timeout on TestDFSIO tests,The timeout on these tests is only 3 seconds and so one of the tests in the suite will fail on a regular basis. 
MAPREDUCE-6743,nativetask unit tests need to provide usable output; fix link errors during mvn test,"Currently, hadoop-mapreduce-client-nativetask creates a nttest binary which provides an binary exit code to determine failure.  This means there is no output generated by the Jenkins run to actually debug or provide hints as to what failed.  Given that nttest is written with gtest, it should be configured to either spit out junit or TAP which can then be used to provide further analysis."
MAPREDUCE-6742,Test,
MAPREDUCE-6741,add MR support to redact job conf properties,JHS today displays all Job conf properties in Web UI directly. Users may have some credentials or any sensitive information they added to the job conf but do not want to be shown in Web UI. It'd be nice if we can allow users to specify a set of properties which JHS will filter out when Job conf is displayed.
MAPREDUCE-6740,Enforce mapreduce.task.timeout to be at least mapreduce.task.progress-report.interval,"MAPREDUCE-6242 makes task status update interval configurable to ease the pressure on MR AM to process status updates, but it did not ensure that mapreduce.task.timeout is no smaller than the configured value of task report interval. "
MAPREDUCE-6739,allow specifying range on the port that MR AM web server binds to,"MR AM web server binds itself to an arbitrary port.  This means if the RM web proxy lives outside of a cluster, the whole port range needs to be wide open. It'd be nice to reuse yarn.app.mapreduce.am.job.client.port-range to place a port range restriction on MR AM web server, so that connection from outside the cluster can be restricted within a range of ports."
MAPREDUCE-6738,TestJobListCache.testAddExisting failed intermittently in slow VM testbed,"Kick off Jenkins test which occasionally failed for this test with stack trace below: 
org.apache.hadoop.mapreduce.v2.hs.TestJobListCache.testAddExisting

java.lang.Exception: test timed out after 1000 milliseconds
	at org.mockito.cglib.proxy.Enhancer.generateClass(Enhancer.java:483)
	at org.mockito.cglib.core.DefaultGeneratorStrategy.generate(DefaultGeneratorStrategy.java:25)
	at org.mockito.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:217)
	at org.mockito.cglib.proxy.Enhancer.createHelper(Enhancer.java:378)
	at org.mockito.cglib.proxy.Enhancer.createClass(Enhancer.java:318)
	at org.mockito.internal.creation.jmock.ClassImposterizer.createProxyClass(ClassImposterizer.java:93)
	at org.mockito.internal.creation.jmock.ClassImposterizer.imposterise(ClassImposterizer.java:50)
	at org.mockito.internal.util.MockUtil.createMock(MockUtil.java:54)
	at org.mockito.internal.MockitoCore.mock(MockitoCore.java:45)
	at org.mockito.Mockito.mock(Mockito.java:921)
	at org.mockito.Mockito.mock(Mockito.java:816)
	at org.apache.hadoop.mapreduce.v2.hs.TestJobListCache.testAddExisting(TestJobListCache.java:42)"
MAPREDUCE-6733,"MapReduce JerseyTest tests failing with ""java.net.BindException: Address already in use""","Similar to YARN-2912 / YARN-3433, MR JerseyTests fail when port 9998 is in external use. We should fix the MR tests too similar to YARN-2912."
MAPREDUCE-6732,mapreduce tasks for YARN Timeline Service v.2: alpha 2,"This s an umbrella JIRA to capture all mapreduce tasks for YARN Timeline Service v.2 alpha 2.

This is developed on feature branches: {{YARN-5355}} for the trunk-based development and {{YARN-5355-branch-2}} to maintain backports to branch-2. Any subtask work on this JIRA will be committed to those 2 branches."
MAPREDUCE-6731,TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling() may fail for concurrent tests,"{{TestMRTimelineEventHandling.testMRNewTimelineServiceEventHandling()}} uses the default file-system storage directory, and is brittle against concurrent tests.

We should use a unique storage directory for the tests."
MAPREDUCE-6730,Use StandardCharsets instead of String overload in TextOutputFormat,"In TextOutputFormat.java, instead of:
{code:java}
private static final String utf8 = ""UTF-8"";
private static final byte[] newline;
static {
  try {
    newline = ""\n"".getBytes(utf8);
  } catch (UnsupportedException uee) {
    threw new IllegalArgumentException(""can't find "" + utf8 + "" encoding"");
  }
}
{code}

Let's do something like:
{code:java}
private static final byte[] newline = ""\n"".getBytes(StandardCharsets.UTF_8);
{code}"
MAPREDUCE-6729,Accurately compute the test execute time in DFSIO,"When doing DFSIO test as a distributed i/o benchmark tool. Then especially writes plenty of files to disk or read from, both can cause performance issue and imprecise value in a way. The question is that existing practices needs to delete files when before running a job and that will cause extra time consumption and furthermore cause performance issue, statistical time error and imprecise throughput as the files are lots of. So we need to replace or improve this hack to prevent this from happening in the future.

{code}
public static void testWrite() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.writeTest(fs); // this line of code will cause extra time consumption as fs.delete(*,*) by the writeTest method
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime);
  }

private void writeTest(FileSystem fs) throws IOException {
  Path writeDir = getWriteDir(config);
  fs.delete(getDataDir(config), true);
  fs.delete(writeDir, true);    
  runIOTest(WriteMapper.class, writeDir);
  }
{code}　

[https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestDFSIO.java]


"
MAPREDUCE-6728,Give fetchers hint when ShuffleHandler rejects a shuffling connection,"If # of open shuffle connection to a node goes over the max, ShuffleHandler closes the connection immediately without giving fetchers any hint of the reason, which causes fetchers to fail due to exceptions 

java.net.SocketException: Unexpected end of file from server
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:772)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:633)
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:769)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:633)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1323)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifyConnection(Fetcher.java:430)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupConnectionsWithRetry(Fetcher.java:395)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.openShuffleUrl(Fetcher.java:266)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:323)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)


OR 

java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:196)
	at java.net.SocketInputStream.read(SocketInputStream.java:122)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:275)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:334)
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:687)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:633)
	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:769)
	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:633)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1323)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:468)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifyConnection(Fetcher.java:430)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupConnectionsWithRetry(Fetcher.java:395)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.openShuffleUrl(Fetcher.java:266)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java

Such failures are counted as fetcher failures"
MAPREDUCE-6725,Javadoc for CLI#listEvents() contains no-existent param,"Comment for CLI#listEvents() contains @param jobid,  but this method doesn't has the parameter,it  may be some jira changed the method and forgot to change the comment 
So I made a simple fix."
MAPREDUCE-6724,Single shuffle to memory must not exceed Integer#MAX_VALUE,"When shuffle is done in memory, MergeManagerImpl converts the requested size to an int to allocate an instance of InMemoryMapOutput. This results in an overflow if the requested size is bigger than Integer.MAX_VALUE and eventually causes the reducer to fail."
MAPREDUCE-6723,Turn log level to Debug in test,"The current log level in test enviroment for all mapreduce projects is info. Often in case where we are investigating intermittent test failures, DEBUG level messages in log file can be very useful to identify problems.  "
MAPREDUCE-6721,mapreduce.reduce.shuffle.memory.limit.percent=0.0 should be legal to enforce shuffle to disk,"We are potentially hitting an in-memory-shuffle-related reservation starvation resembling MAPREDUCE-6445. To work it around, we wanted to disable in memory shuffle via mapreduce.reduce.shuffle.memory.limit.percent=0.0 that turned out to be disallowed by the current logic. So we had to resort to another small float value such as 0.0001. However, zero is more logical imo.

"
MAPREDUCE-6720,Inconsistent values of counters across tasks and job reported to timeline service.,"While testing found below issue. For some of the task counters, we do not have consistent values. This is not the case with every counter though.
Consider the case of counter ""org.apache.hadoop.mapreduce.FileSystemCounter:FILE_BYTES_WRITTEN"".

I found that its value for a flow I ran, was 936018 bytes. For the 3 apps associated with this flow run, the values were 312006 bytes each (which equals to value for a flow run i.e. 3 * 312006 = 936018). Drilling further down I found though that for one of the apps, the 4 tasks(2 mappers and 2 reducers) had values as 155918 bytes each for the 2 reducers and 156003 bytes each for the 2 mappers.

This means the value reported for the app should be (2 * 156003 + 2* 155918) or 623842 bytes but it is only 312006 bytes which indicates that only counter value of mappers is being picked up."
MAPREDUCE-6719,The list of -libjars archives should be replaced with a wildcard in the distributed cache to reduce the application footprint in the state store,"When using the -libjars option to add classes to the classpath, every library so added is explicitly listed in the ContainerLaunchContext's local resources even though they're all uploaded to the same directory in HDFS. When using tools like Crunch without an uber JAR or when trying to take advantage of the shared cache, the number of libraries can be quite large. We've seen many cases where we had to turn down the max number of applications to prevent ZK from running out of heap because of the size of the state store entries.
This JIRA proposes to allow for wildcards both in the internal processing of the -libjars switch and in paths added through the Job and DistributedCache classes. Rather than listing all files independently, this JIRA proposes to replace the complete list of libdir files with the wildcarded libdir directory, e.g. ""libdir/*"". This behavior is the same as the current behavior when using -libjars, but avoids explicitly listing every file.
This capability will also be exposed by the {{DistributedCache.addCacheFile()}} method.
See YARN-4958 for the NM side of the implementation and additional discussion.
"
MAPREDUCE-6718,add progress log to JHS during startup,"
lWhen the JHS starts up, it initializes the internal caches and storage via the HistoryFileManager. If we have a large number of existing finished jobs then we could spent minutes in this startup phase without logging progress:
2016-03-14 10:56:01,444 INFO org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://hadoopcdh.itnas01.ieee.org:8020]
2016-03-14 10:56:11,455 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Initializing Existing Jobs...
2016-03-14 12:01:36,926 INFO org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage: CachedHistoryStorage Init
This makes it really difficult to assess if things are working correctly (it looks hung). We can add logs to notify users of progress."
MAPREDUCE-6717,Remove deprecated StringUtils.getFormattedTimeWithDiff,"MAPREDUCE-6542 deprecated {{StringUtils.getFormattedTimeWithDiff(DateFormat, long, long)}}, so it should be removed later.
This method can be removed in branch-2 because {{StringUtils}} is not {{@Public}}."
MAPREDUCE-6715,Fix Several Unsafe Practices,"{code}
Null Dereference        CleanupQueue.java:139
Weak SecurityManager Check: Overridable Method  LocalDistributedCacheManager.java:229
Null Dereference        TextOutputFormat.java:137
Null Dereference        ShuffleSchedulerImpl.java:422
Null Dereference        MapTask.java:415
Null Dereference        Pentomino.java:160
Unreleased Resource: Streams    TeraScheduler.java:77
Unreleased Resource: Streams    CLI.java:570
Null Dereference        CLI.java:370
{code}"
MAPREDUCE-6714,Refactor UncompressedSplitLineReader.fillBuffer(),"MAPREDUCE-6635 made this change:

{code}
-      maxBytesToRead = Math.min(maxBytesToRead,
-                                (int)(splitLength - totalBytesRead));
+      long leftBytesForSplit = splitLength - totalBytesRead;
+      // check if leftBytesForSplit exceed Integer.MAX_VALUE
+      if (leftBytesForSplit <= Integer.MAX_VALUE) {
+        maxBytesToRead = Math.min(maxBytesToRead, (int)leftBytesForSplit);
+      }
{code}

The result is one more comparison than necessary and code that's a little convoluted.  The code can be simplified as:

{code}
      long leftBytesForSplit = splitLength - totalBytesRead;

      if (leftBytesForSplit < maxBytesToRead) {
        maxBytesToRead = (int)leftBytesForSplit;
      }
{code}

The comparison will auto promote {{maxBytesToRead}}, making it safe."
MAPREDUCE-6711,JobImpl fails to handle preemption events on state COMMITTING,"When a MR app being preempted on COMMITTING state, we saw the following exceptions in its log:
{code}
ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at COMMITTING
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:996)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:138)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1289)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1285)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:182)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:108)
        at java.lang.Thread.run(Thread.java:744)
{code}
and 
{code}
ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_MAP_TASK_RESCHEDULED at COMMITTING
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:996)
at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:138)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1289)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1285)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:182)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:108)
        at java.lang.Thread.run(Thread.java:744)
{code}

Seems like we need to handle those preemption related events when the job is being committed? "
MAPREDUCE-6705,Task failing continuously on trunk,"Task attempt failing continuously. Submit any mapreduce application

Run the job as below

{code}
./yarn jar ../share/hadoop/mapreduce/hadoop-mapreduce-examples*.jar pi -Dyarn.app.mapreduce.am.env=""HADOOP_MAPRED_HOME={{HADOOP_COMMON_HOME}}"" -Dmapreduce.admin.user.env=""HADOOP_MAPRED_HOME={{HADOOP_COMMON_HOME}}""  1 1
{code}

{noformat}
2016-05-27 11:28:27,148 DEBUG [main] org.apache.hadoop.ipc.Client: getting client out of cache: org.apache.hadoop.ipc.Client@291ae
2016-05-27 11:28:27,160 DEBUG [main] org.apache.hadoop.mapred.YarnChild: PID: 22305
2016-05-27 11:28:27,160 INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
2016-05-27 11:28:27,161 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.reflect.UndeclaredThrowableException
	at com.sun.proxy.$Proxy10.getTask(Unknown Source)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:136)
Caused by: com.google.protobuf.ServiceException: Too many or few parameters for request. Method: [getTask], Expected: 2, Actual: 1
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	... 2 more

2016-05-27 11:28:27,161 DEBUG [main] org.apache.hadoop.ipc.Client: stopping client from cache: org.apache.hadoop.ipc.Client@291ae
2016-05-27 11:28:27,161 DEBUG [main] org.apache.hadoop.ipc.Client: removing client from cache: org.apache.hadoop.ipc.Client@291ae
{noformat}"
MAPREDUCE-6704,Update the documents to run MapReduce application,"Container fail to launch for mapred application.
As part for launch script {{HADOOP_MAPRED_HOME}} default value is not set .After https://github.com/apache/hadoop/commit/9d4d30243b0fc9630da51a2c17b543ef671d035c   {{HADOOP_MAPRED_HOME}} is not able to get from {{builder.environment()}} since {{DefaultContainerExecutor#buildCommandExecutor}} sets inherit to false.



{noformat}
16/05/02 09:16:05 INFO mapreduce.Job: Job job_1462155939310_0004 failed with state FAILED due to: Application application_1462155939310_0004 failed 2 times due to AM Container for appattempt_1462155939310_0004_000002 exited with  exitCode: 1
Failing this attempt.Diagnostics: Exception from container-launch.
Container id: container_1462155939310_0004_02_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1:
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:946)
        at org.apache.hadoop.util.Shell.run(Shell.java:850)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1144)
        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:227)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.launchContainer(ContainerLaunch.java:385)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:281)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:89)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 1. Last 4096 bytes of stderr :
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0
Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster

Container exited with a non-zero exit code 1. Last 4096 bytes of stderr :
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option UseSplitVerifier; support was removed in 8.0
{noformat}"
MAPREDUCE-6703,Add flag to allow MapReduce AM to request for OPPORTUNISTIC containers,"YARN-2882 and YARN-4335 introduces the concept of container ExecutionTypes and specifically OPPORTUNISTIC containers.
The default ExecutionType is GUARANTEED. This JIRA proposes to allow users to provide hints via config to the MR framework as to the number of containers it would like to schedule as OPPORTUNISTIC."
MAPREDUCE-6702,TestMiniMRChildTask.testTaskEnv and TestMiniMRChildTask.testTaskOldEnv are failing,"-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapred.TestMiniMRChildTask
Tests run: 3, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 92.48 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestMiniMRChildTask
testTaskEnv(org.apache.hadoop.mapred.TestMiniMRChildTask)  Time elapsed: 21.906 sec  <<< FAILURE!
java.lang.AssertionError: The environment checker job failed.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.mapred.TestMiniMRChildTask.runTestTaskEnv(TestMiniMRChildTask.java:550)
	at org.apache.hadoop.mapred.TestMiniMRChildTask.testTaskEnv(TestMiniMRChildTask.java:472)

testTaskOldEnv(org.apache.hadoop.mapred.TestMiniMRChildTask)  Time elapsed: 17.452 sec  <<< FAILURE!
java.lang.AssertionError: The environment checker job failed.
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.mapred.TestMiniMRChildTask.runTestTaskEnv(TestMiniMRChildTask.java:550)
	at org.apache.hadoop.mapred.TestMiniMRChildTask.testTaskOldEnv(TestMiniMRChildTask.java:496)"
MAPREDUCE-6701,application master log can not be available when clicking jobhistory's am logs link,"In history server webapp, application master logs link is wrong. it shows ""No logs available for container container_1462419429440_0003_01_000001"".  It direct to a wrong nodemanager http port instead of a node manager' container managerment port. I think YARN-4701 brought this bug"
MAPREDUCE-6700,Jobhistory server attempt and task table not loading maps/reduce,"Browser
=======
Chrome

Steps to reproduce
==============
# Submit mapreduce application with 20 maps
# Wait till completion of mapreduce application
# Check maps attempts page
{{jobhistory/attempts/job_1463446678437_0003/m/SUCCESSFUL}}
and {{jobhistory/tasks/job_1463446678437_0003/m}} page

Actual
=====
Table not loading.
Sort based on any column other than attempt contents are loaded.

Column 0 is of *natural sorting* and not working. So waiting for ever to be sorted.


{noformat}
SCRIPT438: Object doesn't support property or method 'natural-asc' 
jquery.dataTables.min.js, line 86 character 179

{noformat}
"
MAPREDUCE-6699,hadoop-mapred unit tests for dynamic commands,"This is a hold over from HADOOP-12930, dynamic sub commands.  Currently there are no unit tests for this in mapred and there really should be."
MAPREDUCE-6698,Increase timeout on TestUnnecessaryBlockingOnHistoryFileInfo.testTwoThreadsQueryingDifferentJobOfSameUser,"The timeout on TestUnnecessaryBlockingOnHistoryFileInfo.testTwoThreadsQueryingDifferentJobOfSameUser is added to verify the fix of MAPREDUCE-6684 works. When two thread are requesting different jobs owned by the same user, one thread request jobA should not be blocked by the other that is processing a large job jobB. The timeout exception, if happened, should ideally indicate the fix does not work. But the timeout period is set too aggressive, so the test always fails  on slow VMs."
MAPREDUCE-6697,Concurrent task limits should only be applied when necessary,"The concurrent task limit feature should only adjust the ANY portion of the AM heartbeat ask when a limit is truly necessary, otherwise extraneous containers could be allocated by the RM to the AM adding some overhead to both.  Specifying a concurrent task limit that is beyond the total number of tasks in the job should be the same as asking for no limit."
MAPREDUCE-6696,Add a configuration to limit the number of map tasks allowed per job.,"Add a configuration ""mapreduce.job.max.map"" to limit the number of map tasks allowed per job. It will be useful for Hadoop admin to save Hadoop cluster resource by preventing users from submitting big mapreduce jobs. A mapredeuce job with too many mappers may fail with OOM after running for long time. It will be a big waste."
MAPREDUCE-6695,Problem accessing /jobtracker.jsp,"Problem accessing /jobtracker.jsp. Reason:

    Too many counters: 121 max=120

Caused by:

org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120
	at org.apache.hadoop.mapreduce.counters.Limits.checkCounters(Limits.java:61)
	at org.apache.hadoop.mapreduce.counters.Limits.incrCounters(Limits.java:68)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.addCounter(AbstractCounterGroup.java:77)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.addCounterImpl(AbstractCounterGroup.java:94)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.findCounterImpl(AbstractCounterGroup.java:122)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.findCounter(AbstractCounterGroup.java:112)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.findCounter(AbstractCounterGroup.java:129)
	at org.apache.hadoop.mapred.Counters$Group.findCounter(Counters.java:323)
	at org.apache.hadoop.mapred.Counters$Group.getCounterForName(Counters.java:268)
	at org.apache.hadoop.mapred.Counters.incrAllCounters(Counters.java:533)
	at org.apache.hadoop.mapred.JobInProgress.incrementTaskCounters(JobInProgress.java:1705)
	at org.apache.hadoop.mapred.JobInProgress.getMapCounters(JobInProgress.java:1667)
	at org.apache.hadoop.mapred.JSPUtil.generateJobTable(JSPUtil.java:428)
	at org.apache.hadoop.mapred.jobtracker_jsp._jspService(jobtracker_jsp.java:207)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:98)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)"
MAPREDUCE-6693,ArrayIndexOutOfBoundsException occurs when the length of the job name is equal to mapreduce.jobhistory.jobname.limit,"Job history entry missing when JOB name is of {{mapreduce.jobhistory.jobname.limit}} character

{noformat}
2016-05-10 06:51:00,674 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Interrupting Event Handling thread
2016-05-10 06:51:00,674 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Waiting for Event Handling thread to complete
2016-05-10 06:51:00,674 ERROR [eventHandlingThread] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[eventHandlingThread,5,main] threw an Exception.
java.lang.ArrayIndexOutOfBoundsException: 50
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.trimURLEncodedString(FileNameIndexUtils.java:326)
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.getDoneFileName(FileNameIndexUtils.java:86)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:1147)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:635)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler$1.run(JobHistoryEventHandler.java:341)
	at java.lang.Thread.run(Thread.java:745)
2016-05-10 06:51:00,675 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Shutting down timer for Job MetaInfo for job_1462840033869_0009 history file hdfs://hacluster:9820/staging-dir/dsperf/.staging/job_1462840033869_0009/job_1462840033869_0009_1.jhist
2016-05-10 06:51:00,675 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Shutting down timer Job MetaInfo for job_1462840033869_0009 history file hdfs://hacluster:9820/staging-dir/dsperf/.staging/job_1462840033869_0009/job_1462840033869_0009_1.jhist
2016-05-10 06:51:00,676 DEBUG [Thread-73] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Closing Writer
{noformat}

Looks like 50 character check is going wrong"
MAPREDUCE-6691,move the shell code out of hadoop-mapreduce-project,We need to move the shell code out of hadoop-mapreduce-project so that we can properly build test code.
MAPREDUCE-6690,Limit the number of resources a single map reduce job can submit for localization,"Users will sometimes submit a large amount of resources to be localized as part of a single map reduce job. This can cause issues with YARN localization that destabilize the cluster and potentially impact other user jobs. These resources are specified via the files, libjars, archives and jobjar command line arguments or directly through the configuration (i.e. distributed cache api). The resources specified could be too large in multiple dimensions:
# Total size
# Number of files
# Size of an individual resource (i.e. a large fat jar)

We would like to encourage good behavior on the client side by having the option of enforcing resource limits along the above dimensions.

There should be a separate effort to enforce limits at the YARN layer on the server side, but this jira is only covering the map reduce layer on the client side. In practice, having these client side limits will get us a long way towards preventing these localization anti-patterns."
MAPREDUCE-6689,MapReduce job can infinitely increase number of reducer resource requests,"We have seen this issue from one of our clusters: when running terasort map-reduce job, some mappers failed after reducer started, and then MR AM tries to preempt reducers to schedule these failed mappers.

After that, MR AM enters an infinite loop, for every RMContainerAllocator#heartbeat run, it:

- In {{preemptReducesIfNeeded}}, it cancels all scheduled reducer requests. (total scheduled reducers = 1024)
- Then, in {{scheduleReduces}}, it ramps up all reducers (total = 1024).

As a result, we can see total #requested-containers increased 1024 for every MRAM-RM heartbeat (1 sec per heartbeat). The AM is hanging for 18+ hours, so we get 18 * 3600 * 1024 ~ 66M+ requested containers in RM side.

And this bug also triggered YARN-4844, which makes RM stop scheduling anything.

Thanks to [~sidharta-s] for helping with analysis. "
MAPREDUCE-6688,Store job configurations in Timeline Service v2,We already have configuration field in HBase schema for application entity. We need to make sure AM write it out when it get launched.
MAPREDUCE-6687,Allow specifing java home via job configuration,"Suggest allowing user to use a preferred JVM implementation (or version) by specifying java home via JobConf, to launch Map/Reduce tasks. 

Especially useful for running A/B tests on real workload or benchmark between JVM implementations."
MAPREDUCE-6686,Add a way to download the job config from the mapred CLI,It would be convenient if there was a way to easily grab the job configuration via the CLI instead of having to find and go to the specific HDFS location to grab it.
MAPREDUCE-6685,LocalDistributedCacheManager can have overlapping filenames,"LocalDistributedCacheManager has this setup:

bq. AtomicLong uniqueNumberGenerator = new AtomicLong(System.currentTimeMillis());

to create this temporary filename:

bq. new FSDownload(localFSFileContext, ugi, conf, new Path(destPath,  Long.toString(uniqueNumberGenerator.incrementAndGet())), resource);

when using LocalJobRunner.  When two or more start on the same machine, then it's possible to end up having the same timestamp or a large enough overlap that two successive timestamps may not be sufficiently far apart.

Given the assumptions:

1) Assume timestamp is the same. Then the most common starting random seed will be the same.
2) Process ID will very likely be unique, but will likely be close in value.
3) Thread ID is not guaranteed to be unique.

A unique ID based on PID as a seed (in addition to the timestamp) should be a better unique identifier for temporary filenames."
MAPREDUCE-6684,High contention on scanning of user directory under immediate_done in Job History Server,"HistoryFileManager.scanIntermediateDirectory() in JHS acquires a lock on each user directory it tries to scan (move or delete files under the user directory as necessary). This method is called in a thread in JobHistory that performs periodical scanning of intermediate directory, and can also be called by web server threads for each Web API call made by a JHS client. In cases where there are many concurrent Web API calls/connections to JHS, all but one thread are blocked on the lock on the user directory. Eventually, client connects will time out, but the threads in JHS will not be killed and leave a lot of TCP connections in CLOSE_WAIT state. 

{noformat}
[systest@vb1120 ~]$ sudo netstat -nap | grep 63729 | sort -k 4
tcp        0      0 10.17.202.19:10020          0.0.0.0:*                   LISTEN      63729/java          
tcp        0      0 10.17.202.19:10020          10.17.198.30:33010          ESTABLISHED 63729/java          
tcp        0      0 10.17.202.19:10020          10.17.200.30:33980          ESTABLISHED 63729/java          
tcp        0      0 10.17.202.19:10020          10.17.202.10:59625          ESTABLISHED 63729/java          
tcp        0      0 10.17.202.19:10020          10.17.202.13:35765          ESTABLISHED 63729/java          
tcp        0      0 10.17.202.19:10033          0.0.0.0:*                   LISTEN      63729/java          
tcp        0      0 10.17.202.19:19888          0.0.0.0:*                   LISTEN      63729/java          
tcp        0      0 10.17.202.19:19888          10.17.198.30:35103          ESTABLISHED 63729/java          
tcp      277      0 10.17.202.19:19888          10.17.198.30:43670          ESTABLISHED 63729/java          
tcp        0      0 10.17.202.19:19888          10.17.198.30:45453          ESTABLISHED 63729/java          
tcp      277      0 10.17.202.19:19888          10.17.198.30:49184          ESTABLISHED 63729/java          
tcp        1      0 10.17.202.19:19888          10.17.202.13:49992          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52703          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52707          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52708          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52710          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52714          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52723          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52726          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52727          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52739          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52749          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52753          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52757          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52760          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52820          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52827          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52829          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52831          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52833          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52836          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52839          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52841          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52843          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52850          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52860          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52876          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52879          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52881          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52884          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52886          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52888          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52891          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52893          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52896          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52898          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52899          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52902          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52909          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52910          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52912          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52923          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52925          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52927          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52930          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52937          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52939          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52945          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52947          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52969          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:52972          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:52975          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53004          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53007          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53009          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53011          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53052          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53058          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53059          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53063          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53071          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53084          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53093          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53095          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53097          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53101          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53104          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53106          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53108          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53110          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53112          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53114          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53115          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53117          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53121          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53123          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53125          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53127          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53129          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53131          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53134          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53138          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53140          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53153          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53155          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53157          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53159          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53173          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53176          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53177          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53178          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53179          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53181          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53183          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53201          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53204          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53218          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53267          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53270          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53275          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53278          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53280          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53283          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53293          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53296          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53299          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53309          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53312          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53314          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53317          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53320          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53322          CLOSE_WAIT  63729/java          
tcp      256      0 10.17.202.19:19888          10.17.202.13:53338          CLOSE_WAIT  63729/java          
tcp      261      0 10.17.202.19:19888          10.17.202.13:53340          CLOSE_WAIT  63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53364          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53366          ESTABLISHED 63729/java          
tcp      260      0 10.17.202.19:19888          10.17.202.13:53367          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53380          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53382          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53386          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53390          ESTABLISHED 63729/java          
tcp      255      0 10.17.202.19:19888          10.17.202.13:53392          ESTABLISHED 63729/java          
tcp     1278      0 10.17.202.19:19888          10.17.202.18:45301          CLOSE_WAIT  63729/java          
tcp     1278      0 10.17.202.19:19888          10.17.202.18:45303          CLOSE_WAIT  63729/java          
tcp     1277      0 10.17.202.19:19888          10.17.202.18:45306          ESTABLISHED 63729/java 
{noformat}"
MAPREDUCE-6683,Execute hadoop 1.0.1 application in hadoop 2.6.0 cause Output directory not set execption,"The application can run normally in Hadoop 1.0.1 but can't run in 2.6.0 even though adapt to use new mapreduce API. 

org.apache.hadoop.mapred.InvalidJobConfException: Output directory not set.
	at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:128)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:889)
	at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:850)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1093)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:850)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:500)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:336)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run(JobControl.java:233)
	at java.lang.Thread.run(Thread.java:745)
"
MAPREDUCE-6682,TestMRCJCFileOutputCommitter fails intermittently,"{noformat}
java.lang.AssertionError: Output directory not empty expected:<0> but was:<4>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.mapred.TestMRCJCFileOutputCommitter.testAbort(TestMRCJCFileOutputCommitter.java:153)
{noformat}

*PreCommit Report* 
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6434/testReport/"
MAPREDUCE-6681,TestUberAM  fails intermittently ,"{noformat}
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.verifySleepJobCounters(TestMRJobs.java:474)
	at org.apache.hadoop.mapreduce.v2.TestUberAM.verifySleepJobCounters(TestUberAM.java:71)
{noformat}

*PreCommit Build* 

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6434/testReport/"
MAPREDUCE-6680,"JHS UserLogDir scan algorithm sometime could skip directory with update in CloudFS (Azure FileSystem, S3, etc.)","In our cluster based on a Cloud FileSystem, we notice JHS sometimes could skip directory with .jhist file in scanning.
The behavior is like:
First round scan, doesn't found .jhist file:
{noformat}
16/04/13 11:14:34 DEBUG azure.NativeAzureFileSystem: Found path as a directory with 6 files in it.
16/04/13 11:14:34 DEBUG hs.HistoryFileManager: Found 0 files
...
{noformat}

Then, we see ""Scan not needed of ..."" for the same directory every 3 minutes until application failed as timeout.

From our analysis, we found the root cause is: most of Cloud File System (Azure FS, S3, etc.) is truncating file/directory modification time to seconds instead of milliseconds - which could due to limit of http protocol (from discussion at: https://forums.aws.amazon.com/thread.jspa?messageID=476615). 

So if the time sequence is happen to be: latest non .jhist file modification on directory happens at T1, directory scanning happens at T2, .jhist file added to directory at T3. If we have {{T1< T2 < T3}} and T1 is equal to T3 after truncating to seconds, this issue could appear."
MAPREDUCE-6678,Allow ShuffleHandler readahead without drop-behind,"Currently mapreduce.shuffle.manage.os.cache enables/disables both readahead (POSIX_FADV_WILLNEED) and drop-behind (POSIX_FADV_DONTNEED) logic within the ShuffleHandler.

It would be beneficial if these were separately configurable. 
- Running without readahead can lead to significant seek storms caused by large numbers of sendfiles() competing with one another.
- However, running with drop-behind can also lead to seek storms because there are cases where the server can successfully write the shuffle bytes to the network, BUT the client doesn't want the bytes right now (MergeManager wants to WAIT is an example) so it ignores them and asks for them again a bit later. This causes repeated reads of the same data from disk.

I'll attach a simple patch that enables/disables readahead based on mapreduce.shuffle.readahead.bytes==0, leaving mapreduce.shuffle.manage.os.cache controlling only the drop-behind.
"
MAPREDUCE-6677,LocalContainerAllocator doesn't specify resource of the containers allocated.,
MAPREDUCE-6676,NNBench should Throw IOException when rename and delete fails,"Throw IOException when rename,delete fails, currently it's unknown to user when rename and delte fails.."
MAPREDUCE-6675,TestJobImpl.testUnusableNode failed ,"TestJobImpl#testUnusableNodeTransition is flaky.

2016-02-13 09:16:42 Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
2016-02-13 09:16:50 Tests run: 17, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 8.324 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
2016-02-13 09:16:50 testUnusableNodeTransition(org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl)  Time elapsed: 5.165 sec  <<< FAILURE!
2016-02-13 09:16:50 java.lang.AssertionError: expected:<SUCCEEDED> but was:<ERROR>
2016-02-13 09:16:50 	at org.junit.Assert.fail(Assert.java:88)
2016-02-13 09:16:50 	at org.junit.Assert.failNotEquals(Assert.java:743)
2016-02-13 09:16:50 	at org.junit.Assert.assertEquals(Assert.java:118)
2016-02-13 09:16:50 	at org.junit.Assert.assertEquals(Assert.java:144)
2016-02-13 09:16:50 	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.assertJobState(TestJobImpl.java:977)
2016-02-13 09:16:50 	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.testUnusableNodeTransition(TestJobImpl.java:627)
2016-02-13 09:16:50 
2016-02-13 09:16:50 
2016-02-13 09:16:50 Results :
2016-02-13 09:16:50 
2016-02-13 09:16:50 Failed tests: 
2016-02-13 09:16:50   TestJobImpl.testUnusableNodeTransition:627->assertJobState:977 expected:<SUCCEEDED> but was:<ERROR>
2016-02-13 09:16:50 
2016-02-13 09:16:50 Tests run: 17, Failures: 1, Errors: 0, Skipped: 0.


Looking at the code, an JobUpdatedNodesEvent is handled by putting an TaskAttemptKill event on the async dispatcher queue and return immediately, but the event might not have been processed by the time  all JobTaskEvents events are seen by the job (the jobTaskSucceeded events are handed to Job immediately without going through the dispatcher). Therefore, there is a slight chance that the job will see all three succeeded attempts and  transition to Committing state before the taskAttemptKill event is handled by the dispatcher. Committing jobs will reject later JobTaskEvents received, transition to InternalError state and cause the test to fail."
MAPREDUCE-6674,configure parallel tests for mapreduce-client-jobclient,mapreduce-client-jobclient takes almost an hour and a half.  Configuring parallel-tests would greatly reduce this run time.
MAPREDUCE-6673,Add a test example job that grows in memory usage over time,"While working on YARN-1011, I needed to put together an example that would have tasks increase their resource usage deterministically over time. It would be useful for any other utilization related work or stress tests. "
MAPREDUCE-6672,TestTeraSort fails on Windows,"TestTeraSort testcase fails on Windows.

The test case uses the build directory as test working directory.
Under Windows the build directory starts with a drive definition ( ""C:"" ),
which is interpreted as (an invalid) URI scheme. 

The fix is trivial: Add URI scheme to the beginning of the working directory.

Error message:
{noformat}
Running org.apache.hadoop.examples.terasort.TestTeraSort
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.647 sec <<< FAILURE! - in org.apache.hadoop.examples.terasort.TestTeraSort
testTeraSort(org.apache.hadoop.examples.terasort.TestTeraSort)  Time elapsed: 3.359 sec  <<< ERROR!
java.io.IOException: No FileSystem for scheme: C
        at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2787)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2798)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:99)
        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2837)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2819)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:381)
        at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:223)
        at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:93)
        at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:57)
        at org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:179)
        at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:98)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:193)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1742)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1359)
        at org.apache.hadoop.examples.terasort.TeraSort.run(TeraSort.java:331)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
        at org.apache.hadoop.examples.terasort.TestTeraSort.runTeraSort(TestTeraSort.java:75)
        at org.apache.hadoop.examples.terasort.TestTeraSort.testTeraSort(TestTeraSort.java:101)


Results :

Tests in error:
  TestTeraSort.testTeraSort:101->runTeraSort:75 ╗ IO No FileSystem for scheme: C

Tests run: 2, Failures: 0, Errors: 1, Skipped: 0
{noformat}



"
MAPREDUCE-6670,TestJobListCache#testEviction sometimes fails on Windows with timeout,TestJobListCache#testEviction often needs more than 1000 ms to finish in Windows environment. Increasing the timeout solves the issue.
MAPREDUCE-6669,Jobs with encrypted spills don't tolerate AM failures,"The key used for encrypting intermediate data is not persisted anywhere, and hence can't be recovered the same way other MR jobs can be. We should support recovering these jobs as well, hopefully without having to re-run completed tasks."
MAPREDUCE-6667,Migrate MR test cases part 3,"Migrate the following to JUnit4

./hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapred/TestMRWithDistributedCache.java:public class TestMRWithDistributedCache extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestFileOutputCommitter.java:public class TestFileOutputCommitter extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestIndexCache.java:public class TestIndexCache extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java:public class TestJobEndNotifier extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestFileOutputCommitter.java:public class TestFileOutputCommitter extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestFileOutputFormat.java:public class TestFileOutputFormat extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/TestJobMonitorAndPrint.java:public class TestJobMonitorAndPrint extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/DistributedFSCheck.java:public class DistributedFSCheck extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestDelegatingInputFormat.java:public class TestDelegatingInputFormat extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRCJCFileOutputCommitter.java:public class TestMRCJCFileOutputCommitter extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/buffer/TestInputBuffer.java:public class TestInputBuffer extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/buffer/TestOutputBuffer.java:public class TestOutputBuffer extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/serde/TestKVSerializer.java:public class TestKVSerializer extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/TestTaskContext.java:public class TestTaskContext extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/utils/TestReadWriteBuffer.java:public class TestReadWriteBuffer extends TestCase {
./hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/utils/TestSizedWritable.java:public class TestSizedWritable extends TestCase {"
MAPREDUCE-6663,[NNBench] Refactor nnbench as a Tool implementation.,"Refactor NNBench as a tool to accept generic command line option, and add a regression test."
MAPREDUCE-6662,Clear ASF Warnings on test data files,"In all MAPREDUCE QA runs, '14 ASF Warnings' will mark the entire QA result as '-1 Overall'.
These warnings are from the files generated in tests.

It will be good to see green +1s in QA report than RED -1(s)."
MAPREDUCE-6657,job history server can fail on startup when NameNode is in start phase,"Job history server will try to create a history directory in HDFS on startup. When NameNode is in safe mode, it will keep retrying for a configurable time period.  However, it should also keeps retrying if the name node is in start state. Safe mode does not happen until the NN is out of the startup phase. 

A RetriableException with the text ""NameNode still not started"" is thrown when the NN is in its internal service startup phase. We should add the check for this specific exception in isBecauseSafeMode() to account for that."
MAPREDUCE-6656,[NNBench] OP_DELETE operation isn't working after MAPREDUCE-6363,"After the fix of MAPREDUCE-6363, in NNBench OP_DELETE Operation isn't working."
MAPREDUCE-6655,Fix a typo (STRICT_IE6) in Encrypted Shuffle,"Found a typo in Encrypted Shuffle documentation (STRICT_I6 --> STRICT_IE6).
The typo also appears in core-default.xml"
MAPREDUCE-6652,Add configuration property to prevent JHS from loading jobs with a task count greater than X,"Jobs with large number of tasks can have job history files that are large in size and resource-consuming(mainly memory) to parse in Job History Server. If there are many such jobs, the job history server can very easily hang.

It would be a good usability feature if we added a new config property that could be set to X, where the JHS wouldn't load the details for a job with more than X tasks. The job would still show up on the list of jobs page, but clicking on it would give a warning message that the job is too big, instead of actually loading the job. This way we can prevent users from loading a job that's way too big for the JHS, which currently makes the JHS hang. The default value can be -1 so that it's disabled.
"
MAPREDUCE-6649,getFailureInfo not returning any failure info,"The following command does not produce any failure info as to why the job failed. 

{noformat}
$HADOOP_PREFIX/bin/hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-${HADOOP_VERSION}-tests.jar sleep -Dmapreduce.jobtracker.split.metainfo.maxsize=10 -Dmapreduce.job.queuename=default -m 1 -r 1 -mt 1 -rt 1
{noformat}

{noformat}
2016-03-07 10:34:58,112 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1431)) - Job job_1457364518683_0004 failed with state FAILED due to: 
{noformat}

To contrast, here is a command and associated command line output to show a failed job that gives the correct failiure info. 

{noformat}
$HADOOP_PREFIX/bin/hadoop jar $HADOOP_PREFIX/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-${HADOOP_VERSION}-tests.jar sleep -Dyarn.app.mapreduce.am.command-opts=-goober -Dmapreduce.job.queuename=default -m 20 -r 0 -mt 30000
{noformat}

{noformat}
2016-03-07 10:30:13,103 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1431)) - Job job_1457364518683_0003 failed with state FAILED due to: Application application_1457364518683_0003 failed 3 times due to AM Container for appattempt_1457364518683_0003_000003 exited with  exitCode: 1
Failing this attempt.Diagnostics: Exception from container-launch.
Container id: container_1457364518683_0003_03_000001
Exit code: 1
Stack trace: ExitCodeException exitCode=1: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:927)
	at org.apache.hadoop.util.Shell.run(Shell.java:838)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:227)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:319)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:88)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
{noformat}"
MAPREDUCE-6648,Add yarn.app.mapreduce.am.log.level to mapred-default.xml,
MAPREDUCE-6647,MR usage counters use the resources requested instead of the resources allocated,"As can be seen in the following snippet, the MR counters for usage use the resources requested instead of the resources allocated. The scheduler increment-allocation-mb configs could lead to these values not being the same. We could change the counters to use the allocated resources in order to account for this.

{code}
  private static void updateMillisCounters(JobCounterUpdateEvent jce,
      TaskAttemptImpl taskAttempt) {
     /***omitted**/
    long duration = (taskAttempt.getFinishTime() - taskAttempt.getLaunchTime());
    int mbRequired =
        taskAttempt.getMemoryRequired(taskAttempt.conf, taskType);
    int vcoresRequired = taskAttempt.getCpuRequired(taskAttempt.conf, taskType);

    int minSlotMemSize = taskAttempt.conf.getInt(
      YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB,
      YarnConfiguration.DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB);

    int simSlotsRequired =
        minSlotMemSize == 0 ? 0 : (int) Math.ceil((float) mbRequired
            / minSlotMemSize);

    if (taskType == TaskType.MAP) {
      jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_MAPS, simSlotsRequired * duration);
      jce.addCounterUpdate(JobCounter.MB_MILLIS_MAPS, duration * mbRequired);
      jce.addCounterUpdate(JobCounter.VCORES_MILLIS_MAPS, duration * vcoresRequired);
      jce.addCounterUpdate(JobCounter.MILLIS_MAPS, duration);
    } else {
      jce.addCounterUpdate(JobCounter.SLOTS_MILLIS_REDUCES, simSlotsRequired * duration);
      jce.addCounterUpdate(JobCounter.MB_MILLIS_REDUCES, duration * mbRequired);
      jce.addCounterUpdate(JobCounter.VCORES_MILLIS_REDUCES, duration * vcoresRequired);
      jce.addCounterUpdate(JobCounter.MILLIS_REDUCES, duration);
    }
{code}
"
MAPREDUCE-6645,TestWordStats outputs logs under directories other than target/test-dir,
MAPREDUCE-6644,Use doxia macro to generate in-page TOC of MapReduce site documentation,"Since maven-site-plugin 3.5 was released, we can use toc macro in Markdown."
MAPREDUCE-6641,TestTaskAttempt fails in trunk,"{code}
Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
Tests run: 23, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 24.917 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
testMRAppHistoryForTAFailedInAssigned(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)  Time elapsed: 12.732 sec  <<< FAILURE!
java.lang.AssertionError: No Ta Started JH Event
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.assertTrue(Assert.java:41)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.testTaskAttemptAssignedKilledHistory(TestTaskAttempt.java:388)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.testMRAppHistoryForTAFailedInAssigned(TestTaskAttempt.java:177)
{code}"
MAPREDUCE-6640,mapred job -history command should be able to take Job ID,"The {{mapred job -history}} command currently accepts only a {{jobHistoryFile>}}.  It would be much easier for the user if it could also accept a Job ID so the user doesn't have to go and find the jhist file.  It would also be more consistent with the other commands, which generally take a Job ID."
MAPREDUCE-6639,Process hangs in LocatedFileStatusFetcher if FileSystem.get throws,"ListLocatedFileStatusFetcher uses a thread pool, but one of the Callable thread functions, [{{ProcessInitialInputPathCallable}}|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/LocatedFileStatusFetcher.java#L306], doesn't catch exceptions (the callbacks do). When an exception is thrown, the thread exists and doesn't signal the error to the calling thread, which continues waiting to be signaled. This can happen when a FS implementation cannot be found."
MAPREDUCE-6638,Do not attempt to recover progress from previous job attempts if spill encryption is enabled,"Post the fix to CVE-2015-1776, jobs with ecrypted spills enabled cannot be recovered if the AM fails. We should store the key some place safe so they can actually be recovered. If there is no ""safe"" place, at least we should restart the job by re-running all mappers/reducers. "
MAPREDUCE-6637,Testcase Failure : TestFileInputFormat.testSplitLocationInfo,"Following testcase is failing after HADOOP-12810
{noformat}
FAILED:  org.apache.hadoop.mapred.TestFileInputFormat.testSplitLocationInfo[0]

Error Message:
expected:<2> but was:<1>

Stack Trace:
java.lang.AssertionError: expected:<2> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapred.TestFileInputFormat.testSplitLocationInfo(TestFileInputFormat.java:115)

{noformat}"
MAPREDUCE-6635,Unsafe long to int conversion in UncompressedSplitLineReader and IndexOutOfBoundsException,"LineRecordReader creates the unsplittable reader like so:
{noformat}
      in = new UncompressedSplitLineReader(
          fileIn, job, recordDelimiter, split.getLength());
{noformat}
Split length goes to
{noformat}
  private long splitLength;
{noformat}
At some point when reading the first line, fillBuffer does this:
{noformat}
  @Override
  protected int fillBuffer(InputStream in, byte[] buffer, boolean inDelimiter)
      throws IOException {
    int maxBytesToRead = buffer.length;
    if (totalBytesRead < splitLength) {
      maxBytesToRead = Math.min(maxBytesToRead,
                                (int)(splitLength - totalBytesRead));
{noformat}
which will be a negative number for large splits, and the subsequent dfs read will fail with a boundary check.
{noformat}
java.lang.IndexOutOfBoundsException
        at java.nio.Buffer.checkBounds(Buffer.java:559)
        at java.nio.ByteBuffer.get(ByteBuffer.java:668)
        at java.nio.DirectByteBuffer.get(DirectByteBuffer.java:279)
        at org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:172)
        at org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:744)
        at org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:800)
        at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:860)
        at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:903)
        at java.io.DataInputStream.read(DataInputStream.java:149)
        at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:59)
        at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
        at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
        at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:91)
        at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:144)
        at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:184)
{noformat}
This has been reported here: https://issues.streamsets.com/browse/SDC-2229, also happens in Hive if very large text files are forced to be read in a single split (e.g. via header-skipping feature, or via set mapred.min.split.size=9999999999999999)
"
MAPREDUCE-6634,Log uncaught exceptions/errors in various thread pools in mapreduce,"For a detailed description, please see HADOOP-12748
"
MAPREDUCE-6633,AM should retry map attempts if the reduce task encounters commpression related errors.,"When reduce task encounters compression related errors, AM  doesn't retry the corresponding map task.
In one of the case we encountered, here is the stack trace.
{noformat}
2016-01-27 13:44:28,915 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#29
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1694)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.ArrayIndexOutOfBoundsException
	at com.hadoop.compression.lzo.LzoDecompressor.setInput(LzoDecompressor.java:196)
	at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:104)
	at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85)
	at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:192)
	at org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput.shuffle(InMemoryMapOutput.java:97)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:537)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:336)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)
{noformat}
In this case, the node on which the map task ran had a bad drive.
If the AM had retried running that map task somewhere else, the job definitely would have succeeded."
MAPREDUCE-6632,Master.getMasterAddress() should be updated to use YARN-4629,The new {{YarnClientUtil.getRmPrincipal()}} method can replace most of the {{Master.getMasterAddress()}} method and should to reduce redundancy and improve servicability.
MAPREDUCE-6628,Potential memory leak in CryptoOutputStream,"There is a potential memory leak in {{CryptoOutputStream.java.}}  It allocates two direct byte buffers ({{inBuffer}} and {{outBuffer}}) that get freed when {{close()}} method is called.  Most of the time, {{close()}} method is called.  However, when writing to intermediate Map output file or the spill files in {{MapTask}}, {{close()}} is never called since calling so  would close the underlying stream which is not desirable.  There is a single underlying physical stream that contains multiple logical streams one per partition of Map output.  

By default the amount of memory allocated per byte buffer is 128 KB and  so the total memory allocated is 256 KB,  This may not sound much.  However, if the number of partitions (or number of reducers) is large (in the hundreds) and/or there are spill files created in {{MapTask}}, this can grow into a few hundred MB. 

I can think of two ways to address this issue:

h2. Possible Fix - 1
According to JDK documentation:
{quote}
The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory footprint of an application might not be obvious.  It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system's native I/O operations.  In general it is best to allocate direct buffers only when they yield a measureable gain in program performance.
{quote}
It is not clear to me whether there is any benefit of allocating direct byte buffers in {{CryptoOutputStream.java}}.  In fact, there is a slight CPU overhead in moving data from {{outBuffer}} to a temporary byte array as per the following code in {{CryptoOutputStream.java}}.
{code}
    /*
     * If underlying stream supports {@link ByteBuffer} write in future, needs
     * refine here. 
     */
    final byte[] tmp = getTmpBuf();
    outBuffer.get(tmp, 0, len);
    out.write(tmp, 0, len);
{code}
Even if the underlying stream supports direct byte buffer IO (or direct IO in OS parlance), it is not clear whether it will yield any measurable performance gain.

The fix would be to allocate a ByteBuffer on the heap for inBuffer and wrap a byte array in a {{ByteBuffer}} for {{outBuffer}}.  By the way, the {{inBuffer}} and {{outBuffer}} have to be {{ByteBuffer}} as demanded by the {{encrypt()}} method in {{Encryptor}}.

h2. Possible Fix - 2
Assuming that we want to keep the buffers as direct byte buffers, we can create a new constructor to {{CryptoOutputStream}} and pass a boolean flag {{ownOutputStream}} to indicate whether the underlying stream will be owned by {{CryptoOutputStream}}. If it is true, then calling the {{close()}} method will close the underlying stream.  Otherwise, when {{close()}} is called only the direct byte buffers will be freed and the underlying stream will not be closed.

The scope of changes for this fix will be somewhat wider.  We need to modify {{MapTask.java}}, {{CryptoUtils.java}}, and {{CryptoFSDataOutputStream.java}} as well to pass the ownership flag mentioned above.

I can post a patch for either of the above.  I welcome any other ideas from developers to fix this issue.
"
MAPREDUCE-6627,Add machine-readable output to mapred job -history command,"It would be great if we could add a machine-readable output format, say JSON, to the {{mapred job -history \[all\] <jobHistoryFile>}} command so that it's easier for programs to consume that information and do further processing on it.  At the same time, we should keep the existing API and formatting intact for backwards compatibility."
MAPREDUCE-6626,Reuse ObjectMapper instance in MapReduce,"Now in MapReduce, there are some places creating a new ObjectMapper instance every time. In wiki of ObjectMapper, it suggested:
{code}
Further: it is beneficial to use just one instance (or small number of instances) for data binding; many optimizations for reuse (of symbol tables, some buffers) depend on ObjectMapper instances being reused. 
{code}
http://webcache.googleusercontent.com/search?q=cache:kybMTIJC6F4J:wiki.fasterxml.com/JacksonFAQ+&cd=4&hl=ja&ct=clnk&gl=jp, it's similar to HDFS-9724."
MAPREDUCE-6625,TestCLI#testGetJob fails occasionally,"Lately TestCLI has been failing sometimes in precommit builds:
{noformat}
Running org.apache.hadoop.mapreduce.tools.TestCLI
Tests run: 4, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.883 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.tools.TestCLI
testGetJob(org.apache.hadoop.mapreduce.tools.TestCLI)  Time elapsed: 0.037 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.tools.TestCLI.testGetJob(TestCLI.java:175)
{noformat}
"
MAPREDUCE-6623,TestRMNMInfo and TestNetworkedJob fails in trunk,"TestRMNMInfo:
{code}
Running org.apache.hadoop.mapreduce.v2.TestRMNMInfo
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 32.347 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestRMNMInfo
testRMNMInfo(org.apache.hadoop.mapreduce.v2.TestRMNMInfo)  Time elapsed: 1.572 sec  <<< FAILURE!
java.lang.AssertionError: Unexpected number of live nodes: expected:<4> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.apache.hadoop.mapreduce.v2.TestRMNMInfo.testRMNMInfo(TestRMNMInfo.java:111)
{code}

TestNetworkedJob
{code}
testNetworkedJob:174 expected:<[[Thu Jan 28 22:41:20 +0000 2016] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:8192, vCores:16> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 0.0 % ; Queue's Absolute max capacity = 100.0 % ; ]> but was:<[]>
  TestRMNMInfo.testRMNMInfo:111 Unexpected number of live nodes: expected:<4> but was:<0>
{code}

JDK version: JDK v1.8.0_66

"
MAPREDUCE-6622,Add capability to set JHS job cache to a task-based limit,"When setting the property mapreduce.jobhistory.loadedjobs.cache.size the jobs can be of varying size.  This is generally not a problem when the jobs sizes are uniform or small, but when the job sizes can be very large (say greater than 250k tasks), then the JHS heap size can grow tremendously.

In cases, where multiple jobs are very large, then the JHS can lock up and spend all its time in GC.  However, since the cache is holding on to all the jobs, not much heap space can be freed up.

By setting a property that sets a cap on the number of tasks allowed in the cache and since the total number of tasks loaded is directly proportional to the amount of heap used, this should help prevent the JHS from locking up.
"
MAPREDUCE-6621,Memory Leak in JobClient#submitJobInternal(),"In JobClient:
{code}
public RunningJob submitJobInternal(final JobConf conf)
      throws FileNotFoundException, IOException {
    try {
      conf.setBooleanIfUnset(""mapred.mapper.new-api"", false);
      conf.setBooleanIfUnset(""mapred.reducer.new-api"", false);
      Job job = clientUgi.doAs(new PrivilegedExceptionAction<Job> () {
        @Override
        public Job run() throws IOException, ClassNotFoundException, 
          InterruptedException {
          Job job = Job.getInstance(conf);
          job.submit();
          return job;
        }
      });

      // update our Cluster instance with the one created by Job for submission
      // (we can't pass our Cluster instance to Job, since Job wraps the config
      // instance, and the two configs would then diverge)
      cluster = job.getCluster();

      return new NetworkedJob(job);
    } catch (InterruptedException ie) {
      throw new IOException(""interrupted"", ie);
    }
  }
{code}
We will replace the cluster object with the cluster object from Job, but the previous old cluster object would never be closed."
MAPREDUCE-6620,Jobs that did not start are shown as starting in 1969 in the JHS web UI,"If a job fails, its start time is stored as -1.  The RM UI correctly handles negative start times.  The JHS UI does not, blindly converting it into a date in 1969."
MAPREDUCE-6619,HADOOP_CLASSPATH is overwritten in MR container,Previously env variable HADOOP_CLASSPAH in MR containers inherit from defaults of the worker node. MAPREDUCE-6454 introduced change to overwrite HADOOP_CLASSPATH completely. This caused regression. We need to add additional entries to HADOOP_CLASSPATH instead of completely replacing it.
MAPREDUCE-6618,YarnClientProtocolProvider leaking the YarnClient thread. ,"YarnClientProtocolProvider creates YarnRunner which includes ResourceMgrDelegate. In ResourceMgrDelegate, we would initiate and start yarnclient. The yarnClient thread would be leaked due to
{code}
  @Override
  public void close(ClientProtocol clientProtocol) throws IOException {
    // nothing to do
  }
{code} in YarnClientProtocolProvider"
MAPREDUCE-6616,Fail to create jobhistory file if there are some multibyte characters in the job name,"When creating jobhistory file, job name is trimmed within 50 characters by default, and the name is URL-encoded *after* the job name is trimmed. Therefore, if there are some multibyte characters in the job name, the encoded job name can be longer than 50 characters. Eventually it can break the limit of the file name (Usually 255 characters)."
MAPREDUCE-6614,Remove unnecessary code in TestMapreduceConfigFields,"In branch-2, the following code can be removed because these parameters are in both mapred-default.xml and MRJobConfig.java.
{code:title=TestMapreduceConfigFields.java}
    xmlPropsToSkipCompare.add(""mapreduce.reduce.skip.proc-count.auto-incr"");
    xmlPropsToSkipCompare.add(""mapreduce.map.skip.proc-count.auto-incr"");
{code}"
MAPREDUCE-6613,Change mapreduce.jobhistory.jhist.format default from json to binary,"MAPREDUCE-6376 added a configuration setting to set up .jhist internal format:

mapreduce.jobhistory.jhist.format

Currently, the default is ""json"".  Changing the default to ""binary"" allows faster parsing, but with the downside of making the file not output friendly by using ""hadoop fs cat""."
MAPREDUCE-6610,JobHistoryEventHandler should not swallow timeline response,"As discussed in YARN-4596, JobHistoryEventHandler should process and log timeline put errors after the timeline put call. "
MAPREDUCE-6607,Enable regex pattern matching when mapreduce.task.files.preserve.filepattern is set,"if either of the following configs are set, then .staging dir is not cleaned up:
* mapreduce.task.files.preserve.failedtask 
* mapreduce.task.files.preserve.filepattern

The former was supposed to keep only .staging of failed tasks and the latter was supposed to be used only if that task name matches against the specified regular expression.

{code}
  protected boolean keepJobFiles(JobConf conf) {
    return (conf.getKeepTaskFilesPattern() != null || conf
        .getKeepFailedTaskFiles());
  }
{code}

{code}
  public void cleanupStagingDir() throws IOException {
    /* make sure we clean the staging files */
    String jobTempDir = null;
    FileSystem fs = getFileSystem(getConfig());
    try {
      if (!keepJobFiles(new JobConf(getConfig()))) {
        jobTempDir = getConfig().get(MRJobConfig.MAPREDUCE_JOB_DIR);
        if (jobTempDir == null) {
          LOG.warn(""Job Staging directory is null"");
          return;
        }
        Path jobTempDirPath = new Path(jobTempDir);
        LOG.info(""Deleting staging directory "" + FileSystem.getDefaultUri(getConfig()) +
            "" "" + jobTempDir);
        fs.delete(jobTempDirPath, true);
      }
    } catch(IOException io) {
      LOG.error(""Failed to cleanup staging dir "" + jobTempDir, io);
    }
  }
{code}

"
MAPREDUCE-6606,Findbug issue in org.apache.hadoop.mapred.OutputCommitter,"{noformat}
org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext) doesn't override method in superclass because parameter type org.apache.hadoop.mapred.JobContext doesn't match superclass parameter type org.apache.hadoop.mapreduce.JobContext
	

Bug type NM_WRONG_PACKAGE_INTENTIONAL (click for details)
In class org.apache.hadoop.mapred.OutputCommitter
In method org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)
superclass is org.apache.hadoop.mapreduce.OutputCommitter
Did you intend to override org.apache.hadoop.mapreduce.OutputCommitter.isCommitJobRepeatable(JobContext)
Actual type org.apache.hadoop.mapred.JobContext
Expected org.apache.hadoop.mapreduce.JobContext
Overrides org.apache.hadoop.mapred.OutputCommitter.isCommitJobRepeatable(JobContext)
At OutputCommitter.java:[line 230]
{noformat}

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6268/artifact/patchprocess/branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core-warnings.html#Warnings_BAD_PRACTICE
"
MAPREDUCE-6605,Fix typos mapreduce.map.skip.proc.count.autoincr and mapreduce.reduce.skip.proc.count.autoincr in mapred-default.xml,"As the default configuration file shows,
https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml

 we can configure options
mapreduce.map.skip.proc.count.autoincr
mapreduce.reduce.skip.proc.count.autoincr
in the mapred-default.xml. But they do not work because the expected keys in org.apache.hadoop.mapreduce.MRJobConfig.java

public static final String MAP_SKIP_INCR_PROC_COUNT = ""mapreduce.map.skip.proc-count.auto-incr""
public static final String REDUCE_SKIP_INCR_PROC_COUNT = ""mapreduce.reduce.skip.proc-count.auto-incr"";

Or
in org.apache.hadoop.mapreduce.util.ConfigUtil.java

new DeprecationDelta(""mapred.skip.map.auto.incr.proc.count"",
        MRJobConfig.MAP_SKIP_INCR_PROC_COUNT),
new DeprecationDelta(""mapred.skip.reduce.auto.incr.proc.count"",
        MRJobConfig.REDUCE_SKIP_INCR_PROC_COUNT),

we can change them to mapreduce.map.skip.proc-count.auto-incr and mapreduce.reduce.skip.proc-count.auto-incr in the default configuration file.
 "
MAPREDUCE-6601,Fix typo in Job#setUseNewAPI,"""compatability"" -> ""compatibility"""
MAPREDUCE-6598,"LineReader enhencement to support text records contains ""\n""","We have billions of XML message records stored on text files need to be parsed parallel by Spark. By default, Spark open a Hadoop text file using LineReader which provides a single line of text as a record. 

The XML messages contains ""\n"" and I believe it is a common scenario - many users have cross-line records. Currently, the solution is to the extend the interface RecordReader.

To reduce the repeat work, I wrote a class named MessageRecordReader to extend the interface RecordReader, user can set a string as record delimiter, then MessageRecordReader provides a multiple line record to user. 

I would like to contribute the code to community. Please let me know if you are interested in this simple but useful implementation. 

Thank you very much and happy new year!"
MAPREDUCE-6595,Fix findbugs warnings in OutputCommitter and FileOutputCommitter,There are 2 findbugs warnings in hadoop-mapreduce-client-core module. https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6237/artifact/patchprocess/branch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core-warnings.html
MAPREDUCE-6593,TestJobHistoryEventHandler.testTimelineEventHandling fails on trunk because of NPE,"https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/824/

{code}
Tests run: 13, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 21.163 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler
testTimelineEventHandling(org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler)  Time elapsed: 5.115 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:331)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processEventForTimelineServer(JobHistoryEventHandler.java:1015)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:586)
	at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.handleEvent(TestJobHistoryEventHandler.java:722)
	at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testTimelineEventHandling(TestJobHistoryEventHandler.java:510)
{code}"
MAPREDUCE-6592,MR ApplicationMaster is not supposed to resolve rack locality! It should ask RM or NN about the topology,"While working on configuring Rack Awareness (following [HDP Documentation|http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.5/bk_system-admin-guide/content/admin_configure_rack_awareness.html]), we realized that this does not work for MR applications, unless the rack topology resolution script is installed on the node managers where the application masters reside. Otherwise, the AM will thrown an {{IOException: Cannot run program ""/etc/hadoop/conf/rack_topology.sh""}}. 

This is contradictory to the documentations which states it makes sense to have the scripts that resolve the rack and node names on the Resource Manager and Name Node. 

It is clearly not scalable to require to install these scripts on all the node managers!"
MAPREDUCE-6591,TestJobHistoryEventHandler#testTimelineEventHandling failing in trunk,"org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testTimelineEventHandling failing in trunk


{noformat}
java.lang.NullPointerException: null
	at org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:331)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processEventForTimelineServer(JobHistoryEventHandler.java:1015)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.handleEvent(JobHistoryEventHandler.java:586)
	at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.handleEvent(TestJobHistoryEventHandler.java:722)
	at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testTimelineEventHandling(TestJobHistoryEventHandler.java:510)
{noformat}

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6240/testReport/"
MAPREDUCE-6590,Update MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV value for loading correct navite lib when using ubertask feature,"By default, the MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set.
If yarn.app.mapreduce.am.admin.user.env (or yarn.app.mapreduce.am.env) is not configured to set LD_LIBRARY_PATH, MR AM will fail to load the native library, then you can find the error message as below.
{panel}
org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable.
{panel}
I found the patch in https://issues.apache.org/jira/browse/MAPREDUCE-5799 update YARNRunner code and use MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV as the default value. The code is as below.
{code:title=YARNRunner.java|borderStyle=solid}
    MRApps.setEnvFromInputString(environment, 
        conf.get(MRJobConfig.MR_AM_ADMIN_USER_ENV,
            MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV), conf);
{code}
In fact the parameters yarn.app.mapreduce.am.env and yarn.app.mapreduce.am.admin.user.env are resolved in YARNRunner running on hadoop client host.
But their values, e.g. LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native, will be used on hadoop cluster hosts.
If the hadoop client host installs hadoop on a different path from that on hadoop cluster hosts,
the $HADOOP_COMMON_HOME/lib/native will be resolved to a path which is not existed on hadoop cluster hosts.
Then MRAppMaster running on hadoop cluster host cannot load native lib.
If don't use MAPREDUCE-5799 patch, I set my hadoop client's mapred-site.xml with the following content.
{code:xml}
<property>
        <name>yarn.app.mapreduce.am.admin.user.env</name>
        <value>LD_LIBRARY_PATH={{HADOOP_COMMON_HOME}}/lib/native</value>        
</property>
{code}
In this way, the YARNRunner will put LD_LIBRARY_PATH={{HADOOP_COMMON_HOME}}/lib/native into environment. 
The method ContainerLaunch.expandEnvironment running in NodeManager can translate LD_LIBRARY_PATH={{HADOOP_COMMON_HOME}}/lib/native 
to LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native. 
The host running NodeManager can find its $HADOOP_COMMON_HOME/lib/native path.

I suggest MRJobConfig.DEFAULT_MAPRED_ADMIN_USER_ENV should be defined as below.
{code:title=MRJobConfig.java|borderStyle=solid}
public final String DEFAULT_MAPRED_ADMIN_USER_ENV = 
      Shell.WINDOWS ? 
          ""PATH={{PATH}};{{HADOOP_COMMON_HOME}}\\bin"":
          ""LD_LIBRARY_PATH={{HADOOP_COMMON_HOME}}/lib/native"";
{code}
Please see my patch."
MAPREDUCE-6589,TestTaskLog outputs a log under directory other than target/test-dir,"In MAPREDUCE-6584, Jenkins reported license error for {{location/debugout}}, which is created by {{TestTaskLog}}.
The test should create a file under {{target/test-dir}} and remove the file after the test."
MAPREDUCE-6587,Remove unused params in connection-related methods of Fetcher,"There are some unused params in Fecther#openConnectionWithRetry.The code is following:
{code}
private void openConnectionWithRetry(MapHost host,
      Set<TaskAttemptID> remaining, URL url) throws IOException {
    long startTime = Time.monotonicNow();
    boolean shouldWait = true;
    while (shouldWait) {
      try {
        openConnection(url);
        shouldWait = false;
      } catch (IOException e) {
        if (!fetchRetryEnabled) {
           // throw exception directly if fetch's retry is not enabled
           throw e;
        }
        if ((Time.monotonicNow() - startTime) >= this.fetchRetryTimeout) {
          LOG.warn(""Failed to connect to host: "" + url + ""after "" 
              + fetchRetryTimeout + "" milliseconds."");
          throw e;
        }
        try {
          Thread.sleep(this.fetchRetryInterval);
        } catch (InterruptedException e1) {
          if (stopped) {
            return;
          }
        }
      }
    }
  }
{code}
we can see that the param remaing and host is not be used in this method. So we need to remove these param and update the method params which invoke this method."
MAPREDUCE-6584,Remove trailing whitespaces from mapred-default.xml,"In MAPREDUCE-6583, test-patch reported that mapred-default.xml has many trailing whitespaces."
MAPREDUCE-6583,Clarify confusing sentence in MapReduce tutorial document,"The current MapReduce tutorial has the following statement which is confusing:

{quote}
Overall, Mapper implementations are passed the Job for the job via the Job.setMapperClass(Class) method.
{quote}

The sentence seems to contradict itself.   The code shows the mapper getting passed to the job.  However, the working suggests that the job is passed to the mapper?

https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Mapper"
MAPREDUCE-6580,Test failure : TestMRJobsWithProfiler,"From [https://builds.apache.org/job/PreCommit-YARN-Build/9976/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient-jdk1.8.0_66.txt] TestMRJobsWithProfiler fails intermittently
{code}
Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 212.973 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler
testDifferentProfilers(org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler)  Time elapsed: 133.116 sec  <<< FAILURE!
java.lang.AssertionError: expected:<4> but was:<1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfilerInternal(TestMRJobsWithProfiler.java:212)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testDifferentProfilers(TestMRJobsWithProfiler.java:117)
{code}"
MAPREDUCE-6579,JobStatus#getFailureInfo should not output diagnostic information when the job is running,"From [https://builds.apache.org/job/PreCommit-YARN-Build/9976/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient-jdk1.8.0_66.txt] TestNetworkedJob are failed intermittently.

{code}
Running org.apache.hadoop.mapred.TestNetworkedJob
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 81.131 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestNetworkedJob
testNetworkedJob(org.apache.hadoop.mapred.TestNetworkedJob)  Time elapsed: 30.55 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[[Tue Dec 15 14:02:45 +0000 2015] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:8192, vCores:16> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 0.0 % ; Queue's Absolute max capacity = 100.0 % ; ]> but was:<[]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob(TestNetworkedJob.java:174)
{code}"
MAPREDUCE-6578,Add support for HDFS heterogeneous storage testing to TestDFSIO,HDFS heterogeneous storage allows user to store data blocks to different storage medias according to predefined storage policies. Only 'Default' policy is supported in current TestDFSIO implementation. This is going to add an new option to enable tests of other storage polices.
MAPREDUCE-6577,MR AM unable to load native library without MR_AM_ADMIN_USER_ENV set,"If yarn.app.mapreduce.am.admin.user.env (or yarn.app.mapreduce.am.env) is not configured to set LD_LIBRARY_PATH, MR AM will fail to load the native library:

{noformat}
2015-12-15 21:29:22,473 WARN [main] org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
{noformat}

As a result, any code that needs the hadoop native library in the MR AM will fail. For example, an uber-AM with lz4 compression for the mapper task will fail:
{noformat}
2015-12-15 21:30:17,575 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.lang.RuntimeException: native lz4 library not available
	at org.apache.hadoop.io.compress.Lz4Codec.getCompressorType(Lz4Codec.java:125)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:148)
	at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:163)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:114)
	at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:97)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1602)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1482)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:457)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:391)
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:309)
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:195)
	at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:238)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{noformat}"
MAPREDUCE-6576,AM java.io.tmpdir should be set to $PWD/tmp,"For tasks it is already done by MapReduceChildJVM 

{code}
Path childTmpDir = new Path(Environment.PWD.$(),
        YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);
    vargs.add(""-Djava.io.tmpdir="" + childTmpDir);
So it is only needed to be set for AM in launcher because of uber mode.
{code}

Need to do this in AM as well, so that running in uber mode does not go to default java.io.tmpdir of /tmp and fill up task nodes and not be cleanedup. "
MAPREDUCE-6574,MR AM should print host of failed tasks.,"Something tasks failed because of issues on NMs. For example, bad disk/network could cause reducer fetching failure and mappers need to be re-scheduled.

It will be very helpful to identify such issues if we could print host of failed tasks, which we can simply grep MR AM's log to see what happened."
MAPREDUCE-6571,JobEndNotification info logs are missing in AM container syslog,"JobEndNotification logs are not written by MRAppMaster and JobEndNotifier classes even though Log.info is present. The reason was  MRAppMaster.this.stop() has been called before the JobEndNotification and hence somewhere during the stop log appenders also made null.

AM container syslog is not having below logs from JobEndNotifier

   Job end notification trying + urlToNotify
   Job end notification to + urlToNotify + succeeded / failed"
MAPREDUCE-6567,mapreduce ACLs documentation shows incorrect syntax,"The description of the mapreduce.job.acl-* in the mapred-default.xml shows the wrong syntax.  
{quote}
For specifying a list of users and groups the format to use is ""user1,user2 group1,group"". If set to '*', it allows all users/groups to modify this job.
{quote}

This doesn't actually work.  The syntax that does work:
{quote}
For specifying a list of users and groups the format to use is ""user1,user2 group1,* group"". If set to '*', it allows all users/groups to modify this job.
{quote}

The difference being that to make all members of a group have permissions for an ACL, the specification must be '* group' not just 'group'."
MAPREDUCE-6566,Add retry support to mapreduce CLI tool,MAPREDUCE-6251 added support for retries to JobClient. However the MR CLI class doesn't use the JobClient. It would be useful to add support for retries to the CLI class as well.
MAPREDUCE-6565,Configuration to use host name in delegation token service is not read from job.xml during MapReduce job execution.,"By default, the service field of a delegation token is populated based on server IP address.  Setting {{hadoop.security.token.service.use_ip}} to {{false}} changes this behavior to use host name instead of IP address.  However, this configuration property is not read from job.xml.  Instead, it's read from a separate {{Configuration}} instance created during static initialization of {{SecurityUtil}}.  This does not work correctly with MapReduce jobs if the framework is distributed by setting {{mapreduce.application.framework.path}} and the {{mapreduce.application.classpath}} is isolated to avoid reading core-site.xml from the cluster nodes.  MapReduce tasks will fail to authenticate to HDFS, because they'll try to find a delegation token based on the NameNode IP address, even though at job submission time the tokens were generated using the host name."
MAPREDUCE-6563,Streaming documentation contains a stray '%' character.,"We have an unneeded '%' character above the title in this page.

http://hadoop.apache.org/docs/r2.7.1/hadoop-streaming/HadoopStreaming.html
"
MAPREDUCE-6561,Lack of confirmation of debug log enabled in HistoryFileManager,Debug log in {{scanIntermediateDirectory}} lacks the confirmation of debug mode is enabled or not.
MAPREDUCE-6560,ClientServiceDelegate doesn't handle retries during AM restart as intended,"In the {{invoke()}} method, I found the following code:

{code}
  private AtomicBoolean usingAMProxy = new AtomicBoolean(false);
...
        // if it's AM shut down, do not decrement maxClientRetry as we wait for
        // AM to be restarted.
        if (!usingAMProxy.get()) {
          maxClientRetry--;
        }
        usingAMProxy.set(false);
{code}

When we create the AM proxy, we set the flag to true.  If we fail to connect, the impact of the flag being true is that the code will try one extra time, giving it 400ms instead of just 300ms.  I can't imagine that's the intended behavior.  After any failure, the flag will forever more be false, but fortunately (?!?) the flag is otherwise unused.

Looks like I need to do some archeology to figure out how we ended up here."
MAPREDUCE-6559,TestMRAppMaster should use test.build.data for test directory,"TestMRAppMaster creates intermediate files other than {{test.build.data}}, so the files are checked by Apache Rat and Jenkins reports license warnings. https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6185/artifact/patchprocess/patch-asflicense-problems.txt"
MAPREDUCE-6558,multibyte delimiters with compressed input files generate duplicate records,"This is the follow up for MAPREDUCE-6549. Compressed files cause record duplications as shown in different junit tests. The number of duplicated records changes with the splitsize:

Unexpected number of records in split (splitsize = 10)
Expected: 41051
Actual: 45062

Unexpected number of records in split (splitsize = 100000)
Expected: 41051
Actual: 41052

Test passes with splitsize = 147445 which is the compressed file length.The file is a bzip2 file with 100k blocks and a total of 11 blocks"
MAPREDUCE-6557,Some tests in mapreduce-client-app are writing outside of target,There is a staging directory appearing. It should not.
MAPREDUCE-6555,TestMRAppMaster fails on trunk,"Observed in QA report of YARN-3840 
{noformat}
Running org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster
Tests run: 9, Failures: 1, Errors: 1, Skipped: 0, Time elapsed: 20.699 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster
testMRAppMasterMidLock(org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster)  Time elapsed: 0.474 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMidLock(TestMRAppMaster.java:174)

testMRAppMasterSuccessLock(org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster)  Time elapsed: 0.175 sec  <<< ERROR!
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.FileNotFoundException: File file:/home/varun/hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/staging/history/done_intermediate/TestAppMasterUser/job_1317529182569_0004-1448100479292-TestAppMasterUser-%3Cmissing+job+name%3E-1448100479413-0-0-SUCCEEDED-default-1448100479292.jhist_tmp does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:640)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:866)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:630)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:340)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:292)
	at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:372)
	at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:513)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.moveTmpToDone(JobHistoryEventHandler.java:1346)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:1154)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1751)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1247)
	at org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterSuccessLock(TestMRAppMaster.java:254)
{noformat}"
MAPREDUCE-6554,MRAppMaster servicestart failing  with NPE in MRAppMaster#parsePreviousJobHistory,"Create scenario so that MR app master gets preempted.
On next MRAppMaster launch tried to recover previous job history file {{MRAppMaster#parsePreviousJobHistory}}


{noformat}
2015-11-21 13:52:27,722 INFO [main] org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.app.MRAppMaster failed in state STARTED; cause: java.lang.NullPointerException
java.lang.NullPointerException
        at java.io.StringReader.<init>(StringReader.java:50)
        at org.apache.avro.Schema$Parser.parse(Schema.java:917)
        at org.apache.avro.Schema.parse(Schema.java:966)
        at org.apache.hadoop.mapreduce.jobhistory.EventReader.<init>(EventReader.java:75)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:139)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.parsePreviousJobHistory(MRAppMaster.java:1256)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.processRecovery(MRAppMaster.java:1225)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1087)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$4.run(MRAppMaster.java:1570)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1673)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1566)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1499)
2015-11-21 13:52:27,725 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0

{noformat}

EventReader(EventReader stream)
{noformat}
 this.version = in.readLine();
...
    Schema myschema = new SpecificData(Event.class.getClassLoader()).getSchema(Event.class);
    this.schema = Schema.parse(in.readLine());
{noformat}

"
MAPREDUCE-6553,Replace '\u2b05' with '<-' in rendering job configuration,"U+2B05 (leftwards black arrow) is not supported in some browsers, so we should replace it with ""<-""."
MAPREDUCE-6552,Add job search button in JobHistoryServer WebUI,"In jobhistory webui, it's not convenient to direct search the specific retired job when there are only few job records in page.And if you want to show more jobs in page(so that you can find your target job), the main page will be opened slowly.Because the renderd page will be large,and the browser will be cost much time to download this page.So we can add a search job button , and by inputing a specific jobid and clicking the button, we can jump its job page."
MAPREDUCE-6550,archive-logs tool changes log ownership to the Yarn user when using DefaultContainerExecutor,"The archive-logs tool added in MAPREDUCE-6415 leverages the Distributed Shell app.  When using the DefaultContainerExecutor, this means that the job will actually run as the Yarn user, so the resulting har files are owned by the Yarn user instead of the original owner. The permissions are also now world-readable.

In the below example, the archived logs are owned by 'yarn' instead of 'paul' and are now world-readable:
{noformat}
[root@gs28-centos66-5 ~]# sudo -u hdfs hdfs dfs -ls -R /tmp/logs
...
drwxrwx---   - paul  hadoop          0 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005
drwxr-xr-x   - yarn  hadoop          0 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005/application_1443805425363_0005.har
-rw-r--r--   3 yarn  hadoop          0 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005/application_1443805425363_0005.har/_SUCCESS
-rw-r--r--   3 yarn  hadoop       1256 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005/application_1443805425363_0005.har/_index
-rw-r--r--   3 yarn  hadoop         24 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005/application_1443805425363_0005.har/_masterindex
-rw-r--r--   3 yarn  hadoop    8451177 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0005/application_1443805425363_0005.har/part-0
drwxrwx---   - paul  hadoop          0 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0006
-rw-r-----   3 paul  hadoop       1155 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0006/gs-centos66-2.vpc.cloudera.com_8041
-rw-r-----   3 paul  hadoop       4880 2015-10-02 13:24 /tmp/logs/paul/logs/application_1443805425363_0006/gs28-centos66-3.vpc.cloudera.com_8041
...
{noformat}"
MAPREDUCE-6549,multibyte delimiters with LineRecordReader cause duplicate records,"LineRecorderReader currently produces duplicate records under certain scenarios such as:

1) input string: ""abc+++def++ghi++"" 
delimiter string: ""+++"" 
test passes with all sizes of the split 
2) input string: ""abc++def+++ghi++"" 
delimiter string: ""+++"" 
test fails with a split size of 4 
2) input string: ""abc+++def++ghi++"" 
delimiter string: ""++"" 
test fails with a split size of 5 
3) input string ""abc+++defg++hij++"" 
delimiter string: ""++"" 
test fails with a split size of 4 
4) input string ""abc++def+++ghi++"" 
delimiter string: ""++"" 
test fails with a split size of 9 "
MAPREDUCE-6548,Jobs executed can be configurated with specific users and time hours,"In recent hadoop versions,the system has no limitation for users to execute their jobs if you don't configurate ACL.And I find that the ACL is only called in IPC, isn't operated in job submissions.And this condition can't satisfied with this case that I have a very important job, and I am prepared to execute this job in 0 to 9 o'clock.In order to let this job executed quickly, I am not allowed other user's job to execute in these time. So I can see the result in tomorrow morning.So may be we can let jobs executed with specific users in specific time hours."
MAPREDUCE-6546,reconcile the two versions of the timeline service performance tests,"The trunk now has a version of the timeline service performance test (YARN-2556). The timeline service v.2 (YARN-2928) also has a performance test, and these two versions are quite similar (by design).

We need to reconcile the two."
MAPREDUCE-6543,Migrate MR Client test cases part 2,"Migrate the second half of the MR client test cases.  The files included will be:
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/DFSCIOTest.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/DistributedFSCheck.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestFileSystem.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/fs/TestJHLA.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/ClusterMapReduceTestCase.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/join/TestDatamerge.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/join/TestTupleWritable.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/join/TestWrappedRecordReaderClassloader.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/aggregate/TestAggregates.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/db/TestConstructQuery.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestDelegatingInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestLineInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestMultipleInputs.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/pipes/TestPipes.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestAuditLogger.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestCollect.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestCommandLineJobSubmission.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestFieldSelection.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestFileInputFormatPathFilter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestGetSplitHosts.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestIFileStreams.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestInputPath.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestJavaSerialization.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestJobSysDirWithDFS.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestKeyValueTextInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestLazyOutput.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMapProgress.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMerge.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRBringup.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMiniMRDFSCaching.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMRCJCFileInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMRCJCFileOutputCommitter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultiFileInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultiFileSplit.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultipleLevelCaching.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestMultipleTextOutputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestReduceFetchFromPartialMem.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestReduceTask.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileAsBinaryInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileAsBinaryOutputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileAsTextInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileInputFilter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSequenceFileInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSortedRanges.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestSpecialCharactersInOutputPath.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestStatisticsCollector.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestUserDefinedCounters.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestWritableJobConf.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestYARNRunner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/aggregate/TestMapReduceAggregates.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/db/TestDBOutputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/db/TestIntegerSplitter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/db/TestTextSplitter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/fieldsel/TestMRFieldSelection.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestDelegatingInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileAsBinaryInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileAsTextInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMRSequenceFileInputFilter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestNLineInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinDatamerge.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinProperties.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestJoinTupleWritable.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/join/TestWrappedRRClassloader.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRCJCFileOutputCommitter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRSequenceFileAsBinaryOutputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/partition/TestBinaryPartitioner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/partition/TestKeyFieldHelper.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/partition/TestMRKeyFieldBasedPartitioner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/partition/TestTotalOrderPartitioner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestLocalRunner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapReduceLazyOutput.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestValueIterReset.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestYarnClientProtocolProvider.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/util/TestMRAsyncDiskService.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestMiniMRProxyUser.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/v2/TestNonExistentJob.java"
MAPREDUCE-6542,"HistoryViewer uses SimpleDateFormat, but SimpleDateFormat is not threadsafe","I use SimpleDateFormat to Parse the JobHistory File before 

{code}
private static final SimpleDateFormat dateFormat =
    new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss"");
 public static String getJobDetail(JobInfo job) {
        StringBuffer jobDetails = new StringBuffer("""");
        SummarizedJob ts = new SummarizedJob(job);
        jobDetails.append(job.getJobId().toString().trim()).append(""\t"");
        jobDetails.append(job.getUsername()).append(""\t"");
        jobDetails.append(job.getJobname().replaceAll(""\\n"", """")).append(""\t"");
        jobDetails.append(job.getJobQueueName()).append(""\t"");
        jobDetails.append(job.getPriority()).append(""\t"");
        jobDetails.append(job.getJobConfPath()).append(""\t"");
        jobDetails.append(job.getUberized()).append(""\t"");
        jobDetails.append(dateFormat.format(job.getSubmitTime())).append(""\t"");
        jobDetails.append(dateFormat.format(job.getLaunchTime())).append(""\t"");
        jobDetails.append(dateFormat.format(job.getFinishTime())).append(""\t"");
       return jobDetails.toString();
}
{code}

But I find I query the SubmitTime and LaunchTime in hive and compare JobHistory File time , I find that the submitTime  and launchTime was wrong.

Finally,I change to use the FastDateFormat to parse the time format and the time become right"
MAPREDUCE-6541,Exclude scheduled reducer memory when calculating available mapper slots from headroom to avoid deadlock ,"We saw a MR deadlock recently:

- When NM restarted by framework without enable recovery, containers running on these nodes will be identified as ""ABORTED"", and MR AM will try to reschedule ""ABORTED"" mapper containers.
- Since such lost mappers are ""ABORTED"" container, MR AM gives normal mapper priority (priority=20) to such mapper requests. If there's any pending reducer (priority=10) at the same time, mapper requests need to wait for reducer requests satisfied.
- In our test, one mapper needs 700+ MB, reducer needs 1000+ MB, and RM available resource = mapper-request = (700+ MB), only one job was running in the system so scheduler cannot allocate more reducer containers AND MR-AM thinks there're enough headroom for mapper so reducer containers will not be preempted.

MAPREDUCE-6302 can solve most of the problems, but in the other hand, I think we may need to exclude scheduled reducers resource when calculating #available-mapper-slots from headroom. Which we can avoid excessive reducer preemption."
MAPREDUCE-6540,TestMRTimelineEventHandling fails,"TestMRTimelineEventHandling fails after YARN-2859 is merged because it changed the port the AHS binds to in a mini cluster.

{noformat}
Running org.apache.hadoop.mapred.TestMRTimelineEventHandling
Tests run: 3, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 184.38 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestMRTimelineEventHandling
testMRTimelineEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 70.528 sec  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling(TestMRTimelineEventHandling.java:99)

testMapreduceJobTimelineServiceEnabled(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 84.312 sec  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled(TestMRTimelineEventHandling.java:162)
{noformat}
"
MAPREDUCE-6538,Deprecate hadoop-pipes,"Development appears to have stopped on hadoop-pipes upstream for the last few years, aside from very basic maintenance.  Hadoop streaming seems to be a better alternative, since it supports more programming languages and is better implemented.

There were no responses to a message on the mailing list asking for users of Hadoop pipes... and in my experience, I have never seen anyone use this.  We should remove it to reduce our maintenance burden and build times."
MAPREDUCE-6537,Include hadoop-pipes examples in the release tarball,Hadoop pipes examples are built but never packaged.
MAPREDUCE-6536,hadoop-pipes doesn't use maven properties for openssl,hadoop-common has some maven properties that are used to define where OpenSSL lives.  hadoop-pipes should also use them so we can enable automated testing.
MAPREDUCE-6535,TaskID default constructor results in NPE on toString(),"This code will reproduce the issue:

{code}
new TaskAttemptID().toString();
{code}

The issue is that the default constructor leaves the type {{null}}.  The {{get()}} in {{CharTaskTypesMaps.getRepresentingCharacter()}} then throws an NPE on the null type key.

The simplest solution would be to only call the {{get()}} on line 288 of {{TaskID.java}} if {{type}} is not {{null}} and return some other literal otherwise.  Since no part of the code is tripping on the NPE, what we choose for the literal shouldn't matter.  How about ""x""?"
MAPREDUCE-6534,Sorting based on attempt not working in JHS,"Steps to reproduce
===============

1.Submit application with 1100 maps
2.Check successful maps in JHS
3.Try sorting based on attempt

/jobhistory/attempts/job_1446629175560_0005/m/SUCCESSFUL"
MAPREDUCE-6533,testDetermineCacheVisibilities of TestClientDistributedCacheManager is broken,
MAPREDUCE-6531,CLONE - Mumak: Map-Reduce Simulator,"h3. Vision:

We want to build a Simulator to simulate large-scale Hadoop clusters, applications and workloads. This would be invaluable in furthering Hadoop by providing a tool for researchers and developers to prototype features (e.g. pluggable block-placement for HDFS, Map-Reduce schedulers etc.) and predict their behaviour and performance with reasonable amount of confidence, there-by aiding rapid innovation.

----

h3. First Cut: Simulator for the Map-Reduce Scheduler

The Map-Reduce Scheduler is a fertile area of interest with at least four schedulers, each with their own set of features, currently in existence: Default Scheduler, Capacity Scheduler, Fairshare Scheduler & Priority Scheduler.

Each scheduler's scheduling decisions are driven by many factors, such as fairness, capacity guarantee, resource availability, data-locality etc.

Given that, it is non-trivial to accurately choose a single scheduler or even a set of desired features to predict the right scheduler (or features) for a given workload. Hence a simulator which can predict how well a particular scheduler works for some specific workload by quickly iterating over schedulers and/or scheduler features would be quite useful.

So, the first cut is to implement a simulator for the Map-Reduce scheduler which take as input a job trace derived from production workload and a cluster definition, and simulates the execution of the jobs in as defined in the trace in this virtual cluster. As output, the detailed job execution trace (recorded in relation to virtual simulated time) could then be analyzed to understand various traits of individual schedulers (individual jobs turn around time, throughput, faireness, capacity guarantee, etc). To support this, we would need a simulator which could accurately model the conditions of the actual system which would affect a schedulers decisions. These include very large-scale clusters (thousands of nodes), the detailed characteristics of the workload thrown at the clusters, job or task failures, data locality, and cluster hardware (cpu, memory, disk i/o, network i/o, network topology) etc.


"
MAPREDUCE-6528,Memory leak for HistoryFileManager.getJobSummary(),"We meet memory leak issues for JHS in a large cluster which is caused by code below doesn't release FSDataInputStream in exception case. MAPREDUCE-6273 should fix most cases that exceptions get thrown. However, we still need to fix the memory leak for occasional case.

{code} 
private String getJobSummary(FileContext fc, Path path) throws IOException {
    Path qPath = fc.makeQualified(path);
    FSDataInputStream in = fc.open(qPath);
    String jobSummaryString = in.readUTF();
    in.close();
    return jobSummaryString;
  }
{code}"
MAPREDUCE-6526,Remove usage of metrics v1 from hadoop-mapreduce,LocalJobRunnerMetrics and ShuffleClientMetrics are still using metrics v1. We should remove these metrics or rewrite them to use metrics v2.
MAPREDUCE-6525,Fix test failure of TestMiniMRClientCluster.testRestart,MiniMRYarnClusterAdapter#restart creates new MiniMRYarnCluster with configuration of existing MiniMRYarnCluster but the address of HistoryServer is properly set.
MAPREDUCE-6524,Fix intermittent test failure of TestMRJobsWithHistoryService.testJobHistoryData,The historyClient tried to connect to port 0 and failed.
MAPREDUCE-6523,hadoop-yarn Avoid unsafe split and append on fields that might be IPv6 literals,"Yarn changes needed for IPv6 support for work
It seems I cannot assign JIRA under YARN (see YARN-4283) so creating under mapreduce"
MAPREDUCE-6521,MiniMRYarnCluster should not create /tmp/hadoop-yarn/staging on local filesystem in unit test,MiniMRYarnCluster create /tmp/hadoop-yarn/staging/history/done by default. It should be under {{testWorkDir}} if the file system is localFs in order to make it to be removed by {{mvn clean}}. It would also avoid issues under parallel unit testing.
MAPREDUCE-6520,Migrate MR Client test cases part 1,"Migrate the mr client test cases from JUnit3 part 1.  This will be a 3 part exercise.  Files in this JIRA will be:
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/conf/TestNoDefaultsJobConf.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/HadoopTestCase.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/NotificationTestCase.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestFileOutputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/TestTaskCommit.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/jobcontrol/TestLocalJobControl.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestChainMapReduce.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestKeyFieldBasedComparator.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/lib/TestMultithreadedMapRunner.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestChild.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestNoJobSetupCleanup.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestTaskContext.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/chain/TestChainErrors.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/chain/TestMapReduceChain.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/chain/TestSingleElementChain.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/db/TestDataDrivenDBInputFormat.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestMultipleInputs.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/jobcontrol/TestMapReduceJobControl.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/map/TestMultithreadedMapper.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestJobOutputCommitter.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRMultipleOutputs.java
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/partition/TestMRKeyFieldBasedComparator.java
hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/java/org/apache/hadoop/examples/terasort/TestTeraSort.java"
MAPREDUCE-6519,Avoid unsafe split and append on fields that might be IPv6 literals,mapreduce portion of patch in HADOOP-12122 that couldn't run due to number of components touched.
MAPREDUCE-6518,Set SO_KEEPALIVE on shuffle connections,Shuffle handler does not set SO_KEEPALIVE so we've seen cases where FDs/sockets get stuck in ESTABLISHED state indefinitely because the server did not see the client leave (network cut or otherwise). 
MAPREDUCE-6515,Update Application priority in AM side from AM-RM heartbeat,"After YARN-4170, Application Priority is available via heartbeat call. Update this information in AM sothat client can fetch this information via JobStatus (JobReport) call.

This is as per the discussion happened in MAPREDUCE-5870."
MAPREDUCE-6514,Job hangs as ask is not updated after ramping down of all reducers,"In RMContainerAllocator#preemptReducesIfNeeded, we simply clear the scheduled reduces map and put these reducers to pending. This is not updated in ask. So RM keeps on assigning and AM is not able to assign as no reducer is scheduled(check logs below the code).
If this is updated immediately, RM will be able to schedule mappers immediately which anyways is the intention when we ramp down reducers.
Scheduler need not allocate for ramped down reducers
This if not handled can lead to map starvation as pointed out in MAPREDUCE-6513
{code}
 LOG.info(""Ramping down all scheduled reduces:""
            + scheduledRequests.reduces.size());
        for (ContainerRequest req : scheduledRequests.reduces.values()) {
          pendingReduces.add(req);
        }
        scheduledRequests.reduces.clear();
{code}
{noformat}
2015-10-13 04:55:04,912 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Container not assigned : container_1437451211867_1485_01_000215
2015-10-13 04:55:04,912 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Cannot assign container Container: [ContainerId: container_1437451211867_1485_01_000216, NodeId: hdszzdcxdat6g06u04p:26009, NodeHttpAddress: hdszzdcxdat6g06u04p:26010, Resource: <memory:4096, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 10.2.33.236:26009 }, ] for a reduce as either  container memory less than required 4096 or no pending reduce tasks - reduces.isEmpty=true
2015-10-13 04:55:04,912 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Container not assigned : container_1437451211867_1485_01_000216
2015-10-13 04:55:04,912 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Cannot assign container Container: [ContainerId: container_1437451211867_1485_01_000217, NodeId: hdszzdcxdat6g06u06p:26009, NodeHttpAddress: hdszzdcxdat6g06u06p:26010, Resource: <memory:4096, vCores:1>, Priority: 10, Token: Token { kind: ContainerToken, service: 10.2.33.239:26009 }, ] for a reduce as either  container memory less than required 4096 or no pending reduce tasks - reduces.isEmpty=true
{noformat}"
MAPREDUCE-6513,MR job got hanged forever when one NM unstable for some time,"when job is in-progress which is having more tasks,one node became unstable due to some OS issue.After the node became unstable, the map on this node status changed to KILLED state. 

Currently maps which were running on unstable node are rescheduled, and all are in scheduled state and wait for RM assign container.Seen ask requests for map till Node is good (all those failed), there are no ask request after this. But AM keeps on preempting the reducers (it's recycling).

Finally reducers are waiting for complete mappers and mappers did n't get container..

My Question Is:
============
why map requests did not sent AM ,once after node recovery.?






"
MAPREDUCE-6512,FileOutputCommitter tasks unconditionally create parent directories,"If the output directory is deleted then subsequent tasks should fail. Instead they blindly create the missing parent directories, leading the job to be ""succesful"" despite potentially missing almost all of the output. Task attempts should fail if the parent app attempt directory is missing when they go to create their task attempt directory."
MAPREDUCE-6511,MRAppMaster second attempt starting on the same node as a previously failed MRAppMaster attempt,"Scenario: MRAppMaster attempt one executed on node that experience hardware issue.

Now the second attempt of the Application Master was scheduled on the same node.
Section from RM log for first APP Master attempt:

2015-10-09 05:54:10,857 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): YARN label is enabled with AM labels CORE
2015-10-09 05:54:10,859 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): appattempt_1444369886652_0001_000001 State change from SUBMITTED to SCHEDULED
2015-10-09 05:54:10,942 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue (ResourceManager Event Processor): assignContainers: node=ip-172-31-39-137.us-west-2.compute.internal application=1 priority=0 request={Priority: 0, Capability: <memory:15104, vCores:1>, # Containers: 1, Labels: CORE, Location: *, Relax Locality: true} type=OFF_SWITCH
2015-10-09 05:54:10,973 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl (ResourceManager Event Processor): container_1444369886652_0001_01_000001 Container Transitioned from NEW to ALLOCATED
2015-10-09 05:54:10,973 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger (ResourceManager Event Processor): USER=hadoop OPERATION=AM Allocated Container        TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1444369886652_0001    CONTAINERID=container_1444369886652_0001_01_000001


Section from RM log for second APP Master attempt:

2015-10-09 07:29:10,483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): YARN label is enabled with AM labels CORE
2015-10-09 07:29:10,483 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl (AsyncDispatcher event handler): appattempt_1444369886652_0001_000002 State change from SUBMITTED to SCHEDULED
2015-10-09 07:29:10,498 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue (ResourceManager Event Processor): assignContainers: node=ip-172-31-39-137.us-west-2.compute.internal application=1 priority=0 request={Priority: 0, Capability: <memory:15104, vCores:1>, # Containers: 1, Labels: CORE, Location: *, Relax Locality: true} type=OFF_SWITCH
2015-10-09 07:29:10,499 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl (ResourceManager Event Processor): container_1444369886652_0001_02_000001 Container Transitioned from NEW to ALLOCATED
2015-10-09 07:29:10,499 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger (ResourceManager Event Processor): USER=hadoop OPERATION=AM Allocated Container        TARGET=SchedulerApp     RESULT=SUCCESS  APPID=application_1444369886652_0001    CONTAINERID=container_1444369886652_0001_02_000001
"
MAPREDUCE-6510,TestRMContainerAllocator is failing," *Trace* 

{noformat}
FAILED: org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator.testSimple

Error Message:
null

Stack Trace:
java.lang.NullPointerException: null
at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.isRequestLabelChanged(AppSchedulingInfo.java:420)
at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.updateResourceRequests(AppSchedulingInfo.java:341)
at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.updateResourceRequests(SchedulerApplicationAttempt.java:300)
at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.allocate(FifoScheduler.java:350)
at org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator$MyFifoScheduler.allocate(TestRMContainerAllocator.java:1719)
at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:506)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:204)
at org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator$MyContainerAllocator.makeRemoteRequest(TestRMContainerAllocator.java:2060)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:724)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:268)
at org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator$MyContainerAllocator.schedule(TestRMContainerAllocator.java:2023)
at org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator.testSimple(TestRMContainerAllocator.java:231)


FAILED: org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator.testIgnoreBlacklisting
{noformat}"
MAPREDUCE-6508,TestNetworkedJob fails consistently due to delegation token changes on RM.,"{noformat}
Running org.apache.hadoop.mapred.TestNetworkedJob
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 84.215 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestNetworkedJob
testNetworkedJob(org.apache.hadoop.mapred.TestNetworkedJob)  Time elapsed: 31.537 sec  <<< ERROR!
java.io.IOException: org.apache.hadoop.yarn.exceptions.YarnException: java.io.IOException: Delegation Token can be issued only with kerberos authentication
	at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:38)
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getDelegationToken(ClientRMService.java:1044)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.getDelegationToken(ApplicationClientProtocolPBServiceImpl.java:325)
	at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:483)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:637)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:976)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2236)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2232)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1667)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2230)
Caused by: java.io.IOException: Delegation Token can be issued only with kerberos authentication
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getDelegationToken(ClientRMService.java:1017)
	... 10 more

	at org.apache.hadoop.ipc.Client.call(Client.java:1448)
	at org.apache.hadoop.ipc.Client.call(Client.java:1379)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:230)
	at com.sun.proxy.$Proxy84.getDelegationToken(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getDelegationToken(ApplicationClientProtocolPBClientImpl.java:339)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:251)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:103)
	at com.sun.proxy.$Proxy85.getDelegationToken(Unknown Source)
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getRMDelegationToken(YarnClientImpl.java:541)
	at org.apache.hadoop.mapred.ResourceMgrDelegate.getDelegationToken(ResourceMgrDelegate.java:177)
	at org.apache.hadoop.mapred.YARNRunner.getDelegationToken(YARNRunner.java:231)
	at org.apache.hadoop.mapreduce.Cluster.getDelegationToken(Cluster.java:401)
	at org.apache.hadoop.mapred.JobClient$16.run(JobClient.java:1234)
	at org.apache.hadoop.mapred.JobClient$16.run(JobClient.java:1231)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1667)
	at org.apache.hadoop.mapred.JobClient.getDelegationToken(JobClient.java:1230)
	at org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob(TestNetworkedJob.java:260)

{noformat}"
MAPREDUCE-6506,Make the reducer-preemption configs consistent in how they handle defaults,"{{mapreduce.job.reducer.preempt.delay.sec}} and {{mapreduce.job.reducer.unconditional-preempt.delay.sec}} are two configs related to reducer preemption. These configs are not consistent in how they handle non-positive values. Also, the way to disable them is different. 

It would be nice to make them consistent somehow, and change the behavior of former if need be. "
MAPREDUCE-6503,archive-logs tool should use HADOOP_PREFIX instead of HADOOP_HOME,The archive-logs tool currently uses {{HADOOP_HOME}} in the distributed shell job.  It should instead use {{HADOOP_PREFIX}} due to HADOOP-12451/HADOOP-12456.
MAPREDUCE-6499,Add elapsed time for retired job in JobHistoryServer WebUI,"Now in  JobHistory Main Page show too little information about finished jobs,even don't have the job's running total time,only startTime,finishedTime.So,in jobHistory main page,we can add more informations about jobs, that we can better analyze jobs."
MAPREDUCE-6497,Fix wrong value of JOB_FINISHED event in JobHistoryEventHandler,"It seems that ""MAP_COUNTER_GROUPS"" values use total_counter value.
We should fix to use map_counter value."
MAPREDUCE-6495,Docs for archive-logs tool,Write documentation for the 'mapred archive-logs' tool added in MAPREDUCE-6415.
MAPREDUCE-6494,Permission issue when running archive-logs tool as different users,"If the tool is run as user A, it creates {{/tmp/logs/archive-logs-work}} for temp work, but doesn't delete it. When it's run again as user B, you can run into permissions problems on {{/tmp/logs/archive-logs-work}} because user B doesn't have permission to do anything to that dir (it's 700).  We should have the tool delete {{/tmp/logs/archive-logs-work}} when exiting."
MAPREDUCE-6492,AsyncDispatcher exit with NPE on TaskAttemptImpl#sendJHStartEventForAssignedFailTask,"For {{TaskAttemptImpl#DeallocateContainerTransition}} {{sendJHStartEventForAssignedFailTask}} is send for TaskAttemptStateInternal.UNASSIGNED also .


Causing NPE on {{taskAttempt.container.getNodeHttpAddress()}} 


{noformat}
2015-09-28 18:01:48,656 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.sendJHStartEventForAssignedFailTask(TaskAttemptImpl.java:1494)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.access$2900(TaskAttemptImpl.java:147)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$DeallocateContainerTransition.transition(TaskAttemptImpl.java:1700)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$DeallocateContainerTransition.transition(TaskAttemptImpl.java:1686)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:290)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1190)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:146)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1415)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1407)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:183)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:109)
	at java.lang.Thread.run(Thread.java:745)
2015-09-28 18:01:48,660 INFO [AsyncDispatcher ShutDown handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..
2015-09-28 18:01:48,660 INFO [ContainerLauncher #6] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_e04_1443430524957_0006_01_000059 taskAttempt attempt_1443430524957_0006_m_000000_9
{noformat}

Log aggregation fail for mapreduce application.
"
MAPREDUCE-6489,Fail fast rogue tasks that write too much to local disk,"Tasks of the rogue jobs can write too much to local disk, negatively affecting the jobs running in collocated containers. Ideally YARN will be able to limit amount of local disk used by each task: YARN-4011. Until then, the mapreduce task can fail fast if the task is writing too much (above a configured threshold) to local disk.

As we discussed [here|https://issues.apache.org/jira/browse/YARN-4011?focusedCommentId=14902750&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14902750] the suggested approach is that the MapReduce task checks for BYTES_WRITTEN counter for the local disk and throws an exception when it goes beyond a configured value.  It is true that written bytes is larger than the actual used disk space, but to detect a rogue task the exact value is not required and a very large value for written bytes to local disk is a good indicative that the task is misbehaving."
MAPREDUCE-6488,Make buffer size in PipeMapRed configurable,"Default value of buffer size is 128K in {{PipeMapRed}}.

When mapper input record is large enough that it won't fit in buffer, {{MapRunner}} blocks until written. If child process and input reader are both slow (due to calculation and decompress), then process of decoding and reading will rarely overlap with each other, hurting performance.

I suppose we should make the buffer size configurable."
MAPREDUCE-6485,MR job hanged forever because all resources are taken up by reducers and the last map attempt never get resource to run,"The scenarios is like this:
With configuring mapreduce.job.reduce.slowstart.completedmaps=0.8, reduces will take resource and  start to run when all the map have not finished. 
But It could happened that when all the resources are taken up by running reduces, there is still one map not finished. 
Under this condition , the last map have two task attempts .
As for the first attempt was killed due to timeout(mapreduce.task.timeout), and its state transitioned from RUNNING to FAIL_CONTAINER_CLEANUP then to FAILED, but failed map attempt would not be restarted for there is still one speculate map attempt in progressing. 
As for the second attempt which was started due to having enable map task speculative is pending at UNASSINGED state because of no resource available. But the second map attempt request have lower priority than reduces, so preemption would not happened.
As a result all reduces would not finished because of there is one map left. and the last map hanged there because of no resource available. so, the job would never finish."
MAPREDUCE-6484,Yarn Client uses local address instead of RM address as token renewer in a secure cluster when RM HA is enabled.,"Yarn Client uses local address instead of RM address as token renewer in a secure cluster when RM HA is enabled. This will cause HDFS token renew failure for renewer ""nobody""  if the rules from {{hadoop.security.auth_to_local}} exclude the client address in HDFS {{DelegationTokenIdentifier}}.
The reason why the local address is returned is: When HA is enabled, ""yarn.resourcemanager.address"" may not be set,  if {{HOSTNAME_PATTERN}}(""_HOST"") is used in ""yarn.resourcemanager.principal"", the default address ""0.0.0.0:8032"" will be used,  Based on the following code at SecurityUtil.java, the local address will be used to replace ""0.0.0.0"".
{code}
  private static String replacePattern(String[] components, String hostname)
      throws IOException {
    String fqdn = hostname;
    if (fqdn == null || fqdn.isEmpty() || fqdn.equals(""0.0.0.0"")) {
      fqdn = getLocalHostName();
    }
    return components[0] + ""/"" + fqdn.toLowerCase(Locale.US) + ""@"" + components[2];
  }
  static String getLocalHostName() throws UnknownHostException {
    return InetAddress.getLocalHost().getCanonicalHostName();
  }
  public static String getServerPrincipal(String principalConfig,
      InetAddress addr) throws IOException {
    String[] components = getComponents(principalConfig);
    if (components == null || components.length != 3
        || !components[1].equals(HOSTNAME_PATTERN)) {
      return principalConfig;
    } else {
      if (addr == null) {
        throw new IOException(""Can't replace "" + HOSTNAME_PATTERN
            + "" pattern since client address is null"");
      }
      return replacePattern(components, addr.getCanonicalHostName());
    }
  }
{code}
The following is the exception which cause the job fail:
{code}
15/09/12 16:27:24 WARN security.UserGroupInformation: PriviledgedActionException as:test@EXAMPLE.COM (auth:KERBEROS) cause:java.io.IOException: Failed to run job : yarn tries to renew a token with renewer nobody
at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:464)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken(FSNamesystem.java:7109)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewDelegationToken(NameNodeRpcServer.java:512)
at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.renewDelegationToken(AuthorizationProviderProxyClientProtocol.java:648)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:975)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:415)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
java.io.IOException: Failed to run job : yarn tries to renew a token with renewer nobody
at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:464)
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewDelegationToken(FSNamesystem.java:7109)
at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewDelegationToken(NameNodeRpcServer.java:512)
at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.renewDelegationToken(AuthorizationProviderProxyClientProtocol.java:648)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewDelegationToken(ClientNamenodeProtocolServerSideTranslatorPB.java:975)
at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:415)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:300)
at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:438)
at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1295)
at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1292)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:415)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
at org.apache.hadoop.mapreduce.Job.submit(Job.java:1292)
at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1313)
at org.apache.hadoop.examples.WordCount.main(WordCount.java:87)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:145)
at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
{code}
"
MAPREDUCE-6483,Replace deprecated method NameNode.getUri() with DFSUtilClient.getNNUri() in TestMRCredentials,"Test {{TestMRCredentials}} uses the {{NameNode.getUri()}} method which is deprecated in [HDFS-9022]. We should use {{DFSUtilClient.getNNUri()}} instead to get the name node URI given NN address. To make the Jenkins pass unit tests, jira [HDFS-9022] focuses on changes in {{hadoop-hdfs}} module.

This jira tracks the effort of replacing usage of {{NameNode.getUri()}} with {{DFSUtilClient.getNNUri()}} in {{TestMRCredentials}}. 
This patch will remove the newly brought javac warning in [HDFS-9022] {quote}TestMRCredentials.java: getUri(InetSocketAddress) in NameNode has been deprecated. {quote}"
MAPREDUCE-6482,"Since jvm reuse is not supported in hadoop 2.x, why I still find mapreduce.job.jvm.numtasks in mapre-default.xml",
MAPREDUCE-6481,LineRecordReader may give incomplete record and wrong position/key information for uncompressed input sometimes.,"LineRecordReader may give incomplete record and wrong position/key information for uncompressed input sometimes.
There are two issues:
# LineRecordReader may give incomplete record: some characters cut off at the end of record.
# LineRecordReader may give wrong position/key information.

The first issue only happens for Custom Delimiter, which is caused by the following code at {{LineReader#readCustomLine}}:
{code}
    if (appendLength > 0) {
        if (ambiguousByteCount > 0) {
          str.append(recordDelimiterBytes, 0, ambiguousByteCount);
          //appending the ambiguous characters (refer case 2.2)
          bytesConsumed += ambiguousByteCount;
          ambiguousByteCount=0;
        }
        str.append(buffer, startPosn, appendLength);
        txtLength += appendLength;
      }
{code}
If {{appendLength}} is 0 and {{ambiguousByteCount}} is not 0, this bug will be triggered. For example, input is ""123456789aab"", Custom Delimiter is ""ab"", bufferSize is 10 and splitLength is 12, the correct record should be ""123456789a"" with length 10, but we get incomplete record ""123456789"" with length 9 from current code.

The second issue can happen for both Custom Delimiter and Default Delimiter, which is caused by the code in {{UncompressedSplitLineReader#readLine}}. {{UncompressedSplitLineReader#readLine}} may report wrong size information at some corner cases. The reason is {{unusedBytes}} in the following code:
{code}
bytesRead += unusedBytes;
unusedBytes = bufferSize - getBufferPosn();
bytesRead -= unusedBytes;
{code}
If the last bytes read (bufferLength) is less than bufferSize, the previous {{unusedBytes}} will be wrong, which should be {{bufferLength}} - {{bufferPosn}} instead of bufferSize - {{bufferPosn}}. It will return larger value.
For example, input is ""1234567890ab12ab345"", Custom Delimiter is ""ab"", bufferSize is 10 and two splits:first splitLength is 15 and second splitLength 4:
the current code will give the following result:
First record: Key:0 Value:""1234567890""
Second record: Key:12 Value:""12""
Third Record: Key:21 Value:""345""
You can see the Key for the third record is wrong, it should be 16 instead of 21. It is due to wrong {{unusedBytes}}. {{fillBuffer}} read 10 bytes for the first time, for the second times, it only read 5 bytes, which is 5 bytes less than the bufferSize. That is why the key we get is 5 bytes larger than the correct one."
MAPREDUCE-6480,archive-logs tool may miss applications,"MAPREDUCE-6415 added a tool to archive aggregated logs into HAR files.  It seeds the initial list of applications to process based on apps which have finished aggregated, according to the RM.  However, the RM doesn't remember completed applications forever (e.g. failover), so it's possible for the tool to miss applications if they're no longer in the RM.  

Instead, we should do the following:
# Seed the initial list of apps based on the aggregated log directories
# Make the RM not consider applications ""complete"" until their log aggregation has reached a terminal state (i.e. DISABLED, SUCCEEDED, FAILED, TIME_OUT).  

#2 will allow #1 to assume that any apps not found in the RM are done aggregating.  #1 on it's own should cover most cases though"
MAPREDUCE-6479,Add missing mapred job command options in mapreduce document,"As per initial analysis the following command details are not added in
http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html#job

{noformat}
        [-list-active-trackers]
        [-list-blacklisted-trackers]
        [-list-attempt-ids <job-id> <task-type> <task-state>]. Valid values for <task-type> are MAP REDUCE. Valid values for <task-state> are running, completed
        [-logs <job-id> <task-attempt-id>]
{noformat}

Please let me know it is intentionally skipped ?
if not i will update a patch to add.

"
MAPREDUCE-6478,Add an option to skip cleanupJob stage or ignore cleanup failure during commitJob().,"In some of our test cases for MR on public cloud scenario, a very big MR job with hundreds or thousands of reducers cannot finish successfully because of Job Cleanup failures which is caused by different scale/performance impact for File System on the cloud (like AzureFS) which replacing HDFS's deletion for whole directory with REST API calls on deleting each sub-directories recursively. Even it get successfully, that could take much longer time (hours) which is not necessary and waste time/resources especially in public cloud scenario. 
In these scenarios, some failures of cleanupJob can be ignored or user choose to skip cleanupJob() completely make more sense. This is because making whole job finish successfully with side effect of wasting some user spaces is much better as user's jobs are usually comes and goes in public cloud, so have choices to tolerant some temporary files exists with get rid of big job re-run (or saving job's running time) is quite effective in time/resource cost. 
We should allow user to have this option (ignore failure or skip job cleanup stage completely) especially when user know the cleanup failure is not due to HDFS abnormal status but other FS' different performance trade-off."
MAPREDUCE-6477,Replace usage of deprecated NameNode.DEFAULT_PORT in TestFileSystem,The {{NameNode.DEFAULT_PORT}} static attribute is stale as we use {{HdfsClientConfigKeys.DFS_NAMENODE_RPC_PORT_DEFAULT}} config value. Jira [HDFS-9010] marks it as {{@Deprecated}} and refactored its usages in {{hadoop-hdfs}} module. This jira tracks the effort of replacing its usage in {{org.apache.hadoop.fs.TestFileSystem}}.
MAPREDUCE-6475,test failing: TestRMContainerAllocator,"Jenkins is failing on trunk on the test {{org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator
testAttemptNotFoundCausesRMCommunicatorException}}

This is replicable locally. "
MAPREDUCE-6474,ShuffleHandler can possibly exhaust nodemanager file descriptors,"The async nature of the shufflehandler can cause it to open a huge number of
file descriptors, when it runs out it crashes.

Scenario:
Job with 6K reduces, slow start set to 0.95, about 40 map outputs per node.
Let's say all 6K reduces hit a node at about same time asking for their
outputs. Each reducer will ask for all 40 map outputs over a single socket in a
single request (not necessarily all 40 at once, but with coalescing it is
likely to be a large number).

sendMapOutput() will open the file for random reading and then perform an async transfer of the particular portion of this file(). This will theoretically
happen 6000*40=240000 times which will run the NM out of file descriptors and cause it to crash.

The algorithm should be refactored a little to not open the fds until they're
actually needed. "
MAPREDUCE-6473,Job submission can take a long time during Cluster initialization,"During initialization in Cluster.java, the framework provider classes are loaded inside a sync block which can considerably increase job submission time when the number of submissions are high. The motive is to reduce time spent in this sync block safely to improve performance.
{noformat}
synchronized (frameworkLoader) {
      for (ClientProtocolProvider provider : frameworkLoader) {
        LOG.debug(""Trying ClientProtocolProvider : ""
            + provider.getClass().getName());
{noformat}"
MAPREDUCE-6472,MapReduce AM should have java.io.tmpdir=./tmp to be consistent with tasks,"MapReduceChildJVM.getVMCommand ensures that all tasks have -Djava.io.tmpdir=./tmp set as part of the task command-line, but this is only used for tasks.  The AM itself does not have a corresponding java.io.tmpdir setting.  It should also use the same tmpdir setting to avoid cases where the AM JVM wants to place files in /tmp by default."
MAPREDUCE-6471,Document distcp incremental copy ,"MAPREDUCE-5899 added distcp support for incremental copy with a new {{append}} flag.

It should be documented."
MAPREDUCE-6469,libnativetask lacks header files and documentation,The MR native task library appears to have no header files included in the maven package and no documentation generated for mvn site.
MAPREDUCE-6466,NNBench map task should create files in separate folder,"In case of NNBench  with current implementation  all files created using different maps are created in same directory.

In this JIRA will provide a flag to create files in same folder or separate folder for each task.

{{dfs.namenode.fs-limits.max-directory-items}} cannot be set to more than
6,400,000 as i understand

Advantage

# For scenarios like creating fsimage with large size NNBench can be used
# Creation of multiple files of same size using NNBench folder based.

No need to run NNBench multiple time to create FSImage of large size.
"
MAPREDUCE-6465,NNBench result wrong when number of reducers greater than 1,"Currently NNBench#analyzeResults consider only the part-0000 for analysis

{code}
                TPS: Create/Write/Close: 0
 Avg exec time (ms): Create/Write/Close: Infinity
             Avg Lat (ms): Create/Write: Infinity
                    Avg Lat (ms): Close: NaN

{code}

Should consider all part files for output.
or disable reduces option"
MAPREDUCE-6463,AM should register RM using IP address instead of hostname,"I copied hadoop direcotry to a host which is not in cluster, and ran a streaming job on it. I encountered following error:

{noformat}
15/08/25 18:48:07 INFO impl.YarnClientImpl: Submitted application application_1440039112410_1578
15/08/25 18:48:07 INFO mapreduce.JobSubmitter: JobID:job_1440039112410_1578 ClientSubmitJob time:692
15/08/25 18:48:07 INFO mapreduce.Job: The url to track the job: http://10.222.7.210:8080/proxy/application_1440039112410_1578/
15/08/25 18:48:07 INFO mapreduce.Job: Running job: job_1440039112410_1578
15/08/25 18:48:13 INFO mapred.ClientServiceDelegate: Connecting to szsk-ad-serving-10-222-7-204:41486
15/08/25 18:48:13 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1440039112410_1578 retrying..
java.net.UnknownHostException: Invalid host name: local host is: (unknown); destination host is: ""szsk-ad-serving-10-222-7-204"":41486; java.net.UnknownHostException; For more details see:  http://wiki.apache.org/hadoop/UnknownHost
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:742)
	at org.apache.hadoop.ipc.Client$Connection.<init>(Client.java:400)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1452)
	at org.apache.hadoop.ipc.Client.call(Client.java:1381)
	at org.apache.hadoop.ipc.Client.call(Client.java:1363)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy16.getJobReport(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:133)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:350)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:517)
	at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:536)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:318)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:315)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1667)
	at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:315)
	at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:604)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1337)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.monitorAndPrintJob(JobClient.java:409)
	at org.apache.hadoop.mapred.JobClient.monitorAndPrintJob(JobClient.java:858)
	at org.apache.hadoop.streaming.StreamJob.submitAndMonitorJob(StreamJob.java:1018)
	at org.apache.hadoop.streaming.StreamJob.run(StreamJob.java:135)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: java.net.UnknownHostException
	... 34 more
{noformat}

The exception is because AM register RM with hostname 'szsk-ad-serving-10-222-7-204' and client could not resolve it."
MAPREDUCE-6462,JobHistoryServer to support JvmPauseMonitor as a service,"As JvmPauseMonitor is made as an AbstractService, subsequent method changes are needed in all places which uses the monitor."
MAPREDUCE-6460,TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException fails,"TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException fails with the following logs:
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator
Tests run: 24, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 94.525 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator
testAttemptNotFoundCausesRMCommunicatorException(org.apache.hadoop.mapreduce.v2.app.rm.TestRMContainerAllocator)  Time elapsed: 2.606 sec  <<< FAILURE!
java.lang.AssertionError: Expected exception: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocationException
	at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:32)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)


Results :

Failed tests: 
  TestRMContainerAllocator.testAttemptNotFoundCausesRMCommunicatorException Expected exception: org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocationException

Tests run: 24, Failures: 1, Errors: 0, Skipped: 0
"
MAPREDUCE-6459,Native task crashes when merging spilled file on ppc64,"when running native task on ppc64，merging spilled files fails since we could not deserialize local spill file correctly.
Function readVLong in WritableUtils.h and Buffers.h, we try to compare a char with a number and convert a char to int64_t. It does not work correctly on ppc64 since char definition is different between ppc64 and x86 platform. On x86 platform char is defined as signed number while on ppc64 char is unsigned. As a result, we write EOF marker [-1, -1] at the end of spill partition, but deserialize chars as [255, 255]."
MAPREDUCE-6454,MapReduce doesn't set the HADOOP_CLASSPATH for jar lib in distributed cache.,"We already set lib jars on distributed-cache to CLASSPATH. However, in some corner cases (like: MR local mode, Hive Map side local join, etc.), we need these jars on HADOOP_CLASSPATH so hadoop scripts can take it in launching runjar process."
MAPREDUCE-6452,NPE when intermediate encrypt enabled for LocalRunner,"Enable the below properties try running mapreduce job

mapreduce.framework.name=local
mapreduce.job.encrypted-intermediate-data=true

{code}
2015-08-14 16:27:25,248 WARN  [Thread-21] mapred.LocalJobRunner (LocalJobRunner.java:run(561)) - job_local473843898_0001
java.lang.Exception: java.lang.NullPointerException
        at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:463)
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:523)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:92)
        at org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:31)
        at org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:112)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1611)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1492)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:723)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:793)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
        at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:244)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
        at java.lang.Thread.run(Thread.java:745)

{code}

Jobs are failing always"
MAPREDUCE-6451,DistCp has incorrect chunkFilePath for multiple jobs when strategy is dynamic,"DistCp when used with dynamic strategy does not update the chunkFilePath and other static variables any time other than for the first job. This is seen when DistCp::run() is used. 

A single copy succeeds but multiple jobs finish successfully without any real copying. "
MAPREDUCE-6445,Shuffle hang,"Scale cluster has run for months with 2.6.0.
2 of 200 reduces hang on shuffle

instance 1 log seems like loop on 1 map output:
{noformat}
2015-08-06 21:54:14,649 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-132.bj:22408 to fetcher#1
2015-08-06 21:54:14,651 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=20&map=attempt_1438689528746_10193_m_000013_0,attempt_1438689528746_10193_m_000020_0 sent hash and received reply
2015-08-06 21:54:14,651 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2015-08-06 21:54:14,651 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-132.bj:22408 freed by fetcher#1 in 2ms
2015-08-06 21:54:14,651 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-132.bj:22408 with 2 to fetcher#5
2015-08-06 21:54:14,651 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-132.bj:22408 to fetcher#5
2015-08-06 21:54:14,656 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=20&map=attempt_1438689528746_10193_m_000013_0,attempt_1438689528746_10193_m_000020_0 sent hash and received reply
2015-08-06 21:54:14,656 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2015-08-06 21:54:14,656 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-132.bj:22408 freed by fetcher#5 in 4ms
2015-08-06 21:54:14,656 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-132.bj:22408 with 2 to fetcher#5
2015-08-06 21:54:14,656 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-132.bj:22408 to fetcher#5
2015-08-06 21:54:14,660 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=20&map=attempt_1438689528746_10193_m_000013_0,attempt_1438689528746_10193_m_000020_0 sent hash and received reply
2015-08-06 21:54:14,660 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2015-08-06 21:54:14,660 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-132.bj:22408 freed by fetcher#5 in 5ms
2015-08-06 21:54:14,660 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-132.bj:22408 with 2 to fetcher#5
2015-08-06 21:54:14,660 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-132.bj:22408 to fetcher#5
{noformat}

node 2 log seems like loop on 5 map output:
{noformat}
2015-08-06 21:43:33,626 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-172.bj:22408 with 1 to fetcher#5
2015-08-06 21:43:33,626 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to node-172.bj:22408 to fetcher#5
2015-08-06 21:43:33,627 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000013_0,attempt_1438689528746_10193_m_000020_0 sent hash and received reply
2015-08-06 21:43:33,627 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
2015-08-06 21:43:33,627 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-132.bj:22408 freed by fetcher#3 in 5ms
2015-08-06 21:43:33,627 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-179.bj:22408 with 1 to fetcher#3
2015-08-06 21:43:33,627 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to node-179.bj:22408 to fetcher#3
2015-08-06 21:43:33,627 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000084_0,attempt_1438689528746_10193_m_000046_0 sent hash and received reply
2015-08-06 21:43:33,627 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergeManager returned status WAIT ...
2015-08-06 21:43:33,627 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-71.bj:22408 freed by fetcher#4 in 5ms
2015-08-06 21:43:33,627 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-71.bj:22408 with 2 to fetcher#4
2015-08-06 21:43:33,627 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-71.bj:22408 to fetcher#4
2015-08-06 21:43:33,628 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000092_0 sent hash and received reply
2015-08-06 21:43:33,628 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#2 - MergeManager returned status WAIT ...
2015-08-06 21:43:33,628 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-167.bj:22408 freed by fetcher#2 in 3ms
2015-08-06 21:43:33,628 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-132.bj:22408 with 2 to fetcher#2
2015-08-06 21:43:33,628 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 2 of 2 to node-132.bj:22408 to fetcher#2
2015-08-06 21:43:33,629 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000097_0 sent hash and received reply
2015-08-06 21:43:33,629 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 - MergeManager returned status WAIT ...
2015-08-06 21:43:33,629 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-174.bj:22408 freed by fetcher#1 in 3ms
2015-08-06 21:43:33,629 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-174.bj:22408 with 1 to fetcher#1
2015-08-06 21:43:33,629 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to node-174.bj:22408 to fetcher#1
2015-08-06 21:43:33,629 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000093_0 sent hash and received reply
2015-08-06 21:43:33,629 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#5 - MergeManager returned status WAIT ...
2015-08-06 21:43:33,630 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: node-172.bj:22408 freed by fetcher#5 in 3ms
2015-08-06 21:43:33,630 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning node-172.bj:22408 with 1 to fetcher#5
2015-08-06 21:43:33,630 INFO [fetcher#5] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 1 of 1 to node-172.bj:22408 to fetcher#5
2015-08-06 21:43:33,630 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=22408/mapOutput?job=job_1438689528746_10193&reduce=85&map=attempt_1438689528746_10193_m_000089_0 sent hash and received reply
2015-08-06 21:43:33,630 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergeManager returned status WAIT ...
{noformat}"
MAPREDUCE-6443,Add JvmPauseMonitor to Job History Server,We should add the {{JvmPauseMonitor}} from HADOOP-9618 to the Job History Server.
MAPREDUCE-6442,Stack trace is missing when error occurs in client protocol provider's constructor,when provider creation fail dump the stack trace rather than just print out the message
MAPREDUCE-6441,Improve temporary directory name generation in LocalDistributedCacheManager for concurrent processes,"Kicking off many sqoop processes in different threads results in:

{code}
2014-08-01 13:47:24 -0400:  INFO - 14/08/01 13:47:22 ERROR tool.ImportTool: Encountered IOException running import job: java.io.IOException: java.util.concurrent.ExecutionException: java.io.IOException: Rename cannot overwrite non empty destination directory /tmp/hadoop-hadoop/mapred/local/1406915233073

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:149)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapred.LocalJobRunner$Job.<init>(LocalJobRunner.java:163)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:731)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:432)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)

2014-08-01 13:47:24 -0400:  INFO - 	at java.security.AccessController.doPrivileged(Native Method)

2014-08-01 13:47:24 -0400:  INFO - 	at javax.security.auth.Subject.doAs(Subject.java:415)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1303)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.mapreduce.ImportJobBase.doSubmitJob(ImportJobBase.java:186)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.mapreduce.ImportJobBase.runJob(ImportJobBase.java:159)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.mapreduce.ImportJobBase.runImport(ImportJobBase.java:239)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.manager.SqlManager.importQuery(SqlManager.java:645)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:415)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:502)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.Sqoop.run(Sqoop.java:145)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:181)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:220)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.Sqoop.runTool(Sqoop.java:229)

2014-08-01 13:47:24 -0400:  INFO - 	at org.apache.sqoop.Sqoop.main(Sqoop.java:238)
{code}

If two are kicked off in the same second. The issue is the following lines of code in the org.apache.hadoop.mapred.LocalDistributedCacheManager class: 

{code}
    // Generating unique numbers for FSDownload.
    AtomicLong uniqueNumberGenerator =
       new AtomicLong(System.currentTimeMillis());
{code}

and 

{code}
Long.toString(uniqueNumberGenerator.incrementAndGet())),
{code}"
MAPREDUCE-6440,Duplicate Key in Json Output for Job details,"Duplicate key in Json Output for Job details for the url : 
http://<jhs_ip>:<jhs_port>/ws/v1/history/mapreduce/jobs/job_id/tasks/task_id/attempts

If the task type is ""REDUCE"" the json output for this url contains duplicate key for ""type"".
"
MAPREDUCE-6439,AM may fail instead of retrying if RM shuts down during the allocate call,"We are seeing cases where MR AM gets a YarnRuntimeException thats thrown in RM and gets sent back to AM causing it to think that it has exhausted the number of retries. Copying the error which causes the heartbeat thread to quit.

{noformat}
2015-07-25 20:07:27,346 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: java.lang.InterruptedException
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)
	at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)
	at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)
	... 11 more

org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.InterruptedException
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)
	at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)
	at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)
	... 11 more

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:107)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy36.allocate(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:188)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:667)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:244)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:282)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.yarn.exceptions.YarnRuntimeException): java.lang.InterruptedException
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:245)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:469)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)
	at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1219)
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:340)
	at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:338)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:240)
	... 11 more

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy35.allocate(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:77)
	... 12 more
{noformat} 
"
MAPREDUCE-6437,Add retry on some connection exception on job commit phase,"{code}
Job commit failed: java.net.ConnectException: Call From TS-DN-167/172.22.5.167 to SHYF-H11-BH03:52310 failed on connection exception: java.net.ConnectException: Connection timed out; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
at org.apache.hadoop.ipc.Client.call(Client.java:1415)
at org.apache.hadoop.ipc.Client.call(Client.java:1364)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
at com.sun.proxy.$Proxy14.create(Unknown Source)
at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:287)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
at java.lang.reflect.Method.invoke(Method.java:606)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
at com.sun.proxy.$Proxy15.create(Unknown Source)
at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1645)
at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1627)
at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1552)
at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:396)
at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:392)
at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:392)
at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:336)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889)
at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786)
at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.touchz(CommitterEventHandler.java:244)
at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.handleJobCommit(CommitterEventHandler.java:250)
at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.run(CommitterEventHandler.java:216)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection timed out
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
at org.apache.hadoop.ipc.Client.getConnection(Client.java:1463)
at org.apache.hadoop.ipc.Client.call(Client.java:1382)
... 28 more
{code}

Check the code, there is no chance to make another application master attempt if it encounters the issue of connection. So could we identify the exception, and make another retry or kick off another AM attempt?
"
MAPREDUCE-6436,JobHistory cache issue,"Problem: 
HistoryFileManager.addIfAbsent produces large amount of logs if number of
cached entries whose age is less than mapreduce.jobhistory.max-age-ms becomes
larger than mapreduce.jobhistory.joblist.cache.size by far.

Example:
For example, if the cache contains 50000 entries in total and 10,000 entries
newer than mapreduce.jobhistory.max-age-ms where
mapreduce.jobhistory.joblist.cache.size is 20000, HistoryFileManager.addIfAbsent
method produces 50000 - 20000 = 30000 lines of ""Waiting to remove <key> from
JobListCache because it is not in done yet"" message.

It will attach a stacktrace.

Impact:
In addition to large disk consumption, this issue blocks JobHistory.getJob
long time and slows job execution down significantly because getJob is called
by RPC such as HistoryClientService.HSClientProtocolHandler.getJobReport.
This impact happens because HistoryFileManager.UserLogDir.scanIfNeeded
eventually calls HistoryFileManager.addIfAbsent in a synchronized block. When
multiple threads call scanIfNeeded simultaneously, one of them acquires lock
and the other threads are blocked until the first thread completes long-running
HistoryFileManager.addIfAbsent call.

Solution: 
* Reduce amount of logs so that HistoryFileManager.addIfAbsent doesn't take too long time.
* Good to have if possible: HistoryFileManager.UserLogDir.scanIfNeeded skips
  scanning if another thread is already scanning. This changes semantics of
  some HistoryFileManager methods (such as getAllFileInfo and getFileInfo)
  because scanIfNeeded keep outdated state.
* Good to have if possible: Make scanIfNeeded asynchronous so that RPC calls are
  not blocked by a loop at scale of tens of thousands.
 
This patch implemented the first item.
"
MAPREDUCE-6435,MapReduce client assumes the world is x86,hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/util/Checksum.cc contains x86-only code and assumes it's going to work by default. The logic should be inverted so that it only uses the x86 code when built on x86 and otherwise defaults to the architecture-independent code. That will prevent changes having to be made for each new architecture.
MAPREDUCE-6433,launchTime may be negative,"Under extremely rare conditions (.0017% in our sample size), launchTime in the jhist files may be set to -1."
MAPREDUCE-6431,JobClient should be an AutoClosable,"Since the new target version if Java is 7, it would be great if JobClient could implement the java.lang.AutoClosable interface, so that it can be used in try-with-ressource statements. See here: https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html"
MAPREDUCE-6427,Fix typo in JobHistoryEventHandler," JobHistoryEventHandler#processEventForTimelineServer

 {code}tEvent.addEventInfo(""WORKLFOW_ID"", jse.getWorkflowId());{code}

 *should be like below.* 

 {code}tEvent.addEventInfo(""WORKFLOW_ID"", jse.getWorkflowId()); {code}"
MAPREDUCE-6426,TestShuffleHandler#testGetMapOutputInfo is failing,"{code:xml}
expected:<1> but was:<0>
Stacktrace

java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapred.TestShuffleHandler.testGetMapOutputInfo(TestShuffleHandler.java:927)
{code}

https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2195/testReport/junit/org.apache.hadoop.mapred/TestShuffleHandler/testGetMapOutputInfo/

https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/247/testReport/org.apache.hadoop.mapred/TestShuffleHandler/testGetMapOutputInfo/
"
MAPREDUCE-6425,"ShuffleHandler passes wrong ""base"" parameter to getMapOutputInfo if mapId is not in the cache.","ShuffleHandler passes wrong {{base}} parameter to {{getMapOutputInfo}} if mapId is not in the cache.
{{getMapOutputInfo}} expected the {{base}} parameter is {{getBaseLocation(jobId, user) + mapId}}
When it is called inside populateHeaders, the {{base}} parameter is set correctly
{code}
        String base = outputBaseStr + mapId;
        MapOutputInfo outputInfo = getMapOutputInfo(base, mapId, reduce, user);
{code}
When  it is called outside populateHeaders, the {{base}} parameter is set wrongly to outputBasePathStr after number of mapId cached exceeds {{mapOutputMetaInfoCacheSize}}.
{code}
         String outputBasePathStr = getBaseLocation(jobId, user);
          MapOutputInfo info = mapOutputInfoMap.get(mapId);
          if (info == null) {
            info = getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);
          }
{code}"
MAPREDUCE-6424,Store MR counters as timeline metrics instead of event,"In MAPREDUCE-6327, we make map/reduce counters get encoded from JobFinishedEvent as timeline events with counters details in JSON format. 
We need to store framework specific counters as metrics in timeline service to support query, aggregation, etc."
MAPREDUCE-6421,Fix findbugs warning in RMContainerAllocator.reduceNodeLabelExpression,"The actual error message is:

  Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceNodeLabelExpression; locked 66% of time

The full URL for the findbugs is at:

  https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5858/artifact/patchprocess/trunkFindbugsWarningshadoop-mapreduce-client-app.html

I haven't looked to see if this message is in error or if findbugs is correct.
"
MAPREDUCE-6420,Interrupted Exception in LocalContainerLauncher should be logged in warn/info level,Interrupted Exception in LocalContainerLauncher should be logged in warn/info levle instead of error because it won't fail the job. Otherwise it will cause some confusions during debugging
MAPREDUCE-6419,JobHistoryServer doesn't sort properly based on Job ID when Job id's exceed 9999,"When Job id's exceed 9999, JobHistoryServer is not sorting properly based on the Job ID. It is mixing the jobs having > 9999 with other jobs considering only the first four digits of the job id. The same problem could exist for Job Map tasks and Reduce tasks table as well.


It is similar to the issue YARN-3840 exists for YARN."
MAPREDUCE-6418,MRApp should not shutdown LogManager during shutdown,Tests in TestRecovery.java lost their logs after recovery due to the change of MAPREDUCE-5694. MRApp should overwrite those changes to allow log after am recover to be shown.
MAPREDUCE-6416,Not all platforms have d_type in struct dirent,"list() in hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/src/lib/FileSystem.cc assumes that struct dirent always contains a d_type field which can be used to determine the type of the directory entry. This field is non-POSIX and is not available on all platforms. On platforms where it is not available, stat() should be used instead to determine the type of the directory entry."
MAPREDUCE-6415,Create a tool to combine aggregated logs into HAR files,"While we wait for YARN-2942 to become viable, it would still be great to improve the aggregated logs problem.  We can write a tool that combines aggregated log files into a single HAR file per application, which should solve the too many files and too many blocks problems.  See the design document for details.

See YARN-2942 for more context."
MAPREDUCE-6413,TestLocalJobSubmission is failing with unknown host,ThestLocalJobSubmission.testLocalJobLibjarsOption is failing with java.net.UnknownHostException: testcluster
MAPREDUCE-6412,Make hadoop-mapreduce-client Native code -Wall-clean,
MAPREDUCE-6410,Aggregated Logs Deletion doesnt work after refreshing Log Retention Settings in secure cluster,"{{GSSException}} is thrown everytime log aggregation deletion is attempted after executing bin/mapred hsadmin -refreshLogRetentionSettings in a secure cluster.

The problem can be reproduced by following steps:
1. startup historyserver in secure cluster.
2. Log deletion happens as per expectation. 
3. execute {{mapred hsadmin -refreshLogRetentionSettings}} command to refresh the configuration value.
4. All the subsequent attempts of log deletion fail with {{GSSException}}

Following exception can be found in historyserver's log if log deletion is enabled. 
{noformat}
2015-06-04 14:14:40,070 | ERROR | Timer-3 | Error reading root log dir this deletion attempt is being aborted | AggregatedLogDeletionService.java:127
java.io.IOException: Failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]; Host Details : local host is: ""vm-31/9.91.12.31""; destination host is: ""vm-33"":25000; 
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
        at org.apache.hadoop.ipc.Client.call(Client.java:1414)
        at org.apache.hadoop.ipc.Client.call(Client.java:1363)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
        at com.sun.proxy.$Proxy9.getListing(Unknown Source)
        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:519)
        at sun.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
        at com.sun.proxy.$Proxy10.getListing(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1767)
        at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1750)
        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:691)
        at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:102)
        at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:753)
        at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:749)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:749)
        at org.apache.hadoop.yarn.logaggregation.AggregatedLogDeletionService$LogDeletionTask.run(AggregatedLogDeletionService.java:68)
        at java.util.TimerThread.mainLoop(Timer.java:555)
        at java.util.TimerThread.run(Timer.java:505)
Caused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:677)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1641)
        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:640)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:724)
        at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1462)
        at org.apache.hadoop.ipc.Client.call(Client.java:1381)
        ... 21 more
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:212)
        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:411)
        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:550)
        at org.apache.hadoop.ipc.Client$Connection.access$1800(Client.java:367)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:716)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:712)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1641)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:711)
        ... 24 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:147)
        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:121)
        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:187)
        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:223)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:212)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:179)
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:193)
        ... 33 more
{noformat}"
MAPREDUCE-6408,Queue name and user name should be printed on the job page,"Sometimes, users just give us a job link, and from there we don't which user submits this job and which queue was used. Currently we have go through the confs to find that out."
MAPREDUCE-6407,Migrate MAPREDUCE nativetask build to new CMake framework,"As per HADOOP-12036, the CMake infrastructure should be refactored and made common across all Hadoop components. This bug covers the migration of MAPREDUCE to the new CMake infrastructure. This change will also add support for building MAPREDUCE Native components on Solaris."
MAPREDUCE-6406,Update FileOutputCommitter.FILEOUTPUTCOMMITTER_ALGORITHM_VERSION_DEFAULT to match mapred-default.xml,"MAPREDUCE-6336 updated the default version for the property mapreduce.fileoutputcommitter.algorithm.version to 2.  Should the FileOutputCommitter class default be updated to match?
"
MAPREDUCE-6405,NullPointerException in App Attempts page,
MAPREDUCE-6404,Allow AM to specify a port range for starting its webapp,Allow AM to specify a port range for starting its webapp
MAPREDUCE-6403,Fix typo in the usage of NNBench,"Fix typo 'becnhmarks'.
{code:title=NNBench.java}
      ""\t-baseDir <base DFS path. default is /becnhmarks/NNBench. "" +
      ""This is not mandatory>\n"" +
{code}"
MAPREDUCE-6400,Multiple shuffle transfer fails because input is closed too early,"TestReduceFetchFromPartialMem fails.
{noformat}
Running org.apache.hadoop.mapred.TestReduceFetchFromPartialMem
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 132.978 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestReduceFetchFromPartialMem
testReduceFromPartialMem(org.apache.hadoop.mapred.TestReduceFetchFromPartialMem)  Time elapsed: 69.214 sec  <<< ERROR!
java.io.IOException: Job failed!
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:867)
	at org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.runJob(TestReduceFetchFromPartialMem.java:300)
	at org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem(TestReduceFetchFromPartialMem.java:93)


Results :

Tests in error: 
  TestReduceFetchFromPartialMem.testReduceFromPartialMem:93->runJob:300 » IO Job...

Tests run: 1, Failures: 0, Errors: 1, Skipped: 0
{noformat}"
MAPREDUCE-6398,Two RMNodes for the same NodeId are used in RM sometimes after NM is reconnected.,"Two RMNodes for the same NodeId are used in RM sometimes after NM is reconnected. Scheduler and RMContext use different RMNode reference for the same NodeId sometimes after NM is reconnected, which is not correct. Scheduler and RMContext should always use same RMNode reference for the same NodeId."
MAPREDUCE-6396,TestPipeApplication fails by NullPointerException,"TestPipeApplication#testApplication and TestPipeApplication#testRunner fail on trunk.
{noformat}
Running org.apache.hadoop.mapred.pipes.TestPipeApplication
Tests run: 5, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 5.758 sec <<< FAILURE! - in org.apache.hadoop.mapred.pipes.TestPipeApplication
testApplication(org.apache.hadoop.mapred.pipes.TestPipeApplication)  Time elapsed: 1.157 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.fs.permission.FsPermission.applyUMask(FsPermission.java:213)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:498)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:553)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:526)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:298)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:287)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:891)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:788)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:777)
	at org.apache.hadoop.mapred.pipes.TestPipeApplication.testApplication(TestPipeApplication.java:180)

testRunner(org.apache.hadoop.mapred.pipes.TestPipeApplication)  Time elapsed: 0.035 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.fs.permission.FsPermission.applyUMask(FsPermission.java:213)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:498)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:553)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:526)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:298)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:287)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:891)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:788)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:777)
	at org.apache.hadoop.mapred.pipes.TestPipeApplication.testRunner(TestPipeApplication.java:98)
{noformat}"
MAPREDUCE-6395,Improve the commit failure messages in MRAppMaster recovery,"There are typos, and pluralis majestatis (royal we) or user-including ""we"" messages that are confusing to the users:
{code}
        if (commitSuccess) {
          shutDownMessage = ""We crashed after successfully committing. Recovering."";
          forcedState = JobStateInternal.SUCCEEDED;
        } else if (commitFailure) {
          shutDownMessage = ""We crashed after a commit failure."";
          forcedState = JobStateInternal.FAILED;
        } else {
          //The commit is still pending, commit error
          shutDownMessage = ""We crashed durring a commit"";
          forcedState = JobStateInternal.ERROR;
        }
{code}"
MAPREDUCE-6394,Speed up Task processing loop in HsTasksBlock#render(),"In HsTasksBlock#render(), there is a loop to create a Javascript table which slows down immensely on jobs with a large number of tasks (200k or more)."
MAPREDUCE-6392,Document mapred class path options,"--global, --jar options are not documented.

{code}
$ mapred classpath --help
classpath [--glob|--jar <path>|-h|--help] :
  Prints the classpath needed to get the Hadoop jar and the required
  libraries.
  Options:

  --glob       expand wildcards
  --jar <path> write classpath as manifest in jar named <path>
  -h, --help   print help
{code}

current document:
{code}
Prints the class path needed to get the Hadoop jar and the required libraries.

Usage: mapred classpath
{code}

http://hadoop.apache.org/docs/r2.7.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapredCommands.html#classpath"
MAPREDUCE-6391,util/Timer.cc completely misunderstands _POSIX_CPUTIME,"util/Timer.cc contains the following code:

clock_gettime(_POSIX_CPUTIME, &ts);

I'm not exactly sure what sort of time value this code is attempting to obtain (the process's on-CPU time perhaps?) but it is completely wrong, even on Linux. _POSIX_CPUTIME is a feature test macro and is *not* a valid parameter to clock_gettime. From the clock_gettime manpage:

bq. The symbols _POSIX_MONOTONIC_CLOCK, _POSIX_CPUTIME, _POSIX_THREAD_CPUTIME indicate that CLOCK_MONOTONIC, CLOCK_PROCESS_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID are available

On  my Linux distro the value of _POSIX_CPUTIME is defined as 0. That corresponds to

bq.  #define __CLOCK_REALTIME0       0       /* obsolete; same as CLOCK_REALTIME */

And CLOCK_REALTIME is

bq. #define CLOCK_REALTIME          3       /* wall clock */

Which I suspect is not what is required here.

Getting cross-platform CPU time is fiddly, the following blog post has a good summary: http://nadeausoftware.com/articles/2012/03/c_c_tip_how_measure_cpu_time_benchmarking (code examples are CC licensed so should be no taint issues)
"
MAPREDUCE-6389,Fix BaileyBorweinPlouffe CLI usage message ,"The usage message from code does not match with the command helpline option. 

 *usage from command line* 
{noformat}
hduser@canberra:~/work/software/cloudera/hadoop-2.0.0-cdh4.0.0$ hadoop jar src/hadoop-mapreduce-project/hadoop-mapreduce-examples/target/hadoop-mapreduce-examples-2.0.0-cdh4.0.0.jar 
An example program must be given as the first argument.
Valid program names are:
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
  dbcount: An example job that count the pageview counts from a database.
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
  grep: A map/reduce program that counts the matches of a regex in the input.
{noformat}

 *usage from code* 
{code}
 public int run(String[] args) throws IOException {
    if (args.length != 4) {
      System.err.println(""Usage: java "" + getClass().getName()
          + "" <startDigit> <nDigits> <nMaps> <workingDir>"");
      ToolRunner.printGenericCommandUsage(System.err);
      return -1;
    }
{code}"
MAPREDUCE-6388,Remove deprecation warnings from JobHistoryServer classes,There are a ton of deprecation warnings in the JobHistoryServer classes.  This is affecting some modifications I'm making since a single line move shifts all the deprecation warnings.  I'd like to get these fixed to prevent minor changes from generating a ton of warnings in test-patch.
MAPREDUCE-6387,Serialize the recently added Task#encryptedSpillKey field at the end,"There was a recent addition of an {{encryptedSpillKey}} to the Task object. And when serialized, this field was written out somewhere in the middle. This caused deployments that do not use DistributedCache to push job jars before running the job to fail rolling upgrade.

Although deploying via Distributed Cache is the recommended method, there might still be deployments that use the node local classpath to pick up the MR framework classes (eg. for efficiency purposes, since this does not require the jar being copied to hdfs and then to all the nodes)

Ensuring that it is the last field written and read when the Task object is serialized would alleviate this issue."
MAPREDUCE-6384,Add the last reporting reducer info for too many fetch failure diagnostics,
MAPREDUCE-6383,Pi job (QuasiMonteCarlo) should not try to read the results file if its job fails,Currently it tries to read the standard result path and logs a failure a second time.
MAPREDUCE-6382,Don't escape HTML links in Diagnostics in JHS job overview,"for some reason, links are working properly in 2.4, but they are escaped in 2.6"
MAPREDUCE-6378,convergence error in hadoop-streaming during mvn install,Running mvn install in the hadoop-tools/hadoop-streaming directory results in a convergence error.  See comments.
MAPREDUCE-6377,JHS sorting on state column not working in webUi,"Steps to reproduce
================
1. Install and setup HA cluster with JHS
2.Create state in in JHS where few jobs are killed and Success

Check sorting State in JHS WebUI

Actual
=====
Sorting on state column  not working in JHS

Expected
======
Sorting on state column should be working
"
MAPREDUCE-6376,Add avro binary support for jhist files,"When you click on a Job link in the JHS Web UI, it loads the .jhist file.  For jobs which have a large number of tasks, the load time can break UI responsiveness."
MAPREDUCE-6375,Modify the JHS to be able to read the ConcatenatableAggregatedLogFormat,"When serving logs, the JHS needs to be able to read the {{ConcatenatableAggregatedLogFormat}} or the {{AggregatedLogFormat}} transparently.

(see YARN-2942)"
MAPREDUCE-6374,Distributed Cache File visibility should check permission of full path,should do full ancestor permission check for a relative cache file input
MAPREDUCE-6373,The logger reports total input paths but it is referring to input files,"The log message in the FileInputFormat is misleading : 

{code}
2015-04-24 13:12:30,205 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 6
{code} 

There is only 1 input path and 6 input files so the log message should be :

{code}
2015-04-24 13:12:30,205 [main] INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 6
{code} "
MAPREDUCE-6372,clean up several issues with TimelineServicePerformance,We found a few issues with the TimelineServicePerformanceV2 test driver while running it for the performance tests. Filing this JIRA to fix those issues.
MAPREDUCE-6371,HTML tag shown in Diagnostics field of JobHistoryPage,"Diagnostics shown wrong in Jobhistory page
Incase of failed task

{code}
Diagnostics  : Task failed <a href=""/jobhistory/task/task_1432651802642_0086_r_000000"">task_1432651802642_0086_r_000000</a>
Job failed as tasks failed. failedMaps:0 failedReduces:1
{code}

Please check the image for detail"
MAPREDUCE-6370,Timeline service v2 load generator needs to write event id,We need to write a sample event id in SimpleEntityWriter so that both HBase and Phoenix writers can actually write the timeline event. For now the Phoenix implementation will throw exceptions and the HBase will skip storing the timeline event. 
MAPREDUCE-6368,Unreachable Java code,"Reference
Class: org.apache.hadoop.mapreduce.lib.partition.InputSampler
Method: writePartitionFile
Line: 337

The issue exists in the following code loop at line 337:-

while (last >= k && comparator.compare(samples[last], samples[k]) == 0) 
{
      ++k; 
 }

The problem is that the first condition in the while loop (last >= k) will always be false. The value of 'last' will always be lesser than 'k' and hence the first condition will never evaluate to true. There is second condition as well but since it is appearing as AND condition, that will never be checked since the first condition itself is false. Hence this loop is not contributing towards the code output anyways. If this was intended to execute, then I guess it will need investigation. But from what I have noticed, it doesn't seem to harm the output of the method. In that case why even keep it there. We could very well remove it from the code. And if this was done with the some other intention, in that case this needs to be corrected as currently it is unreachable code. This issue very much exists in the release 2.6.0, I have not seen the release 2.7.0 source code, but it may very well exist in that as well (it's worth checking).

Thanks & Regards,
Dhiraj"
MAPREDUCE-6367,UniformSizeInputFormat skews left over bytes to last split,"In UniformSizeInputFormat it is trying to get equal amount of bytes to every split. But the logic today will result in every split having a little less then the perfect amount and that left over from every split will be put into the last split.

Resulting in a large skew for the last split.

Below if the area of the code that is affected:

https://github.com/apache/hadoop/blob/9ae7f9eb7baeb244e1b95aabc93ad8124870b9a9/hadoop-tools/hadoop-distcp/src/main/java/org/apache/hadoop/tools/mapred/UniformSizeInputFormat.java#L98

The fix would be to change the following line:

currentSplitSize += srcFileStatus.getLen();

to

currentSplitSize += srcFileStatus.getLen() + (currentSplitSize - nBytesPerSplit);"
MAPREDUCE-6366,mapreduce.terasort.final.sync configuration in TeraSort  doesn't work,"A TeraOutputFormat's field, finalSync, is always set ""true"". Therefore TeraSort 's  mapreduce.terasort.final.sync option doesn't work."
MAPREDUCE-6365,Refactor JobResourceUploader#uploadFilesInternal,JobResourceUploader#uploadFilesInternal is a large method and there are similar pieces of code that could probably be pulled out into separate methods.  This refactor would improve readability of the code.
MAPREDUCE-6364,"Add a ""Kill"" link to Task Attempts page","Add a ""Kill"" link to Task Attempts page, calling REST API by pushing the link."
MAPREDUCE-6363,[NNBench] Lease mismatch error when running with multiple mappers,"Command :

./yarn jar ../share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.0.1-tests.jar nnbench -operation create_write -numberOfFiles 1000 -blockSize 268435456 -bytesToWrite 1024000000 -baseDir /benchmarks/NNBench`hostname -s` -replicationFactorPerFile 3 -maps 100 -reduces 10

Trace :

013-06-21 10:44:53,763 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9005, call org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 192.168.105.214:36320: error: org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: Lease mismatch on /benchmarks/NNBenchlinux-185/data/file_linux-214__0 owned by DFSClient_attempt_1371782327901_0001_m_000048_0_1383437860_1 but is accessed by DFSClient_attempt_1371782327901_0001_m_000084_0_1880545303_1
org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException: Lease mismatch on /benchmarks/NNBenchlinux-185/data/file_linux-214__0 owned by DFSClient_attempt_1371782327901_0001_m_000048_0_1383437860_1 but is accessed by DFSClient_attempt_1371782327901_0001_m_000084_0_1880545303_1
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2351)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.analyzeFileState(FSNamesystem.java:2098)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2019)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:501)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:213)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java:52012)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:435)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:925)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1710)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1706)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
"
MAPREDUCE-6361,NPE issue in shuffle caused by concurrent issue between copySucceeded() in one thread and copyFailed() in another thread on the same host,"The failure in log:
2015-05-08 21:00:00,513 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#25
         at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
         at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
         at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
         at java.security.AccessController.doPrivileged(Native Method)
         at javax.security.auth.Subject.doAs(Subject.java:415)
         at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
         at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
Caused by: java.lang.NullPointerException
         at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:267)
         at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:308)
         at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)"
MAPREDUCE-6360,"TestMapreduceConfigFields is placed in wrong dir, introducing compile error","MAPREDUCE-6192 has introduced a Test file {{TestMapreduceConfigFields }}
which was committed in package {{org.apache.hadoop.mapred}}
But the package declaration  inside file is {{org.apache.hadoop.mapreduce}}.

By surprise, this is not giving any compile errors in maven build. But eclipse catches it.
So move {{TestMapreduceConfigFields }} to correct package  {{org.apache.hadoop.mapreduce}}"
MAPREDUCE-6359,"RM HA setup, ""Cluster"" tab links populated with AM hostname instead of RM ","In RM HA setup ( e.g. http://rm-1.vip.abc.com:50030/proxy/application_1427789305393_0002/ ), go to the job details and click on the ""Cluster tab"" on left top side. Click on any of the links , ""About"", Applications"" , ""Scheduler"". You can see that the hyperlink is pointing to http://am-1.vip.abc.com:port/cluster ).

The port details for secure and unsecure cluster is given below :-
  8088 ( DEFAULT_RM_WEBAPP_PORT = 8088 )
  8090  ( DEFAULT_RM_WEBAPP_HTTPS_PORT = 8090 )

Ideally, it should have pointed to resourcemanager hostname instead of AM hostname."
MAPREDUCE-6357,MultipleOutputs.write() API should document that output committing is not utilized when input path is absolute,"After spending the afternoon debugging a user job where reduce tasks were failing on retry with the below exception, I think it would be worthwhile to add a note in the MultipleOutputs.write() documentation, saying that absolute paths may cause improper execution of tasks on retry or when MR speculative execution is enabled. 

{code}
2015-04-28 23:13:10,452 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.IOException: File already exists:wasb://full20150320@bgtstoragefull.blob.core.windows.net/user/hadoop/some/path/block-r-00299.bz2
       at org.apache.hadoop.fs.azure.NativeAzureFileSystem.create(NativeAzureFileSystem.java:1354)
       at org.apache.hadoop.fs.azure.NativeAzureFileSystem.create(NativeAzureFileSystem.java:1195)
       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908)
       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889)
       at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786)
       at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:135)
       at org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.getRecordWriter(MultipleOutputs.java:475)
       at org.apache.hadoop.mapreduce.lib.output.MultipleOutputs.write(MultipleOutputs.java:433)
       at com.ancestry.bigtree.hadoop.LevelReducer.processValue(LevelReducer.java:91)
       at com.ancestry.bigtree.hadoop.LevelReducer.reduce(LevelReducer.java:69)
       at com.ancestry.bigtree.hadoop.LevelReducer.reduce(LevelReducer.java:14)
       at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
       at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
       at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
       at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:415)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
       at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)
{code}

As discussed in MAPREDUCE-3772, when the baseOutputPath passed to MultipleOutputs.write() is an absolute path (or more precisely a path that resolves outside of the job output-dir), the concept of output committing is not utilized. 

In this case, the user read thru the MultipleOutputs docs and was assuming that everything will be working fine, as there are blog posts saying that MultipleOutputs does handle output commit. "
MAPREDUCE-6356,Misspelling of threshold in log4j.properties for tests,"log4j.properties file for test contains misspelling ""log4j.threshhold"".
We should use ""log4j.threshold"" correctly."
MAPREDUCE-6355,2.5 client cannot communicate with 2.5 job on 2.6 cluster,Trying to run a job on a Hadoop 2.6 cluster from a Hadoop 2.5 client submitting a job that uses Hadoop 2.5 jars results in a job that succeeds but the client cannot communicate with the AM while the job is running.
MAPREDUCE-6354,ShuffleHandler should be able to log shuffle connections,"currently, shuffle handler only log connection info in debug mode, we want to log that info in a more concise way"
MAPREDUCE-6353,Divide by zero error in MR AM when calculating available containers,"When running a sleep job with zero CPU vcores i see the following exception

2015-04-30 06:41:06,954 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
java.lang.ArithmeticException: / by zero
at org.apache.hadoop.mapreduce.v2.app.rm.ResourceCalculatorUtils.computeAvailableContainers(ResourceCalculatorUtils.java:38)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:947)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$200(RMContainerAllocator.java:840)
at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:247)
at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:282)
at java.lang.Thread.run(Thread.java:745)"
MAPREDUCE-6351,Reducer hung in copy phase.,"*Problem*
Reducer gets stuck in copy phase and doesn't make progress for very long time. After killing this task for couple of times manually, it gets completed. 

*Observations*
- Verfied gc logs. Found no memory related issues. Attached the logs.
- Verified thread dumps. Found no thread related problems. 
- On verification of logs, fetcher threads are not copying the map outputs and they are just waiting for merge to happen.
- Merge thread is alive and in wait state.


*Analysis* 
On careful observation of logs, thread dumps and code, this looks to me like a classic case of multi-threading issue. Thread goes to wait state after it has been notified. 

Here is the suspect code flow.
*Thread #1*
Fetcher thread - notification comes first
org.apache.hadoop.mapreduce.task.reduce.MergeThread.startMerge(Set<T>)
{code}
      synchronized(pendingToBeMerged) {
        pendingToBeMerged.addLast(toMergeInputs);
        pendingToBeMerged.notifyAll();
      }
{code}

*Thread #2*
Merge Thread - goes to wait state (Notification goes unconsumed)
org.apache.hadoop.mapreduce.task.reduce.MergeThread.run()
{code}
        synchronized (pendingToBeMerged) {
          while(pendingToBeMerged.size() <= 0) {
            pendingToBeMerged.wait();
          }
          // Pickup the inputs to merge.
          inputs = pendingToBeMerged.removeFirst();
        }
{code}"
MAPREDUCE-6350,JobHistory doesn't support fully-functional search,job history server will only output the first 50 characters of the job names in webUI.
MAPREDUCE-6349,Fix typo in property org.apache.hadoop.mapreduce.lib.chain.Chain.REDUCER_INPUT_VALUE_CLASS,Ran across this typo in a property.  It doesn't look like it's used anywhere externally.
MAPREDUCE-6348,JobHistoryEventHandler could not flush every 30 secondes,"JobHistoryEventHandler could not flush the event every 30 seconds.
cause the var isTimerActive is never set to true.
"
MAPREDUCE-6347,TestBinaryTokenFile (and others) fail,"Seeing the following stack trace and the unit test goes into a infinite loop:

2013-06-24 17:03:58,316 ERROR [LocalizerRunner for container_1372118631537_0001_01_000001] security.UserGroupInformation (UserGroupInformation.java:doAs(1480)) - PriviledgedActionException as:kamkasravi (auth:SIMPLE) cause:java.io.IOException: Server asks us to fall back to SIMPLE auth, but this client is configured to only allow secure connections.
2013-06-24 17:03:58,317 WARN  [LocalizerRunner for container_1372118631537_0001_01_000001] ipc.Client (Client.java:run(579)) - Exception encountered while connecting to the server : java.io.IOException: Server asks us to fall back to SIMPLE auth, but this client is configured to only allow secure connections.
2013-06-24 17:03:58,318 ERROR [LocalizerRunner for container_1372118631537_0001_01_000001] security.UserGroupInformation (UserGroupInformation.java:doAs(1480)) - PriviledgedActionException as:kamkasravi (auth:SIMPLE) cause:java.io.IOException: java.io.IOException: Server asks us to fall back to SIMPLE auth, but this client is configured to only allow secure connections.
java.lang.reflect.UndeclaredThrowableException
        at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.unwrapAndThrowException(YarnRemoteExceptionPBImpl.java:135)
        at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.client.LocalizationProtocolPBClientImpl.heartbeat(LocalizationProtocolPBClientImpl.java:56)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.localizeFiles(ContainerLocalizer.java:247)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.runLocalization(ContainerLocalizer.java:181)
        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.startLocalizer(DefaultContainerExecutor.java:103)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:859)"
MAPREDUCE-6346,mapred.nativetask.kvtest.KVTest crashes on PPC64LE,"Test org.apache.hadoop.mapred.nativetask.kvtest.KVTest (and 5 or 6 other tests) crashes on PPC64LE .

....
15/04/28 10:46:06 INFO Mid-spill: { id: 4, collect: 245 ms, in-memory sort: 32 ms, in-memory records: 48202, merge&spill: 80 ms, uncompressed size: 5031451, real size: 3739319 path: /tmp/hadoop-reixt/mapred/local/localRunner/reixt/jobcache/job_local408221154_0008/attempt_local408221154_0008_m_000000_0/output/spill4.out }
# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x00003fff6c7d8e50, pid=945, tid=70366264881616
#
# JRE version: OpenJDK Runtime Environment (7.0_79-b14) (build 1.7.0_79-mockbuild_2015_04_10_10_48-b00)
# Java VM: OpenJDK 64-Bit Server VM (24.79-b02 mixed mode linux-ppc64 compressed oops)
# Derivative: IcedTea 2.5.5
# Distribution: Built on Red Hat Enterprise Linux Server release 7.1 (Maipo) (Fri Apr 10 10:48:01 EDT 2015)
# Problematic frame:
# C  [libnativetask.so.1.0.0+0x58e50]  NativeTask::WritableUtils::ReadVLongInner(char const*, unsigned int&)+0x40
#
# Core dump written. Default location: /home/reixt/HADOOP-2.7.0/hadoop-FromApache-Trunk-201504241115/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/core or core.945
#
# An error report file with more information is saved as:
# /tmp/jvm-945/hs_error.log
#
# If you would like to submit a bug report, please include
# instructions on how to reproduce the bug and visit:
#   http://icedtea.classpath.org/bugzilla
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#
/bin/sh: line 1:   945 Aborted                 (core dumped) /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.79-2.5.5.1.ael7b_1.ppc64le/jre/bin/java -Xmx4096m -XX:MaxPermSize=768m -XX:+HeapDumpOnOutOfMemoryError -jar /home/reixt/HADOOP-2.7.0/hadoop-FromApache-Trunk-201504241115/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/surefire/surefirebooter9078773752877532263.jar /home/reixt/HADOOP-2.7.0/hadoop-FromApache-Trunk-201504241115/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/surefire/surefire4138802116387705281tmp /home/reixt/HADOOP-2.7.0/hadoop-FromApache-Trunk-201504241115/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/target/surefire/surefire_01525011254551870798tmp

/tmp/jvm-945/hs_error.log :

# C  [libnativetask.so.1.0.0+0x58e50]  NativeTask::WritableUtils::ReadVLongInner(char const*, unsigned int&)+0x40"
MAPREDUCE-6345,Documentation fix for when CRLA is enabled for MRAppMaster logs,"CRLA is enabled for the ApplicationMaster when both yarn.app.mapreduce.am.container.log.limit.kb (not mapreduce.task.userlog.limit.kb) and yarn.app.mapreduce.am.container.log.backups are greater than zero.

This was changed in MAPREDUCE-5773.
"
MAPREDUCE-6343,JobConf.parseMaximumHeapSizeMB() fails to parse value greater than 2GB expressed in bytes,"It currently tries to parse the value as an integer, which blows up whenever the value is greater than 2GB and expressed in bytes."
MAPREDUCE-6342,Make POM project names consistent,This is track MR changes for POM changes  by name
MAPREDUCE-6341,Fix typo in mapreduce tutorial,There are some typos in the converted tutorial in markdown.
MAPREDUCE-6339,Job history file is not flushed correctly because isTimerActive flag is not set true when flushTimerTask is scheduled.,"Job history file is not flushed correctly because isTimerActive flag is not set true when flushTimerTask is scheduled.
It looks like we should set isTimerActive to true when flushTimerTask is scheduled. Otherwise if a new qualified event comes before the current flush timer is expired,  flushTimerTask will be canceled and rescheduled.
Also I didn't find any code which set isTimerActive flag to true, So isTimerActive is useless in current code."
MAPREDUCE-6338,MR AppMaster does not honor ephemeral port range,"# The MR AppMaster should only use port ranges defined in the yarn.app.mapreduce.am.job.client.port-range property.  On initial startup of the MRAppMaster, it does use the port range defined in the property.  However, it also opens up a listener on a random ephemeral port.  This is not the Jetty listener.  It is another listener opened by the MRAppMaster via another thread and is recognized by the RM.  Other nodes will try to communicate to it via that random port.  With firewall settings on, the MR job will fail because the random port is not opened.  This problem has caused others to have all OS ephemeral ports opened to have MR jobs run.

This is related to MAPREDUCE-4079"
MAPREDUCE-6337,add a mode to replay MR job history files to the timeline service,The subtask covers the work on top of YARN-3437 to add a mode to replay MR job history files to the timeline service storage.
MAPREDUCE-6336,Enable v2 FileOutputCommitter by default,"This JIRA is to propose making new FileOutputCommitter behavior from MAPREDUCE-4815 enabled by default in trunk, and potentially in branch-2. "
MAPREDUCE-6335,convert load test driver to timeline service v.2,This subtask covers the work for converting the proposed patch for the load test driver (YARN-2556) to work with the timeline service v.2.
MAPREDUCE-6334,Fetcher#copyMapOutput is leaking usedMemory upon IOException during InMemoryMapOutput shuffle handler,"We are seeing this happen when
- an NM's disk goes bad during the creation of map output(s)
- the reducer's fetcher can read the shuffle header and reserve the memory
- but gets an IOException when trying to shuffle for InMemoryMapOutput
- shuffle fetch retry is enabled
"
MAPREDUCE-6333,"TestEvents,TestAMWebServicesTasks,TestAppController are broken due to MAPREDUCE-6297","For some reason, tests in MAPREDUCE-6297 are all passed"
MAPREDUCE-6331,[Umbrella] Make MapReduce work with Timeline Service Nextgen (YARN-2928),Tracking umbrella for all MR changes to make it work with Timeline Service Nextgen - YARN-2928.
MAPREDUCE-6330,Fix typo in Task Attempt API's URL in documentations,Some Task Attempt API's URL is typo. attempt is wrong
MAPREDUCE-6327,[Event producers] Implement MapReduce AM writing MR events/counters to v2 ATS,"Per design in YARN-2928, select a handful of MR metrics (e.g. HDFS bytes written) and have the MR AM write the framework-specific metrics to ATS."
MAPREDUCE-6324,Uber jobs fail to update AMRM token when it rolls over,When the RM rolls a new AMRM master key the AMs are supposed to receive a new AMRM token on subsequent heartbeats between the time when the new key is rolled and when it is activated.  This is not occurring for uber jobs.  If the connection to the RM needs to be re-established after the new key is activated (e.g.: RM restart or network hiccup) then the uber job AM will be unable to reconnect to the RM.
MAPREDUCE-6317,Invalid Resource Exception could be handled properly when cores not available,"Configure yarn.nodemanager.resource.cpu-vcores=2 for NM
Set mapreduce.map.cpu.vcores=5 while running sleep job n client


{code}
2015-04-10 20:37:26,111 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: ERROR IN CONTACTING RM. 
org.apache.hadoop.yarn.exceptions.InvalidResourceRequestException: Invalid resource request, requested virtual cores < 0, or requested virtual cores > max configured, requestedVirtualCores=5, maxVirtualCores=2
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerUtils.validateResourceRequest(SchedulerUtils.java:213)
	at org.apache.hadoop.yarn.server.resourcemanager.RMServerUtils.validateResourceRequests(RMServerUtils.java:97)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.allocate(ApplicationMasterService.java:502)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationMasterProtocolPBServiceImpl.allocate(ApplicationMasterProtocolPBServiceImpl.java:60)
	at org.apache.hadoop.yarn.proto.ApplicationMasterProtocol$ApplicationMasterProtocolService$2.callBlockingMethod(ApplicationMasterProtocol.java:99)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:636)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:976)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2142)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2138)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1669)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2136)

	at sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:101)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:79)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)
	at com.sun.proxy.$Proxy34.allocate(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:199)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:686)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:257)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:281)
	at java.lang.Thread.run(Thread.java:745)
Caused by: 2015-04-10 20:37:27,117 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Could not contact RM after 360000 milliseconds.
2015-04-10 20:37:27,173 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator: Error communicating with RM: Could not contact RM after 360000 milliseconds.
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Could not contact RM after 360000 milliseconds.
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:712)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:257)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:281)
	at java.lang.Thread.run(Thread.java:745)
{code}

Rm communication timeout is thrown and fails after 2 app attempts
Invalid resource exception not handled in RM container allocator
{code}
    @SuppressWarnings(""unchecked"")
  private List<Container> getResources() throws Exception {
    applyConcurrentTaskLimits();

    // will be null the first time
    Resource headRoom =
        getAvailableResources() == null ? Resources.none() :
            Resources.clone(getAvailableResources());
    AllocateResponse response;
    /*
     * If contact with RM is lost, the AM will wait MR_AM_TO_RM_WAIT_INTERVAL_MS
     * milliseconds before aborting. During this interval, AM will still try
     * to contact the RM.
     */
    try {
      response = makeRemoteRequest();
      // Reset retry count if no exception occurred.
      retrystartTime = System.currentTimeMillis();
    } catch (ApplicationAttemptNotFoundException e ) {
{code}

RMContainerAllocator should handle invalid resource exception and wait till new nodemanager added with expected resource

"
MAPREDUCE-6316,Task Attempt List entries should link to the task overview,"Typical workflow is to click on the list of failed attempts. Then you want to look at the counters, or the list of attempts of just one task in general. If each entry task attempt id linked the task id portion of it back to the task, we would not have to go through the list of tasks to search for the task."
MAPREDUCE-6314,TestPipeApplication fails on trunk,MAPREDUCE-6291 causes the TestPipeApplication#testSubmitter test to fail.
MAPREDUCE-6313,Audit/optimize tests in hadoop-mapreduce-client-jobclient,"The tests in this package take an extremely long time to run, with some tests taking 15-20 minutes on their own.  It would be worthwhile to verify and optimize any tests in this package in order to reduce patch testing time or perhaps even splitting the package up."
MAPREDUCE-6310,Add jdiff support to MapReduce,Previously we used jdiff for Hadoop common and HDFS. Now we're extending the support of jdiff to YARN. Probably we'd like to do similar things with MapReduce? 
MAPREDUCE-6309,Sort by Elapsed Time doesn't work properly in Task UI,Sort by elapsed time does not work properly because 3sec is regarded greater than 10sec.
MAPREDUCE-6308,Remove mapreduce.tasktracker.taskmemorymanager.monitoringinterval from trunk,"mapreduce.tasktracker.taskmemorymanager.monitoringinterval is not used anywhere, should be removed."
MAPREDUCE-6307,Remove property mapreduce.tasktracker.taskmemorymanager.monitoringinterval,mapreduce.tasktracker.taskmemorymanager.monitoringinterval is not used anywhere. We should remove the property.
MAPREDUCE-6305,AM/Task log page should be able to link back to the job,
MAPREDUCE-6304,Specifying node labels when submitting MR jobs,"Per the discussion on YARN-796, we need a mechanism in MAPREDUCE to specify node labels when submitting MR jobs."
MAPREDUCE-6303,Read timeout when retrying a fetch error can be fatal to a reducer,If a reducer encounters an error trying to fetch from a node then encounters a read timeout when trying to re-establish the connection then the reducer can fail.  The read timeout exception can leak to the top of the Fetcher thread which will cause the reduce task to teardown.  This type of error can repeat across reducer attempts causing jobs to fail due to a single bad node.
MAPREDUCE-6302,Preempt reducers after a configurable timeout irrespective of headroom,"I submit a  big job, which has 500 maps and 350 reduce, to a queue(fairscheduler) with 300 max cores. When the big mapreduce job is running 100% maps, the 300 reduces have occupied 300 max cores in the queue. And then, a map fails and retry, waiting for a core, while the 300 reduces are waiting for failed map to finish. So a deadlock occur. As a result, the job is blocked, and the later job in the queue cannot run because no available cores in the queue.
I think there is the similar issue for memory of a queue .
"
MAPREDUCE-6301,"Task UI, sort by name doesn't work","If you go to the MapReduce ApplicationMaster or HistoryServer UI and open the list of tasks, then try to sort by the task name/id, it does nothing.

Note that if you go to the task attempts, that seem to sort fine."
MAPREDUCE-6300,Task list sort by task id broken,"If you go to the MapReduce ApplicationMaster or HistoryServer UI and open the list of tasks, then try to sort by the task name/id, it does nothing.
Note that if you go to the task attempts, that seem to sort fine."
MAPREDUCE-6297,Task Id of the failed task in diagnostics should link to the task page,"Currently we have to copy it and search in the task list.
"
MAPREDUCE-6295,Fix MR resource counter to handle negative value for getting memory resource after YARN-3304,"After YARN-3304, we will get negative value for memory resource if resource data is unavailable. MR resource counter shouldn't put negative value there so a simple fix is required."
MAPREDUCE-6294,Remove an extra parameter described in Javadoc of TockenCache,"/**
   * get delegation token for a specific FS
   * @param fs
   * @param credentials
   * @param p
   * @param conf
   * @throws IOException
   */
  static void obtainTokensForNamenodesInternal(FileSystem fs, 
      Credentials credentials, Configuration conf) throws IOException {"
MAPREDUCE-6293,Set job classloader on uber-job's LocalContainerLauncher event thread,"An uberized job fails if the job classloader is enabled and the job needs to use the thread context classloader to load a class. Some example error in the log:

{quote}
2015-03-23 23:28:34,675 INFO [main\] org.apache.hadoop.mapreduce.v2.util.MRApps: Creating job classloader
...
2015-03-23 23:28:42,096 ERROR [uber-SubtaskRunner\] cascading.provider.ServiceLoader: unable to find service class: cascading.tuple.hadoop.collect.HadoopTupleMapFactory, with exception: java.lang.ClassNotFoundException: cascading.tuple.hadoop.collect.HadoopTupleMapFactory
{quote}
"
MAPREDUCE-6292,Use org.junit package instead of junit.framework in TestCombineFileInputFormat,o.a.h.mapreduce.lib.inputTestCombineFileInputFormat now uses both packages. We should replace junit.framework package with org.junit package.
MAPREDUCE-6291,Correct mapred queue usage command,"
 *Currently it is like following..* 

Usage: JobQueueClient <command> <args>

 *It should be* 

Usage: queue <command> <args>

 *For more Details check following* 
{noformat}
hdfs@host1:/hadoop/bin> ./mapred queue
Usage: JobQueueClient <command> <args>
	[-list]
	[-info <job-queue-name> [-showJobs]]
	[-showacls] 
{noformat}"
MAPREDUCE-6290,job.setJar not working for jars on hdfs,"when I used job.setJar(""hdfs://dev01:9000/root/mrjob-0.0.1.jar"") to start MR job on remote hadoop cluster, I got errors saying class not found.
However I noticed comments said ""If the job jar is already in fs, we don't need to copy it from local fs"", so I think by design setJar method should work for jars that exist on HDFS.
"
MAPREDUCE-6289,libjars are assumed to be in the DistributedCache but are never added in pseudo distributed mode,"Used version:
{noformat}$ hadoop version
Hadoop 2.6.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r e3496499ecb8d220fba99dc5ed4c99c8f9e33bb1
Compiled by jenkins on 2014-11-13T21:10Z
Compiled with protoc 2.5.0
From source with checksum 18e43357c8f927c0695f1e9522859d6a
This command was run using /usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/hadoop-common-2.6.0.jar{noformat}

Having a pseudo-distributed setup with the worker node on the same machine as the master, no libjars are ever copied on the DFS but the following code assumes so resulting in {{FileNotFoundException}} s:

The issue starts in {{org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path, short)}} in this block: 
{code:java}    if (libjars != null) {
      FileSystem.mkdirs(jtFs, libjarsDir, mapredSysPerms);
      String[] libjarsArr = libjars.split("","");
      for (String tmpjars: libjarsArr) {
        Path tmp = new Path(tmpjars);
        Path newPath = copyRemoteFiles(libjarsDir, tmp, conf, replication);
        DistributedCache.addFileToClassPath(
            new Path(newPath.toUri().getPath()), conf);
      }
    }{code}
# For ""local files"" - as all libjars are in a pseudo-distributed setup {{copyRemoteFiles}} returns the path itself - including the {{file://}} URI but not coping the file to the DFS itself.
# This URI is stripped while creating the new {{Path}} object.
# Within the {{DistributedCache}}, the ""current filesystem"" is used to restore the URI in {{org.apache.hadoop.mapreduce.filecache.DistributedCache.addFileToClassPath(Path, Configuration, FileSystem)}}
#* which is now the DFS itself.

This causes i.e. {{file:/usr/local/Cellar/hbase/1.0.0/libexec/lib/hbase-client-1.0.0.jar}} to be added to the Distributed Cache as {{hdfs://localhost:8020/usr/local/Cellar/hbase/1.0.0/libexec/lib/hbase-client-1.0.0.jar}} - whereas it was never uploaded by {{copyRemoteFiles}} .

During verification afterwards this causes a {{FileNotFoundException}} :
{noformat}15/03/23 21:08:42 INFO mapreduce.JobSubmitter: Cleaning up the staging area file:/Users/sme/development/hadoop-data/mapred/staging/sme1224959894/.staging/job_local1224959894_0001
java.io.FileNotFoundException: File does not exist: hdfs://localhost:8020/usr/local/Cellar/hadoop/2.6.0/libexec/share/hadoop/common/lib/guava-11.0.2.jar
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1122)
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1114)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1114)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:288)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:224)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:99)
	at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:57)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:269)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:390)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:483)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1296)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1293)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1293)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1314)
	at com.sungard.advtech.bigtable.hbase.FixMessageMapOnlyImporter.main(FixMessageMapOnlyImporter.java:232)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
	at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:152)
	at com.sungard.advtech.bigtable.hbase.HadoopDriver.main(HadoopDriver.java:19)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
{noformat}"
MAPREDUCE-6288,mapred job -status fails with AccessControlException ,"After MAPREDUCE-5875, we're seeing this Exception when trying to do {{mapred job -status job_1427080398288_0001}}
{noformat}
Exception in thread ""main"" org.apache.hadoop.security.AccessControlException: Permission denied: user=jenkins, access=EXECUTE, inode=""/user/history/done"":mapred:hadoop:drwxrwx---
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkTraverse(DefaultAuthorizationProvider.java:180)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:137)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6553)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6535)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:6460)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1919)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1870)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1850)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1822)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:545)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2038)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1213)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1201)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1191)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:299)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:265)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:257)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1490)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:302)
	at org.apache.hadoop.hdfs.DistributedFileSystem$3.doCall(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:298)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:766)
	at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:190)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:264)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1239)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=jenkins, access=EXECUTE, inode=""/user/history2/done"":mapred:hadoop:drwxrwx---
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkTraverse(DefaultAuthorizationProvider.java:180)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:137)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6553)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6535)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPathAccess(FSNamesystem.java:6460)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1919)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1870)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1850)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1822)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:545)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:87)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:363)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1060)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2044)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2040)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2038)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy17.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:254)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy18.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1211)
	... 16 more
{noformat}
"
MAPREDUCE-6287,Deprecated methods in org.apache.hadoop.examples.Sort,org.apache.hadoop.examples.Sort is still using deprecated methods like Path#makeQualified and DistributedCache. It is better to replace them.
MAPREDUCE-6286,"A typo in HistoryViewer makes some code useless, which causes counter limits are not reset correctly.","A typo in HistoryViewer makes some code useless and it causes counter limits are not reset correctly.
The typo is
Limits.reset(conf);
We should use jobConf instead of conf.
With the typo, the following code becomes useless:
{code}
      final Path jobConfPath = new Path(jobFile.getParent(),  jobDetails[0]
          + ""_"" + jobDetails[1] + ""_"" + jobDetails[2] + ""_conf.xml"");
      final Configuration jobConf = new Configuration(conf);
        jobConf.addResource(fs.open(jobConfPath), jobConfPath.toString());
{code}
The code wants to load the configuration from the Job configuration file and reset the Limits based on the new configuration loaded from the Job configuration file. But with the typo, the Limits are reset with the old configuration.
So this typo is apparent."
MAPREDUCE-6285,ClientServiceDelegate should not retry upon AuthenticationException,"ClientServiceDelegate tries really hard to getJobStatus from a job through retries. However, if an AuthorizationException occurs, it will always continue to fail no matter how many retries it makes. AuthorizationException is also thrown when mapred job -status is call on unsupported services like tez jobs. This jira will limit the negative effect on AMs in both scenarios.

Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.authorize.AuthorizationException): Protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB is not known."
MAPREDUCE-6284,Add Task Attempt State API to MapReduce Application Master REST API,"It want to 'task attempt state' on the 'App state' similarly REST API.
GET http://<proxy http address:port>/proxy/<application _id>/ws/v1/mapreduce/jobs/<job_id>/tasks/<task_id>/attempts/<attempt_id>/state
PUT http://<proxy http address:port>/proxy/<application _id>/ws/v1/mapreduce/jobs/<job_id>/tasks/<task_id>/attempts/<attempt_id>/state "
MAPREDUCE-6282,Reuse historyFileAbsolute.getFileSystem in CompletedJob#loadFullHistoryData for code optimization.,Reuse historyFileAbsolute.getFileSystem in CompletedJob#loadFullHistoryData for code optimization.
MAPREDUCE-6281,Fix javadoc in Terasort,"Nothing fancy

{noformat}
-     * @param job the job config
+     * @param conf the job config
{noformat}

probably leftover from the Hadoop 1.0 -> 2.0 transition."
MAPREDUCE-6279,AM should explicity exit JVM after all services have stopped,"Occasionally the MapReduce AM can ""get stuck"" trying to shut down.  MAPREDUCE-6049 and MAPREDUCE-5888 were specific instances that have been fixed, but this can also occur with uber jobs if the task code inadvertently leaves non-daemon threads lingering.

We should explicitly shutdown the JVM after the MapReduce AM has unregistered and all services have been stopped."
MAPREDUCE-6277,Job can post multiple history files if attempt loses connection to the RM,Related to a fixed issue MAPREDUCE-6230 which cause a Job to get into error state. In that situation Job's second or some later attempt could succeed but those later attempts' history file will all be lost. Because the first attempt in error state will copy its history file to intermediate dir while mistakenly think of itself as lastattempt. Jobhistory server will later move the history file of that error attempt from intermediate dir to done dir while ignore the rest of that job attempt's later history files in intermediate dir.  
MAPREDUCE-6276,Error in encrypted shuffle,"Hey Guys,

After enabling wire encryption my UIs are working fine, I'm able to read/write to hdfs securely however encrypted shuffle is not working. I'm getting below error, could you please help me ?

Note - mappers are getting finished successfully however job gets failed during shuffle.

{code}
2015-03-17 17:00:54,322 WARN [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to hdprndnode.dm.com:13562 with 8 map outputs
javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192)
{code}

Please find attached full log for more details.

Thanks,
Kuldeep"
MAPREDUCE-6275,Race condition in FileOutputCommitter v2 for user-specified task output subdirs,
MAPREDUCE-6273,HistoryFileManager should check whether summaryFile exists to avoid FileNotFoundException causing HistoryFileInfo into MOVE_FAILED state,"HistoryFileManager should check whether summaryFile exists to avoid FileNotFoundException causing HistoryFileInfo into MOVE_FAILED state,
I saw the following error message:
{code}
2015-02-17 19:13:45,198 ERROR org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Error while trying to move a job to done
java.io.FileNotFoundException: File does not exist: /user/history/done_intermediate/agd_laci-sluice/job_1423740288390_1884.summary
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:65)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:55)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1878)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1799)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1771)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:527)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:85)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.GeneratedConstructorAccessor29.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1181)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1169)
	at org.apache.hadoop.hdfs.DFSClient.getLocatedBlocks(DFSClient.java:1159)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchLocatedBlocksAndGetLastBlockLength(DFSInputStream.java:270)
	at org.apache.hadoop.hdfs.DFSInputStream.openInfo(DFSInputStream.java:237)
	at org.apache.hadoop.hdfs.DFSInputStream.<init>(DFSInputStream.java:230)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1457)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:318)
	at org.apache.hadoop.fs.Hdfs.open(Hdfs.java:59)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:621)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:789)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:785)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:785)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getJobSummary(HistoryFileManager.java:953)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.access$400(HistoryFileManager.java:82)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.moveToDone(HistoryFileManager.java:370)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo.access$1400(HistoryFileManager.java:295)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$1.run(HistoryFileManager.java:843)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /user/history/done_intermediate/agd_laci-sluice/job_1423740288390_1884.summary
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:65)
	at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:55)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1878)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1799)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1771)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:527)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.getBlockLocations(AuthorizationProviderProxyClientProtocol.java:85)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:356)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1642)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1411)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy13.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getBlockLocations(ClientNamenodeProtocolTranslatorPB.java:246)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getBlockLocations(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.callGetBlockLocations(DFSClient.java:1179)
	... 21 more
{code}
We should avoid this error by checking whether summaryFile exists before call getJobSummary, otherwise we will see this error happen every time scanIntermediateDirectory is called."
MAPREDUCE-6270,Doc typo,"Disregard, wrong project."
MAPREDUCE-6268,Fix typo in Task Attempt API's URL,Task Attempt API's URL is typo. attempt is wrong
MAPREDUCE-6267,Refactor JobSubmitter#copyAndConfigureFiles into it's own class,Refactor the uploading logic in JobSubmitter#copyAndConfigureFiles into it's own class. This makes the JobSubmitter class more readable and isolates the logic that is actually uploading the job resources to HDFS.
MAPREDUCE-6266,Job#getTrackingURL should consistently return a proper URL,"When a job is running, Job#getTrackingURL returns a proper URL like:

    http://<RM_IP>:8088/proxy/application_1424910897258_0004/

Once a job is finished and the job has moved to the JHS, then Job#getTrackingURL returns a URL without the protocol like:

    <JHS_IP>:19888/jobhistory/job/job_1424910897258_0004
"
MAPREDUCE-6265,Make ContainerLauncherImpl.INITIAL_POOL_SIZE configurable to better control to launch/kill containers,"make INITIAL_POOL_SIZE in ContainerLauncherImpl configurable to better control the thread pool size to launch/kill containers
Currently INITIAL_POOL_SIZE in ContainerLauncherImpl is hard-coded at 
{code}
  protected static final int INITIAL_POOL_SIZE = 10;
{code}
We should make it configurable because the thread pool size will be decided by INITIAL_POOL_SIZE, limitOnPoolSize and number of node used by the AM.
Since we already made limitOnPoolSize configurable, it make senses to also make INITIAL_POOL_SIZE configurable to better manage the thread pool size.
We saw some issue due to the small thread pool size when some node is down. The recovery from a shutdown node take very long time due to all the ContainerLauncher threads are blocked by IPC client connection to the shutdown node."
MAPREDUCE-6264,Remove httpclient dependency from hadoop-mapreduce-client,Sub-task of HADOOP-10105. Remove httpclient dependency from TestAMWebApp.java and JobEndNotifier.java.
MAPREDUCE-6263,Configurable timeout between YARNRunner terminate the application and forcefully kill.,"YARNRunner connects to the AM to send the kill job command then waits a hardcoded 10 seconds for the job to enter a terminal state.  If the job fails to enter a terminal state in that time then YARNRunner will tell YARN to kill the application forcefully.  The latter type of kill usually results in no job history, since the AM process is killed forcefully.

Ten seconds can be too short for large jobs in a large cluster, as it takes time to connect to all the nodemanagers, process the state machine events, and copy a large jhist file.  The timeout should be more lenient or configurable."
MAPREDUCE-6261,NullPointerException if MapOutputBuffer.flush invoked twice,"MapOutputBuffer.flush will throw an NPE if it is invoked twice, since it blindly assumes kvbuffer is not null yet sets kvbuffer to null towards the end of the method."
MAPREDUCE-6260,Convert site documentation to markdown,
MAPREDUCE-6259,IllegalArgumentException due to missing job submit time,"-1 job submit time cause IllegalArgumentException when parse the Job history file name and JOB_INIT_FAILED cause -1 job submit time in JobIndexInfo.
We found the following job history file name which cause IllegalArgumentException when parse the job status in the job history file name.
{code}
job_1418398645407_115853--1-worun-kafka%2Dto%2Dhdfs%5Btwo%5D%5B15+topic%28s%29%5D-1423572836007-0-0-FAILED-root.journaling-1423572836007.jhist
{code}
The stack trace for the IllegalArgumentException is
{code}
2015-02-10 04:54:01,863 WARN org.apache.hadoop.mapreduce.v2.hs.PartialJob: Exception while parsing job state. Defaulting to KILLED
java.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.v2.api.records.JobState.0
	at java.lang.Enum.valueOf(Enum.java:236)
	at org.apache.hadoop.mapreduce.v2.api.records.JobState.valueOf(JobState.java:21)
	at org.apache.hadoop.mapreduce.v2.hs.PartialJob.getState(PartialJob.java:82)
	at org.apache.hadoop.mapreduce.v2.hs.PartialJob.<init>(PartialJob.java:59)
	at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getAllPartialJobs(CachedHistoryStorage.java:159)
	at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getPartialJobs(CachedHistoryStorage.java:173)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistory.getPartialJobs(JobHistory.java:284)
	at org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobs(HsWebServices.java:212)
	at sun.reflect.GeneratedMethodAccessor63.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)
	at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)
	at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
	at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1223)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:767)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{code}


when IOException happened in JobImpl#setup, the Job submit time in JobHistoryEventHandler#MetaInfo#JobIndexInfo will not be changed and the Job submit time will be its [initial value -1|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/jobhistory/JobHistoryEventHandler.java#L1185].
{code}
      this.jobIndexInfo =
          new JobIndexInfo(-1, -1, user, jobName, jobId, -1, -1, null,
                           queueName);
{code}

The following is the sequences to get -1 job submit time:
1. 
a job is created at MRAppMaster#serviceStart and  the new job is at state JobStateInternal.NEW after created
{code}
    job = createJob(getConfig(), forcedState, shutDownMessage);
{code}

2.
JobEventType.JOB_INIT is sent to JobImpl from MRAppMaster#serviceStart
{code}
      JobEvent initJobEvent = new JobEvent(job.getID(), JobEventType.JOB_INIT);
      // Send init to the job (this does NOT trigger job execution)
      // This is a synchronous call, not an event through dispatcher. We want
      // job-init to be done completely here.
      jobEventDispatcher.handle(initJobEvent);
{code}

3.
after JobImpl received JobEventType.JOB_INIT, it call InitTransition#transition
{code}
          .addTransition
              (JobStateInternal.NEW,
              EnumSet.of(JobStateInternal.INITED, JobStateInternal.NEW),
              JobEventType.JOB_INIT,
              new InitTransition())
{code}

4.
then the exception happen from setup(job) in InitTransition#transition before JobSubmittedEvent is handled.
JobSubmittedEvent will update the job submit time. Due to the exception, the submit time is still the initial value -1.
This is the code InitTransition#transition
{code}
public JobStateInternal transition(JobImpl job, JobEvent event) {
      job.metrics.submittedJob(job);
      job.metrics.preparingJob(job);
      if (job.newApiCommitter) {
        job.jobContext = new JobContextImpl(job.conf, job.oldJobId);
      } else {
        job.jobContext = new org.apache.hadoop.mapred.JobContextImpl(job.conf, job.oldJobId);
      }
      try {
        setup(job);
        job.fs = job.getFileSystem(job.conf);
        //log to job history
        JobSubmittedEvent jse = new JobSubmittedEvent(job.oldJobId,
              job.conf.get(MRJobConfig.JOB_NAME, ""test""), 
            job.conf.get(MRJobConfig.USER_NAME, ""mapred""),
            job.appSubmitTime,
            job.remoteJobConfFile.toString(),
            job.jobACLs, job.queueName,
            job.conf.get(MRJobConfig.WORKFLOW_ID, """"),
            job.conf.get(MRJobConfig.WORKFLOW_NAME, """"),
            job.conf.get(MRJobConfig.WORKFLOW_NODE_NAME, """"),
            getWorkflowAdjacencies(job.conf),
            job.conf.get(MRJobConfig.WORKFLOW_TAGS, """"));
        job.eventHandler.handle(new JobHistoryEvent(job.jobId, jse));
        //TODO JH Verify jobACLs, UserName via UGI?

        TaskSplitMetaInfo[] taskSplitMetaInfo = createSplits(job, job.jobId);
        job.numMapTasks = taskSplitMetaInfo.length;
        job.numReduceTasks = job.conf.getInt(MRJobConfig.NUM_REDUCES, 0);

        if (job.numMapTasks == 0 && job.numReduceTasks == 0) {
          job.addDiagnostic(""No of maps and reduces are 0 "" + job.jobId);
        } else if (job.numMapTasks == 0) {
          job.reduceWeight = 0.9f;
        } else if (job.numReduceTasks == 0) {
          job.mapWeight = 0.9f;
        } else {
          job.mapWeight = job.reduceWeight = 0.45f;
        }

        checkTaskLimits();

        long inputLength = 0;
        for (int i = 0; i < job.numMapTasks; ++i) {
          inputLength += taskSplitMetaInfo[i].getInputDataLength();
        }

        job.makeUberDecision(inputLength);
        
        job.taskAttemptCompletionEvents =
            new ArrayList<TaskAttemptCompletionEvent>(
                job.numMapTasks + job.numReduceTasks + 10);
        job.mapAttemptCompletionEvents =
            new ArrayList<TaskCompletionEvent>(job.numMapTasks + 10);
        job.taskCompletionIdxToMapCompletionIdx = new ArrayList<Integer>(
            job.numMapTasks + job.numReduceTasks + 10);

        job.allowedMapFailuresPercent =
            job.conf.getInt(MRJobConfig.MAP_FAILURES_MAX_PERCENT, 0);
        job.allowedReduceFailuresPercent =
            job.conf.getInt(MRJobConfig.REDUCE_FAILURES_MAXPERCENT, 0);

        // create the Tasks but don't start them yet
        createMapTasks(job, inputLength, taskSplitMetaInfo);
        createReduceTasks(job);

        job.metrics.endPreparingJob(job);
        return JobStateInternal.INITED;
      } catch (Exception e) {
        LOG.warn(""Job init failed"", e);
        job.metrics.endPreparingJob(job);
        job.addDiagnostic(""Job init failed : ""
            + StringUtils.stringifyException(e));
        // Leave job in the NEW state. The MR AM will detect that the state is
        // not INITED and send a JOB_INIT_FAILED event.
        return JobStateInternal.NEW;
      }
    }
{code}

This is the code JobImpl#setup
{code}
    protected void setup(JobImpl job) throws IOException {

      String oldJobIDString = job.oldJobId.toString();
      String user = 
        UserGroupInformation.getCurrentUser().getShortUserName();
      Path path = MRApps.getStagingAreaDir(job.conf, user);
      if(LOG.isDebugEnabled()) {
        LOG.debug(""startJobs: parent="" + path + "" child="" + oldJobIDString);
      }

      job.remoteJobSubmitDir =
          FileSystem.get(job.conf).makeQualified(
              new Path(path, oldJobIDString));
      job.remoteJobConfFile =
          new Path(job.remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE);

      // Prepare the TaskAttemptListener server for authentication of Containers
      // TaskAttemptListener gets the information via jobTokenSecretManager.
      JobTokenIdentifier identifier =
          new JobTokenIdentifier(new Text(oldJobIDString));
      job.jobToken =
          new Token<JobTokenIdentifier>(identifier, job.jobTokenSecretManager);
      job.jobToken.setService(identifier.getJobId());
      // Add it to the jobTokenSecretManager so that TaskAttemptListener server
      // can authenticate containers(tasks)
      job.jobTokenSecretManager.addTokenForJob(oldJobIDString, job.jobToken);
      LOG.info(""Adding job token for "" + oldJobIDString
          + "" to jobTokenSecretManager"");

      // If the job client did not setup the shuffle secret then reuse
      // the job token secret for the shuffle.
      if (TokenCache.getShuffleSecretKey(job.jobCredentials) == null) {
        LOG.warn(""Shuffle secret key missing from job credentials.""
            + "" Using job token secret as shuffle secret."");
        TokenCache.setShuffleSecretKey(job.jobToken.getPassword(),
            job.jobCredentials);
      }
    }
{code}

5.
Due to the IOException from  JobImpl#setup, the new job is still at state JobStateInternal.NEW
{code}
      } catch (Exception e) {
        LOG.warn(""Job init failed"", e);
        job.metrics.endPreparingJob(job);
        job.addDiagnostic(""Job init failed : ""
            + StringUtils.stringifyException(e));
        // Leave job in the NEW state. The MR AM will detect that the state is
        // not INITED and send a JOB_INIT_FAILED event.
        return JobStateInternal.NEW;
      }
{code}
At the following code of MRAppMaster#serviceStart, The MR AM detect the state is not INITED and send a JOB_INIT_FAILED event.
{code}
      // If job is still not initialized, an error happened during
      // initialization. Must complete starting all of the services so failure
      // events can be processed.
      initFailed = (((JobImpl)job).getInternalState() != JobStateInternal.INITED);
    if (initFailed) {
      JobEvent initFailedEvent = new JobEvent(job.getID(), JobEventType.JOB_INIT_FAILED);
      jobEventDispatcher.handle(initFailedEvent);
    } else {
      // All components have started, start the job.
      startJobs();
    }
{code}

6.
After JobImpl receives the JOB_INIT_FAILED, it will call InitFailedTransition#transition and enter state JobStateInternal.FAIL_ABORT
{code}
          .addTransition(JobStateInternal.NEW, JobStateInternal.FAIL_ABORT,
              JobEventType.JOB_INIT_FAILED,
              new InitFailedTransition())
{code}

7.
JobImpl will send CommitterJobAbortEvent in  InitFailedTransition#transition 
{code}
    public void transition(JobImpl job, JobEvent event) {
        job.eventHandler.handle(new CommitterJobAbortEvent(job.jobId,
                job.jobContext,
                org.apache.hadoop.mapreduce.JobStatus.State.FAILED));
    }
{code}

8.
CommitterJobAbortEvent will be handled by CommitterEventHandler#handleJobAbort which will send JobAbortCompletedEvent(JobEventType.JOB_ABORT_COMPLETED)
{code}
    protected void handleJobAbort(CommitterJobAbortEvent event) {
      cancelJobCommit();
      try {
        committer.abortJob(event.getJobContext(), event.getFinalState());
      } catch (Exception e) {
        LOG.warn(""Could not abort job"", e);
      }
      context.getEventHandler().handle(new JobAbortCompletedEvent(
          event.getJobID(), event.getFinalState()));
    }
{code}

9.
After JobImpl receives the JOB_ABORT_COMPLETED, it will call JobAbortCompletedTransition#transition and enter state JobStateInternal.FAILED
{code}
          .addTransition(JobStateInternal.FAIL_ABORT, JobStateInternal.FAILED,
              JobEventType.JOB_ABORT_COMPLETED,
              new JobAbortCompletedTransition())
{code}

10.
JobAbortCompletedTransition#transition will call JobImpl#unsuccessfulFinish which will send JobUnsuccessfulCompletionEvent with finish time.
{code}
    public void transition(JobImpl job, JobEvent event) {
      JobStateInternal finalState = JobStateInternal.valueOf(
          ((JobAbortCompletedEvent) event).getFinalState().name());
      job.unsuccessfulFinish(finalState);
    }
  private void unsuccessfulFinish(JobStateInternal finalState) {
      if (finishTime == 0) setFinishTime();
      cleanupProgress = 1.0f;
      JobUnsuccessfulCompletionEvent unsuccessfulJobEvent =
          new JobUnsuccessfulCompletionEvent(oldJobId,
              finishTime,
              succeededMapTaskCount,
              succeededReduceTaskCount,
              finalState.toString(),
              diagnostics);
      eventHandler.handle(new JobHistoryEvent(jobId,
          unsuccessfulJobEvent));
      finished(finalState);
  }
{code}

11.
JobUnsuccessfulCompletionEvent will be handled by JobHistoryEventHandler#handleEvent with type EventType.JOB_FAILED
Based on the following code, you can see the JobIndexInfo#finishTime is set correctly but JobIndexInfo#submitTime and  JobIndexInfo#jobStartTime are still -1.
{code}
      if (event.getHistoryEvent().getEventType() == EventType.JOB_FAILED
          || event.getHistoryEvent().getEventType() == EventType.JOB_KILLED) {
        try {
          JobUnsuccessfulCompletionEvent jucEvent = 
              (JobUnsuccessfulCompletionEvent) event
              .getHistoryEvent();
          mi.getJobIndexInfo().setFinishTime(jucEvent.getFinishTime());
          mi.getJobIndexInfo().setNumMaps(jucEvent.getFinishedMaps());
          mi.getJobIndexInfo().setNumReduces(jucEvent.getFinishedReduces());
          mi.getJobIndexInfo().setJobStatus(jucEvent.getStatus());
          closeEventWriter(event.getJobID());
          processDoneFiles(event.getJobID());
        } catch (IOException e) {
          throw new YarnRuntimeException(e);
        }
      }
{code}

The error job history file name in our log is ""job_1418398645407_115853--1-worun-kafka%2Dto%2Dhdfs%5Btwo%5D%5B15+topic%28s%29%5D-1423572836007-0-0-FAILED-root.journaling-1423572836007.jhist""
Based on the filename, you can see submitTime is -1, finishTime is 1423572836007 and jobStartTime is 1423572836007.
The jobStartTime is not -1, and  jobStartTime is the same as  finishTime.
It is because jobStartTime is handled specially in FileNameIndexUtils#getDoneFileName:
{code}
    //JobStartTime
    if (indexInfo.getJobStartTime() >= 0) {
      sb.append(indexInfo.getJobStartTime());
    } else {
      sb.append(indexInfo.getFinishTime());
    }
{code}

"
MAPREDUCE-6257,Document encrypted spills,Encrypted spills appear to be completely undocumented.
MAPREDUCE-6256,Removed unused private methods in o.a.h.mapreduce.Job.java,"These below methods are not used any where in the code and these can be removed.
{code:xml}
  private void setStatus(JobStatus status)
  private boolean shouldDownloadProfile()
{code}"
MAPREDUCE-6255,Fix JobCounter's format to use grouping separator,"MRv2 Job Counter has not been comma format, this is hard to see."
MAPREDUCE-6253,Update use of Iterator to Iterable,"Found these using the IntelliJ Findbugs-IDEA plugin, which uses findbugs3."
MAPREDUCE-6252,JobHistoryServer should not fail when encountering a missing directory,"The JobHistoryServer maintains a cache of job serial number parts to dfs paths which it uses when seeking a job it no longer has in its memory cache, multiple directories for a given serial number differentiated by time stamp.  At present the jobhistory server will fail any time it attempts to find a job in a directory which no longer exists based on that cache - even though the job may well exist in a different directory for the serial number.  Typically this is not an issue, but the history cleanup process removes the directory from dfs before removing it from the cache which leaves a window of time where a directory may be missing from dfs which is present in the cache, resulting in failure.  For some dfs's it appears that the top level directory may become unavailable some time before the full deletion of the tree completes which extends what might otherwise be a brief period of failure to a more extended period.  Further, this also places the service at the mercy of outside processes which might remove those directories.  The proposal is simply to make the server resistant to this state such that encountering this missing directory is not fatal and the process will continue on to seek it elsewhere."
MAPREDUCE-6251,JobClient needs additional retries at a higher level to address not-immediately-consistent dfs corner cases,"The JobClient is used to get job status information for running and completed jobs.  Final state and history for a job is communicated from the application master to the job history server via a distributed file system - where the history is uploaded by the application master to the dfs and then scanned/loaded by the jobhistory server.  While HDFS has strong consistency guarantees not all Hadoop DFS's do.  When used in conjunction with a distributed file system which does not have this guarantee there will be cases where the history server may not see an uploaded file, resulting in the dreaded ""no such job"" and a null value for the RunningJob in the client."
MAPREDUCE-6250,deprecate sbin/mr-jobhistory-daemon.sh,Functionality has been moved to bin/mapred.
MAPREDUCE-6249,Streaming task will not untar tgz uploaded with -archives,"when writing hadoop streaming task. i used -archives to upload a tgz from local machine to hdfs task working directory, but it has not been untarred as the document says. I've searched a lot without any luck.

Here is the hadoop streaming task starting command with hadoop-2.5.2

hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.5.2.jar \
    -files mapper.sh
    -archives /home/hadoop/tmp/test.tgz#test \
    -D mapreduce.job.maps=1 \
    -D mapreduce.job.reduces=1 \
    -input ""/test/test.txt"" \
    -output ""/res/"" \
    -mapper ""sh mapper.sh"" \
    -reducer ""cat""

and ""mapper.sh""

cat > /dev/null
ls -l test
exit 0

in ""test.tgz"" there is two files ""test.1.txt"" and ""test.2.txt""

echo ""abcd"" > test.1.txt
echo ""efgh"" > test.2.txt
tar zcvf test.tgz test.1.txt test.2.txt

the output from above task

lrwxrwxrwx 1 hadoop hadoop     71 Feb  8 23:25 test -> /tmp/hadoop-hadoop/nm-local-dir/usercache/hadoop/filecache/116/test.tgz

but what desired may be like this

-rw-r--r-- 1 hadoop hadoop 5 Feb  8 23:25 test.1.txt
-rw-r--r-- 1 hadoop hadoop 5 Feb  8 23:25 test.2.txt

so, why test.tgz has not been untarred automatically as document says, and or there is actually another way makes the ""tgz"" being untarred"
MAPREDUCE-6248,Allow users to get the MR job information for distcp,Currently the DistCp is acting as a tool and the corresponding MapReduce Job  is created and used inside of its {{execute}} method. It is thus difficult for external services to query its progress and counters. It may be helpful to persist the job id into a file inside its staging directory.
MAPREDUCE-6246,DBOutputFormat.java appending extra semicolon to query which is incompatible with DB2,"DBoutputformat is used for writing output of mapreduce jobs to the database and when used with db2 jdbc drivers it fails with following error

com.ibm.db2.jcc.am.SqlSyntaxErrorException: DB2 SQL Error: SQLCODE=-104, SQLSTATE=42601, SQLERRMC=;;,COUNT) VALUES (?,?);END-OF-STATEMENT, DRIVER=4.16.53 at com.ibm.db2.jcc.am.fd.a(fd.java:739) at com.ibm.db2.jcc.am.fd.a(fd.java:60) at com.ibm.db2.jcc.am.fd.a(fd.java:127)


In DBOutputFormat class there is constructQuery method that generates ""INSERT INTO"" statement with semicolon("";"") at the end.

Semicolon is ANSI SQL-92 standard character for a statement terminator but this feature is disabled(OFF) as a default settings in IBM DB2.

Although by using -t we can turn it ON for db2. (http://www-01.ibm.com/support/knowledgecenter/SSEPGG_9.7.0/com.ibm.db2.luw.admin.cmd.doc/doc/r0010410.html?cp=SSEPGG_9.7.0%2F3-6-2-0-2). But there are some products that already built on top of this default setting (OFF) so by turning ON this feature make them error prone."
MAPREDUCE-6243,Fix findbugs warnings in hadoop-rumen,There are 7 findbugs warnings in hadoop-rumen modules.
MAPREDUCE-6242,Progress report log is incredibly excessive in application master,"We saw incredibly excessive logs in application master for a long running one with many task attempts. The log write rate is around 1MB/sec in some cases. 

Most of the log entries were from the progress report such as the following ones.

    2015-02-03 17:46:14,321 INFO [IPC Server handler 56 on 37661] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1422985365246_0001_m_000000_0 is : 0.15605757
    2015-02-03 17:46:17,581 INFO [IPC Server handler 2 on 37661] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1422985365246_0001_m_000000_0 is : 0.4108217
    2015-02-03 17:46:20,426 INFO [IPC Server handler 0 on 37661] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1422985365246_0001_m_000002_0 is : 0.06634143
    2015-02-03 17:46:20,807 INFO [IPC Server handler 4 on 37661] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1422985365246_0001_m_000000_0 is : 0.55556506
    2015-02-03 17:46:21,013 INFO [IPC Server handler 6 on 37661] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1422985365246_0001_m_000001_0 is : 0.21723115

Looks like the report interval is controlled by a hard-coded variable PROGRESS_INTERVAL as 3 seconds in class org.apache.hadoop.mapred.Task. We should allow users to set the appropriate progress interval for their applications.
"
MAPREDUCE-6240,Hadoop client displays confusing error message,"Hadoop client often throws exception  with ""java.io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses"".

This is a misleading and generic message for any cluster initialization problem. It takes a lot of debugging hours to identify the root cause. The correct error message could resolve this problem quickly.

In one such instance, Oozie log showed the following exception  while the root cause was CNF  that Hadoop client didn't return in the exception.

{noformat}
 JA009: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
        at org.apache.oozie.action.ActionExecutor.convertExceptionHelper(ActionExecutor.java:412)
        at org.apache.oozie.action.ActionExecutor.convertException(ActionExecutor.java:392)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:979)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.start(JavaActionExecutor.java:1134)
        at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:228)
        at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:63)
        at org.apache.oozie.command.XCommand.call(XCommand.java:281)
        at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:323)
        at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:252)
        at org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:174)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)
Caused by: java.io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
        at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:120)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:82)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:75)
        at org.apache.hadoop.mapred.JobClient.init(JobClient.java:470)
        at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:449)
        at org.apache.oozie.service.HadoopAccessorService$1.run(HadoopAccessorService.java:372)
        at org.apache.oozie.service.HadoopAccessorService$1.run(HadoopAccessorService.java:370)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.oozie.service.HadoopAccessorService.createJobClient(HadoopAccessorService.java:379)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.createJobClient(JavaActionExecutor.java:1185)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:927)
 ... 10 more
{noformat}"
MAPREDUCE-6239,Consolidate TestJobConf classes in hadoop-mapreduce-client-jobclient and hadoop-mapreduce-client-core,
MAPREDUCE-6238,MR2 can't run local jobs with -libjars command options which is a regression from MR1,"MR2 can't run local jobs with -libjars command options which is a regression from MR1. 
When run MR2 job with -jt local and -libjars, the job fails with java.io.FileNotFoundException: File does not exist: hdfs://XXXXXXXXXXXXXXX.jar.
But the same command is working in MR1.
I find the problem is
1.
because when MR2 run local job using  LocalJobRunner
from JobSubmitter, the JobSubmitter#jtFs is local filesystem,
So copyRemoteFiles will return from [the middle of the function|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmitter.java#L138]
because source and destination file system are same.
{code}
    if (compareFs(remoteFs, jtFs)) {
      return originalPath;
    }
{code}
The following code at [JobSubmitter.java|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmitter.java#L219]
try to add the destination file to DistributedCache which introduce a bug for local job.
{code}
        Path newPath = copyRemoteFiles(libjarsDir, tmp, conf, replication);
        DistributedCache.addFileToClassPath(
            new Path(newPath.toUri().getPath()), conf);
{code}
Because new Path(newPath.toUri().getPath()) will lose the filesystem information from newPath, the file added to DistributedCache will use the default Uri filesystem hdfs based on the following code. This causes the 
 FileNotFoundException when we access the file later at 
 [determineTimestampsAndCacheVisibilities|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/JobSubmitter.java#L270]
{code}
  public static void addFileToClassPath(Path file, Configuration conf)
    throws IOException {
	  addFileToClassPath(file, conf, file.getFileSystem(conf));
  }
  public static void addFileToClassPath
           (Path file, Configuration conf, FileSystem fs)
        throws IOException {
    String classpath = conf.get(MRJobConfig.CLASSPATH_FILES);
    conf.set(MRJobConfig.CLASSPATH_FILES, classpath == null ? file.toString()
             : classpath + "","" + file.toString());
    URI uri = fs.makeQualified(file).toUri();
    addCacheFile(uri, conf);
  }
{code}

Compare to the following [MR1 code|https://github.com/apache/hadoop/blob/branch-1/src/mapred/org/apache/hadoop/mapred/JobClient.java#L811]:
{code}
        Path newPath = copyRemoteFiles(fs, libjarsDir, tmp, job, replication);
        DistributedCache.addFileToClassPath(
          new Path(newPath.toUri().getPath()), job, fs);
{code}
You will see why MR1 doesn't have this issue.
because it passes the local filesystem into  DistributedCache#addFileToClassPath instead of using the default Uri filesystem hdfs.
2.
Another incompatible change in MR2 is in [LocalDistributedCacheManager#setup|https://github.com/apache/hadoop/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java#L113]
{code}
    // Find which resources are to be put on the local classpath
    Map<String, Path> classpaths = new HashMap<String, Path>();
    Path[] archiveClassPaths = DistributedCache.getArchiveClassPaths(conf);
    if (archiveClassPaths != null) {
      for (Path p : archiveClassPaths) {
        FileSystem remoteFS = p.getFileSystem(conf);
        p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
            remoteFS.getWorkingDirectory()));
        classpaths.put(p.toUri().getPath().toString(), p);
      }
    }
    Path[] fileClassPaths = DistributedCache.getFileClassPaths(conf);
    if (fileClassPaths != null) {
      for (Path p : fileClassPaths) {
        FileSystem remoteFS = p.getFileSystem(conf);
        p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(),
            remoteFS.getWorkingDirectory()));
        classpaths.put(p.toUri().getPath().toString(), p);
      }
    }
{code}
Similar code from MR1 is at [TaskDistributedCacheManager#makeCacheFiles|https://github.com/apache/hadoop/blob/branch-1/src/mapred/org/apache/hadoop/filecache/TaskDistributedCacheManager.java#L119]
{code}
        Map<String, Path> classPaths = new HashMap<String, Path>();
        if (paths != null) {
          for (Path p : paths) {
            classPaths.put(p.toUri().getPath().toString(), p);
            }
        }
{code}
I think we don't need call remoteFS.resolvePath to get the class path and
We can use the  class path from DistributedCache.getFileClassPaths directly.
Also p.toUri().getPath().toString() will remove the filesystem information(scheme) and only keySet of classpaths is used(ValueSet of classpaths is not used).
It is better to do the same in MR2 to maintain backward compatible with MR1.
"
MAPREDUCE-6237,Multiple mappers with DBInputFormat don't work because of reusing conections,"DBInputFormat.createDBRecorder is reusing JDBC connections across instances of DBRecordReader. This is not a good idea. We should be creating separate connection. If performance is a concern, then we should be using connection pooling instead.

I looked at DBOutputFormat.getRecordReader. It actually creates a new Connection object for each DBRecordReader. So can we just change DBInputFormat to create new Connection every time? The connection reuse code was added as part of connection leak bug in MAPREDUCE-1443. Any reason for caching the connection?

We observed this issue in a customer setup where they were reading data from MySQL using Pig. As per customer, the query is returning two records which causes Pig to create two instances of DBRecordReader. These two instances are sharing the database connection instance. The first DBRecordReader runs to extract the first record from MySQL just fine, but then closes the shared connection instance. When the second DBRecordReader runs, it tries to execute a query to retrieve the second record on the closed shared connection instance, which fail. If we set
mapred.map.tasks to 1, the query will be successful."
MAPREDUCE-6236,Fix findbugs warnings in hadoop-mapreduce-client-core,"{code}
Dm	Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): java.io.ByteArrayOutputStream.toString()
Dm	Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): new java.io.PrintStream(OutputStream)
Bx	Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.TaskLogAppender.setOptionsFromSystemProperties()
Bx	org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[], List) invokes inefficient new Integer(String) constructor; use Integer.valueOf(String) instead
RCN	Redundant nullcheck of info, which is known to be non-null in org.apache.hadoop.mapred.IndexCache.removeMap(String)
RCN	Redundant nullcheck of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory(), which is known to be non-null in org.apache.hadoop.mapreduce.JobSubmitter.addLog4jToDistributedCache(Job, Path)
RCN	Redundant nullcheck of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory(), which is known to be non-null in org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path)
RCN	Redundant nullcheck of value, which is known to be non-null in org.apache.hadoop.mapreduce.util.ResourceBundles.getValue(String, String, String, Object)
UrF	Unread public/protected field: org.apache.hadoop.mapred.lib.CombineFileRecordReader.rrClass
UrF	Unread public/protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.rrClass
UuF	Unused public or protected field: org.apache.hadoop.mapred.lib.CombineFileRecordReader.fs
UuF	Unused public or protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.fs
{code}
"
MAPREDUCE-6235,Bundle and compress files passed with -libjars prior to uploading and distributing,"To improve performance, we should upload jars flagged by -libjars as a single bundle and expand on arrival instead of uploading the jars one by one.   This would also reduce network overhead of using the -libjars option."
MAPREDUCE-6234,TestHighRamJob fails due to the change in MAPREDUCE-5785,"TestHighRamJob fails by this.
{code}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapred.gridmix.TestHighRamJob
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.162 sec <<< FAILURE! - in org.apache.hadoop.mapred.gridmix.TestHighRamJob
testHighRamFeatureEmulation(org.apache.hadoop.mapred.gridmix.TestHighRamJob)  Time elapsed: 1.102 sec  <<< FAILURE!
java.lang.AssertionError: expected:<1024> but was:<-1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapred.gridmix.TestHighRamJob.testHighRamConfig(TestHighRamJob.java:98)
	at org.apache.hadoop.mapred.gridmix.TestHighRamJob.testHighRamFeatureEmulation(TestHighRamJob.java:117)
{code}"
MAPREDUCE-6233,org.apache.hadoop.mapreduce.TestLargeSort.testLargeSort failed in trunk," https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2039/

{code}
Stack Trace:
java.lang.AssertionError: Large sort failed for 128 expected:<0> but was:<1>
        at org.junit.Assert.fail(Assert.java:88)
        at org.junit.Assert.failNotEquals(Assert.java:743)
        at org.junit.Assert.assertEquals(Assert.java:118)
        at org.junit.Assert.assertEquals(Assert.java:555)
        at org.apache.hadoop.mapreduce.TestLargeSort.testLargeSort(TestLargeSort.java:61)
{code}
"
MAPREDUCE-6231,Grep example job is not working on a fully-distributed cluster,"Grep.java is missing Job.setJarByClass, so grep example job is not working on a fully-distributed cluster.
This issue was originally reported at user ML.
http://mail-archives.apache.org/mod_mbox/hadoop-user/201501.mbox/%3C54C8E6AE.1010507%40sql-ag.de%3E"
MAPREDUCE-6230,MR AM does not survive RM restart if RM activated a new AMRM secret key,"A MapReduce AM will fail to reconnect to an RM that performed restart in the following scenario:

# MapReduce job launched with AMRM token generated from AMRM secret X
# RM rolls new AMRM secret Y and activates the new key
# RM performs a work-preserving restart
# MapReduce job AM now unable to connect to RM with ""Invalid AMRMToken"" exception"
MAPREDUCE-6228,Add truncate operation to SLive,Add truncate into the mix of operations for SLive test.
MAPREDUCE-6227,DFSIO for truncate,Create a benchmark and a test for truncate within the framework of TestDFSIO.
MAPREDUCE-6226,Findbugs warnings in mapreduce-client-core,Found findbugs warnings reported for mapreduce-client-core while fixing MAPREDUCE-6223
MAPREDUCE-6225,Fix new findbug warnings in hadoop-mapreduce-client-core,Recent precommit builds in hadoop-mapreduce-client-core are flagging findbug warnings that appear to be new with the recent findbugs upgrade.  These need to be cleaned up.
MAPREDUCE-6223,TestJobConf#testNegativeValueForTaskVmem failures,"{code}
Tests run: 8, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 3.328 sec <<< FAILURE! - in org.apache.hadoop.conf.TestJobConf
testNegativeValueForTaskVmem(org.apache.hadoop.conf.TestJobConf)  Time elapsed: 0.089 sec  <<< FAILURE!
java.lang.AssertionError: expected:<1024> but was:<-1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.conf.TestJobConf.testNegativeValueForTaskVmem(TestJobConf.java:111)
{code}"
MAPREDUCE-6222,Add server-side pagination to JobHistoryServer tasks page,"I'm encountering an issue with the Mapreduce HistoryServer processing the history files for large jobs.  This has come up several times with for jobs with around 60000 total tasks.  When the HistoryServer loads the .jhist file from HDFS for a job of that size (which is usually around 500 Mb), the HistoryServer's CPU usage spiked and the UI became unresponsive.  After about 10 minutes I restarted the HistoryServer and it was behaving normally again.

The cluster is running CDH 5.3 (2.5.0-cdh5.3.0).  I've attached the output of jstack from a time this was occurring."
MAPREDUCE-6221,Stringifier is left unclosed in Chain#getChainElementConf(),"{code}
      Stringifier<Configuration> stringifier = 
        new DefaultStringifier<Configuration>(jobConf, Configuration.class);
      String confString = jobConf.get(confKey, null);
      if (confString != null) {
        conf = stringifier.fromString(jobConf.get(confKey, null));
{code}
stringifier is not closed upon return from the method."
MAPREDUCE-6220,Provide option to suppress stdout of MapReduce task,"System.out is a ugly way to print log, and many times it would do harm to Hadoop cluster. So we can provide an option to forbid it"
MAPREDUCE-6213,NullPointerException caused by job history server addr not resolvable,"When DNS failed for a time, all MapReduce jobs which completed during that time got failed. Log as below:
{noformat}
2015-01-08 01:26:44,968 ERROR [Thread-856] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering 
java.lang.NullPointerException
    at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithoutScheme(MRWebAppUtil.java:135)
    at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(MRWebAppUtil.java:150)
    at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.doUnregistration(RMCommunicator.java:212)
    at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister(RMCommunicator.java:182)
    at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStop(RMCommunicator.java:255)
    at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStop(RMContainerAllocator.java:257)
    at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
    at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
    at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStop(MRAppMaster.java:823)
    at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
    at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
    at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
    at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:157)
    at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
    at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1471)
    at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
    at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1085)
    at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:554)
    at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$1.run(MRAppMaster.java:605)
{noformat}"
MAPREDUCE-6212,UnsatisfiedLinkError: org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative() happened when starting MRAppMaster,"I have just started to work with Hadoop 2.

After installing with basic configs, I always failed to run any examples. Has anyone seen this problem and please help me?

This is the log

2015-01-08 01:52:01,599 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application appattempt_1420648881673_0004_000001
2015-01-08 01:52:01,764 FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:70)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:66)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:280)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:271)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:299)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1473)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1429)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:408)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:129)
	... 7 more
Caused by: java.lang.UnsatisfiedLinkError: org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative()V
	at org.apache.hadoop.security.JniBasedUnixGroupsMapping.anchorNative(Native Method)
	at org.apache.hadoop.security.JniBasedUnixGroupsMapping.<clinit>(JniBasedUnixGroupsMapping.java:49)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.<init>(JniBasedUnixGroupsMappingWithFallback.java:39)
	... 12 more
2015-01-08 01:52:01,767 INFO [main] org.apache.hadoop.util.ExitUtil: Exiting with status 1


This is my configs

core-site.xml

<property>
  <name>fs.defaultFS</name>
  <value>hdfs://grey5:9000</value>
</property>
 
<property>
  <name>hadoop.tmp.dir</name>
  <value>/home/maidinh/hadoop2/hadoop-data</value>
</property>

 
hdfs-site.xml

<property>
  <name>dfs.namenode.name.dir</name>
  <value>/home/maidinh/hadoop2/nn</value>
</property>
 
<property>
  <name>dfs.datanode.data.dir</name>
  <value>/data1/maidinh/hadoop2/dn,/data2/maidinh/hadoop2/dn,/data3/maidinh/hadoop2/dn</value>
</property>


yarn-site.xml

<property>
  <name>yarn.resourcemanager.hostname</name>
  <value>grey5</value>
</property>
 
<property>
  <name>yarn.nodemanager.local-dirs</name>
  <value>/data4/maidinh/hadoop2/yarn-data,/data5/maidinh/hadoop2/yarn-data,/data6/maidinh/hadoop2/yarn-data</value>
</property>
 
<property>
  <name>yarn.nodemanager.log-dirs</name>
  <value>/data4/maidinh/hadoop2/yarn-logs,/data5/maidinh/hadoop2/yarn-logs,/data6/maidinh/hadoop2/yarn-logs</value>
</property>
 
<property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
</property>


mapred-site.xml

<property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
</property>
 
<property>
  <name>mapreduce.jobhistory.address</name>
  <value>grey5:10020</value>
</property>
<property>
  <name>mapreduce.jobhistory.webapp.address</name>
  <value>grey5:19888</value>
</property>
 
<property>
  <name>mapreduce.jobtracker.address</name>
  <value>grey5:50030</value>
</property>


.bashrc
export JAVA_HOME=""/usr/java/latest/""
export HADOOP_PREFIX=""/home/maidinh/hadoop2/hadoop-2.6.0""
export HADOOP_YARN_USER=""maidinh""

export HADOOP_HOME=""$HADOOP_PREFIX""
export HADOOP_CONF_DIR=""$HADOOP_PREFIX/etc/hadoop""
export HADOOP_PID_DIR=""$HADOOP_PREFIX""
export HADOOP_LOG_DIR=""$HADOOP_PREFIX/logs""
export HADOOP_OPTS=""$HADOOP_OPTS -Djava.io.tmpdir=$HADOOP_PREFIX/tmp""

export YARN_HOME=""$HADOOP_PREFIX""
export YARN_CONF_DIR=""$HADOOP_PREFIX/etc/hadoop""
export YARN_PID_DIR=""$HADOOP_PREFIX""
export YARN_LOG_DIR=""$HADOOP_PREFIX/logs""
export YARN_OPTS=""$YARN_OPTS -Djava.io.tmpdir=$HADOOP_PREFIX/tmp"""
MAPREDUCE-6211,Update the MapReduce documentation post-shell rewrite,"Post HADOOP-9902, the mapreduce command documentation is out of date."
MAPREDUCE-6210,Use getApplicationAttemptId() instead of getApplicationID() for logging AttemptId in RMContainerAllocator.java,"It's confusing in the following codes of RMContainerAllocator.java .

{code:title=RMContainerAllocator.java|borderStyle=solid}
      throw new YarnRuntimeException(
        ""Resource Manager doesn't recognize AttemptId: ""
            + this.getContext().getApplicationID(), e);
{code}

Here should be getApplicationAttemptId() instead of getApplicationID(). "
MAPREDUCE-6207,TestAggregatedTransferRate fails on non-US systems,"When running the test TestAggregatedTransferRate from org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler on a non-US system (or, to be more precise, a system which does not use the point as a decimal separator), the test fails.

E.g. on a German system, the progress message is:
{{copy task(attempt_test_0000_m_000000_0 succeeded at 1,00 MB/s) Aggregated copy rate(1 of 10 at 1,00 MB/s)}}

But the test checks for:
{{copy task(attempt_test_0000_m_000000_0 succeeded at 1.00 MB/s) Aggregated copy rate(1 of 10 at 1.00 MB/s)}}

which causes it to fail."
MAPREDUCE-6206,TestAggregatedTransferRate fails on non-US systems,"When running the test TestAggregatedTransferRate from org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler on a non-US system (or, to be more precise, a system which does not use the point as a decimal separator), the test fails.

E.g. on a German system, the progress message is:
{{copy task(attempt_test_0000_m_000000_0 succeeded at 1,00 MB/s) Aggregated copy rate(1 of 10 at 1,00 MB/s)}}

But the test checks for:
{{copy task(attempt_test_0000_m_000000_0 succeeded at 1.00 MB/s) Aggregated copy rate(1 of 10 at 1.00 MB/s)}}

which causes it to fail."
MAPREDUCE-6204,TestJobCounters should use new properties instead of JobConf.MAPRED_TASK_JAVA_OPTS,
MAPREDUCE-6203,"if log-aggregation is enable and run some MR job, the AM log will be aggregated.then disable it,then in MR JobHistoryServer and YARN RM UI link,the AM log cannot be visible","as the Summary description, I think for the MR JobHistory Server, should not let “yarn.log-aggregation-enable” affect the history job,even “yarn.log-aggregation-enable” is false."
MAPREDUCE-6202,TestMRTimelineEventHandling fails on trunk,"Currently, {{TestMRTimelineEventHandling}} is failing on trunk:
{noformat}
Running org.apache.hadoop.mapred.TestMRTimelineEventHandling
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 181.186 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestMRTimelineEventHandling
testMRTimelineEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 97.149 sec  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling(TestMRTimelineEventHandling.java:53)

testMapreduceJobTimelineServiceEnabled(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 83.884 sec  <<< ERROR!
java.io.IOException: Job didn't finish in 30 seconds
	at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled(TestMRTimelineEventHandling.java:107)
{noformat}"
MAPREDUCE-6201,TestNetworkedJob fails on trunk,"Currently, {{TestNetworkedJob}} is failing on trunk:

{noformat}
Running org.apache.hadoop.mapred.TestNetworkedJob
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 215.01 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestNetworkedJob
testNetworkedJob(org.apache.hadoop.mapred.TestNetworkedJob)  Time elapsed: 67.363 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<2>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapred.TestNetworkedJob.testNetworkedJob(TestNetworkedJob.java:195)
{noformat}"
MAPREDUCE-6199,AbstractCounters are not reset completely on deserialization,AbstractCounters are partially reset on deserialization. This patch completely resets them. 
MAPREDUCE-6198,NPE from JobTracker#resolveAndAddToTopology in MR1 cause initJob and heartbeat failure.,"NPE from JobTracker#resolveAndAddToTopology in MR1 cause initJob and heartbeat failure. The NPE is caused by dnsToSwitchMapping.resolve return null at the following:
{code}
    List <String> rNameList = dnsToSwitchMapping.resolve(tmpList);
    String rName = rNameList.get(0);
{code}
I check the code in MR2, MR2 handle it correctly in coreResolve  of RackResolver.java
{code}
    List <String> rNameList = dnsToSwitchMapping.resolve(tmpList);
    String rName = null;
    if (rNameList == null || rNameList.get(0) == null) {
      rName = NetworkTopology.DEFAULT_RACK;
      LOG.info(""Couldn't resolve "" + hostName + "". Falling back to ""
          + NetworkTopology.DEFAULT_RACK);
    } else {
      rName = rNameList.get(0);
      LOG.info(""Resolved "" + hostName + "" to "" + rName);
    }
{code}

We should do the same in MR1, if dnsToSwitchMapping.resolve return null, use NetworkTopology.DEFAULT_RACK."
MAPREDUCE-6197,Cache MapOutputLocations in ShuffleHandler,"ShuffleHandler currently seems to create a map of mapId - mapInfo (file.out / index information) when it receives a message.
This should be caching map info across requests, so that the a scan of all directories is not required for each reducer fetching from the same map.

Also, the scan for each map output / index file is performed twice per mapId within a request. In populateHeaders - once in the call to getMapOutputInfo, and then directly in the method.

For an invocation where we do end up with more than 1000 (default) mapIds in a single call, and don't cache them in the map - the path constructed for such entries will be invalid. This is highly unlikely to be the case though, until there's proper caching.
{code}
MapOutputInfo info = mapOutputInfoMap.get(mapId);
          if (info == null) {
            info = getMapOutputInfo(outputBasePathStr, mapId, reduceId, user);
          }
{code}"
MAPREDUCE-6196,Fix BigDecimal ArithmeticException in PiEstimator,"Certain combinations of arguments to PiEstimator cause the following exception:

java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result.
	at java.math.BigDecimal.divide(BigDecimal.java:1603)
	at org.apache.hadoop.examples.PiEstimator.estimate(PiEstimator.java:313)
	at org.apache.hadoop.examples.PiEstimator.run(PiEstimator.java:342)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.examples.PiEstimator.main(PiEstimator.java:351)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:208)

The calls to the BigDecimal methods should have some large default precision to prevent this exception."
MAPREDUCE-6194,Bubble up final exception in failures during creation of output collectors,"MAPREDUCE-5974 added in ability to instantiate multiple OCs, but if none of them are able to load it ""throws"" only a final a generic message: {{""Unable to initialize any output collector""}}

The older behaviour was to throw the actual instantiation exception back, so it makes it to client logs with an actual meaningful error.

Now the clients need to go take a look at the task's logs to find the WARNs that represent the failure in instantiation."
MAPREDUCE-6192,Create unit test to automatically compare MR related classes and mapred-default.xml,Create a unit test that will automatically compare the fields in the various MapReduce related classes and mapred-default.xml. It should throw an error if a property is missing in either the class or the file.
MAPREDUCE-6191,TestJavaSerialization fails with getting incorrect MR job result,"TestJavaSerialization#testMapReduceJob() fails with getting incorrect MR job result:
""junit.framework.ComparisonFailure: expected:<[a ]1> but was:<[0 1]1>"""
MAPREDUCE-6190,"If a task stucks before its first heartbeat, it never timeouts and the MR job becomes stuck","Trying to figure out a weird issue we started seeing on our CDH5.1.0 cluster with map reduce jobs on YARN.

We had a job stuck for hours because one of the mappers never started up fully. Basically, the map task had 2 attempts, the first one failed and the AM tried to schedule a second one and the second attempt was stuck on STATE: STARTING, STATUS: NEW. A node never got assigned and the task along with the job was stuck indefinitely.

The AM logs had this being logged again and again:

{code}
2014-12-09 19:25:12,347 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down 0
2014-12-09 19:25:13,352 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1408745633994_450952_02_003807
2014-12-09 19:25:13,352 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce preemption successful attempt_1408745633994_450952_r_000048_1000
2014-12-09 19:25:13,352 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:0
2014-12-09 19:25:13,352 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 1
2014-12-09 19:25:13,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1408745633994_450952_r_000050_1000
2014-12-09 19:25:13,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=0
2014-12-09 19:25:13,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.99968 totalMemLimit:1722880 finalMapMemLimit:2560 finalReduceMemLimit:1720320 netScheduledMapMem:2560 netScheduledReduceMem:1722880
2014-12-09 19:25:13,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down 0
2014-12-09 19:25:13,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:77 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:0 AssignedReds:673 CompletedMaps:3124 CompletedReds:0 ContAlloc:4789 ContRel:798 HostLocal:2944 RackLocal:155
2014-12-09 19:25:14,353 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:78 ScheduledMaps:1 ScheduledReds:0 AssignedMaps:0 AssignedReds:673 CompletedMaps:3124 CompletedReds:0 ContAlloc:4789 ContRel:798 HostLocal:2944 RackLocal:155
2014-12-09 19:25:14,359 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule, headroom=0
{code}

On killing the task manually, the AM started up the task again, scheduled and ran it successfully completing the task and the job with it.

Some quick code grepping led us here:
http://grepcode.com/file/repo1.maven.org/maven2/org.apache.hadoop/hadoop-mapreduce-client-app/2.3.0/org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.java#397

But still dont quite understand why this would happen once in a while and why the job would suddenly be ok once the stuck task is manually killed.

Note: Other jobs succeed on the cluster while this job is stuck.
"
MAPREDUCE-6189,TestMRTimelineEventHandling fails in trunk,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1988/:
{code}
REGRESSION:  org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling

Error Message:
Job didn't finish in 30 seconds

Stack Trace:
java.io.IOException: Job didn't finish in 30 seconds
        at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
        at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling(TestMRTimelineEventHandling.java:105)


REGRESSION:  org.apache.hadoop.mapred.TestMRTimelineEventHandling.testTimelineServiceStartInMiniCluster

Error Message:
Job didn't finish in 30 seconds

Stack Trace:
java.io.IOException: Job didn't finish in 30 seconds
        at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
        at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testTimelineServiceStartInMiniCluster(TestMRTimelineEventHandling.java:61)


REGRESSION:  org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled

Error Message:
Job didn't finish in 30 seconds

Stack Trace:
java.io.IOException: Job didn't finish in 30 seconds
        at org.apache.hadoop.mapred.UtilsForTests.runJobSucceed(UtilsForTests.java:622)
        at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMapreduceJobTimelineServiceEnabled(TestMRTimelineEventHandling.java:198)
{code}"
MAPREDUCE-6186,Redundant call to requireJob() while displaying the conf page,"There are multiple calls to {{requireJob()}} in {{AppController.java#conf()}}

The duplicate call seems to be introduced by mistake in https://github.com/apache/hadoop/commit/fe1cf3b0aca5f4d7a8af02a915b218f9b1de0fa6

"
MAPREDUCE-6185,YARN M/R may return NaN for reducer progress after Job completion,
MAPREDUCE-6184,Fix findbugs warnings in mapreduce-client-core,"Work on MAPREDUCE-5800 has exposed some findbugs warnings.
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5063//artifact/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-core.html"
MAPREDUCE-6183,Fix findbugs warnings in mapreduce-examples,"Work on MAPREDUCE-5800 has exposed some findbugs warnings. 
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5063//artifact/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-examples.html"
MAPREDUCE-6182,Fix findbugs warnings in gridmix,"Work on MAPREDUCE-5800 has exposed some findbugs warnings.
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5063//artifact/patchprocess/newPatchFindbugsWarningshadoop-gridmix.html"
MAPREDUCE-6181,WordCount.java in mapreduce-examples.jar uses deprecated job object creation API,"In the trunk branch the mapreduce-examples.jar contains a WordCount class. In which deprecated Job object has been used. So this Jira is to fix the deprecation warning.

{code:title=WordCount.java|borderStyle=solid}
// Currently : Job job = new Job(conf, ""word count"");
Job job = Job.getInstance(conf); 
job.setJobName(""word count"");
{code}"
MAPREDUCE-6179,Running any MapReduce jobs is throwing Heap Error,"I have a hadoop distribution installed on a cluster with 1 namenode and 2 data nodes. I have been trying to run the default mapreduce example included in the hadoop package and its been throwing the following error :

""Error occurred during initialization of VM
Could not reserve enough space for object heap""

The complete message test is as following :

[192769@hawq /]$ hadoop jar /usr/lib/gphd/hadoop-mapreduce/hadoop-mapreduce-examples-2.2.0-gphd-3.0.1.0.jar pi 10 100
Number of Maps  = 10
Samples per Map = 100
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Wrote input for Map #3
Wrote input for Map #4
Wrote input for Map #5
Wrote input for Map #6
Wrote input for Map #7
Wrote input for Map #8
Wrote input for Map #9
Starting Job
14/12/04 17:28:44 INFO client.RMProxy: Connecting to ResourceManager at dn2.tcsgegdc.com/3.209.124.208:8032
14/12/04 17:28:44 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 50 for 192769 on 3.209.124.204:8020
14/12/04 17:28:44 INFO security.TokenCache: Got dt for hdfs://pcc.tcsgegdc.com:8020; Kind: HDFS_DELEGATION_TOKEN, Service: 3.209.124.204:8020, Ident: (HDFS_DELEGATION_TOKEN token 50 for 192769)
14/12/04 17:28:44 INFO input.FileInputFormat: Total input paths to process : 10
14/12/04 17:28:44 INFO mapreduce.JobSubmitter: number of splits:10
14/12/04 17:28:44 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.map.tasks.speculative.execution is deprecated. Instead, use mapreduce.map.speculative
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
14/12/04 17:28:44 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/12/04 17:28:44 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/12/04 17:28:44 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/12/04 17:28:44 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/12/04 17:28:44 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1413806590994_0039
14/12/04 17:28:44 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: 3.209.124.204:8020, Ident: (HDFS_DELEGATION_TOKEN token 50 for 192769)
14/12/04 17:28:44 INFO impl.YarnClientImpl: Submitted application application_1413806590994_0039 to ResourceManager at dn2.tcsgegdc.com/3.209.124.208:8032
14/12/04 17:28:44 INFO mapreduce.Job: The url to track the job: http://dn2.tcsgegdc.com:8088/proxy/application_1413806590994_0039/
14/12/04 17:28:44 INFO mapreduce.Job: Running job: job_1413806590994_0039
14/12/04 17:28:48 INFO mapreduce.Job: Job job_1413806590994_0039 running in uber mode : false
14/12/04 17:28:48 INFO mapreduce.Job:  map 0% reduce 0%
14/12/04 17:28:48 INFO mapreduce.Job: Job job_1413806590994_0039 failed with state FAILED due to: Application application_1413806590994_0039 failed 2 times due to AM Container for appattempt_1413806590994_0039_000002 exited with  exitCode: -1000 due to: Application application_1413806590994_0039 initialization failed (exitCode=1) with output: main : command provided 0
main : user is 192769
Error occurred during initialization of VM
Could not reserve enough space for object heap

.Failing this attempt.. Failing the application.
14/12/04 17:28:49 INFO mapreduce.Job: Counters: 0
Job Finished in 4.863 seconds
java.io.FileNotFoundException: File does not exist: hdfs://pcc.tcsgegdc.com:8020/user/192769/QuasiMonteCarlo_1417694322429_282484071/out/reduce-out
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1120)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1112)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1112)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1749)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1773)
        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:314)
        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:354)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:363)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)

Please help understand what is causing this error as all installation steps were followed to the word."
MAPREDUCE-6178,MRAppBenchmark.benchmark1() error,"when running the test, it ouputs an exception:""java.lang.NullPointerException"""
MAPREDUCE-6177,Minor typo in the EncryptedShuffle document about ssl-client.xml,The installation documentation for Hadoop MapReduce EncryptedShuffle document has some error entry(http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html)  in the *ssl-client.xml (Reducer/Fetcher) Configuration:* section   the *The mapred user should own the ssl-server.xml file and it should have default permissions.*  should be *The mapred user should own the ssl-client.xml file and it should have default permissions.*
MAPREDUCE-6176,To limit the map task number or reduce task number of an application,"As MapReduce is a batch framework of calculation, so people may want to run application A as well as application B 、C, and a limit resource be put on A. A good way to do so is that we can limit the number of application's map task or reduce task. If we set mapreduce.map.num.max as M, then the map task number will not exceed M. At the same time, if we set mapreduce.map.num.max as R, then the reduce task number will not exceed R"
MAPREDUCE-6174,Combine common stream code into parent class for InMemoryMapOutput and OnDiskMapOutput.,"Per MAPREDUCE-6166, both InMemoryMapOutput and OnDiskMapOutput will be doing similar things with regards to IFile streams.

In order to make it explicit that InMemoryMapOutput and OnDiskMapOutput are different from 3rd-party implementations, this JIRA will make them subclass a common class (see https://issues.apache.org/jira/browse/MAPREDUCE-6166?focusedCommentId=14223368&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14223368)"
MAPREDUCE-6173,Document the configuration of deploying MR over distributed cache with enabling wired encryption at the same time,"Use the current documented configuration (specified in http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/DistributedCacheDeploy.html) to work with the cluster enabling shuffle encryption (http://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/EncryptedShuffle.html) will cause the job failed with exception below:
{noformat}
2014-10-10 02:17:16,600 WARN [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to tassapol-centos5nano1-3.cs1cloud.internal:13562 with 1 map outputs
javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
	at com.sun.net.ssl.internal.ssl.Alerts.getSSLException(Alerts.java:174)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1731)
	at com.sun.net.ssl.internal.ssl.Handshaker.fatalSE(Handshaker.java:241)
	at com.sun.net.ssl.internal.ssl.Handshaker.fatalSE(Handshaker.java:235)
	at com.sun.net.ssl.internal.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1206)
	at com.sun.net.ssl.internal.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:136)
	at com.sun.net.ssl.internal.ssl.Handshaker.processLoop(Handshaker.java:593)
	at com.sun.net.ssl.internal.ssl.Handshaker.process_record(Handshaker.java:529)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:925)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1170)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1197)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1181)
	at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:434)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.setNewClient(AbstractDelegateHttpsURLConnection.java:81)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.setNewClient(AbstractDelegateHttpsURLConnection.java:61)
	at sun.net.www.protocol.http.HttpURLConnection.writeRequests(HttpURLConnection.java:584)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1193)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:379)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:318)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.verifyConnection(Fetcher.java:427)
{noformat}
This is due to ssl-client.xml is not included in MR tar ball when we deploy it over distributed cache. Putting the ssl-client.xml on CLASSPATH of MR job can resolve the problem and we should document it."
MAPREDUCE-6172,TestDbClasses timeouts are too aggressive,"Some of the TestDbClasses test timeouts are only 1 second, and some of those tests perform disk I/O which could easily exceed the test timeout if the disk is busy or there's some other hiccup on the system at the time.  We should increase these timeouts to something more reasonable (i.e.: 10 or 20 seconds)."
MAPREDUCE-6171,The visibilities of the distributed cache files and archives should be determined by both their permissions and if they are located in HDFS encryption zone,"The visibilities of the distributed cache files and archives are currently determined by the permission of these files or archives. 
The following is the logic of method isPublic() in class ClientDistributedCacheManager:
{code}
static boolean isPublic(Configuration conf, URI uri,
      Map<URI, FileStatus> statCache) throws IOException {
    FileSystem fs = FileSystem.get(uri, conf);
    Path current = new Path(uri.getPath());
    //the leaf level file should be readable by others
    if (!checkPermissionOfOther(fs, current, FsAction.READ, statCache)) {
      return false;
    }
    return ancestorsHaveExecutePermissions(fs, current.getParent(), statCache);
  }
{code}
At NodeManager side, it will use ""yarn"" user to download public files and use the user who submits the job to download private files. In normal cases, there is no problem with this. However, if the files are located in an encryption zone(HDFS-6134) and yarn user are configured to be disallowed to fetch the DataEncryptionKey(DEK) of this encryption zone by KMS, the download process of this file will fail. 

You can reproduce this issue with the following steps (assume you submit job with user ""testUser""): 
# create a clean cluster which has HDFS cryptographic FileSystem feature
# create directory ""/data/"" in HDFS and make it as an encryption zone with keyName ""testKey""
# configure KMS to only allow user ""testUser"" can decrypt DEK of key ""testKey"" in KMS
{code}
  <property>
    <name>key.acl.testKey.DECRYPT_EEK</name>
    <value>testUser</value>
  </property>
{code}
# execute job ""teragen"" with user ""testUser"":
{code}
su -s /bin/bash testUser -c ""hadoop jar hadoop-mapreduce-examples*.jar teragen 10000 /data/terasort-input"" 
{code}
# execute job ""terasort"" with user ""testUser"":
{code}
su -s /bin/bash testUser -c ""hadoop jar hadoop-mapreduce-examples*.jar terasort /data/terasort-input /data/terasort-output""
{code}

You will see logs like this at the job submitter's console:
{code}
INFO mapreduce.Job: Job job_1416860917658_0002 failed with state FAILED due to: Application application_1416860917658_0002 failed 2 times due to AM Container for appattempt_1416860917658_0002_000002 exited with  exitCode: -1000 due to: org.apache.hadoop.security.authorize.AuthorizationException: User [yarn] is not authorized to perform [DECRYPT_EEK] on key with ACL name [testKey]!!
{code}

The initial idea to solve this issue is to modify the logic in ClientDistributedCacheManager.isPublic to consider also whether this file is in an encryption zone. If it is in an encryption zone, this file should be considered as private. Then at NodeManager side, it will use user who submits the job to fetch the file."
MAPREDUCE-6170,TestUlimit failure on JDK8,"TestUlimit#testCommandLine fails on JDK8, because the map task JVM fails to launch. We're setting the virtual memory limit too low, and the JVM errors out with: Could not allocate metaspace"
MAPREDUCE-6169,MergeQueue should release reference to the current item from key and value at the end of the iteration to save memory.,"MergeQueue should release reference to the current item from key and value at the end of the iteration to save memory.
these buffers referenced by key and value can be large, which may cause an OOM error."
MAPREDUCE-6168,Old MR client is still broken when receiving new counters from MR job,"In the following scenarios:

1. Either insecure or secure;
2. MR 2.2 with new shuffle on NM;
3. Submitting via old client.

We will see the following console exception:
{code}
14/11/17 14:56:19 INFO mapreduce.Job: Job job_1416264695865_0003 completed successfully
java.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.JobCounter.MB_MILLIS_REDUCES
        at java.lang.Enum.valueOf(Enum.java:236)
        at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.valueOf(FrameworkCounterGroup.java:148)
        at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.findCounter(FrameworkCounterGroup.java:182)
        at org.apache.hadoop.mapreduce.counters.AbstractCounters.findCounter(AbstractCounters.java:154)
        at org.apache.hadoop.mapreduce.TypeConverter.fromYarn(TypeConverter.java:240)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:370)
        at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:511)
        at org.apache.hadoop.mapreduce.Job$7.run(Job.java:756)
        at org.apache.hadoop.mapreduce.Job$7.run(Job.java:753)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
        at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:753)
        at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1361)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1289)
        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:306)
        at org.apache.hadoop.examples.QuasiMonteCarlo.run(QuasiMonteCarlo.java:354)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.examples.QuasiMonteCarlo.main(QuasiMonteCarlo.java:363)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
{code}

The problem is supposed to be fixed by MAPREDUCE-5831, however, it seems that we haven't cover all the problematic code path."
MAPREDUCE-6166,Reducers do not validate checksum of map outputs when fetching directly to disk,"In very large map/reduce jobs (50000 maps, 2500 reducers), the intermediate map partition output gets corrupted on disk on the map side. If this corrupted map output is too large to shuffle in memory, the reducer streams it to disk without validating the checksum. In jobs this large, it could take hours before the reducer finally tries to read the corrupted file and fails. Since retries of the failed reduce attempt will also take hours, this delay in discovering the failure is multiplied greatly."
MAPREDUCE-6165,[JDK8] TestCombineFileInputFormat failed on JDK8,"The error msg:
{noformat}
testSplitPlacementForCompressedFiles(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat)  Time elapsed: 2.487 sec  <<< FAILURE!
junit.framework.AssertionFailedError: expected:<2> but was:<1>
	at junit.framework.Assert.fail(Assert.java:57)
	at junit.framework.Assert.failNotEquals(Assert.java:329)
	at junit.framework.Assert.assertEquals(Assert.java:78)
	at junit.framework.Assert.assertEquals(Assert.java:234)
	at junit.framework.Assert.assertEquals(Assert.java:241)
	at junit.framework.TestCase.assertEquals(TestCase.java:409)
	at org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testSplitPlacementForCompressedFiles(TestCombineFileInputFormat.java:911)

testSplitPlacement(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat)  Time elapsed: 0.985 sec  <<< FAILURE!
junit.framework.AssertionFailedError: expected:<2> but was:<1>
	at junit.framework.Assert.fail(Assert.java:57)
	at junit.framework.Assert.failNotEquals(Assert.java:329)
	at junit.framework.Assert.assertEquals(Assert.java:78)
	at junit.framework.Assert.assertEquals(Assert.java:234)
	at junit.framework.Assert.assertEquals(Assert.java:241)
	at junit.framework.TestCase.assertEquals(TestCase.java:409)
	at org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testSplitPlacement(TestCombineFileInputFormat.java:368)
{noformat}"
MAPREDUCE-6164,"""mapreduce.reduce.shuffle.fetch.retry.timeout-ms"" should be set to 3 minutes instead of 30 seconds by default to be consistent with other retry timeout ","In MAPREDUCE-5891, we are adding retry logic to MAPREDUCE shuffle stage for fetcher can be survival during NM downtime (with shuffle service down as well). In many places, we are setting the default timeout to be 3 minutes (connection timeout, etc.) to tolerant possible more time for NM down, but we are making ""mapreduce.reduce.shuffle.fetch.retry.timeout-ms"" to be 30 seconds which is not consistent here. We should change this to 180 seconds. "
MAPREDUCE-6162,mapred hsadmin fails on a secure cluster,"Attempts to use mapred hsadmin fail on a secure cluster for a couple of reasons. The HSAdmin client isn't configuring the principal config key for the protocol, resulting in a ""Failed to specify server's Kerberos principal name"" error.  The principal can be specified manually on the command-line via -Dhadoop.security.service.user.name.key, but then it results in a ""Protocol interface ... is not known"" error because HSAdminServer is not registering an appropriately configured policy provider when authorization is enabled."
MAPREDUCE-6161,mapred hsadmin command missing from trunk,The hsadmin subcommand of the mapred script is no longer present in trunk. It is present in branch-2.
MAPREDUCE-6160,Potential NullPointerException in MRClientProtocol interface implementation.,"In the implementation of MRClientProtocol, many methods can throw NullPointerExceptions. Instead of NullPointerExceptions, better to throw IOException with proper message.

In the HistoryClientService class and MRClientService class has #verifyAndGetJob() method that return job object as null.
{code}
getTaskReport(GetTaskReportRequest request) throws IOException;
getTaskAttemptReport(GetTaskAttemptReportRequest request) throws IOException;
getCounters(GetCountersRequest request) throws IOException;
getTaskAttemptCompletionEvents(GetTaskAttemptCompletionEventsRequest request) throws IOException;
getTaskReports(GetTaskReportsRequest request) throws IOException;
getDiagnostics(GetDiagnosticsRequest request) throws IOException;
{code}"
MAPREDUCE-6159,No log of JobHistory found in all logs files,"I intend to dig into 'mapreduce.jobhistory.intermediate-done-dir' argument, the position of which is at `JHAdminConfig:73`, to get some comprehension on history server. This argument is referenced at `JobHistoryEventHandler.moveToDoneNow()`, where history server moves job summary file 
from ""$[yarn.app.mapreduce.am.staging-dir]/$[user]/.staging"" to ""$[mapreduce.jobhistory.intermediate-done-dir]/$[user]"". 

The following code snippet in `moveToDoneNow()` will definitely write some logs out to log file, but I can found no any sign of it in all logs in $HADOOP_LOG_DIR via command `grep ""Copied to done location"" *`.
    if (copied)
        LOG.info(""Copied to done location: "" + toPath);
    else 
        LOG.info(""copy failed"");

Is there anything that I missed?"
MAPREDUCE-6157,Connect failed in shuffle (due to NM down) could break current retry logic to tolerant NM restart.,"The connection failure log during NM restart is as following:
{noformat}
014-11-12 03:31:20,728 WARN [fetcher#23] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to ip-172-31-37-212.ec2.internal:13562 with 4 map outputs
java.net.ConnectException: Connection refused
        at java.net.PlainSocketImpl.socketConnect(Native Method)
        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
        at java.net.Socket.connect(Socket.java:579)
        at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
        at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)
        at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)
        at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)
        at sun.net.www.http.HttpClient.New(HttpClient.java:308)
        at sun.net.www.http.HttpClient.New(HttpClient.java:326)
        at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)
        at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)
        at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.connect(Fetcher.java:685)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.setupConnectionsWithRetry(Fetcher.java:386)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:292)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:193)
2014-11-12 03:31:20,743 INFO [fetcher#22] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=13562/mapOutput?job=job_1415762969065_0001&reduce=3&map=attempt_1415762969065_0001_m_000021_0,attempt_1415762969065_0001_m_000004_0,attempt_1415762969065_0001_m_000018_0,attempt_1415762969065_0001_m_000015_0,attempt_1415762969065_0001_m_000001_0,attempt_1415762969065_0001_m_000009_0,attempt_1415762969065_0001_m_000012_0,attempt_1415762969065_0001_m_000006_0 sent hash and received reply
{noformat}
We have some code to handle the retry logic for connection with a timeout (as below). But if connection get refused quickly, we only try very limited times and it get failed also quickly.

{code}
while (true) {
      try {
        connection.connect();
        break;
      } catch (IOException ioe) {
        // update the total remaining connect-timeout
        connectionTimeout -= unit;

        // throw an exception if we have waited for timeout amount of time
        // note that the updated value if timeout is used here
        if (connectionTimeout == 0) {
          throw ioe;
        }

        // reset the connect timeout for the last try
        if (connectionTimeout < unit) {
          unit = connectionTimeout;
          // reset the connect time out for the final connect
          connection.setConnectTimeout(unit);
        }
      }
{code}
We should fix this to make retry can continue until timeout."
MAPREDUCE-6156,Fetcher - connect() doesn't handle connection refused correctly ,"The connect() function in the fetcher assumes that whenever an IOException is thrown, the amount of time passed equals ""connectionTimeout"" ( see code snippet below ). This is incorrect. For example, in case the NM is down, an ConnectException is thrown immediately - and the catch block assumes a minute has passed when it is not the case.

{code}
  if (connectionTimeout < 0) {
      throw new IOException(""Invalid timeout ""
                            + ""[timeout = "" + connectionTimeout + "" ms]"");
    } else if (connectionTimeout > 0) {
      unit = Math.min(UNIT_CONNECT_TIMEOUT, connectionTimeout);
    }
    // set the connect timeout to the unit-connect-timeout
    connection.setConnectTimeout(unit);
    while (true) {
      try {
        connection.connect();
        break;
      } catch (IOException ioe) {
        // update the total remaining connect-timeout
        connectionTimeout -= unit;

        // throw an exception if we have waited for timeout amount of time
        // note that the updated value if timeout is used here
        if (connectionTimeout == 0) {
          throw ioe;
        }

        // reset the connect timeout for the last try
        if (connectionTimeout < unit) {
          unit = connectionTimeout;
          // reset the connect time out for the final connect
          connection.setConnectTimeout(unit);
        }
      }
    }
{code}"
MAPREDUCE-6153,Apply `mapreduce.admin.user.env' to AM,"Would be nice to be able to manipulate the AM's library path to include snappy. The `mapreduce.admin.user.env' seems perfect for this, except that it only affects the tasks. I think it's useful to have it apply to the AM as well.

Use case: I have a job that uses the output committer (which runs in the AM) to read the output file of the reducer, which is compressed using snappy."
MAPREDUCE-6152,TestUberAM occasionally fails in trunk,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1949/console :
{code}
Tests run: 11, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 249.123 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.TestUberAM
testConfVerificationWithClassloader(org.apache.hadoop.mapreduce.v2.TestUberAM)  Time elapsed: 7.346 sec  <<< FAILURE!
java.lang.AssertionError: Job status: Task failed task_1415281971262_0011_r_000000
Job failed as tasks failed. failedMaps:0 failedReduces:1

	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testConfVerification(TestMRJobs.java:328)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testConfVerificationWithClassloader(TestMRJobs.java:222)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
{code}"
MAPREDUCE-6151,Update document of GridMix,
MAPREDUCE-6150,Update document of Rumen,
MAPREDUCE-6149,Document override log4j.properties in MR job,"This new feature comes from MAPREDUCE-6052, some documentation requirements from Vinod below:
    Document the new config in mapred-default.xml
    Mention in that documentation that if no-scheme is given in the path, it defaults to a log4j file on the local FS.
    Modify the documentation of log-level configs to say that if you override to have your own log4j.properties file, the log-level configs may not work.
"
MAPREDUCE-6147,Support mapreduce.input.fileinputformat.split.maxsize,"support mapreduce.input.fileinputformat.split.maxsize in MR1 mapred.
Hive use mapred API,
Hive expects mapred.max.split.size and mapreduce.input.fileinputformat.split.maxsize should be equivalent in MR1."
MAPREDUCE-6145,No space in an error output message,"[nzhdusr@nhga0007 ~]$ hadoop job -history ~/1
Exception in thread ""main"" java.io.IOException: Not able to initialize History viewer
	at org.apache.hadoop.mapred.HistoryViewer.<init>(HistoryViewer.java:95)
	at org.apache.hadoop.mapred.JobClient.viewHistory(JobClient.java:1917)
	at org.apache.hadoop.mapred.JobClient.run(JobClient.java:1866)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:2123)
Caused by: java.io.IOException: History directory /home/nzhdusr/1/_logs/historydoes not exist"
MAPREDUCE-6144,DefaultSpeculator always add both MAP and REDUCE Speculative task even MAP_SPECULATIVE or REDUCE_SPECULATIVE is disabled.,"DefaultSpeculator always add both MAP and REDUCE Speculative task even MAP_SPECULATIVE or REDUCE_SPECULATIVE is disabled.
If both MAP_SPECULATIVE and REDUCE_SPECULATIVE are disabled, 
DefaultSpeculator won't start.
The issue will happen if only one of MAP_SPECULATIVE and REDUCE_SPECULATIVE is enabled, both MAP and REDUCE Speculative task  are generate."
MAPREDUCE-6143,add configuration for  mapreduce speculative execution in MR2,"add configuration for  mapreduce speculative execution in MR2.
Currently mapreduce.job.speculative.speculativecap and mapreduce.job.speculative.slownodethreshold are not used for MR2 mapreduce speculative execution any more.

We should make the following hardcode constants in DefaultSpeculator configurable for MR2 Map Reduce speculative execution:

private static final long SOONEST_RETRY_AFTER_NO_SPECULATE = 1000L * 1L;
private static final long SOONEST_RETRY_AFTER_SPECULATE = 1000L * 15L;
private static final double PROPORTION_RUNNING_TASKS_SPECULATABLE = 0.1;
private static final double PROPORTION_TOTAL_TASKS_SPECULATABLE = 0.01;
private static final int MINIMUM_ALLOWED_SPECULATIVE_TASKS = 10;"
MAPREDUCE-6142,Test failure in TestJobHistoryEventHandler and TestMRTimelineEventHandling,"{code}
Running org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler
Tests run: 12, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 28.122 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler
testTimelineEventHandling(org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler)  Time elapsed: 6.014 sec  <<< FAILURE!
java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapreduce.jobhistory.TestJobHistoryEventHandler.testTimelineEventHandling(TestJobHistoryEventHandler.java:467)


Results :

Failed tests: 
  TestJobHistoryEventHandler.testTimelineEventHandling:467 expected:<1> but was:<0>

Tests run: 12, Failures: 1, Errors: 0, Skipped: 0
{code}

{code}
Running org.apache.hadoop.mapred.TestMRTimelineEventHandling
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 204.488 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestMRTimelineEventHandling
testMRTimelineEventHandling(org.apache.hadoop.mapred.TestMRTimelineEventHandling)  Time elapsed: 54.84 sec  <<< FAILURE!
java.lang.AssertionError: expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.mapred.TestMRTimelineEventHandling.testMRTimelineEventHandling(TestMRTimelineEventHandling.java:58)


Results :

Failed tests: 
  TestMRTimelineEventHandling.testMRTimelineEventHandling:58 expected:<1> but was:<0>

Tests run: 2, Failures: 1, Errors: 0, Skipped: 0
{code}"
MAPREDUCE-6141,History server leveldb recovery store,"It would be nice to have a leveldb option to the job history server recovery store.  Leveldb would provide some benefits over the existing filesystem store such as better support for atomic operations, fewer I/O ops per state update, and far fewer total files on the filesystem."
MAPREDUCE-6138,"Unable to run start-all.sh script, getting error","Present working Shell: /bin/bash

Trying to run start-all.sh, but getting below error.

hduser@jagadeesh-Aspire-E5-511:/usr/local/hadoop/hadoop-2.5.0/sbin$ sh start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
start-all.sh: 82: /usr/local/hadoop/hadoop-2.5.0/sbin/../libexec/hadoop-config.sh: Syntax error: word unexpected (expecting "")"")

Kindly help.

Regards
Jagadeesh A Y"
MAPREDUCE-6137,"Unable to run start-all.sh script, getting error","Present working Shell: /bin/bash

Trying to run start-all.sh, but getting below error.

hduser@jagadeesh-Aspire-E5-511:/usr/local/hadoop/hadoop-2.5.0/sbin$ sh start-all.sh
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
start-all.sh: 82: /usr/local/hadoop/hadoop-2.5.0/sbin/../libexec/hadoop-config.sh: Syntax error: word unexpected (expecting "")"")

Kindly help.

Regards
Jagadeesh A Y"
MAPREDUCE-6136,MRAppMaster doesn't shutdown file systems,"When MRAppMaster exit it doesn't call close on its open file systems instances.

MAPREDUCE-3614 sets conf.setBoolean(""fs.automatic.close"", false); in MRAppMaster::main and then called FileSystem.closeAll() in MRAppMasterShutdownHook.

However, MAPREDUCE-4205 removed the call to FileSystem.closeAll() MRAppMasterShutdownHook but left `fs.automatic.close` set to false.

Removing `conf.setBoolean(""fs.automatic.close"", false);` worked for me, but it wasn't clear if this had other implications."
MAPREDUCE-6135,Job staging directory remains if MRAppMaster is OOM,"If MRAppMaster attempts run out of memory, it won't go through the normal job clean up process to move history files to history server location. When customers try to find out why the job failed, the data won't be available on history server webUI.

The work around is to extract the container id and NM id from the jhist file in the job staging directory; then use ""yarn logs"" command to get the AM logs.

It would be great the platform can take care of it by moving these hist files automatically to history server if AM attempts don't exit properly.

We discuss ideas on how to address this and would like get suggestions from others. Not sure if timeline server design covers this scenario.

1. Define some protocol for YARN to tell AppMaster ""you have exceeded AM max attempt, please clean up"". For example, YARN can launch AppMaster one more time after AM max attempt and MRAppMaster use that as the indication this is clean-up-only attempt.

2. Have some program periodically check job statuses and move files from job staging directory to history server for those finished jobs."
MAPREDUCE-6132,Rumen unable to accept hdfs as scheme,"while running,

java -cp hadoop-2.4.1/share/hadoop/common/hadoop-common-2.4.1.jar:hadoop-2.4.1/share/hadoop/tools/lib/hadoop-rumen-2.4.1.jar:hadoop-2.4.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:hadoop-2.4.1/share/hadoop/common/lib/commons-cli-1.2.jar:hadoop-2.4.1/share/hadoop/common/lib/commons-configuration-1.6.jar:hadoop-2.4.1/share/hadoop/common/lib/commons-lang-2.6.jar:hadoop-2.4.1/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:hadoop-2.4.1/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:hadoop-2.4.1/share/hadoop/tools/lib/guava-11.0.2.jar:hadoop-2.4.1/share/hadoop/tools/lib/guava-11.0.2.jar:hadoop-2.4.1/share/hadoop/tools/lib/commons-collections-3.2.1.jar:hadoop-2.4.1/share/hadoop/common/lib/hadoop-auth-2.4.1.jar:hadoop-2.4.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:hadoop-2.4.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.4.1.jar:hadoop-2.4.1/share/hadoop/common/lib/log4j-1.2.17.jar:hadoop-2.4.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:hadoop-2.4.1/share/hadoop/common/lib/log4j-1.2.17.jar org.apache.hadoop.tools.rumen.TraceBuilder file:///pathto/rumen/jobjars/job-trace.json file:///pathto/rumen/jobjars/topology hdfs://path to jhist file

We are getting,
java.io.IOException: No FileSystem for scheme: hdfs
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2385)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2392)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:89)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2431)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2413)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:368)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:296)
	at org.apache.hadoop.tools.rumen.TraceBuilder$MyOptions.processInputArgument(TraceBuilder.java:134)
	at org.apache.hadoop.tools.rumen.TraceBuilder$MyOptions.<init>(TraceBuilder.java:91)
	at org.apache.hadoop.tools.rumen.TraceBuilder.run(TraceBuilder.java:206)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.tools.rumen.TraceBuilder.main(TraceBuilder.java:186)
"
MAPREDUCE-6131,Integer overflow in RMContainerAllocator results in starvation of applications,"When processing large datasets, Hadoop encounters a scenario where all
 containers run reduce tasks and no map tasks are scheduled. The 
application does not fail but rather remains in this state without making 
any forward progress. It then has to be manually terminated. 

This bug is due to integer overflow in scheduleReduces() of 
RMContainerAllocator. The variable netScheduledMapMem overflows for 
large data sizes, takes negative value, and results in a large 
finalReduceMemLimit and a large rampup value. In almost all cases, this 
large rampup value is greater than the total number of reduce tasks. 
Therefore, the AM tries to assign all reduce tasks. And if the total number 
of reduce tasks is greater than the total container slots, then all slots are 
taken up by reduce tasks, leaving none for maps. 

With 128MB block size and 2GB map container size, overflow occurs with 128 TB data size. An example scenario for the reproduction is: 

- Input data size of 32TB, block size 128MB, Map container size = 10GB,
reduce container size = 10GB, #reducers = 50,  cluster mem capacity =  7 x 40GB, slowstart=0.0

Better resolution might be to change the variables used in 
RMContainerAllocator from int to long. A simpler fix instead would be to 
only change the local variables of scheduleReduces() to long data types. 
Patch is attached for 2.2.0. 

"
MAPREDUCE-6130,Mapreduce tests fail with IllegalArgumentException in trunk,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1929/console :
{code}
testComplexNameWithRegex(org.apache.hadoop.mapred.TestJobName)  Time elapsed: 5.153 sec  <<< ERROR!
java.lang.IllegalArgumentException: Illegal capacity of -1.0 for label=x in queue=root.default
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration.getNodeLabelCapacities(CapacitySchedulerConfiguration.java:473)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.AbstractCSQueue.<init>(AbstractCSQueue.java:119)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.<init>(LeafQueue.java:120)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:567)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:587)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.initializeQueues(CapacityScheduler.java:462)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.initScheduler(CapacityScheduler.java:294)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.serviceInit(CapacityScheduler.java:323)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$RMActiveServices.serviceInit(ResourceManager.java:537)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.createAndInitActiveServices(ResourceManager.java:976)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.serviceInit(ResourceManager.java:239)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.yarn.server.MiniYARNCluster.initResourceManager(MiniYARNCluster.java:291)
	at org.apache.hadoop.yarn.server.MiniYARNCluster.access$400(MiniYARNCluster.java:95)
	at org.apache.hadoop.yarn.server.MiniYARNCluster$ResourceManagerWrapper.serviceInit(MiniYARNCluster.java:442)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:107)
	at org.apache.hadoop.yarn.server.MiniYARNCluster.serviceInit(MiniYARNCluster.java:267)
	at org.apache.hadoop.mapreduce.v2.MiniMRYarnCluster.serviceInit(MiniMRYarnCluster.java:183)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
{code}
A lot of tests failed due to 'Illegal capacity' exception"
MAPREDUCE-6129,Job failed due to counter out of limited in MRAppMaster,"Lots of of cluster's job use more than 120 counters, those kind of jobs  failed with exception like below
{noformat}
2014-10-15 22:55:43,742 WARN [Socket Reader #1 for port 45673] org.apache.hadoop.ipc.Server: Unable to read call parameters for client 10.180.216.12on connection protocol org.apache.hadoop.mapred.TaskUmbilicalProtocol for rpcKind RPC_WRITABLE
org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120
	at org.apache.hadoop.mapreduce.counters.Limits.checkCounters(Limits.java:103)
	at org.apache.hadoop.mapreduce.counters.Limits.incrCounters(Limits.java:110)
	at org.apache.hadoop.mapreduce.counters.AbstractCounterGroup.readFields(AbstractCounterGroup.java:175)
	at org.apache.hadoop.mapred.Counters$Group.readFields(Counters.java:324)
	at org.apache.hadoop.mapreduce.counters.AbstractCounters.readFields(AbstractCounters.java:314)
	at org.apache.hadoop.mapred.TaskStatus.readFields(TaskStatus.java:489)
	at org.apache.hadoop.mapred.ReduceTaskStatus.readFields(ReduceTaskStatus.java:140)
	at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:285)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invocation.readFields(WritableRpcEngine.java:157)
	at org.apache.hadoop.ipc.Server$Connection.processRpcRequest(Server.java:1802)
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1734)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1494)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:732)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:606)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:577)

{noformat}

The class org.apache.hadoop.mapreduce.counters.Limits load the mapred-site.xml on nodemanager node for JobConf if it hasn't been inited. 
If the mapred-site.xml on nodemanager node is not exist or the mapreduce.job.counters.max hasn't been defined on that file, Class org.apache.hadoop.mapreduce.counters.Limits will just  use the default value 120. 

Instead, we should read user job's conf file rather than config files on nodemanager for checking counters limits.

I will submitt a patch later.
"
MAPREDUCE-6126,"(Rumen) Rumen tool returns error ""ava.lang.IllegalArgumentException: JobBuilder.process(HistoryEvent): unknown event type""","java.lang.IllegalArgumentException: JobBuilder.process(HistoryEvent): unknown event type 
at org.apache.hadoop.tools.rumen.JobBuilder.process(JobBuilder.java:172) 
at org.apache.hadoop.tools.rumen.TraceBuilder.processJobHistory(TraceBuilder.java:305)
at org.apache.hadoop.tools.rumen.TraceBuilder.run(TraceBuilder.java:259) 
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70) 
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84) 
at org.apache.hadoop.tools.rumen.TraceBuilder.main(TraceBuilder.java:186) "
MAPREDUCE-6125,TestContainerLauncherImpl sometimes fails,"{noformat}
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.yarn.api.ContainerManagementProtocol$$EnhancerByMockitoWithCGLIB$$25708415.close()
	at java.lang.Class.getMethod(Class.java:1665)
	at org.apache.hadoop.yarn.factories.impl.pb.RpcClientFactoryPBImpl.stopClient(RpcClientFactoryPBImpl.java:90)
	at org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC.stopProxy(HadoopYarnProtoRPC.java:54)
	at org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.mayBeCloseProxy(ContainerManagementProtocolProxy.java:79)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.kill(ContainerLauncherImpl.java:225)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.shutdownAllContainers(ContainerLauncherImpl.java:320)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.serviceStop(ContainerLauncherImpl.java:331)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl.testMyShutdown(TestContainerLauncherImpl.java:315)
{noformat}"
MAPREDUCE-6123,TestCombineFileInputFormat incorrectly starts 2 MiniDFSCluster instances.,"{{TestCombineFileInputFormat#testGetSplitsWithDirectory}} starts 2 {{MiniDFSCluster}} instances, one right after the other, using the exact same configuration.  There is no need for 2 clusters in this test."
MAPREDUCE-6122,TestLineRecordReader may fail due to test data files checked out of git with incorrect line endings.,"{{TestLineRecordReader}} uses several test input files at src/test/resources/*.txt.  Some of the tests expect a specific length for the files, such as dealing with a record that spans multiple splits.  If they get checked out of git with CRLF line endings by mistake, then the test assertions will fail."
MAPREDUCE-6121,JobResourceUpdater#compareFs() doesn't handle HA namespaces,"Looking at the JobSubmitter.compareFs it doesn't look like it properly handles HA namespaces.  The code tries to lookup the hostname using InetAddress.getByName, but if you are using namespaces this is going to fail and its going to copy the file when it doesn't need to. 

Edit: JobSubmitter was updated to JobResourceUpdater in MAPREDUCE-6267."
MAPREDUCE-6120,TestPipeApplication fails on trunk,"TestPipeApplication asserts following case:
{code}
     assertTrue(out.toString().contains(
             ""-jt <local|ResourceManager:port>    specify a ResourceManager""));
{code}

The current shell script outputs not ResourceManager:port but resourcemanager:port."
MAPREDUCE-6115,TestPipeApplication#testSubmitter fails in trunk,"This can be reproduced locally:
{code}
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 4.89 sec <<< FAILURE! - in org.apache.hadoop.mapred.pipes.TestPipeApplication
testSubmitter(org.apache.hadoop.mapred.pipes.TestPipeApplication)  Time elapsed: 0.061 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(TestPipeApplication.java:310)
{code}"
MAPREDUCE-6114,TestMRCJCFileInputFormat#testAddInputPath fails in trunk,"This can be reproduced locally:
{code}
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.474 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat
testAddInputPath(org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat)  Time elapsed: 0.86 sec  <<< ERROR!
java.io.IOException: No FileSystem for scheme: s3
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2583)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2590)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2629)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169)
	at org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat.testAddInputPath(TestMRCJCFileInputFormat.java:55)
{code}"
MAPREDUCE-6113,An ability to override LocalResourceVisibility for public resources,"Currently it is impossible to specify APPLICATION level for files in distributed cache in YARN. For applications with big common data it is very crucial to have ability to share data only for application and do not spam public cache. Moreover, public localiser is limited for parallel downloads, so applications with big caches affect application startup of other applications.
Current logic is complicated and based on file permissions. Making proposed changes, user can override public level to any level (PUBLIC/APP/PRIVATE) without breaking anything, and ever not need to bother with permission, if private cache is needed.
"
MAPREDUCE-6110,JobHistoryServer CLI throws NullPointerException with job ids that do not exist,"When using JobHistoryServer CLI to query a job id that does not exist on the server, it may throw NullPointerException sometimes. 

I tried ""mapred job -events <some_wrong_jobId> 0 100"", and the result was:

Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.tools.CLI.listEvents(CLI.java:487)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:316)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1237)

Similar symptoms also appear with -list-attempt-ids, but were fine with -status and -set-priority. 

I traced back to CLI.listEvents, and line 487 is:
{code}
TaskCompletionEvent[] events = job.
      getTaskCompletionEvents(fromEventId, numEvents);
{code}
The job object is obtained from JobID.forName(jobid)) (line 316), which will return null if the job does not exist on server. 

Maybe we want to have some behaviors consistent with -status here, by simply reporting jobId does not exist? "
MAPREDUCE-6109,Fix minor typo in distcp -p usage text,"In the distcp usage for -p there needs to be a space added after ""-p"":

{quote}
the -p flag.Refer to the DistCp documentation for
{quote}"
MAPREDUCE-6108,ShuffleError OOM while reserving memory by MergeManagerImpl,"Shuffle has OOM issue from time to time.  

Such as this email reported.
http://mail-archives.apache.org/mod_mbox/hadoop-mapreduce-dev/201408.mbox/%3CCABWXXjNK-on0XTrMuriJD8SDGJjTAMSvQW2CZpm3oEkJ3YM8YQ@mail.gmail.com%3E"
MAPREDUCE-6106,hadoop-mapreduce-client-nativetask fails to compile on OS X,gtest isn't able to use it's built-in version of tuple.  See comments.
MAPREDUCE-6105,Inconsistent configuration in property mapreduce.reduce.shuffle.merge.percent,"Similar to MAPREDUCE-5906, In MergeManagerImpl.java, the default value of MRJobConfig.SHUFFLE_MERGE_PERCENT(mapreduce.reduce.shuffle.merge.percent) should be 0.66 
According to official doc.
https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml

{code}
    this.mergeThreshold = (long)(this.memoryLimit * 
                          jobConf.getFloat(MRJobConfig.SHUFFLE_MERGE_PERCENT, 
                                           0.90f));

{code}"
MAPREDUCE-6104,TestJobHistoryParsing.testPartialJob fails in branch-2,"TestJobHistoryParsing.testPartialJob intermittently fails with the following timeout error.

{noformat}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.239 sec <<<
FAILURE! - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
testPartialJob(org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing)  Time
elapsed: 1.025 sec  <<< ERROR!
java.lang.Exception: test timed out after 1000 milliseconds
    at java.util.zip.Inflater.inflateBytes(Native Method)
    at java.util.zip.Inflater.inflate(Inflater.java:259)
    at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:152)
    at sun.misc.Resource.getBytes(Resource.java:124)
    at java.net.URLClassLoader.defineClass(URLClassLoader.java:444)
    at java.net.URLClassLoader.access$100(URLClassLoader.java:71)
    at java.net.URLClassLoader$1.run(URLClassLoader.java:361)
    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
    at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
    at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
    at
org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
    at
org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:257)
    at
org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:234)
    at
org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:773)
    at
org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:758)
    at
org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:631)
    at
org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testPartialJob(TestJobHistoryParsing.java:824)


Results :

Tests in error: 
  TestJobHistoryParsing.testPartialJob:824 »  test timed out after 1000
millisec...

Tests run: 1, Failures: 0, Errors: 1, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
{noformat}"
MAPREDUCE-6103,Adding reservation APIs to resource manager delegate,YARN-1051 introduces the ReservationSystem and the corresponding APIs for create/update/delete ops. The MR resource manager delegate needs to to be updated with the APIs.
MAPREDUCE-6100,"replace ""mapreduce.job.credentials.binary"" with MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY for better readability.","replace ""mapreduce.job.credentials.binary"" with MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY for better readability."
MAPREDUCE-6099,"Adding  getSplits(JobContext job, List<FileStatus> stats) to mapreduce CombineFileInputFormat","Currently we have getSplits(JobContext job) in CombineFileInputFormat. 
This api does not give freedom to the client to create a list if file status it self and then create splits on the resultant List<FileStatus> stats.
The client might be able to perform some filtering on its end on the File sets in the input paths. For the reasons, above it would be a good idea to have getSplits(JobContext, List<FileStatus>).
Please let me know what you think about this.

"
MAPREDUCE-6098,org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat intermittently failed in trunk,See: https://issues.apache.org/jira/browse/YARN-611?focusedCommentId=14129761&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14129761 for details
MAPREDUCE-6095,Enable DistributedCache for uber-mode Jobs,mapreduce.job.cache.local.* is not set for uber-mode jobs. TestUberAM hides the fact that DC files are not available for uber-mode jobs by overriding testDistributedCache with a nop method. 
MAPREDUCE-6094,TestMRCJCFileInputFormat.testAddInputPath() fails on trunk,"{noformat}
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.624 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat
testAddInputPath(org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat)  Time elapsed: 0.886 sec  <<< ERROR!
java.io.IOException: No FileSystem for scheme: s3
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2583)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2590)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:91)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2629)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2611)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:370)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:169)
	at org.apache.hadoop.mapreduce.lib.input.TestMRCJCFileInputFormat.testAddInputPath(TestMRCJCFileInputFormat.java:55)
{noformat}"
MAPREDUCE-6093,minor distcp doc edits,Minor edits to DistCp.md.vm
MAPREDUCE-6092,TestJobHistoryParsing#testPartialJob timeouts in some environments,"Rebasing the patch in MAPREDUCE-5392, I found TestJobHistoryParsing#testPartialJob timeout in my environments.
{code}
Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
Tests run: 15, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 106.007 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing
testPartialJob(org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing)  Time elapsed: 0.987 sec  <<< ERROR!
java.lang.Exception: test timed out after 1000 milliseconds
        at org.apache.xerces.impl.XMLEntityScanner.scanQName(Unknown Source)
        at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
        at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
        at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
        at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
        at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)
        at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)
        at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:150)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2334)
        at org.apache.hadoop.conf.Configuration.parse(Configuration.java:2322)
        at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2393)
        at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:2346)
        at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2263)
        at org.apache.hadoop.conf.Configuration.get(Configuration.java:868)
        at org.apache.hadoop.conf.Configuration.getTrimmed(Configuration.java:887)
        at org.apache.hadoop.conf.Configuration.getBoolean(Configuration.java:1288)
        at org.apache.hadoop.security.SecurityUtil.<clinit>(SecurityUtil.java:70)
        at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:247)
        at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:235)
        at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:761)
        at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:746)
        at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:619)
        at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testPartialJob(TestJobHistoryParsing.java:829)
{code}
We should extend the timeout not to fail the test in slow machines."
MAPREDUCE-6091,YARNRunner.getJobStatus() fails with ApplicationNotFoundException if the job rolled off the RM view,"If you query the job status of a job that rolled off the RM view via YARNRunner.getJobStatus(), it fails with an ApplicationNotFoundException. For example,

{noformat}
2014-09-15 07:09:51,084 ERROR org.apache.pig.tools.grunt.Grunt: ERROR 6017: JobID: job_1410289045532_90542 Reason: java.io.IOException: org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException: Application with id 'application_1410289045532_90542' doesn't exist in RM.
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getApplicationReport(ClientRMService.java:288)
	at org.apache.hadoop.yarn.api.impl.pb.service.ApplicationClientProtocolPBServiceImpl.getApplicationReport(ApplicationClientProtocolPBServiceImpl.java:150)
	at org.apache.hadoop.yarn.proto.ApplicationClientProtocol$ApplicationClientProtocolService$2.callBlockingMethod(ApplicationClientProtocol.java:337)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2058)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2054)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1547)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2052)

	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:348)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:419)
	at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:559)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:314)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:311)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1547)
	at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:311)
	at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:599)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.checkRunningState(ControlledJob.java:257)
	at org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.checkState(ControlledJob.java:282)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.pig.backend.hadoop23.PigJobControl.checkState(PigJobControl.java:120)
	at org.apache.pig.backend.hadoop23.PigJobControl.run(PigJobControl.java:180)
	at java.lang.Thread.run(Thread.java:662)
	at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:279)
{noformat}

Prior to 2.1.0, it used to be able to fall back onto the job history server and get the status.

This appears to be introduced by YARN-873. YARN-873 changed ClientRMService to throw an ApplicationNotFoundException on an unknown app id (from returning null). But MR's ClientServiceDelegate was never modified to change its behavior."
MAPREDUCE-6090,mapred hsadmin getGroups fails to connect in some cases,"If you do {{mapred hsadmin -getGroups}} it works fine (assuming {{mapreduce.jobhistory.admin.address}} is set properly in mapred-site.xml).  

But if you do {{mapred hsadmin -getGroups foo_user}}, it will keep retrying to connect to localhost:
{noformat}
INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:10033. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
...
{noformat}"
MAPREDUCE-6088,TestTokenCache tests should use their own JobConf instances,"TestTokenCache in mrv1 (branch-1) depend on the order of test execution. testLocalJobTokenCache will fail if it executed after testTokenCache.
The reason is because testLocalJobTokenCache depends on the jConf setup by testTokenCache.
The fix is to set up the JobConf separately for testLocalJobTokenCache and testTokenCache.

See the following test result.
{noformat}
Testcase: testLocalJobTokenCache took 1.197 sec
	FAILED
local Job failed
junit.framework.AssertionFailedError: local Job failed
	at org.apache.hadoop.mapreduce.security.TestTokenCache.testLocalJobTokenCache(TestTokenCache.java:258)
Testcase: testGetTokensForNamenodes took 0.003 sec
Testcase: testGetTokensForUriWithoutAuth took 0.01 sec
Testcase: testCleanUpTokenReferral took 0.014 sec
Testcase: testTokenCache took 13.316 sec
{noformat}"
MAPREDUCE-6087,MRJobConfig#MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS config name is wrong,"The config name for MRJobConfig#MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS now has double prefix as ""yarn.app.mapreduce."" + ""yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts"""
MAPREDUCE-6086,mapreduce.job.credentials.binary should allow all URIs,"Change ""mapreduce.job.credentials.binary"" configuration to handle all URIs properly.
The current ""mapreduce.job.credentials.binary"" configuration only support local fs, It would be better to make it support non-local FS URIs."
MAPREDUCE-6081,MapReduce should take cpu into account when doing headroom calculations,Currently the MapReduce AM only uses memory when doing headroom calculation as well calculations about launching reducers. It would be preferable to account for CPU as well if the scheduler on the YARN side is using CPU when scheduling. YARN-2448 lets AMs know what resources are being considered when scheduling.
MAPREDUCE-6079,Rename JobImpl#username to reporterUserName,"On MAPREDUCE-6033, we found the bug because of confusing field names {{userName}} and {{username}}. We should change the names to distinguish them easily. "
MAPREDUCE-6078,native-task: fix gtest build on macosx,"Try compile the HEAD code in macos but failed, looks like MAPREDUCE-5977 separate gtest compile from nttest in order to surpress compile warnings, but it forget to add addition compile flags added to nttest is also required for  gtest build, this patch fix this. "
MAPREDUCE-6077,Remove CustomModule examples in nativetask,"Currently, we don't need to support custom key types. So, this module can be removed for now."
MAPREDUCE-6076,Zero map split input length combine with none zero  map split input length may cause MR1 job hung sometimes. ,"Zero map split input length combine with none zero map split input length may cause MR1 job hung sometimes.
This problem may happen when use HBASE input split(TableSplit).
HBASE split input length can be zero for unknown regions or non-zero for known regions in the following code:
{code}
// TableSplit.java
public long getLength() {
    return length;
  }

// RegionSizeCalculator.java
public long getRegionSize(byte[] regionId) {
    Long size = sizeMap.get(regionId);
    if (size == null) {
      LOG.debug(""Unknown region:"" + Arrays.toString(regionId));
      return 0;
    } else {
      return size;
    }
  }
{code}
The TableSplit length come from RegionSizeCalculator.getRegionSize.

The job hung is because in MR1,
If these zero split input length map tasks are scheduled and completed before all none zero split input length map tasks are scheduled,
Scheduling new map task in JobProgress.java will be failed to pass the TaskTracker resources check at.
{code}
// findNewMapTask
    // Check to ensure this TaskTracker has enough resources to 
    // run tasks from this job
    long outSize = resourceEstimator.getEstimatedMapOutputSize();
    long availSpace = tts.getResourceStatus().getAvailableSpace();
    if(availSpace < outSize) {
      LOG.warn(""No room for map task. Node "" + tts.getHost() + 
               "" has "" + availSpace + 
               "" bytes free; but we expect map to take "" + outSize);

      return -1; //see if a different TIP might work better. 
    }
{code}
The resource calculation is at
{code}
// in ResourceEstimator.java
protected synchronized long getEstimatedTotalMapOutputSize()  {
    if(completedMapsUpdates < threshholdToUse) {
      return 0;
    } else {
      long inputSize = job.getInputLength() + job.desiredMaps(); 
      //add desiredMaps() so that randomwriter case doesn't blow up
      //the multiplication might lead to overflow, casting it with
      //double prevents it
      long estimate = Math.round(((double)inputSize * 
          completedMapsOutputSize * 2.0)/completedMapsInputSize);
      if (LOG.isDebugEnabled()) {
        LOG.debug(""estimate total map output will be "" + estimate);
      }
      return estimate;
    }
  }
protected synchronized void updateWithCompletedTask(TaskStatus ts, 
      TaskInProgress tip) {

    //-1 indicates error, which we don't average in.
    if(tip.isMapTask() &&  ts.getOutputSize() != -1)  {
      completedMapsUpdates++;

      completedMapsInputSize+=(tip.getMapInputSize()+1);
      completedMapsOutputSize+=ts.getOutputSize();

      if(LOG.isDebugEnabled()) {
        LOG.debug(""completedMapsUpdates:""+completedMapsUpdates+""  ""+
                  ""completedMapsInputSize:""+completedMapsInputSize+""  "" +
                  ""completedMapsOutputSize:""+completedMapsOutputSize);
      }
    }
  }
{code}
You can see in the calculation:
completedMapsInputSize will be a very small number and inputSize * 
          completedMapsOutputSize  will be a very big number
For example, completedMapsInputSize = 1; inputSize = 100MBytes and  completedMapsOutputSize=100MBytes,
The estimate will be 5000TB which will be more than most task tracker disk space size.

So I think if the map split input length is 0, it means the split input length is unknown and it is reasonable to use map output size as input size for the calculation in ResourceEstimator. I will upload a fix based on this method."
MAPREDUCE-6075,HistoryServerFileSystemStateStore can create zero-length files,When the history server state store writes a token file it uses IOUtils.cleanup() to close the file which will silently ignore errors.  This can lead to empty token files in the state store.
MAPREDUCE-6074,"native-task: fix release audit, javadoc, javac warnings",RAT is showing some release audit warnings. They all look spurious - just need to do a little cleanup and add excludes
MAPREDUCE-6073,Description of mapreduce.job.speculative.slowtaskthreshold in mapred-default should be moved into description tags,"Currently, description of mapreduce.job.speculative.slowtaskthreshold in mapred-default is put outside of description tags. We should move it into description tags.

{code}
<property>
  <name>mapreduce.job.speculative.slowtaskthreshold</name>
  <value>1.0</value>The number of standard deviations by which a task's 
  ave progress-rates must be lower than the average of all running tasks'
  for the task to be considered too slow.
  <description>
  </description>
</property>
{code}"
MAPREDUCE-6072,Remove INSTALL document,"""./hadoop-mapreduce-project/INSTALL"" has become stale. The document shows
* svn as SCM, now we use git
* ant to compile hadoop-mapreduce-examples

The document should be updated to link BUILDING.txt and web docs."
MAPREDUCE-6071,JobImpl#makeUberDecision doesn't log that Uber mode is disabled because of too much CPUs,"JobImpl#makeUberDecision usually logs why the Job cannot be launched as Uber mode(e.g. ""too much RAM;"" or something).  About CPUs, it's not logged currently. We should log it when ""too much CPU""."
MAPREDUCE-6070,yarn.app.am.resource.mb/cpu-vcores affects uber mode but is not documented,"We should document the condition when uber mode is enabled. Currently, users need to read following code to understand the condition.

{code}
    boolean smallMemory =
        ( (Math.max(conf.getLong(MRJobConfig.MAP_MEMORY_MB, 0),
            conf.getLong(MRJobConfig.REDUCE_MEMORY_MB, 0))
            <= sysMemSizeForUberSlot)
            || (sysMemSizeForUberSlot == JobConf.DISABLED_MEMORY_LIMIT));
   boolean smallCpu =
            Math.max(
                conf.getInt(
                    MRJobConfig.MAP_CPU_VCORES, 
                    MRJobConfig.DEFAULT_MAP_CPU_VCORES), 
                conf.getInt(
                    MRJobConfig.REDUCE_CPU_VCORES, 
                    MRJobConfig.DEFAULT_REDUCE_CPU_VCORES)) 
             <= sysCPUSizeForUberSlot
{code}"
MAPREDUCE-6069,native-task: Style fixups and dead code removal,"A few more cleanup things we should address:
- fix style issues (eg lines too long, bad indentation, commented-out code blocks, etc) both in Java and C++
- Found a few pieces of unused code by running a coverage tool. We should remove them"
MAPREDUCE-6068,Illegal progress value warnings in map tasks,"When running a terasort on latest trunk, I see the following in my task logs:

{code}
2014-09-02 17:42:28,437 INFO [main] org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2014-09-02 17:42:42,238 WARN [main] org.apache.hadoop.util.Progress: Illegal progress value found, progress is larger than 1. Progress will be changed to 1
2014-09-02 17:42:42,238 WARN [main] org.apache.hadoop.util.Progress: Illegal progress value found, progress is larger than 1. Progress will be changed to 1
2014-09-02 17:42:42,241 INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
{code}

We should eliminate these warnings."
MAPREDUCE-6067,native-task: fix some counter issues,"After running a terasort, I see the spilled records counter at 5028651606, which is about half what I expected to see. Using the non-native collector I see the expected count of 10000000000. It seems the correct number of records were indeed spilled, because the job's output record count is correct."
MAPREDUCE-6066,Speculative attempts should not run on the same node as their original attempt,"I'm seeing a behavior on trunk with fair scheduler enabled where a speculative reduce attempt is getting run on the same node as its original attempt. This doesn't make sense -- the main reason for speculative execution is to deal with a slow node, so scheduling a second attempt on the same node would just make the problem worse if anything."
MAPREDUCE-6065,native-task: warnings about illegal Progress values,"In running terasort tests, I see a few warnings like this:
2014-09-02 18:50:34,623 WARN [main] org.apache.hadoop.util.Progress: Illegal progress value found, progress is larger than 1. Progress will be changed to 1

It sounds like we're improperly calculating task progress somewhere. We should fix this."
MAPREDUCE-6063,"In sortAndSpill of MapTask.java, size is calculated wrongly when bufend < bufstart.","In sortAndSpill of MapTask.java, size is calculated wrongly when bufend < bufstart.  we should change (bufvoid - bufend) + bufstart to (bufvoid - bufstart) + bufend.
Should change
{code}
     long size = (bufend >= bufstart
          ? bufend - bufstart
          : (bufvoid - bufend) + bufstart) +
                  partitions * APPROX_HEADER_LENGTH;
{code}
to:
{code}
     long size = (bufend >= bufstart
          ? bufend - bufstart
          : (bufvoid - bufstart) + bufend) +
                  partitions * APPROX_HEADER_LENGTH;
{code}

It is because when wraparound happen (bufend < bufstart) ,  the size should 
bufvoid - bufstart (bigger one) + bufend(small one).
You can find similar code implementation in MapTask.java:
{code}
        mapOutputByteCounter.increment(valend >= keystart
            ? valend - keystart
            : (bufvoid - keystart) + valend);
{code}
"
MAPREDUCE-6061,Fix MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS property in MRJobConfig,"The property MR_CLIENT_TO_AM_IPC_MAX_RETRIES_ON_TIMEOUTS is defined as:

  MR_PREFIX + ""yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts""

which results in the prefix part showing up twice.  It should be

  MR_PREFIX + ""client-am.ipc.max-retries-on-timeouts""
"
MAPREDUCE-6059,Speed up history server startup time,"When history server starts up, It scans every history directories and put all history files into a cache, whereas this cache only stores 20K recent history files. Therefore, it is wasting a large portion of time loading old history files into the cache, and the startup time will keep increasing if we don't trim the number of history files. For example, when history server starts up with 2.5M history files in HDFS, it took ~5 minutes."
MAPREDUCE-6058,native-task: KVTest and LargeKVTest should check mr job is sucessful,"When running KVTest and LargeKVTest, if the job failed for some reason(lack libhadoop.so etc), both native and normal job failed, and both compare empty output directory, so the test passes without noticing failure.
"
MAPREDUCE-6057,Remove obsolete entries from mapred-default.xml,"The following properties are defined in mapred-default.xml but no longer exist in MRJobConfig.

  map.sort.class
  mapred.child.env
  mapred.child.java.opts
  mapreduce.app-submission.cross-platform
  mapreduce.client.completion.pollinterval
  mapreduce.client.output.filter
  mapreduce.client.progressmonitor.pollinterval
  mapreduce.client.submit.file.replication
  mapreduce.cluster.acls.enabled
  mapreduce.cluster.local.dir
  mapreduce.framework.name
  mapreduce.ifile.readahead
  mapreduce.ifile.readahead.bytes
  mapreduce.input.fileinputformat.list-status.num-threads
  mapreduce.input.fileinputformat.split.minsize
  mapreduce.input.lineinputformat.linespermap
  mapreduce.job.counters.limit
  mapreduce.job.max.split.locations
  mapreduce.job.reduce.shuffle.consumer.plugin.class
  mapreduce.jobhistory.address
  mapreduce.jobhistory.admin.acl
  mapreduce.jobhistory.admin.address
  mapreduce.jobhistory.cleaner.enable
  mapreduce.jobhistory.cleaner.interval-ms
  mapreduce.jobhistory.client.thread-count
  mapreduce.jobhistory.datestring.cache.size
  mapreduce.jobhistory.done-dir
  mapreduce.jobhistory.http.policy
  mapreduce.jobhistory.intermediate-done-dir
  mapreduce.jobhistory.joblist.cache.size
  mapreduce.jobhistory.keytab
  mapreduce.jobhistory.loadedjobs.cache.size
  mapreduce.jobhistory.max-age-ms
  mapreduce.jobhistory.minicluster.fixed.ports
  mapreduce.jobhistory.move.interval-ms
  mapreduce.jobhistory.move.thread-count
  mapreduce.jobhistory.principal
  mapreduce.jobhistory.recovery.enable
  mapreduce.jobhistory.recovery.store.class
  mapreduce.jobhistory.recovery.store.fs.uri
  mapreduce.jobhistory.store.class
  mapreduce.jobhistory.webapp.address
  mapreduce.local.clientfactory.class.name
  mapreduce.map.skip.proc.count.autoincr
  mapreduce.output.fileoutputformat.compress
  mapreduce.output.fileoutputformat.compress.codec
  mapreduce.output.fileoutputformat.compress.type
  mapreduce.reduce.skip.proc.count.autoincr
  mapreduce.shuffle.connection-keep-alive.enable
  mapreduce.shuffle.connection-keep-alive.timeout
  mapreduce.shuffle.max.connections
  mapreduce.shuffle.max.threads
  mapreduce.shuffle.port
  mapreduce.shuffle.ssl.enabled
  mapreduce.shuffle.ssl.file.buffer.size
  mapreduce.shuffle.transfer.buffer.size
  mapreduce.shuffle.transferTo.allowed
  yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts

Submitting bug for comment/feedback about which properties should be kept in mapred-default.xml."
MAPREDUCE-6056,nativetask: move system test working dir to target dir and cleanup test config xml files,
MAPREDUCE-6055,"native-task: findbugs, interface annotations, and other misc cleanup","A few items which we need to address before merge:
- fix findbugs errors
- add interface and stability annotations to all public classes
- fix eclipse warnings where possible"
MAPREDUCE-6054,native-task: speed up test runs,Currently the KVTest compatibility test takes so long on my machine that it regularly times out maven. We should speed it up.
MAPREDUCE-6052,Support overriding log4j.properties per job,"For current MR application, the ""log4j.configuration"" is hard coded to container-log4j.properties within each node. We still need flexibility to override it per job like what we do in MRV1.
{code}
  public static void addLog4jSystemProperties(
      String logLevel, long logSize, int numBackups, List<String> vargs) {
    vargs.add(""-Dlog4j.configuration=container-log4j.properties"");
{code}"
MAPREDUCE-6051,Fix typos in log messages,"There are a bunch of typos in log messages. HADOOP-10946 was initially created, but may have failed due to being in multiple components. Try fixing typos on a per-component basis."
MAPREDUCE-6050,Upgrade JUnit3 TestCase to JUnit 4,There are still test classes that extend from junit.framework.TestCase. upgrade them to JUnit4.
MAPREDUCE-6049,AM JVM does not exit if MRClientService gracefull shutdown fails,"Eventhough job got FAILED, AM process still not exiting

ThreadDump of AM process is below
{noformat}
""Job Fail Wait Timeout Monitor #0"" daemon prio=10 tid=0x0000000000aa9000 nid=0x41fa waiting on condition [0x00007f0e0d1d0000]
   java.lang.Thread.State: WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000c104c688> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1079)
	at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
	at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
{noformat}"
MAPREDUCE-6048,TestJavaSerialization fails in trunk build,"This happened in builds #1871 and #1872
{code}
testMapReduceJob(org.apache.hadoop.mapred.TestJavaSerialization)  Time elapsed: 2.784 sec  <<< FAILURE!
junit.framework.ComparisonFailure: expected:<[a	]1> but was:<[0	1]1>
	at junit.framework.Assert.assertEquals(Assert.java:100)
	at junit.framework.Assert.assertEquals(Assert.java:107)
	at junit.framework.TestCase.assertEquals(TestCase.java:269)
	at org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob(TestJavaSerialization.java:127)
{code}"
MAPREDUCE-6047,Introduce localization phase for mapreduce jobs,"we have been experienced lots of task timeout due to localization of a large number of files. It would be great if we have an additional phase that keep track of how many files have been localized. Thus for Mappers we had ""localization"", ""map"", ""sort"". For backwards compatibility, we can keep it 0% but still heartbeat to AM with the status string ""5/300 files localized""."
MAPREDUCE-6046,Change the class name for logs in RMCommunicator.java,"It is little confusing when the logs gets generated with the class name as RMContainerAllocator and not present in RMContainerAllocator.java.
{code:title=RMCommunicator.java|borderStyle=solid}

  private static final Log LOG = LogFactory.getLog(RMContainerAllocator.class);

{code}

In the above RMContainerAllocator.class needs to be changed to RMCommunicator.class.
"
MAPREDUCE-6045,need close the DataInputStream after open it in TestMapReduce.java,"In TestMapReduce.java, we didn't close the DataInputStream after open it in isSequenceFile.
"
MAPREDUCE-6044,Fully qualified intermediate done directory will break per-user dir creation on Windows,"After MAPREDUCE-6032, the string of the intermediate done dir will be a fully qualified path.

The following code in JobHistoryUtils tries to concat this path and user name to create a per-user dir path, using File.separator as the seperator (on Windows, it is ""\"").

{code}
  public static String getHistoryIntermediateDoneDirForUser(Configuration conf) throws IOException {
    return getConfiguredHistoryIntermediateDoneDirPrefix(conf) + File.separator
        + UserGroupInformation.getCurrentUser().getShortUserName();
  }
{code}

Therefore, an intermediate done dir for user will become ""hdfs://localhost:9201/mapred/history/done_intermediate\user"". With the scheme available in the path, Path class will not replace ""\"" with ""/"", and finally FS cannot handle this path correctly: it will take ""done_intermediateuser"" as a single directory name."
MAPREDUCE-6043,Lost messages from RM to MRAppMaster,"We have seen various cases that reducer-preemption does not kick in and the scheduled mappers wait behind running reducers forever. Each time there seems to be a different scenario. So far we have tracked down two of such cases and the common element between them is that the variables in RMContainerAllocator go out of sync since they only get updated when completed container is reported by RM. However there are many corner cases that such report is not received from RM and yet the MapReduce app moves forward. Perhaps one possible fix would be to update such variables also after exceptional cases.

The logic for triggering preemption is at RMContainerAllocator::preemptReducesIfNeeded
The preemption is triggered if the following is true:
{code}
headroom +  am * |m| + pr * |r| < mapResourceRequest
{code} 
where am: number of assigned mappers, |m| is mapper size, pr is number of reducers being preempted, and |r| is the reducer size. Each of these variables going out of sync will cause the preemption not to kick in. In the following comment, we explain two of such cases."
MAPREDUCE-6041,Fix TestOptionsParser,"Error Message

expected:<...argetPathExists=true[]}> but was:<...argetPathExists=true[, preserveRawXattrs=false]}>

Stacktrace

org.junit.ComparisonFailure: expected:<...argetPathExists=true[]}> but was:<...argetPathExists=true[, preserveRawXattrs=false]}>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.tools.TestOptionsParser.testToString(TestOptionsParser.java:361)
"
MAPREDUCE-6039,mapreduce.v2.hs.webapp.dao.TestJobInfo is using old name of job history file,"In the file: org.apache.hadoop.mapreduce.v2.hs.webapp.dao.TestJobInfo.java, there's an example job history file named ""job_1329348432655_0001-1329348443227-user-Sleep+job-1329348468601-10-1-SUCCEEDED-default.jhist""; 
This name is no longer valid since the change of MAPREDUCE-5052, which added the ""startTime"" of the job to the end of the job history file name, which makes the name should be like: job_1329348432655_0001-1329348443227-user-Sleep+job-1329348468601-10-1-SUCCEEDED-default-1329348448308.jhist

The code in TestJobInfo.java: {code}
public void testAverageMergeTime() throws IOException {
    String historyFileName =
        ""job_1329348432655_0001-1329348443227-user-Sleep+job-1329348468601-10-1-SUCCEEDED-default.jhist"";
    String confFileName =
        ""job_1329348432655_0001_conf.xml"";
    Configuration conf = new Configuration();
    JobACLsManager jobAclsMgr = new JobACLsManager(conf);
    Path fulleHistoryPath =
        new Path(TestJobHistoryEntities.class.getClassLoader()
            .getResource(historyFileName)
            .getFile());
    Path fullConfPath =
        new Path(TestJobHistoryEntities.class.getClassLoader()
            .getResource(confFileName)
            .getFile());

    HistoryFileInfo info = mock(HistoryFileInfo.class);
    when(info.getConfFile()).thenReturn(fullConfPath);

    JobId jobId = MRBuilderUtils.newJobId(1329348432655l, 1, 1);
    CompletedJob completedJob =
        new CompletedJob(conf, jobId, fulleHistoryPath, true, ""user"",
            info, jobAclsMgr);
    JobInfo jobInfo = new JobInfo(completedJob);
    // There are 2 tasks with merge time of 45 and 55 respectively. So average
    // merge time should be 50.
    Assert.assertEquals(50L, jobInfo.getAvgMergeTime().longValue());
  }
{code}"
MAPREDUCE-6038,A boolean may be set error in the Word Count v2.0 in MapReduce Tutorial,"As a beginner, when I learned about the basic of the mr, I found that I cound't run the WordCount2 using the command ""bin/hadoop jar wc.jar WordCount2 /user/joe/wordcount/input /user/joe/wordcount/output"" in the Tutorial. The VM throwed the NullPoniterException at the line 47. In the line 45, the returned default value of ""conf.getBoolean"" is true. That is to say  when ""wordcount.skip.patterns"" is not set ,the WordCount2 will continue to execute getCacheFiles.. Then patternsURIs gets the null value. When the ""-skip"" option dosen't exist,  ""wordcount.skip.patterns"" will not be set. Then a NullPointerException come out.
At all, the block after the if-statement in line no. 45 shoudn't be executed when the ""-skip"" option dosen't exist in command. Maybe the line 45 should like that  ""if (conf.getBoolean(""wordcount.skip.patterns"", false)) { ""
.Just change the boolean."
MAPREDUCE-6036,TestJobEndNotifier fails intermittently in branch-2,"I have seen TestJobEndNotifier#testNotificationOnLastRetryUnregistrationFailure
failing in branch-2 intermittently. I ran the test on my machine and it fails
3 in 10 times.

This is how the test fails.

{noformat}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 8.472 sec <<<
FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier
testNotificationOnLastRetryUnregistrationFailure(org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier)
 Time elapsed: 8.389 sec  <<< FAILURE!
java.lang.AssertionError: expected:<0> but was:<1>
    at org.junit.Assert.fail(Assert.java:88)
    at org.junit.Assert.failNotEquals(Assert.java:743)
    at org.junit.Assert.assertEquals(Assert.java:118)
    at org.junit.Assert.assertEquals(Assert.java:555)
    at org.junit.Assert.assertEquals(Assert.java:542)
    at
org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier.testNotificationOnLastRetryUnregistrationFailure(TestJobEndNotifier.java:276)


Results :

Failed tests: 
  TestJobEndNotifier.testNotificationOnLastRetryUnregistrationFailure:276
expected:<0> but was:<1>

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
{noformat}"
MAPREDUCE-6035,native-task: sources/test-sources jar distribution,nativetask sources jar and test-sources jar should be distributed like other modules under hadoop-mapreduce-project
MAPREDUCE-6033,"Users are not allowed to view their own jobs, denied by JobACLsManager","Have a Hadoop 2.4.1 cluster with Yarn ACL enabled, and try to submit jobs as a non-admin user user1. The job could be finished successfully, but the running progress was not displayed correctly on the command-line, and I got following in the corresponding ApplicationMaster log:
INFO [IPC Server handler 0 on 56717] org.apache.hadoop.ipc.Server: IPC Server handler 0 on 56717, call org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB.getJobReport from 9.30.95.26:61024 Call#59 Retry#0
org.apache.hadoop.security.AccessControlException: User user1 cannot perform operation VIEW_JOB on job_1407456690588_0003
	at org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.verifyAndGetJob(MRClientService.java:191)
	at org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getJobReport(MRClientService.java:233)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getJobReport(MRClientProtocolPBServiceImpl.java:122)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:275)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(AccessController.java:366)
	at javax.security.auth.Subject.doAs(Subject.java:572)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1567)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
"
MAPREDUCE-6032,Unable to check mapreduce job status if submitted using a non-default namenode,"When MRv2 job container runs in a context of non-default file system JobHistoryUtils.java obtains mapreduce.jobhistory.done-dir and
 mapreduce.jobhistory.intermediate-done-dir as a non-qualified paths (e.g. /mapred/history). This path is considered to belong to the current container's context. As result the application history is being written to another file system and job history server is unable to pick it up, because it expects it to be found on the default file system. Currently providing fully qualified path to those parameters is not supported as well, because of a bug in JobHistoryEventHandler.

After this fix two scenarios will be supported:
- mapreduce.jobhistory.done-dir and mapreduce.jobhistory.intermediate-done-dir (and the staging directory BTW) will support a fully qualified path
- If a non-qualified path is configured then it will always be defaulted to the default file system (core-site.xml). That's how consistency of history location will be archived

Implementation notes:
 - FileSystem#makeQualified throws exception if specified path belongs to another file system. However FileContext#makeQualified work properly in this case, and this is the meaning of the fix in JobHistoryEventHandler. I was not ready to change behavior FileSystem#makeQualified because much more thought is required. I afraid that many users expect such behavior, and fixing it would break their code.
- The fix in JobHistoryUtils detects non-default namenode configuration only if it comes from some ""real"" configuration: core-default.xml is ignored. This is done primary as a kind of test hook, because otherwise setting fs.defaultFS value during test executions would be always recognized by  JobHistoryUtils  as a non-default namenode against 'file:///' specified in core-default.xml. 

(Remark. Note that makeQualified doesn't behave properly with file:/// filesystem, for example:
new Path(""file:///dir/subdir"").makeQualified(new URI(""hdfs://server:8020""), new Path(""/dir""))
Returns: ""file://server:8020/dir/subdir"" which doesn't make sense.
However I don't believe it worth fixing, since nobody really case about local file system besides tests. My fix just ensures that all tests run smoothly by ignoring core-default.xml file system in the logic.)


"
MAPREDUCE-6029,TestCommitterEventHandler fails in trunk,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1857/console :
{code}
Running org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.429 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler
testFailure(org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler)  Time elapsed: 1.198 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertNotNull(Assert.java:621)
	at org.junit.Assert.assertNotNull(Assert.java:631)
	at org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.testFailure(TestCommitterEventHandler.java:314)
{code}"
MAPREDUCE-6028,java.lang.ArithmeticException: / by zero,"Run any sql through hive with following 
error message:
2014-08-07 10:22:28,061 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_201407251033_24476_m_000002_0: Error initializing attempt_201407251033_24476_m_000002_0:
java.lang.ArithmeticException: / by zero

and after restart hadoop cluster,the problem resolved。how to find the root casue for the problem? thks。"
MAPREDUCE-6026,native-task: fix logging,nativetask should use commons-logging and add log4j.properties in test configuration as per hadoop standard
MAPREDUCE-6025,native-task: fix native library distribution,"currently running ""mvn install -Pdist"" fails and nativetask native library is not distributed to hadoop tar"
MAPREDUCE-6024,java.net.SocketTimeoutException in Fetcher caused jobs stuck for more than 1 hour,"2014-08-04 21:09:42,356 WARN fetcher#33 org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to fake.host.name:13562 with 2 map outputs
java.net.SocketTimeoutException: Read timed out
at java.net.SocketInputStream.socketRead0(Native Method)
at java.net.SocketInputStream.read(SocketInputStream.java:129)
at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:697)
at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:640)
at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1195)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:289)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:165)
2014-08-04 21:09:42,360 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: fake.host.name:13562 freed by fetcher#33 in 180024ms
2014-08-04 21:09:55,360 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning fake.host.name:13562 with 3 to fetcher#33
2014-08-04 21:09:55,360 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 3 of 3 to fake.host.name:13562 to fetcher#33
2014-08-04 21:12:55,463 WARN fetcher#33 org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to fake.host.name:13562 with 3 map outputs
java.net.SocketTimeoutException: Read timed out
at java.net.SocketInputStream.socketRead0(Native Method)
at java.net.SocketInputStream.read(SocketInputStream.java:129)
at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:697)
at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:640)
at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1195)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:289)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:165)
...
2014-08-04 22:03:13,416 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: fake.host.name:13562 freed by fetcher#33 in 271081ms
2014-08-04 22:04:13,417 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning fake.host.name:13562 with 3 to fetcher#33
2014-08-04 22:04:13,417 INFO fetcher#33 org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned 3 of 3 to fake.host.name:13562 to fetcher#33
2014-08-04 22:07:13,449 WARN fetcher#33 org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to fake.host.name:13562 with 3 map outputs
java.net.SocketTimeoutException: Read timed out
at java.net.SocketInputStream.socketRead0(Native Method)
at java.net.SocketInputStream.read(SocketInputStream.java:129)
at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:697)
at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:640)
at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1195)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:289)
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:165)"
MAPREDUCE-6022,map_input_file is missing from streaming job environment,"When running a streaming job the 'map_input_file' environment variable is not being set.  This property is deprecated, but in the past deprecated properties still appeared in a stream job's environment."
MAPREDUCE-6021,MR AM should have working directory in LD_LIBRARY_PATH,"Tasks implicitly pick up shared libraries added to the job because the task launch context explicitly adds the container working directory to LD_LIBRARY_PATH.  However the same is not done for the AM container which is inconsistent.  User code can run in the AM via output committer, speculator, uber job, etc., so the AM's LD_LIBRARY_PATH should have the container work directory for consistency with tasks."
MAPREDUCE-6019,MapReduce changes for exposing YARN/MR endpoints on multiple interfaces.,
MAPREDUCE-6018,Create a framework specific config to enable timeline server,
MAPREDUCE-6016,hadoop yarn mapreduce skip failed records doesn't work,"I am trying to use ""skip failed records"" map-reduce functionality during the map phase. I created special testing file with 8 corrupted records. I am using TextInputFormat and during the processing (of the record) map function fails with unhandled exception (parsing the record into expected structure). Job is using the old mapred api.

My job settings for enabling ""skip failed records feature"":

    <property>
        <name>mapred.skip.mode.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>mapreduce.map.maxattempts</name>
        <value>10</value>
    </property>
    <property>
        <name>mapreduce.task.skip.start.attempts</name>
        <value>1</value>
    </property>
    <property>
        <name>mapreduce.map.skip.maxrecords</name>
        <value>1</value>
    </property>

I verified that those properties are propagated via verification in job.xml. 
I am using hadoop 2.2.0 (HDP 2.0). Job is still failing after 10 attempts.

UPDATE:
- obviously job is not entering skip record mode

Q: Does this feature works on RecordReader level only? Hadoop definite guide (which is for v.1) descibes thais feature at the level of map/reduce funciton"
MAPREDUCE-6014,New task status field in task attempts table can lead to an empty web page ,MAPREDUCE-5550 added a new task attempts field but didn't Javascript-escape the contents.  Tasks with status messages that have newlines or other characters can then break the parsing of the web page and leave the user with a blank page.
MAPREDUCE-6013,mapred version is missing,'mapred version' is missing.
MAPREDUCE-6012,DBInputSplit creates invalid ranges on Oracle,"The DBInputFormat on Oracle does not create valid ranges.

The method getSplit line 263 is as follows:

          split = new DBInputSplit(i * chunkSize, (i * chunkSize) + chunkSize);

So the first split will have a start value of 0 (0*chunkSize).

However, the OracleDBRecordReader, line 84 is as follows:

      if (split.getLength() > 0 && split.getStart() > 0){

Since the start value of the first range is equal to 0, we will skip the block that partitions the input set. As a result, one of the map task will process the entire data set, rather than the partition.

I'm assuming the fix is trivial and would involve removing the second check in the if block.

Also, I believe the OracleDBRecordReader paging query is incorrect.

Line 92 should read:

  query.append("" ) WHERE dbif_rno > "").append(split.getStart());

instead of (note > instead of >=)

  query.append("" ) WHERE dbif_rno >= "").append(split.getStart());

Otherwise some rows will be ignored and some counted more than once.

A map/reduce job that counts the number of rows based on a predicate will highlight the incorrect behavior.

"
MAPREDUCE-6010,HistoryServerFileSystemStateStore fails to update tokens,When token recovery is enabled and the file system state store is being used then tokens fail to be updated due to a rename destination conflict.
MAPREDUCE-6009,Map-only job with new-api runs wrong OutputCommitter when cleanup scheduled in a reduce slot,"In branch 1 job commit is executed in a JOB_CLEANUP task that may run in either map or reduce slot

in org.apache.hadoop.mapreduce.Job#setUseNewAPI there is a logic setting new-api flag only for reduce-ful jobs.
{code}
    if (numReduces != 0) {
      conf.setBooleanIfUnset(""mapred.reducer.new-api"",
                             conf.get(oldReduceClass) == null);
      ...
{code}
Therefore, when cleanup runs in a reduce slot, ReduceTask inits using the old API and runs incorrect default OutputCommitter, instead of consulting OutputFormat.
"
MAPREDUCE-6008,Update distcp docs to include new option that suppresses preservation of RAW.* namespace extended attributes,Update the docs to include this new option.
MAPREDUCE-6007,Add support to distcp to preserve raw.* namespace extended attributes,"As part of the Data at Rest Encryption work (HDFS-6134), we need to add support to distcp which preserves raw.* namespace extended attributes when both the src and target pathnames are in the /.reserved/raw directory hierarchy. See the doc in HDFS-6509 for details."
MAPREDUCE-6006,native-task: add native tests to maven and fix bug in pom.xml,
MAPREDUCE-6005,native-task: fix some valgrind errors ,"Running test with valgrind shows there are some bugs, this jira try to fix them."
MAPREDUCE-6004,native-task should not fail to build if zlib is missing,zlib is required by Gzip. We need to check for its existence in build and exclude Gzip related codes when zlib is missing. similar to MAPREDUCE-5976
MAPREDUCE-6002,MR task should prevent report error to AM when process is shutting down,"With MAPREDUCE-5900, preempted MR task should not be treat as failed. 
But it is still possible a MR task fail and report to AM when preemption take effect and the AM hasn't received completed container from RM yet. It will cause the task attempt marked failed instead of preempted.

An example is FileSystem has shutdown hook, it will close all FileSystem instance, if at the same time, the FileSystem is in-use (like reading split details from HDFS), MR task will fail and report the fatal error to MR AM. An exception will be raised:
{code}
2014-07-22 01:46:19,613 FATAL [IPC Server handler 10 on 56903] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1405985051088_0018_m_000025_0 - exited : java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:707)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:776)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:837)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:645)
	at java.io.DataInputStream.readByte(DataInputStream.java:265)
	at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
	at org.apache.hadoop.io.WritableUtils.readVIntInRange(WritableUtils.java:348)
	at org.apache.hadoop.io.Text.readString(Text.java:464)
	at org.apache.hadoop.io.Text.readString(Text.java:457)
	at org.apache.hadoop.mapred.MapTask.getSplitDetails(MapTask.java:357)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:731)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
{code}

We should prevent this, because it is possible other exceptions happen when shutting down, we shouldn't report any of such exceptions to AM."
MAPREDUCE-6000,native-task: Simplify ByteBufferDataReader/Writer,"The ByteBufferDataReader and ByteBufferDataWriter class are more complex than necessary:
- several methods related to reading/writing strings and char arrays are implemented but never used by the native task code. Given that the use case for these classes is limited to serializing binary data to/from the native code, it seems unlikely people will want to use these methods in any performance-critical space. So, let's do simpler implementations that are less likely to be buggy, even if they're slightly less performant.
- methods like readLine() are even less likely to be used. Since it's a complex implementation, let's just throw UnsupportedOperationException
- in the test case, we can use Mockito to shorten the amount of new code"
MAPREDUCE-5999,Fix dead link in InputFormat javadoc,"In [InputFormat|http://hadoop.apache.org/docs/r2.4.1/api/org/apache/hadoop/mapred/InputFormat.html] javadoc, there is a dead link 'mapreduce.input.fileinputformat.split.minsize'."
MAPREDUCE-5998,CompositeInputFormat javadoc is broken,"In [CompositeInputFormat javadoc|https://hadoop.apache.org/docs/r2.4.1/api/org/apache/hadoop/mapred/join/CompositeInputFormat.html], some part of the description is converted to hyperlink by {{@see}} tag."
MAPREDUCE-5997,native-task: Use DirectBufferPool from Hadoop Common,"The native task code has its own direct buffer pool, but Hadoop already has an implementation. HADOOP-10882 will move that implementation into Common, and this JIRA is to remove the duplicate code and use that one instead."
MAPREDUCE-5996,native-task: Rename system tests into standard directory layout,Currently there are a number of tests in src/java/system. This confuses IDEs which think that the package should then be system.org.apache.hadoop instead of just org.apache.hadoop.
MAPREDUCE-5995,native-task: revert changes which expose Text internals,"The current branch has some changes to the Text writable which allow it to manually set the backing array, capacity, etc. Rather than exposing these internals, we should use the newly-committed facility from HADOOP-10855 to implement this."
MAPREDUCE-5994,native-task: TestBytesUtil fails,This class appears to have some bugs. Two tests fail consistently on my system. BytesUtil itself appears to duplicate a lot of code from guava - we should probably just use the Guava functions.
MAPREDUCE-5993,native-task: simplify/remove dead code,"The native task code has a bunch of code in it which isn't related to the map output collector. I suspect much if this is dead code. Let's remove it before we merge, so that the amount of code we have to maintain going forward is more limited."
MAPREDUCE-5991,native-task should not run unit tests if native profile is not enabled,"Currently, running ""mvn test"" without the 'native' profile enabled causes all of the native-task tests to fail. In order to integrate to trunk, we need to fix this - either using JUnit ""Assume"" commands in each test that depends on native code, or disabling the tests from the pom unless -Pnative is specified"
MAPREDUCE-5989,Add DeletionService in AM,"In AM, for graceful cleanup, I propose addition of a DeletionService which will do the following :
1. Cleanup of failed tasks (temporary data need not occupy space till NM's Deletion Service is invoked)
2. Staging directory deletion (During AM shutdown, its better to place staging dir cleanup in Deletion Service: Refer to MAPREDUCE-4841 )
"
MAPREDUCE-5988,Fix dead links to the javadocs in mapreduce project,"In http://hadoop.apache.org/docs/r2.4.1/api/allclasses-frame.html, some classes are listed, but not documented."
MAPREDUCE-5987,native-task: Unit test TestGlibCBug fails on ubuntu,"On  ubuntu12, glibc: 2.15-0ubuntu10.3, UT TestGlibCBug fails

[ RUN      ] IFile.TestGlibCBug
14/07/21 15:55:30 INFO TestGlibCBug ./testData/testGlibCBugSpill.out
/home/decster/projects/hadoop-trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/main/native/test/TestIFile.cc:186: Failure
Value of: realKey
  Actual: 1127504685
Expected: expect[index]
Which is: 4102672832
[  FAILED  ] IFile.TestGlibCBug (0 ms)
[----------] 2 tests from IFile (240 ms total)"
MAPREDUCE-5985,native-task: Fix build on macosx,
MAPREDUCE-5984,native-task: reuse lz4 sources in hadoop-common,
MAPREDUCE-5982,Task attempts that fail from the ASSIGNED state can disappear,"If a task attempt fails in the ASSIGNED state, e.g.: container launch fails,  then it can disappear from the job history.  The task overview page will show subsequent attempts but the attempt in question is simply missing.  For example attempt ID 1 appears but the attempt ID 0 is missing.  Similarly in the job overview page the task attempt doesn't appear in any of the failed/killed/succeeded counts or pages.  It's as if the task attempt never existed, but the AM logs show otherwise."
MAPREDUCE-5981,Log levels of certain MR logs can be changed to DEBUG,"Following map reduce logs can be changed to DEBUG log level as they appear too many times in the log file and are not that important for debugging.

1. In org.apache.hadoop.mapreduce.task.reduce.Fetcher#copyFromHost(Fetcher.java : 313), the second log is not required to be at info level. This can be moved to debug as a warn log is anyways printed if verifyReply fails.

      SecureShuffleUtils.verifyReply(replyHash, encHash, shuffleSecretKey);
      LOG.info(""for url=""+msgToEncode+"" sent hash and received reply"");

2. Thread related info need not be printed in logs at INFO level. Below 2 logs can be moved to DEBUG
    a) In org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl#getHost(ShuffleSchedulerImpl.java : 381), below log can be changed to DEBUG

   LOG.info(""Assigning "" + host + "" with "" + host.getNumKnownMapOutputs() +
               "" to "" + Thread.currentThread().getName());

    b) In org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.getMapsForHost(ShuffleSchedulerImpl.java : 411), below log can be changed to DEBUG
 LOG.info(""assigned "" + includedMaps + "" of "" + totalSize + "" to "" +
             host + "" to "" + Thread.currentThread().getName());
 "
MAPREDUCE-5980,filter empty string in the libjars when submitting jobs,"-libjars is used to upload jars into hdfs when submitting jobs. If there is empty string between two comma, the copying processing will try to copy all the subdirs/files under current directory. I believe it is not user's expected behavior."
MAPREDUCE-5979,FairScheduler: zero weight can cause sort failures,"When the weight is set to zero (which is possible with a custom weight adjuster) we can get failures in comparing schedulables.
This is because when calculating running tasks to weight ratio could result in a 0.0/0.0 which ends up as NaN. Comparisons with NaN are undefined such that (int)Math.signum(NaN - anyNumber) will be 0 causing different criteria to be used in comparison which may not be consistent. This will result in 
{{IllegalArgumentException: Comparison method violates its general contract!}}
 "
MAPREDUCE-5978,native-task CompressTest failure on Ubuntu,"The MR-2841 branch fails the following unit tests on my box:
  CompressTest.testBzip2Compress:84 file compare result: if they are the same ,then return true expected:<true> but was:<false>
  CompressTest.testDefaultCompress:116 file compare result: if they are the same ,then return true expected:<true> but was:<false>

We need to fix these before merging."
MAPREDUCE-5977,Fix or suppress native-task gcc warnings,"Currently, building the native task code on gcc 4.8 has a fair number of warnings. We should fix or suppress them so that new warnings are easier to see."
MAPREDUCE-5976,native-task should not fail to build if snappy is missing,"Other native parts of Hadoop will automatically disable snappy support if snappy is not present and -Drequire.snappy is not passed. native-task should do the same. (right now, it fails to build if snappy is missing)"
MAPREDUCE-5975,Fix native-task build on Ubuntu 13.10,I'm having some issues building the native-task branch on my Ubuntu 13.10 box. This JIRA is to figure out and fix whatever's going on.
MAPREDUCE-5974,Allow specifying multiple MapOutputCollectors with fallback,"Currently we only allow specifying a single MapOutputCollector implementation class in a job. It would be nice to allow a comma-separated list of classes: we should try each collector implementation in the user-specified order until we find one that can be successfully instantiated and initted.

This is useful for cases where a particular optimized collector implementation cannot operate on all key/value types, or requires native code. The cluster administrator can configure the cluster to try to use the optimized collector and fall back to the default collector."
MAPREDUCE-5973,TestAMWebServices* fails intermittently,The tests can fail because of bind exception.
MAPREDUCE-5972,Fix typo 'programatically' in job.xml (and a few other places),"In job.xml, there's a typo 'programatically' as the below if a property is set through program.
{code}
<property>
  <name>mapreduce.job.map.class</name>
  <value>org.apache.hadoop.examples.WordCount$TokenizerMapper</value>
  <source>programatically</source>
</property>
{code}
should be 'programmatically'."
MAPREDUCE-5971,Move the default options for distcp -p to DistCpOptionSwitch,The default preserve flags for distcp -p are embedded in the OptionsParser code. Refactor to co-locate them with the actual flag initialization.
MAPREDUCE-5970,Provide a boolean switch to enable MR-AM profiling,MR task profiling can be enabled with a simple switch {{mapreduce.task.profile=true}}. We can analogously have {{yarn.app.mapreduce.am.profile}} for MR-AM
MAPREDUCE-5968,Work directory is not deleted when downloadCacheObject throws IOException,"Work directory is not deleted in  DistCache if Exception happen in downloadCacheObject. In downloadCacheObject, the cache file will be copied to temporarily work directory first, then the  work directory will be renamed to the final directory. If IOException happens during the copy, the  work directory will not be deleted. This will cause garbage data left in local disk cache. For example If the MR application use Distributed Cache to send a very large Archive/file(50G), if the disk is full during the copy, then the IOException will be triggered, the work directory will be not deleted or renamed and the work directory will occupy a big chunk of disk space.

"
MAPREDUCE-5967,TestRecovery fails in trunk,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1828/console :
{code}
Running org.apache.hadoop.mapreduce.v2.app.TestRecovery
Tests run: 15, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 51.578 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestRecovery
testRecoveryWithoutShuffleSecret(org.apache.hadoop.mapreduce.v2.app.TestRecovery)  Time elapsed: 0.438 sec  <<< FAILURE!
java.lang.AssertionError: Reduce Task state not correct expected:<RUNNING> but was:<SCHEDULED>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.apache.hadoop.mapreduce.v2.app.TestRecovery.testRecoveryWithoutShuffleSecret(TestRecovery.java:1346)

testRecoveryWithOldCommiter(org.apache.hadoop.mapreduce.v2.app.TestRecovery)  Time elapsed: 12.329 sec  <<< FAILURE!
java.lang.AssertionError: Task state is not correct (timedout) expected:<SUCCEEDED> but was:<RUNNING>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.waitForState(MRApp.java:394)
	at org.apache.hadoop.mapreduce.v2.app.TestRecovery.testRecoveryWithOldCommiter(TestRecovery.java:1120)
{code}"
MAPREDUCE-5966,MR1 FairScheduler use of custom weight adjuster is not thread safe for comparisons,"When comparing JobSchedulables one of the factors is the weight. If someone uses a custom weight adjuster, that may be called multiple times during a sort causing different values to return. That causes a failure in sorting because the weight may change during the sort.

This reproes as 
{code}
java.io.IOException: java.lang.IllegalArgumentException: Comparison method violates its general contract!
at java.util.TimSort.mergeHi(TimSort.java:868)
at java.util.TimSort.mergeAt(TimSort.java:485)
at java.util.TimSort.mergeCollapse(TimSort.java:410)
at java.util.TimSort.sort(TimSort.java:214)
at java.util.TimSort.sort(TimSort.java:173)
at java.util.Arrays.sort(Arrays.java:659)
at java.util.Collections.sort(Collections.java:217)
at org.apache.hadoop.mapred.PoolSchedulable.assignTask(PoolSchedulable.java:163)
at org.apache.hadoop.mapred.FairScheduler.assignTasks(FairScheduler.java:499)
at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2961)
{code}"
MAPREDUCE-5965,"Hadoop streaming throws error if list of input files is high. Error is: ""error=7, Argument list too long at if number of input file is high""","Hadoop streaming exposes all the key values in job conf as environment variables when it forks a process for streaming code to run. Unfortunately the variable mapreduce_input_fileinputformat_inputdir contains the list of input files, and Linux has a limit on size of environment variables + arguments.
Based on how long the list of files and their full path is this could be pretty huge. And given all of these variables are not even used it stops user from running hadoop job with large number of files, even though it could be run.

Linux throws E2BIG if the size is greater than certain size which is error code 7. And java translates that to ""error=7, Argument list too long"". More: http://man7.org/linux/man-pages/man2/execve.2.html I suggest skipping variables if it is greater than certain length. That way if user code requires the environment variable it would fail. It should also introduce a config variable to skip long variables, and set it to false by default. That way user has to specifically set it to true to invoke this feature.

Here is the exception:
{code}
Error: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:426) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:342) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163) Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106) ... 9 more Caused by: java.lang.RuntimeException: Error in configuring object at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:109) at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:75) at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133) at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:38) ... 14 more Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:106) ... 17 more Caused by: java.lang.RuntimeException: configuration exception at org.apache.hadoop.streaming.PipeMapRed.configure(PipeMapRed.java:222) at org.apache.hadoop.streaming.PipeMapper.configure(PipeMapper.java:66) ... 22 more Caused by: java.io.IOException: Cannot run program ""/data/hadoop/hadoop-yarn/cache/yarn/nm-local-dir/usercache/oo-analytics/appcache/application_1403599726264_13177/container_1403599726264_13177_01_000006/./rbenv_runner.sh"": error=7, Argument list too long at java.lang.ProcessBuilder.start(ProcessBuilder.java:1041) at org.apache.hadoop.streaming.PipeMapRed.configure(PipeMapRed.java:209) ... 23 more Caused by: java.io.IOException: error=7, Argument list too long at java.lang.UNIXProcess.forkAndExec(Native Method) at java.lang.UNIXProcess.<init>(UNIXProcess.java:135) at java.lang.ProcessImpl.start(ProcessImpl.java:130) at java.lang.ProcessBuilder.start(ProcessBuilder.java:1022) ... 24 more Container killed by the ApplicationMaster. Container killed on request. Exit code is 143 Container exited with a non-zero exit code 143
{code}

Hive does a similar trick: HIVE-2372 I have a patch for this, will soon submit a patch."
MAPREDUCE-5963,ShuffleHandler DB schema should be versioned with compatible/incompatible changes,"ShuffleHandler persist job shuffle info into DB schema, which should be versioned with compatible/incompatible changes to support rolling upgrade."
MAPREDUCE-5962,Support CRC32C in IFile,"Currently, the IFile format used by the MR shuffle checksums all data using the zlib CRC32 polynomial. If we allow use of CRC32C instead, we can get a large reduction in CPU usage by leveraging the native hardware CRC32C implementation (approx half a second of CPU time savings per GB checksummed)."
MAPREDUCE-5961,"Job start time setting to ""Thu Jan 01 05:29:59 IST 1970""","Induce RM switchover while job is in progress

Observe that  job start time setting to ""Thu Jan 01 05:29:59 IST 1970"" saying below error

{code}

2014-07-05 21:38:12,415 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Moving hdfs://mycluster:8020/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0056_conf.xml to hdfs://mycluster:8020/home/testos/staging-dir/history/done/2014/07/05/000000/job_1404572770516_0056_conf.xml
2014-07-05 21:41:12,289 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Starting scan to move intermediate done files
2014-07-05 21:41:12,294 WARN org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils: Unable to parse launch time from job history file job_1404572770516_0057-1404576372149-testos-word+count-1404576499406-85-10-SUCCEEDED-default--1.jhist : java.lang.NumberFormatException: For input string: """"
2014-07-05 21:41:12,297 INFO org.apache.hadoop.mapreduce.jobhistory.JobSummary: jobId=job_1404572770516_0057,submitTime=1404576372149,launchTime=-1,firstMapTaskLaunchTime=1404576442635,firstReduceTaskLaunchTime=1404576492243,finishTime=1404576499406,resourcesPerMap=1024,resourcesPerReduce=1024,numMaps=85,numReduces=10,user=testos,queue=default,status=SUCCEEDED,mapSlotSeconds=690,reduceSlotSeconds=39,jobName=word count
2014-07-05 21:41:12,298 INFO org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager: Deleting JobSummary file:
{code}

AM LOG

{code}

2014-07-05 21:38:19,432 INFO [Thread-74] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2014-07-05 21:38:19,432 INFO [Thread-74] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2014-07-05 21:38:19,433 INFO [Thread-74] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2014-07-05 21:38:19,556 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://mycluster/home/testos/staging-dir/testos/.staging/job_1404572770516_0057/job_1404572770516_0057_2.jhist to hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057-1404576372149-testos-word+count-1404576499406-85-10-SUCCEEDED-default--1.jhist_tmp
2014-07-05 21:38:19,770 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057-1404576372149-testos-word+count-1404576499406-85-10-SUCCEEDED-default--1.jhist_tmp
2014-07-05 21:38:19,785 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://mycluster/home/testos/staging-dir/testos/.staging/job_1404572770516_0057/job_1404572770516_0057_2_conf.xml to hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057_conf.xml_tmp
2014-07-05 21:38:19,862 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057_conf.xml_tmp
2014-07-05 21:38:19,886 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057.summary_tmp to hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057.summary
2014-07-05 21:38:19,898 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057_conf.xml_tmp to hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057_conf.xml
2014-07-05 21:38:19,910 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057-1404576372149-testos-word+count-1404576499406-85-10-SUCCEEDED-default--1.jhist_tmp to hdfs://mycluster/home/testos/staging-dir/history/done_intermediate/testos/job_1404572770516_0057-1404576372149-testos-word+count-1404576499406-85-10-SUCCEEDED-default--1.jhist
{code}
"
MAPREDUCE-5960,JobSubmitter's check whether job.jar is local is incorrect with no authority in job jar path.,"{code}
$ mapred job -submit myjob.xml 
2014-07-06 15:06:34.731 java[12120:1903] Unable to load realm info from SCDynamicStore
14/07/06 15:06:34 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/07/06 15:06:34 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/07/06 15:06:37 WARN conf.Configuration: bad conf file: element not <property>
14/07/06 15:06:37 WARN conf.Configuration: bad conf file: element not <property>
14/07/06 15:06:37 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
14/07/06 15:11:11 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/gshegalov/.staging/job_1404679996131_0004
Exception in thread ""main"" java.lang.IllegalArgumentException: Wrong FS: viewfs:/user/gshegalov/hadoop-mapreduce-examples-3.0.0-SNAPSHOT.jar, expected: file:///
	at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:643)
	at org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:80)
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:525)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:739)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:520)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:397)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1902)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1870)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1835)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyJar(JobSubmitter.java:286)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:254)
	at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:301)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:389)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1285)
	at org.apache.hadoop.mapreduce.Job$10.run(Job.java:1282)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1626)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1282)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:260)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1239)
{code}"
MAPREDUCE-5958,Wrong reduce task progress if map output is compressed,"If the map output is compressed (_mapreduce.map.output.compress_ set to _true_) then the reduce task progress may be highly underestimated.

In the reduce phase (but also in the merge phase), the progress of a reduce task is computed as the ratio between the number of processed bytes and the number of total bytes. But:

- the number of total bytes is computed by summing up the uncompressed segment sizes (_Merger.Segment.getRawDataLength()_)

- the number of processed bytes is computed by exploiting the position of the current _IFile.Reader_ (using _IFile.Reader.getPosition()_) but this may refer to the position in the underlying on disk file (which may be compressed)

Thus, if the map outputs are compressed then the progress may be underestimated (e.g., only 1 map output ondisk file, the compressed file is 25% of its original size, then the reduce task progress during the reduce phase will range between 0 and 0.25 and then artificially jump to 1.0).

Attached there is a patch: the number of processed bytes is now computed by exploiting _IFile.Reader.bytesRead_ (if the the reader is in memory, then _getPosition()_ already returns exactly this field).
"
MAPREDUCE-5957,AM throws ClassNotFoundException with job classloader enabled if custom output format/committer is used,"With the job classloader enabled, the MR AM throws ClassNotFoundException if a custom output format class is specified.

{noformat}
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.foo.test.TestOutputFormat not found
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createOutputCommitter(MRAppMaster.java:473)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceInit(MRAppMaster.java:374)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1459)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1456)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1389)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class com.foo.test.TestOutputFormat not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1895)
	at org.apache.hadoop.mapreduce.task.JobContextImpl.getOutputFormatClass(JobContextImpl.java:222)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.createOutputCommitter(MRAppMaster.java:469)
	... 8 more
Caused by: java.lang.ClassNotFoundException: Class com.foo.test.TestOutputFormat not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1801)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1893)
	... 10 more
{noformat}"
MAPREDUCE-5956,MapReduce AM should not use maxAttempts to determine if this is the last retry,"Found this while reviewing YARN-2074. The problem is that after YARN-2074, we don't count AM preemption towards AM failures on RM side, but MapReduce AM itself checks the attempt id against the max-attempt count to determine if this is the last attempt.
{code}
    public void computeIsLastAMRetry() {
      isLastAMRetry = appAttemptID.getAttemptId() >= maxAppAttempts;
    }
{code}
This causes issues w.r.t deletion of staging directory etc.."
MAPREDUCE-5952,LocalContainerLauncher#renameMapOutputForReduce incorrectly assumes a single dir for mapOutIndex,"The javadoc comment for {{renameMapOutputForReduce}} incorrectly refers to a single map output directory, whereas this depends on LOCAL_DIRS.
mapOutIndex should be set to subMapOutputFile.getOutputIndexFile()

{code}
2014-06-30 14:48:35,574 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : java.io.FileNotFoundException: File /Users/gshegalov/workspace/hadoop-common/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapreduce.v2.TestMRJobs/org.apache.hadoop.mapreduce.v2.          TestMRJobs-localDir-nm-2_3/usercache/gshegalov/appcache/application_1404164272885_0001/output/file.out.index does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:517)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:726)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:507)
  at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:337)                      
  at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:289)                          
  at org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:334)    
  at org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:504)
  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.renameMapOutputForReduce(LocalContainerLauncher.java:471)
  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runSubtask(LocalContainerLauncher.java:370)
  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.runTask(LocalContainerLauncher.java:292)
  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler.access$200(LocalContainerLauncher.java:178)
  at org.apache.hadoop.mapred.LocalContainerLauncher$EventHandler$1.run(LocalContainerLauncher.java:221)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)    
  at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)         
  at java.util.concurrent.FutureTask.run(FutureTask.java:138)                       
  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
  at java.lang.Thread.run(Thread.java:695)         
{code}"
MAPREDUCE-5951,Add support for the YARN Shared Cache,"Implement the necessary changes so that the MapReduce application can leverage the new YARN shared cache (i.e. YARN-1492).

Specifically, allow per-job configuration so that MapReduce jobs can specify which set of resources they would like to cache (i.e. jobjar, libjars, archives, files)."
MAPREDUCE-5950,incorrect description in distcp2 document,"In http://hadoop.apache.org/docs/r1.2.1/distcp2.html#UpdateAndOverwrite

The first statement of the ""Update and Overwrite"" section says:
{quote}
-update is used to copy files from source that don't exist at the target, or have different contents. -overwrite overwrites target-files even if they exist at the source, or have the same contents.
{quote}

The ""Command Line Options"" table says :
{quote}
  -overwrite: Overwrite destination
  -update: Overwrite if src size different from dst size
{quote}

Based on the implementation, making the following modification would be more accurate:

The first statement of the ""Update and Overwrite"" section:
{code}
-update is used to copy files from source that don't exist at the target, or have different contents. -overwrite overwrites target-files if they exist at the target.
{code}

The ""Command Line Options"" table:
{code}
  -overwrite: Overwrite destination
  -update: Overwrite destination if source and destination have different contents
{code}

Thanks.
"
MAPREDUCE-5949,Tasktracker's java threads hunging,"I set up hadoop-1.2.1 (from ports) on FreeBSD-10/stable with openjdk version 1.7.0_60.

On the first glance it is doing well except one annoying thing:  after executing some tasks, tasktracker process starts to eat CPU when idle.
Sometimes it is 10-20% (numbers from top(1) output), sometimes it is 100-150%.

In tasktrackers's log I see numerious records like this:

2014-06-09 13:08:29,858 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay59 times
2014-06-09 13:08:29,859 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 59 times, canceled keys 944 times
2014-06-09 13:09:29,862 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay58 times
2014-06-09 13:09:29,862 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 58 times, canceled keys 928 times
2014-06-09 13:10:29,901 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - injecting delay58 times
2014-06-09 13:10:29,901 INFO org.mortbay.log: org.mortbay.io.nio.SelectorManager$SelectSet@abdcc1c JVM BUG(s) - recreating selector 58 times, canceled keys 928 times
<...>


The more jobs I run, more java threads start to consume CPU after all tasks finished.  After several job execution, top(1) output looks like this (splitted by thread, the same PID):

PID USERNAME     PRI NICE   SIZE    RES STATE   C   TIME    WCPU COMMAND
79045 hadoop        47    0  1948M   867M uwait   2  20:49  37.50% java{java}
79045 hadoop        31    0  1948M   867M uwait  31   1:45  19.29% java{java}
79045 hadoop        33    0  1948M   867M uwait  21   2:51  19.19% java{java}
79045 hadoop        30    0  1948M   867M uwait  17   2:51  18.65% java{java}
79045 hadoop        30    0  1948M   867M uwait  11   1:52  18.36% java{java}
79045 hadoop        30    0  1948M   867M uwait  22   1:45  18.36% java{java}
79045 hadoop        31    0  1948M   867M uwait  29   2:50  18.26% java{java}
79045 hadoop        31    0  1948M   867M uwait   6   1:57  18.16% java{java}
79045 hadoop        31    0  1948M   867M uwait  13   4:55  17.97% java{java}
79045 hadoop        31    0  1948M   867M uwait  26   3:39  17.77% java{java}
79045 hadoop        33    0  1948M   867M uwait   8   1:21  17.48% java{java}
79045 hadoop        30    0  1948M   867M uwait   1   3:32  16.70% java{java}
79045 hadoop        32    0  1948M   867M uwait  24   3:12  16.70% java{java}
79045 hadoop        26    0  1948M   867M uwait   4   1:27  10.35% java{java}
72417 root          20    0 19828K  3252K CPU21  21   0:00   0.29% top
836 root          20    0 36104K  1952K select 14   6:51   0.00% snmpd
79045 hadoop        20    0  1948M   867M uwait  20   6:51   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait  27   3:45   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait  30   2:37   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait  15   0:54   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait   2   0:48   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait  14   0:48   0.00% java{java}
79045 hadoop        20    0  1948M   867M uwait   2   0:48   0.00% java{java}
<....>

This is on absolutely idle cluster, no single task is running.
I am attaching truss(1) output for that java process:

"
MAPREDUCE-5948,org.apache.hadoop.mapred.LineRecordReader does not handle multibyte record delimiters well,"Having defined a recorddelimiter of multiple bytes in a new InputFileFormat sometimes has the effect of skipping records from the input.

This happens when the input splits are split off just after a recordseparator. Starting point for the next split would be non zero and skipFirstLine would be true. A seek into the file is done to start - 1 and the text until the first recorddelimiter is ignored (due to the presumption that this record is already handled by the previous maptask). Since the re ord delimiter is multibyte the seek only got the last byte of the delimiter into scope and its not recognized as a full delimiter. So the text is skipped until the next delimiter (ignoring a full record!!)
"
MAPREDUCE-5945,Update the description of GenericOptionsParser -jt option,Now -jt option is used to specify the address of ResourceManager but document says -jt option specifies JobTracker. The document should be updated.
MAPREDUCE-5943,Separate mapred commands from CommandsManual.apt.vm,"Now that MapReduce is just an application running on YARN, so I think it's better to separate {{mapred}} commands from CommandsManual.apt.vm and move these commands into MapReduce section."
MAPREDUCE-5942,Remove MRv1 commands from CommandsManual.apt.vm,There're some old commands such as 'hadoop jobtracker' and 'hadoop tasktracker' in CommandsManual.apt.vm. These commands should be removed.
MAPREDUCE-5939,StartTime showing up as the epoch time in JHS UI after upgrade,"After upgrading from 0.23.x to 2.5, the start time of old apps are showing up as the epoch time.  It looks like 2.5 expects start time to be encoded at the end of the jhist file name (....xxxx-[timestamp].jhist). It should have been made backward compatible."
MAPREDUCE-5933,Enable MR AM to post history events to the timeline server,"Nowadays, MR AM collects the history events and writes it to HDFS for JHS to source. With the timeline server, MR AM can put these events there."
MAPREDUCE-5932,Provide an option to use a dedicated reduce-side shuffle log,"For reducers in large jobs our users cannot easily spot portions of the log associated with problems with their code. An example reducer with INFO-level logging generates ~3500 lines / ~700KiB  lines per second. 95% of the log is the client-side of the shuffle {{org.apache.hadoop.mapreduce.task.reduce.*}}

{code}
$ wc syslog 
    3642   48192  691013 syslog
$ grep task.reduce syslog | wc 
    3424   46534  659038
$ grep task.reduce.ShuffleScheduler syslog | wc 
    1521   17745  251458
$ grep task.reduce.Fetcher syslog | wc 
    1045   15340  223683
$ grep task.reduce.InMemoryMapOutput syslog | wc 
     400    4800   72060
$ grep task.reduce.MergeManagerImpl syslog | wc 
     432    8200  106555
{code}

Byte percentage breakdown:
{code}
Shuffle total:           95%

ShuffleScheduler:        36%
Fetcher:                 32%
InMemoryMapOutput:       10%
MergeManagerImpl:        15%
{code}

While this is information is actually often useful for devops debugging shuffle performance issues, the job users are often lost. 

We propose to have a dedicated syslog.shuffle file.
"
MAPREDUCE-5931,Validate SleepJob command line parameters,"This is a minor issue per se. I had a typo in my script specifying a negative number of reducers for the SleepJob. It results in the exception that is far from the root cause, and appeared as a serious issue with the map-side sort.

{noformat}
2014-06-17 21:42:48,072 INFO [main] org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@972141f
java.lang.NullPointerException
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1447)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:700)
	at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1990)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:774)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:173)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1626)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
2014-06-17 21:42:48,075 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.IllegalArgumentException
	at java.nio.ByteBuffer.allocate(ByteBuffer.java:330)
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:51)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1824)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1484)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:700)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:770)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:173)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1626)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
{noformat}"
MAPREDUCE-5928,Deadlock allocating containers for mappers and reducers,"I have a small cluster consisting of 8 desktop class systems (1 master + 7 workers).
Due to the small memory of these systems I configured yarn as follows:
{quote}
yarn.nodemanager.resource.memory-mb = 2200
yarn.scheduler.minimum-allocation-mb = 250
{quote}
On my client I did
{quote}
mapreduce.map.memory.mb = 512
mapreduce.reduce.memory.mb = 512
{quote}
Now I run a job with 27 mappers and 32 reducers.
After a while I saw this deadlock occur:
-	All nodes had been filled to their maximum capacity with reducers.
-	1 Mapper was waiting for a container slot to start in.

I tried killing reducer attempts but that didn't help (new reducer attempts simply took the existing container).

*Workaround*:
I set this value from my job. The default value is 0.05 (= 5%)
{quote}
mapreduce.job.reduce.slowstart.completedmaps = 0.99f
{quote}
"
MAPREDUCE-5927,Getting following error,"Hi,

I am getting following error, while running application on cluser -

14/06/16 16:21:48 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
14/06/16 16:21:49 INFO input.FileInputFormat: Total input paths to process : 1
14/06/16 16:21:49 INFO mapreduce.JobSubmitter: number of splits:1
14/06/16 16:21:49 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/06/16 16:21:49 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/06/16 16:21:49 INFO Configuration.deprecation: mapreduce.inputformat.class is deprecated. Instead, use mapreduce.job.inputformat.class
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/06/16 16:21:49 INFO Configuration.deprecation: mapreduce.outputformat.class is deprecated. Instead, use mapreduce.job.outputformat.class
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/06/16 16:21:49 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/06/16 16:21:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1402913701967_0006
14/06/16 16:21:49 INFO impl.YarnClientImpl: Submitted application application_1402913701967_0006 to ResourceManager at master/10.71.71.110:8032
14/06/16 16:21:49 INFO mapreduce.Job: The url to track the job: http://gs-1695:8088/proxy/application_1402913701967_0006/
14/06/16 16:21:49 INFO mapreduce.Job: Running job: job_1402913701967_0006
14/06/16 16:21:54 INFO mapreduce.Job: Job job_1402913701967_0006 running in uber mode : false
14/06/16 16:21:54 INFO mapreduce.Job:  map 0% reduce 0%
14/06/16 16:21:54 INFO mapreduce.Job: Job job_1402913701967_0006 failed with state FAILED due to: Application application_1402913701967_0006 failed 2 times due to AM Container for appattempt_1402913701967_0006_000002 exited with  exitCode: 1 due to: Exception from container-launch:
org.apache.hadoop.util.Shell$ExitCodeException:
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
        at org.apache.hadoop.util.Shell.run(Shell.java:379)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
        at java.util.concurrent.FutureTask.run(FutureTask.java:262)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:744)


.Failing this attempt.. Failing the application.
14/06/16 16:21:54 INFO mapreduce.Job: Counters: 0


Can you please help me in fixing this ?

Thanks,
~Kedar
"
MAPREDUCE-5926,Support utf-8 text with BOM (byte order marker) for branch-1,
MAPREDUCE-5924,Windows: Sort Job failed due to 'Invalid event: TA_COMMIT_PENDING at COMMIT_PENDING',"The Sort job over 1GB data failed with below error
{code}
2014-06-09 09:15:38,746 INFO [Socket Reader #1 for port 63415] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1402304714683_0002 (auth:SIMPLE)
2014-06-09 09:15:38,750 INFO [IPC Server handler 13 on 63415] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1402304714683_0002_r_000015_1000
2014-06-09 09:15:38,751 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1402304714683_0002_r_000015_1000
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_COMMIT_PENDING at COMMIT_PENDING
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:305)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1058)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:145)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1271)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1263)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:173)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:106)
        at java.lang.Thread.run(Thread.java:722)
2014-06-09 09:15:38,753 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1402304714683_0002Job Transitioned from RUNNING to ERROR

{code}

The JobHistory Url prints job state = ERROR"
MAPREDUCE-5923,org.apache.hadoop.mapred.pipes.TestPipeApplication timeouts intermittently,
MAPREDUCE-5922,Update distcp documentation to mention option for preserving xattrs.,"In hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/site/markdown/DistCp.md.vm, let's add a mention of the new distcp option for preserving xattrs."
MAPREDUCE-5920,Add Xattr option in DistCp docs ,
MAPREDUCE-5918,LineRecordReader can return the same decompressor to CodecPool multiple times,LineRecordReader can return the same decompressor to CodecPool multiple times if method close() called multiple times. In this case CodecPool doesn't guarantee that it always return different decompressors. This issue can cause some difficult reproducible and difficult diagnosable bugs in Hadoop based programs. 
MAPREDUCE-5912,Task.calculateOutputSize does not handle Windows files after MAPREDUCE-5196,"{code}
@@ -1098,8 +1120,8 @@ private long calculateOutputSize() throws IOException {
     if (isMapTask() && conf.getNumReduceTasks() > 0) {
       try {
         Path mapOutput =  mapOutputFile.getOutputFile();
-        FileSystem localFS = FileSystem.getLocal(conf);
-        return localFS.getFileStatus(mapOutput).getLen();
+        FileSystem fs = mapOutput.getFileSystem(conf);
+        return fs.getFileStatus(mapOutput).getLen();
       } catch (IOException e) {
         LOG.warn (""Could not find output size "" , e);
       }
{code}

causes Windows local output files to be routed through HDFS:

{code}
2014-06-02 00:14:53,891 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : java.lang.IllegalArgumentException: Pathname /c:/Hadoop/Data/Hadoop/local/usercache/HadoopUser/appcache/application_1401693085139_0001/output/attempt_1401693085139_0001_m_000000_0/file.out from c:/Hadoop/Data/Hadoop/local/usercache/HadoopUser/appcache/application_1401693085139_0001/output/attempt_1401693085139_0001_m_000000_0/file.out is not a valid DFS filename.
       at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:187)
       at org.apache.hadoop.hdfs.DistributedFileSystem.access$000(DistributedFileSystem.java:101)
       at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1024)
       at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1020)
       at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
       at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1020)
       at org.apache.hadoop.mapred.Task.calculateOutputSize(Task.java:1124)
       at org.apache.hadoop.mapred.Task.sendLastUpdate(Task.java:1102)
       at org.apache.hadoop.mapred.Task.done(Task.java:1048)
{code}
"
MAPREDUCE-5911,Terasort TeraOutputFormat does not check for output directory existance,"The enforcement that the directory must not yet exist is implemented in {{FileOutputFormat#checkOutputSpecs}} by throwing {{FileAlreadyExistsException}}.  However, terasort uses a specialized output format, {{TeraOutputFormat}}, which is a subclass of {{FileOutputFormat}}.  The subclass overrides {{checkOutputSpecs}}, but does not re-implement the existence check and throw {{FileAlreadyExistsException}}."
MAPREDUCE-5910,MRAppMaster should handle Resync from RM instead of shutting down.,The ApplicationMasterService currently sends a resync response to which the AM responds by shutting down. The MRAppMaster behavior is expected to change to calling resyncing with the RM. Resync means resetting the allocate RPC sequence number to 0 and the AM should send its entire outstanding request to the RM. Note that if the AM is making its first allocate call to the RM then things should proceed like normal without needing a resync. The RM will return all containers that have completed since the RM last synced with the AM. Some container completions may be reported more than once.
MAPREDUCE-5906,"Inconsistent configuration in property ""mapreduce.reduce.shuffle.input.buffer.percent""","In MergeManagerImpl.java, the default value of MRJobConfig.SHUFFLE_INPUT_BUFFER_PERCENT (=mapreduce.reduce.shuffle.input.buffer.percent) looks 0.90.
{code}
  final float maxInMemCopyUse =
    jobConf.getFloat(MRJobConfig.SHUFFLE_INPUT_BUFFER_PERCENT, 0.90f);
{code}
However, the actual default value is 0.70 in mapred-default.xml.
{code}
  <name>mapreduce.reduce.shuffle.input.buffer.percent</name>
  <value>0.70</value>
{code}"
MAPREDUCE-5905,"CountersStrings.toEscapedCompactStrings outputs unnecessary ""null"" strings","CountersStrings.toEscapedCompactStrings outputs ""null"" strings if a CounterGroup has more than one Counter.

That way there are some ""null"" strings in MRv1(CDH) job history log.
https://issues.cloudera.org/browse/DISTRO-598"
MAPREDUCE-5903,"If Kerberos Authentication is enabled, MapReduce job is failing on reducer phase","I have 3-node cluster configuration: 1 ResourceManager and 3 NodeManagers, Kerberos is enabled, have hdfs, yarn, mapred principals\keytabs. ResourceManager and NodeManager are ran under yarn user, using yarn Kerberos principal. 
Use case 1: WordCount, submit job using yarn UGI (i.e. superuser, the one having Kerberos principal on all boxes). Result: job successfully completed.
Use case 2: WordCount, submit job using LDAP user impersonation via yarn UGI. Result: Map tasks are completed SUCCESSfully, Reduce task fails with ShuffleError Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES (see the stack trace below).
The use case with user impersonation used to work on earlier versions, without YARN (with JT&TT).

I found similar issue with Kerberos AUTH involved here: https://groups.google.com/forum/#!topic/nosql-databases/tGDqs75ACqQ
And here https://issues.apache.org/jira/browse/MAPREDUCE-4030 it's marked as resolved, which is not the case when Kerberos Authentication is enabled.

The exception trace from YarnChild JVM:
2014-05-21 12:49:35,687 FATAL [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Shuffle failed with too many fetch failures and insufficient progress!
2014-05-21 12:49:35,688 WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#3
        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:167)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:416)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1557)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:162)
Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out.
        at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkReducerHealth(ShuffleSchedulerImpl.java:323)
        at org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:245)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:347)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:165)


"
MAPREDUCE-5901,Hadoop 2.4 Java execution issue: remotely submission jobs fail ,"I have installed Hadoop 2.4 on remote machine in Single-Mode setting. From another machine (client) I run a Java application that submit a job to a remote Hadoop machine (cluster), I have used the attached code. The problem is that the real execution of the map process is run on my local machine (client) not on the cluster machine.
JobConf job = new JobConf(SOF.class);
job.setJobName(""SIM-""+sim_id);
System.setProperty(""HADOOP_USER_NAME"", ""hadoop"");
FileInputFormat.addInputPath(job,new Path(""hdfs://cluster_ip:port""+USERS_HOME+user+""/SIM-""+sim_id+""/""+INPUT_FOLDER_HOME+""/input.tmp"")/*new_inputs_path*/);
FileOutputFormat.setOutputPath(job, new Path(""hdfs://cluster_ip:port""+USERS_HOME+user+""/SIM-""+sim_id+""/""+OUTPUT_FOLDER_HOME));
job.set(""jar.work.directory"", ""hdfs://cluster_ip:port""+SOF.USERS_HOME+user+""/SIM-""+sim_id+""/flockers.jar"");
job.setMapperClass(Mapper.class);
job.setReducerClass(Reducer.class);
job.setOutputKeyClass(org.apache.hadoop.io.Text.class);
job.setOutputValueClass(org.apache.hadoop.io.Text.class);

job.set(""mapred.job.tracker"", ""cluster_ip:port"");
job.set(""fs.default.name"", ""hdfs://cluster_ip:port"");
 job.set(""hadoop.job.ugi"", ""hadoop,hadoop"");
job.set(""user"", ""hadoop"");       
        try {
            JobClient jobc=new JobClient(job);
            System.out.println(jobc+"" ""+job);
            RunningJob runjob;
            runjob = jobc.submitJob(job);
            System.out.println(runjob);
            System.out.println(""VM ""+Inet4Address.getLocalHost());
            while(runjob.getJobStatus().equals(JobStatus.SUCCEEDED)){}
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        } 
    }
I have tried to set up correctly hadoop using the following mapred-site.xml:
<configuration>
     <property>
         <name>mapred.job.tracker</name>
         <value>cluster_ip:port</value>
     </property>
 <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>"
MAPREDUCE-5900,Container preemption interpreted as task failures and eventually job failures ,"We have Added preemption exit code needs to be incorporated
MR needs to recognize the special exit code value of -102 and interpret it as a container being killed instead of a container failure."
MAPREDUCE-5899,Support incremental data copy in DistCp,"Currently when doing distcp with -update option, for two files with the same file names but with different file length or checksum, we overwrite the whole file. It will be good if we can detect the case where (sourceFile = targetFile + appended_data), and only transfer the appended data segment to the target. This will be very useful if we're doing incremental distcp."
MAPREDUCE-5898,distcp to support preserving HDFS extended attributes(XAttrs),"This JIRA to track the distcp support to handle the Xattrs with preserving options.
Add new command line argument to support that."
MAPREDUCE-5896,InputSplits should indicate which locations have the block cached in memory,
MAPREDUCE-5895,FileAlreadyExistsException was thrown : Temporary Index File can not be cleaned up because OutputStream doesn't close properly,"In TaskLog.java, Temporary Index File is created by following code.

{code}
BufferedOutputStream bos =
  new BufferedOutputStream(
    SecureIOUtils.createForWrite(tmpIndexFile, 0644));
DataOutputStream dos = new DataOutputStream(bos);
{code}

The code is surrounded by try-finally so if some Exception/ERROR is thrown between constructing bos and dos, temporary file is not cleaned up.
I met the situation that when a thread ran, OOM was thrown after bos created and temporary file is not cleaned up. At different time, another thread executed same logic and fail because of FileAlreadyExistsException."
MAPREDUCE-5891,Improved shuffle error handling across NM restarts,To minimize the number of map fetch failures reported by reducers across an NM restart it would be nice if reducers only reported a fetch failure after trying for at specified period of time to retrieve the data.
MAPREDUCE-5890,Support for encrypting Intermediate data and spills in local filesystem,"For some sensitive data, encryption while in flight (network) is not sufficient, it is required that while at rest it should be encrypted. HADOOP-10150 & HDFS-6134 bring encryption at rest for data in filesystem using Hadoop FileSystem API. MapReduce intermediate data and spills should also be encrypted while at rest."
MAPREDUCE-5888,Failed job leaves hung AM after it unregisters ,"When a job fails the AM hangs during shutdown.  A non-daemon thread pool executor thread prevents the JVM teardown from completing, and the AM lingers on the cluster for the AM expiry interval in the FINISHING state until eventually the RM expires it and kills the container.  If application limits on the queue are relatively low (e.g.: small queue or small cluster) this can cause unnecessary delays in resource scheduling on the cluster."
MAPREDUCE-5887,Move split creation from submission client to MRAppMaster,"This JIRA is filed to improve scalability of job submission, specifically when there is a significant latency between the submission client and the cluster nodes RM and NN, e.g. in a multi-datacenter environment."
MAPREDUCE-5886,Allow wordcount example job to accept multiple input paths.,It would be convenient if the wordcount example MapReduce job could accept multiple input paths and run the word count on all of them.
MAPREDUCE-5885,build/test/test.mapred.spill causes release audit warnings,"Multiple unit tests are creating files under hadoop-mapreduce-client-jobclient/build/test/test.mapred.spill which are causing release audit warnings during Jenkins patch precommit builds.  In addition to being in a poor location for test output and not cleaning up after the test, there are multiple tests using this location which will cause conflicts if tests are run in parallel."
MAPREDUCE-5884,History server uses short user name when canceling tokens,"When the owner of a token tries to explicitly cancel the token, it gets the following error/exception
{noformat} 
2014-04-14 20:07:35,744 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:<someuser>/<machine_name>.linkedin.com@<realm>.LINKEDIN.COM (auth:KERBEROS) cause:org.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token
2014-04-14 20:07:35,744 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 10020, call org.apache.hadoop.mapreduce.v2.api.HSClientProtocolPB.cancelDelegationToken from 172.20.158.61:49042 Call#4 Retry#0: error: org.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token
org.apache.hadoop.security.AccessControlException: <someuser> is not authorized to cancel the token
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.cancelToken(AbstractDelegationTokenSecretManager.java:429)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.cancelDelegationToken(HistoryClientService.java:400)
        at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.cancelDelegationToken(MRClientProtocolPBServiceImpl.java:286)
        at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:301)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)

{noformat}


Details:
AbstractDelegationTokenSecretManager.cacelToken() gets the owner as full principal name where as the canceller is the short name.
The potential code snippets:
{code}
String owner = id.getUser().getUserName(); 
    Text renewer = id.getRenewer();
    HadoopKerberosName cancelerKrbName = new HadoopKerberosName(canceller);
    String cancelerShortName = cancelerKrbName.getShortName();
    if (!canceller.equals(owner)
        && (renewer == null || renewer.toString().isEmpty() || !cancelerShortName
            .equals(renewer.toString()))) {
      throw new AccessControlException(canceller
          + "" is not authorized to cancel the token"");
    }
{code}

The code shows 'owner' gets the full principal name. Where as the value of 'canceller' depends on who is calling it. 
In some cases, it is the short name. REF: HistoryClientService.java
{code}
String user = UserGroupInformation.getCurrentUser().getShortUserName();
        jhsDTSecretManager.cancelToken(token, user);
{code}
 
In other cases, the value could be full principal name. REF: FSNamesystem.java.
{code}
String canceller = getRemoteUser().getUserName();
      DelegationTokenIdentifier id = dtSecretManager
        .cancelToken(token, canceller);
{code}

Possible resolution:
--------------------------
Option 1: in cancelToken() method, compare with both : short name and full principal name.
Pros: Easy. Have to change in one place.
Cons: Someone can argue that it is hacky!
 
Option 2:
All the caller sends the consistent value as 'canceller' : either short name or full principal name.

Pros: Cleaner.
Cons: A lot of code changes and potential bug injections.

I'm open for both options.
Please give your opinion.

Btw, how it is working now in most cases?  The short name and the full principal name are usually the same for end-users.


"
MAPREDUCE-5883,"""Total megabyte-seconds"" in job counters is slightly misleading","The following counters are in milliseconds so ""megabyte-seconds"" might be better stated as ""megabyte-milliseconds""
MB_MILLIS_MAPS.name=               Total megabyte-seconds taken by all map tasks
MB_MILLIS_REDUCES.name=            Total megabyte-seconds taken by all reduce tasks
VCORES_MILLIS_MAPS.name=           Total vcore-seconds taken by all map tasks
VCORES_MILLIS_REDUCES.name=        Total vcore-seconds taken by all reduce tasks
"
MAPREDUCE-5879,Hive is broke after YARN-1553,Hive cannot build against branch-2 after YARN-1553
MAPREDUCE-5878,some standard JDK APIs are not part of system classes defaults,"There are some standard JDK APIs that are not part of the mapreduce.job.classloader.system.classes property value.

Currently the default value covers only ""java.,javax."" from the JDK. However, there are other APIs that are as well-established as these, such as org.w3c.dom and org.xml.sax. In other similar systems (e.g. OSGi), it is a standard practice to include both of these packages in the system classes. We should add these to the default values."
MAPREDUCE-5877,Inconsistency between JT/TT for tasks taking a long time to launch,"For the tasks that take too long to launch (for genuine reasons like large distributed caches), JT expires the task. Depending on whether job recovery is enabled and the JT's restart state, another attempt is launched or not even when the JT is not restarted. The status of the attempt changes to ""Error launching task"". Meanwhile, the TT is not informed of this task expiry and eventually launches the task. Also, the ""new"" attempt might be assigned to the same TT leading to more inconsistent behavior. 

To avoid this, one can bump up the mapred.tasktracker.expiry.interval, but leading to long TT failure discovery times. 

We should have a per-job timeout for task launches/ heartbeat and JT/TT should be consistent in what they say."
MAPREDUCE-5875,"Make Counter limits consistent across JobClient, MRAppMaster, and YarnChild","Currently, counter limits ""mapreduce.job.counters.*"" handled by {{org.apache.hadoop.mapreduce.counters.Limits}} are initialized asymmetrically: on the client side, and on the AM, job.xml is ignored whereas it's taken into account in YarnChild.

It would be good to make the Limits job-configurable, such that max counters/groups is only increased when needed. With the current Limits implementation relying on static constants, it's going to be challenging for tools that submit jobs concurrently  without resorting to class loading isolation.

The patch that I am uploading is not perfect but demonstrates the issue. "
MAPREDUCE-5874,Creating MapReduce REST API section,"Now that we have the YARN HistoryServer, perhaps we should move HistoryServerRest.apt.vm and MapRedAppMasterRest.apt.vm into the MapReduce section where it really belongs?"
MAPREDUCE-5873,Shuffle bandwidth computation includes time spent waiting for maps,"Currently ShuffleScheduler in ReduceTask JVM status displays bandwidth. Its definition however is confusing because it captures the time where there is no copying because there is a pause between when new wave of map outputs is available.
current bw is definded as (bytes copied so far) / (total time in the copy phase so far)
It would be more useful 
1) to measure bandwidth of a single copy call.
2) display aggregated bw as long as there is at least one fetcher is in the copy call."
MAPREDUCE-5872,Update NativeS3FileSystem to issue copy commands for files with in a directory with a configurable number of threads,"In NativeS3FileSystem if you do a copy of a directory it will copy all the files to the new location, but it will do this with one thread.  Code is below.  This jira will allow a configurable number of threads to be used to issue the copy commands to S3.

do {
        PartialListing listing = store.list(srcKey, S3_MAX_LISTING_LENGTH, priorLastKey, true);
        for (FileMetadata file : listing.getFiles()) {
          keysToDelete.add(file.getKey());
          store.copy(file.getKey(), dstKey + file.getKey().substring(srcKey.length()));
        }
        priorLastKey = listing.getPriorLastKey();
      } while (priorLastKey != null);"
MAPREDUCE-5871,Estimate Job Endtime,"YARN-1969 adds a new earliest-endtime-first policy to the fair scheduler. As a prerequisite step, the AppMaster should estimate its end time and send it to the RM via the heartbeat. This jira focuses on how the AppMaster performs this estimation."
MAPREDUCE-5870,Support for passing Job priority through Application Submission Context in Mapreduce Side,"Job Priority support in MapReduce.

1. Job Priority can be set from client side as below (Configuration and api).
			- JobConf.getJobPriority() and JobConf.setJobPriority(JobPriority priority) 
			- We can also use configuration ""mapreduce.job.priority"".

		Now this Job priority can be passed in Application Submission context from Client side.
		Here we can reuse the MRJobConfig.PRIORITY configuration. 
2. CLI changes to support {{--set-priority}}. Run time change of JobPriority is also to be handled.
3. Change {{Job}} to have the support for {{setPriority}} and {{getPriority}} (getter is handled with JobStatus)"
MAPREDUCE-5869,Wrong date and and time on job tracker page,"When an application master restarts during execution of a task, job tracker page displays wrong start date-time for the job."
MAPREDUCE-5868,TestPipeApplication causing nightly build to fail,TestPipeApplication appears to be timing out which causes the nightly build to fail.
MAPREDUCE-5867,Possible NPE in KillAMPreemptionPolicy related to ProportionalCapacityPreemptionPolicy,"I configured KillAMPreemptionPolicy for My Application Master and tried to check preemption of queues.
In one scenario I have seen below NPE in my AM

014-04-24 15:11:08,860 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.app.rm.preemption.KillAMPreemptionPolicy.preempt(KillAMPreemptionPolicy.java:57)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:662)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:246)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:267)
	at java.lang.Thread.run(Thread.java:662)

I was using 2.2.0 and merged MAPREDUCE-5189 to see how AM preemption works."
MAPREDUCE-5866,TestFixedLengthInputFormat fails in windows,org.apache.hadoop.mapred.TextFixedLengthInputFormat and org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat tests fail in Windows
MAPREDUCE-5862,Line records longer than 2x split size aren't handled correctly,"Suppose this split (100-200) is in the middle of a record (90-240):

{noformat}
   0              100            200             300
   |---- split ----|---- curr ----|---- split ----|
                 <------- record ------->
                 90                     240
{noformat}
      
Currently, the first split would read the entire record, up to offset 240, which is good. But the 2nd split has a bug in producing a phantom record of (200, 240)."
MAPREDUCE-5861,finishedSubMaps field in LocalContainerLauncher does not need to be volatile,"Around line 374:
{code}
          if (++finishedSubMaps == numMapTasks) {
            doneWithMaps = true;
          }
{code}
The increment of finishedSubMaps is not atomic.

See the answer to http://stackoverflow.com/questions/9749746/what-is-the-difference-of-atomic-volatile-synchronize .

AtomicInteger can be used to achieve atomicity."
MAPREDUCE-5856,Counter limits always use defaults even if JobClient is given a different Configuration,"If you have a job with more than the default number of counters (i.e. > 120), and you create a JobClient with a Configuration where the default is increased (e.g. 500), then JobClient will throw this Exception:
{noformat}
org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120
{noformat}"
MAPREDUCE-5853,ChecksumFileSystem.getContentSummary() including contents for crc files ,"Trying to track down some differences in Hive statistics between hadoop-1/hadoop-2.  It looks like although ChecksumFileSystem.listStatus() filters out CRC files, getContentSummary() falls back to using the FilterFileSystem.getContentSummary() implementation, which calls fs.getContentSummary().  The underlying fs may not have the same filters as the ChecksumFileSystem and so the CRC files can get included in the content summary."
MAPREDUCE-5852,Prepare MapReduce codebase for JUnit 4.11.,"HADOOP-10503 upgrades the entire Hadoop repo to use JUnit 4.11. Some of the MapReduce code needs some minor updates to fix deprecation warnings before the upgrade.
"
MAPREDUCE-5850,PATH environment variable contains duplicate values in map and reduce tasks on Windows.,"The value of the PATH environment variable gets appended twice before execution of a container for a map or reduce task.  This is ultimately harmless at runtime, but it does cause a failure in {{TestMiniMRChildTask}} when running on Windows."
MAPREDUCE-5848,MapReduce counts forcibly preempted containers as FAILED,"The MapReduce AM is considering a forcibly preempted container as FAILED, while I think it should be considered as KILLED (i.e., not count against the maximum number of failures). "
MAPREDUCE-5847,Remove redundant code for fileOutputByteCounter in MapTask and ReduceTask ,"Both MapTask and ReduceTask carry redundant code to update BYTES_WRITTEN counter. However, {{Task.updateCounters}} uses file system stats for this. "
MAPREDUCE-5846,Rumen doesn't understand JobQueueChangedEvent,"MAPREDUCE:5732 introduced a JobQueueChangeEvent to jhist files. Rumen fails to parse jhist files containing this event. 
"
MAPREDUCE-5844,Add a configurable delay to reducer-preemption,"We observed cases where the reducer preemption makes the job finish much later, and the preemption does not seem to be necessary since after preemption both the preempted reducer and the mapper are assigned immediately--meaning that there was already enough space for the mapper.

The logic for triggering preemption is at RMContainerAllocator::preemptReducesIfNeeded
The preemption is triggered if the following is true:
{code}
headroom +  am * |m| + pr * |r| < mapResourceRequest
{code} 
where am: number of assigned mappers, |m| is mapper size, pr is number of reducers being preempted, and |r| is the reducer size.

The original idea apparently was that if headroom is not big enough for the new mapper requests, reducers should be preempted. This would work if the job is alone in the cluster. Once we have queues, the headroom calculation becomes more complicated and it would require a separate headroom calculation per queue/job.

So, as a result headroom variable is kind of given up currently: *headroom is always set to 0* What this implies to the speculation is that speculation becomes very aggressive, not considering whether there is enough space for the mappers or not."
MAPREDUCE-5843,TestMRKeyValueTextInputFormat failing on Windows,TestMRKeyValueInputFormat fails intermittently on Windows.
MAPREDUCE-5842,uber job with LinuxContainerExecutor cause exception,"enable ubertask with linux container executer cause exception:
{noformat}
2014-04-17 23:26:07,859 DEBUG [localfetcher#1] org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: LocalFetcher 1 going to fetch: attempt_1397748070416_0001_m_000006_0
2014-04-17 23:26:07,860 WARN [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Exception running local (uberized) 'child' : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in localfetcher#1
	at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:134)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:376)
	at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.runSubtask(LocalContainerLauncher.java:351)
	at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.run(LocalContainerLauncher.java:232)
	at java.lang.Thread.run(Thread.java:744)
Caused by: java.lang.ExceptionInInitializerError
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:70)
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:62)
	at org.apache.hadoop.mapred.SpillRecord.<init>(SpillRecord.java:57)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.copyMapOutput(LocalFetcher.java:123)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.doCopy(LocalFetcher.java:101)
	at org.apache.hadoop.mapreduce.task.reduce.LocalFetcher.run(LocalFetcher.java:84)
Caused by: java.lang.RuntimeException: Secure IO is not possible without native code extensions.
	at org.apache.hadoop.io.SecureIOUtils.<clinit>(SecureIOUtils.java:75)
	... 6 more
{noformat}"
MAPREDUCE-5841,uber job doesn't terminate on getting mapred job kill,"If you issue a ""mapred job -kill"" against a uberized job, the job (and the yarn application) state transitions to KILLED, but the application master process continues to run. The job actually runs to completion despite the killed status.

This can be easily reproduced by running a sleep job:

{noformat}
hadoop jar hadoop-mapreduce-client-jobclient-2.3.0-tests.jar sleep -m 1 -r 0 -mt 300000
{noformat}

Issue a kill with ""mapred job -kill \[job-id\]"". The UI will show the job (app) is in the KILLED state. However, you can see the application master is still running."
MAPREDUCE-5840,Update MapReduce calls to ProxyUsers#authorize.,HADOOP-10499 will remove an unnecessary overload of {{ProxyUsers#authorize}}. This issue tracks updating call sites in the MapReduce code.
MAPREDUCE-5837,MRAppMaster fails when checking on uber mode,"When the MRAppMaster determines whether the job should run in the uber mode, it call {{Class.forName()}} to check whether the class is derived from {{ChainMapper}}:

{code}
 try {
      String mapClassName = conf.get(MRJobConfig.MAP_CLASS_ATTR);
      if (mapClassName != null) {
        Class<?> mapClass = Class.forName(mapClassName);
        if (ChainMapper.class.isAssignableFrom(mapClass))
          isChainJob = true;
      }
    } catch (ClassNotFoundException cnfe) {
      // don't care; assume it's not derived from ChainMapper
    }
{code}

The problem here is that {{Class.forName()}} can also throw {{NoClassDefError}}. It happens when the additional dependent jar is unavailable to the MRAppMaster. For example, the MRAppMaster complains about a MR job on Scala:

{noformat}
2014-04-15 11:52:55,877 FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
java.lang.NoClassDefFoundError: scala/Function1
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:190)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.isChainJob(JobImpl.java:1282)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.makeUberDecision(JobImpl.java:1224)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.access$3700(JobImpl.java:136)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1425)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1363)
        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:976)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:135)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1263)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1063)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1480)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1606)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1476)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1409)
Caused by: java.lang.ClassNotFoundException: scala.Function1
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
        ... 22 more
{noformat}
 
The proposed fix is to catch {{NoClassDefError}} at the corresponding places."
MAPREDUCE-5836,Fix typo in RandomTextWriter,"In RandomTextWriter.java, there is a typo.
{code}
  /**
   * A random list of 100 words from /usr/share/dict/words
   */
  private static String[] words = {
                                   ""diurnalness"", ""Homoiousian"",
{code}
The list actually contains 1000 words."
MAPREDUCE-5835,Killing Task might cause the job to go to ERROR state,"There could be a race condition if job is killed right after task attempt receives TA_DONE event. In that case, TaskImpl might receive T_ATTEMPT_SUCCEEDED followed by T_ATTEMPTED_KILLED for the same attempt, thus transition job to ERROR state.

a. The task is in KILL_WAIT.
b. TA receives TA_DONE event.
c. Before TA transitions to SUCCEEDED state, Task sends TA_KILL event.
d. TA transitions to SUCCEEDED state and thus send T_ATTEMPT_SUCCEEDED to the task. The task transitions to KILLED state.
e. TA processes TA_KILL event and sends T_ATTEMPT_KILLED to the task.
f. When task is in KILLED state, it can't handle T_ATTEMPT_KILLED event, thus transition job to ERROR state.
"
MAPREDUCE-5834,TestGridMixClasses tests timesout on branch-2,"testSleepReducer times out everytime I try to run it.
{noformat}
java.lang.Exception: test timed out after 1000 milliseconds
	at org.apache.hadoop.mapred.gridmix.TestGridMixClasses$FakeRawKeyValueReducerIterator.getKey(TestGridMixClasses.java:947)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:138)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapred.gridmix.SleepJob$SleepReducer.setup(SleepJob.java:173)
	at org.apache.hadoop.mapred.gridmix.TestGridMixClasses.testSleepReducer(TestGridMixClasses.java:911)
{noformat}"
MAPREDUCE-5833,TestRMContainerAllocator fails ocassionally,"testReportedAppProgress and testReportedAppProgressWithOnlyMaps have race conditions.

{code}
Stacktrace

java.util.NoSuchElementException: null
	at java.util.Collections$EmptyIterator.next(Collections.java:2998)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testReportedAppProgress(TestRMContainerAllocator.java:535)
{code}

{code}
Error Message

Task state is not correct (timedout) expected:<RUNNING> but was:<SCHEDULED>
Stacktrace

junit.framework.AssertionFailedError: Task state is not correct (timedout) expected:<RUNNING> but was:<SCHEDULED>
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.failNotEquals(Assert.java:287)
	at junit.framework.Assert.assertEquals(Assert.java:67)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.waitForState(MRApp.java:393)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testReportedAppProgressWithOnlyMaps(TestRMContainerAllocator.java:700)
{code}"
MAPREDUCE-5832,Few tests in TestJobClient fail on Windows,"java.lang.Exception: test timed out after 1000 milliseconds
	at java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:866)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1258)
	at java.net.InetAddress.getLocalHost(InetAddress.java:1434)
	at sun.security.krb5.Config.getRealmFromDNS(Config.java:1174)
	at sun.security.krb5.Config.getDefaultRealm(Config.java:1081)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.security.authentication.util.KerberosUtil.getDefaultRealm(KerberosUtil.java:75)
	at org.apache.hadoop.security.authentication.util.KerberosName.<clinit>(KerberosName.java:85)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:246)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:233)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:719)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:704)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:606)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:81)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:75)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:470)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:460)
	at org.apache.hadoop.mapred.TestJobClient.testGetStagingAreaDir(TestJobClient.java:74)"
MAPREDUCE-5831,Old MR client is not compatible with new MR application,"Recently, we saw the following scenario:

1. The user setup a cluster of hadoop 2.3., which contains YARN 2.3 and MR  2.3.

2. The user client on a machine that MR 2.2 is installed and in the classpath.

Then, when the user submitted a simple wordcount job, he saw the following message:
{code}
16:00:41,027  INFO main mapreduce.Job:1345 -  map 100% reduce 100%
16:00:41,036  INFO main mapreduce.Job:1356 - Job job_1396468045458_0006 completed successfully
16:02:20,535  WARN main mapreduce.JobRunner:212 - Cannot start job [wordcountJob]
java.lang.IllegalArgumentException: No enum constant org.apache.hadoop.mapreduce.JobCounter.MB_MILLIS_REDUCES
	at java.lang.Enum.valueOf(Enum.java:236)
	at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.valueOf(FrameworkCounterGroup.java:148)
	at org.apache.hadoop.mapreduce.counters.FrameworkCounterGroup.findCounter(FrameworkCounterGroup.java:182)
	at org.apache.hadoop.mapreduce.counters.AbstractCounters.findCounter(AbstractCounters.java:154)
	at org.apache.hadoop.mapreduce.TypeConverter.fromYarn(TypeConverter.java:240)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:370)
	at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:511)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:756)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:753)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:753)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1361)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1289)
        . . .
{code}

The problem is that the wordcount job was running on one or more than one nodes of the YARN cluster, where MR 2.3 libs were installed, and JobCounter.MB_MILLIS_REDUCES is available in the counters. On the other side, due to the classpath setting, the client was likely to run with MR 2.2 libs. After the client retrieved the counters from MR AM, it tried to construct the Counter object with the received counter name. Unfortunately, the enum didn't exist in the client's classpath. Therefore, ""No enum constant"" exception is thrown here.

JobCounter.MB_MILLIS_REDUCES is brought to MR2 via MAPREDUCE-5464 since Hadoop 2.3."
MAPREDUCE-5830,HostUtil.getTaskLogUrl is not backwards binary compatible with 2.3,"HostUtil.getTaskLogUrl used to have a signature like this in Hadoop 2.3.0 and earlier:

public static String getTaskLogUrl(String taskTrackerHostName, String httpPort, String taskAttemptID)

but now has a signature like this:

public static String getTaskLogUrl(String scheme, String taskTrackerHostName, String httpPort, String taskAttemptID)

This breaks source and binary backwards-compatibility.  MapReduce and Hive both have references to this, so their jars compiled against 2.3 or earlier do not work on 2.4."
MAPREDUCE-5828,TestMapReduceJobControl fails on JDK 7 + Windows,"It fails when testControlledJob() runs first on Windows with an exception message saying ""output_2"" directory already exists."
MAPREDUCE-5827,TestSpeculativeExecutionWithMRApp fails,"{code}
junit.framework.AssertionFailedError: Couldn't speculate successfully
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at org.apache.hadoop.mapreduce.v2.TestSpeculativeExecutionWithMRApp.testSpeculateSuccessfulWithoutUpdateEvents(TestSpeculativeExecutionWithMRApp.java:122
{code}"
MAPREDUCE-5826,TestHistoryServerFileSystemStateStoreService.testTokenStore fails in windows,The test is failing in windows with the updateToken function failing.
MAPREDUCE-5825,Provide diagnostics for reducers killed during ramp down,"Since we operate many queues pretty much at their capacity it some times happens that a failed mapper causes a reducer ramp down. However, the user can only see ""Container killed by the ApplicationMaster"" as a diagnostic message for the task attempt, and have to dig through the AM log in order to piece things together."
MAPREDUCE-5824,TestPipesNonJavaInputFormat.testFormat fails in windows,
MAPREDUCE-5823,TestTaskAttempt fails in trunk and branch-2 with NPE,"Here is the console output I got

{noformat}
java.lang.NullPointerException: null
	at org.apache.hadoop.security.token.Token.write(Token.java:221)
	at org.apache.hadoop.mapred.ShuffleHandler.serializeServiceData(ShuffleHandler.java:272)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createCommonContainerLaunchContext(TaskAttemptImpl.java:715)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createContainerLaunchContext(TaskAttemptImpl.java:801)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1516)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1493)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:362)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1058)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.testTooManyFetchFailureAfterKill(TestTaskAttempt.java:660)
{noformat}"
MAPREDUCE-5822,FairScheduler does not preempt due to fairshare-starvation when fairshare is 1,"If the fair share returned by the scheduler getFairShare() == 1 the pool will never be marked as being starved because of the following calculation:

{code}
boolean isStarvedForFairShare(PoolSchedulable sched) { 
  int desiredFairShare = (int) Math.floor(Math.min( sched.getFairShare() / 2, sched.getDemand())); 
  return (sched.getRunningTasks() < desiredFairShare); 
}
{code}
getFairShare() returns 1
Math.min calculation will return 0.5
Math.Floor() which will cause the desiredFairShare to be set to 0.
the return value to be 'false' (0 < 0)
If you have a small job without a minimum set it will not get scheduled if a large job is hogging the slots."
MAPREDUCE-5821,IFile merge allocates new byte array for every value,"I wrote a standalone benchmark of the MapOutputBuffer and found that it did a lot of allocations during the merge phase. After looking at an allocation profile, I found that IFile.Reader.nextRawValue() would always allocate a new byte array for every value, so the allocation rate goes way up during the merge phase of the mapper. I imagine this also affects the reducer input, though I didn't profile that."
MAPREDUCE-5820,Unable to process mongodb gridfs collection data in Hadoop Mapreduce,"I saved a 2GB pdf file into MongoDB using GridFS. now i want process those GridFS collection data using Java Spark Mapreduce. previously i have succesfully processed mongoDB collections with Hadoop mapreduce using Mongo-Hadoop connector. now i'm unable to handle binary data which is coming from input GridFS collections.

 MongoConfigUtil.setInputURI(config, ""mongodb://localhost:27017/pdfbooks.fs.chunks"" );
 MongoConfigUtil.setOutputURI(config,""mongodb://localhost:27017/""+output );
 JavaPairRDD<Object, BSONObject> mongoRDD = sc.newAPIHadoopRDD(config,
            com.mongodb.hadoop.MongoInputFormat.class, Object.class,
            BSONObject.class);
 JavaRDD<String> words = mongoRDD.flatMap(new FlatMapFunction<Tuple2<Object,BSONObject>,
   String>() {                                
   @Override
   public Iterable<String> call(Tuple2<Object, BSONObject> arg) {   
   System.out.println(arg._2.toString());
   ...
In the above code i'm accesing fs.chunks collection as input to my mapper. so mapper is taking it as BsonObject. but the problem is that input BSONObject data is in unreadable binary format. for example the above program ""System.out.println(arg._2.toString());"" statement giving following result:

   { ""_id"" : { ""$oid"" : ""533e53048f0c8bcb0b3a7ff7""} , ""files_id"" : { ""$oid"" : ""533e5303fac7a2e2c4afea08""} , ""n"" : 0 , ""data"" : <Binary Data>}

How Do i print/access that data in readable format. Can i use GridFS Api to do that. if so please suggest me how to convert input BSONObject to GridFS object and other best ways to do...Thank you in Advance!!!"
MAPREDUCE-5818,hsadmin cmd is missing in mapred.cmd,
MAPREDUCE-5817,Mappers get rescheduled on node transition even after all reducers are completed,"We're seeing a behavior where a job runs long after all reducers were already finished. We found that the job was rescheduling and running a number of mappers beyond the point of reducer completion. In one situation, the job ran for some 9 more hours after all reducers completed!

This happens because whenever a node transition (to an unusable state) comes into the app master, it just reschedules all mappers that already ran on the node in all cases.

Therefore, if any node transition has a potential to extend the job period. Once this window opens, another node transition can prolong it, and this can happen indefinitely in theory.

If there is some instability in the pool (unhealthy, etc.) for a duration, then any big job is severely vulnerable to this problem.

If all reducers have been completed, JobImpl.actOnUnusableNode() should not reschedule mapper tasks. If all reducers are completed, the mapper outputs are no longer needed, and there is no need to reschedule mapper tasks as they would not be consumed anyway."
MAPREDUCE-5816,TestMRAppMaster fails in trunk,"As can be seen from https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1741/console:
{code}
Tests in error: 
  TestMRAppMaster.testMRAppMasterMidLock:163 » NullPointer
  TestMRAppMaster.testMRAppMasterSuccessLock:202 » NullPointer
  TestMRAppMaster.testMRAppMasterFailLock:241 » NullPointer
{code}
I got the following locally:
{code}
Tests run: 7, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 2.964 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster
testMRAppMasterMidLock(org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster)  Time elapsed: 0.963 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.escapeDelimiters(FileNameIndexUtils.java:275)
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.getDoneFileName(FileNameIndexUtils.java:97)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:743)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:158)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1491)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1099)
	at org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMidLock(TestMRAppMaster.java:163)

testMRAppMasterSuccessLock(org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster)  Time elapsed: 0.25 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.escapeDelimiters(FileNameIndexUtils.java:275)
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.getDoneFileName(FileNameIndexUtils.java:97)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:743)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:158)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1491)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1099)
	at org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterSuccessLock(TestMRAppMaster.java:202)

testMRAppMasterFailLock(org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster)  Time elapsed: 0.232 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.escapeDelimiters(FileNameIndexUtils.java:275)
	at org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils.getDoneFileName(FileNameIndexUtils.java:97)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.processDoneFiles(JobHistoryEventHandler.java:743)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:158)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:131)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStop(MRAppMaster.java:1491)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.stop(MRAppMaster.java:1099)
	at org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterFailLock(TestMRAppMaster.java:241)
{code}"
MAPREDUCE-5815,Fix NPE in TestMRAppMaster,Working MAPREDUCE-5813 I stumbled on NPE's in TestMRAppMaster. They seem to be introduced by MAPREDUCE-5805.
MAPREDUCE-5814,fat jar with *-default.xml may fail when mapreduce.job.classloader=true.,We faced a failure when a job.jar compiled against 0.20+ hadoop artifacts had to run with {{mapreduce.job.classloader=true}} because it needed a more recent guava as a dependency. The job failed because the cluster's {{*-default.xml}} files were overshadowed by the ones in the fat jar. We propose to treat these default config files like the system packages {{org.apache.hadoop.}} to avoid a counterintuitivie behavior as if we had {{mapreduce.job.user.classpath.first}} set.
MAPREDUCE-5813,YarnChild does not load job.xml with mapreduce.job.classloader=true ,"{{YarnChild.main}} uses {{JobConf.addResource(String)}} to load {{job.xml}} that relies on class loading. When {{mapreduce.job.classloader=true}} the job-speicific part of the class path is separated from {{CLASSPATH}} into {{APP_CLASSPATH}}. Therefore {{job.xml}} is inaccessible for the default class loader. Later {{writeLocalJobFile}} overwrites the correct localized {{job.xml}} on disk as well.

This problem is easily avoided by using  {{JobConf.addResource(Path)}} to read the localized {{job.xml}} without relying on class loading.

"
MAPREDUCE-5812, Make job context available to OutputCommitter.isRecoverySupported(),"Background
==========
The system like Hive provides its version of  OutputCommitter. The custom implementation of isRecoverySupported() requires task context. From taskContext:getConfiguration(), hive checks if  hive-defined specific property is set or not. Based on the property value, it returns true or false. However, in the current OutputCommitter:isRecoverySupported(), there is no way of getting task config. As a result, user can't  turn on/off the MRAM recovery feature.

Proposed resolution:
===============
1. Pass Task Context into  isRecoverySupported() method.
Pros: Easy and clean
Cons: Possible backward compatibility issue due to aPI changes. (Is it true?)

2. Call outputCommitter.setupTask(taskContext) from MRAM: The new OutputCommitter will store the context in the class level variable and use it from  isRecoverySupported() 

Props: No API changes. No backward compatibility issue. This call can be made from MRAppMaster.getOutputCommitter() method for old API case.
Cons: Might not be very clean solution due to class level variable.

Please give your comments.
"
MAPREDUCE-5810,TestStreamingTaskLog#testStreamingTaskLogWithHadoopCmd is failing,"testStreamingTaskLogWithHadoopCmd(org.apache.hadoop.streaming.TestStreamingTaskLog)  Time elapsed: 44.069 sec  <<< FAILURE!
java.lang.AssertionError: environment set for child is wrong
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.apache.hadoop.streaming.TestStreamingTaskLog.runStreamJobAndValidateEnv(TestStreamingTaskLog.java:157)
	at org.apache.hadoop.streaming.TestStreamingTaskLog.testStreamingTaskLogWithHadoopCmd(TestStreamingTaskLog.java:107)


Results :

Failed tests: 
  TestStreamingTaskLog.testStreamingTaskLogWithHadoopCmd:107->runStreamJobAndValidateEnv:157 environment set for child is wrong"
MAPREDUCE-5809,Enhance distcp to support preserving HDFS ACLs.,This issue tracks enhancing distcp to add a new command-line argument for preserving HDFS ACLs from the source at the copy destination.
MAPREDUCE-5808,Port output replication factor configurable for terasort to Hadoop 1.x,"Currently, terasort output is hardcoded to have replication factor of 1 in TeraSort.java in Hadoop branch-1 code base and configurable in Hadoop 2.0 and trunk. We would like to back port the changes to make terasort output replication factor configurable in Hadoop 1.0."
MAPREDUCE-5807,Print usage for TeraSort job.,"For new to hadoop, try for getting help mesage for examples jobs provided in mapreduce. These Usage helps them in providing arguements.


terasort job execution does not print Usage message instead throw exception.

./yarn jar ../share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar terasort
14/03/24 15:34:55 INFO terasort.TeraSort: starting
java.lang.ArrayIndexOutOfBoundsException: 0
        at org.apache.hadoop.examples.terasort.TeraSort.run(TeraSort.java:283)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.examples.terasort.TeraSort.main(TeraSort.java:325)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
"
MAPREDUCE-5806,Log4j settings in container-log4j.properties cannot be overridden ,"setting HADOOP_ROOT_LOGGER, -Dhadoop.root.logger has no effect"
MAPREDUCE-5805,Unable to parse launch time from job history file,"when job complete, there are WARN complains in the log:
{code}
2014-03-19 13:31:10,036 WARN org.apache.hadoop.mapreduce.v2.jobhistory.FileNameIndexUtils: Unable to parse launch time from job history file job_1395204058904_0003-1395206473646-root-test_one_word-1395206966214-4-2-SUCCEEDED-root.test-queue-1395206480070.jhist : java.lang.NumberFormatException: For input string: ""queue""
{code}

because  there is (-)  in the queue name 'test-queue', we split the job history file name by (-), and get the ninth item as job start time.
FileNameIndexUtils.java
{code}
private static final int JOB_START_TIME_INDEX = 9;
{code}

but there is another potential issue:
if I also include '-' in the job name(test_one_world in this case), there are all misunderstand.
"
MAPREDUCE-5804,TestMRJobsWithProfiler#testProfiler timesout,"{noformat}
testProfiler(org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler)  Time elapsed: 154.972 sec  <<< ERROR!
java.lang.Exception: test timed out after 120000 milliseconds
	at java.io.UnixFileSystem.getBooleanAttributes0(Native Method)
	at java.io.UnixFileSystem.getBooleanAttributes(UnixFileSystem.java:242)
	at java.io.File.exists(File.java:813)
	at sun.misc.URLClassPath$FileLoader.getResource(URLClassPath.java:1080)
	at sun.misc.URLClassPath.getResource(URLClassPath.java:199)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:358)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
	at org.apache.log4j.spi.LoggingEvent.<init>(LoggingEvent.java:165)
	at org.apache.log4j.Category.forcedLog(Category.java:391)
	at org.apache.log4j.Category.log(Category.java:856)
	at org.apache.commons.logging.impl.Log4JLogger.warn(Log4JLogger.java:208)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:338)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:419)
	at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:532)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:314)
	at org.apache.hadoop.mapreduce.Job$1.run(Job.java:311)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1570)
	at org.apache.hadoop.mapreduce.Job.updateStatus(Job.java:311)
	at org.apache.hadoop.mapreduce.Job.isComplete(Job.java:599)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1344)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1306)
	at org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfiler(TestMRJobsWithProfiler.java:138)


Results :

Tests in error: 
  TestMRJobsWithProfiler.testProfiler:138 »  test timed out after 120000 millise...
{noformat}"
MAPREDUCE-5803,Counters page display all task neverthless of task type( Map or Reduce),"Accessing JobCouner page in HistoryServer, display all the task info.Clicking on ""Launched map tasks"" display Map Task and Reduce Task."
MAPREDUCE-5802,Provide an inclusion list mapreduce.job.classloader.job.classes for the class loading isolation,"MAPREDUCE-1700  introduced a way to isolate job-suplied classes in an Application Classloader.  mapreduce.job.classloader.system.classes is a way to provide an exclusion list for this class loader. Sometimes it's much easier to express what to include. For this purpose, we propose an inclusion list. mapreduce.job.classloader.job.classes.  The semantics would be use the exclusion list unless the inclusion list is specified to determine what classes should be loaded in the app class loader."
MAPREDUCE-5801,Uber mode's log message is missing a vcore reason,"If a job cannot be run in uber mode because of insufficient vcores, the resulting log message has an empty reason.
"
MAPREDUCE-5800,Use Job#getInstance instead of deprecated constructors,"There're some methods calling deprecated constructors such as {{new Job()}}, which causes javac warnings.
We should use {{Job.getInstance()}} to get an instance."
MAPREDUCE-5799,add default value of MR_AM_ADMIN_USER_ENV,"Submit a 1 map + 1 reduce sleep job with the following config:
{code}
  <property>
      <name>mapreduce.map.output.compress</name>
      <value>true</value>
  </property>
  <property>
      <name>mapreduce.map.output.compress.codec</name>
      <value>org.apache.hadoop.io.compress.SnappyCodec</value>
  </property>
<property>
  <name>mapreduce.job.ubertask.enable</name>
  <value>true</value>
</property>
{code}
And the LinuxContainerExecutor is enable on NodeManager.
This job will fail with the following error:
{code}
2014-03-18 21:28:20,153 FATAL [uber-SubtaskRunner] org.apache.hadoop.mapred.LocalContainerLauncher: Error running local (uberized) 'child' : java.lang.UnsatisfiedLinkError: org.apache.hadoop.util.NativeCodeLoader.buildSupportsSnappy()Z
        at org.apache.hadoop.util.NativeCodeLoader.buildSupportsSnappy(Native Method)
        at org.apache.hadoop.io.compress.SnappyCodec.checkNativeCodeLoaded(SnappyCodec.java:63)
        at org.apache.hadoop.io.compress.SnappyCodec.getCompressorType(SnappyCodec.java:132)
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:148)
        at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:163)
        at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:115)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1583)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1462)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:700)
        at org.apache.hadoop.mapred.MapTask.closeQuietly(MapTask.java:1990)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:774)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)
        at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.runSubtask(LocalContainerLauncher.java:317)
        at org.apache.hadoop.mapred.LocalContainerLauncher$SubtaskRunner.run(LocalContainerLauncher.java:232)
        at java.lang.Thread.run(Thread.java:662)
{code}

When create a ContainerLaunchContext for task in TaskAttemptImpl.createCommonContainerLaunchContext(), the DEFAULT_MAPRED_ADMIN_USER_ENV which is ""LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native"" is added to the environment. Where when create a ContainerLaunchContext for mrappmaster in YARNRunner.createApplicationSubmissionContext(), there is no default environment. So the ubermode job fails to find native lib."
MAPREDUCE-5796,Use current version of the archive name in DistributedCacheDeploy document,The archive name is {{hadoop-mapreduce-2.1.1.tar.gz}} in DistributedCacheDeploy document but Hadoop 2.1.1 is not released. It should be fixed to {{hadoop-mapreduce-$\{project.version\}.tar.gz}} to show the current version.
MAPREDUCE-5795,Job should be marked as Failed if it is recovered from commit.,"If Resource manager is restarted when a job is in commit state, The job is not able to recovered after RM restart and it is marked as Killed.
The job status should be Failed instead killed."
MAPREDUCE-5794,SliveMapper always uses default FileSystem.,"Similar to MAPREDUCE-5780, SliveMapper should use the test path to get FileSystem."
MAPREDUCE-5793,Make TestMRJobsWithProfiler#testProfiler faster,"TestMRJobsWithProfiler#testProfiler sometimes took more than 120 seconds and then got timeout.
https://builds.apache.org/job/PreCommit-HADOOP-Build/3656//testReport/org.apache.hadoop.mapreduce.v2/TestMRJobsWithProfiler/testProfiler/
"
MAPREDUCE-5792,"When mapreduce.jobhistory.intermediate-done-dir isn't writable, application fails with generic error","When trying to run an application and the permissions are wrong on {{mapreduce.jobhistory.intermediate-done-dir}}, the MapReduce AM fails with a non-descriptive error message:

{noformat}
Application application_1394227890066_0004 failed 2 times due to AM Container for appattempt_1394227890066_0004_000002 exited with exitCode: 1 due to: Exception from container-launch:
org.apache.hadoop.util.Shell$ExitCodeException:
at org.apache.hadoop.util.Shell.runCommand(Shell.java:505)
at org.apache.hadoop.util.Shell.run(Shell.java:418)
at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:650)
at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:279)
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
at java.util.concurrent.FutureTask.run(FutureTask.java:262)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
at java.lang.Thread.run(Thread.java:744)
main : command provided 1
main : user is tthompso
main : requested yarn user is tthompso
Container exited with a non-zero exit code 1
.Failing this attempt.. Failing the application. 
{noformat}

When permissions are corrected on this dir, applications are able to run.  There should probably be some sort of check on this dir before launching the AM so a more meaningful error message can be thrown."
MAPREDUCE-5791,Shuffle phase is slow in Windows - FadviseFileRegion::transferTo does not read disks efficiently,"transferTo method in org.apache.hadoop.mapred.FadvisedFileRegion is using transferTo method from a FileChannel to transfer data from a disk to socket. This is performing slow in Windows, slower than in Linux. The reason is that transferTo method for the java.nio is issuing 32K IO requests all the time. In Windows, these 32K transfers are not optimal and we don't get the best performance form the underlying IO subsystem. In order to achieve better performance when reading from the drives, we need to read data in bigger chunks, 512K for example."
MAPREDUCE-5790,Default map hprof profile options do not work,"I have an MR job doing the following:

{code}
    Job job = Job.getInstance(conf);

    // Enable profiling
    job.setProfileEnabled(true);
    job.setProfileTaskRange(true, ""0"");
    job.setProfileTaskRange(false, ""0"");
{code}

When I run this job, some of my map tasks fail with this error message:

{noformat}
org.apache.hadoop.util.Shell$ExitCodeException: /data/5/yarn/nm/usercache/hdfs/appcache/application_1394482121761_0012/container_1394482121761_0012_01_000041/launch_container.sh: line 32: $JAVA_HOME/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx825955249 -Djava.io.tmpdir=$PWD/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/var/log/hadoop-yarn/container/application_1394482121761_0012/container_1394482121761_0012_01_000041 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA ${mapreduce.task.profile.params} org.apache.hadoop.mapred.YarnChild 10.20.212.12 43135 attempt_1394482121761_0012_r_000000_0 41 1>/var/log/hadoop-yarn/container/application_1394482121761_0012/container_1394482121761_0012_01_000041/stdout 2>/var/log/hadoop-yarn/container/application_1394482121761_0012/container_1394482121761_0012_01_000041/stderr : bad substitution
{noformat}

It looks like ${mapreduce.task.profile.params} is not getting subbed in correctly."
MAPREDUCE-5789,Average Reduce time is incorrect on Job Overview page,"The Average Reduce time displayed on the job overview page is incorrect.
Previously Reduce time was calculated as difference between finishTime and shuffleFinishTime.
It should be difference of finishTime and sortFinishTime"
MAPREDUCE-5788,Modify Fetcher to pull data using persistent connection,
MAPREDUCE-5787,Modify ShuffleHandler to support Keep-Alive,
MAPREDUCE-5786,Support Keep-Alive connections in ShuffleHandler,"Currently ShuffleHandler supports fetching map-outputs in batches from same host.  But there are scenarios wherein, fetchers pull data aggressively (i.e start pulling the data as & when they are available).  In this case, the number of mapIds that are pulled from same host remains at 1. This causes lots of connections to be established.

Number of connections can be reduced a lot if ShuffleHandler supports Keep-Alive.
"
MAPREDUCE-5785,Derive heap size or mapreduce.*.memory.mb automatically,"Currently users have to set 2 memory-related configs per Job / per task type.  One first chooses some container size map reduce.\*.memory.mb and then a corresponding maximum Java heap size Xmx < map reduce.\*.memory.mb. This makes sure that the JVM's C-heap (native memory + Java heap) does not exceed this mapreduce.*.memory.mb. If one forgets to tune Xmx, MR-AM might be 
- allocating big containers whereas the JVM will only use the default -Xmx200m.
- allocating small containers that will OOM because Xmx is too high.

With this JIRA, we propose to set Xmx automatically based on an empirical ratio that can be adjusted. Xmx is not changed automatically if provided by the user.
"
MAPREDUCE-5780,SliveTest always uses default FileSystem,"It should use the specified path to get FileSystem.  Otherwise, it won't work if the FileSystem is different."
MAPREDUCE-5778,JobSummary does not escape newlines in the job name,JobSummary is not escaping newlines in the job name.  This can result in a job summary log entry that spans multiple lines when users are expecting one-job-per-line output.
MAPREDUCE-5777,Support utf-8 text with BOM (byte order marker),"UTF-8 text may have a BOM. TextInputFormat, KeyValueTextInputFormat and friends should recognize the BOM and not treat it as actual data."
MAPREDUCE-5775,Remove unnecessary job.setNumReduceTasks in SleepJob.createJob,"The two SleepJob's createJob() call job.setNumReduceTasks(numReducer) twice, which is unnecessary."
MAPREDUCE-5774,Job overview in History UI should list reducer phases in chronological order,"Current order:

Average Map Time	         9sec
Average Reduce Time	 0sec
Average Shuffle Time	 22sec
Average Merge Time	 0sec

Proposed order:

Average Map Time	         9sec
Average Shuffle Time	 22sec
Average Merge Time	 0sec
Average Reduce Time	 0sec
"
MAPREDUCE-5773,Provide dedicated MRAppMaster syslog length limit,"Currently mapreduce.task.userlog.limit.kb controls both the length of task attempt logs and MA-AM attempt logs. Obviously, MR-AM log is not userlog.
We are interested in keeping MR-AM log either in its entirety or in much larger size than task logs for debugging. 

MAPREDUCE-5672 introduced CRLA. We already use a dedicated setting for how many backups of rolled files we keep for MR-AM. However, for large jobs with tens of megabyte AM log, it means that you have a long series of files. A natural improvement is to have a configuration yarn.app.mapreduce.am.container.log.limit.kb . It allows to either disable rolling the log for altogether while keeping it for the task attempts, or to use much a larger limit to make rolling less frequent. 
"
MAPREDUCE-5770,Redirection from AM-URL is broken with HTTPS_ONLY policy,"

Steps to reproduce:

1) Run a sleep job
2) Run: yarn application -list command to find AM URL.
root@host1:~# yarn application -list
Total number of applications (application-types: [] and states: SUBMITTED, ACCEPTED, RUNNING):1
Application-Id Application-Name Application-Type User Queue State Final-State Progress Tracking-URL
application_1383251398986_0003 Sleep job MAPREDUCE hdfs default RUNNING UNDEFINED 5% http://host1:40653

3) Try to access ""http://host1:40653/ws/v1/mapreduce/info"" url.

This URL redirects to http://RM_host:RM_https_port/proxy/application_1383251398986_0003/ws/v1/mapreduce/info

Here, Http protocol is used with HTTPS port for RM.

The expected Url is https://RM_host:RM_https_port/proxy/application_1383251398986_0003/ws/v1/mapreduce/info
"
MAPREDUCE-5769,Unregistration to RM should not be called if AM is crashed before registering with RM,"Got the scenario from YARN-1752, where unregistration of application master is called before registering with RM.

There should be mechanism to identify isApplicationMasaterRegistered before calling unregistration (finishApplicationMaster)."
MAPREDUCE-5768,TestMRJobs.testContainerRollingLog fails on trunk,"Error Message

Number of sylog* files expected same:<4> was not:<8>
Stacktrace

java.lang.AssertionError: Number of sylog* files expected same:<4> was not:<8>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotSame(Assert.java:641)
	at org.junit.Assert.assertSame(Assert.java:580)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testContainerRollingLog(TestMRJobs.java:523)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:62)"
MAPREDUCE-5766,Ping messages from attempts should be moved to DEBUG,"Messages such as ""org.apache.hadoop.mapred.TaskAttemptListenerImpl: Ping from attempt_1391416522080_0015_m_000000_0"" in AM logs should be moved to DEBUG.
"
MAPREDUCE-5765,Update hadoop-pipes examples README,wordcount-simple is in the native/examples directory
MAPREDUCE-5764,Potential NullPointerException in YARNRunner.killJob(JobID arg0),"I found YARNRunner.killJob(JobID arg0) can throw NullPointerException if job status is null. 
bq. clientCache.getClient(arg0).getJobStatus(arg0);  can be null.
This can happen when there is history write is failed because of hdfs errors or staging directory is different from history server..
 
We need to have null check otherwise killJob() is prone to throw NPE which cause joblient to exit.

{noformat}
@Override
  public void killJob(JobID arg0) throws IOException, InterruptedException {
    /* check if the status is not running, if not send kill to RM */
    JobStatus status = clientCache.getClient(arg0).getJobStatus(arg0);
    if (status.getState() != JobStatus.State.RUNNING) {
      try {
        resMgrDelegate.killApplication(TypeConverter.toYarn(arg0).getAppId());
      } catch (YarnException e) {
        throw new IOException(e);
      }
      return;
    }
.......
......
.......
  }
{noformat}"
MAPREDUCE-5763,Warn message about httpshuffle in NM logs,"{code}
2014-02-20 12:08:45,141 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.
2014-02-20 12:08:45,142 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices: Adding auxiliary service httpshuffle, ""mapreduce_shuffle""
{code}

I'm seeing this in my NodeManager logs,  even though things work fine.  A WARN is being caused by some sort of mismatch between the name of the service (in terms of org.apache.hadoop.service.Service.getName()) and the name of the auxiliary service."
MAPREDUCE-5762,Port MAPREDUCE-3223 and MAPREDUCE-4695 (Remove MRv1 config from mapred-default.xml) to branch-2,"MRv1 configs are removed in trunk, but they are not removed in branch-2."
MAPREDUCE-5761,"Add a log message like ""encrypted shuffle is ON"" in nodemanager logs","Currently no log message gets printed for encrypted shuffle which can determine if encrypted shuffle is On or Off.

Need to add message at Info level such as ""encrypted shuffle is ON"""
MAPREDUCE-5759,Remove unnecessary conf load in Limits,This is a continuation if MAPREDUCE-5487.
MAPREDUCE-5757,ConcurrentModificationException in JobControl.toList,"Despite having the fix for MAPREDUCE-5513 we saw another ConcurrencyModificationException in JobControl, so something there still isn't fixed."
MAPREDUCE-5756,CombineFileInputFormat.getSplits() including directories in its results,"Trying to track down HIVE-6401, where we see some ""is not a file"" errors because getSplits() is giving us directories.  I believe the culprit is FileInputFormat.listStatus():

{code}
                if (recursive && stat.isDirectory()) {
                  addInputPathRecursively(result, fs, stat.getPath(),
                      inputFilter);
                } else {
                  result.add(stat);
                }
{code}

Which seems to be allowing directories to be added to the results if recursive is false.  Is this meant to return directories? If not, I think it should look like this:

{code}
                if (stat.isDirectory()) {
                 if (recursive) {
                  addInputPathRecursively(result, fs, stat.getPath(),
                      inputFilter);
                 }
                } else {
                  result.add(stat);
                }
{code}"
MAPREDUCE-5755,MapTask.MapOutputBuffer#compare/swap should have @Override annotation,"MapTask.MapOutputBuffer#compare/swap implements IndexedSortable interface, but not have @Override annotation. It should be added."
MAPREDUCE-5754,Preserve Job diagnostics in history,History does not store the runtime diagnostics information. JobHistoryParser tries to blame a task. We propose to preserve the original runtime diagnostics that covers all the cases including the job being killed. This is particularly important in the context of user-supplied diagnostic message as in MAPREDUCE-5648. 
MAPREDUCE-5752,Potential invalid iterator in NMClientImpl#cleanupRunningContainers(),"In cleanupRunningContainers() :
{code}
    for (StartedContainer startedContainer : startedContainers.values()) {
      try {
        stopContainer(startedContainer.getContainerId(),
            startedContainer.getNodeId());
{code}
Removal of container is done in removeStartedContainer():
{code}
    startedContainers.remove(container.containerId);
{code}
This may result in invalid iterator for the loop on startedContainers.values()"
MAPREDUCE-5751,MR app master fails to start in some cases if mapreduce.job.classloader is true,"If mapreduce.job.classloader is set to true, and the MR client includes a jetty jar in its libjars or job jar, the MR app master fails to start. A typical stack trace we get is as follows:

{noformat}
java.lang.ClassCastException: org.mortbay.jetty.webapp.WebInfConfiguration cannot be cast to org.mortbay.jetty.webapp.Configuration
	at org.mortbay.jetty.webapp.WebAppContext.loadConfigurations(WebAppContext.java:890)
	at org.mortbay.jetty.webapp.WebAppContext.doStart(WebAppContext.java:462)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerCollection.doStart(HandlerCollection.java:152)
	at org.mortbay.jetty.handler.ContextHandlerCollection.doStart(ContextHandlerCollection.java:156)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.handler.HandlerWrapper.doStart(HandlerWrapper.java:130)
	at org.mortbay.jetty.Server.doStart(Server.java:224)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:676)
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:208)
	at org.apache.hadoop.mapreduce.v2.app.client.MRClientService.start(MRClientService.java:151)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.start(MRAppMaster.java:1040)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1307)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1478)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1303)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1259)
{noformat}

This happens because as part of the MR app master start the jetty classes are loaded normally through the app classloader, but WebAppContext tries to load the specific Configuration class via the thread context classloader (which had been set to the user job classloader)."
MAPREDUCE-5749,TestRMContainerAllocator#testReportedAppProgress Failed,"When execute ""mvn test -Dtest=TestRMContainerAllocator#testReportedAppProgress"", It failed with message:
{code}
Caused by: java.io.FileNotFoundException: File /home/yuling.sh/hadoop-common/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator/appattempt_1392009213299_0001_000001/.staging/job_1392009213299_0001/job.xml does not exist
{code}
But in fact, the job.xml exits:
{code}
-rw-rw-r-- 1 yuling.sh yuling.sh 65791  2月 10 13:13 /home/yuling.sh/hadoop-common/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/target/org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator/yuling.sh/.staging/job_1392009213299_0001/job.xml
{code}
See the following code:
{code}
public Job submit(Configuration conf, boolean mapSpeculative,
      boolean reduceSpeculative) throws Exception {
    String user = conf.get(MRJobConfig.USER_NAME, UserGroupInformation
        .getCurrentUser().getShortUserName());
    conf.set(MRJobConfig.USER_NAME, user);
    conf.set(MRJobConfig.MR_AM_STAGING_DIR, testAbsPath.toString());
    conf.setBoolean(MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, true);
    // TODO: fix the bug where the speculator gets events with
    // not-fully-constructed objects. For now, disable speculative exec
    conf.setBoolean(MRJobConfig.MAP_SPECULATIVE, mapSpeculative);
    conf.setBoolean(MRJobConfig.REDUCE_SPECULATIVE, reduceSpeculative);

    init(conf);
    start();
    DefaultMetricsSystem.shutdown();
    Job job = getContext().getAllJobs().values().iterator().next();
    if (assignedQueue != null) {
      job.setQueueName(assignedQueue);
    }

    // Write job.xml
    String jobFile = MRApps.getJobFile(conf, user,
        TypeConverter.fromYarn(job.getID()));
    LOG.info(""Writing job conf to "" + jobFile);
    new File(jobFile).getParentFile().mkdirs();
    conf.writeXml(new FileOutputStream(jobFile));

    return job;
  }
{code}
At first, user is ""yuling.sh"",  but the UGI is setted to attemptId at ""start();"", after that, job.xml write to yuling.sh/.staging/job_1392009213299_0001/job.xml. But when the job is running, MRAppMaster can't find the job.xml at appattempt_1392009213299_0001_000001/.staging/job_1392009213299_0001."
MAPREDUCE-5748,Potential null pointer dereference in ShuffleHandler#Shuffle#messageReceived(),"Starting around line 510:
{code}
      ChannelFuture lastMap = null;
      for (String mapId : mapIds) {
...
      }
      lastMap.addListener(metrics);
      lastMap.addListener(ChannelFutureListener.CLOSE);
{code}
If mapIds is empty, lastMap would remain null, leading to NPE in addListener() call."
MAPREDUCE-5746,Job diagnostics can implicate wrong task for a failed job,"We've seen a number of cases where the history server is showing the wrong task as the reason a job failed.  For example, ""Task task_1383802699973_515536_m_027135 failed 1 times"" when some other task had failed 4 times and was the real reason the job failed."
MAPREDUCE-5745,"thread may hang forever, even after it receives all the expected data","Please discard this JIRA issue (I should open it under a different project). Tried to cancel this issue, but could not find a way to do so. Sorry about this. "
MAPREDUCE-5744,Job hangs because RMContainerAllocator$AssignedRequests.preemptReduce() violates the comparator contract,"We ran into a situation where tasks are not getting assigned because RMContainerAllocator$AssignedRequests.preemptReduce() fails repeatedly with the following exception:

{code}
2014-02-06 16:43:45,183 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.
java.lang.IllegalArgumentException: Comparison method violates its general contract!
     at java.util.TimSort.mergeLo(TimSort.java:747)
     at java.util.TimSort.mergeAt(TimSort.java:483)
     at java.util.TimSort.mergeCollapse(TimSort.java:408)
     at java.util.TimSort.sort(TimSort.java:214)
     at java.util.TimSort.sort(TimSort.java:173)
     at java.util.Arrays.sort(Arrays.java:659)
     at java.util.Collections.sort(Collections.java:217)
     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$AssignedRequests.preemptReduce(RMContainerAllocator.java:1106)
     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.preemptReducesIfNeeded(RMContainerAllocator.java:416)
     at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:230)
     at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:252)
     at java.lang.Thread.run(Thread.java:744)
{code}

It is because the comparator that's defined in this method does not abide by the contract, specifically if p == 0.

Comparator.compare(): http://docs.oracle.com/javase/7/docs/api/java/util/Comparator.html#compare(T, T)"
MAPREDUCE-5743,TestRMContainerAllocator is failing,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1666/console :
{code}
Tests run: 14, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 63.12 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator
testCompletedTasksRecalculateSchedule(org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator)  Time elapsed: 2.083 sec  <<< ERROR!
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:50)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:277)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.register(RMCommunicator.java:154)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$MyContainerAllocator.register(TestRMContainerAllocator.java:1476)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStart(RMCommunicator.java:112)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStart(RMContainerAllocator.java:219)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$MyContainerAllocator.<init>(TestRMContainerAllocator.java:1444)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$RecalculateContainerAllocator.<init>(TestRMContainerAllocator.java:1629)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testCompletedTasksRecalculateSchedule(TestRMContainerAllocator.java:1665)
{code}
In above case getMasterContainer() returned null.

AbstractYarnScheduler#getTransferredContainers() should check such condition."
MAPREDUCE-5742,pipes.Application should use SecureRandom for security purposes,"org.apache.hadoop.mapred.pipes.Application calls its private method getSecurityChallenge(), which uses java.util.Random. It should use java.security.SecureRandom."
MAPREDUCE-5739,DirectoryCollection#createNonExistentDirs() may use an invalid iterator,"Here is related code:
{code}
    for (final String dir : localDirs) {
      try {
        createDir(localFs, new Path(dir), perm);
      } catch (IOException e) {
        LOG.warn(""Unable to create directory "" + dir + "" error "" +
            e.getMessage() + "", removing from the list of valid directories."");
        localDirs.remove(dir);
{code}
Call to localDirs.remove() modifies Iterable ""localDirs"" which invalidates the iterator."
MAPREDUCE-5732,Report proper queue when job has been automatically placed,"Some schedulers, such as the Fair Scheduler, provide the ability to automatically place an application into a queue based on attributes such as the user and group of the submitter.  In these cases, the JobHistoryServer and AM web UI report the requested queue, not the queue that the app is actually running in."
MAPREDUCE-5731,testMiniMRChildtask fails on branch-2,"{noformat}
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.FileNotFoundException: File file:/tmp/hadoop-yarn/staging/history/done_intermediate does not exist
	at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getFullJob(CachedHistoryStorage.java:147)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistory.getJob(JobHistory.java:217)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler$1.run(HistoryClientService.java:203)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler$1.run(HistoryClientService.java:199)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1562)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.verifyAndGetJob(HistoryClientService.java:199)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.getJobReport(HistoryClientService.java:231)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getJobReport(MRClientProtocolPBServiceImpl.java:122)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:275)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1958)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1562)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1956)
Caused by: java.io.FileNotFoundException: File file:/tmp/hadoop-yarn/staging/history/done_intermediate does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:353)
	at org.apache.hadoop.fs.DelegateToFileSystem.listStatus(DelegateToFileSystem.java:149)
	at org.apache.hadoop.fs.ChecksumFs.listStatus(ChecksumFs.java:512)
	at org.apache.hadoop.fs.AbstractFileSystem$1.<init>(AbstractFileSystem.java:857)
	at org.apache.hadoop.fs.AbstractFileSystem.listStatusIterator(AbstractFileSystem.java:855)
	at org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1392)
	at org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1387)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.listStatus(FileContext.java:1387)
	at org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.listFilteredStatus(JobHistoryUtils.java:438)
	at org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.localGlobber(JobHistoryUtils.java:385)
	at org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.localGlobber(JobHistoryUtils.java:377)
	at org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils.localGlobber(JobHistoryUtils.java:372)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(HistoryFileManager.java:779)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.getFileInfo(HistoryFileManager.java:931)
	at org.apache.hadoop.mapreduce.v2.hs.CachedHistoryStorage.getFullJob(CachedHistoryStorage.java:132)
{noformat}"
MAPREDUCE-5730,AM log is truncated,The ApplicationMaster log is being truncated with only the log messages up until around the point where the job is being setup are present.
MAPREDUCE-5729,mapred job -list throws NPE,"mapred job -list throws the following NPE:
{noformat}
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.TypeConverter.fromYarn(TypeConverter.java:445)
	at org.apache.hadoop.mapreduce.TypeConverter.fromYarnApps(TypeConverter.java:460)
	at org.apache.hadoop.mapred.ResourceMgrDelegate.getAllJobs(ResourceMgrDelegate.java:125)
	at org.apache.hadoop.mapred.YARNRunner.getAllJobs(YARNRunner.java:164)

{noformat}"
MAPREDUCE-5727,History server web page can filter without showing filter keyword,"I loaded up a job conf page on the history server and used one of the search boxes to narrow the results.  I then navigated to other pages (e.g.: map tasks, logs, etc.) then navigated back to the job conf page using the job configuration link on the left side of the page.  When I arrived it promptly showed me just a few conf entries (the ones I had searched for earlier) but my search term was missing.  At first glance it looked like those were the only entries in the entire job conf, which can be very confusing.  Somehow the search term is being remembered but not replotted when the configuration page is revisited."
MAPREDUCE-5726,TestRMContainerAllocator#testCompletedTasksRecalculateSchedule fails,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1670/console :
{code}
org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator
testCompletedTasksRecalculateSchedule(org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator)  Time elapsed: 2.08 sec  <<< ERROR!
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.getTransferredContainers(AbstractYarnScheduler.java:50)
	at org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService.registerApplicationMaster(ApplicationMasterService.java:277)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.register(RMCommunicator.java:154)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$MyContainerAllocator.register(TestRMContainerAllocator.java:1476)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStart(RMCommunicator.java:112)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStart(RMContainerAllocator.java:219)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$MyContainerAllocator.<init>(TestRMContainerAllocator.java:1444)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$RecalculateContainerAllocator.<init>(TestRMContainerAllocator.java:1629)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testCompletedTasksRecalculateSchedule(TestRMContainerAllocator.java:1665)
{code}"
MAPREDUCE-5725,TestNetworkedJob relies on the Capacity Scheduler,We should either make this explicit or make it scheduler-agnostic.
MAPREDUCE-5724,JobHistoryServer does not start if HDFS is not running,"Starting JHS without HDFS running fails with the following error:

{code}
STARTUP_MSG:   build = git://git.apache.org/hadoop-common.git -r ad74e8850b99e03b0b6435b04f5b3e9995bc3956; compiled by 'tucu' on 2014-01-14T22:40Z
STARTUP_MSG:   java = 1.7.0_45
************************************************************/
2014-01-14 16:47:40,264 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: registered UNIX signal handlers for [TERM, HUP, INT]
2014-01-14 16:47:40,883 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-01-14 16:47:41,101 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: JobHistory Init
2014-01-14 16:47:41,710 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:505)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistory.serviceInit(JobHistory.java:94)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:143)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.launchJobHistoryServer(JobHistoryServer.java:207)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:217)
Caused by: java.net.ConnectException: Call From dontknow.local/172.20.10.4 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.Client.call(Client.java:1359)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:185)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:671)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1722)
	at org.apache.hadoop.fs.Hdfs.getFileStatus(Hdfs.java:124)
	at org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1106)
	at org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1102)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.getFileStatus(FileContext.java:1102)
	at org.apache.hadoop.fs.FileContext$Util.exists(FileContext.java:1514)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.mkdir(HistoryFileManager.java:561)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:502)
	... 8 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:601)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:696)
	at org.apache.hadoop.ipc.Client$Connection.access$2700(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1458)
	at org.apache.hadoop.ipc.Client.call(Client.java:1377)
	... 28 more
2014-01-14 16:47:41,713 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.JobHistory failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:505)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistory.serviceInit(JobHistory.java:94)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:108)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:143)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.launchJobHistoryServer(JobHistoryServer.java:207)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:217)
Caused by: java.net.ConnectException: Call From dontknow.local/172.20.10.4 to localhost:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1410)
	at org.apache.hadoop.ipc.Client.call(Client.java:1359)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:185)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:101)
	at com.sun.proxy.$Proxy9.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:671)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1722)
	at org.apache.hadoop.fs.Hdfs.getFileStatus(Hdfs.java:124)
	at org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1106)
	at org.apache.hadoop.fs.FileContext$14.next(FileContext.java:1102)
	at org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90)
	at org.apache.hadoop.fs.FileContext.getFileStatus(FileContext.java:1102)
	at org.apache.hadoop.fs.FileContext$Util.exists(FileContext.java:1514)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.mkdir(HistoryFileManager.java:561)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.serviceInit(HistoryFileManager.java:502)
	... 8 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:735)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:601)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:696)
	at org.apache.hadoop.ipc.Client$Connection.access$2700(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1458)
	at org.apache.hadoop.ipc.Client.call(Client.java:1377)
	... 28 more
2014-01-14 16:47:41,714 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistory: Stopping JobHistory
2014-01-14 16:47:41,714 INFO org.apache.hadoop.service.AbstractService: Service org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Error creating done directory: [hdfs://localhost:8020/tmp/hadoop-yarn/staging/history/done]
{code}
"
MAPREDUCE-5723,MR AM container log can be truncated or empty,"It occurs when the property ""mapreduce.task.userlog.limit.kb"" is set non-zero in mapped-site.xml.
AM container syslog remains empty if any exception occurs. 

Bug details:
In MRAppMaster.java, the following code snippets show the bug.

{code}
    } catch (Throwable t) {
       LOG.fatal(""Error starting MRAppMaster"", t);
      System.exit(1);
    }finally {
       LogManager.shutdown();
    }
{code}
In the catch block, we are exiting the JVM. So finally block (therefore LogManager.shutdown()) is never executed.

Possible fix: 
Make sure LogManager.shutdown() is executed in all cases.
 "
MAPREDUCE-5722,"client-app module failing to compile, missing jersey dependency","This seems a fallout of YARN-888, oddly enough it did not happen while doing a full build with the patch before committing."
MAPREDUCE-5721,RM occur exception while unregistering,"when i run WORDCOUNT EXAMPLES,it occur.
[hadoop@namenode0 ~]$ hadoop jar hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount /wordcount-input /wordcount-output
14/01/10 14:42:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
14/01/10 14:43:01 INFO client.RMProxy: Connecting to ResourceManager at namenode0/192.168.0.133:8032
14/01/10 14:43:03 INFO input.FileInputFormat: Total input paths to process : 2
14/01/10 14:43:03 INFO mapreduce.JobSubmitter: number of splits:2
14/01/10 14:43:03 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
14/01/10 14:43:03 INFO Configuration.deprecation: mapreduce.combine.class is deprecated. Instead, use mapreduce.job.combine.class
14/01/10 14:43:03 INFO Configuration.deprecation: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
14/01/10 14:43:03 INFO Configuration.deprecation: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
14/01/10 14:43:03 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
14/01/10 14:43:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1389336130986_0001
14/01/10 14:43:05 INFO impl.YarnClientImpl: Submitted application application_1389336130986_0001 to ResourceManager at namenode0/192.168.0.133:8032
14/01/10 14:43:05 INFO mapreduce.Job: The url to track the job: http://namenode0:8088/proxy/application_1389336130986_0001/
14/01/10 14:43:05 INFO mapreduce.Job: Running job: job_1389336130986_0001
14/01/10 14:43:16 INFO mapreduce.Job: Job job_1389336130986_0001 running in uber mode : false
14/01/10 14:43:16 INFO mapreduce.Job:  map 0% reduce 0%
14/01/10 14:44:20 INFO mapreduce.Job:  map 50% reduce 0%
14/01/10 14:44:34 INFO mapreduce.Job:  map 100% reduce 0%
14/01/10 14:44:51 INFO mapreduce.Job:  map 100% reduce 100%
14/01/10 14:44:58 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:44:59 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:45:00 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:45:01 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:45:02 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:45:03 INFO ipc.Client: Retrying connect to server: datanode0.hadoop/192.168.0.134:43052. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1 SECONDS)
14/01/10 14:45:17 INFO mapreduce.Job:  map 0% reduce 0%
14/01/10 14:45:17 INFO mapreduce.Job: Job job_1389336130986_0001 failed with state FAILED due to: Application application_1389336130986_0001 failed 2 times due to AM Container for appattempt_1389336130986_0001_000002 exited with  exitCode: 1 due to: Exception from container-launch: 
org.apache.hadoop.util.Shell$ExitCodeException: 
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
        at org.apache.hadoop.util.Shell.run(Shell.java:380)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:590)
        at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:139)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:909)
        at java.lang.Thread.run(Thread.java:662)


.Failing this attempt.. Failing the application.
14/01/10 14:45:17 INFO mapreduce.Job: Counters: 0
[hadoop@namenode0 ~]$ 

LOGS
Hadoop:
2014-01-10 16:21:45,987 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /mr-history/tmp/hadoop/job_1389341658181_0001.summary_tmp to /mr-history/tmp/hadoop/job_1389341658181_0001.summary because destination exists
2014-01-10 16:21:45,988 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 192.168.0.135:50010 is added to blk_1073742140_1320 size 76810
2014-01-10 16:21:46,000 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp to /mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml because destination exists
2014-01-10 16:21:46,005 WARN org.apache.hadoop.hdfs.StateChange: DIR* FSDirectory.unprotectedRenameTo: failed to rename /mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp to /mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist because destination exists
2014-01-10 16:21:46,005 INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
2014-01-10 16:21:46,152 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742126_1306 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742127_1307 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742128_1308 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742129_1309 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742131_1311 192.168.0.134:50010 192.168.0.135:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742130_1310 192.168.0.134:50010 192.168.0.135:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742137_1317 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:46,153 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073742136_1316 192.168.0.135:50010 192.168.0.134:50010 
2014-01-10 16:21:48,901 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 192.168.0.134:50010 to delete [blk_1073742128_1308, blk_1073742129_1309, blk_1073742130_1310, blk_1073742131_1311, blk_1073742136_1316, blk_1073742137_1317, blk_1073742126_1306, blk_1073742127_1307]
2014-01-10 16:21:51,904 INFO org.apache.hadoop.hdfs.StateChange: BLOCK* InvalidateBlocks: ask 192.168.0.135:50010 to delete [blk_1073742128_1308, blk_1073742129_1309, blk_1073742130_1310, blk_1073742131_1311, blk_1073742136_1316, blk_1073742137_1317, blk_1073742126_1306, blk_1073742127_1307]

RM:
2014-01-10 16:21:47,006 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1389341658181_0001_000002 released container container_1389341658181_0001_02_000001 on node: host: datanode1.hadoop:56467 #containers=0 available=8192 used=0 with event: FINISHED
2014-01-10 16:21:47,006 INFO org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: Unregistering app attempt : appattempt_1389341658181_0001_000002
2014-01-10 16:21:47,006 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1389341658181_0001_000002 State change from RUNNING to FAILED
2014-01-10 16:21:47,007 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Application application_1389341658181_0001 failed 2 times due to AM Container for appattempt_1389341658181_0001_000002 exited with  exitCode: 1 due to: Exception from container-launch: 
org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:380)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:590)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:139)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:909)
	at java.lang.Thread.run(Thread.java:662)


.Failing this attempt.. Failing the application.
2014-01-10 16:21:47,010 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1389341658181_0001 State change from RUNNING to FAILED
2014-01-10 16:21:47,012 INFO org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStore: Removing info for app: application_1389341658181_0001
2014-01-10 16:21:47,016 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=hadoop	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1389341658181_0001 failed 2 times due to AM Container for appattempt_1389341658181_0001_000002 exited with  exitCode: 1 due to: Exception from container-launch: 
org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:380)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:590)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:139)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:909)
	at java.lang.Thread.run(Thread.java:662)


.Failing this attempt.. Failing the application.	APPID=application_1389341658181_0001
2014-01-10 16:21:47,019 INFO org.apache.hadoop.yarn.server.resourcemanager.RMAppManager$ApplicationSummary: appId=application_1389341658181_0001,name=word count,user=hadoop,queue=default,state=FAILED,trackingUrl=namenode0:8088/cluster/app/application_1389341658181_0001,appMasterHost=,startTime=1389341979049,finishTime=1389342107008,finalStatus=FAILED
2014-01-10 16:21:47,021 INFO org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher: Cleaning master appattempt_1389341658181_0001_000002
2014-01-10 16:21:47,012 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1389341658181_0001_000002 is done. finalState=FAILED
2014-01-10 16:21:47,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo: Application application_1389341658181_0001 requests cleared
2014-01-10 16:21:47,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Application removed - appId: application_1389341658181_0001 user: hadoop queue: default #user-pending-applications: 0 #user-active-applications: 0 #queue-pending-applications: 0 #queue-active-applications: 0
2014-01-10 16:21:47,022 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue: Application removed - appId: application_1389341658181_0001 user: hadoop leaf-queue of parent: root #applications: 0

datanode0-syslog:
2014-01-10 16:21:09,369 INFO [Socket Reader #1 for port 39047] SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for job_1389341658181_0001 (auth:SIMPLE)
2014-01-10 16:21:09,405 INFO [IPC Server handler 11 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : jvm_1389341658181_0001_r_000004 asked for a task
2014-01-10 16:21:09,405 INFO [IPC Server handler 11 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID: jvm_1389341658181_0001_r_000004 given task: attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:10,012 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Received completed container container_1389341658181_0001_01_000002
2014-01-10 16:21:10,012 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:2 CompletedReds:0 ContAlloc:3 ContRel:0 HostLocal:2 RackLocal:0
2014-01-10 16:21:10,012 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1389341658181_0001_m_000000_0: Container killed by the ApplicationMaster.
Container killed on request. Exit code is 143

2014-01-10 16:21:10,578 INFO [IPC Server handler 12 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from attempt_1389341658181_0001_r_000000_0. startIndex 0 maxEvents 10000
2014-01-10 16:21:11,593 INFO [IPC Server handler 13 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from attempt_1389341658181_0001_r_000000_0. startIndex 2 maxEvents 10000
2014-01-10 16:21:12,003 INFO [IPC Server handler 14 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,003 INFO [IPC Server handler 14 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1389341658181_0001_r_000000_0 is : 0.0
2014-01-10 16:21:12,077 INFO [IPC Server handler 15 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,077 INFO [IPC Server handler 15 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1389341658181_0001_r_000000_0 is : 0.0
2014-01-10 16:21:12,698 INFO [IPC Server handler 16 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit-pending state update from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,699 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1389341658181_0001_r_000000_0 TaskAttempt Transitioned from RUNNING to COMMIT_PENDING
2014-01-10 16:21:12,700 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: attempt_1389341658181_0001_r_000000_0 given a go for committing the task output.
2014-01-10 16:21:12,702 INFO [IPC Server handler 16 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Commit go/no-go request from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,703 INFO [IPC Server handler 16 on 39047] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Result of canCommit for attempt_1389341658181_0001_r_000000_0:true
2014-01-10 16:21:12,776 INFO [IPC Server handler 18 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,777 INFO [IPC Server handler 18 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1389341658181_0001_r_000000_0 is : 1.0
2014-01-10 16:21:12,779 INFO [IPC Server handler 18 on 39047] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,780 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1389341658181_0001_r_000000_0 TaskAttempt Transitioned from COMMIT_PENDING to SUCCESS_CONTAINER_CLEANUP
2014-01-10 16:21:12,785 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for container container_1389341658181_0001_01_000004 taskAttempt attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,785 INFO [ContainerLauncher #5] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1389341658181_0001_r_000000_0 TaskAttempt Transitioned from SUCCESS_CONTAINER_CLEANUP to SUCCEEDED
2014-01-10 16:21:12,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1389341658181_0001_r_000000_0
2014-01-10 16:21:12,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1389341658181_0001_r_000000 Task Transitioned from RUNNING to SUCCEEDED
2014-01-10 16:21:12,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Num completed Tasks: 3
2014-01-10 16:21:12,867 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1389341658181_0001Job Transitioned from RUNNING to COMMITTING
2014-01-10 16:21:12,870 INFO [CommitterEvent Processor #1] org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: JOB_COMMIT
2014-01-10 16:21:12,974 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2014-01-10 16:21:12,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1389341658181_0001Job Transitioned from COMMITTING to SUCCEEDED
2014-01-10 16:21:12,978 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
2014-01-10 16:21:12,978 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2014-01-10 16:21:12,979 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: true
2014-01-10 16:21:12,979 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2014-01-10 16:21:12,979 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2014-01-10 16:21:12,979 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
2014-01-10 16:21:12,983 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 1
2014-01-10 16:21:13,021 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:2 CompletedReds:1 ContAlloc:3 ContRel:0 HostLocal:2 RackLocal:0
2014-01-10 16:21:13,094 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_1.jhist to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp
2014-01-10 16:21:13,140 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp
2014-01-10 16:21:13,143 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_1_conf.xml to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp
2014-01-10 16:21:13,210 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp
2014-01-10 16:21:13,214 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001.summary_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001.summary
2014-01-10 16:21:13,215 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml
2014-01-10 16:21:13,216 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist
2014-01-10 16:21:13,219 INFO [Thread-69] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2014-01-10 16:21:13,226 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to 
2014-01-10 16:21:13,229 ERROR [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering 
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithoutScheme(MRWebAppUtil.java:133)
	at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(MRWebAppUtil.java:148)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.doUnregistration(RMCommunicator.java:207)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister(RMCommunicator.java:177)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStop(RMCommunicator.java:250)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStop(RMContainerAllocator.java:255)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStop(MRAppMaster.java:817)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:159)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:132)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.shutDownJob(MRAppMaster.java:548)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler$1.run(MRAppMaster.java:599)
2014-01-10 16:21:13,234 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:2 CompletedReds:1 ContAlloc:3 ContRel:0 HostLocal:2 RackLocal:0
2014-01-10 16:21:13,234 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Skipping cleaning up the staging dir. assuming AM will be retried.
2014-01-10 16:21:13,235 INFO [Thread-69] org.apache.hadoop.ipc.Server: Stopping server on 39047
2014-01-10 16:21:13,241 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2014-01-10 16:21:13,242 INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
2014-01-10 16:21:13,243 INFO [IPC Server listener on 39047] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 39047
2014-01-10 16:21:18,243 INFO [Thread-69] org.apache.hadoop.ipc.Server: Stopping server on 41351
2014-01-10 16:21:18,272 INFO [Thread-69] org.mortbay.log: Stopped SelectChannelConnector@0.0.0.0:0
2014-01-10 16:21:18,274 INFO [IPC Server listener on 41351] org.apache.hadoop.ipc.Server: Stopping IPC Server listener on 41351
2014-01-10 16:21:18,275 INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: Stopping IPC Server Responder
2014-01-10 16:21:18,378 INFO [Thread-69] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Exiting MR AppMaster..GoodBye!
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster received a signal. Signaling RMCommunicator and JobHistoryEventHandler.
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that iSignalled is: true
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: false
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: false
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: false
2014-01-10 16:21:18,390 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is false


datanode1-syslog：
014-01-10 16:21:39,815 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Will not try to recover. recoveryEnabled: true recoverySupportedByCommitter: false numReduceTasks: 1 shuffleKeyValidForRecovery: true ApplicationAttemptID: 2
2014-01-10 16:21:39,871 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Previous history file is at hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_1.jhist
2014-01-10 16:21:41,503 INFO [Main Thread] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class org.apache.hadoop.mapreduce.v2.app.job.event.JobFinishEvent$Type for class org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler
2014-01-10 16:21:41,752 INFO [Main Thread] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2014-01-10 16:21:42,641 INFO [Main Thread] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-01-10 16:21:42,641 INFO [Main Thread] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: MRAppMaster metrics system started
2014-01-10 16:21:42,777 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
2014-01-10 16:21:42,777 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: maxTaskFailuresPerNode is 3
2014-01-10 16:21:42,777 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: blacklistDisablePercent is 33
2014-01-10 16:21:42,896 INFO [Main Thread] org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at namenode0/192.168.0.133:8030
2014-01-10 16:21:43,123 INFO [Main Thread] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: 8192
2014-01-10 16:21:43,183 INFO [Main Thread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryCopyService: History file is at hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_1.jhist
2014-01-10 16:21:43,413 ERROR [Main Thread] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:hadoop (auth:SIMPLE) cause:java.io.IOException: Was asked to shut down.
2014-01-10 16:21:43,414 FATAL [Main Thread] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
java.io.IOException: Was asked to shut down.
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1447)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1452)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1374)
2014-01-10 16:21:43,454 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster received a signal. Signaling RMCommunicator and JobHistoryEventHandler.
2014-01-10 16:21:43,455 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that iSignalled is: true
2014-01-10 16:21:43,456 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify RMCommunicator isAMLastRetry: true
2014-01-10 16:21:43,457 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: RMCommunicator notified that shouldUnregistered is: true
2014-01-10 16:21:43,457 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify JHEH isAMLastRetry: true
2014-01-10 16:21:43,457 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: JobHistoryEventHandler notified that forceJobCompletion is true
2014-01-10 16:21:43,470 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 17
2014-01-10 16:21:43,543 INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: job_1389341658181_0001, File: hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_2.jhist
2014-01-10 16:21:43,657 INFO [eventHandlingThread] org.apache.hadoop.conf.Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
2014-01-10 16:21:44,698 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event AM_STARTED
2014-01-10 16:21:44,700 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event JOB_SUBMITTED
2014-01-10 16:21:44,705 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event JOB_INITED
2014-01-10 16:21:44,707 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event JOB_INFO_CHANGED
2014-01-10 16:21:44,708 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_STARTED
2014-01-10 16:21:44,708 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_STARTED
2014-01-10 16:21:44,708 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_STARTED
2014-01-10 16:21:44,708 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event MAP_ATTEMPT_STARTED
2014-01-10 16:21:44,710 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event MAP_ATTEMPT_STARTED
2014-01-10 16:21:44,710 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event MAP_ATTEMPT_FINISHED
2014-01-10 16:21:44,763 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_FINISHED
2014-01-10 16:21:44,767 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event REDUCE_ATTEMPT_STARTED
2014-01-10 16:21:44,767 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event MAP_ATTEMPT_FINISHED
2014-01-10 16:21:44,769 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_FINISHED
2014-01-10 16:21:44,771 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event REDUCE_ATTEMPT_FINISHED
2014-01-10 16:21:44,775 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event TASK_FINISHED
2014-01-10 16:21:44,777 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event JOB_FINISHED
2014-01-10 16:21:44,886 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_2.jhist to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp
2014-01-10 16:21:45,005 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp
2014-01-10 16:21:45,008 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://namenode0:9000/tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001/job_1389341658181_0001_2_conf.xml to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp
2014-01-10 16:21:45,079 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp
2014-01-10 16:21:45,103 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001.summary_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001.summary
2014-01-10 16:21:45,108 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001_conf.xml
2014-01-10 16:21:45,110 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist_tmp to hdfs://namenode0:9000/mr-history/tmp/hadoop/job_1389341658181_0001-1389341978991-hadoop-word+count-1389342072969-2-1-SUCCEEDED-default.jhist
2014-01-10 16:21:45,110 INFO [Thread-1] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2014-01-10 16:21:45,122 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to We crashed after successfully committing. Recovering.

2014-01-10 16:21:45,198 ERROR [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering 
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithoutScheme(MRWebAppUtil.java:133)
	at org.apache.hadoop.mapreduce.v2.util.MRWebAppUtil.getApplicationWebURLOnJHSWithScheme(MRWebAppUtil.java:148)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.doUnregistration(RMCommunicator.java:207)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.unregister(RMCommunicator.java:177)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStop(RMCommunicator.java:250)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStop(RMContainerAllocator.java:255)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStop(MRAppMaster.java:817)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:159)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:132)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1399)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2014-01-10 16:21:45,199 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:0 ContRel:0 HostLocal:0 RackLocal:0
2014-01-10 16:21:45,203 INFO [Thread-1] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://namenode0:9000 /tmp/hadoop-yarn/staging/hadoop/.staging/job_1389341658181_0001






"
MAPREDUCE-5720,RM occur exception while unregistering,
MAPREDUCE-5717,Task pings are interpreted as task progress,
MAPREDUCE-5716,yarn framework occurs Shell$ExitCodeException,"I use hadoop2.2.0 to run map-reduce task,at first I set the  property ""mapreduce.framework.name"" with ""local"" in mapred-site.xml,everything goes fine ,and there is no exception,but when I run the mapreduce task on server cluster,setting the ""mapreduce.framework.name"" property value with ""yarn"",it shows exception belows:

    2014-01-10 14:51:03,131 INFO ContainersLauncher #0 org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer: [/home/hadoop/hadoop-2.2.0/bin/container-executor, hadoop, 1, application_1389336249740_0001, container_1389336249740_000
_01_000013, /new/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1389336249740_0001/container_1389336249740_0001_01_000013, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/application_1389336249740_0001/container_1389336249740_0001_01_00001
/launch_container.sh, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/application_1389336249740_0001/container_1389336249740_0001_01_000013/container_1389336249740_0001_01_000013.tokens, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/container_1389336249740_0001
01_000013.pid, /new/hadoop/data/tmp/nm-local-dir, /home/hadoop/hadoop-2.2.0/logs/userlogs, cgroups=none]
2014-01-10 14:51:03,134 INFO ContainersLauncher #2 org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer: [/home/hadoop/hadoop-2.2.0/bin/container-executor, hadoop, 1, application_1389336249740_0001, container_1389336249740_000
_01_000014, /new/hadoop/data/tmp/nm-local-dir/usercache/hadoop/appcache/application_1389336249740_0001/container_1389336249740_0001_01_000014, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/application_1389336249740_0001/container_1389336249740_0001_01_00001
/launch_container.sh, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/application_1389336249740_0001/container_1389336249740_0001_01_000014/container_1389336249740_0001_01_000014.tokens, /new/hadoop/data/tmp/nm-local-dir/nmPrivate/container_1389336249740_0001
01_000014.pid, /new/hadoop/data/tmp/nm-local-dir, /home/hadoop/hadoop-2.2.0/logs/userlogs, cgroups=none]
2014-01-10 14:51:03,142 INFO AsyncDispatcher event handler org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1389336249740_0001_01_000013 transitioned from LOCALIZED to RUNNING
2014-01-10 14:51:03,144 INFO AsyncDispatcher event handler org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Container container_1389336249740_0001_01_000014 transitioned from LOCALIZED to RUNNING
2014-01-10 14:51:03,144 WARN ContainersLauncher #4 org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exception from container-launch with container ID: container_1389336249740_0001_01_000016 and exit code: 127
org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:252)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:636)
2014-01-10 14:51:03,161 WARN ContainersLauncher #2 org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exit code from container container_1389336249740_0001_01_000014 is : 127

my mapred-site.xml content:
<configuration>
<property>
  <name>mapreduce.jobtracker.address</name>
  <value>local</value>
  <description>The host and port that the MapReduce job tracker runs
  at.  If ""local"", then jobs are run in-process as a single map
  and reduce task.
  </description>
</property>

<property>
  <name>mapreduce.jobtracker.http.address</name>
  <value>121server:50030</value>
  <description>
    The job tracker http server address and port the server will listen on.
    If the port is 0 then the server will start on a free port.
  </description>
</property>

<property>
  <name>mapreduce.job.maps</name>
  <value>40</value>
  <description>The default number of map tasks per job.
  Ignored when mapreduce.jobtracker.address is ""local"".  
  </description>
</property>
<property>
  <name>mapreduce.framework.name</name>
  <value>classic</value>
</property>
</configuration>

my yarn-site.xml content:

<configuration>
<!-- Site specific YARN configuration properties -->
 <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>152server:8990</value>
    <description>host is the hostname of the resource manager and 
    port is the port on which the NodeManagers contact the Resource Manager.
    </description>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>152server:8991</value>
    <description>host is the hostname of the resourcemanager and port is the port
    on which the Applications in the cluster talk to the Resource Manager.
    </description>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.class</name>    <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
    <description>In case you do not want to use the default scheduler</description>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>152server:8993</value>
    <description>the host is the hostname of the ResourceManager and the port is the port on
    which the clients can talk to the Resource Manager. </description>
  </property>
<property> 
<description>The address of the RM web application.</description> 
<name>yarn.resourcemanager.webapp.address</name> 
<value>152server:18088</value> 
</property> 
<property> 
<name>yarn.nodemanager.aux-services</name> 
<value>mapreduce_shuffle</value> 
</property>
<property>
 <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
 <value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
<property>
<name>yarn.nodemanager.resource.memory-mb</name>
<value>5120</value>
</property>
</configuration>

"
MAPREDUCE-5714,TestMRAppComponentDependencies causes surefire to exit without saying proper goodbye,"When running test TestMRAppComponentDependencies, surefire exits with the following message: 

Failed to execute goal org.apache.maven.plugins:maven-surefire-plugin:2.16:test (default-test) on project hadoop-mapreduce-client-app: ExecutionException; nested exception is java.util.concurrent.ExecutionException: java.lang.RuntimeException: The forked VM terminated without saying properly goodbye. VM crash or System.exit called ?

The following code is found in o.a.h.mapreduce.v2.app.MRAppMaster#shutDownJob, which the test case inherits. So, before the test testComponentStopOrder completes in TestMRAppComponentDependencies, shutDownJob finishes executing and exits the JVM, thus causing the error. Based on the comment, the System.exit(0) is there as a workaround for before HADOOP-7140. Since the patch for HADOOP-7140 is committed in branch-2, are we safe to remove the System.exit call now.

    //Bring the process down by force.
    //Not needed after HADOOP-7140
    LOG.info(""Exiting MR AppMaster..GoodBye!"");
    sysexit();



 "
MAPREDUCE-5713,InputFormat and JobConf JavaDoc Fixes,"https://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/mapred/InputFormat.html

Instead of ""record boundaries are to respected""
Should be ""record boundaries are to be respected""

https://hadoop.apache.org/docs/r1.2.1/api/org/apache/hadoop/mapred/JobConf.html

Instead of ""some parameters interact subtly rest of the framework""
Should be ""some parameters interact subtly with the rest of the framework"""
MAPREDUCE-5712,Backport Fair Scheduler pool placement by secondary group,YARN-1423 introduced a quue police that support selecting a queue if a secondary group was found in the defined queues. This functionality would be useful and minimally invasive in MR1 as well.
MAPREDUCE-5711,"When JobTracker writing JobHistory to HDFS, it may hung for long time due to DataNode error","When writing JobHistory to HDFS, it may takes very long time due to DataNode error, unfortunately, it also hold JobTracker lock, so it makes JobTracker hung for long time. It happens couple of times on our cluster."
MAPREDUCE-5710,Backport MAPREDUCE-1305 to branch-1,"File this bug for backporting MAPREDUCE-1305 to branch-1.
"
MAPREDUCE-5708,Duplicate String.format in YarnOutputFiles.getSpillFileForWrite,"The code responsible for formatting the spill file name (namely _getSpillFileForWrite_) unnecessarily calls _String.format_ twice. This does not only affect performance, but leads to the weird requirement that task attempt ids cannot contain _%_ characters (because these would be interpreted as format specifiers in the outside _String.format_ call).

I assume this was done by mistake, as it could only be useful if task attempt ids contained _%n_."
MAPREDUCE-5706,toBeDeleted parent directories aren't being cleaned up,"When security is enabled on 0.22, MRASyncDiskService doesn't always delete the parent directories under {{toBeDeleted}}.

MRAsyncDiskService goes through {{toBeDeleted}} and creates ""tasks"" to delete the directories under there using the LinuxTaskController. It chooses which user to run as by looking at who owns that directory.
For example:
{noformat}
ls -al /mapred/local/toBeDeleted/2013-07-05_05-37-49.052_0
total 12
drwxr-xr-x 3 mapred mapred 4096 Jul  5 05:37 .
drwxr-xr-x 5 mapred mapred 4096 Dec 19 10:15 ..
drwxr-s--- 4 test   mapred 4096 Jul  2 02:54 test
{noformat}

It would create a task to use ""test"" user to delete /mapred/local/toBeDeleted/2013-07-05_05-37-49.052_0/test (there could be more in there for other users). It then creates a task to use ""mapred"" user to delete /mapred/local/toBeDeleted/2013-07-05_05-37-49.052_0.

So, the problem is that we normally configure ""mapred"" to not be allowed by the LinuxTaskController in the /etc/hadoop/conf.cloudera.mapreduce1/taskcontroller.cfg.  The permissions on the toBeDeleted dir is drwxr-xr-x mapred:mapred, which means that only ""mapred"" can delete things in it (i.e. the timestamped dirs).  However, the MRAsyncDiskService is already running as the mapred user, so there's no reason to use the LinuxTaskController for impersonation anyway; we can directly do it from the Java code.

Another issue is that {{MRAsyncDiskService#deletePathsInSecureCluster}} expects an absolute file path (e.g. {{/mapred/local/toBeDeleted/2013-07-05_05-37-49.052_0}}, but {{MRAsyncDiskService#moveAndDeleteRelativePath}} passes in a relative path (e.g. {{toBeDeleted/2013-07-05_05-37-49.052_0}}).  

"
MAPREDUCE-5703,Job client gets failure though RM side job execution result is FINISHED and SUCCEEDED,"1) Run MR job 
2) After reduce completed and while JHS file writing, restart DN.

RM side job is shown as successful.
JHS doesnt have info about the job.
Job client gets NPE and exit code as 255.

java.io.IOException: org.apache.hadoop.ipc.RemoteException(java.lang.NullPointerException): java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$HSClientProtocolHandler.getTaskAttemptCompletionEvents(HistoryClientService.java:269)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBServiceImpl.java:173)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:283)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:929)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2080)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2076)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2074)

	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:330)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:382)
	at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:529)
	at org.apache.hadoop.mapreduce.Job$5.run(Job.java:668)
	at org.apache.hadoop.mapreduce.Job$5.run(Job.java:665)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1491)
	at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:665)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1349)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.monitorAndPrintJob(JobClient.java:407)
	at org.apache.hadoop.mapred.JobClient.monitorAndPrintJob(JobClient.java:855)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:835)"
MAPREDUCE-5702,TaskLogServlet#printTaskLog has spurious HTML closing tags,"TaskLogServlet#printTaskLog closes some HTML tags that it never opens. These should be removed. This isn't a problem while viewing in a browser, but can lead to issues while parsing it.

{code}
      if( !plainText ) {
        out.write(""</pre></td></tr></table><hr><br>\n"".getBytes()); // <--- here
      }
{code}"
MAPREDUCE-5699,Allow setting tags on MR jobs,"YARN-1399 / YARN-1461 add support for tagging YARN applications. MR should expose to users, so they can set tags on an MR job. "
MAPREDUCE-5698,Backport MAPREDUCE-1285 to branch-1,"I found that MAPREDUCE-1285 is not in branch-1. File this issue for backporting.
"
MAPREDUCE-5697,"My MapReduce program read .gz packets from HDFS, but if one of the packets is incorrect, the program will throw exception, then job will stop.",
MAPREDUCE-5694,MR AM container syslog is empty  ,"When the property ""mapreduce.task.userlog.limit.kb"" is set non-zero in mapped-site.xml, AM container syslog remains empty. Without the log, it is hard to identify the cause of any MR AM failure.
However, if ""mapreduce.task.userlog.limit.kb""  is not set (or defaulted to 0), syslog contents are correct.
  
Bug details:
For  non zero ""mapreduce.task.userlog.limit.kb"", the code caches the log contents into memory, waited to be written to file when close() method is called at the end(Ref: ContainerLogAppender.java). 
Explicit call of LogManager.shutdown() from the main() (REF:MRAppMaster.java), ultimately call the *Appender.close().

Root Cause: 
LogManager.shutdown() is not being called from MRAppMaster.java.
Similar steps were taken correctly in YarnChild.java.
  
 "
MAPREDUCE-5693,Restore MRv1 behavior for log flush,"to improve log consistency and completeness for diagnostics in the case of JVM crashes and SIGTERMing by NM this JIRA proposes to restore the MRv1 behavior of periodic log syncing (every 5s) and having log sync as part of a shutdown hook.
"
MAPREDUCE-5692,Add explicit diagnostics when a task attempt is killed due to speculative execution,We need to clearly indicate when a task attempt is killed because another task attempt succeeded first when speculative execution is enabled.
MAPREDUCE-5690,TestLocalMRNotification.testMR occasionally fails,"TestLocalMRNotificationis occasionally failing with the error:
{code}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapred.TestLocalMRNotification
-------------------------------------------------------------------------------
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 24.992 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestLocalMRNotification
testMR(org.apache.hadoop.mapred.TestLocalMRNotification)  Time elapsed: 24.881 sec  <<< ERROR!
java.io.IOException: Job cleanup didn't start in 20 seconds
        at org.apache.hadoop.mapred.UtilsForTests.runJobKill(UtilsForTests.java:685)
        at org.apache.hadoop.mapred.NotificationTestCase.testMR(NotificationTestCase.java:178)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at junit.framework.TestCase.runTest(TestCase.java:168)
        at junit.framework.TestCase.runBare(TestCase.java:134)
        at junit.framework.TestResult$1.protect(TestResult.java:110)
        at junit.framework.TestResult.runProtected(TestResult.java:128)
        at junit.framework.TestResult.run(TestResult.java:113)
        at junit.framework.TestCase.run(TestCase.java:124)
        at junit.framework.TestSuite.runTest(TestSuite.java:243)
        at junit.framework.TestSuite.run(TestSuite.java:238)
        at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:254)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:149)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
{code}"
MAPREDUCE-5689,MRAppMaster does not preempt reducers when scheduled maps cannot be fulfilled,"We saw corner case where Jobs running on cluster were hung. Scenario was something like this. Job was running within a pool which was running at its capacity. All available containers were occupied by reducers and last 2 mappers. There were few more reducers waiting to be scheduled in pipeline. 
At this point two mappers which were running failed and went back to scheduled state. two available containers were assigned to reducers, now whole pool was full of reducers waiting on two maps to be complete. 2 maps never got scheduled because pool was full.

Ideally reducer preemption should have kicked in to make room for Mappers from this code in RMContaienrAllocator
{code}
int completedMaps = getJob().getCompletedMaps();
    int completedTasks = completedMaps + getJob().getCompletedReduces();
    if (lastCompletedTasks != completedTasks) {
      lastCompletedTasks = completedTasks;
      recalculateReduceSchedule = true;
    }

    if (recalculateReduceSchedule) {
      preemptReducesIfNeeded();
{code}

But in this scenario lastCompletedTasks is always completedTasks because maps were never completed. This would cause job to hang forever. As workaround if we kill few reducers, mappers would get scheduled and caused job to complete.

"
MAPREDUCE-5688,TestStagingCleanup fails intermittently with JDK7,"Due to random ordering ordering in JDK7, the test TestStagingCleanup#testDeletionofStagingOnKillLastTry is failing

{noformat}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 4.231 sec <<< FAILURE!
test(org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup)  Time elapsed: 3882 sec  <<< ERROR!
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop(JobHistoryEventHandler.java:349)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.service.ServiceOperations.stop(ServiceOperations.java:52)
	at org.apache.hadoop.service.ServiceOperations.stopQuietly(ServiceOperations.java:80)
	at org.apache.hadoop.service.CompositeService.stop(CompositeService.java:159)
	at org.apache.hadoop.service.CompositeService.serviceStop(CompositeService.java:132)
	at org.apache.hadoop.service.AbstractService.stop(AbstractService.java:221)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1399)
	at org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.testDeletionofStagingOnKillLastTry(TestStagingCleanup.java:239)
	at org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.test(TestStagingCleanup.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:242)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:137)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}"
MAPREDUCE-5687,TestYARNRunner#testResourceMgrDelegate fails with NPE after YARN-1446,"On trunk, I got:
{code}
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.049 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestYARNRunner
testResourceMgrDelegate(org.apache.hadoop.mapred.TestYARNRunner)  Time elapsed: 0.782 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.killApplication(YarnClientImpl.java:201)
	at org.apache.hadoop.mapred.ResourceMgrDelegate.killApplication(ResourceMgrDelegate.java:284)
	at org.apache.hadoop.mapred.TestYARNRunner.testResourceMgrDelegate(TestYARNRunner.java:212)
{code}"
MAPREDUCE-5686,"Found Class org.apache.hadoop.mapreduce.TaskAttemptContext,but interface was excepted","hi,

Iam using the hadoop version 0.20. 

Please suggest to fix the bug.

Thanks in advance.

Ranjini"
MAPREDUCE-5685,getCacheFiles()  api doesn't work in WrappedReducer.java due to typo,"Typo in WrappedReducer.java which causes getCacheFiles() fucntions returns null

Java File: hadoop-common / hadoop-mapreduce-project / hadoop-mapreduce-client / hadoop-mapreduce-client-core / src / main / java / org / apache / hadoop / mapreduce / lib / reduce / WrappedReducer.java 

line 140:
Error code:
{code}
return reduceContext.getCacheArchives();
{code}
Should be:
{code}
return reduceContext.getCacheFiles();
{code}"
MAPREDUCE-5681,TestJHSSecurity fails on trunk,"{code}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapreduce.security.TestJHSSecurity
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.763 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.security.TestJHSSecurity
testDelegationToken(org.apache.hadoop.mapreduce.security.TestJHSSecurity)  Time elapsed: 1.56 sec  <<< ERROR!
java.lang.NullPointerException: null
	at java.util.Hashtable.get(Hashtable.java:334)
	at java.util.Properties.getProperty(Properties.java:932)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:874)
	at org.apache.hadoop.http.HttpServer.initSpnego(HttpServer.java:892)
	at org.apache.hadoop.http.HttpServer.access$100(HttpServer.java:101)
	at org.apache.hadoop.http.HttpServer$Builder.build(HttpServer.java:323)
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:232)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.initializeWebApp(HistoryClientService.java:149)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.serviceStart(HistoryClientService.java:118)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceStart(JobHistoryServer.java:175)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken(TestJHSSecurity.java:100)


Results :

Tests in error: 
  TestJHSSecurity.testDelegationToken:100 ? NullPointer

Tests run: 1, Failures: 0, Errors: 1, Skipped: 0
{code}

Did some preliminary investigation, in HistoryClientService:
{code}
        .withHttpSpnegoPrincipalKey(
            JHAdminConfig.MR_WEBAPP_SPNEGO_USER_NAME_KEY)
{code}
MR_WEBAPP_SPNEGO_USER_NAME_KEY seems not to be in the configuration."
MAPREDUCE-5679,TestJobHistoryParsing has race condition,"org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing can fail because of race condition.
{noformat}
testHistoryParsingWithParseErrors(org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing)  Time elapsed: 4.102 sec  <<< ERROR!
java.io.IOException: Unable to initialize History Viewer
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:520)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
        at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:137)
        at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:339)
        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:798)
        at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.<init>(JobHistoryParser.java:86)
        at org.apache.hadoop.mapreduce.jobhistory.HistoryViewer.<init>(HistoryViewer.java:85)
        at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(TestJobHistoryParsing.java:339)
        at org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.testHistoryParsingWithParseErrors(TestJobHistoryParsing.java:125)
{noformat}

In the checkHistoryParsing() function, after 
{code}
HistoryFileInfo fileInfo = jobHistory.getJobFileInfo(jobId);
{code}
a thread named MoveIntermediateToDone will be launched to move history file from done_intermediate to done directory.
If the history file is moved, 
{code}
      HistoryViewer viewer = new HistoryViewer(fc.makeQualified(
          fileInfo.getHistoryFile()).toString(), conf, true);
{code}
will throw IOException，because the history file is not found."
MAPREDUCE-5678,Move junit to test scope in more projects,"MAPREDUCE-5624 moved junit to test scope for most projects but missed a few pom.xml

This JIRA moves junit to test scope for the missed projects

Thanks to Jeff Bowles who made the discovery"
MAPREDUCE-5674,Missing start and finish time in mapred.JobStatus,"The JobStatus obtained from the JobClient or runningJob has no start or finish time for the job -- the start and finish time is always 0. This is a regression with respect to 1.0 mapreduce client and JobStatus API. This can also lead to regressions in downstream projects. For example, we discovered the problem in webhcat that the jobstatus for mapreduce job submmited to webhcat always reports start time as 0."
MAPREDUCE-5672,Provide optional RollingFileAppender for container log4j (syslog),"This JIRA is an alternative take on YARN-1130

We propose providing an option of using a RollingFileAppender(RFA)-based implementation of container log appender as means of log size control via mapreduce.task.userlog.limit.kb. 

The idea is to use mapreduce.task.userlog.limit.kb as maximumFileSize of RFA. In addition yarn.app.mapreduce.container.log.backups (task attempt containers) and yarn.app.mapreduce.am.log.backups (MR-AM) are passed as maxBackupIndex.

Both current ContainerLogAppender (CLA) and new ContainerRollingLogAppender (CRLA) co-exist. CLA is the default. CRLA is chosen when  mapreduce.task.userlog.limit.kb > 0 && *.backups > 0.

Pros: 
1) CRLA output is visible in UI right away. CLA output with mapreduce.task.userlog.limit.kb > 0 is not visible until the task attempt finishes that prevents timely diagnostics. 
2) Even with excessive logging and a large mapreduce.task.userlog.limit.kb, no space is taken from the JVM heap.
3) No UI impact, since YARN is already designed to deal with any log name beyond stderr/out, syslog, debug.out, profile.out

Cons:
1) if the logging is excessive there will be more local filesystem metadata I/O due to roll. That should be negligible in the grand scheme.

Furthermore, to improve log consistency and completeness in the case of JVM crashes and SIGTERMing by NM, we propose to restore the MRv1 behavior of periodic log syncing (every 5s) and having log sync as part of a shutdown hook.
 

"
MAPREDUCE-5671,NaN can be created by client and assign to Progress,"MapReduce should filter ""illegal"" progress values that do not fall into (0,1) interval when the progress value is given.

If it is Float.NaN, Float.NEGATIVE_INFINITY, or smaller than 0: set progress to be 0;
If its is Float.POSITIVE_INFINITY or larger than 1: set progress to be 1;
"
MAPREDUCE-5670,CombineFileRecordReader should report progress when moving to the next file,"If a combine split consists of many ""empty"" files (i.e.: no record found by the underlying record reader) then theoretically a task can timeout due to lack of reported progress."
MAPREDUCE-5668,"Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.JobContext, but interface was expected","hi
 pl help

i have wrote this code , at runtime i got this issue.
Exception in thread ""main"" java.lang.IncompatibleClassChangeError: Found class org.apache.hadoop.mapreduce.JobContext, but interface was expected
	at org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat.getSplits(CombineFileInputFormat.java:170)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:885)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:779)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:432)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:447)
	at MultiFileWordCount.run(MultiFileWordCount.java:395)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at MultiFileWordCount.main(MultiFileWordCount.java:401)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
hduser@localhost:~$ 


I have attached the code.

import java.io.DataInput;  

import java.io.DataOutput;  

import java.io.IOException;  

import java.util.StringTokenizer;  

import org.apache.hadoop.conf.Configured;  

import org.apache.hadoop.fs.FSDataInputStream;  

import org.apache.hadoop.fs.FileSystem;  

import org.apache.hadoop.fs.Path;  

import org.apache.hadoop.io.IntWritable;  

import org.apache.hadoop.io.Text;  

import org.apache.hadoop.io.WritableComparable;  

import org.apache.hadoop.mapreduce.InputSplit;  

import org.apache.hadoop.mapreduce.Job;  

import org.apache.hadoop.mapreduce.Mapper;  

import org.apache.hadoop.mapreduce.RecordReader;  

import org.apache.hadoop.mapreduce.TaskAttemptContext;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;  

import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  

import org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer;  

import org.apache.hadoop.util.LineReader;  

import org.apache.hadoop.util.Tool;  

import org.apache.hadoop.util.ToolRunner;  


 /**  

  * MultiFileWordCount is an example to demonstrate the usage of   

  * MultiFileInputFormat. This examples counts the occurrences of  

  * words in the text files under the given input directory.  

  */ 

public class MultiFileWordCount extends Configured implements Tool {  

   /**  

    * This record keeps <filename,offset> pairs.  

    */ 

public static class WordOffset implements WritableComparable {  

   private long offset;  

   private String fileName;  
  
   public void readFields(DataInput in) throws IOException {  

      this.offset = in.readLong();  

      this.fileName = Text.readString(in);  

     }  

     public void write(DataOutput out) throws IOException {  

       out.writeLong(offset);  

       Text.writeString(out, fileName);  

     }  

      public int compareTo(Object o) {  

       WordOffset that = (WordOffset)o;  

       int f = this.fileName.compareTo(that.fileName);  

       if(f == 0) {  

         return (int)Math.signum((double)(this.offset - that.offset));  

       }  

       return f;  

     }  

     @Override 

     public boolean equals(Object obj) {  

       if(obj instanceof WordOffset)  

       return this.compareTo(obj) == 0;  

       return false;  

     }  

     @Override 

     public int hashCode() {  

     assert false : ""hashCode not designed"";  

     return 42; //an arbitrary constant  

     }  

   }  

   /**  

    * To use {@link CombineFileInputFormat}, one should extend it, to return a   

    * (custom) {@link RecordReader}. CombineFileInputFormat uses   

    * {@link CombineFileSplit}s.   

    */ 

   public static class MyInputFormat   

     extends CombineFileInputFormat  {  

     public RecordReader createRecordReader(InputSplit split,  

      TaskAttemptContext context) throws IOException {  

       return new CombineFileRecordReader(  

         (CombineFileSplit)split, context, CombineFileLineRecordReader.class);  

     }  

   }  

  
   /**  

    * RecordReader is responsible from extracting records from a chunk  

    * of the CombineFileSplit.   

    */ 

   public static class CombineFileLineRecordReader   

     extends RecordReader {  

     private long startOffset; //offset of the chunk;  

     private long end; //end of the chunk;  

     private long pos; // current pos   

     private FileSystem fs;  

     private Path path;  

     private WordOffset key;  

     private Text value;  

     private FSDataInputStream fileIn;  

     private LineReader reader;  

     public CombineFileLineRecordReader(CombineFileSplit split,  

         TaskAttemptContext context, Integer index) throws IOException {  
      
       this.path = split.getPath(index);  

       fs = this.path.getFileSystem(context.getConfiguration());  

       this.startOffset = split.getOffset(index);  

       this.end = startOffset + split.getLength(index);  

       boolean skipFirstLine = false;  

       //open the file  

       fileIn = fs.open(path);  

       if (startOffset != 0) {  

       skipFirstLine = true;  

         --startOffset;  

         fileIn.seek(startOffset);  

       }  

       reader = new LineReader(fileIn);  

       if (skipFirstLine) {  // skip first line and re-establish ""startOffset"".  

        startOffset += reader.readLine(new Text(), 0,  

         (int)Math.min((long)Integer.MAX_VALUE, end - startOffset));  

       }  

       this.pos = startOffset;  

     }  

     public void initialize(InputSplit split, TaskAttemptContext context)  

        throws IOException, InterruptedException {  

     }
     public void close() throws IOException { }  

     public float getProgress() throws IOException {  

       if (startOffset == end) {  

        return 0.0f;  

       } else {  

       return Math.min(1.0f, (pos - startOffset) / (float)(end - startOffset));  

       }  

     }  

    public boolean nextKeyValue() throws IOException {  

       if (key == null) {  

         key = new WordOffset();  

         key.fileName = path.getName();  

       }  

       key.offset = pos;  

       if (value == null) {  

       value = new Text();  

       }  

       int newSize = 0;  

       if (pos < end) {  

        newSize = reader.readLine(value);  

        pos += newSize;  

       }  

       if (newSize == 0) {  

        key = null;  

        value = null;  

        return false;  

       } else {  

        return true;  

       }  

     }  

         public WordOffset getCurrentKey()   

         throws IOException, InterruptedException {  

          return key;  

     }  

         public Text getCurrentValue() throws IOException, InterruptedException {  

         return value;  

     }  

   }  

  
   /**  

    * This Mapper is similar to the one in {@link WordCount.MapClass}.  

    */ 

   public static class MapClass extends  

       Mapper {  

     private final static IntWritable one = new IntWritable(1);  

     private Text word = new Text();  

     public void map(WordOffset key, Text value, Context context)  

         throws IOException, InterruptedException {  

       String line = value.toString();  

       StringTokenizer itr = new StringTokenizer(line);  

       while (itr.hasMoreTokens()) {  

         word.set(itr.nextToken());  

         context.write(word, one);  

       }  

     }  

   }  

   private void printUsage() {  

     System.out.println(""Usage : multifilewc  "" );  

   }  
   public int run(String[] args) throws Exception {  

     if(args.length < 2) {  

       printUsage();  

       return 2;  

     }  

     Job job = new Job(getConf());  

     job.setJobName(""MultiFileWordCount"");  

     job.setJarByClass(MultiFileWordCount.class);  
    
     //set the InputFormat of the job to our InputFormat  

     job.setInputFormatClass(MyInputFormat.class);  
       
     // the keys are words (strings)  

     job.setOutputKeyClass(Text.class);  

     // the values are counts (ints)  

     job.setOutputValueClass(IntWritable.class);  
 
     //use the defined mapper  

     job.setMapperClass(MapClass.class);  

     //use the WordCount Reducer  

     job.setCombinerClass(IntSumReducer.class);  

     job.setReducerClass(IntSumReducer.class);  
   

     FileInputFormat.addInputPaths(job, args[0]);  

     FileOutputFormat.setOutputPath(job, new Path(args[1]));  

     return job.waitForCompletion(true) ? 0 : 1;  

   }  
   
   public static void main(String[] args) throws Exception {  

     int ret = ToolRunner.run(new MultiFileWordCount(), args);  

     System.exit(ret);  

   }  

 

"
MAPREDUCE-5667,Error in runtime in mapreduce code,"Hi,

While executing the code taking input xml file in mapreduce.

The error occurred is
Error: java.lang.ClassNotFoundException: org.jdom.input.SAXBuilder

Error: java.lang.ClassNotFoundException: org.jdom.JDOMException

I am using hadoop 0.20 and java 1.6

I used jdom-1.0.jar but still error coming.

Please help this issue suggest what version jar should i use.

Thanks in advance.
 "
MAPREDUCE-5666,org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java(org/apache/hadoop/mapreduce/lib/input:FileInputFormat.java):cannot find symbol,"hi 

I have written the below code , and facing the issue. i am using hadoop 0.20 vesion and java 1.6 the issue is 

org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java(org/apache/hadoop/mapreduce/lib/input:FileInputFormat.java):232: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
          if (globStat.isDirectory()) {
                      ^
org/apache/hadoop/mapreduce/lib/output/FileOutputCommitter.java(org/apache/hadoop/mapreduce/lib/output:FileOutputCommitter.java):208: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
    } else if(fs.getFileStatus(taskOutput).isDirectory()) {
                                          ^
org/apache/hadoop/mapred/JobConf.java(org/apache/hadoop/mapred:JobConf.java):433: cannot find symbol
symbol  : method getPattern(java.lang.String,java.util.regex.Pattern)
location: class org.apache.hadoop.mapred.JobConf
    return getPattern(JobContext.JAR_UNPACK_PATTERN, UNPACK_JAR_PATTERN_DEFAULT);
           ^
org/apache/hadoop/mapred/JobConf.java(org/apache/hadoop/mapred:JobConf.java):450: cannot find symbol
symbol  : method getTrimmedStrings(java.lang.String)
location: class org.apache.hadoop.mapred.JobConf
    return getTrimmedStrings(MRConfig.LOCAL_DIR);
           ^
org/apache/hadoop/mapred/FileInputFormat.java(org/apache/hadoop/mapred:FileInputFormat.java):165: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
      if (stat.isDirectory()) {
              ^
org/apache/hadoop/mapred/FileInputFormat.java(org/apache/hadoop/mapred:FileInputFormat.java):215: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
          if (globStat.isDirectory()) {
                      ^
org/apache/hadoop/mapred/FileInputFormat.java(org/apache/hadoop/mapred:FileInputFormat.java):218: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
              if (recursive && stat.isDirectory()) {
                                   ^
org/apache/hadoop/mapred/FileInputFormat.java(org/apache/hadoop/mapred:FileInputFormat.java):258: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
      if (file.isDirectory()) {
              ^
org/apache/hadoop/mapred/FileOutputCommitter.java(org/apache/hadoop/mapred:FileOutputCommitter.java):166: cannot find symbol
symbol  : method isDirectory()
location: class org.apache.hadoop.fs.FileStatus
    } else if(fs.getFileStatus(taskOutput).isDirectory()) {
                                          ^
org/apache/hadoop/mapred/LineRecordReader.java(org/apache/hadoop/mapred:LineRecordReader.java):100: incompatible types
found   : org.apache.hadoop.io.compress.SplitCompressionInputStream
required: org.apache.hadoop.fs.Seekable
        filePosition = cIn; // take pos from compressed stream
                       ^
org/apache/hadoop/mapreduce/lib/input/LineRecordReader.java(org/apache/hadoop/mapreduce/lib/input:LineRecordReader.java):98: incompatible types
found   : org.apache.hadoop.io.compress.SplitCompressionInputStream
required: org.apache.hadoop.fs.Seekable
        filePosition = cIn;



I have attached the code 

import java.io.DataInput;  

import java.io.DataOutput;  

import java.io.IOException;  

import java.util.StringTokenizer;  

import org.apache.hadoop.conf.Configured;  

import org.apache.hadoop.fs.FSDataInputStream;  

import org.apache.hadoop.fs.FileSystem;  

import org.apache.hadoop.fs.Path;  

import org.apache.hadoop.io.IntWritable;  

import org.apache.hadoop.io.Text;  

import org.apache.hadoop.io.WritableComparable;  

import org.apache.hadoop.mapreduce.InputSplit;  

import org.apache.hadoop.mapreduce.Job;  

import org.apache.hadoop.mapreduce.Mapper;  

import org.apache.hadoop.mapreduce.RecordReader;  

import org.apache.hadoop.mapreduce.TaskAttemptContext;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader;  

import org.apache.hadoop.mapreduce.lib.input.CombineFileSplit;  

import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  

import org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer;  

import org.apache.hadoop.util.LineReader;  

import org.apache.hadoop.util.Tool;  

import org.apache.hadoop.util.ToolRunner;  


 /**  

  * MultiFileWordCount is an example to demonstrate the usage of   

  * MultiFileInputFormat. This examples counts the occurrences of  

  * words in the text files under the given input directory.  

  */ 

public class MultiFileWordCount extends Configured implements Tool {  

   /**  

    * This record keeps <filename,offset> pairs.  

    */ 

public static class WordOffset implements WritableComparable {  

   private long offset;  

   private String fileName;  
  
   public void readFields(DataInput in) throws IOException {  

      this.offset = in.readLong();  

      this.fileName = Text.readString(in);  

     }  

     public void write(DataOutput out) throws IOException {  

       out.writeLong(offset);  

       Text.writeString(out, fileName);  

     }  

      public int compareTo(Object o) {  

       WordOffset that = (WordOffset)o;  

       int f = this.fileName.compareTo(that.fileName);  

       if(f == 0) {  

         return (int)Math.signum((double)(this.offset - that.offset));  

       }  

       return f;  

     }  

     @Override 

     public boolean equals(Object obj) {  

       if(obj instanceof WordOffset)  

       return this.compareTo(obj) == 0;  

       return false;  

     }  

     @Override 

     public int hashCode() {  

     assert false : ""hashCode not designed"";  

     return 42; //an arbitrary constant  

     }  

   }  

   /**  

    * To use {@link CombineFileInputFormat}, one should extend it, to return a   

    * (custom) {@link RecordReader}. CombineFileInputFormat uses   

    * {@link CombineFileSplit}s.   

    */ 

   public static class MyInputFormat   

     extends CombineFileInputFormat  {  

     public RecordReader createRecordReader(InputSplit split,  

      TaskAttemptContext context) throws IOException {  

       return new CombineFileRecordReader(  

         (CombineFileSplit)split, context, CombineFileLineRecordReader.class);  

     }  

   }  

  
   /**  

    * RecordReader is responsible from extracting records from a chunk  

    * of the CombineFileSplit.   

    */ 

   public static class CombineFileLineRecordReader   

     extends RecordReader {  

     private long startOffset; //offset of the chunk;  

     private long end; //end of the chunk;  

     private long pos; // current pos   

     private FileSystem fs;  

     private Path path;  

     private WordOffset key;  

     private Text value;  

     private FSDataInputStream fileIn;  

     private LineReader reader;  

     public CombineFileLineRecordReader(CombineFileSplit split,  

         TaskAttemptContext context, Integer index) throws IOException {  
      
       this.path = split.getPath(index);  

       fs = this.path.getFileSystem(context.getConfiguration());  

       this.startOffset = split.getOffset(index);  

       this.end = startOffset + split.getLength(index);  

       boolean skipFirstLine = false;  

       //open the file  

       fileIn = fs.open(path);  

       if (startOffset != 0) {  

       skipFirstLine = true;  

         --startOffset;  

         fileIn.seek(startOffset);  

       }  

       reader = new LineReader(fileIn);  

       if (skipFirstLine) {  // skip first line and re-establish ""startOffset"".  

        startOffset += reader.readLine(new Text(), 0,  

         (int)Math.min((long)Integer.MAX_VALUE, end - startOffset));  

       }  

       this.pos = startOffset;  

     }  

     public void initialize(InputSplit split, TaskAttemptContext context)  

        throws IOException, InterruptedException {  

     }
     public void close() throws IOException { }  

     public float getProgress() throws IOException {  

       if (startOffset == end) {  

        return 0.0f;  

       } else {  

       return Math.min(1.0f, (pos - startOffset) / (float)(end - startOffset));  

       }  

     }  

    public boolean nextKeyValue() throws IOException {  

       if (key == null) {  

         key = new WordOffset();  

         key.fileName = path.getName();  

       }  

       key.offset = pos;  

       if (value == null) {  

       value = new Text();  

       }  

       int newSize = 0;  

       if (pos < end) {  

        newSize = reader.readLine(value);  

        pos += newSize;  

       }  

       if (newSize == 0) {  

        key = null;  

        value = null;  

        return false;  

       } else {  

        return true;  

       }  

     }  

         public WordOffset getCurrentKey()   

         throws IOException, InterruptedException {  

          return key;  

     }  

         public Text getCurrentValue() throws IOException, InterruptedException {  

         return value;  

     }  

   }  

  
   /**  

    * This Mapper is similar to the one in {@link WordCount.MapClass}.  

    */ 

   public static class MapClass extends  

       Mapper {  

     private final static IntWritable one = new IntWritable(1);  

     private Text word = new Text();  

     public void map(WordOffset key, Text value, Context context)  

         throws IOException, InterruptedException {  

       String line = value.toString();  

       StringTokenizer itr = new StringTokenizer(line);  

       while (itr.hasMoreTokens()) {  

         word.set(itr.nextToken());  

         context.write(word, one);  

       }  

     }  

   }  

   private void printUsage() {  

     System.out.println(""Usage : multifilewc  "" );  

   }  
   public int run(String[] args) throws Exception {  

     if(args.length < 2) {  

       printUsage();  

       return 2;  

     }  

     Job job = new Job(getConf());  

     job.setJobName(""MultiFileWordCount"");  

     job.setJarByClass(MultiFileWordCount.class);  
    
     //set the InputFormat of the job to our InputFormat  

     job.setInputFormatClass(MyInputFormat.class);  
       
     // the keys are words (strings)  

     job.setOutputKeyClass(Text.class);  

     // the values are counts (ints)  

     job.setOutputValueClass(IntWritable.class);  
 
     //use the defined mapper  

     job.setMapperClass(MapClass.class);  

     //use the WordCount Reducer  

     job.setCombinerClass(IntSumReducer.class);  

     job.setReducerClass(IntSumReducer.class);  
   

     FileInputFormat.addInputPaths(job, args[0]);  

     FileOutputFormat.setOutputPath(job, new Path(args[1]));  

     return job.waitForCompletion(true) ? 0 : 1;  

   }  
   
   public static void main(String[] args) throws Exception {  

     int ret = ToolRunner.run(new MultiFileWordCount(), args);  

     System.exit(ret);  

   }  

 } 
"
MAPREDUCE-5665,Add audience annotations to MiniMRYarnCluster and MiniMRCluster,We should make it clear whether these are public interfaces.
MAPREDUCE-5664,java.lang.RuntimeException: javax.xml.parsers.ParserConfigurationException:,"Hi,

I am using hadoop 0.21 vesrsion and java 1.6.  Please help me to fix the issue. What version jar should i put. 

The sample code with xml i have attached here.

{code}
<?xml version=""1.0""?>
<Company>
<Employee>
<id>100</id>
<ename>ranjini</ename>
<dept>IT</dept>
<sal>123456</sal>
<location>nextlevel</location>
</Employee>
</Company>
{code}

{code}
import java.io.IOException;
import java.util.*;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapred.*;
import org.apache.hadoop.util.*;
import java.io.*;
import org.apache.hadoop.mapred.lib.*;

import java.io.Reader;
import java.io.StringReader;
import org.jdom.Document;
import org.jdom.Element;
import org.jdom.JDOMException;
import org.jdom.input.SAXBuilder;

public class ParseXml {
	public static class Map extends MapReduceBase implements
			Mapper<LongWritable, Text, Text, Text> {
		
		public void map(LongWritable key, Text value,
				OutputCollector<Text, Text> output, Reporter reporter) 
				throws IOException {
			
			String s="""";
			FileSystem fs=null;
			Configuration conf=new Configuration();
			conf.set(""fs.default.name"",""hdfs://localhost:4440/"");
			Path srcpath=new Path(""/user/hduser/Ran/"");
try {
	
					String xmlString = value.toString();
             
             		SAXBuilder builder = new SAXBuilder();
            		Reader in = new StringReader(xmlString);
 					Document doc = builder.build(in);
           			 Element root = doc.getRootElement();
	

  s =root.getChild(""Employee"").getChild(""id"").getChild(""ename"").getChild(""dept"").getChild(""sal"").getChild(""location"").getTextTrim();
 output.collect(new Text(""""),new Text(s));
		
    } catch (Exception e) {
	e.printStackTrace();
    }

}
}
			
	public static void main(String[] args) throws Exception {
		
		String input=""/user/hduser/Ran/"";
		String fileoutput=""/user/task/Sales/"";
		JobConf conf = new JobConf(ParseXml.class);
		conf.setJobName(""file"");
		conf.setOutputKeyClass(Text.class);
		conf.setOutputValueClass(Text.class);
		conf.setNumReduceTasks(1);
		conf.setMapperClass(Map.class);
		conf.setInputFormat(TextInputFormat.class);
		conf.setOutputFormat(TextOutputFormat.class);
		FileInputFormat.setInputPaths(conf,input);
		Path outPath = new Path(fileoutput);
		FileOutputFormat.setOutputPath(conf, outPath);
		FileSystem dfs = FileSystem.get(outPath.toUri(), conf);
			if (dfs.exists(outPath)) {
				dfs.delete(outPath, true);
			}
		//conf.setOutputFormat(MultiFileOutput.class);

		JobClient.runJob(conf);
	}
}
{code}

When processing xml file as input via map reduce, the error occurred is 

{code}
conf.Configuration: error parsing conf file: javax.xml.parsers.ParserConfigurationException: Feature 'http://apache.org/xml/features/xinclude' is not recognized.
Exception in thread ""main"" java.lang.RuntimeException: javax.xml.parsers.ParserConfigurationException: Feature 'http://apache.org/xml/features/xinclude' is not recognized.
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1171)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1030)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:980)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:382)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:109)
Caused by: javax.xml.parsers.ParserConfigurationException: Feature 'http://apache.org/xml/features/xinclude' is not recognized.
	at org.apache.xerces.jaxp.DocumentBuilderFactoryImpl.newDocumentBuilder(Unknown Source)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1061)
	... 4 more
{code}

Please help to fix the issue"
MAPREDUCE-5662,implement the support for using the shared cache for the job jar and libjars,
MAPREDUCE-5661,ShuffleHandler using yarn.nodemanager.local-dirs instead of mapreduce.cluster.local.dir,"While debugging an issue where a MapReduce job is failing due to running out of disk space, I noticed that the {{ShuffleHandler}} uses {{yarn.nodemanager.local-dirs}} for its {{LocalDirAllocator}} whereas all of the other MapReduce classes use {{mapreduce.cluster.local.dir}}:

{noformat}
$ find hadoop-mapreduce-project/hadoop-mapreduce-client/*/src/main/java/ -name ""*.java"" | xargs grep ""new LocalDirAllocator(""
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnChild.java:    LocalDirAllocator lDirAlloc = new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapred/YarnOutputFiles.java:    new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalDistributedCacheManager.java:      new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/BackupStore.java:      this.lDirAlloc = new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/MROutputFiles.java:    new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Merger.java:    new LocalDirAllocator(MRConfig.LOCAL_DIR);
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/Task.java:    this.lDirAlloc = new LocalDirAllocator(MRConfig.LOCAL_DIR);

*****hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/src/main/java/org/apache/hadoop/mapred/ShuffleHandler.java:      new LocalDirAllocator(YarnConfiguration.NM_LOCAL_DIRS);
{noformat}

This inconsistency feels like something that is likely to confuse admins.  "
MAPREDUCE-5660,Log info about possible thrashing (when using memory-based scheduling in Capacity Scheduler) is not printed,"There is a tiny, but confusing when troubleshooting, bug in TaskTracker code:
{code}
if (totalMemoryAllottedForTasks > totalPhysicalMemoryOnTT) {
  LOG.info(""totalMemoryAllottedForTasks > totalPhysicalMemoryOnTT.""
      + "" Thrashing might happen."");
} else if (totalMemoryAllottedForTasks > totalVirtualMemoryOnTT) {
  LOG.info(""totalMemoryAllottedForTasks > totalVirtualMemoryOnTT.""
      + "" Thrashing might happen."");
}
{code}
totalMemoryAllottedForTasks is calculated in megabytes, while totalPhysicalMemoryOnTT (and totalVirtualMemoryOnTT) is calculated in bytes. totalMemoryAllottedForTasks should be converted to bytes for a correct comparison."
MAPREDUCE-5657,[JDK8] Fix Javadoc errors caused by incorrect or illegal tags in doc comments,Javadoc is more strict by default in JDK8 and will error out on malformed or illegal tags found in doc comments. Although tagged as JDK8 all of the required changes are generic Javadoc cleanups.
MAPREDUCE-5656,bzip2 codec can drop records when reading data in splits,"Bzip2Codec.BZip2CompressionInputStream can cause records to be dropped when reading them in splits based on where record delimiters occur relative to compression block boundaries.

Thanks to [~knoguchi] for discovering this problem while working on PIG-3251."
MAPREDUCE-5655,Remote job submit from windows to a linux hadoop cluster fails due to wrong classpath,"I was trying to run a java class on my client, windows 7 developer environment, which submits a job to the remote Hadoop cluster, initiates a mapreduce there, and then downloads the results back to the local machine.

General use case is to use hadoop services from a web application installed on a non-cluster computer, or as part of a developer environment.

The problem was, that the ApplicationMaster's startup shell script (launch_container.sh) was generated with wrong CLASSPATH entry. Together with the java process call on the bottom of the file, these entries were generated in windows style, using % as shell variable marker and ; as the CLASSPATH delimiter.

I tracked down the root cause, and found that the MrApps.java, and the YarnRunner.java classes create these entries, and is passed forward to the ApplicationMaster, assuming that the OS that runs these classes will match the one running the ApplicationMaster. But it's not the case, these are in 2 different jvm, and also the OS can be different, the strings are generated based on the client/submitter side's OS.

I made some workaround changes to these 2 files, so i could launch my job, however there may be more problems ahead.

update
 error message:
13/12/04 16:33:15 INFO mapreduce.Job: Job job_1386170530016_0001 failed with state FAILED due to: Application application_1386170530016_0001 failed 2 times due to AM Container for appattempt_1386170530016_0001_000002 exited with  exitCode: 1 due to: Exception from container-launch: 
org.apache.hadoop.util.Shell$ExitCodeException: /bin/bash: line 0: fg: no job control

at org.apache.hadoop.util.Shell.runCommand(Shell.java:464)
	at org.apache.hadoop.util.Shell.run(Shell.java:379)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:589)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:195)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:283)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:79)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
	at java.util.concurrent.FutureTask.run(FutureTask.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:724)

update2: 
 It also reqires to add the following property to 
 mapred-site.xml (or mapred-default.xml), on the windows box, so that the job launcher knows, that the job runner will be a linux:
  <property>
  <name>mapred.remote.os</name>
  <value>Linux</value>
  <description>Remote MapReduce framework's OS, can be either Linux or Windows</description>
 </property

without this entry, the patched jar does the same as the unpatched, so it's required to work!"
MAPREDUCE-5653,"DistCp does not honour config-overrides for mapreduce.[map,reduce].memory.mb","When a DistCp job is run through Oozie (through a Java action that launches DistCp), one sees that mapred.child.java.opts as set from the caller is honoured by DistCp. But, DistCp doesn't seem to honour any overrides for configs mapreduce.[map,reduce].memory.mb.

Problem has been identified. I'll post a patch shortly."
MAPREDUCE-5652,NM Recovery. ShuffleHandler should handle NM restarts,"ShuffleHandler should work across NM restarts and not require re-running map-tasks. On NM restart, the map outputs are cleaned up requiring re-execution of map tasks and should be avoided."
MAPREDUCE-5651,Backport Fair Scheduler queue placement policies to branch-1,YARN-1392 introduced general policies for assigning applications to queues in the YARN fair scheduler.  This functionality would be useful and minimally invasive in MR1 as well.
MAPREDUCE-5650,Job fails when hprof mapreduce.task.profile.map/reduce.params is specified,"When one uses dedicated hprof mapreduce.task.profile.map.params or mapreduce.task.profile.reduce.params, the profiled tasks will fail to launch because hprof parameters are supplied to the child jvm twice."
MAPREDUCE-5649,Reduce cannot use more than 2G memory  for the final merge,"In the org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.java file, in the finalMerge method: 

 int maxInMemReduce = (int)Math.min(
        Runtime.getRuntime().maxMemory() * maxRedPer, Integer.MAX_VALUE);
 
This means no matter how much memory user has, reducer will not retain more than 2G data in memory before the reduce phase starts.
"
MAPREDUCE-5646,Option to shuffle splits of equal size,"Mapreduce split calculation has the following base logic (via JobClient and the major InputFormat implementations ):
◾enumerate input files in natural (aka linear) order.
◾create one split for each 'block-size' of each input. Apart from rack-awareness, combining and so on, the input file order remains in its natural order.
◾sort the splits by size using a stable sort based on splitsize.

When data from multiple storage services are used in a single hadoop job, we get better I/O utilization if the list of splits does round-robin or random-access across the services. 
The particular scenario arises in Azure HDInsight where jobs can easily read from many storage accounts and each storage account has hard limits on throughtput.  Concurrent access to the accounts is substantially better than 
 
Two common scenarios can cause non-ideal access pattern:
 1. many/all input files are the same size
 2. files have different sizes, but many/all input files have size>blocksize.
 In the second scenario, for each file will have one or more splits with size exactly equal to block size so it basically degenerates to the first scenario.

There are various ways to solve the problem but the simplest is to alter the mapreduce JobClient to sort splits by size _and_ randomize the order of splits with equal size. This keeps the old behavior effectively unchanged while also fixing both common problematic scenarios.

Some rare scenarios will still suffer bad access patterns due. For example if two storage accounts are used and the files from one storage account are all smaller than from the other then problems can arise. Addressing these scenarios would be further work, perhaps by completely randomizing the split order. These problematic scenarios are considered rare and not requiring immediate attention.

If further algorithms for split ordering are necessary, the implementation in JobClient will change to being interface-based (eg interface splitOrderer) with various standard implementations.  At this time there is only the need for two implementations and so simple Boolean flag and if/then logic is used.
"
MAPREDUCE-5645,TestFixedLengthInputFormat fails with native libs,"mvn clean install -Pnative -DskipTests
hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient
mvn clean test -Dtest=TestFixedLengthInputFormat

Running org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat
Tests run: 8, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 39.957 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat
testGzipWithTwoInputs(org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat)  Time elapsed: 0.029 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:65)
	at org.apache.hadoop.io.compress.GzipCodec.createOutputStream(GzipCodec.java:162)
	at org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.writeFile(TestFixedLengthInputFormat.java:397)
	at org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testGzipWithTwoInputs(TestFixedLengthInputFormat.java:229)

testFormatCompressedIn(org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat)  Time elapsed: 0.01 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:65)
	at org.apache.hadoop.io.compress.GzipCodec.createOutputStream(GzipCodec.java:162)
	at org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.createFile(TestFixedLengthInputFormat.java:261)
	at org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.runRandomTests(TestFixedLengthInputFormat.java:314)
	at org.apache.hadoop.mapreduce.lib.input.TestFixedLengthInputFormat.testFormatCompressedIn(TestFixedLengthInputFormat.java:96)

Running org.apache.hadoop.mapred.TestFixedLengthInputFormat
Tests run: 8, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 46.151 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestFixedLengthInputFormat
testPartialRecordCompressedIn(org.apache.hadoop.mapred.TestFixedLengthInputFormat)  Time elapsed: 0.031 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:65)
	at org.apache.hadoop.io.compress.GzipCodec.createOutputStream(GzipCodec.java:162)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.writeFile(TestFixedLengthInputFormat.java:357)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.runPartialRecordTest(TestFixedLengthInputFormat.java:386)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.testPartialRecordCompressedIn(TestFixedLengthInputFormat.java:182)

testGzipWithTwoInputs(org.apache.hadoop.mapred.TestFixedLengthInputFormat)  Time elapsed: 0.009 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:65)
	at org.apache.hadoop.io.compress.GzipCodec.createOutputStream(GzipCodec.java:162)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.writeFile(TestFixedLengthInputFormat.java:357)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.testGzipWithTwoInputs(TestFixedLengthInputFormat.java:201)

testFormatCompressedIn(org.apache.hadoop.mapred.TestFixedLengthInputFormat)  Time elapsed: 0.017 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.io.compress.zlib.ZlibFactory.isNativeZlibLoaded(ZlibFactory.java:65)
	at org.apache.hadoop.io.compress.GzipCodec.createOutputStream(GzipCodec.java:162)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.createFile(TestFixedLengthInputFormat.java:234)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(TestFixedLengthInputFormat.java:287)
	at org.apache.hadoop.mapred.TestFixedLengthInputFormat.testFormatCompressedIn(TestFixedLengthInputFormat.java:90)


Results :

Tests in error: 
  TestFixedLengthInputFormat.testGzipWithTwoInputs:229->writeFile:397 » NullPointer
  TestFixedLengthInputFormat.testFormatCompressedIn:96->runRandomTests:314->createFile:261 » NullPointer
  TestFixedLengthInputFormat.testPartialRecordCompressedIn:182->runPartialRecordTest:386->writeFile:357 » NullPointer
  TestFixedLengthInputFormat.testGzipWithTwoInputs:201->writeFile:357 » NullPointer
  TestFixedLengthInputFormat.testFormatCompressedIn:90->runRandomTests:287->createFile:234 » NullPointer

Tests run: 16, Failures: 0, Errors: 5, Skipped: 0
"
MAPREDUCE-5643,DynamicMR: A Dynamic Slot Utilization Optimization Framework for Hadoop MRv1,"Hadoop MRv1 uses the slot-based resource model with the static configuration of map/reduce slots. There is a strict utility constrain that map tasks can only run on map slots and reduce tasks can only use reduce slots. Due to the rigid execution order between map and reduce tasks in a MapReduce environment, slots can be severely under-utilized, which significantly degrades the performance. 

In contrast to YARN that gives up the slot-based resource model and propose a container-based model to maximize the resource utilization via unawareness of the types of map/reduce tasks, we keep the slot-based model and propose a dynamic slot utilization optimization system called DynamicMR to improve the performance of Hadoop by maximizing the slots utilization as well as slot utilization efficiency while guaranteeing the fairness across pools. It consists of three types of scheduling components, namely, Dynamic Hadoop Fair Scheduler (DHFS), Dynamic Speculative Task Scheduler (DSTS), and Data Locality Maximization Scheduler (DLMS).

Our tests show that DynamicMR outperforms YARN for MapReduce workloads with multiple jobs, especially when the number of jobs is large. The explanation is that, given a certain number of resources, it is obvious that the performance for the case with a ratio control of concurrently running map and reduce tasks is better than without control. Because without control, it easily occurs that there are too many reduce tasks running, causing the network to be a bottleneck seriously. For YARN, both map and reduce tasks can run on any idle container. There is no control mechanism for the ratio of resource allocation between map and reduce tasks. It means that when there are pending reduce tasks, the idle container will be most likely possessed by them. In contrast, DynamicMR follows the traditional slot-based model. In contrast to the ’hard’ constrain of slot allocation that map slots have to be allocated to map tasks and reduce tasks should be dispatched to reduce tasks, DynamicMR obeys a ’soft’ constrain of slot allocation to allow that map slot can be allocated to reduce task and vice versa. But whenever there are pending map tasks, the map slot should be given to map tasks first, and the rule is similar for reduce tasks. It means that, the traditional way of static map/reduce slot configuration for the ratio control of running map/reduce tasks still works for DynamicMR. In comparison to YARN which maximizes the resource utilization only, DynamicMR can maximize the slot resource utilization and meanwhile dynamically control the ratio of running map/reduce tasks via map/reduce slot configuration."
MAPREDUCE-5642,TestMiniMRChildTask fails on Windows,"The test fails on Windows as a regression from MAPREDUCE-5451. In MAPREDUCE-5451, we set default config of ""mapreduce.admin.user.env"" to ""PATH=%PATH%;%HADOOP_COMMON_HOME%\\bin"" on Windows. In the test, we set ""PATH=%PATH%;tmp"" for ""mapreduce.map.env"" and ""mapreduce.map.env"". Because the the change in MAPREDUCE-5451, PATH will be set twice now and the value we get in the child tasks no longer matches the previous expected value."
MAPREDUCE-5640,Rename TestLineRecordReader in jobclient module,HADOOP-9622 proposes to add new unit tests for LineRecordReader in the mapreduce-client-core module alongside the code.  The existing LineRecordReader tests in the mapreduce-client-jobclient module should be renamed to something like TestLineRecordReaderJobs to avoid a name conflict and to better indicate these are integration tests using full jobs rather than unit tests.
MAPREDUCE-5639,Port DistCp2 document to trunk,Port DistCp2 document (http://hadoop.apache.org/docs/r1.2.1/distcp2.html)  to trunk.
MAPREDUCE-5638,Port Hadoop Archives document to trunk,Now Hadoop Archive document exists only in branch-1. Let's port Hadoop Archives document to trunk.
MAPREDUCE-5637,Convert Hadoop Streaming document to APT,Convert Hadoop Streaming document from forrest to APT.
MAPREDUCE-5636,Convert MapReduce Tutorial document to APT,"Convert MapReduce Tutorial document from forrest to APT.
"
MAPREDUCE-5635,FileInputFormat does not specify how the file is split,"

Here is what the TextInputFormat javadoc says:
[TextInputFormat|http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/lib/input/TextInputFormat.html]

An InputFormat for plain text files. Files are broken into lines. Either linefeed or carriage-return are used to signal end of line. Keys are the position in the file, and values are the line of text..

FileInputFormat should say the same on
[FileInputFormat|http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.html]

"
MAPREDUCE-5633,Can Hadoop use multi-cores of a processor under single machine,
MAPREDUCE-5632,TestRMContainerAllocator#testUpdatedNodes fails,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1607/console :
{code}
Running org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator
Tests run: 14, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 65.78 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator
testUpdatedNodes(org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator)  Time elapsed: 3.125 sec  <<< FAILURE!
junit.framework.AssertionFailedError: null
	at junit.framework.Assert.fail(Assert.java:48)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testUpdatedNodes(TestRMContainerAllocator.java:779)
{code}
This assertion fails:
{code}
    Assert.assertTrue(allocator.getJobUpdatedNodeEvents().isEmpty());
{code}
The List returned by allocator.getJobUpdatedNodeEvents() is:
[EventType: JOB_UPDATED_NODES]"
MAPREDUCE-5631,TestJobEndNotifier.testNotifyRetries fails with Should have taken more than 5 seconds in jdk7,Configuration settings are bleeding over from test to test in jdk7 environment since tests are run in random order.
MAPREDUCE-5628,Tracking ids only for HDFS tokens should be included in jobconf,"MAPREDUCE-5379 adds the ability to track HDFS accesses of an MR job by adding the tracking-ids from all the tokens to the jobconf. However, only HDFS delegation tokens have a tracking-id. Trying to fetch tracking-ids from other tokens can lead to an NPE."
MAPREDUCE-5626,TaskLogServlet could not get syslog,"When multiply tasks use one jvm and generated logs.
eg.
./attempt_201211220735_0001_m_000000_0:
log.index
./attempt_201211220735_0001_m_000001_0:
log.index
./attempt_201211220735_0001_m_000002_0:
log.index  stderr  stdout  syslog
get from http://xxxxxxxx:50060/tasklog?attemptid= attempt_201211220735_0001_m_000000_0 
could get stderr,stdout,but not the others,include syslog.

see TaskLogServlet.haveTaskLog() method, not check from local && log.index, but check the original path.

resolve:
modify TaskLogServlet haveTaskLog method
    private boolean haveTaskLog(TaskAttemptID taskId, boolean isCleanup,  
            TaskLog.LogName type) throws IOException {  
        File f = TaskLog.getTaskLogFile(taskId, isCleanup, type);  
        if (f.exists() && f.canRead()) {  
            return true;  
        } else {  
            File indexFile = TaskLog.getIndexFile(taskId, isCleanup);  
            if (!indexFile.exists()) {  
                return false;  
            }  
       
       
            BufferedReader fis;  
            try {  
                fis = new BufferedReader(new InputStreamReader(  
                        SecureIOUtils.openForRead(indexFile,  
                                TaskLog.obtainLogDirOwner(taskId))));  
            } catch (FileNotFoundException ex) {  
                LOG.warn(""Index file for the log of "" + taskId  
                        + "" does not exist."");  
       
       
                // Assume no task reuse is used and files exist on attemptdir  
                StringBuffer input = new StringBuffer();  
                input.append(LogFileDetail.LOCATION  
                        + TaskLog.getAttemptDir(taskId, isCleanup) + ""\n"");  
                for (LogName logName : TaskLog.LOGS_TRACKED_BY_INDEX_FILES) {  
                    input.append(logName + "":0 -1\n"");  
                }  
                fis = new BufferedReader(new StringReader(input.toString()));  
            }  
       
       
            try {  
                String str = fis.readLine();  
                if (str == null) { // thefile doesn't have anything  
                    throw new IOException(""Index file for the log of "" + taskId  
                            + ""is empty."");  
                }  
                String loc = str.substring(str.indexOf(LogFileDetail.LOCATION)  
                        + LogFileDetail.LOCATION.length());  
                File tf = new File(loc, type.toString());  
                return tf.exists() && tf.canRead();  
       
       
            } finally {  
                if (fis != null)  
                    fis.close();  
            }  
        }  
       
       
    }  

workaround:
url add filter=SYSLOG could print syslog also.
"
MAPREDUCE-5625,TestFixedLengthInputFormat fails in jdk7 environment,
MAPREDUCE-5624,move grizzly-test and junit dependencies to test scope,stop the the grizzly dependences & Junit getting into everything downstream by moving them to test scope
MAPREDUCE-5623,TestJobCleanup fails because of RejectedExecutionException and NPE.,"org.apache.hadoop.mapred.TestJobCleanup can fail because of RejectedExecutionException by NonAggregatingLogHandler. This problem is described in YARN-1409. TestJobCleanup can still fail after fixing RejectedExecutionException, because of NPE by Job#getCounters()'s returning null.

{code}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapred.TestJobCleanup
-------------------------------------------------------------------------------
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 140.933 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestJobCleanup
testCustomAbort(org.apache.hadoop.mapred.TestJobCleanup)  Time elapsed: 31.068 sec  <<< ERROR!
java.lang.NullPointerException: null
        at org.apache.hadoop.mapred.TestJobCleanup.testFailedJob(TestJobCleanup.java:199)
        at org.apache.hadoop.mapred.TestJobCleanup.testCustomAbort(TestJobCleanup.java:296)
{code}"
MAPREDUCE-5621,mr-jobhistory-daemon.sh doesn't have to execute mkdir and chown all the time,"mr-jobhistory-daemon.sh executes mkdir and chown command to output the log files.
This is always executed with or without a directory. In addition, this is executed not only starting daemon but also stopping daemon.
It add ""if"" like hadoop-daemon.sh and yarn-daemon.sh and should control it."
MAPREDUCE-5620,distcp1 -delete fails when target directory contains files with percent signs,"Debugging a distcp1 issue, it fails to delete extra files in the target directory when there is a percent sign in the filename. I'm pretty sure this is an issue with how percent encoding is handled in FsShell (reproduced with just ""hadoop fs -rmr""), but we can also fix this in distcp1 by using FileSystem instead of FsShell. This is what distcp2 does."
MAPREDUCE-5618,Allow setting lineage information,"MR AM sets the applicationType to be ""MAPREDUCE"". Downstream projects like Pig, Hive, Oozie might want to set this to a different value for their error-handling, query-tracking etc. Making this pluggable should help this cause.

"
MAPREDUCE-5617,map task is not re-launched when the task is failed while reducers are running with full cluster capacity - which will lead to job hang,"In a Cluster with 16GB capacity, job has started with 100maps and 10 reducers. 

When the reducers has started its execution, one NM has went down and resulted a failure for 2 maps. But at this time, remaining 8Gb was used by 6 reducers and AM. So there was no place to launch the failed maps. [NM never came up again, and cluster size became 8GB]

If we kill one of reducers, then also the map cannot be launched as the priority of Failed map is lesser than that of reducer. So the remaining reducer only will get allocated from RM side.

This is causing a hang for in reducer side. "
MAPREDUCE-5616,MR Client-AppMaster RPC max retries on socket timeout is too high.,"MAPREDUCE-3811 introduced a separate config key for overriding the max retries applied to RPC connections from the MapReduce Client to the MapReduce Application Master.  This was done to make failover from the AM to the MapReduce History Server faster in the event that the AM completes while the client thinks it's still running.  However, the RPC client uses a separate setting for socket timeouts, and this one is not overridden.  The default for this is 45 retries with a 20-second timeout on each retry.  This means that in environments subject to connection timeout instead of connection refused, the client waits 15 minutes for failover."
MAPREDUCE-5614,job history file name should escape job status,"Our cluster's queue name contains hyphen e.g. cug-taobao. Because hyphen is the delimiter of job history file name, JobHistoryServer shows ""cug"" as the queue name. To fix this problem, we should escape queuename in job history file name."
MAPREDUCE-5613,DefaultSpeculator holds and checks hashmap that is always empty,"The only way pendingSpeculations is used:
{code}
     // If the task is already known to be speculation-bait, don't do anything   
      if (pendingSpeculations.get(task) != null) {                                
        if (pendingSpeculations.get(task).get()) {                                
          return;                                                                 
        }                                                                         
      } 
{code}"
MAPREDUCE-5612,Add javadoc for TaskCompletionEvent.Status,What's the difference between FAILED and TIPFAILED?  What is OBSOLETE?
MAPREDUCE-5610,TestSleepJob fails in jdk7,"In jdk7 tests methods in a class do not run in file order, but rather in random order. TestSleepJob hosts are not initialized and a NullPointerException is thrown unless testRandomLocation was run first.

This can be easily seen by running tests individually.

org.apache.hadoop.mapred.gridmix.TestSleepJob#testStressSubmit
org.apache.hadoop.mapred.gridmix.TestSleepJob#testReplaySubmit
org.apache.hadoop.mapred.gridmix.TestSleepJob#testSerialSubmit
org.apache.hadoop.mapred.gridmix.TestSleepJob#testMapTasksOnlySleepJobs
org.apache.hadoop.mapred.gridmix.TestSleepJob#testRandomLocation"
MAPREDUCE-5609,Add debug log message when sending job end notification,"Currently, it's hard to tell if the job end notification is working and if its backed up because you only see log messages if there was an error making the notification.  It would be helpful to add a debug log message when the job end notification is sent."
MAPREDUCE-5608,Replace and deprecate mapred.tasktracker.indexcache.mb,"In MR2 mapred.tasktracker.indexcache.mb still works for configuring the size of the shuffle service index cache.  As the tasktracker no longer exists, we should replace this with something like mapreduce.shuffle.indexcache.mb. "
MAPREDUCE-5607,Backport MAPREDUCE-5086 - MR app master deletes staging dir when sent a reboot command from the RM,"If the RM is restarted when the MR job is running, then it sends a reboot command to the job. The job ends up deleting the staging dir and that causes the next attempt to fail."
MAPREDUCE-5606,JobTracker blocked for DFSClient: Failed recovery attempt,"when a  datanode was crash,the server can  ping ok,but can not  call rpc ,and also can not ssh login. and then jobTracker may be request a block on this datanode.
it will happened ,the  JobTracker can not work,the webUI is also unwork,hadoop job -list also unwork,the jobTracker logs no other info .

and then we need to restart the datanode.
then jobTraker can work too,but the taskTracker num come to zero,
we need run : hadoop mradmin -refreshNodes
then the JobTracker begin to add taskTraker ,but is very slowly.

this problem occur 5time  in 2weeks.
"
MAPREDUCE-5604,TestMRAMWithNonNormalizedCapabilities fails on Windows due to exceeding max path length,The test uses the full class name as a component of the {{yarn.nodemanager.local-dirs}} setting for a {{MiniMRYarnCluster}}.  This causes container launch to fail when trying to access files at a path longer than the maximum of 260 characters.
MAPREDUCE-5603,Ability to disable FileInputFormat listLocatedStatus optimization to save client memory,It would be nice if users had the option to disable the listLocatedStatus optimization in FileInputFormat to save client memory.
MAPREDUCE-5601,ShuffleHandler fadvises file regions as DONTNEED even when fetch fails,"When a reducer initiates a fetch request, it does not know whether it will be able to fit the fetched data in memory.  The first part of the response tells how much data will be coming.  If space is not currently available, the reduce will abandon its request and try again later.  When this occurs, the ShuffleHandler still fadvises the file region as DONTNEED.  Meaning that the next time it's asked for, it will definitely be read from disk, even if it happened to be in the page cache before the request.

I noticed this when trying to figure out why my job was doing so much more disk IO in MR2 than in MR1.  When I turned the fadvise stuff off, I found that disk reads went to nearly 0 on machines that had enough memory to fit map outputs into the page cache.  I then straced the NodeManager and noticed that there were over four times as many fadvise DONTNEED calls as map-reduce pairs.  Further logging showed the same map outputs being fetched about this many times.

This is a regression from MR1, which only did the fadvise DONTNEED after all the bytes were transferred."
MAPREDUCE-5598,TestUserDefinedCounters.testMapReduceJob is flakey,"{{TestUserDefinedCounters.testMapReduceJob}} is flakey.  

We sometimes see it fail:
{noformat}
junit.framework.AssertionFailedError
	at junit.framework.Assert.fail(Assert.java:48)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob(TestUserDefinedCounters.java:113)
{noformat}

Upon investigation, the problem is that the input for the MR job in this test is at {{System.getProperty(""test.build.data"", ""/tmp"") + ""/input""}}.  If an earlier test wrote some files there, this test will use them as part of its input.  This can cause all sorts of problems with this test because its not expecting the additional input data."
MAPREDUCE-5597,Missing alternatives in javadocs for deprecated constructors in mapreduce.Job,"Deprecated API, such as `new Job()` don't have javadocs explaining what the alternatives are. (It'd also help if the new methods had @since tags to help determine if one could safely use that API on older versions at runtime.)"
MAPREDUCE-5596,Allow configuring the number of threads used to serve shuffle connections,MR1 had mapreduce.tasktracker.http.threads.  MR2 always uses the Netty default 2 * Runtime.availableProcessors().  We should make this configurable.
MAPREDUCE-5595,Typo in MergeManagerImpl.java,"There's a typo (""Invlaid"" which should be ""Invalid"") in line 199 of MergeManagerImpl.java
currently:
    if (this.maxSingleShuffleLimit >= this.mergeThreshold) {
      throw new RuntimeException(""Invlaid configuration: ""
          + ""maxSingleShuffleLimit should be less than mergeThreshold""
          + ""maxSingleShuffleLimit: "" + this.maxSingleShuffleLimit
          + ""mergeThreshold: "" + this.mergeThreshold);
    }

should be:

    if (this.maxSingleShuffleLimit >= this.mergeThreshold) {
      throw new RuntimeException(""Invalid configuration: ""
          + ""maxSingleShuffleLimit should be less than mergeThreshold""
          + ""maxSingleShuffleLimit: "" + this.maxSingleShuffleLimit
          + ""mergeThreshold: "" + this.mergeThreshold);
    }"
MAPREDUCE-5589,MapReduce Job setup error leaves no useful info to users  (when LinuxTaskController is used),
MAPREDUCE-5588,TaskTrackers get killed by JettyBugMonitor because of incredibly high cpu usage,"We are running a little cluster with 10 servers running task trackers. All of them are getting killed randomly with the following message

{quote}
2013-10-17 11:32:31,037 FATAL org.apache.hadoop.mapred.JettyBugMonitor: ************************************************************
Jetty CPU usage: 120093277.1%. This is greater than the fatal threshold mapred.tasktracker.jetty.cpu.threshold.fatal. Aborting JVM.
************************************************************
2013-10-17 11:32:31,039 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down TaskTracker
************************************************************/
{quote}

Everytime, the message notices a cpu usage above 120M%. Everything has been running for a while now (since 1.1.2 release) without any problems, and it started just like that.

Any idea of what could cause this ?"
MAPREDUCE-5587,TestTextOutputFormat fails on JDK7,the test method run order on JDK7 is not fixed causing test method inter-dependencies to show themselves.
MAPREDUCE-5586,TestCopyMapper#testCopyFailOnBlockSizeDifference fails when run from hadoop-tools/hadoop-distcp directory,
MAPREDUCE-5585,TestCopyCommitter#testNoCommitAction Fails on JDK7,TestCopyCommitter#testNoCommitAction fails on JDK7 when run after testAtomicCommitMissingFinal or testAtomicCommitExistingFinal. Config settings are from atomic tests are being accidentally used for testNoCommitAction.
MAPREDUCE-5584,ShuffleHandler becomes unresponsive during gridmix runs and can leak file descriptors,While running gridmix on 2.3 we noticed that jobs are running much slower than normal.  We tracked this down to reducers having difficulties shuffling data from maps.  Details to follow.
MAPREDUCE-5583,Ability to limit running map and reduce tasks,"It would be nice if users could specify a limit to the number of map or reduce tasks that are running simultaneously.  Occasionally users are performing operations in tasks that can lead to DDoS scenarios if too many tasks run simultaneously (e.g.: accessing a database, web service, etc.).  Having the ability to throttle the number of tasks simultaneously running would provide users a way to mitigate issues with too many tasks on a large cluster attempting to access a serivce at any one time.

This is similar to the functionality requested by MAPREDUCE-224 and implemented by HADOOP-3412 but was dropped in mrv2."
MAPREDUCE-5582,Setting mapred.job.reduce.memory.mb to 0 from a job with CapacityTracker leads to inconsistent state in JVMManager,"If a job sets mapred.job.reduce.memory.mb to 0 the capacity scheduler incorrectly allocates resources eventually causing ""Inconsistent state!!! JVM Manager reached an unstable state while reaping a JVM for task"" errors from the JVMManager killing all TaskTrackers that have been used for the job."
MAPREDUCE-5581,killing jobs which have failed causes log missing,"In hive code,when a job failed,they invoke the RunningJob.killJob() API immediately.
From mapreduce client side,when job is at failed state,the YARNRunner will invoke resMgrDelegate.killApplication to kill that job.And this prevent AM from writing logs to job history server."
MAPREDUCE-5571,allow access to the DFS job submission + staging directory by members of the job submitters group,"The job submission and staging directories are explicitly given 0700 permissions restricting access of job submission files only to the submitter UID. this prevents hadoop daemon services running under different UIDs from reading the job submitters files.  it is common unix practice to run daemon services under their own UIDs for security purposes.

This bug can be demonstrated by creating a single node configuration, which runs LocalFileSystem and not HDFS.  Create two users and add them to a 'hadoop' group.  Start the hadoop services with one of the users, then submit a map/reduce job with the other user (or run one of the examples).  Job submission ultimately fails and the M/R job doesn't execute.

The fix is simple enough and secure-- change the staging directory permissions to 2750.  i have demonstrated the patch against 2.0.5 (along  with another fix for an incorrect decimal->octal conversion) and will attach the patch.

this bug is present since very early versions.  i would like to fix it at the lowest level as  it's a simple file mode change in all versions, and localized to one file.  is this possible?"
MAPREDUCE-5570,Map task attempt with fetch failure has incorrect attempt finish time,If a map task attempt is retroactively failed due to excessive fetch failures reported by reducers then the attempt's finish time is set to the time the task was retroactively failed rather than when the task attempt completed.  This causes the map task attempt to appear to have run for much longer than it actually did.
MAPREDUCE-5569,FloatSplitter is not generating correct splits,"The closing split is not calculated correctly:
{code}
     // Catch any overage and create the closed interval for the last split.
     if (curLower <= maxVal || splits.size() == 1) {
       splits.add(new DataDrivenDBInputFormat.DataDrivenDBInputSplit(
-          lowClausePrefix + Double.toString(curUpper),
+          lowClausePrefix + Double.toString(curLower),
           colName + "" <= "" + Double.toString(maxVal)));
     }
{code}
For the case of min=5.0, max=7.0, 2 splits, the current code returns splits of (column1 >=5.0, column1 <6.0), (column1 >=7.0, column1 <=7.0). The second split is obviously not correct."
MAPREDUCE-5568,JHS returns invalid string for reducer completion percentage if AM restarts with 0 reducer.,"JobCLient shows like:
{code}
13/10/05 16:26:09 INFO mapreduce.Job:  map 100% reduce NaN%
13/10/05 16:26:09 INFO mapreduce.Job: Job job_1381015536254_0001 completed successfully
13/10/05 16:26:09 INFO mapreduce.Job: Counters: 26
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=76741
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=48
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=1
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
{code}
With mapped job -status command, it shows:
{code}
Uber job : false
Number of maps: 1
Number of reduces: 0
map() completion: 1.0
reduce() completion: NaN
Job state: SUCCEEDED
retired: false
reason for failure:
{code}"
MAPREDUCE-5567,[Umbrella] Stabilize MR framework w.r.t ResourceManager restart,There are a bunch of tickets tracking MR AM's issues w.r.t RM restart. Consolidating them here so that we don't make contradictory fixes accross JIRAs.
MAPREDUCE-5566,On MR application master ui cluster links are broken in https,The links are pointing to http port instead of https port of resource manager.
MAPREDUCE-5565,job clean up fails on secure cluster as the file system is not created in the context of the ugi running the job,"On secure clusters we see the following exceptions in the jt log

{code}
2013-10-04 04:52:31,753 ERROR org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:tt/host@REALM cause:javax.security.sasl.SaslException: GSS
initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
{code}


And after the job finishes the staging dir is not cleaned up. While debugging with [~acmurthy] we determined that file system object needs to be created in the the context of the user who ran the job.

Job however successfully completes"
MAPREDUCE-5563,  TestMiniMRChildTask test cases failing on trunk,"Failed tests:
  TestMiniMRChildTask.testTaskTempDir:367 Exception in testing temp dir
  TestMiniMRChildTask.testTaskEnv:390 Exception in testing child env
  TestMiniMRChildTask.testTaskOldEnv:413 Exception in testing child env

"
MAPREDUCE-5562,MR AM should exit when unregister() throws exception,
MAPREDUCE-5561,org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl testcase failing on trunk,"Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
Tests run: 15, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 9.029 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl
testFailAbortDoesntHang(org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl)  Time elapsed: 5.507 sec  <<< FAILURE!
java.lang.AssertionError: expected:<FAIL_ABORT> but was:<FAILED>
at org.junit.Assert.fail(Assert.java:93)
at org.junit.Assert.failNotEquals(Assert.java:647)
at org.junit.Assert.assertEquals(Assert.java:128)
at org.junit.Assert.assertEquals(Assert.java:147)
at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.assertJobState(TestJobImpl.java:817)
at org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.testFailAbortDoesntHang(TestJobImpl.java:418)"
MAPREDUCE-5560,org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler failing on trunk,"Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 1.406 sec <<< FAILURE! - in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler
testBasic(org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler)  Time elapsed: 0.185 sec  <<< FAILURE!
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:92)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertNotNull(Assert.java:526)
	at org.junit.Assert.assertNotNull(Assert.java:537)
	at org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.testBasic(TestCommitterEventHandler.java:263)"
MAPREDUCE-5558,Scheme for local file is lost when submitting mapreduce job using mapreduce API,"HBase snapshot export adds dependent jars (local files) through ""tmpjars"" config entry.

When debugging HBASE-9687, we found that scheme for local file (file://) is lost by DistributedCache.addFileToClassPath() call in JobSubmitter.

The root cause of this problem is that we are somehow losing ""file://"" from the uri. In the earlier code we were creating new Path object (new Path (newPath.toUri().getPath()) ) where as part of newPath.toUri().getPath() call we are losing the authority and scheme which are passed in.

Thanks to Omkar and Vinod who helped debug this issue"
MAPREDUCE-5556,mapred docs have incorrect classpath,"http://hadoop.apache.org/docs/stable/mapred_tutorial.html

The classpath for javac under the ""Usage"" section is incorrect.
"
MAPREDUCE-5554,hdfs-site.xml included in hadoop-mapreduce-client-jobclient tests jar is breaking tests for downstream components,"The hadoop-mapreduce-client-jobclient tests jar has an hdfs-site.xml in it, so if its in the classpath first, then a downstream component's tests can fail if it needs to use a different hdfs-site.xml as the one in the mapreduce jar gets picked up instead.  We should remove it from the jar."
MAPREDUCE-5553,Add task state filters on Application/MRJob page for MR Application master ,"On Job page of MR application master, the task attempts have a nice breakdown of different state: running, failed.... But for map/reduce task level, there's only one links to all tasks without breakdown for different states:
pending, running, complete, etc.

With Hadoop 1, the similar functionality exists: user can go thru jobtracker-> job-> map/reduce tasks -> attempts.

This ticket will improve the usability to allow user to go job-> total, pending, running, complete Map/Reduce task.

"
MAPREDUCE-5552,org.apache.hadoop.mapred.TestJobCleanup failing on trunk,"Running org.apache.hadoop.mapred.TestJobCleanup
Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 138.031 sec <<< FAILURE! - in org.apache.hadoop.mapred.TestJobCleanup
testDefaultCleanupAndAbort(org.apache.hadoop.mapred.TestJobCleanup)  Time elapsed: 25.522 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapred.TestJobCleanup.testFailedJob(TestJobCleanup.java:199)
	at org.apache.hadoop.mapred.TestJobCleanup.testDefaultCleanupAndAbort(TestJobCleanup.java:275)

testCustomAbort(org.apache.hadoop.mapred.TestJobCleanup)  Time elapsed: 31.755 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapred.TestJobCleanup.testFailedJob(TestJobCleanup.java:199)
	at org.apache.hadoop.mapred.TestJobCleanup.testCustomAbort(TestJobCleanup.java:296)

testCustomCleanup(org.apache.hadoop.mapred.TestJobCleanup)  Time elapsed: 52.086 sec  <<< ERROR!
java.lang.NullPointerException: null
	at org.apache.hadoop.mapred.TestJobCleanup.testFailedJob(TestJobCleanup.java:199)
	at org.apache.hadoop.mapred.TestJobCleanup.testCustomCleanup(TestJobCleanup.java:319)"
MAPREDUCE-5551,Binary Incompatibility of O.A.H.U.mapred.SequenceFileAsBinaryOutputFormat.WritableValueBytes,"The non-default constructor is moved to the super class, but it cannot be inherited."
MAPREDUCE-5550,Task Status message (reporter.setStatus) not shown in UI with Hadoop 2.0,"Hadoop 1.0 JobTracker UI displays task status message when list of mapper or reduce tasks are listed. This give an idea of how that task is making progress.

Hadoop 2.0 AM/JHS UI does not have this. It would be good to have this on AM/JHS UI.
"
MAPREDUCE-5546,mapred.cmd on Windows set HADOOP_OPTS incorrectly,"The mapred command on Windows does not set HADOOP_OPTS correctly. As a result, some options and settings will miss in the final command, and this will lead to some desired behavior missing. One example is the logging file setting will miss, i.e. even if one set HADOOP_ROOT_LOGGER to DRFA, there is no history server log at HADOOP_LOGFILE."
MAPREDUCE-5545,org.apache.hadoop.mapred.TestTaskAttemptListenerImpl.testCommitWindow times out,We've been seeing org.apache.hadoop.mapred.TestTaskAttemptListenerImpl.testCommitWindow time out. We should increase the timeout.
MAPREDUCE-5544,JobClient#getJob loads job conf twice,"Calling JobClient#getJob causes the job conf file to be loaded twice, once in the constructor of JobClient.NetworkedJob and once in Cluster#getJob.  We should remove the former.

MAPREDUCE-5001 was meant to fix a race that was causing problems in Hive tests, but the problem persists because it only fixed one of the places where the job conf file is loaded."
MAPREDUCE-5543,In-memory map outputs can be leaked after shuffle completes in 0.23,"MergeManagerImpl#close adds the contents of inMemoryMergedMapOutputs and inMemoryMapOutputs to a list of map outputs that is subsequently processed, but it does not clear those sets.  This prevents some of the map outputs from being garbage collected and significantly reduces the memory available for the subsequent reduce phase.

This was fixed for trunk and branch-2 by MAPREDUCE-5493, but that has since been closed after 2.1.1 released.  This JIRA tracks backporting the fix to branch-0.23 as well."
MAPREDUCE-5542,Killing a job just as it finishes can generate an NPE in client,If a client tries to kill a job just as the job is finishing then the client can crash with an NPE.
MAPREDUCE-5541,Improved algorithm for whether need speculative task,"Most of time, tasks won't start running at same time.
In this case hasSpeculativeTask in TaskInProgress not working very well.
Some times, some tasks just start running, and scheduler already decide it need speculative task to run.
And this waste a lot of resource."
MAPREDUCE-5538,MRAppMaster#shutDownJob shouldn't send job end notification before checking isLastRetry,
MAPREDUCE-5537,hive return different results with and without index when hive.hadoop.supports.splittable.combineinputformat =true,"the  environment:
hive-0.8.1
hadoop-0.20.2-cdh3u6
the Presentation:
i use the hive-0.8.1 to exec the query:
select count(*) from table t1;

the table t1 is lzo formatted ,and the follows is :
# Storage Information                                                                                                
SerDe Library:                  org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                   
InputFormat:                    com.hadoop.mapred.DeprecatedLzoTextInputFormat                                       
OutputFormat:                   org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat 

and the hive.hadoop.supports.splittable.combineinputformat =true
when i index the table t1,the result is  265329 .
when i remove the index of the t1,the result is  265325."
MAPREDUCE-5536,mapreduce.jobhistory.webapp.https.address property is not respected,"The jobhistory server starts on port defined by mapreduce.jobhistory.webapp.address property instead mapreduce.jobhistory.webapp.https.address when hadoop.ssl.enabled=true.

"
MAPREDUCE-5535,TestClusterMRNotification.testMR is failing,"{code}
testMR(org.apache.hadoop.mapred.TestClusterMRNotification)  Time elapsed: 35.222 sec  <<< FAILURE!
junit.framework.AssertionFailedError: expected:<2> but was:<0>
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.failNotEquals(Assert.java:287)
	at junit.framework.Assert.assertEquals(Assert.java:67)
	at junit.framework.Assert.assertEquals(Assert.java:199)
	at junit.framework.Assert.assertEquals(Assert.java:205)
	at org.apache.hadoop.mapred.NotificationTestCase.testMR(NotificationTestCase.java:163)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)
{code}"
MAPREDUCE-5533,Speculative execution does not function for reduce,We have sort job where reduce attempt does not send heartbeat in timely manner to application master. The AM should kick off another attempt to let job succeeds. What we find is the job fails and there is no speculation happening.
MAPREDUCE-5531,Binary and source incompatibility in mapreduce.TaskID and mapreduce.TaskAttemptID between branch-1 and branch-2,"{{mapreduce.TaskID}} in branch-1 has these two constructors:
{code:java}
public TaskID(JobID jobId, boolean isMap, int id)
public TaskID(String jtIdentifier, int jobId, boolean isMap, int id)
{code}
In branch-2, {{mapreduce.TaskID}} no longer has either of the above two constructors.  

Also, {{mapreduce.TaskAttemptID}} in branch-1 has this constructor:
{code:java}
public TaskAttemptID(String jtIdentifier, int jobId, boolean isMap, int taskId, int id)
{code}
In branch-2, {{mapreduce.TaskAttemptID}} no longer his this constructor.

It looks like these constructors were probably removed because the {{boolean isMap}} was replaced by an enum, {{TaskType}}.

This means that any code that tries to use any of those constructors will not be binary or source compatible (in fact, the missing {{TaskAttemptID}} constructor calls one of the missing {{TaskID}} constructors)."
MAPREDUCE-5530,Binary and source incompatibility in mapred.lib.CombineFileInputFormat between branch-1 and branch-2,"{{mapred.lib.CombineFileInputFormat}} in branch-1 has this method:
{code:java}
protected boolean isSplitable(FileSystem fs, Path file)
{code}

In branch-2, {{mapred.lib.CombineFileInputFormat}} is now a subclass of {{mapreduce.lib.input.CombineFileInputFormat}}, from which it inherits the similar method:
{code:java}
protected boolean isSplitable(JobContext context, Path file)
{code}

This means that any code that subclasses {{mapred.lib.CombineFileInputFormat}} and does not provide its own implementation of {{protected boolean isSplitable(FileSystem fs, Path file)}} will not be binary or source compatible if it tries to call {{isSplitable}} with a {{FileSystem}} argument anywhere (that is, if compiled against branch-1, it will throw a {{NoSuchMethodError}} if run against branch-2; also, it won't even compile against branch-2).  "
MAPREDUCE-5529,Binary incompatibilities in mapred.lib.TotalOrderPartitioner between branch-1 and branch-2,"{{mapred.lib.TotalOrderPartitioner}} in branch-1 has these two methods:
{code:java}
public static String getPartitionFile(JobConf job)
public static void setPartitionFile(JobConf job, Path p)
{code}

In branch-2, {{mapred.lib.TotalOrderPartitioner}} is now a subclass of {{mapred.lib.TotalOrderPartitioner}}, from which it inherits the similar methods:
{code:java}
public static String getPartitionFile(Configuration conf)
public static void setPartitionFile(Configuration conf, Path p)
{code}

This means that any code that does either of the following:
{code:java}
TotalOrderPartitioner.setPartitionFile(new JobConf(), new Path(""/""));
String str = TotalOrderPartitioner.getPartitionFile(new JobConf());
{code}
will not be binary compatible (that is, if compiled against branch-1, it will throw a {{NoSuchMethodError}} if run against branch-2)."
MAPREDUCE-5526,TestMRJobClient fails on Windows and Linux,The unit test fails on both Windows and Linux. I think the failures are due to wrong assertion at several places.
MAPREDUCE-5525,Increase timeout of TestDFSIO.testAppend and TestMRJobsWithHistoryService.testJobHistoryData,"The two test cases consistently fail on Windows due to timeout. The running time of TestDFSIO.testAppend on my Linux box was also close. In the case of TestMRJobsWithHistoryService.testJobHistoryData, it also fails on my Linux due to timeout."
MAPREDUCE-5524,java.io.IOException: Task process exit with nonzero status of   255. how to fix it?,"> Task ......FAILED
> java.lang.Throwable: Child Error
> at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
> Caused by: java.io.IOException: Task process exit with nonzero status of
> 255.
> at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)"
MAPREDUCE-5523,Need to add https port related property in Job history server,related ticket YARN-1204
MAPREDUCE-5522,Incorrectly expect the array of JobQueueInfo returned by o.a.h.mapred.QueueManager#getJobQueueInfos to have a specific order.,"There is a bug in test o.a.h.mapred.TestQueue. The implementation of getJobQueueInfos in QueueManager uses the keySet of a HashMap to populate the return value and since there is no guarantee in the ordering of the elements in the keySet of a Hashmap, this test would fail if the order returned by getJobQueueInfos is different than what the test is expecting."
MAPREDUCE-5518,"Fix typo ""can't read paritions file""","Noticed a spelling error when I saw this error message

{noformat}
13/09/19 13:25:08 INFO mapreduce.Job: Task Id : attempt_1379622083112_0002_m_000114_0, Status : FAILED
Error: java.lang.IllegalArgumentException: can't read paritions file
{noformat}

""paritions"" should be ""partitions"""
MAPREDUCE-5517,enabling uber mode with 0 reducer still requires mapreduce.reduce.memory.mb to be less than yarn.app.mapreduce.am.resource.mb,"Since there is no reducer, the memory allocated to reducer is irrelevant to enable uber mode of a job"
MAPREDUCE-5516,TestMRJobClient fails on trunk,
MAPREDUCE-5515,Application Manager UI does not appear with Https enabled,related issue YARN-1203. We need to disable https for MR-AM by default as they will need access to keystore which can not be granted in the cluster.
MAPREDUCE-5514,TestRMContainerAllocator fails on trunk,
MAPREDUCE-5513,ConcurrentModificationException in JobControl,"JobControl.toList is locking individual lists to iterate them, but those lists can be modified elsewhere without holding the list lock.  The locking approaches are mismatched, with toList holding the lock on the actual list object while other methods hold the JobControl lock when modifying the lists."
MAPREDUCE-5512,TaskTracker hung after failed reconnect to the JobTracker,"TaskTracker hung after failed reconnect to the JobTracker. 

This is the problematic piece of code:
{code}
    this.distributedCacheManager = new TrackerDistributedCacheManager(
        this.fConf, taskController);
    this.distributedCacheManager.startCleanupThread();
    
    this.jobClient = (InterTrackerProtocol) 
    UserGroupInformation.getLoginUser().doAs(
        new PrivilegedExceptionAction<Object>() {
      public Object run() throws IOException {
        return RPC.waitForProxy(InterTrackerProtocol.class,
            InterTrackerProtocol.versionID,
            jobTrackAddr, fConf);
      }
    });
{code}

In case RPC.waitForProxy() throws, TrackerDistributedCacheManager cleanup thread will never be stopped, and given that it is a non daemon thread it will keep TT up forever."
MAPREDUCE-5508,JobTracker memory leak caused by unreleased FileSystem objects in JobInProgress#cleanupJob,"MAPREDUCE-5351 fixed a memory leak problem but introducing another filesystem object (see ""tempDirFs"") that is not properly released.
{code} JobInProgress#cleanupJob()

  void cleanupJob() {
...
          tempDirFs = jobTempDirPath.getFileSystem(conf);
          CleanupQueue.getInstance().addToQueue(
              new PathDeletionContext(jobTempDirPath, conf, userUGI, jobId));
...
 if (tempDirFs != fs) {
      try {
        fs.close();
      } catch (IOException ie) {
...
}
{code}
"
MAPREDUCE-5506,Hadoop-1.1.1 occurs ArrayIndexOutOfBoundsException with MultithreadedMapRunner,"After I set:
- 'jobConf.setMapRunnerClass(MultithreadedMapRunner.class);' in MR app
- 'mapred.map.multithreadedrunner.threads = 2' in mapred-site.xml

A simple MR app failed as its Map task encountered ArrayIndexOutOfBoundsException as below(please ignore the line numbers in the exception as I added some log print codes):
java.lang.ArrayIndexOutOfBoundsException
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$Buffer.write(MapTask.java:1331)
        at java.io.DataOutputStream.write(DataOutputStream.java:101)
        at org.apache.hadoop.io.Text.write(Text.java:282)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:90)
        at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.serialize(WritableSerialization.java:77)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1060)
        at org.apache.hadoop.mapred.MapTask$OldOutputCollector.collect(MapTask.java:591)
        at study.hadoop.mapreduce.sample.WordCount$Map.map(WordCount.java:41)
        at study.hadoop.mapreduce.sample.WordCount$Map.map(WordCount.java:1)
        at org.apache.hadoop.mapred.lib.MultithreadedMapRunner$MapperInvokeRunable.run(MultithreadedMapRunner.java:231)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:897)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:919)
        at java.lang.Thread.run(Thread.java:738)


And the exception happens on line 'System.arraycopy(b, off, kvbuffer, bufindex, len)' in MapTask.java#MapOutputBuffer#Buffer#write(). When the exception occurs, 'b.length=4' but 'len=9'. 

Btw, if I set 'mapred.map.multithreadedrunner.threads = 1', no exception happened. So it should be an issue caused by multiple threads.
"
MAPREDUCE-5505,Clients should be notified job finished only after job successfully unregistered ,This is to make sure user is notified job finished after job is really done. This does increase client latency but can reduce some races during unregister like YARN-540
MAPREDUCE-5504,mapred queue -info inconsistent with types,"$ mapred queue -info default
======================
Queue Name : default
Queue State : running
Scheduling Info : Capacity: 4.0, MaximumCapacity: 0.67, CurrentCapacity: 0.9309831


The capacity is displayed in % as 4, however maximum capacity is displayed as an absolute number 0.67 instead of 67%.

We should make these consistent with the type we are displaying"
MAPREDUCE-5503,TestMRJobClient.testJobClient is failing,"TestMRJobClient.testJobClient is failing on trunk and causing precommit builds to complain:

{noformat}
testJobClient(org.apache.hadoop.mapreduce.TestMRJobClient)  Time elapsed: 26.361 sec  <<< FAILURE!
junit.framework.AssertionFailedError: expected:<1> but was:<0>
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.failNotEquals(Assert.java:287)
	at junit.framework.Assert.assertEquals(Assert.java:67)
	at junit.framework.Assert.assertEquals(Assert.java:199)
	at junit.framework.Assert.assertEquals(Assert.java:205)
	at org.apache.hadoop.mapreduce.TestMRJobClient.testJobList(TestMRJobClient.java:474)
	at org.apache.hadoop.mapreduce.TestMRJobClient.testJobClient(TestMRJobClient.java:112)
{noformat}"
MAPREDUCE-5501,RMContainer Allocator does not stop when cluster shutdown is performed in tests,"After running MR job client tests many MRAppMaster processes stay alive. The reason seems that RMContainer Allocator thread ignores InterruptedException and keeps retrying:

{code}
2013-09-09 18:52:07,505 WARN [RMCommunicator Allocator] org.apache.hadoop.util.ThreadUtil: interrupted while sleeping
java.lang.InterruptedException: sleep interrupted
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.ThreadUtil.sleepAtLeastIgnoreInterrupts(ThreadUtil.java:43)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:149)
        at com.sun.proxy.$Proxy29.allocate(Unknown Source)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.makeRemoteRequest(RMContainerRequestor.java:154)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:553)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:219)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:236)
        at java.lang.Thread.run(Thread.java:680)
2013-09-09 18:52:37,639 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: dhcpx-197-141.corp.yahoo.com/10.73.197.141:61163. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
2013-09-09 18:52:38,640 INFO [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: dhcpx-197-141.corp.yahoo.com/10.73.197.141:61163. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1 SECONDS)
{code}

It takes > 6 minutes for the processes to die, and this causes various issues with tests which use the same DFS dir. 

{code}
2013-09-09 22:26:47,179 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Could not contact RM after 360000 milliseconds.
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Could not contact RM after 360000 milliseconds.
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:563)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:219)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:236)
        at java.lang.Thread.run(Thread.java:680)
{code}

Will attach a thread dump separately. "
MAPREDUCE-5500,Accessing task page for running job throw 500 Error code,"For running jobs on Hadoop 2.0, trying to access Task counters page throws Server 500 error. Digging a bit I see this exception in MRAppMaster logs

{noformat}

2013-08-09 21:54:35,083 ERROR [556661283@qtp-875702288-23] org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /mapreduce/task/task_1376081364308_0002_m_000001
java.lang.reflect.InvocationTargetException
     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
     at java.lang.reflect.Method.invoke(Method.java:606)
     at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:150)
     at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
     at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)
     at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)
     at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
     at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
     at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
     at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
     at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
     at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
     at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:123)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1069)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
     at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
     at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
     at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
     at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
     at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
     at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
     at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
     at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
     at org.mortbay.jetty.Server.handle(Server.java:326)
     at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
     at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
     at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
     at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
     at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
     at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
     at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: org.apache.hadoop.yarn.webapp.WebAppException: Error rendering block: nestLevel=6 expected 5
     at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:66)
     at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
     at org.apache.hadoop.yarn.webapp.View.render(View.java:233)
     at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
     at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
     at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
     at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
     at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:80)
     at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:210)
     at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.task(AppController.java:256)
     ... 39 more
2013-08-09 21:54:36,660 INFO [IPC Server handler 4 on 51776] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1376081364308_0002_m_000000_0
2013-08-09 21:54:36,661 INFO [IPC Server handler 4 on 51776] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1376081364308_0002_m_000000_0 is : 0.21281

{noformat}

This looks to be critical bug because unable to access counters will be major setback for users to be able to debug running jobs.

Note that same job counters work fine if we access it from JobHistoryServer"
MAPREDUCE-5498,maven Junit dependency should be test only,"The maven dependencies for the YARN artifacts don't restrict to test time, so it gets picked up by all downstream users."
MAPREDUCE-5497,'5s sleep'  in MRAppMaster.shutDownJob is only needed before stopping ClientService,"Since the '5s sleep' is for the purpose to let clients know the final states, put it after other services are stopped and only before stopping ClientService is enough. This can reduce some race conditions like MAPREDUCE-5471"
MAPREDUCE-5493,In-memory map outputs can be leaked after shuffle completes,"MergeManagerImpl#close adds the contents of inMemoryMergedMapOutputs and inMemoryMapOutputs to a list of map outputs that is subsequently processed, but it does not clear those sets.  This prevents some of the map outputs from being garbage collected and significantly reduces the memory available for the subsequent reduce phase."
MAPREDUCE-5492,Suppress expected log output stated on MAPREDUCE-5,"Jetty in MR1 may produce an expected EOFException during its operation that we shouldn't log out in ERROR form.

This shouldn't affect MR2, however, as it uses Netty.

See MAPREDUCE-5 (Jothi's comments) for more info."
MAPREDUCE-5490,MapReduce doesn't set the environment variable for children processes,"Currently, MapReduce uses the command line argument to pass the classpath to the child. This breaks if the process forks a child that needs the same classpath. Such a case happens in Hive when it uses map-side joins. I propose that we make MapReduce in branch-1 use the CLASSPATH environment variable like YARN does."
MAPREDUCE-5489,MR jobs hangs as it does not use the node-blacklisting feature in RM requests,"When RM restarted, if during restart one NM went bad (bad disk), NM got blacklisted by AM and RM keeps giving the containers on the same node even though AM doesn't want it there.

Need to change AM to specifically blacklist node in the RM requests.
"
MAPREDUCE-5488,Job recovery fails after killing all the running containers for the app,"Here is the client stack trace

{code}
RUNNING: /usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples-2.1.0.2.0.5.0-66.jar wordcount ""-Dmapreduce.reduce.input.limit=-1"" /user/user/test_yarn_ha/medium_wordcount_input /user/hrt_qa/test_yarn_ha/test_mapred_ha_single_job_applicationmaster-1-time
13/08/30 08:45:39 INFO client.RMProxy: Connecting to ResourceManager at hostname/68.142.247.148:8032
13/08/30 08:45:40 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 19 for user on ha-hdfs:ha-2-secure
13/08/30 08:45:40 INFO security.TokenCache: Got dt for hdfs://ha-2-secure; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ha-2-secure, Ident: (HDFS_DELEGATION_TOKEN token 19 for user)
13/08/30 08:45:40 INFO input.FileInputFormat: Total input paths to process : 20
13/08/30 08:45:40 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library
13/08/30 08:45:40 INFO lzo.LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev cf4e7cbf8ed0f0622504d008101c2729dc0c9ff3]
13/08/30 08:45:40 INFO mapreduce.JobSubmitter: number of splits:180
13/08/30 08:45:40 WARN conf.Configuration: user.name is deprecated. Instead, use mapreduce.job.user.name
13/08/30 08:45:40 WARN conf.Configuration: mapred.jar is deprecated. Instead, use mapreduce.job.jar
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.combine.class is deprecated. Instead, use mapreduce.job.combine.class
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.map.class is deprecated. Instead, use mapreduce.job.map.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.job.name is deprecated. Instead, use mapreduce.job.name
13/08/30 08:45:40 WARN conf.Configuration: mapreduce.reduce.class is deprecated. Instead, use mapreduce.job.reduce.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
13/08/30 08:45:40 WARN conf.Configuration: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
13/08/30 08:45:40 WARN conf.Configuration: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
13/08/30 08:45:40 WARN conf.Configuration: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
13/08/30 08:45:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1377851032086_0003
13/08/30 08:45:41 INFO mapreduce.JobSubmitter: Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:ha-2-secure, Ident: (HDFS_DELEGATION_TOKEN token 19 for user)
13/08/30 08:45:42 INFO impl.YarnClientImpl: Submitted application application_1377851032086_0003 to ResourceManager at hostname/68.142.247.148:8032
13/08/30 08:45:42 INFO mapreduce.Job: The url to track the job: http://hostname:8088/proxy/application_1377851032086_0003/
13/08/30 08:45:42 INFO mapreduce.Job: Running job: job_1377851032086_0003
13/08/30 08:45:48 INFO mapreduce.Job: Job job_1377851032086_0003 running in uber mode : false
13/08/30 08:45:48 INFO mapreduce.Job:  map 0% reduce 0%
stop applicationmaster
beaver.component.hadoop|INFO|Kill container container_1377851032086_0003_01_000001 on host hostname
RUNNING: ssh -o StrictHostKeyChecking=no hostname ""sudo su - -c \""ps aux | grep container_1377851032086_0003_01_000001 | awk '{print \\\$2}' | xargs kill -9\"" root""
Warning: Permanently added 'hostname,68.142.247.155' (RSA) to the list of known hosts.
kill 8978: No such process
waiting for down time 10 seconds for service applicationmaster
13/08/30 08:45:55 INFO ipc.Client: Retrying connect to server: hostname/68.142.247.155:52713. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1 SECONDS)
13/08/30 08:45:56 INFO ipc.Client: Retrying connect to server: hostname/68.142.247.155:52713. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=1, sleepTime=1 SECONDS)
13/08/30 08:45:56 ERROR security.UserGroupInformation: PriviledgedActionException as:user@REALM (auth:KERBEROS) cause:java.io.IOException: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
java.io.IOException: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:319)
at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:354)
at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:529)
at org.apache.hadoop.mapreduce.Job$5.run(Job.java:668)
at org.apache.hadoop.mapreduce.Job$5.run(Job.java:665)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:665)
at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1349)
at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1289)
at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
at org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)
at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.util.RunJar.main(RunJar.java:212)
Caused by: java.net.ConnectException: Call From hostname.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
at org.apache.hadoop.ipc.Client.call(Client.java:1351)
at org.apache.hadoop.ipc.Client.call(Client.java:1300)
at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
at $Proxy14.getTaskAttemptCompletionEvents(Unknown Source)
at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:177)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:310)
... 23 more
Caused by: java.net.ConnectException: Connection refused
at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:547)
at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:642)
at org.apache.hadoop.ipc.Client$Connection.access$2600(Client.java:314)
at org.apache.hadoop.ipc.Client.getConnection(Client.java:1399)
at org.apache.hadoop.ipc.Client.call(Client.java:1318)
... 32 more
{code}"
MAPREDUCE-5487,"In task processes, JobConf is unnecessarily loaded again in Limits","Limits statically loads a JobConf, which incurs costs of reading files from disk and parsing XML.  The contents of this JobConf are identical to the one loaded by YarnChild (before adding job.xml as a resource).  Allowing Limits to initialize with the JobConf loaded in YarnChild would reduce task startup time."
MAPREDUCE-5485,Allow repeating job commit by extending OutputCommitter API,"There are chances MRAppMaster crush during job committing,or NodeManager restart cause the committing AM exit due to container expire.In these cases ,the job will fail.
However,some jobs can redo commit so failing the job becomes unnecessary.
Let clients tell AM to allow redo commit or not is a better choice.
This idea comes from Jason Lowe's comments in MAPREDUCE-4819 
"
MAPREDUCE-5484,YarnChild unnecessarily loads job conf twice,"In MR task processes, a JobConf is instantiated with the same job.xml twice, once at the beginning of main() and once in configureTask.  IIUC, the second instantiation is not necessary.  These take time reading from disk and parsing XML.

Removing the second instantiation shaved a second off the average map task time in a 1,000-map sleep job."
MAPREDUCE-5483,revert MAPREDUCE-5357,"MAPREDUCE-5357 does a fileystem chown() operation. chown() is not valid unless you are superuser. if you a chown() to yourself is a NOP, that is why has not been detected in Hadoop testcases where user is running as itself. However, in distcp testcases run by Oozie which use test users/groups from UGI for minicluster it is failing because of this chown() either because the test user does not exist of because the current use does not have privileges to do a chown().

We should revert MAPREDUCE-5357. Windows should handle this with some conditional logic used only when running in Windows.

Opening a new JIRA and not reverting directly because MAPREDUCE-5357 went in 2.1.0-beta."
MAPREDUCE-5481,Enable uber jobs to have multiple reducers ,"TestUberAM has been timing out on trunk for some time now and surefire then fails the build.  I'm not able to reproduce it locally, but the Jenkins builds have been seeing it fairly consistently.  See https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1529/console

This is caused by changes made in MAPREDUCE-434 breaking Uber AMs.  The easiest fix is to make similar changes in Uber AMs to those in MAPREDUCE-434 to allow multiple reducers."
MAPREDUCE-5480,TestJSHSecurity.testDelegationToken is breaking after YARN-1085,"See https://builds.apache.org/job/PreCommit-YARN-Build/1755//testReport/.

{code}
org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:251)
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.initializeWebApp(HistoryClientService.java:152)
 ---
Caused by: javax.servlet.ServletException: javax.servlet.ServletException: Principal not defined in configuration
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:203)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:146)
 ---
Caused by: javax.servlet.ServletException: Principal not defined in configuration
	at org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:164)
	... 53 more
{code}"
MAPREDUCE-5478,TeraInputFormat unnecessarily defines its own FileSplit subclass,"TeraInputFormat defines its own TeraFileSplit subclass of FileSplit that adds a locations field, which is already included in FileSplit.

This is causing MR2 TeraSort to fail on MR1, which, for a System.arraycopy, requires splits to be of the FileSplit class.  While nobody is promising that everything that runs on MR2 should run on MR1, fixing this would be easy and make it possible to compare MR2 TeraSort performance between MR1 and MR2.

We should just get rid of TeraFileSplit and use FileSplit."
MAPREDUCE-5476,Job can fail when RM restarts after staging dir is cleaned but before MR successfully unregister with RM,
MAPREDUCE-5475,MRClientService does not verify ACLs properly,"When MRClientService receives requests, it calls verifyAndGetJob which does not actually validate that the current user has the proper access."
MAPREDUCE-5472,reducer of sort job restarts from scratch in between after RM restart,"Steps Followed:
1) Run a sort job. As soon as it finishes all the map tasks. [100% map], restart resource manager.

2) Analyse the progress of the sort job.
It starts with 100% map 0% reduce
100% map 32% reduce
100% map 0% reduce
Reducer stays at 30% reduce for around 5-10 minutes. and again start reducer from scratch.

Log from failed reducer attempt:

Error: java.io.IOException: Error while reading compressed data at org.apache.hadoop.io.IOUtils.wrappedReadForCompressedData(IOUtils.java:174) at org.apache.hadoop.mapred.IFile$Reader.readData(IFile.java:383) at org.apache.hadoop.mapred.IFile$Reader.nextRawValue(IFile.java:444) at org.apache.hadoop.mapred.Merger$Segment.nextRawValue(Merger.java:327) at org.apache.hadoop.mapred.Merger$Segment.getValue(Merger.java:309) at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:533) at org.apache.hadoop.mapred.ReduceTask$4.next(ReduceTask.java:619) at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:154) at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121) at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:297) at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170) at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:645) at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:405) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:162) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:157) Caused by: org.apache.hadoop.fs.FSError: java.io.IOException: Input/output error at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.read(RawLocalFileSystem.java:177) at java.io.BufferedInputStream.read1(BufferedInputStream.java:256) at java.io.BufferedInputStream.read(BufferedInputStream.java:317) at java.io.DataInputStream.read(DataInputStream.java:132) at org.apache.hadoop.mapred.IFileInputStream.doRead(IFileInputStream.java:209) at org.apache.hadoop.mapred.IFileInputStream.read(IFileInputStream.java:152) at org.apache.hadoop.io.compress.BlockDecompressorStream.getCompressedData(BlockDecompressorStream.java:127) at org.apache.hadoop.io.compress.BlockDecompressorStream.decompress(BlockDecompressorStream.java:98) at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:85) at org.apache.hadoop.io.IOUtils.wrappedReadForCompressedData(IOUtils.java:170) ... 17 more Caused by: java.io.IOException: Input/output error at java.io.FileInputStream.readBytes(Native Method) at java.io.FileInputStream.read(FileInputStream.java:220) at org.apache.hadoop.fs.RawLocalFileSystem$TrackingFileInputStream.read(RawLocalFileSystem.java:110) at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.read(RawLocalFileSystem.java:171) ... 26 more
"
MAPREDUCE-5471,Succeed job tries to restart after RMrestart,"Run a job , restart RM when job just finished. It should not restart the job once it Succeed.

After RM restart, The AM of restarted job fails with below error.

AM log after Rmrestart:

013-08-19 17:29:21,144 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is 0
2013-08-19 17:29:21,145 INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
2013-08-19 17:29:21,146 INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://host1:port1/user/ABC/.staging/job_1376933101704_0001
2013-08-19 17:29:21,156 FATAL [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Error starting MRAppMaster
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.io.FileNotFoundException: File does not exist: hdfs://host1:port1/ABC/.staging/job_1376933101704_0001/job.splitmetainfo
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createSplits(JobImpl.java:1469)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1324)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.transition(JobImpl.java:1291)
        at org.apache.hadoop.yarn.state.StateMachineFactory$MultipleInternalArc.doTransition(StateMachineFactory.java:385)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:46)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:448)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:922)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:131)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1184)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:995)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1394)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1390)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1323)
Caused by: java.io.FileNotFoundException: File does not exist: hdfs://host1:port1/ABC/.staging/job_1376933101704_0001/job.splitmetainfo
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1121)
        at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1113)
        at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:78)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1113)
        at org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:51)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InitTransition.createSplits(JobImpl.java:1464)
        ... 17 more
2013-08-19 17:29:21,158 INFO [Thread-2] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster received a signal. Signaling RMCommunicator and JobHistoryEventHandler.
2013-08-19 17:29:21,159 WARN [Thread-2] org.apache.hadoop.util.ShutdownHookManager: ShutdownHook 'MRAppMasterShutdownHook' failed, java.lang.NullPointerException
java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.setSignalled(MRAppMaster.java:805)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1344)
        at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
"
MAPREDUCE-5470,LocalJobRunner does not work on Windows.,"{{LocalJobRunner#getLocalTaskDir}} creates a directory that is unique to the task ID.  The logic of this method concatenates the local job dir and a task-specific path, but one of the arguments is a {{Path}} with a scheme, so the final result has ""file:"" embedded in it.  This works on Linux, but the ':' is an invalid character in a file name on Windows."
MAPREDUCE-5469,Counters for MRAppMaster,"We have counters for map tasks and reduce tasks ,but has no counters for MRAppMaster.
Sometimes we need information like GC time,memory usage for AM tuning."
MAPREDUCE-5468,AM recovery does not work for map only jobs,"Map only job (randomwriter, randomtextwriter) restarts from scratch [0% map 0% reduce] after RM restart.
It should resume from the last state when AM restarted."
MAPREDUCE-5466,Historyserver does not refresh the result of restarted jobs after RM restart,"Restart RM when sort job is running and verify that the job passes successfully after RM restarts. 

Once the job finishes successfully, run job status command for sort job. It shows ""Job state =FAILED"". Job history server does not update the result for the job which restarted after RM restart.

hadoop job -status job_1375923346354_0003
13/08/08 01:24:13 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server

Job: job_1375923346354_0003
Job File: hdfs://host1:port1/history/done/2013/08/08/000000/job_1375923346354_0003_conf.xml
Job Tracking URL : http://historyserver:port2/jobhistory/job/job_1375923346354_0003
Uber job : false
Number of maps: 80
Number of reduces: 1
map() completion: 0.0
reduce() completion: 0.0
Job state: FAILED
retired: false
reason for failure: There are no failed tasks for the job. Job is failed due to some other reason and reason can be found in the logs.
Counters not available. Job is retired."
MAPREDUCE-5465,Tasks are often killed before they exit on their own,"If there is profiling enabled for mapper or reducer then hprof dumps profile.out at process exit. It is dumped after task signaled to AM that work is finished.

AM kills container with finished work without waiting for hprof to finish dumps. If hprof is dumping larger outputs (such as with depth=4 while depth=3 works) , it could not finish dump in time before being killed making entire dump unusable because cpu and heap stats are missing.

There needs to be better delay before container is killed if profiling is enabled."
MAPREDUCE-5464,Add analogs of the SLOTS_MILLIS counters that jive with the YARN resource model,"Per discussion on MAPREDUCE-5311, it would be good to have analogs for SLOTS_MILLIS that better fit the MR2 resource model.
"
MAPREDUCE-5463,Deprecate SLOTS_MILLIS counters,"As discussed in MAPREDUCE-5311, the SLOTS_MILLIS_MAPS and SLOTS_MILLIS_REDUCES counters don't really make sense in MR2, and should be deprecated so that they can eventually be removed."
MAPREDUCE-5462,"In map-side sort, swap entire meta entries instead of indexes for better cache performance ",
MAPREDUCE-5459,Update the doc of running MRv1 examples jar on YARN,"In addition to adding two env vars: HADOOP_USER_CLASSPATH_FIRST and HADOOP_CLASSPATH, we still need to add
{code}
    <property>
        <name>mapreduce.job.user.classpath.first</name>
        <value>true</value>
    </property>
{code}
in mapred-site.xml to make sure that the MRv1 examples jar runs correctly on YARN. Some examples will use Java reflection to find the classes in the examples jar dynamically when they are running. With this configuration, the MRv1 examples jar will appear before the MRv2 examples jar in CLASSPATH of the processes in YARN containers. Therefore, the classes found via reflection will be picked from MRv1 examples jar instead of MRv2 examples jar as well.

MapReduce_Compatibility_Hadoop1_Hadoop2.apt.vm needs to be updated to document this."
MAPREDUCE-5458,Jobhistory server (and probably others) throws HTTP 500 error if keytab fails,"I had a situation where the job history didn't renew its kerberos credentials (still verifying that problem).  If a user connects to the web UI at a point when the server can't talk to HDFS, it shows the user a 500 error rather than giving something meaningful."
MAPREDUCE-5457,Add a KeyOnlyTextOutputReader to enable streaming to write out text files without separators,"MR jobs sometimes want to just output lines of text, not key/value pairs.  TextOutputFormat handles this by, if a null value is given, outputting only the key with no separator.  Streaming jobs are unable to take advantage of this, because they can't output null values.  A text output format reader takes each line as a key and outputs NullWritables for values would allow streaming jobs to output lines of text. 

"
MAPREDUCE-5456,TestFetcher.testCopyFromHostExtraBytes is missing,"I noticed that the test to verify the fix from MAPREDUCE-5308 was deleted by MAPREDUCE-5194.  It looks like an accidental deletion from an upmerge.  
We should reinstate this unit test."
MAPREDUCE-5454,TestDFSIO fails intermittently on JDK7,TestDFSIO occasionally fails on JDK7
MAPREDUCE-5451,MR uses LD_LIBRARY_PATH which doesn't mean anything in Windows,"In order to set the path for loading native libraries, MR relies on the default value of the mapreduce.admin.user.env configuration setting the LD_LIBRARY_PATH environment entry. There are two problems with this setting in Windows:
a) LD_LIBRARY_PATH doesn't mean anything in Windows.
b) It sets it using $HADOOP_COMMON_HOME, instead of %HADOOP_COMMON_HOME%.

The default value here should be platform-dependent (use the PATH variable in Windows instead of LD_LIBRARY_PATH), or we should rely on another mechanism. The net effect is that in Windows unless this configuration is over-ridden MR jobs fail with this error:

{code}
2013-05-29 13:51:41,049 FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:393)
	at org.apache.hadoop.fs.FileUtil.canRead(FileUtil.java:928)
	at org.apache.hadoop.util.DiskChecker.checkAccessByFileMethods(DiskChecker.java:177)
	at org.apache.hadoop.util.DiskChecker.checkDirAccess(DiskChecker.java:164)
	at org.apache.hadoop.util.DiskChecker.checkDir(DiskChecker.java:98)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(LocalDirAllocator.java:288)
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:431)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:164)
	at org.apache.hadoop.mapred.YarnChild.configureLocalDirs(YarnChild.java:235)
	at org.apache.hadoop.mapred.YarnChild.configureTask(YarnChild.java:294)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)
{code}"
MAPREDUCE-5450,Unnecessary Configuration instantiation in IFileInputStream slows down merge - Port to branch-1,"We are using hadoop-2.0.0+1357-1.cdh4.3.0.p0.21 with MRv1. After upgrade from 4.1.2 to 4.3.0, I have noticed some performance deterioration in our MR job in the Reduce phase. The MR job has usually 10 000 map tasks (10 000 files on input each about 100MB) and 6 000 reducers (one reducer per table region). I was trying to figure out what at which phase the slow down appears (firstly I suspected that the slow gathering of the 10000 map output files is the culprit) and found out that the problem is not reading the map output (the shuffle) but the sort/merge phase that follows - the last and actual reduce phase is fast. I have tried to up the io.sort.factor because I thought the lots of small files are being merged on disk, but again upping that to 1000 didnt do any difference. I have then printed the stack trace and found out that the problem is initialization of the org.apache.hadoop.mapred.IFileInputStream namely the creation of the Configuration object which is not propagated along from earlier context, see the stack trace: 

Thread 13332: (state = IN_NATIVE)
 - java.io.UnixFileSystem.getBooleanAttributes0(java.io.File) @bci=0 (Compiled frame; information may be imprecise)
 - java.io.UnixFileSystem.getBooleanAttributes(java.io.File) @bci=2, line=228 (Compiled frame)
 - java.io.File.exists() @bci=20, line=733 (Compiled frame)
 - sun.misc.URLClassPath$FileLoader.getResource(java.lang.String, boolean) @bci=136, line=999 (Compiled frame)
 - sun.misc.URLClassPath$FileLoader.findResource(java.lang.String, boolean) @bci=3, line=966 (Compiled frame)
 - sun.misc.URLClassPath.findResource(java.lang.String, boolean) @bci=17, line=146 (Compiled frame)
 - java.net.URLClassLoader$2.run() @bci=12, line=385 (Compiled frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedAction, java.security.AccessControlContext) @bci=0 (Compiled frame)
 - java.net.URLClassLoader.findResource(java.lang.String) @bci=13, line=382 (Compiled frame)
 - java.lang.ClassLoader.getResource(java.lang.String) @bci=30, line=1002 (Compiled frame)
 - java.lang.ClassLoader.getResourceAsStream(java.lang.String) @bci=2, line=1192 (Compiled frame)
 - javax.xml.parsers.SecuritySupport$4.run() @bci=26, line=96 (Compiled frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedAction) @bci=0 (Compiled frame)
 - javax.xml.parsers.SecuritySupport.getResourceAsStream(java.lang.ClassLoader, java.lang.String) @bci=10, line=89 (Compiled frame)
 - javax.xml.parsers.FactoryFinder.findJarServiceProvider(java.lang.String) @bci=38, line=250 (Interpreted frame)
 - javax.xml.parsers.FactoryFinder.find(java.lang.String, java.lang.String) @bci=273, line=223 (Interpreted frame)
 - javax.xml.parsers.DocumentBuilderFactory.newInstance() @bci=4, line=123 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.loadResource(java.util.Properties, org.apache.hadoop.conf.Configuration$Resource, boolean) @bci=16, line=1890 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.loadResources(java.util.Properties, java.util.ArrayList, boolean) @bci=49, line=1867 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getProps() @bci=43, line=1785 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.get(java.lang.String) @bci=35, line=712 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getTrimmed(java.lang.String) @bci=2, line=731 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getBoolean(java.lang.String, boolean) @bci=2, line=1047 (Interpreted frame)
 - org.apache.hadoop.mapred.IFileInputStream.<init>(java.io.InputStream, long, org.apache.hadoop.conf.Configuration) @bci=111, line=93 (Interpreted frame)
 - org.apache.hadoop.mapred.IFile$Reader.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FSDataInputStream, long, org.apache.hadoop.io.compress.CompressionCodec, org.apache.hadoop.mapred.Counters$Counter) @bci=60, line=303 (Interpreted frame)
 - org.apache.hadoop.mapred.IFile$InMemoryReader.<init>(org.apache.hadoop.mapred.RamManager, org.apache.hadoop.mapred.TaskAttemptID, byte[], int, int) @bci=11, line=480 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier.createInMemorySegments(java.util.List, long) @bci=133, line=2416 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier.createKVIterator() @bci=669, line=2530 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask.run(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.TaskUmbilicalProtocol) @bci=513, line=425 (Interpreted frame)
 - org.apache.hadoop.mapred.Child$4.run() @bci=29, line=268 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Interpreted frame)
 - javax.security.auth.Subject.doAs(javax.security.auth.Subject, java.security.PrivilegedExceptionAction) @bci=42, line=396 (Interpreted frame)
 - org.apache.hadoop.security.UserGroupInformation.doAs(java.security.PrivilegedExceptionAction) @bci=14, line=1408 (Interpreted frame)
 - org.apache.hadoop.mapred.Child.main(java.lang.String[]) @bci=776, line=262 (Interpreted frame)


A blank configuration object is created at IFileInputStream. I have made a test and found out that this operation costs about 10-15ms depending on the load on the system, because it goes to the local FS to load the properties!!! This is to my opinion a bug since in the context the configuration (of the job) is known and could be reused at that point. My problem (and every others who has big number of reducer and mapper tasks) is that for 10K map taks it does 10000 x 15 = 150 seconds just to find out that there is nothing to sort. The overhead should be normally zero. 

At this moment, the 10-15ms problem is amplified by 6 000 reducers so the bottom line is that my reduce phase is at least 1.6 hours longer than it should be."
MAPREDUCE-5448,MapFileOutputFormat#getReaders bug with invisible files/folders,"MapReduce jobs also produce some invisible files such as _SUCCESS, even when the output format is MapFileOutputFormat. MapFileOutputFormat#getReaders however reads the entire content of the job output, assming that they are MapFiles.
{code}
Path[] names = FileUtil.stat2Paths(fs.listStatus(dir));
{code}
It should use a filter to skip the files that start with ""."" or ""_"".
"
MAPREDUCE-5447,"When a job state is ERROR , total map and reduce task are displayed as 0 in JHS home page , while navigating inside the respective job page displays the correct total. ","When a job state is in error , total map and reduce task are displayed as 0 in JHS home page , while navigating inside the respective job page displays the correct total.

JHS Homepage:
============
Total Map and Reduce Task are 0

Job Page:
=========
Total Map task    -2
Total Reduce task -1

successful Map Attempts -2"
MAPREDUCE-5446,TestJobHistoryEvents and TestJobHistoryParsing have race conditions,"TestJobHistoryEvents and TestJobHistoryParsing are not properly waiting for MRApp to finish.  Currently they are polling the service state looking for Service.STATE.STOPPED, but the service can appear to be in that state *before* it is fully stopped.  This causes tests to finish with MRApp threads still in-flight, and those threads can conflict with subsequent tests when they collide in the filesystem.
"
MAPREDUCE-5444,MRAppMaster throws InvalidStateTransitonException: Invalid event: JOB_AM_REBOOT at SUCCEEDED,"{noformat}
2013-08-02 14:55:11,537 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Calling handler for JobFinishedEvent 
2013-08-02 14:55:11,538 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1375199817609_0049Job Transitioned from COMMITTING to SUCCEEDED
2013-08-02 14:55:11,663 INFO [Thread-52] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://0.0.0.0:45000/home/restest/staging-dir/restest/.staging/job_1375199817609_0049/job_1375199817609_0049_2.jhist to hdfs://0.0.0.0:45000/home/restest/staging-dir/history/done_intermediate/restest/job_1375199817609_0049-1375435337429-restest-word+count-1375435511533-10-1-SUCCEEDED-a.jhist_tmp
2013-08-02 14:55:11,750 INFO [Thread-52] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://0.0.0.0:45000/home/restest/staging-dir/history/done_intermediate/restest/job_1375199817609_0049-1375435337429-restest-word+count-1375435511533-10-1-SUCCEEDED-a.jhist_tmp
2013-08-02 14:55:11,769 INFO [Thread-52] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying hdfs://0.0.0.0:45000/home/restest/staging-dir/restest/.staging/job_1375199817609_0049/job_1375199817609_0049_2_conf.xml to hdfs://0.0.0.0:45000/home/restest/staging-dir/history/done_intermediate/restest/job_1375199817609_0049_conf.xml_tmp
2013-08-02 14:55:11,880 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 AssignedReds:1 CompletedMaps:10 CompletedReds:1 ContAlloc:1 ContRel:0 HostLocal:0 RackLocal:0
2013-08-02 14:55:13,649 ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Resource Manager doesn't recognize AttemptId: application_1375199817609_0049
org.apache.hadoop.yarn.YarnException: Resource Manager doesn't recognize AttemptId: application_1375199817609_0049
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.getResources(RMContainerAllocator.java:626)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:238)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:250)
	at java.lang.Thread.run(Thread.java:662)
2013-08-02 14:55:13,649 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_AM_REBOOT at SUCCEEDED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:914)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:129)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1114)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1110)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)
	at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.realDispatch(RecoveryService.java:309)
	at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:305)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
	at java.lang.Thread.run(Thread.java:662)
2013-08-02 14:55:13,652 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: JobHistoryEvent is triggered from JobImpl
2013-08-02 14:55:13,652 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1375199817609_0049Job Transitioned from SUCCEEDED to ERROR
{noformat}"
MAPREDUCE-5443,ClientId should have getMsb/getLsb methods,Both ClientId and RetryCache have the same logic to calculate msb and lsb. We should not have same logics in separate classes but have utility methods to do so in one class.
MAPREDUCE-5442,$HADOOP_MAPRED_HOME/$HADOOP_CONF_DIR setting not working on Windows,"Currently the mapred-default.xml has ""mapreduce.application.classpath"" entry set to
$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/
which is problematic on Windows since the path does not work on Windows OS.

Additionally, the yarn-default.xml has ""yarn.application.classpath"" entry that has similar problem, and is currently being tracked by YARN-1138"
MAPREDUCE-5441,JobClient exit whenever RM issue Reboot command to 1st attempt App Master.,"When RM issue Reboot command to app master, app master shutdown gracefully. All the history event are writtent to hdfs with job status set as ERROR. Jobclient get job state as ERROR and exit. 

But RM launches 2nd attempt app master where no client are there to get job status.In RM UI, job status is displayed as SUCCESS but for client Job is Failed.
"
MAPREDUCE-5440,TestCopyCommitter Fails on JDK7,The testNoCommitAction is affected by the testPreserveStatus.  The testPreserveStatus leaves the CONF_LABEL_PRESERVE_STATUS set.
MAPREDUCE-5438,JavaDoc generates partially for MultithreadedMapRunner,"The following code in MultithreadedMapRunner.java does not get published to the HTML docs correctly.

This is what actually appears in the HTML docs:
""It can be used instead of the default implementation, ""

This is what *should* appear:
/**
 * Multithreaded implementation for @link org.apache.hadoop.mapred.MapRunnable.
 * <p>
 * It can be used instead of the default implementation,
 * @link org.apache.hadoop.mapred.MapRunner, when the Map operation is not CPU
 * bound in order to improve throughput.
 * <p>
 * Map implementations using this MapRunnable must be thread-safe.
 * <p>
 * The Map-Reduce job has to be configured to use this MapRunnable class (using
 * the JobConf.setMapRunnerClass method) and
 * the number of thread the thread-pool can use with the
 * <code>mapred.map.multithreadedrunner.threads</code> property, its default
 * value is 10 threads.
 * <p>
 */"
MAPREDUCE-5437,MR2 specific metrics should be collected,"We have a usecase to show the below information. We can find job count by calling the /apps endpoint and filtering by type/state. But we need a way (JMX/API) to get the number of map/red tasks that are running/waiting.

{noformat}
Total Jobs: x jobs
Tasks: Maps	a running / b waiting
Tasks: Reduces	c running / d waiting
{noformat}"
MAPREDUCE-5435,Nodemanager stops working automatically,"Hi Everyone, 
I have been trying to setup a 10 node Hadoop Cluster(Hadoop 2.0.5 alpha). I've completed editing all the configuration files and am now trying to run the daemons. All the processes work fine apart from the nodemanager. The nodemanager runs fine on the slave however, on the master, it will only run for 10-15 sec and then stops. Same thing happens if I run the start command again.

Any suggestions?

Thanks in advance!"
MAPREDUCE-5433,use mapreduce to parse hfiles and output keyvalue,
MAPREDUCE-5431,Missing pom dependency in MR-client,There is a missing dependencies in the mr-client pom.xml that is exposed when running a mvn-rpmbuild against system dependencies.  Regular mvn build bypasses the issue via its default classpath.  patch provided by pmackinn@redhat.com
MAPREDUCE-5430,TestMRApps#testSetClasspathWithArchives is failing,"TestMRApps#testSetClasspathWithArchives is failing, stacktrace to follow."
MAPREDUCE-5429,App Master throw OutOfMemoryErrors.,"While running job , got OOM in app master and exitted the app master jvm.

{noformat}
2013-07-28 13:45:21,937 ERROR [IPC Server handler 14 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 INFO [IPC Server handler 22 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000384_0
2013-07-28 13:45:46,100 INFO [IPC Server handler 22 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1374920247399_0422_r_000384_0 is : 0.22976667
2013-07-28 13:45:21,937 ERROR [IPC Server handler 15 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 ERROR [IPC Server handler 13 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:54,522 INFO [IPC Server handler 15 on 59522] org.apache.hadoop.ipc.Server: IPC Server handler 15 on 59522, call statusUpdate(attempt_1374920247399_0422_r_000225_0, org.apache.hadoop.mapred.ReduceTaskStatus@dd89c26), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.71.115.238:59691: error: java.io.IOException: java.lang.OutOfMemoryError: Java heap space
java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:21,937 INFO [IPC Server handler 19 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000307_0
2013-07-28 13:45:21,937 INFO [IPC Server handler 16 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374920247399_0422_r_000552_0
2013-07-28 13:46:09,900 INFO [IPC Server handler 16 on 59522] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1374920247399_0422_r_000552_0 is : 0.17983334
2013-07-28 13:45:14,870 ERROR [IPC Server handler 6 on 59522] org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:job_1374920247399_0422 (auth:TOKEN) cause:java.io.IOException: java.lang.OutOfMemoryError: Java heap space
2013-07-28 13:45:14,870 FATAL [ResponseProcessor for block BP-myhacluster-25656:blk_-2026966945468195799_12352] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[ResponseProcessor for block BP-myhacluster-25656:blk_-2026966945468195799_12352,5,main] threw an Error.  Shutting down now...
java.lang.OutOfMemoryError: Java heap space
{noformat}"
MAPREDUCE-5428,HistoryFileManager doesn't stop threads when service is stopped,"HistoryFileManager is a service that starts threads, but it does not override the serviceStop method to stop the threads when the service is stopped."
MAPREDUCE-5427,TestRMContainerAllocator.testUpdatedNodes fails on jdk7,"{code}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator
-------------------------------------------------------------------------------
Tests run: 14, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 42.777 sec <<< FAILURE!
testUpdatedNodes(org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator)  Time elapsed: 0.14 sec  <<< FAILURE!
junit.framework.AssertionFailedError: null
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testUpdatedNodes(TestRMContainerAllocator.java:747)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:236)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:134)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:113)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)

{code}"
MAPREDUCE-5426,"MRAM fails to register to RM, AMRM token seems missing","trying to run the pi example in an unsecure pseudo cluster the job fails. 

It seems the AMRM token is MIA.

The AM syslog have the following:

{code}
2013-07-27 14:17:23,703 ERROR [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while registering
org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN]
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.yarn.ipc.RPCUtil.instantiateException(RPCUtil.java:53)
	at org.apache.hadoop.yarn.ipc.RPCUtil.unwrapAndThrowException(RPCUtil.java:104)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:109)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:176)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:95)
	at com.sun.proxy.$Proxy29.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.register(RMCommunicator.java:147)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator.serviceStart(RMCommunicator.java:107)
	at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.serviceStart(RMContainerAllocator.java:213)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$ContainerAllocatorRouter.serviceStart(MRAppMaster.java:789)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:101)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.serviceStart(MRAppMaster.java:1019)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$1.run(MRAppMaster.java:1394)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1477)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.initAndStartAppMaster(MRAppMaster.java:1390)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.main(MRAppMaster.java:1323)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): SIMPLE authentication is not enabled.  Available:[TOKEN]
	at org.apache.hadoop.ipc.Client.call(Client.java:1369)
	at org.apache.hadoop.ipc.Client.call(Client.java:1322)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy28.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.registerApplicationMaster(ApplicationMasterProtocolPBClientImpl.java:106)
	... 22 more
{code}
"
MAPREDUCE-5425,Junit in TestJobHistoryServer failing in jdk 7,"We get the following exception when we run the unit tests of TestJobHistoryServer with jdk 7:
Caused by: java.net.BindException: Problem binding to [0.0.0.0:10033] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:719)
	at org.apache.hadoop.ipc.Server.bind(Server.java:423)
	at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:535)
	at org.apache.hadoop.ipc.Server.<init>(Server.java:2202)
	at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:901)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:505)
	at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:480)
	at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:746)
	at org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer.serviceInit(HSAdminServer.java:100)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)


This is happening because testMainMethod starts the history server and doesnt stop it. This worked in jdk 6 because tests executed sequentially and this test was last one and didnt affect other tests,but in jdk 7 it fails."
MAPREDUCE-5424,TestNonExistentJob failing after YARN-873,
MAPREDUCE-5423,Rare deadlock situation when reducers try to fetch map output,"During our cluster deployment, we found there is a very rare deadlock situation when reducers try to fetch map output. We had 5 fetchers and log snippet illustrates this problem is below (all fetchers went into a wait state after they can't acquire more RAM beyond the memoryLimit and no fetcher is releasing memory):

2013-07-18 04:32:28,135 INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManager: MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2013-07-18 04:32:28,138 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2013-07-18 04:32:28,146 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:28,146 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 1 to fetcher#1
2013-07-18 04:32:28,146 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to 101-09-04.sc1.verticloud.com:8080 to fetcher#1
2013-07-18 04:32:28,319 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000017_0 sent hash and receievd reply
2013-07-18 04:32:28,320 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1373902166027_0622_m_000017_0 decomp: 27 len: 31 to MEMORY
2013-07-18 04:32:28,325 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 27 bytes from map-output for attempt_1373902166027_0622_m_000017_0
2013-07-18 04:32:28,325 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 27, inMemoryMapOutputs.size() -&gt; 1, commitMemory -&gt; 0, usedMemory -&gt;27
2013-07-18 04:32:28,325 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#1 in 179s
2013-07-18 04:32:33,158 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:33,158 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 1 to fetcher#1
2013-07-18 04:32:33,158 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to 101-09-04.sc1.verticloud.com:8080 to fetcher#1
2013-07-18 04:32:33,161 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000016_0 sent hash and receievd reply
2013-07-18 04:32:33,200 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1373902166027_0622_m_000016_0 decomp: 55841282 len: 55841286 to MEMORY
2013-07-18 04:32:33,322 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 55841282 bytes from map-output for attempt_1373902166027_0622_m_000016_0
2013-07-18 04:32:33,323 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 55841282, inMemoryMapOutputs.size() -&gt; 2, commitMemory -&gt; 27, usedMemory -&gt;55841309
2013-07-18 04:32:39,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 118022137 bytes from map-output for attempt_1373902166027_0622_m_000015_0
2013-07-18 04:32:39,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 118022137, inMemoryMapOutputs.size() -&gt; 3, commitMemory -&gt; 55841309, usedMemory -&gt;173863446
2013-07-18 04:32:39,594 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#1 in 413s
2013-07-18 04:32:42,188 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:42,188 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 1 to fetcher#1
2013-07-18 04:32:42,188 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to 101-09-04.sc1.verticloud.com:8080 to fetcher#1
2013-07-18 04:32:42,190 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000014_0 sent hash and receievd reply
2013-07-18 04:32:42,277 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1373902166027_0622_m_000014_0 decomp: 140715962 len: 140715966 to MEMORY
2013-07-18 04:32:42,493 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 140715962 bytes from map-output for attempt_1373902166027_0622_m_000014_0
2013-07-18 04:32:42,493 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 140715962, inMemoryMapOutputs.size() -&gt; 4, commitMemory -&gt; 173863446, usedMemory -&gt;314579408
2013-07-18 04:32:42,494 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#1 in 306s
2013-07-18 04:32:43,192 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:43,192 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 1 to fetcher#1
2013-07-18 04:32:43,192 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to 101-09-04.sc1.verticloud.com:8080 to fetcher#1
2013-07-18 04:32:43,195 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000013_0 sent hash and receievd reply
2013-07-18 04:32:43,280 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1373902166027_0622_m_000013_0 decomp: 141243082 len: 141243086 to MEMORY
2013-07-18 04:32:43,506 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 141243082 bytes from map-output for attempt_1373902166027_0622_m_000013_0
2013-07-18 04:32:43,506 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 141243082, inMemoryMapOutputs.size() -&gt; 5, commitMemory -&gt; 314579408, usedMemory -&gt;455822490
2013-07-18 04:32:43,507 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#1 in 315s
2013-07-18 04:32:44,195 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:44,195 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 1 to fetcher#1
2013-07-18 04:32:44,195 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to 101-09-04.sc1.verticloud.com:8080 to fetcher#1
2013-07-18 04:32:44,198 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000011_0 sent hash and receievd reply
2013-07-18 04:32:44,305 INFO [fetcher#1] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_1373902166027_0622_m_000011_0 decomp: 173528412 len: 173528416 to MEMORY
...
2013-07-18 04:32:56,901 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 282474777 bytes from map-output for attempt_1373902166027_0622_m_000001_0
2013-07-18 04:32:56,901 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 282474777, inMemoryMapOutputs.size() -&gt; 5, commitMemory -&gt; 1179552807, usedMemory -&gt;1462027584
2013-07-18 04:32:56,901 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#2 in 2682s
2013-07-18 04:32:56,901 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 4 to fetcher#4
2013-07-18 04:32:56,902 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to 101-09-04.sc1.verticloud.com:8080 to fetcher#4
2013-07-18 04:32:56,904 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000006_0,attempt_1373902166027_0622_m_000002_0,attempt_1373902166027_0622_m_000003_0,attempt_1373902166027_0622_m_000005_0 sent hash and receievd reply
2013-07-18 04:32:57,336 INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_1373902166027_0622_r_000001_0: Got 1 new map-outputs
2013-07-18 04:32:57,414 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 about to shuffle output of map attempt_1373902166027_0622_m_000006_0 decomp: 280156692 len: 280156696 to MEMORY
2013-07-18 04:32:57,867 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 280156692 bytes from map-output for attempt_1373902166027_0622_m_000006_0
2013-07-18 04:32:57,867 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -&gt; map-output of size: 280156692, inMemoryMapOutputs.size() -&gt; 6, commitMemory -&gt; 1462027584, usedMemory -&gt;1742184276
2013-07-18 04:32:57,900 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#4 - MergerManager returned Status.WAIT ...
2013-07-18 04:32:57,901 INFO [fetcher#4] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: 101-09-04.sc1.verticloud.com:8080 freed by fetcher#4 in 999s
2013-07-18 04:32:57,901 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging 101-09-04.sc1.verticloud.com:8080 with 4 to fetcher#3
2013-07-18 04:32:57,901 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 4 of 4 to 101-09-04.sc1.verticloud.com:8080 to fetcher#3
2013-07-18 04:32:57,903 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1373902166027_0622&amp;reduce=1&amp;map=attempt_1373902166027_0622_m_000000_0,attempt_1373902166027_0622_m_000002_0,attempt_1373902166027_0622_m_000005_0,attempt_1373902166027_0622_m_000003_0 sent hash and receievd reply
2013-07-18 04:32:57,904 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 - MergerManager returned Status.WAIT ...
..."
MAPREDUCE-5422,[Umbrella] Fix invalid state transitions in MRAppMaster,There are mutiple invalid state transitions for the state machines present in MRAppMaster. All these can be handled as part of this umbrell JIRA.
MAPREDUCE-5421,TestNonExistentJob is failed due to recent changes in YARN,"After YARN-873, try to get an application report with unknown appID will get a exception instead of null. This cause test failure in TestNonExistentJob which affects other irrelevant jenkins jobs like: https://builds.apache.org/job/PreCommit-HADOOP-Build/2845//testReport/. We need to fix test failure here."
MAPREDUCE-5420,Remove mapreduce.task.tmp.dir from mapred-default.xml,"mapreduce.task.tmp.dir no longer has any effect, so it should no longer be documented in mapred-default.  (There is no YARN equivalent for the property.  It now is just always ./tmp)."
MAPREDUCE-5419,TestSlive is getting FileNotFound Exception,"The write directory ""slive"" is not getting created on the FS."
MAPREDUCE-5418,JobHistoryServer has no information about applications if the MR-AM crashes,"Currently, the AM writes the job-specific information to HDFS only after it finishes; the JHS needs this info to display anything. If the AM fails, this info is not written and the JHS fails to display anything for that job.

While JHS on top of AHS might address this issue, it would be nice to have a solution in the interim. 
"
MAPREDUCE-5414,TestTaskAttempt fails jdk7 with NullPointerException,"Test case org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt fails once in a while when i run all of them together.
{code:xml} 
Running org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
Tests run: 9, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 7.893 sec <<< FAILURE!
Results :

Tests in error:
  testLaunchFailedWhileKilling(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)
  testContainerCleanedWhileRunning(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)
  testContainerCleanedWhileCommitting(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)
  testDoubleTooManyFetchFailure(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)

Tests run: 9, Failures: 0, Errors: 4, Skipped: 0
{code}
But if i run a single test case,taking testContainerCleanedWhileRunning for example,it will fail without doubt.
{code:xml} 
 <testcase time=""0.057"" classname=""org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt"" name=""testContainerCleanedWhileRunning"">
    <error type=""java.lang.NullPointerException"">java.lang.NullPointerException
        at org.apache.hadoop.security.token.Token.write(Token.java:216)
        at org.apache.hadoop.mapred.ShuffleHandler.serializeServiceData(ShuffleHandler.java:205)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createCommonContainerLaunchContext(TaskAttemptImpl.java:695)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.createContainerLaunchContext(TaskAttemptImpl.java:751)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1309)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1282)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1009)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt.testContainerCleanedWhileRunning(TestTaskAttempt.java:410)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
        at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:236)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:134)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:113)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
        at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
        at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:103)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:74)
</error>
    <system-out>2013-07-24 10:32:27,664 INFO  [main] util.RackResolver (RackResolver.java:coreResolve(100)) - Resolved 127.0.0.1 to /default-rack
2013-07-24 10:32:27,665 INFO  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:handle(1020)) - attempt_1_0002_m_000001_1 TaskAttempt Transitioned from NEW to UNASSIGNED
2013-07-24 10:32:27,666 INFO  [main] util.RackResolver (RackResolver.java:coreResolve(100)) - Resolved 127.0.0.1 to /default-rack
2013-07-24 10:32:27,668 INFO  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:createCommonContainerLaunchContext(636)) - Job jar is not present. Not adding any jar to the list of resources.
2013-07-24 10:32:27,669 INFO  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:createCommonContainerLaunchContext(653)) - The job-conf file on the remote FS is /tmp/hadoop-yarn/staging/root/.staging/job_1_0001/job.xml
2013-07-24 10:32:27,669 INFO  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:createCommonContainerLaunchContext(675)) - Size of containertokens_dob is 1
2013-07-24 10:32:27,670 INFO  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:createCommonContainerLaunchContext(685)) - Putting shuffle token in serviceData
2013-07-24 10:32:27,671 WARN  [main] impl.TaskAttemptImpl (TaskAttemptImpl.java:createCommonContainerLaunchContext(688)) - Cannot locate shuffle secret in credentials. Using job token as shuffle secret.
</system-out>
{code}"
MAPREDUCE-5412,Change MR to use multiple containers API of ContainerManager after YARN-926,
MAPREDUCE-5411,Refresh size of loaded job cache on history server,"We want to be able to refresh size of the loaded job cache(mapreduce.jobhistory.loadedjobs.cache.size) of history server
through history server's admin interface."
MAPREDUCE-5409,MRAppMaster throws InvalidStateTransitonException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at KILLED for TaskAttemptImpl,"{code:xml}
2013-07-23 12:28:05,217 INFO [IPC Server handler 29 on 50796] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Progress of TaskAttempt attempt_1374560536158_0003_m_000040_0 is : 0.0
2013-07-23 12:28:05,221 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Too many fetch-failures for output of task attempt: attempt_1374560536158_0003_m_000007_0 ... raising fetch failure to map
2013-07-23 12:28:05,222 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1374560536158_0003_m_000007_0
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_TOO_MANY_FETCH_FAILURE at KILLED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:1032)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:143)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1123)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:1115)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
	at java.lang.Thread.run(Thread.java:662)
2013-07-23 12:28:05,249 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1374560536158_0003Job Transitioned from RUNNING to ERROR
2013-07-23 12:28:05,338 INFO [IPC Server handler 16 on 50796] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from attempt_1374560536158_0003_m_000040_0
{code}"
MAPREDUCE-5408,CLONE - The logging level of the tasks should be configurable by the job,It would be nice to be able to configure the logging level of the Task JVM's separately from the server JVM's. Reducing logging substantially increases performance and reduces the consumption of local disk on the task trackers.
MAPREDUCE-5407,How to process 1 lack records to show a graph with 12 points,"I started HDFS on which hbase is running.Table created in hbase.
I am using Hive (hive Query) to process the data from HBase Table.

I have to show a graph with some points ( thsese may include 7 days in a week, 12 months in a year etc.).To show an average value of a day i have to process many records (some times 1000 to lacks).
Is there any built in mechanism (in hadoop) ? 
so that i can do it using that.

I need to run a job or hive query (when a hive query is running , actually a job is running) in every 1 hour.Is there any scheduler in hadoop by which can we do this easly.

Also "
MAPREDUCE-5406,Improve logging around Task Tracker exiting with JVM manager inconsistent state,"Looks like we are reaching JVM manager inconsistent state which cases TT to crash:
{code}
2013-06-09 06:41:11,250 FATAL org.apache.hadoop.mapred.JvmManager: Inconsistent state!!! JVM Manager reached an unstable state while reaping a JVM for task: attempt_201306080400_104812_m_000001_0 Number of active JVMs:8
  JVMId jvm_201306080400_104517_m_1331138312 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104517_m_000001_0
  JVMId jvm_201306080400_104641_m_-1631395161 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104641_m_000000_0
  JVMId jvm_201306080400_104494_m_-1702464703 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104494_m_000000_0
  JVMId jvm_201306080400_104784_m_1407576088 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104784_m_000000_0
  JVMId jvm_201306080400_104530_m_186665365 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104530_m_000000_0
  JVMId jvm_201306080400_104589_m_-1080246077 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104589_m_000000_0
  JVMId jvm_201306080400_104674_m_830017814 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104674_m_000000_0
  JVMId jvm_201306080400_104719_m_-226910128 #Tasks ran: 0 Currently busy? true Currently running: attempt_201306080400_104719_m_000000_0. Aborting. 
2013-06-09 06:41:11,250 INFO org.apache.hadoop.mapred.TaskTracker: SHUTDOWN_MSG: 
{code}

Although this causes TT to crash, the frequency of the error is rare and the error itself is recoverable so the priority of the issue is not high.

However, this does look like a bug in the JVM manager state machine. I'm guessing there is some race condition that we're hitting.

(Logs attached)"
MAPREDUCE-5405,Job recovery can fail if task log directory symlink from prior run still exists,"During recovery, the task attempt log dir symlink from the prior run might still exist.  If it does, then the recovered attempt will fail while trying to create a symlink at that path.
"
MAPREDUCE-5404,HSAdminServer does not use ephemeral ports in minicluster mode,"I ran HBase trunk tests against 2.2.0-SNAPSHOT and many mapreduce jobs failed.
Here is one example:
{code}
org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScan2  Time elapsed: 0.001 sec  <<< ERROR!
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: org.apache.hadoop.service.ServiceStateException: java.net.BindException: Problem binding to [0.0.0.0:10033] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.mapreduce.v2.MiniMRYarnCluster$JobHistoryServerWrapper.serviceStart(MiniMRYarnCluster.java:177)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
        at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:101)
        at org.apache.hadoop.service.AbstractService.start(AbstractService.java:193)
        at org.apache.hadoop.mapred.MiniMRClientClusterFactory.create(MiniMRClientClusterFactory.java:80)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:183)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:171)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:163)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:124)
        at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniMapReduceCluster(HBaseTestingUtility.java:1751)
        at org.apache.hadoop.hbase.HBaseTestingUtility.startMiniMapReduceCluster(HBaseTestingUtility.java:1692)
        at org.apache.hadoop.hbase.mapreduce.TestTableInputFormatScanBase.setUpBeforeClass(TestTableInputFormatScanBase.java:84)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:606)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
        at org.junit.runners.Suite.runChild(Suite.java:127)
        at org.junit.runners.Suite.runChild(Suite.java:26)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:724)
Caused by: org.apache.hadoop.service.ServiceStateException: java.net.BindException: Problem binding to [0.0.0.0:10033] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.service.ServiceStateException.convert(ServiceStateException.java:59)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:172)
        at org.apache.hadoop.service.CompositeService.serviceInit(CompositeService.java:88)
        at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.serviceInit(JobHistoryServer.java:91)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
        at org.apache.hadoop.mapreduce.v2.MiniMRYarnCluster$JobHistoryServerWrapper.serviceStart(MiniMRYarnCluster.java:161)
        ... 30 more
Caused by: java.net.BindException: Problem binding to [0.0.0.0:10033] java.net.BindException: Address already in use; For more details see:  http://wiki.apache.org/hadoop/BindException
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:719)
        at org.apache.hadoop.ipc.Server.bind(Server.java:398)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:501)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:2168)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:997)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.<init>(ProtobufRpcEngine.java:505)
        at org.apache.hadoop.ipc.ProtobufRpcEngine.getServer(ProtobufRpcEngine.java:480)
        at org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:840)
        at org.apache.hadoop.mapreduce.v2.hs.server.HSAdminServer.serviceInit(HSAdminServer.java:93)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
        ... 34 more
{code}"
MAPREDUCE-5402,DynamicInputFormat should allow overriding of MAX_CHUNKS_TOLERABLE,"In MAPREDUCE-2765, which provided the design spec for DistCpV2, the author describes the implementation of DynamicInputFormat, with one of the main motivations cited being to reduce the chance of long-tails where a few leftover mappers run much longer than the rest.

However, I today ran into a situation where I experienced exactly such a long tail using DistCpV2 and DynamicInputFormat.  And when I tried to alleviate the problem by overriding the number of mappers and the split ratio used by the DynamicInputFormat, I was prevented from doing so by the hard-coded limit set in the code by the MAX_CHUNKS_TOLERABLE constant.  (Currently set to 400.)

This constant is actually set quite low for production use.  (See a description of my use case below.)  And although MAPREDUCE-2765 states that this is an ""overridable maximum"", when reading through the code there does not actually appear to be any mechanism available to override it.

This should be changed.  It should be possible to expand the maximum # of chunks beyond this arbitrary limit.


For example, here is the situation I ran into today:

I ran a distcpv2 job on a cluster with 8 machines containing 128 map slots.  The job consisted of copying ~2800 files from HDFS to Amazon S3.  I overrode the number of mappers for the job from the default of 20 to 128, so as to more properly parallelize the copy across the cluster.  The number of chunk files created was calculated as 241, and mapred.num.entries.per.chunk was calculated as 12.

As the job ran on, it reached a point where there were only 4 remaining map tasks, which had each been running for over 2 hours.  The reason for this was that each of the 12 files that those mappers were copying were quite large (several hundred megabytes in size) and took ~20 minutes each.  However, during this time, all the other 124 mappers sat idle.


In theory I should be able to alleviate this problem with DynamicInputFormat.  If I were able to, say, quadruple the number of chunk files created, that would have made each chunk contain only 3 files, and these large files would have gotten distributed better around the cluster and copied in parallel.

However, when I tried to do that - by overriding mapred.listing.split.ratio to, say, 10 - DynamicInputFormat responded with an exception (""Too many chunks created with splitRatio:10, numMaps:128. Reduce numMaps or decrease split-ratio to proceed."") - presumably because I exceeded the MAX_CHUNKS_TOLERABLE value of 400.


Is there any particular logic behind this MAX_CHUNKS_TOLERABLE limit?  I can't personally see any.

If this limit has no particular logic behind it, then it should be overridable - or even better:  removed altogether.  After all, I'm not sure I see any need for it.  Even if numMaps * splitRatio resulted in an extraordinarily large number, if the code were modified so that the number of chunks got calculated as Math.min( numMaps * splitRatio, numFiles), then there would be no need for MAX_CHUNKS_TOLERABLE.  In this worst-case scenario where the product of numMaps and splitRatio is large, capping the number of chunks at the number of files (numberOfChunks = numberOfFiles) would result in 1 file per chunk - the maximum parallelization possible.  That may not be the best-tuned solution for some users, but I would think that it should be left up to the user to deal with the potential consequence of not having tuned their job properly.  Certainly that would be better than having an arbitrary hard-coded limit that *prevents* proper parallelization when dealing with large files and/or large numbers of mappers."
MAPREDUCE-5401,Succeeded Job details displayed as Error  In JobHistoryServer UI when RM issues Reboot to 1st app master.,"RM issues Reboot to 1st attempt app master and lauches 2nd attempt app master in available NodeManager.
1st attempt app master shutdown gracefully , not deleting staging directory which is handled in MAPREDUCE-5086. But problem is 1st attempt app master creates jhist(Error),summary and config file.

2nd attempt app master also create jhist(succeeded) , summary and config file.
While moving summary file, since file is already exist of 1st attempt summary file, 2nd attempt summary remain as summary_tmp 



"
MAPREDUCE-5400,MRAppMaster throws InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED for JobImpl,"Step 1: Install cluster with HDFS , MR
Step 2: Execute a job
Step 3: Issue a kill task attempt for which the task has got completed.

Rex@HOST-10-18-91-55:~/NodeAgentTmpDir/installations/hadoop-2.0.5.tar/hadoop-2.0.5/bin> ./mapred job -kill-task attempt_1373875322959_0032_m_000000_0 
No GC_PROFILE is given. Defaults to medium.
13/07/15 14:46:32 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is inited.
13/07/15 14:46:32 INFO proxy.ResourceManagerProxies: HA Proxy Creation with xface : interface org.apache.hadoop.yarn.api.ClientRMProtocol
13/07/15 14:46:33 INFO service.AbstractService: Service:org.apache.hadoop.yarn.client.YarnClientImpl is started.
Killed task attempt_1373875322959_0032_m_000000_0


Observation:
===========
1. task state has been transitioned from SUCCEEDED to SCHEDULED
2. For a Succeeded attempt , when client issues Kill , then the client is notified as killed for a succeeded attempt.
3. Launched second task_attempt which is succeeded and then killed later on client request.
4. Even after the job state transitioned from SUCCEEDED to ERROR , on UI the state is succeeded



Issue :
=====
1. Client has been notified that the atttempt is killed , but acutually the attempt is succeeded and the same is displayed in JHS UI.
2. At App master InvalidStateTransitonException is thrown .
3. At client side and JHS job has exited with state Finished/succeeded ,At RM side the state is Finished/Failed.


AM Logs:
========
2013-07-15 14:46:25,461 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1373875322959_0032_m_000000_0 TaskAttempt Transitioned from RUNNING to SUCCEEDED
2013-07-15 14:46:25,468 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1373875322959_0032_m_000000_0
2013-07-15 14:46:25,470 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1373875322959_0032_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2013-07-15 14:46:33,810 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1373875322959_0032_m_000000 Task Transitioned from SUCCEEDED to SCHEDULED
2013-07-15 14:46:37,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt attempt_1373875322959_0032_m_000000_1
2013-07-15 14:46:37,344 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: task_1373875322959_0032_m_000000 Task Transitioned from RUNNING to SUCCEEDED
2013-07-15 14:46:37,345 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at SUCCEEDED
at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:302)
at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)
at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:866)
at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:128)
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1095)
at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1091)
at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)
at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
at java.lang.Thread.run(Thread.java:662)
"
MAPREDUCE-5399,Unnecessary Configuration instantiation in IFileInputStream slows down merge,"We are using hadoop-2.0.0+1357-1.cdh4.3.0.p0.21 with MRv1. After upgrade from 4.1.2 to 4.3.0, I have noticed some performance deterioration in our MR job in the Reduce phase. The MR job has usually 10 000 map tasks (10 000 files on input each about 100MB) and 6 000 reducers (one reducer per table region). I was trying to figure out what at which phase the slow down appears (firstly I suspected that the slow gathering of the 10000 map output files is the culprit) and found out that the problem is not reading the map output (the shuffle) but the sort/merge phase that follows - the last and actual reduce phase is fast. I have tried to up the io.sort.factor because I thought the lots of small files are being merged on disk, but again upping that to 1000 didnt do any difference. I have then printed the stack trace and found out that the problem is initialization of the org.apache.hadoop.mapred.IFileInputStream namely the creation of the Configuration object which is not propagated along from earlier context, see the stack trace:

Thread 13332: (state = IN_NATIVE)
 - java.io.UnixFileSystem.getBooleanAttributes0(java.io.File) @bci=0 (Compiled frame; information may be imprecise)
 - java.io.UnixFileSystem.getBooleanAttributes(java.io.File) @bci=2, line=228 (Compiled frame)
 - java.io.File.exists() @bci=20, line=733 (Compiled frame)
 - sun.misc.URLClassPath$FileLoader.getResource(java.lang.String, boolean) @bci=136, line=999 (Compiled frame)
 - sun.misc.URLClassPath$FileLoader.findResource(java.lang.String, boolean) @bci=3, line=966 (Compiled frame)
 - sun.misc.URLClassPath.findResource(java.lang.String, boolean) @bci=17, line=146 (Compiled frame)
 - java.net.URLClassLoader$2.run() @bci=12, line=385 (Compiled frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedAction, java.security.AccessControlContext) @bci=0 (Compiled frame)
 - java.net.URLClassLoader.findResource(java.lang.String) @bci=13, line=382 (Compiled frame)
 - java.lang.ClassLoader.getResource(java.lang.String) @bci=30, line=1002 (Compiled frame)
 - java.lang.ClassLoader.getResourceAsStream(java.lang.String) @bci=2, line=1192 (Compiled frame)
 - javax.xml.parsers.SecuritySupport$4.run() @bci=26, line=96 (Compiled frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedAction) @bci=0 (Compiled frame)
 - javax.xml.parsers.SecuritySupport.getResourceAsStream(java.lang.ClassLoader, java.lang.String) @bci=10, line=89 (Compiled frame)
 - javax.xml.parsers.FactoryFinder.findJarServiceProvider(java.lang.String) @bci=38, line=250 (Interpreted frame)
 - javax.xml.parsers.FactoryFinder.find(java.lang.String, java.lang.String) @bci=273, line=223 (Interpreted frame)
 - javax.xml.parsers.DocumentBuilderFactory.newInstance() @bci=4, line=123 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.loadResource(java.util.Properties, org.apache.hadoop.conf.Configuration$Resource, boolean) @bci=16, line=1890 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.loadResources(java.util.Properties, java.util.ArrayList, boolean) @bci=49, line=1867 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getProps() @bci=43, line=1785 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.get(java.lang.String) @bci=35, line=712 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getTrimmed(java.lang.String) @bci=2, line=731 (Compiled frame)
 - org.apache.hadoop.conf.Configuration.getBoolean(java.lang.String, boolean) @bci=2, line=1047 (Interpreted frame)
 - org.apache.hadoop.mapred.IFileInputStream.<init>(java.io.InputStream, long, org.apache.hadoop.conf.Configuration) @bci=111, line=93 (Interpreted frame)
 - org.apache.hadoop.mapred.IFile$Reader.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.fs.FSDataInputStream, long, org.apache.hadoop.io.compress.CompressionCodec, org.apache.hadoop.mapred.Counters$Counter) @bci=60, line=303 (Interpreted frame)
 - org.apache.hadoop.mapred.IFile$InMemoryReader.<init>(org.apache.hadoop.mapred.RamManager, org.apache.hadoop.mapred.TaskAttemptID, byte[], int, int) @bci=11, line=480 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier.createInMemorySegments(java.util.List, long) @bci=133, line=2416 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask$ReduceCopier.createKVIterator() @bci=669, line=2530 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask.run(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.TaskUmbilicalProtocol) @bci=513, line=425 (Interpreted frame)
 - org.apache.hadoop.mapred.Child$4.run() @bci=29, line=268 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Interpreted frame)
 - javax.security.auth.Subject.doAs(javax.security.auth.Subject, java.security.PrivilegedExceptionAction) @bci=42, line=396 (Interpreted frame)
 - org.apache.hadoop.security.UserGroupInformation.doAs(java.security.PrivilegedExceptionAction) @bci=14, line=1408 (Interpreted frame)
 - org.apache.hadoop.mapred.Child.main(java.lang.String[]) @bci=776, line=262 (Interpreted frame)


A blank configuration object is created at IFileInputStream. I have made a test and found out that this operation costs about 10-15ms depending on the load on the system, because it goes to the local FS to load the properties!!! This is to my opinion a bug since in the context the configuration (of the job) is known and could be reused at that point. My problem (and every others who has big number of reducer and mapper tasks) is that for 10K map taks it does 10000 x 15 = 150 seconds just to find out that there is nothing to sort. The overhead should be normally zero. 

At this moment, the 10-15ms problem is amplified by 6 000 reducers so the bottom line is that my reduce phase is at least 1.6 hours longer than it should be."
MAPREDUCE-5398,MR changes for YARN-513,
MAPREDUCE-5391,TestNonLocalJobJarSubmission fails on Windows due to missing classpath entries,"This test works by having the mapper check all classpath entries loaded by the classloader.  On Windows, the classpath is packed into an intermediate jar file with a manifest containing the classpath to work around command line length limitation.  The test needs to be updated to unpack the intermediate jar file and read the manifest when running on Windows."
MAPREDUCE-5386,Ability to refresh history server job retention and job cleaner settings,"We want to be able to refresh following job retention parameters
without having to bounce the history server :
1. Job retention time - mapreduce.jobhistory.max-age-ms
2. Cleaner interval - mapreduce.jobhistory.cleaner.interval-ms
3. Enable/disable cleaner -mapreduce.jobhistory.cleaner.enable"
MAPREDUCE-5385,JobContext cache files api are broken,"I just checked there are issues with latest distributed cache api.

* JobContext.getCacheFiles is broken returns null."
MAPREDUCE-5381,Support graceful decommission of tasktracker,"When TTs are decommissioned for non-fault reasons (capacity change etc.), it's desirable to minimize the impact to running jobs.

Currently if a TT is decommissioned, all running tasks on the TT need to be rescheduled on other TTs. Further more, for finished map tasks, if their map output are not fetched by the reducers of the job, these map tasks will need to be rerun as well.

We propose to introduce a mechanism to optionally gracefully decommission a tasktracker."
MAPREDUCE-5380,Invalid mapred command should return non-zero exit code,"Running the mapred bin script with an invalid command returns exit code 0, but it should return a non-zero exit code.

{code}
[schu@hdfs-snapshots-1 ~]$ hadoop-3.0.0-SNAPSHOT/bin/mapred gibberish
gibberish - invalid command
Usage: mapred [--config confdir] COMMAND
       where COMMAND is one of:
  pipes                run a Pipes job
  job                  manipulate MapReduce jobs
  queue                get information regarding JobQueues
  classpath            prints the class path needed for running
                       mapreduce subcommands
  historyserver        run job history servers as a standalone daemon
  distcp <srcurl> <desturl> copy file or directories recursively
  archive -archiveName NAME -p <parent path> <src>* <dest> create a hadoop archive

Most commands print help when invoked w/o parameters.
[schu@hdfs-snapshots-1 ~]$ echo $?
0
[schu@hdfs-snapshots-1 ~]$ 
{code}"
MAPREDUCE-5379,Include token tracking ids in jobconf,"HDFS-4680 enables audit logging delegation tokens. By storing the tracking ids in the job conf, we can enable tracking what files each job touches."
MAPREDUCE-5378,Enable ApplicationMaster to support different QOP for client and server communications,"Currently ApplicationMaster's QOP(quality of protection) is derived from the client's config. If the client uses privacy, all the communication done by the application master will be set to privacy. 

As part of the feature to support multiple QOP (HADOOP -9709), the application master is modified so that application master can support a different QOPs  for its communication with client vs its communication with other hadoop components.

"
MAPREDUCE-5375,Delegation Token renewal exception in jobtracker logs,"Filing on behalf of [~venkatnrangan] who found this originally and provided a patch.

Saw this in the JT logs while oozie tests were running with Hadoop.

When Oozie java action is executed, the following shows up in the job tracker log.

{code}
ERROR org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal: Exception renewing tokenIdent: 00 07 68 64 70 75 73 65 72 06 6d 61 70 72 65 64 26 6f 6f 7a 69 65 2f 63 6f 6e 64 6f 72 2d 73 65 63 2e 76 65 6e 6b 61 74 2e 6f 72 67 40 76 65 6e 6b 61 74 2e 6f 72 67 8a 01 3e a6 87 5e 5b 8a 01 3e ca 93 e2 5b 02 02, Kind: MAPREDUCE_DELEGATION_TOKEN, Service: ip:50300. Not rescheduled
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Client jt/host@domain.com tries to renew a token with renewer specified as mapred
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:267)
        at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:3878)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1405)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1401)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1399)

        at org.apache.hadoop.ipc.Client.call(Client.java:1118)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
        at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
       at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
        at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
        at org.apache.hadoop.mapred.JobClient$Renewer.renew(JobClient.java:578)
        at org.apache.hadoop.security.token.Token.renew(Token.java:309)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:221)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:217)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.run(DelegationTokenRenewal.java:216)
        at java.util.TimerThread.mainLoop(Timer.java:512)
        at java.util.TimerThread.run(Timer.java:462)
{code}

Setting the renewer to Kerberos Local name does not help because AbstractDelegationTokenIdentifier sets the renewer to Kerberos shortname but JobTracker.renewDelegationToken uses the fullName.  This essentially causes the renewal to fail."
MAPREDUCE-5373,TestFetchFailure.testFetchFailureMultipleReduces could fail intermittently,"The unit test case could fail intermittently on both Linux and Windows in my testing. The error message seems suggesting the task status was wrong during testing.

An example Linux failure:
{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapreduce.v2.app.TestFetchFailure
-------------------------------------------------------------------------------
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 12.235 sec <<< FAILURE!
testFetchFailureMultipleReduces(org.apache.hadoop.mapreduce.v2.app.TestFetchFailure)  Time elapsed: 1261 sec  <<< FAILURE!
java.lang.AssertionError: expected:<SUCCEEDED> but was:<SCHEDULED>
  at org.junit.Assert.fail(Assert.java:93)
  at org.junit.Assert.failNotEquals(Assert.java:647)
  at org.junit.Assert.assertEquals(Assert.java:128)
  at org.junit.Assert.assertEquals(Assert.java:147)
  at org.apache.hadoop.mapreduce.v2.app.TestFetchFailure.testFetchFailureMultipleReduces(TestFetchFailure.java:332)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  at java.lang.reflect.Method.invoke(Method.java:597)
  at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
  at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
  at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
  at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
  at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
  at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
  at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
  at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
  at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
  at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
  at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
  at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
  at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
  at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
  at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
  at java.lang.reflect.Method.invoke(Method.java:597)
  at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
  at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
  at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
  at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
  at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}

An example Windows failure:
{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapreduce.v2.app.TestFetchFailure
-------------------------------------------------------------------------------
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 50.342 sec <<< FAILURE!
testFetchFailureMultipleReduces(org.apache.hadoop.mapreduce.v2.app.TestFetchFailure)  Time elapsed: 36175 sec  <<< FAILURE!
java.lang.AssertionError: expected:<SUCCEEDED> but was:<RUNNING>
	at org.junit.Assert.fail(Assert.java:93)
	at org.junit.Assert.failNotEquals(Assert.java:647)
	at org.junit.Assert.assertEquals(Assert.java:128)
	at org.junit.Assert.assertEquals(Assert.java:147)
	at org.apache.hadoop.mapreduce.v2.app.TestFetchFailure.testFetchFailureMultipleReduces(TestFetchFailure.java:332)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{noformat}"
MAPREDUCE-5372,ControlledJob#getMapredJobID capitalization is inconsistent between MR1 and MR2,"In MR2, the 'd' in Id is lowercase, but in MR1, it is capitalized.  While ControlledJob is marked as Evolving, there is no reason to be inconsistent here."
MAPREDUCE-5371,TestProxyUserFromEnv#testProxyUserFromEnvironment failed caused by domains of windows users,"The error message was:
Error Message
expected:<[sijenkins-vm2]jenkins> but was:<[]jenkins>
Stacktrace
at org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment(TestProxyUserFromEnv.java:45)

The root cause of this failure is the domain used on Windows."
MAPREDUCE-5368,"Save memory by  set capacity, load factor and concurrency level for ConcurrentHashMap in TaskInProgress","Below is histo from our JobTracker:

 num     #instances         #bytes  class name
----------------------------------------------
   1:     136048824    11347237456  [C
   2:     124156992     5959535616  java.util.concurrent.locks.ReentrantLock$NonfairSync
   3:     124156973     5959534704  java.util.concurrent.ConcurrentHashMap$Segment
   4:     135887753     5435510120  java.lang.String
   5:     124213692     3975044400  [Ljava.util.concurrent.ConcurrentHashMap$HashEntry;
   6:      63777311     3061310928  java.util.HashMap$Entry
   7:      35038252     2803060160  java.util.TreeMap
   8:      16921110     2712480072  [Ljava.util.HashMap$Entry;
   9:       4803617     2420449192  [Ljava.lang.Object;
  10:      50392816     2015712640  org.apache.hadoop.mapred.Counters$Counter
  11:       7775438     1181866576  [Ljava.util.concurrent.ConcurrentHashMap$Segment;
  12:       3882847     1118259936  org.apache.hadoop.mapred.TaskInProgress


ConcurrentHashMap takes more than 14G(5959535616 + 5959534704 + 3975044400).
The trouble maker are below codes in TaskInProgress.java:
  Map<TaskAttemptID, Locality> taskLocality = 
      new ConcurrentHashMap<TaskAttemptID, Locality>();
  Map<TaskAttemptID, Avataar> taskAvataar = 
      new ConcurrentHashMap<TaskAttemptID, Avataar>();
"
MAPREDUCE-5367,Local jobs all use same local working directory,"This means that local jobs, even in different JVMs, can't run concurrently because they might delete each other's files during work directory setup."
MAPREDUCE-5366,TestMRAsyncDiskService fails on Windows,"The unit test fails on Windows because mismatching of {{File.seperator}} and  {{Path}} object name. In general, we should only use {{Path.SEPARATOR}} when dealing with {{Path}} objects."
MAPREDUCE-5364,Deadlock between RenewalTimerTask methods cancel() and run(),"MAPREDUCE-4860 introduced a local variable {{cancelled}} in {{RenewalTimerTask}} to fix the race where {{DelegationTokenRenewal}} attempts to renew a token even after the job is removed. However, the patch also makes {{run()}} and {{cancel()}} synchronized methods leading to a potential deadlock against {{run()}}'s catch-block (error-path).

The deadlock stacks below:

{noformat}
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.cancel() @bci=0, line=240 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.removeDelegationTokenRenewalForJob(org.apache.hadoop.mapreduce.JobID) @bci=109, line=319 (Interpreted frame)
{noformat}

{noformat}
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.removeFailedDelegationToken(org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenToRenew) @bci=62, line=297 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal.access$300(org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$DelegationTokenToRenew) @bci=1, line=47 (Interpreted frame)
 - org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.run() @bci=148, line=234 (Interpreted frame)
{noformat}"
MAPREDUCE-5363,Fix doc and spelling for TaskCompletionEvent#getTaskStatus and getStatus,"The doc for TaskCompletionEvent#get(Task)Status in both MR1 and MR2 is
{code}
Returns enum Status.SUCESS or Status.FAILURE.
@return task tracker status
{code}

The actual values that the Status enum can take are
FAILED, KILLED, SUCCEEDED, OBSOLETE, TIPFAILED"
MAPREDUCE-5360,TestMRJobClient fails on Windows due to path format,"This unit test has following two failed test cases on Windows due to path name format.

* testJobHistory
* testSubmit

When passing local path to the command line, the test cases use ""file:///"" + a string derived from Java API {{File.getAbsolutePath()}}. The mixed use of forward and back slashes in the path leads to the failure."
MAPREDUCE-5359,JobHistory should not use File.separator to match timestamp in path,"In {{HistoryFileManager.getTimestampPartFromPath()}} method, we use the following regular expression to match the timestamp in a Path object. 

{code:java}
""\\d{4}"" + ""\\"" + File.separator +  ""\\d{2}"" + ""\\"" + File.separator + ""\\d{2}""
{code}

This is incorrect because Path uses backslash even for Windows path while File.separator is platform dependent, and is a forward slash on Windows.

This leads to failure matching the timestamp on Windows. One consequence is that {{addDirectoryToSerialNumberIndex()}} also failed. Later, {{getFileInfo()}} will fail if the job info is not in cache or intermediate directory.

The test case {{TestJobHistoryParsing.testScanningOldDirs()}} tests exactly the above scenario and fails on Windows."
MAPREDUCE-5358,MRAppMaster throws invalid transitions for JobImpl,"{code:xml}
2013-06-26 11:39:50,128 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at SUCCEEDED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:720)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:119)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:962)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:958)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
	at java.lang.Thread.run(Thread.java:662)
{code}

{code:xml}
2013-06-26 11:39:50,129 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_MAP_TASK_RESCHEDULED at SUCCEEDED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:720)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:119)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:962)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:958)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
	at java.lang.Thread.run(Thread.java:662)
{code}"
MAPREDUCE-5357,Job staging directory owner checking could fail on Windows,"In {{JobSubmissionFiles.getStagingDir()}}, we have following code that will throw exception if the directory owner is not the current user.

{code:java}
      String owner = fsStatus.getOwner();
      if (!(owner.equals(currentUser) || owner.equals(realUser))) {
         throw new IOException(""The ownership on the staging directory "" +
                      stagingArea + "" is not as expected. "" +
                      ""It is owned by "" + owner + "". The directory must "" +
                      ""be owned by the submitter "" + currentUser + "" or "" +
                      ""by "" + realUser);
      }
{code}

This check will fail on Windows when the underlying file system is LocalFileSystem. Because on Windows, the default file or directory owner could be ""Administrators"" group if the user belongs to ""Administrators"" group.

Quite a few MR unit tests that runs MR mini cluster with localFs as underlying file system fail because of this."
MAPREDUCE-5356,Ability to refresh aggregated log retention period and check interval ,"We want to be able to refresh log aggregation retention time
and 'check interval' time on the fly by changing configs so that we dont have to bounce history server."
MAPREDUCE-5355,MiniMRYarnCluster with localFs does not work on Windows,"When MiniMRYarnCluster configured to run on localFs instead of remoteFs, i.e. MiniDFSCluster, the job will fail on Windows. The error message looks like the following.

{noformat}
java.io.IOException: Job status not available
{noformat}

In my testing, the following unit tests hit this exception.

* TestMRJobsWithHistoryService
* TestClusterMRNotification
* TestJobCleanup
* TestJobCounters
* TestMiniMRClientCluster
* TestJobOutputCommitter
* TestMRAppWithCombiner
* TestMROldApiJobs
* TestSpeculativeExecution
"
MAPREDUCE-5352,Optimize node local splits generated by CombineFileInputFormat ,"CombineFileInputFormat currently walks through all available nodes and generates multiple (maxSplitsPerNode) splits on a single node before attempting to generate splits on subsequent nodes. This ends up reducing the possibility of generating splits for subsequent nodes - since these blocks will no longer be available for subsequent nodes. Allowing splits to go 1 block above the max-split-size makes this worse.
Allocating a single split per node in one iteration, should help increase the distribution of splits across nodes - so the subsequent nodes will have more blocks to choose from."
MAPREDUCE-5351,JobTracker memory leak caused by CleanupQueue reopening FileSystem,"When a job is completed, closeAllForUGI is called to close all the cached FileSystems in the FileSystem cache.  However, the CleanupQueue may run after this occurs and call FileSystem.get() to delete the staging directory, adding a FileSystem to the cache that will never be closed.

People on the user-list have reported this causing their JobTrackers to OOME every two weeks."
MAPREDUCE-5349,TestClusterMapReduceTestCase and TestJobName fail on Windows in branch-2,"The two unit tests fails due to MiniMRCluster use test class fullname in branch-2, instead of simple name as in trunk, to construct the MiniMRCluster identifier. Full name in the identifier almost always leads to a command script path with length larger than 260 characters which will generate an exception {{DefaultContainerExecutor.launchContainer()}} when launching the container script.

The exception looks like the follows:
{noformat}
2013-06-24 09:45:03,060 WARN  [ContainersLauncher #0] launcher.ContainerLaunch (ContainerLaunch.java:call(262)) - Failed to launch container.
java.io.IOException: Cannot launch container using script at path C:/Users/chuanliu/AppData/Local/Temp/1/1372092295656/org.apache.hadoop.mapred.ClusterMapReduceTestCaseConfigurableMiniMRCluster_1106798455-localDir-nm-0_1/usercache/chuanliu/appcache/application_1372092193505_0001/container_1372092193505_0001_01_000001/default_container_executor.cmd, because it exceeds the maximum supported path length of 260 characters.  Consider configuring shorter directories in yarn.nodemanager.local-dirs.
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:159)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:257)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:1)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
{noformat}"
MAPREDUCE-5347,getBlacklistedTrackers() should be deprecated and a new method called  getNumBlacklistedTrackers should be added. ,"If the method returns a number, then that is what the method name should reflect. It should be called getNumBlacklistedTrackers(). The method does not return trackers, it returns number of trackers.

The same applies to the following:
- getMapTasks, getReduceTasks, getTaskTrackers

These should be deprecated and a new method should be added: getNumxxx. "
MAPREDUCE-5346,The example provided in the javadoc for Job is outdated.,"This is a portion of the job example:

Here is an example on how to submit a job:

         // Create a new Job
         Job job = new Job(new Configuration());

This way of creating a job is deprecated. The user is supposed to use Job.getInstance. The example should be changed to reflect the new paradigm."
MAPREDUCE-5345,cleanupProgress is misleading. It should be renamed getCleanupTasksProgress ,"cleanupProgress suggests that Progress should be cleaned up. In reality, the user is getting the progress of the cleanup tasks. It should be renamed getCleanupTasksProgress."
MAPREDUCE-5344,getClusterStatus method in Cluster returns ClusterMetrics. It should be called getClusterMetrics or it should return ClusterStatus.,"There is a ClusterStatus class. When getClusterStatus is called, one would expect ClusterStatus to be returned. Instead, one gets ClusterMetrics. 

"
MAPREDUCE-5343,reduceProgress is misleading. It should be renamed getReduceTasksProgress,"reduceProgress suggests that the method is going to reduce progress and is misleading because, in fact, the method provides progress information about reduce tasks. It should be renamed to match what it does: getReduceTasksProgress."
MAPREDUCE-5341,All constructors for Job are deprecated. There is no indication of what the alternative is.,"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Job.html#isRetired%28%29

Job constructors are deprecated and the user is supposed to use getInstance but this is not mentioned anywhere. 

As a rule, all javadocs should be reviewed for deprecated methods/fields to indicate whether an alternative exists or not and if the alternative exists, what is the alternative."
MAPREDUCE-5340,isRetired is not well defined. javadoc does not indicate how a job is retired and waht does retired mean.,"http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Job.html#isRetired%28%29

There is no description of what is retired and how a job is retired."
MAPREDUCE-5335,Rename Job Tracker terminology in ShuffleSchedulerImpl,"{code:xml}
2013-06-17 17:27:30,134 INFO [fetcher#2] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Reporting fetch failure for attempt_1371467533091_0005_m_000010_0 to jobtracker.
{code}



{code:title=ShuffleSchedulerImpl.java|borderStyle=solid}
  // Notify the JobTracker
  // after every read error, if 'reportReadErrorImmediately' is true or
  // after every 'maxFetchFailuresBeforeReporting' failures
  private void checkAndInformJobTracker(
      int failures, TaskAttemptID mapId, boolean readError,
      boolean connectExcpt) {
    if (connectExcpt || (reportReadErrorImmediately && readError)
        || ((failures % maxFetchFailuresBeforeReporting) == 0)) {
      LOG.info(""Reporting fetch failure for "" + mapId + "" to jobtracker."");
      status.addFetchFailedMap((org.apache.hadoop.mapred.TaskAttemptID) mapId);
    }
  }

 {code}"
MAPREDUCE-5334,TestContainerLauncherImpl is failing,"Broken by YARN-694, but Jenkins didn't report it."
MAPREDUCE-5333,Add test that verifies MRAM works correctly when sending requests with non-normalized capabilities,This is a follow on MAPREDUCE-5310 to ensure nothing broke after we removed normalization on the MRAM side.
MAPREDUCE-5332,Support token-preserving restart of history server,"To better support rolling upgrades through a cluster, the history server needs the ability to restart without losing track of delegation tokens."
MAPREDUCE-5330,JVM manager should not forcefully kill the process on Signal.TERM on Windows,"In MapReduce, we sometimes kill a task's JVM before it naturally shuts down if we want to launch other tasks (look in JvmManager$JvmManagerForType.reapJvm). This behavior means that if the map task process is in the middle of doing some cleanup/finalization after the task is done, it might be interrupted/killed without giving it a chance. 

In the Microsoft's Hadoop Service, after a Map/Reduce task is done and during closing file systems in a special shutdown hook, we're typically uploading storage (ASV in our context) usage metrics to Microsoft Azure Tables. So if this kill happens these metrics get lost. The impact is that for many MR jobs we don't see accurate metrics reported most of the time."
MAPREDUCE-5329,APPLICATION_INIT is never sent to AuxServices other than the builtin ShuffleHandler,"APPLICATION_INIT is never sent to AuxServices other than the built-in ShuffleHandler.  This means that 3rd party ShuffleProvider(s) will not be able to function, because APPLICATION_INIT enables the AuxiliaryService to map jobId->userId. This is needed for properly finding the MOFs of a job per reducers' requests.

NOTE: The built-in ShuffleHandler does get APPLICATION_INIT events due to hard-coded expression in hadoop code. The current TaskAttemptImpl.java code explicitly call: serviceData.put (ShuffleHandler.MAPREDUCE_SHUFFLE_SERVICEID, ...) and ignores any additional AuxiliaryService. As a result, only the built-in ShuffleHandler will get APPLICATION_INIT events.  Any 3rd party AuxillaryService will never get APPLICATION_INIT events.


I think a solution can be in one of two ways:
1. Change TaskAttemptImpl.java to loop on all Auxiliary Services and register each of them, by calling serviceData.put (…) in loop.
2. Change AuxServices.java similar to the fix in: MAPREDUCE-2668  ""APPLICATION_STOP is never sent to AuxServices"".  This means that in case the 'handle' method gets APPLICATION_INIT event it will demultiplex it to all Aux Services regardless of the value in event.getServiceID().

I prefer the 2nd solution.  I am welcoming any ideas.  I can provide the needed patch for any option that people like.

See [Pluggable Shuffle in Hadoop documentation|http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/PluggableShuffleAndPluggableSort.html]
"
MAPREDUCE-5328,ClientToken should not be set in the environment,This is to track Map Reduce related changes. related to YARN-610
MAPREDUCE-5327,TestMRJobs and TestUberAM fail at verifying counters,"See the test report in YARN-829 and YARN-830:
* https://builds.apache.org/job/PreCommit-YARN-Build/1269//testReport/
* https://builds.apache.org/job/PreCommit-YARN-Build/1270//testReport/

The failure seems to be related to:

{code}
Assert
        .assertTrue(counters.findCounter(JobCounter.SLOTS_MILLIS_MAPS) != null
            && counters.findCounter(JobCounter.SLOTS_MILLIS_MAPS).getValue() != 0);
{code}

in TestMRJobs."
MAPREDUCE-5326,Add version to shuffle header,We need to add a version to the shuffle header to allow for forward-compatibility etc.
MAPREDUCE-5325,ClientRMProtocol.getAllApplications should accept ApplicationType as a parameter---MR changes,
MAPREDUCE-5323,Min Spills For Combine Ignored,"We've observed for some time that combiners always run when specified. However there is a config called mapreduce.map.combine.minspills which sort of implies that the developer or administrator ought to be able to control when combiners are invoked.

I spelunked into the code and found this gem in MapTask.java:

if (combinerRunner == null || numSpills < minSpillsForCombine) { Merger.writeFile(kvIter, writer, reporter, job); } else { combineCollector.setWriter(writer); combinerRunner.combine(kvIter, combineCollector); }

That looks way buggy to me. If ( A || B ) is made false by A then B is never executed. I spelunked around the code some more and it looks like combinerRunner is never null except on reflection failure. So it looks like the intention is for minSpillsForCombine to be respected, but due to this logic error it's totally ignored."
MAPREDUCE-5319,Job.xml file does not has 'user.name' property for Hadoop2,"Run a sleep job and look for job.xml file generated by sleep job. 

It does not contain ""user.name"" property."
MAPREDUCE-5318,Ampersand in JSPUtil.java is not escaped,"The malformed urls cause hue crash. The malformed urls are caused by the unescaped ampersand ""&"". "
MAPREDUCE-5317,Stale files left behind for failed jobs,"Courtesy [~amar_kamat]!
{quote}
We are seeing _temporary files left behind in the output folder if the job
fails.
The job were failed due to hitting quota issue.
I simply ran the randomwriter (from hadoop examples) with the default setting.
That failed and left behind some stray files.
{quote}"
MAPREDUCE-5316,job -list-attempt-ids command does not handle illegal task-state,"Courtesy : [~mikanboy]
{quote}
job -list-attempt-ids command should handle illegal argument for <task-state>
the same way as <task-type>.  Right now only illegal <task-type> is handle by
an exception being thrown. Illegal <task-state> on the other hand does not
throw exception. For example is a user mistype 'completed' as 'complete', they
may wrongly think there are no completed tasks, instead of being notified of
the illegal <task-state> that was used.

1) illegal <task-type> handled.

[philips@gwbl2003:4095 ~/svn/HadoopQEAutomation/branch-23]$
/home/gs/gridre/yroot.theoden/share/hadoop/bin/mapred job -list-attempt-ids
job_1345673924741_0086 map completed
12/08/24 15:16:31 WARN conf.Configuration: mapred.used.genericoptionsparser is
deprecated. Instead, use mapreduce.client.genericoptionsparser.used
Exception in thread ""main"" java.lang.IllegalArgumentException: No enum const
class org.apache.hadoop.mapreduce.TaskType.map
        at java.lang.Enum.valueOf(Enum.java:196)
        at org.apache.hadoop.mapreduce.TaskType.valueOf(TaskType.java:27)
        at org.apache.hadoop.mapreduce.tools.CLI.displayTasks(CLI.java:553)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:309)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1242)


1) illegal <task-state> not handled.

/home/gs/gridre/yroot.theoden/share/hadoop/bin/mapred job -list-attempt-ids
job_1345673924741_0086 MAP complete
12/08/24 15:15:47 WARN conf.Configuration: mapred.used.genericoptionsparser is
deprecated. Instead, use mapreduce.client.genericoptionsparser.used
{quote}
Also,we could make input task-state to be case-insensitive to be consistent with
task-type behavior(MAPREDUCE-4019).
"
MAPREDUCE-5315,DistCp reports success even on failure.,"DistCp doesn't check the job-status when run in blocking-mode, before returning its exit-code. (The Yahoo-internal version did this correctly.)

In blocking-mode, DistCp must check that the launched job runs to completion, and return an appropriate exit-code.

Pretty serious bug, since it affects data integrity, in Oozie-launched-DistCp actions.

(I could've sworn I had another JIRA with this patch attached.)"
MAPREDUCE-5312,TestRMNMInfo is failing,"2 test methods are failing:

{code}
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 13.904 sec <<< FAILURE!
testRMNMInfo(org.apache.hadoop.mapreduce.v2.TestRMNMInfo)  Time elapsed: 198 sec  <<< ERROR!
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.TestRMNMInfo.testRMNMInfo(TestRMNMInfo.java:121)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

testRMNMInfoMissmatch(org.apache.hadoop.mapreduce.v2.TestRMNMInfo)  Time elapsed: 146 sec  <<< ERROR!
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.TestRMNMInfo.testRMNMInfoMissmatch(TestRMNMInfo.java:159)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)


Results :

Tests in error: 
  testRMNMInfo(org.apache.hadoop.mapreduce.v2.TestRMNMInfo)
  testRMNMInfoMissmatch(org.apache.hadoop.mapreduce.v2.TestRMNMInfo)
{code}"
MAPREDUCE-5311,Remove SLOTS_MILLIS counters,Per discussion in MAPREDUCE-5310 and comments in the code we should remove all the related logic and just leave the counter constant for backwards compatibility and deprecate the counter constants.
MAPREDUCE-5310,MRAM should not normalize allocation request capabilities,"The MRAM is assuming knowledge of the scheduler internals to normalize allocation request capabilities.

Per discussions in YARN-689 and YARN-769 it should not do that.
"
MAPREDUCE-5309,2.0.4 JobHistoryParser can't parse certain failed job history files generated by 2.0.3 history server,"When the 2.0.4 JobHistoryParser tries to parse a job history file generated by hadoop 2.0.3, the jobhistoryparser throws as an error as

java.lang.ClassCastException: org.apache.avro.generic.GenericData$Array cannot be cast to org.apache.hadoop.mapreduce.jobhistory.JhCounters
    at org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletion.put(TaskAttemptUnsuccessfulCompletion.java:58)
    at org.apache.avro.generic.GenericData.setField(GenericData.java:463)
    at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:166)
    at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:138)
    at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:142)
    at org.apache.avro.generic.GenericDatumReader.readRecord(GenericDatumReader.java:166)
    at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:138)
    at org.apache.avro.generic.GenericDatumReader.read(GenericDatumReader.java:129)
    at org.apache.hadoop.mapreduce.jobhistory.EventReader.getNextEvent(EventReader.java:93)
    at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:111)
    at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:156)
    at org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.parse(JobHistoryParser.java:142)
    at com.twitter.somepackage.Test20JobHistoryParsing.testFileAvro(Test20JobHistoryParsing.java:23)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
    at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)


Test code and the job history file are attached.

Test code:
package com.twitter.somepackagel;

import java.io.IOException;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser;
import org.apache.hadoop.mapreduce.jobhistory.JobHistoryParser.JobInfo;
import org.junit.Test;
import org.apache.hadoop.yarn.YarnException;

public class Test20JobHistoryParsing {
   
  @Test
  public void testFileAvro() throws IOException
  {
      Path local_path2 = new Path(""/tmp/job_2_0_3-KILLED.jhist"");
     JobHistoryParser parser2 = new JobHistoryParser(FileSystem.getLocal(new Configuration()), local_path2);
     try {
       JobInfo ji2 = parser2.parse();
       System.out.println("" job info: "" + ji2.getJobname() + "" ""
             + ji2.getFinishedMaps() + "" ""
             + ji2.getTotalMaps() + "" ""
             + ji2.getJobId() ) ;
     }
     catch (IOException e) {
        throw new YarnException(""Could not load history file ""
           + local_path2.getName(), e);
     }
  }
}

This seems to stem from the fix in https://issues.apache.org/jira/browse/MAPREDUCE-4693
that added counters to the historyserver  for failed tasks.

This breaks backward compatibility with JobHistoryServer. 

"
MAPREDUCE-5308,Shuffling to memory can get out-of-sync when fetching multiple compressed map outputs,"When a reducer is fetching multiple compressed map outputs from a host, the fetcher can get out-of-sync with the IFileInputStream, causing several of the maps to fail to fetch.

This occurs because decompressors can return all the decompressed bytes before actually processing all the bytes in the compressed stream (due to checksums or other trailing data that we ignore). In the unfortunate case where these extra bytes cross an io.file.buffer.size boundary, some extra bytes will be left over and the next map_output will not fetch correctly (usually due to an invalid map_id).

This scenario is not typically fatal to a job because the failure is charged to the map_output immediately following the ""bad"" one and the subsequent retry will normally work. "
MAPREDUCE-5304,mapreduce.Job killTask/failTask/getTaskCompletionEvents methods have incompatible signature changes,"Pointed out by [~zjshen] in MAPREDUCE-4942.

In {{o.a.h.mapreduce.Job}} class, the following changed from Hadoop 1 to Hadoop 2.

boolean failTask(TaskAttemptID): Change in return type from void to boolean.
boolean killTask(TaskAttemptID): Change in return type from void to boolean.
TaskCompletionEvent[] getTaskCompletionEvents(int): Change in return type from org.apache.hadoop.mapred.TaskCompletionEvent[] to org.apache.hadoop.mapreduce.TaskCompletionEvent[].


Using same rational as in other JIRAs, we should fix this to ensure Hadoop 1 to Hadoop 2 source compatibility (taking 0.23.x releases as a casualty as there is not right way for everybody because we screwed up :( ). Flagging it as incompatible change because of 0.23."
MAPREDUCE-5303,Changes on MR after moving ProtoBase to package impl.pb on YARN-724,
MAPREDUCE-5301,Update MR code to work with YARN-635 changes,
MAPREDUCE-5300,Two function signature changes in filecache.DistributedCache,"Two more incompatibility issues:

* long[] getArchiveTimestamps(Configuration) -> String[] getArchiveTimestamps(Configuration)
* long[] getFileTimestamps(Configuration) -> String[] getFileTimestamps(Configuration)

Changes will break 0.23

*Move the add-on patch of MAPREDUCE-5263 here.*"
MAPREDUCE-5299,Mapred API: void setTaskID(TaskAttemptID) is missing in TaskCompletionEvent ,Move the add-on patch of MAPREDUCE-5220 here.
MAPREDUCE-5298,Move MapReduce services to YARN-117 stricter lifecycle,The MR services need to be in sync with the YARN-117 lifecycle enhancements
MAPREDUCE-5297,Update MR App  since BuilderUtils is moved to yarn-server-common after YARN-748,
MAPREDUCE-5296,Mapred API: Function signature change in JobControl,String addJob(Job) -> String addJob(ControlledJob)
MAPREDUCE-5295,ShuffleConsumerPlugin.Context should remove unused combiner-related methods and fields,"ShuffleConsumerPlugin.Context only supports org.apache.hadoop.mapred.Reducer currently. Because of this, Reduce side Combiner is not used when using the new API, and just ignored. Please see MAPREDUCE-5221 for more detail.

(Update Jun. 7th,  2013)  The latest version of MergeManagerImpl in MAPREDUCE-5294 never calls ShuffleConsumerPlugin.Context#getCombinerClass() as [~masokan] pointed out. Because of this, combinerClass field and getCombinerClass() method should be removed from ShuffleConsumerPlugin.Context."
MAPREDUCE-5294,Shuffle#MergeManager should support org.apache.hadoop.mapreduce.Reducer,"Shuffle#MergeManager only accepts org.apache.hadoop.mapred.Reducer currently. Because of this, Reduce-side Combiner is not used when using the new API, and just ignored. By supporting it and using the feature from ReduceTask, Reduce-side combiner can be enabled with new API. Please see MAPREDUCE-5221 for more detail."
MAPREDUCE-5293,Shuffle#MergeManager should support org.apache.hadoop.mapreduce.Reducer,"Shuffle#MergeManager only accepts org.apache.hadoop.mapred.Reducer currently. Because of this, Reduce-side Combiner is not used when using the new API, and just ignored. By supporting it and using the feature from ReduceTask, Reduce-side combiner can be enabled with new API. Please see MAPREDUCE-5221 for more detail."
MAPREDUCE-5292,ShuffleConsumerPlugin.Context should support org.apache.hadoop.mapreduce.Reducer,"ShuffleConsumerPlugin.Context only supports org.apache.hadoop.mapred.Reducer currently. Because of this, Reduce side Combiner is not used when using the new API, and just ignored. Please see MAPREDUCE-5221 for more detail."
MAPREDUCE-5291,Change MR App to use update property names in container-log4j.properties,
MAPREDUCE-5289,Update MR App to use Token directly after YARN-717,Ticket for tracking MR changes after YARN-717.
MAPREDUCE-5288,ResourceEstimator#getEstimatedTotalMapOutputSize suffers from divide by zero issues,"The computation in the above mentioned class-method is below:

{code}
      long estimate = Math.round(((double)inputSize * 
          completedMapsOutputSize * 2.0)/completedMapsInputSize);
{code}

Given http://docs.oracle.com/javase/6/docs/api/java/lang/Math.html#round(double), its possible that the returned estimate could be Long.MAX_VALUE if completedMapsInputSize is determined to be zero.

This can be proven with a simple code snippet:

{code}
class Foo {
    public static void main(String... args) {
        long inputSize = 600L + 2;
        long estimate = Math.round(((double)inputSize *
                              1L * 2.0)/0L);
        System.out.println(estimate);
    }
}
{code}

The above conveniently prints out: {{9223372036854775807}}, which is Long.MAX_VALUE (or 8 Exbibytes per MapReduce)."
MAPREDUCE-5286,startContainer call should use the ContainerToken instead of Container [YARN-684],MapReduce counterpart of YARN-684.
MAPREDUCE-5285,"Update MR App to use immutable ApplicationAttemptID, ContainerID, NodeID after YARN-735",
MAPREDUCE-5284,Mapreduce API: CounterGroup changes from non-abstract class to interface,"Therefore, constructors and implemented methods are removed."
MAPREDUCE-5283,Over 10 different tests have near identical implementations of AppContext,"I'm trying to add a method to AppContext for MAPREDUCE-5171, and I have to go into nearly every test file for MR web services to make sure their TestAppContext implements it.  I propose having a common implementation of AppContext that all these tests can use."
MAPREDUCE-5282,Update MR App to use immutable ApplicationID after YARN-716,
MAPREDUCE-5281,Mapreduce API: Counter changes from non-abstract class to interface,"Therefore, significant changes in Counter:

1. Two Constructors are removed;
2. Following methods are removed:
* boolean equals(Object)
* int hashCode()
* void readFields(DataInput)
* void write(DataOutput)

Fix of this issue may break 0.23."
MAPREDUCE-5280,Mapreduce API: ClusterMetrics incompatibility issues with MR1,"1. Constructor has one fewer parameters: numGraylistedTrackers
2. getGrayListedTaskTrackerCount() is removed"
MAPREDUCE-5279,Jobs can deadlock if headroom is limited by cpu instead of memory,"YARN-2 imported cpu dimension scheduling, but MR RMContainerAllocator doesn't take into account virtual cores while scheduling reduce tasks.
This may cause more reduce tasks to be scheduled because memory is enough. And on a small cluster, this will end with deadlock, all running containers are reduce tasks but map phase is not finished. "
MAPREDUCE-5278,Distributed cache is broken when JT staging dir is not on the default FS,"Today, the JobTracker staging dir (""mapreduce.jobtracker.staging.root.dir) is set to point to HDFS, even though other file systems (e.g. Amazon S3 file system and Windows ASV file system) are the default file systems.

For ASV, this config was chosen and there are a few reasons why:

1. To prevent leak of the storage account credentials to the user's storage account; 
2. It uses HDFS for the transient job files what is good for two reasons – a) it does not flood the user's storage account with irrelevant data/files b) it leverages HDFS locality for small files

However, this approach conflicts with how distributed cache caching works, completely negating the feature's functionality.

When files are added to the distributed cache (thru files/achieves/libjars hadoop generic options), they are copied to the job tracker staging dir only if they reside on a file system different that the jobtracker's. Later on, this path is used as a ""key"" to cache the files locally on the tasktracker's machine, and avoid localization (download/unzip) of the distributed cache files if they are already localized.

In this configuration the caching is completely disabled and we always end up copying dist cache files to the job tracker's staging dir first and localizing them on the task tracker machine second.

This is especially not good for Oozie scenarios as Oozie uses dist cache to populate Hive/Pig jars throughout the cluster.

"
MAPREDUCE-5277,Job history completed location cannot be on a file system other than default,mapred.job.tracker.history.completed.location should be configurable to a location on any available file system. This can come handy for cases where HDFS is not the only file system in use. 
MAPREDUCE-5275,Mapreduce API: TokenCache incompatibility issues with MR1,"There're following incompatibility issues:
* Token<DelegationTokenIdentifier> getDelegationToken(Credentials, String) is removed
* Credentials loadTokens(String, Configuration) changes to Credentials loadTokens(String, JobConf)"
MAPREDUCE-5274,Mapreduce API: String toHex(byte[]) is removed from SecureShuffleUtils,String toHex(byte[]) is removed from SecureShuffleUtils in mapreduce after upgrading to M/R 2
MAPREDUCE-5273,Protected variables are removed from CombineFileRecordReader in both mapred and mapreduce,"Two protected variables are removed from CombineFileRecordReader in both mapred and mapreduce:
* FileSystem fs	 
* Class<RecordReader<K, V>> rrClass"
MAPREDUCE-5272,A Minor Error in Javadoc of TestMRWithDistributedCache in Branch-1,"
{code}
/**
  * Tests the use of the
  * {@link org.apache.hadoop.mapreduce.filecache.DistributedCache} within the
  * full MR flow as well as the LocalJobRunner. This ought to be part of the
  * filecache package, but that package is not currently in mapred, so cannot
  * depend on MR for testing.
  */
{code}

It should be org.apache.hadoop.filecache.DistributedCache instead. Branch-1 doesn't have org.apache.hadoop.mapreduce.filecache.DistributedCache"
MAPREDUCE-5270,Migrate from using BuilderUtil factory methods to individual record factory method on MapReduce side," Migrate the factory method on map reduce side.
"
MAPREDUCE-5268,Improve history server startup performance,"The history server can easily take many minutes to startup when there are a significant number of jobs to scan in the done directory.  However the scanning of files is not the bottleneck, rather it's the heavy use of ConcurrentSkipListMap.size in HistoryFileManager.  

ConcurrentSkipListMap.size is a very expensive operation, especially on maps with many entries, as it has to scan every entry to compute the size.  We should avoid calling this method or at least minimize its use."
MAPREDUCE-5266,Ability to refresh retention settings on history server,"It would be very useful if the job and log retention settings of the history server could be refreshed without restarting the history server.  This would include such things as:

* how many to jobs to keep for browsing
* how many jobs to cache
* how long to retain jobs
* how long to retain logs
* how often to check for retention"
MAPREDUCE-5265,History server admin service to refresh user and superuser group mappings,"The history server needs an admin interface with the ability to
1. refresh the super user groups configurations,
2. refresh user to group mappings,
3. refresh its admin acls,
4. get groups given a username 
without requiring a restart of the history server.  This is analogous to the  -refreshSuperUserGroupsConfiguration capabilities provided by hdfs dfsadmin and yarn rmadmin. "
MAPREDUCE-5263,filecache.DistributedCache incompatiblity issues with MR1,"A couple of methods and variables have been removed:

void addLocalArchives(Configuration, String)
void addLocalFiles(Configuration, String)
void createAllSymlink(Configuration, File, File)
FileStatus getFileStatus(Configuration, URI)
long getTimestamp(Configuration, URI)
void setArchiveTimestamps(Configuration, String)
void setFileTimestamps(Configuration, String)
void setLocalArchives(Configuration, String)
void setLocalFiles(Configuration, String)

String CACHE_ARCHIVES
String CACHE_ARCHIVES_SIZES
String CACHE_ARCHIVES_TIMESTAMPS
String CACHE_FILES
String CACHE_FILES_SIZES
String CACHE_FILES_TIMESTAMPS
String CACHE_LOCALARCHIVES
String CACHE_LOCALFILES
String CACHE_SYMLINK"
MAPREDUCE-5261,TestRMContainerAllocator is exiting and failing the build,Recent builds are failing because TestRMContainerAllocator is exiting rather than succeeding or failing.
MAPREDUCE-5260,Job failed because of JvmManager running into inconsistent state,"In our cluster, jobs failed due to randomly task initialization failed because of JvmManager running into inconsistent state and TaskTracker failed to exit:

java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)
	at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)
	at org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)

-------
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:402)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:387)
	at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:192)
	at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:125)
	at org.apache.hadoop.mapred.TaskRunner.launchJvmAndWait(TaskRunner.java:292)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:251)"
MAPREDUCE-5259,TestTaskLog fails on Windows because of path separators missmatch,"Test failure:
{noformat}
Running org.apache.hadoop.mapred.TestTaskLog
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.516 sec <<< FAILURE!
testTaskLog(org.apache.hadoop.mapred.TestTaskLog)  Time elapsed: 409 sec  <<< FAILURE!
junit.framework.AssertionFailedError: null
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at org.apache.hadoop.mapred.TestTaskLog.testTaskLog(TestTaskLog.java:54)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{noformat}"
MAPREDUCE-5257,TestContainerLauncherImpl fails,TestContainerLauncherImpl is hanging and eventually being killed by the surefire timeout which fails a maven test build.
MAPREDUCE-5256,CombineInputFormat isn't thread safe affecting HiveServer,"This was originally fixed as part of MAPREDUCE-5038, but that got reverted now. Which uncovers this issue, breaking HiveServer. Originally reported by [~thejas]."
MAPREDUCE-5252,Fair scheduler should use SchedulerUtils.normalizeRequest,The capacity scheduler and the fifo scheduler use the same normalizeRequest in SchedulerUtils.  The fair scheduler has its own version of this method that does exactly the same thing.  It should use the common one.
MAPREDUCE-5251,Reducer should not implicate map attempt if it has insufficient space to fetch map output,"A job can fail if a reducer happens to run on a node with insufficient space to hold a map attempt's output.  The reducer keeps reporting the map attempt as bad, and if the map attempt ends up being re-launched too many times before the reducer decides maybe it is the real problem the job can fail.

In that scenario it would be better to re-launch the reduce attempt and hopefully it will run on another node that has sufficient space to complete the shuffle.  Reporting the map attempt is bad and relaunching the map task doesn't change the fact that the reducer can't hold the output."
MAPREDUCE-5250,Searching for ';' in JobTracker History throws ArrayOutOfBoundException ,"Searching for ';' in JobTracker History throws ArrayOutOfBoundException 

{noformat}
Problem accessing /jobhistoryhome.jsp. Reason:

    0
Caused by:

java.lang.ArrayIndexOutOfBoundsException: 0
	at org.apache.hadoop.mapred.jobhistoryhome_jsp._jspService(jobhistoryhome_jsp.java:221)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:914)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
{noformat}"
MAPREDUCE-5249,Oozie delegation token renewal fails for MR tokens in branch-1,"When Oozie java action is executed, the following shows up in the job tracker log.
013-05-14 21:51:45,643 ERROR org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal: Exception renewing tokenIdent: 00 07 68 64 70 75 73 65 72 06 6d 61 70 72 65 64 26 6f 6f 7a 69 65 2f 63 6f 6e 64 6f 72 2d 73 65 63 2e 76 65 6e 6b 61 74 2e 6f 72 67 40 76 65 6e 6b 61 74 2e 6f 72 67 8a 01 3e a6 87 5e 5b 8a 01 3e ca 93 e2 5b 02 02, Kind: MAPREDUCE_DELEGATION_TOKEN, Service: 192.168.56.101:50300. Not rescheduled
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.AccessControlException: Client jt/condor-sec.venkat.org@venkat.org tries to renew a token with renewer specified as mapred
at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:267)
at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:3878)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1405)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1401)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1399)
at org.apache.hadoop.ipc.Client.call(Client.java:1118)
at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)
at org.apache.hadoop.mapred.$Proxy8.renewDelegationToken(Unknown Source)
at org.apache.hadoop.mapred.JobClient$Renewer.renew(JobClient.java:578)
at org.apache.hadoop.security.token.Token.renew(Token.java:309)
at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:221)
at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask$1.run(DelegationTokenRenewal.java:217)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
at org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal$RenewalTimerTask.run(DelegationTokenRenewal.java:216)
at java.util.TimerThread.mainLoop(Timer.java:512)
at java.util.TimerThread.run(Timer.java:462)

Setting the renewer to Kerberos Local name does not help because AbstractDelegationTokenIdentifier sets the renewer to Kerberos shortname but JobTracker.renewDelegationToken uses the fullName. This essentially causes the renewal to fail"
MAPREDUCE-5248,Let NNBenchWithoutMR specify the replication factor for its test,"The NNBenchWithoutMR test creates files with a replicationFactorPerFile hard-coded to 1. It'd be nice to be able to specify that on the commandline.

Also, it'd be great if MAPREDUCE-4750 was merged along with this fix. "
MAPREDUCE-5247,FileInputFormat should filter files with '._COPYING_' sufix,"FsShell copy/put creates staging files with '._COPYING_' suffix.  These files should be considered hidden by FileInputFormat.  (A simple fix is to add the following conjunct to the existing hiddenFilter: 
{code}
!name.endsWith(""._COPYING_"")
{code}
After upgrading to CDH 4.2.0 we encountered this bug. We have a legacy data loader which uses 'hadoop fs -put' to load data into hourly partitions.  We also have intra-hourly jobs which are scheduled to execute several times per hour using the same hourly partition as input.  Thus, as the new data is continuously loaded, these staging files (i.e., ._COPYING_) are breaking our jobs (since when copy/put completes staging files are moved).

As a workaround, we've defined a custom input path filter and loaded it with ""mapred.input.pathFilter.class""."
MAPREDUCE-5246,Adding application type to submission context,Adding application type to submission context of map reduce YARN-563
MAPREDUCE-5245,A number of public static variables are removed from JobConf,"A number of public static variables are removed from JobConf:

boolean DEFAULT_MAPREDUCE_RECOVER_JOB	 
String MAPREDUCE_RECOVER_JOB	 	 
String WORKFLOW_ADJACENCY_PREFIX_PATTERN	 
String WORKFLOW_ADJACENCY_PREFIX_STRING	 
String WORKFLOW_ID	 
String WORKFLOW_NAME	 
String WORKFLOW_NODE_NAME	 
String WORKFLOW_TAGS

The workflow related variables are moved to MRJobConfig.

The follwing public static variables becomes default:

String MAPRED_JOB_MAP_MEMORY_MB_PROPERTY	 
String MAPRED_JOB_REDUCE_MEMORY_MB_PROPERTY

The variables there are no longer referred internally in 2.x, but they might be used by users as they were public."
MAPREDUCE-5244,Two functions changed their visibility in JobStatus,"Two functions change their visibility in JobStatus from public to protected:

void setRunState(int)
void setSchedulingInfo(String)"
MAPREDUCE-5243,MRAdmin is removed from M/R while RMAdmin is added to Yarn,"Though in the 2.x mapred script, MRAdmin will not be called, MRAdmin class is better to be there in case users call it programmatically. "
MAPREDUCE-5240,inside of FileOutputCommitter the initialized Credentials cache appears to be empty,"I am attaching a modified wordcount job that clearly demonstrates the problem we've encountered in running Sqoop2 on YARN (BIGTOP-949).

Here's what running it produces:

{noformat}
$ hadoop fs -mkdir in
$ hadoop fs -put /etc/passwd in
$ hadoop jar ./bug.jar org.myorg.LostCreds
13/05/12 03:13:46 WARN mapred.JobConf: The variable mapred.child.ulimit is no longer used.
numberOfSecretKeys: 1
numberOfTokens: 0
..............
..............
..............
13/05/12 03:05:35 INFO mapreduce.Job: Job job_1368318686284_0013 failed with state FAILED due to: Job commit failed: java.io.IOException:
numberOfSecretKeys: 0
numberOfTokens: 0
	at org.myorg.LostCreds$DestroyerFileOutputCommitter.commitJob(LostCreds.java:43)
	at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.handleJobCommit(CommitterEventHandler.java:249)
	at org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler$EventProcessor.run(CommitterEventHandler.java:212)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
{noformat}

As you can see, even though we've clearly initialized the creds via:

{noformat}
job.getCredentials().addSecretKey(new Text(""mykey""), ""mysecret"".getBytes());
{noformat}

It doesn't seem to appear later in the job.

This is a pretty critical issue for Sqoop 2 since it appears to be DOA for YARN in Hadoop 2.0.4-alpha"
MAPREDUCE-5239,Update MR App to reflect YarnRemoteException changes after YARN-634,YARN-634 is making YarnRemoteException to be not backed by PB anymore. Need some MR changes because of that. Tracking MR changes from the patch at YARN-634.
MAPREDUCE-5237,ClusterStatus incompatiblity issues with MR1,"The three functions are:

Collection<String> getGraylistedTrackerNames()
int getGraylistedTrackers()
State getJobTrackerState()

The're tracker related, such that they are no longer used in MR2. Maybe we should add them and throw UnsupportedOperationException?

In addition, UNINITIALIZED_MEMORY_VALUE changes from long to int"
MAPREDUCE-5236,references to JobConf.DISABLE_MEMORY_LIMIT don't make sense in the context of MR2,"In MR1, a special value of -1 could be given for mapreduce.job.map|reduce.memory.mb when memory limits were disabled.  In MR2, this makes no sense, as with slots gone, this value is used for requesting resources and scheduling."
MAPREDUCE-5235,mapred.Counters incompatiblity issues with MR1,MAX_GROUP_LIMIT is removed from Counters in mapred in MR2. Though it seems not to be the variable that will be referred by the user code. It was actually configurable value MR1. We should investigate why the upper bound doesn't need to be checked in MR2.
MAPREDUCE-5234,Signature changes for getTaskId of TaskReport in mapred,"TaskReport in mapred of MR2 extends TaskReport in mapreduce, and inherits getTaskId, which return TaskID object. in MR1, this function returns String."
MAPREDUCE-5233,Functions are changed or removed from Job in jobcontrol,"The functions are removed from Job in jobcontrol:

1. setMapredJobID(String)
2. setState(int)

The function signatures are changed:

1. addDependingJob(ControlledJob)
2. getMapredJobID()"
MAPREDUCE-5232,log classpath and other key properties on child JVM start,"It would be great if we log vital information such as classpath, etc. upon a mapreduce child JVM start. This would help a great deal in terms of troubleshooting classpath issues, etc. Today it is pretty difficult to debug this unless you preserve the container script.

Maybe it can log things like classpath, os name/version, java version, etc. at the beginning of the child JVM start."
MAPREDUCE-5231,Constructor of DBInputFormat.DBRecordReader in mapred is changed,"The constructor of DBInputFormat.DBRecordReader in mapred is changed from MR1 to RM2. Though MAPREDUCE-716 tried to deal with the API difference. However, if DBInputFormat.DBRecordReader is extended, the incompatibility around the constructor is still there."
MAPREDUCE-5230,createFileSplit is removed from NLineInputFormat of mapred,"createFileSplit is removed from NLineInputFormat of mapred, because it's no longer used in the new getSplit implementation. However, since function is protected before, there is still the potential risk that the user defined format class which extends old NLineInputFormat uses the protected function."
MAPREDUCE-5229,TEMP_DIR_NAME is removed from of FileOutputCommitter of mapreduce,"TEMP_DIR_NAME is removed from of FileOutputCommitter of mapreduce. As FileOutputFormat and FileOutputCommitter may be extend by users, and the extended user classes can configured to use. Therefore, this missing public static variable may cause compatibility problem when the extended classes refer it."
MAPREDUCE-5228,Enum Counter is removed from FileInputFormat and FileOutputFormat of both mapred and mapreduce,"The enum was used by findCounter(Enum key) to find a specific counter object. Now it seems to be replaced by FileInputFormatCounter and FileOutputFormatCounter. Now the enum seems to be only used internally, but not sure whether it will be used externally when users extend FileXXXXFormat."
MAPREDUCE-5227,JobTrackerMetricsSource and QueueMetrics should standardize naming rules,"JobTrackerMetricsSource and QueueMetrics provides users with some metrics, but its naming rules( ""jobs_running"", ""running_maps"", ""running_reduces"") sometimes confuses users. It should be standardized.

One concern is backward compatibility, so one idea is to share MetricMutableGaugeInt object from old and new property name.
e.g. to share runningMaps from ""running_maps"" and ""maps_running""."
MAPREDUCE-5226,Handle exception related changes in YARN's AMRMProtocol api after YARN-630,
MAPREDUCE-5224,JobTracker should allow the system directory to be in non-default FS," JobTracker today expects the system directory to be in the default file system
        if (fs == null) {
          fs = mrOwner.doAs(new PrivilegedExceptionAction<FileSystem>() {
            public FileSystem run() throws IOException {
              return FileSystem.get(conf);
          }});
        }


...

  public String getSystemDir() {
    Path sysDir = new Path(conf.get(""mapred.system.dir"", ""/tmp/hadoop/mapred/system""));  
    return fs.makeQualified(sysDir).toString();
  }
In Cloud like Azure the default file system is set as ASV (Windows Azure Blob Storage), but we would still like the system directory to be in DFS. We should change JobTracker to allow that.
"
MAPREDUCE-5222,Fix JobClient incompatibilities with MR1,"JobClient is missing the following two public methods we need to add for binary compatibility:

# static isJobDirValid(Path, FileSystem)
# Path getStagingAreaDir()"
MAPREDUCE-5220,Mapred API: TaskCompletionEvent incompatibility issues with MR1,"1. Setter methods in TaskCompletionEvent are public in MR1 and protected in MR2.

2. void setTaskID(TaskAttemptID) is missing."
MAPREDUCE-5219,JobStatus#getJobPriority changed to JobStatus#getPriority in MR2,We should change it back for compatibility
MAPREDUCE-5218,Annotate (comment) internal classes as Private,"The following classes are intended for internal use and it would be nice to explicitly state that in comments/annotation.

# TaskUmbilicalProtocol
# TaskInProgress
# MapReducePolicyProvider
# MRAdmin?"
MAPREDUCE-5217,DistCp fails when launched by Oozie in a secure cluster,"As mentioned in MAPREDUCE-4324, Oozie has the following boilerplate code in
in the main launcher for Pig, Hive, MR and Sqoop actions.

if (System.getenv(""HADOOP_TOKEN_FILE_LOCATION"") != null) {
            jobConf.set(""mapreduce.job.credentials.binary"", System.getenv(""HADOOP_TOKEN_FILE_LOCATION""));
}

For Java action, which does not have a main launcher in oozie, the above codecan be added by the user as the user purportedly has the code that is launched.

But for DistCp action, the user has no such luxury.  The solution attempted in
MAPREDUCE-4324 would have helped DistCp, but it was not implemented as it would break MAPREDUCE-3727.  So, we have to fix DistCp and
add the same boilerplate code so that DistCp action can be launched by Oozie
in a secure cluster.

The code added checks for an System env. variable to be set which is not
typically set in normal command line execution of DistCp,  DistCp runs fine
with commnad  line usage both in secure and non-secure cluster."
MAPREDUCE-5215,mapreduce.Job is missing getJobClient() so its incompatible with MR1,"The method {{org.apache.hadoop.mapred.JobClient getJobClient()}} is in MR1's {{mapreduce.Job}} but doesn't exist in MR2's, which makes them incompatible.  MR2's implementation of {{Job}} doesn't use a JobClient object, but we can create one and return it."
MAPREDUCE-5214,Compatibility: Add a deprecated MRAdmin that wraps around RMAdmin,"MRAdmin doesn't apply to MR2. However, to maintain compatibility against 1.x releases, it might be a good idea to add a deprecated version of MRAdmin that wraps around RMAdmin, prints out a deprecated message and calls the relevant RMAdmin methods."
MAPREDUCE-5213,Re-assess TokenCache methods marked @Private,"While looking at the source, noticed that TokenCache#loadTokens methods are marked @Private but not used anywhere. 

We should either remove those methods or mark them Public or LimitedPrivate."
MAPREDUCE-5212,Handle exception related changes in YARN's ClientRMProtocol api after YARN-631,
MAPREDUCE-5211,Reducer intermediate files can collide during merge,"The OnDiskMerger.merge method constructs an output path that is not unique to a reduce attempt, and as a result can result in a file collision with other reducers from the same app that are running on the same node.  In addition the name of the output file is based on MapOutput.toString which may not be unique in light of multi-pass merges on disk since the mapId will be null and the basename ends up as ""MapOutput(null, DISK)"""
MAPREDUCE-5209,ShuffleScheduler log message incorrect,"In ShuffleScheduler.java line 361 log message is incorrect, there should be ""ms"" instead of ""s"".

    LOG.info(host + "" freed by "" + Thread.currentThread().getName() + "" in "" + 
             (System.currentTimeMillis()-shuffleStart.get()) + ""ms"");

"
MAPREDUCE-5208,SpillRecord and ShuffleHandler should use SecureIOUtils for reading index file and map output,ShuffleHandler (map output file) and SpillRecord (index file) are reading file using unsecured input stream. There exists a possibility for symlink attack. related to YARN-578 . Creating this issue to track map reduce changes.
MAPREDUCE-5207,Add mapreduce.{map|reduce}.memory.mb defaults to mapred-default.xml,mapred-default.xml is missing defaults for mapredue.{map|reduce}.memory.mb
MAPREDUCE-5206,JT can show the same job multiple times in Retired Jobs section,JT can show the same job multiple times in Retired Jobs section since the RetireJobs thread has a bug which adds the same job multiple times to collection of retired jobs.
MAPREDUCE-5205,Apps fail in secure cluster setup,"Found at YARN-579 by [~daryn]. Need to investigate if it was caused by YARN-579 itself or something else.

Secure setup on trunk passes though."
MAPREDUCE-5204,Handle YarnRemoteException separately from IOException in MR api ,"YarnRemoteException is not rooted as IOException, so in MR api, we need to handle them separately from IOException"
MAPREDUCE-5202,Revert MAPREDUCE-4397 to avoid using incorrect config files,"MAPREDUCE-4397 added the capability to switch the location of the taskcontroller.cfg file, which weakens security."
MAPREDUCE-5199,AppTokens file can/should be removed,"All the required tokens are propagated to AMs and containers via startContainer(), no need for explicitly creating the app-token file that we have today.."
MAPREDUCE-5198,Race condition in cleanup during task tracker renint with LinuxTaskController,"This was noticed when job tracker would be restarted while jobs were running and would ask the task tracker to reinitialize. 

Tasktracker would fail with an error like

{code}
013-04-27 20:19:09,627 INFO org.apache.hadoop.mapred.TaskTracker: Good mapred local directories are: /grid/0/hdp/mapred/local,/grid/1/hdp/mapred/local,/grid/2/hdp/mapred/local,/grid/3/hdp/mapred/local,/grid/4/hdp/mapred/local,/grid/5/hdp/mapred/local
2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075 caught: java.nio.channels.ClosedChannelException
	at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:133)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)
	at org.apache.hadoop.ipc.Server.channelWrite(Server.java:1717)
	at org.apache.hadoop.ipc.Server.access$2000(Server.java:98)
	at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:744)
	at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:808)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1433)

2013-04-27 20:19:09,628 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 42075: exiting
2013-04-27 20:19:10,414 ERROR org.apache.hadoop.mapred.TaskTracker: Got fatal exception while reinitializing TaskTracker: org.apache.hadoop.util.Shell$ExitCodeException: 
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:255)
	at org.apache.hadoop.util.Shell.run(Shell.java:182)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:375)
	at org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:281)
	at org.apache.hadoop.mapred.TaskTracker.deleteUserDirectories(TaskTracker.java:779)
	at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:816)
	at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2704)
	at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3934)
{code} "
MAPREDUCE-5197,Checkpoint Service: a library component to facilitate checkpoint of task state,A small library that abstract file API for the purpose of checkpointing. 
MAPREDUCE-5196,CheckpointAMPreemptionPolicy implements preemption in MR AM via checkpointing ,"This JIRA tracks a checkpoint-based AM preemption policy. The policy handles propagation of the preemption requests received from the RM to the appropriate tasks, and bookeeping of checkpoints. Actual checkpointing of the task state is handled in upcoming JIRAs."
MAPREDUCE-5194,Heed interrupts during Fetcher shutdown,"In the current implementation, {{Fetcher}} instances usually exit gracefully when the shuffle succeeds. When it fails, threads are interrupted, but may continue running harmlessly until the JVM shuts down.

However, to generate consistent checkpoints, these threads should exit cleanly to quiesce the state of the shuffle."
MAPREDUCE-5193,A few MR tests use block sizes which are smaller than the default minimum block size,HDFS-4305 introduced a new configurable minimum block size of 1MB. A few MR tests deliberately set much smaller block sizes. This JIRA is to update those tests to fix these failing tests.
MAPREDUCE-5192,Separate TCE resolution from fetch,"The {{EventFetcher}} thread grounds task completion events as URIs before passing them to the {{ShuffleScheduler}}. If the former deferred this to the scheduler, one could interpret the TCE metadata differently"
MAPREDUCE-5191,TestQueue#testQueue fails with timeout on Windows,"Test times out on my machine after 5 seconds always on the below stack:

{code}
testQueue(org.apache.hadoop.mapred.TestQueue)  Time elapsed: 5009 sec  <<< ERROR!
java.lang.Exception: test timed out after 5000 milliseconds
	at java.lang.Object.wait(Native Method)
	at java.lang.Object.wait(Object.java:485)
	at sun.security.provider.SeedGenerator$ThreadedSeedGenerator.getSeedByte(SeedGenerator.java:330)
	at sun.security.provider.SeedGenerator$ThreadedSeedGenerator.getSeedBytes(SeedGenerator.java:319)
	at sun.security.provider.SeedGenerator.generateSeed(SeedGenerator.java:117)
	at sun.security.provider.SecureRandom.engineGenerateSeed(SecureRandom.java:114)
	at sun.security.provider.SecureRandom.engineNextBytes(SecureRandom.java:171)
	at java.security.SecureRandom.nextBytes(SecureRandom.java:433)
	at java.security.SecureRandom.next(SecureRandom.java:455)
	at java.util.Random.nextLong(Random.java:284)
	at java.io.File.generateFile(File.java:1682)
	at java.io.File.createTempFile(File.java:1791)
	at java.io.File.createTempFile(File.java:1828)
	at org.apache.hadoop.mapred.TestQueue.writeFile(TestQueue.java:221)
	at org.apache.hadoop.mapred.TestQueue.testQueue(TestQueue.java:53)
{code} 
"
MAPREDUCE-5190,Unnecessary condition test in RandomSampler,"In getSampe method, there is a condition test after ""int ind = r.nextInt(numSamples);"". The test is ""(ind != numSamples)"".
This test is unneeded since nextInt(numSamples) will not return numSamples."
MAPREDUCE-5189,Basic AM changes to support preemption requests (per YARN-45),This JIRA tracks the minimum amount of changes necessary in the mapreduce AM to receive preemption requests (per YARN-45) and invoke a local policy that manages preemption. (advanced policies and mechanisms will be tracked separately)
MAPREDUCE-5188,error when verify FileType of RS_SOURCE in getCompanionBlocks  in BlockPlacementPolicyRaid.java,"error when verify FileType of RS_SOURCE in getCompanionBlocks  in BlockPlacementPolicyRaid.java
need change xorParityLength in line #379 to rsParityLength since it's for verifying RS_SOURCE  type"
MAPREDUCE-5187,Create mapreduce command scripts on Windows,"We don't have mapreduce command scripts, e.g. mapred.cmd, on Windows in trunk code base right now. As a result, some import functionality like Job history server is not available. This JIRA is created to track this issue."
MAPREDUCE-5186,mapreduce.job.max.split.locations causes some splits created by CombineFileInputFormat to fail,"CombineFileInputFormat can easily create splits that can come from many different locations (during the last pass of creating ""global"" splits). However, we observe that this often runs afoul of the mapreduce.job.max.split.locations check that's done by JobSplitWriter.

The default value for mapreduce.job.max.split.locations is 10, and with any decent size cluster, CombineFileInputFormat creates splits that are well above this limit."
MAPREDUCE-5184,Document MR Binary Compatibility vis-a-vis hadoop-1 and hadoop-2,
MAPREDUCE-5183,"In, TaskTracker#reportProgress logging of 0.0-1.0 progress is followed by percent sign",This makes looking at progress in the logs unnecessarily confusing.  It would probably look prettiest to keep the percentage sign and have the numbers between 0 and 100.
MAPREDUCE-5182,LineRecordReader#getProgress throwing IOException breaks compatibility,"This has been in trunk for a while (since MAPREDUCE-773), but was only introduced into branch-1 in July."
MAPREDUCE-5181,RMCommunicator should not use AMToken from the env,
MAPREDUCE-5180,"Running wordcount with ""-Ddfs.client.read.shortcircuit=true/false"" fails to get proper message on syslogs","Running wordcount job with -Ddfs.client.read.shortcircuit=true/false fails to mention ""hdfs.DFSClient: Short circuit read is true"" or ""hdfs.DFSClient: Short circuit read is false"" messages in syslogs. 

Attaching screen shot of syslog output for Hadoop 1.1.2. The above message was present in the logs earlier.

Syslog Output of Hadoop 1.3
2013-04-18 13:07:08,265 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2013-04-18 13:07:10,002 INFO org.apache.hadoop.util.ProcessTree: setsid exited with exit code 0
2013-04-18 13:07:10,577 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorPlugin : org.apache.hadoop.util.LinuxResourceCalculatorPlugin@4edc41c5
2013-04-18 13:07:10,682 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://node1:port1/input1.txt:0+215754
2013-04-18 13:07:10,706 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 200
2013-04-18 13:07:10,910 INFO org.apache.hadoop.mapred.MapTask: data buffer = 150994944/167772160
2013-04-18 13:07:10,910 INFO org.apache.hadoop.mapred.MapTask: record buffer = 2359296/2621440
2013-04-18 13:07:10,920 WARN org.apache.hadoop.io.compress.snappy.LoadSnappy: Snappy native library is available
2013-04-18 13:07:10,920 INFO org.apache.hadoop.io.compress.snappy.LoadSnappy: Snappy native library loaded
2013-04-18 13:07:10,934 INFO com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library
2013-04-18 13:07:10,947 INFO com.hadoop.compression.lzo.LzoCodec: Successfully loaded &amp; initialized native-lzo library [hadoop-lzo rev cf4e7cbf8ed0f0622504d008101c2729dc0c9ff3]
2013-04-18 13:07:11,414 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2013-04-18 13:07:11,586 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor
2013-04-18 13:07:11,962 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2013-04-18 13:07:12,034 INFO org.apache.hadoop.mapred.Task: Task:attempt_201304181305_0001_m_000000_0 is done. And is in the process of commiting
2013-04-18 13:07:12,106 INFO org.apache.hadoop.mapred.Task: Task &apos;attempt_201304181305_0001_m_000000_0&apos; done.
2013-04-18 13:07:12,152 INFO org.apache.hadoop.mapred.TaskLogsTruncater: Initializing logs&apos; truncater with mapRetainSize=-1 and reduceRetainSize=-1
2013-04-18 13:07:12,637 INFO org.apache.hadoop.io.nativeio.NativeIO: Initialized cache for UID to User mapping with a cache timeout of 14400 seconds.
2013-04-18 13:07:12,637 INFO org.apache.hadoop.io.nativeio.NativeIO: Got UserName mapred for UID 2002 from the native implementation
"
MAPREDUCE-5179,Change TestHSWebServices to do string equal check on hadoop build version similar to YARN-605,
MAPREDUCE-5178,Fix use of BuilderUtils#newApplicationReport as a result of YARN-577.,
MAPREDUCE-5177,Move to common utils FileUtil#setReadable/Writable/Executable and FileUtil#canRead/Write/Execute,Move to using common utils described in HADOOP-9413 that work well cross-platform.
MAPREDUCE-5176,Preemptable annotations (to support preemption in MR),"Proposing a patch that introduces a new annotation @Checkpointable that represents to the framework property of user-supplied classes (e.g., Reducer, OutputCommiter). The intended semantics is that a tagged class is safe to be preempted between invocations. 

(this is in spirit similar to the Output Contracts of [Nephele/PACT | https://stratosphere.eu/sites/default/files/papers/ComparingMapReduceAndPACTs_11.pdf])"
MAPREDUCE-5175,Update MR App to not set envs that will be set by NMs anyways after YARN-561,"After YARN-561, apps don't need to set specific env variables like container-id etc. This JIRA is to track the MR part of YARN-561."
MAPREDUCE-5171,Expose blacklisted nodes from the MR AM REST API ,It would be useful to expose some the list of nodes that an MR AM has blacklisted.
MAPREDUCE-5170,incorrect exception message if min node size > min rack size,"The exception message for CombineFileInputFormat if min node size > min rack size is worded backwards.

Currently it reads ""Minimum split size per node... cannot be smaller than the minimum split size per rack...""

It should be ""Minimum split size per node... cannot be LARGER than the minimum split size per rack..."""
MAPREDUCE-5169,Job recovery fails if job tracker is restarted after the job is submitted but before its initialized,"This was noticed when within 5 seconds of submitting a word count job, the job tracker was restarted. Upon restart the job failed to recover"
MAPREDUCE-5168,Reducer can OOM during shuffle because on-disk output stream not released,"If a reducer needs to shuffle a map output to disk, it opens an output stream and writes the data to disk.  However it does not release the reference to the output stream within the MapOutput, and the output stream can have a 128K buffer attached to it.  If enough of these on-disk outputs are queued up waiting to be merged, it can cause the reducer to OOM during the shuffle phase.  In one case I saw there were 1200 on-disk outputs queued up to be merged, leading to an extra 150MB of pressure on the heap due to the output stream buffers that were no longer necessary."
MAPREDUCE-5167,Update MR App after YARN-562,Tracking JIRA for MR changes at YARN-562.
MAPREDUCE-5166,ConcurrentModificationException in LocalJobRunner,"With the latest version hive unit tests fail in various places with the following stack trace. The problem seems related to: MAPREDUCE-2931

{noformat}
    [junit] java.util.ConcurrentModificationException
    [junit] 	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
    [junit] 	at java.util.HashMap$ValueIterator.next(HashMap.java:822)
    [junit] 	at org.apache.hadoop.mapred.Counters.incrAllCounters(Counters.java:505)
    [junit] 	at org.apache.hadoop.mapred.Counters.sum(Counters.java:528)
    [junit] 	at org.apache.hadoop.mapred.LocalJobRunner$Job.getCurrentCounters(LocalJobRunner.java:490)
    [junit] 	at org.apache.hadoop.mapred.LocalJobRunner.getJobCounters(LocalJobRunner.java:634)
    [junit] 	at org.apache.hadoop.mapred.JobClient$NetworkedJob.getCounters(JobClient.java:418)
    [junit] 	at org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper$ExecDriverTaskHandle.getCounters(HadoopJobExecHelper.java:465)
    [junit] 	at org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:300)
    [junit] 	at org.apache.hadoop.hive.ql.exec.HadoopJobExecHelper.progress(HadoopJobExecHelper.java:532)
    [junit] 	at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:453)
    [junit] 	at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:681)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    [junit] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    [junit] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    [junit] 	at java.lang.reflect.Method.invoke(Method.java:597)
    [junit] 	at org.apache.hadoop.util.RunJar.main(RunJar.java:160)
{noformat}"
MAPREDUCE-5164,"command  ""mapred job"" and ""mapred queue"" omit HADOOP_CLIENT_OPTS ","HADOOP_CLIENT_OPTS does not take effect when type ""mapred job -list"" and ""mapred queue -list"".
The mapred script omit it "
MAPREDUCE-5163,Update MR App after YARN-441,YARN-441 is removing some collection APIs that are utility methods on top the base APIs. MR App needs to be updated to not use those anymore.
MAPREDUCE-5161,Merge MAPREDUCE-1806 from branch-1 to branch-1-win. CombineFileInputFormat fix for paths not on default FS,MAPREDUCE-1806 fixed a bug related to use of {{CombineFileInputFormat}} with paths that are not on the default file system.  This jira will merge the branch-1 fix to branch-1-win.
MAPREDUCE-5160,Aggregatewordcount and aggregatewordhist in hadoop-1 examples can not find their inner classes when running on Yarn,"Aggregatewordcount and Aggregatewordhist of hadoop-1 cannot run on hadoop-2 due to org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String args[], Class<?> caller) is not available on hadoop-2 (see MAPREDUCE-5159).

After I changed Aggregatewordcount and Aggregatewordhist to use createValueAggregatorJob(String args[], Class<? extends ValueAggregatorDescriptor>[] descriptors), which is available on hadoop-2, the two examples could be accepted and run on Yarn.

However, the two examples still failed, because their inner classes, WordCountPlugInClass and AggregateWordHistogramPlugin, cannot be found in runtime, respectively. Both the plugin classes extend org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorBaseDescriptor."
MAPREDUCE-5159,Aggregatewordcount and aggregatewordhist in hadoop-1 examples are not binary compatible with hadoop-2 mapred.lib.aggregate,"Both examples in hadoop-1 use org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob.createValueAggregatorJob(String args[], Class<?> caller), which no longer exists after upgrading to hadoop-2. Therefore, they cannot not find the accordant function with their function signature in the binary."
MAPREDUCE-5158,Cleanup required when mapreduce.job.restart.recover is set to false,"When mapred.jobtracker.restart.recover is set as true and mapreduce.job.restart.recover is set to false for a MR job, Job clean up never happens for that job if JT restarts while job is running.

.staging and job-info file for that job remains on HDFS forever. "
MAPREDUCE-5157,Sort in hadoop-1 examples is not binary compatible with hadoop-2 mapred.lib,"In SORT example, org.apache.hadoop.mapred.lib.InputSampler.Sampler is used in hadoop-1. However, after upgrading to hadoop-2, org.apache.hadoop.mapred.lib.InputSampler is modified to extend org.apache.hadoop.mapreduce.lib.partition.InputSampler, and the inner class, Sampler, has been moved to the superclass. Therefore, hadoop-1 SORT can not find Sampler when it runs with hadoop-2 framework."
MAPREDUCE-5156,Hadoop-examples-1.x.x.jar cannot run on Yarn,"M/R examples are run through ProgramDriver.driver. ProgramDriver.driver returns void in hadoop-1, while it returns int in hadoop-2. Therefore, the function signatures in the example jar and yarn are incompatible."
MAPREDUCE-5155,Race condition in test case TestFetchFailure cause it to fail,"I run into this once: testFetchFailureWithRecovery(org.apache.hadoop.mapreduce.v2.app.TestFetchFailure): Num completion events not correct expected:<1> but was:<0>

There is a race condition between job.getTaskAttemptCompletionEvents and dealing with JOB_TASK_ATTEMPT_COMPLETED event.
If job.getTaskAttemptCompletionEvents invoked because of task in SUCCEEDED state ,but before JOB_TASK_ATTEMPT_COMPLETED event scheduled,the test case will fail.

"
MAPREDUCE-5154,staging directory deletion fails because delegation tokens have been cancelled,"In a secure setup, the jobtracker needs the job's delegation tokens to delete the staging directory.  MAPREDUCE-4850 made it so that job cleanup staging directory deletion occurs asynchronously, so that it could order it with system directory deletion.  This introduced the issue that a job's delegation tokens could be cancelled before the cleanup thread got around to deleting it, causing the deletion to fail."
MAPREDUCE-5152,MR App is not using Container from RM,The goal of YARN-486 was to make AMs just pass information encapsulated in Container along to NM instead of doing it themselves by duplicating information. We still do not do this pass-through as intended as YARN-486 avoided the individual field duplication but failed to avoid the duplication of container itself.
MAPREDUCE-5151,Update MR App after YARN-444,"YARN-444 is moving standard exit codes from YarnConfiguration into a separate record, creating a tracking ticket for MR only changes."
MAPREDUCE-5150,Backport 2009 terasort (MAPREDUCE-639) to branch-1,"Users evaluate performance of Hadoop clusters using different benchmarks such as TeraSort. However, terasort version in branch-1 is outdated. It works on teragen dataset that cannot exceed 4 billion unique keys and it does not have the fast non-sampling partitioner SimplePartitioner either."
MAPREDUCE-5148,Syslog missing from Map/Reduce tasks,MAPREDUCE-4970 introduced incompatible change and causes syslog to be missing from tasktracker on old clusters which just have log4j.properties configured
MAPREDUCE-5147,Maven build should create hadoop-mapreduce-client-app-VERSION.jar directly,"Currently the build creates mr-app.jar and links it to the proper name.  All hard links to mr-app.jar appear to have been removed.  The maven build should be simplified to directly build the jar.
Related"
MAPREDUCE-5146,application classloader may be used too early to load classes,"At least in the case of YarnChild, the application classloader is set fairly early (both in Configuration and as a TCCL). This has an effect of using the application classloader unexpectedly early.

There is a fair amount of code that gets invoked between setting the classloader and executing mapper/reducer task.

For example, I saw that the application classloader was asked to load a DOM parser class (com.sun.org.apache.xerces...) as part of initializing the filesystem. Luckily, in most cases this would be delegated to the parent classloader as the job classpath would not have those classes.

However, in general, this behavior carries the risk of loading classes with the app classloader accidentally, and potentially causing problems such as ClassCastException. Those would turn into nasty bugs that are hard to fix.

It would be good to either set the application classloader as late as possible or place clearer limitations so it loads only the mapper/reducer classes and their dependencies."
MAPREDUCE-5145,Change default max-attempts to be more than one for MR jobs as well,We need to give the AM of MR jobs the chance to retry.
MAPREDUCE-5143,TestLineRecordReader has no test case for compressed files,TestLineRecordReader was no test case for compressed files
MAPREDUCE-5140,MR part of YARN-514,"In YARN-514, application store needs to be delayed to unblock application submission, such that a new state of MRApp needs to be created. On mapreduce side, there's some function to map yarn states to mapreduce ones. This mapping needs to be updated due to the newly added state."
MAPREDUCE-5139,Update MR App after YARN-486,"MR App needs to be updated after YARN-486 API Changes.

Will try committing this and YARN-486 almost together to not break builds."
MAPREDUCE-5138,Fix LocalDistributedCacheManager after YARN-112,LocalDistributedCacheManager uses FSDownload which is changing in YARN-112. Need to fix it.
MAPREDUCE-5137,AM web UI: clicking on Map Task results in 500 error,"Go to a running mapreduce app master web UI. Click on the job, then click on the MAP task type to bring up the list of maps, then try to click on a particular map task.  It fails with a 500 error.  Note this doesn't exist in 0.23.6.


Exception in the log looks like:

2013-04-09 13:53:01,587 DEBUG [1088374@qtp-13877033-2 - /mapreduce/task/task_1365457322543_0004_m_000000] org.apache.hadoop.yarn.webapp.GenericExceptionHandler: GOT EXCEPITION
com.sun.jersey.api.NotFoundException: null for uri: http://host.com:38158/mapreduce/task/task_1365457322543_0004_m_000000
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1470)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:886)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
	at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:123)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:1069)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
...
...
..."
MAPREDUCE-5136,TestJobImpl->testJobNoTasks fails with IBM JAVA,"I am not sure if this is a testcase or a design issue. During execution of TestJobImpl->testJobNoTasks() there is an assertion made based on the order of key/value pairs stored in adjacency list. However adjacency list was created by Configuration->getValByRegex() as a HashMap (order is not guaranteed):

Testcase:
    JobSubmittedEventHandler jseHandler = new JobSubmittedEventHandler(""testId"",
        ""testName"", ""testNodeName"", ""\""key2\""=\""value2\"" \""key1\""=\""value1\"" "");
   ....
   ....
    try {
      Assert.assertTrue(jseHandler.getAssertValue()); <===

Configuration->getValByRegex():
public Map<String,String> getValByRegex(String regex) {
    Pattern p = Pattern.compile(regex);
    Map<String,String> result = new HashMap<String,String>(); <=======
   

as we all know, HashMap makes absolutely no guarantees about the iteration order. It can (and will) even change completely when new elements are added.

Changing HashMap to LinkedHashMap fixes the ordering inconsistency, however with a small performance side effect. "
MAPREDUCE-5134,Default settings cause LocalJobRunner to OOME,"If I run a job using the local job runner with vanilla settings, I get an out of memory error.  This seems to be because the default client memory maximum is 128 MB, and the default io.sort.mb is 100 MB."
MAPREDUCE-5133,TestSubmitJob.testSecureJobExecution is flaky due to job dir deletion race,"At the end of TestSubmitJob.testSecureJobExecution, the test waits for the job to be done and then asserts that the job submission directory has been deleted.  The directory is deleted by an asynchronous cleanup thread, so the test can hit the assert before the deletion is run.
"
MAPREDUCE-5131,Provide better handling of job status related apis during JT restart,"I've seen pig/hive applications bork during JT restart since they get NPEs - this is due to fact that jobs are not really inited, but are submitted."
MAPREDUCE-5130,Add missing job config options to mapred-default.xml,"I came across that mapreduce.map.java.opts and mapreduce.reduce.java.opts were missing in mapred-default.xml.  I'll do a fuller sweep to see what else is missing before posting a patch.

List so far:
mapreduce.map/reduce.java.opts
mapreduce.map/reduce.memory.mb
mapreduce.job.jvm.numtasks
mapreduce.input.lineinputformat.linespermap
mapreduce.task.combine.progress.records
mapreduce.map/reduce.env
"
MAPREDUCE-5129,Add tag info to JH files,It will be useful to add tags to the existing workflow info logged by JH.  This will allow jobs to be filtered/grouped for analysis more easily.
MAPREDUCE-5128,mapred-default.xml is missing a bunch of history server configs,"mapred-default.xml is missing many configs that work for the job history server.  mapreduce.jobhistory.cleaner.enable, mapreduce.jobhistory.done-dir, and mapreduce.jobhistory.datestring.cache.size are a few examples."
MAPREDUCE-5127,MR job succeeds and exits even when unregister with RM fails,"MR app master will clean staging dir, if the job is already succeeded and asked to reboot. If the finishApplicationMaster call fails, RM will consider this job unfinished and launch further attempts, further attempts will fail because staging dir is cleaned"
MAPREDUCE-5124,AM lacks flow control for task events,"The AM does not have any flow control to limit the incoming rate of events from tasks.  If the AM is unable to keep pace with the rate of incoming events for a sufficient period of time then it will eventually exhaust the heap and crash.  MAPREDUCE-5043 addressed a major bottleneck for event processing, but the AM could still get behind if it's starved for CPU and/or handling a very large job with tens of thousands of active tasks."
MAPREDUCE-5118,Inverted Index,"Inverted-Index takes a list of documents as input and generates word-to-document indexing. Map emits <word, docId> tuples with each word emitted once per docId. Reduce combines all tuples on key <word> and emits <word,docId> tuples after removing duplicates."
MAPREDUCE-5117,With security enabled HS delegation token renewer fails,"It seems that the HSClientProtocolPBClientImpl should implement Closeable as per the attached stack trace. The problem can be observed on a cluster running the latest branch-2.0.4-alpha with MAPREDUCE-5088 applied on top. The easiest way to reproduce it is to run an oozie pig job:

{noformat}
$ oozie job -oozie http://`hostname -f`:11000/oozie -run -DjobTracker=`hostname -f`:8032 -DnameNode=hdfs://`hostname -f`:17020 -DexamplesRoot=examples -config /tmp/examples/apps/pig/job.properties
{noformat}

Please also note that I can successfully submit simple jobs (Pi/Sleep) from a command line using hadoop jar command. Thus it *seems* related to MAPREDUCE-5088 change.
"
MAPREDUCE-5116,PUMA Benchmark Suite,"A benchmark suite which represents a broad range of ""real-world"" MapReduce applications exhibiting application characteristics with high/low computation and high/low shuffle volumes. These benchmarks have been published as part of MaRCO (http://dx.doi.org/10.1016/j.jpdc.2012.12.012) project in JPDC '12."
MAPREDUCE-5115,MR app master may try to assign a reduce priority container to a map,ScheduledRequests.assign() checks reduces.isEmpty() and releases REDUCE priority containers. But it could have received more REDUCE priority containers than reduces.size() in which case it will not release excess REDUCE priority containers. Later on in ScheduledRequests.assignToReduce() it will not be able to assign them to reduces. These containers will fall through to ScheduledRequests.assignMapsWithLocality() where they will get assigned to maps or crash depending on the behavior of Java assert.
MAPREDUCE-5113,Streaming input/output types are ignored with java mapper/reducer,"After MAPREDUCE-1888, with a java mapper or reducer, StreamJob doesn't respect stream.map.output/stream.reduce.output when setting a job's output key/value classes, even if these configs are explicitly set by the user.


As MAPREDUCE-1888 is not in branch-1, this change is only needed in hadoop 2."
MAPREDUCE-5110,Kill task early in case of long task launch delays,"If a task takes too long to launch, the JT expires the task and schedules another attempt. The earlier attempt can start after the later attempt leading to two parallel attempts running at the same time. This is particularly an issue if the user turns off speculation and expects a single attempt of a task to run at any point in time."
MAPREDUCE-5108,Changes needed for Binary Compatibility for MR applications via YARN,"As we get ready to ship out a beta/stable version of hadoop-2, it makes sense to spend time reviewing support for existing MR applications (hadoop-1) to migrate seamlessly.

We've done various pieces of work over time, let's track progress and document things clearly. [~zjshen] has done a bunch of testing and results look very promising so far.

The aim is to support applications using org.apache.hadoop.mapred.* api in a binary compatible manner in hadoop-2 - thus, users can just take existing MR applications jars, point them at YARN clusters and things just work.

Clearly, we might have some corner cases (haven't seen many so far), including semantics (not just apis); however the intent is to, at least, document them throughly if not actually fix them as feasible.

Also, it's clear that we will *not* be able to support org.apache.hadoop.mapreduce api in a *binary compatible* manner due to the interface changes we made in hadoop-0.21 (sigh), and hence, users using the _new_ apis will have to re-compile (i.e. source compatible only). 

Net, given that vast majority of users use the org.apache.hadoop.mapred api, it's a very reasonable way to ease migration to hadoop-2.
"
MAPREDUCE-5106,mapreduce.jobtracker.split.metainfo.maxsize can be set at job level ,"mapreduce.jobtracker.split.metainfo.maxsize gives an impression that this property can be set at JT level only and will require JT restart in case of any modification. But actually this can be set at individual job level.

So either this property should be named properly or should be restricted to JT level only."
MAPREDUCE-5105,Job History Webpage Elapsed Time Column Sort Broken,"The Job History server's table for listing task attempts includes an 'Elapsed Time' column.  It appears this column is being sorted alphabetically instead of numerically.  For example, a duration of 18 minutes is ordered as shorter than a duration of 1 minute.

Example URL:
http://host:port/jobhistory/attempts/job_id/m/SUCCESSFUL"
MAPREDUCE-5102,fix coverage  org.apache.hadoop.mapreduce.lib.db and org.apache.hadoop.mapred.lib.db,"fix coverage  org.apache.hadoop.mapreduce.lib.db and org.apache.hadoop.mapred.lib.db
patch MAPREDUCE-5102-trunk.patch for trunk and branch-2
patch MAPREDUCE-5102-branch-0.23.patch for branch-0.23 only
"
MAPREDUCE-5100,jobconf_history.jsp is not showing job configs in case of retired jobs,"jobconf_history.jsp is not showing job config for retired jobs, even job id mentioned on this page is wrong. As per mapreduce code all this information is calculated from logFile param passed to these jsp, which flows form jobtracker.jsp -> jobdetailshistory.jsp -> jobconf_history.jsp as shown below.

http://localhost:50030/jobdetailshistory.jsp?logFile=file%3A%2FUsers%2Fabhisheg%2Fhadoop%2Flogs%2Fhistory%2Fdone%2Flocalhost_1364233603831_%2F2013%2F02%2F25%2F000000%2Fjob_201303252316_0001_1364233671929_abhisheg_word%2Bcount

http://localhost:50030/jobconf_history.jsp?logFile=file:/Users/abhisheg/hadoop/logs/history/done/localhost_1364233603831_/2013/02/25/000000/job_201303252316_0001_1364233671929_abhisheg_word%2Bcount

----------------------------------- Display on UI

Job Configuration: JobId - 0001_1364233671929_abhisheg

Failed to retreive job configuration for job '0001_1364233671929_abhisheg! java.io.FileNotFoundException: File file:/Users/abhisheg/hadoop/logs/history/done/localhost_1364233603831_/2013/02/25/000000/job_201303252316_0001_1364233671929_abhisheg_conf.xml does not exist
-----------------------------------

actual file is at - /Users/abhisheg/hadoop/logs/history/done/localhost_1364233603831_/2013/02/25/000000/localhost_1364233603831_job_201303252316_0001_conf.xml
"
MAPREDUCE-5099,mapreduce.lib.jobcontrol.JobControl API Incompatibility between branch-1 and branch-2,"The branch-1 API has the following methods:
{code}
public java.util.ArrayList getWaitingJobList();
public java.util.ArrayList getRunningJobList();
public java.util.ArrayList getReadyJobsList();
public java.util.ArrayList getSuccessfulJobList();
public java.util.ArrayList getFailedJobList();
{code}

and the branch-2 API has the following methods:
{code}
public java.util.List getWaitingJobList();
public java.util.List getRunningJobList();
public java.util.List getReadyJobsList();
public java.util.List getSuccessfulJobList();
public java.util.List getFailedJobList();
{code}"
MAPREDUCE-5098,Fix findbugs warnings in gridmix,"Work on MAPREDUCE-5077 has exposed a bunch of findbugs warnings in gridmix code. 

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/3459//artifact/trunk/patchprocess/newPatchFindbugsWarningshadoop-gridmix.html "
MAPREDUCE-5095,TestShuffleExceptionCount#testCheckException fails occasionally with JDK7,The test fails due a test-order dependency that can be violated when running with JDK 7.
MAPREDUCE-5094,Disable mem monitoring by default in MiniMRYarnCluster,"YARN-449. Some hbase tests were failing since containers were getting killed. 
I believe these checks are disabled by default on the branch-1 MiniMRCluster."
MAPREDUCE-5089,Remove TestProcfsBasedProcessTree from mapreduce-client-jobclient,A similar copy already exists in YARN which is where it should be.
MAPREDUCE-5088,MR Client gets an renewer token exception while Oozie is submitting a job,"After the fix for HADOOP-9299 I'm now getting the following bizzare exception in Oozie while trying to submit a job. This also seems to be KRB related:

{noformat}
2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-130315123130987-oozie-oozi-W] ACTION[0000001-130315123130987-oozie-oozi-W@Sleep] Error starting action [Sleep]. ErrorType [ERROR], ErrorCode [UninitializedMessageException], Message [UninitializedMessageException: Message missing required fields: renewer]
org.apache.oozie.action.ActionExecutorException: UninitializedMessageException: Message missing required fields: renewer
	at org.apache.oozie.action.ActionExecutor.convertException(ActionExecutor.java:401)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:738)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.start(JavaActionExecutor.java:889)
	at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:211)
	at org.apache.oozie.command.wf.ActionStartXCommand.execute(ActionStartXCommand.java:59)
	at org.apache.oozie.command.XCommand.call(XCommand.java:277)
	at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:326)
	at org.apache.oozie.service.CallableQueueService$CompositeCallable.call(CallableQueueService.java:255)
	at org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:175)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
Caused by: com.google.protobuf.UninitializedMessageException: Message missing required fields: renewer
	at com.google.protobuf.AbstractMessage$Builder.newUninitializedMessageException(AbstractMessage.java:605)
	at org.apache.hadoop.security.proto.SecurityProtos$GetDelegationTokenRequestProto$Builder.build(SecurityProtos.java:973)
	at org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.mergeLocalToProto(GetDelegationTokenRequestPBImpl.java:84)
	at org.apache.hadoop.mapreduce.v2.api.protocolrecords.impl.pb.GetDelegationTokenRequestPBImpl.getProto(GetDelegationTokenRequestPBImpl.java:67)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getDelegationToken(MRClientProtocolPBClientImpl.java:200)
	at org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:194)
	at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:273)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:392)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1218)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1215)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:581)
	at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:576)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1439)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:576)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:723)
	... 10 more
2013-03-15 13:34:16,555  WARN ActionStartXCommand:542 - USER[hue] GROUP[-] TOKEN[] APP[MapReduce] JOB[0000001-13031512313
{noformat}"
MAPREDUCE-5086,MR app master deletes staging dir when sent a reboot command from the RM,"If the RM is restarted when the MR job is running, then it sends a reboot command to the job. The job ends up deleting the staging dir and that causes the next attempt to fail."
MAPREDUCE-5084,fix coverage  org.apache.hadoop.mapreduce.v2.app.webapp and org.apache.hadoop.mapreduce.v2.hs.webapp,"fix coverage  org.apache.hadoop.mapreduce.v2.app.webapp and org.apache.hadoop.mapreduce.v2.hs.webapp
The same patch for trunk, branch-2 and branch-0.23"
MAPREDUCE-5083,MiniMRCluster should use a random component when creating an actual cluster,Currently all unit tests end up using the same work dir - which can affect anyone trying to run parallel instances.
MAPREDUCE-5081,Backport DistCpV2 and the related JIRAs to branch-1,"Here is a list of DistCpV2 JIRAs:
- MAPREDUCE-2765: DistCpV2 main jira
- HADOOP-8703: turn CRC checking off for 0 byte size 
- HDFS-3054: distcp -skipcrccheck has no effect.
- HADOOP-8431: Running distcp without args throws IllegalArgumentException
- HADOOP-8775: non-positive value to -bandwidth
- MAPREDUCE-4654: TestDistCp is ignored
- HADOOP-9022: distcp fails to copy file if -m 0 specified
- HADOOP-9025: TestCopyListing failing
- MAPREDUCE-5075: DistCp leaks input file handles
- distcp part of HADOOP-8341: Fix findbugs issues in hadoop-tools
- MAPREDUCE-5014: custom CopyListing
"
MAPREDUCE-5080,TestContainerLauncher fails on Windows due to assertion failures on event/thread counts,
MAPREDUCE-5079,Recovery should restore task state from job history info directly,"We've encountered a lot of hanging issues during MR-AM recovery because the state machines don't always end up in the same states after recovery.  This is especially true when speculative execution is enabled.  It should be straightforward to restore task and task attempt states directly from the TaskInfo and TaskAttemptInfo records in the job history file to avoid relying on the task state machines ending up in the proper states with the proper number of attempts.

This should be a more robust solution that would also give us the option of recovering start time and log locations for tasks that were in-progress when the AM crashed."
MAPREDUCE-5078,TestMRAppMaster fails on Windows due to mismatched path separators,"The failing test is {{TestMRAppMaster#testMRAppMasterForDifferentUser}}.  There is an assertion about the AM staging directory, but the expected value is constructed with a mix of forward and back slashes."
MAPREDUCE-5077,Cleanup: mapreduce.util.ResourceCalculatorPlugin and related code should be removed,{{ResourceCalculatorPlugin}} and {{ProcfsBasedProcessTree}} have moved to yarn.util and the mapreduce.util versions don't seem to be used anymore. Should remove related code.
MAPREDUCE-5075,DistCp leaks input file handles,"DistCp wraps the {{InputStream}} for each input file it reads in an instance of {{ThrottledInputStream}}.  This class does not close the wrapped {{InputStream}}.  {{RetriableFileCopyCommand}} guarantees that the {{ThrottledInputStream}} gets closed, but without closing the underlying wrapped stream, it still leaks a file handle."
MAPREDUCE-5074,Remove limits on number of counters and counter groups in MapReduce,"Can we please consider removing limits on the number of counters and counter groups now that it is all user code? Thanks to the much better architecture of YARN in which there is no single Job Tracker we have to worry about overloading, I feel we should do away with this (now arbitrary) constraint on users' capabilities. Thoughts?"
MAPREDUCE-5073,TestJobStatusPersistency.testPersistency fails on JDK7,"TestJobStatusPersistency is sensitive to the order that the tests are run in. If testLocalPersistency runs before testPersistency, testPersistency will fail."
MAPREDUCE-5072,TestDelegationTokenRenewal.testDTRenewal fails in MR1 on jdk7,TestDelegationTokenRenewal.testDTRenewal fails in MR1 for the reasons that TestDelegationTokenRenewer.testDTRenewal fails described in YARN-31.  The fix is the same.
MAPREDUCE-5070,TestClusterStatus.testClusterMetrics fails on JDK7,"TestClusterStatus is sensitive to the order that the tests are run in.  If testReservedSlots is called before testClusterMetrics, testClusterMetrics will fail."
MAPREDUCE-5069,add concrete common implementations of CombineFileInputFormat,"CombineFileInputFormat is abstract, and its specific equivalents to TextInputFormat, SequenceFileInputFormat, etc. are currently not in the hadoop code base.

These sound like very common need wherever CombineFileInputFormat is used, and different folks would write the same code over and over to achieve the same goal. It sounds very natural for hadoop to provide at least the text and sequence file implementations of the CombineFileInputFormat class."
MAPREDUCE-5067,native taskcontroller won't build on Ubuntu 12.10,"Building the native tarball is failing in {{task-controller.c}} with
{code}
[exec] /usr/include/fts.h:41:3: error: #error ""<fts.h> cannot be used with -D_FILE_OFFSET_BITS==64""
{code}"
MAPREDUCE-5066,JobTracker should set a timeout when calling into job.end.notification.url,"In current code, timeout is not specified when JobTracker (JobEndNotifier) calls into the notification URL. When the given URL points to a server that will not respond for a long time, job notifications are completely stuck (given that we have only a single thread processing all notifications). We've seen this cause noticeable delays in job execution in components that rely on job end notifications (like Oozie workflows). 

I propose we introduce a configurable timeout option and set a default to a reasonably small value.

If we want, we can also introduce a configurable number of workers processing the notification queue (not sure if this is needed though at this point).

I will prepare a patch soon. Please comment back."
MAPREDUCE-5065,DistCp should skip checksum comparisons if block-sizes are different on source/target.,"When copying files between 2 clusters with different default block-sizes, one sees that the copy fails with a checksum-mismatch, even though the files have identical contents.

The reason is that on HDFS, a file's checksum is unfortunately a function of the block-size of the file. So you could have 2 different files with identical contents (but different block-sizes) have different checksums. (Thus, it's also possible for DistCp to fail to copy files on the same file-system, if the source-file's block-size differs from HDFS default, and -pb isn't used.)

I propose that we skip checksum comparisons under the following conditions:
1. -skipCrc is specified.
2. File-size is 0 (in which case the call to the checksum-servlet is moot).
3. source.getBlockSize() != target.getBlockSize(), since the checksums are guaranteed to differ in this case.

I have a patch for #3.

Edit: I've modified the fix to warn the user (instead of skipping the checksum-check). Skipping parity-checks is unsafe. The code now fails the copy, and suggests that the user either use -pb to preserve block-size, or consider -skipCrc (and forgo copy validation entirely)."
MAPREDUCE-5064,TestRumenJobTraces failing on 1.3.x and 1.2,"{{TestRumenJobTraces.testCurrentJHParser()}} is failing locally, both in a bulk test and standalone"
MAPREDUCE-5062,MR AM should read max-retries information from the RM,Change MR AM to use app-retry maximum limit that is made available by RM after YARN-378.
MAPREDUCE-5060,Fetch failures that time out only count against the first map task,"When a fetch failure happens, if the socket has already ""connected"" it is only counted against the first map task.  But most of the time it is because of an issue with the Node itself, not the individual map task, and as such all failures when trying to initiate the connection should count against all of the tasks.

This caused a particularly unfortunate job to take an hour an a half longer then it needed to."
MAPREDUCE-5059,Job overview shows average merge time larger than for any reduce attempt,"When looking at a job overview page on the history server, the Average Merge Time is often reported with a value that is far larger than the Elapsed Merge Time shown for any reduce task attempt.  The job overview page calculates the merge time as the time delta between the sort finishing and the job launching while the attempts page calculates it as the time delta between the sort finishing and the shuffle finishing."
MAPREDUCE-5057,Datajoin Package for reduce side join (in contrib folder) MRJobCOnfig class not present hadoop 1.0.3,"DataJoin Package contributed to Hadoop has bug 
1) MRJobConfig config is not present and will not return input file  
   name (MRJobConfig.MAP_INPUT_FILE) 



2 ) While Writing User program for joinig datasets using datajoin package 
    In TaggedWritable class you will find readFields method will throw exception 
    for that matter you will have to  create new Text type object for reading beacause while writing
    you are writing Text object 
       
      Taxt data;

       public void readFields(DataInput in) throws IOException {
    		data = new Text();
        	        	this.tag.readFields(in);        
         	if(this.data != null)
          	{        		
        		       data.readFields(in);
          	}
       }
  "
MAPREDUCE-5056,TestProcfsBasedProcessTree fails on Windows with Process-tree dump doesn't start with a proper header,"Test fails on the below assertion:

Running org.apache.hadoop.mapreduce.util.TestProcfsBasedProcessTree
Tests run: 5, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.266 sec <<< FAILURE!
testProcessTreeDump(org.apache.hadoop.mapreduce.util.TestProcfsBasedProcessTree)  Time elapsed: 0 sec  <<< FAILURE!
junit.framework.AssertionFailedError: Process-tree dump doesn't start with a proper header
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at org.apache.hadoop.mapreduce.util.TestProcfsBasedProcessTree.testProcessTreeDump(TestProcfsBasedProcessTree.java:564)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)"
MAPREDUCE-5055,"Binary compatibility for the method Reporter.incrCounter(String group, String counter, long amount) between hadoop-1.x and hadoop-2.x","Try to generate a lot of counters that exceed the default max limit so the job errors.
To simulate this edit org.apache.hadoop.examples.RandomWriter class and add the following in the mapper:
{code}
        for (int i = 0; i < 150; i++) {
          reporter.incrCounter(""StringCounter"", ""counter"" + i, 1L);
        }
{code}
Attached is the modified code of RandomWriter.java from branch-1.

When I run it against branch-1,
{code}
hadoop jar build/hadoop-examples-1.2.0-SNAPSHOT.jar -Dtest.randomwrite.total_bytes=8 rw2
{code}
it fails with the following error:
{code}
java.lang.Exception: org.apache.hadoop.mapred.Counters$CountersExceededException: Error: Exceeded limits on number of counters - Counters=120 Limit=120
{code}

Using the jar compiled with branch-1 when running in a hadoop 2 cluster completes without any error and don't see the counter. Interestingly there were two more custom counters in the same job that are incremented and they are visible. The difference is that they use the method 
Reporter.incrCounter(Enum<?> key, long amount).

Compiled this against 2.x/trunk and ran it. The job did fail with the expected counter exceeded exception. So it seems to be a case of binary incompatibility between 1.x and 2.x."
MAPREDUCE-5053,java.lang.InternalError from decompression codec cause reducer to fail,"lz4, snappy, zlib, and lzo Decompressor's only throw java.lang.InternalError. This exception will cause the reducer to fail and bypass all of the fetch failure logic.  The decompressing errors should be treated as fetch failures."
MAPREDUCE-5052,Job History UI and web services confusing job start time and job submit time,"The ""Start Time"" column shown on Job History server's main webpage (http://<host>:<port>/jobhistory) is actually showing the *submit* time for jobs.  However, when you drill down to an individual job's page, there the ""Start Time"" really does refer to when the job actually started.  

This also true for the web services REST API, where the Jobs listing returns the submit times as ""startTime"", but the single Job API returns the start time as ""startTime"".

The two different times being referred to by the same name is confusing.  However, it is useful to have both times, as the difference between the submit time and start time can show how long a job was stuck waiting in a queue.  The column on the main job history page should be changed to ""Submit Time"" and the individual job's page should show both the submit time and start time.  The web services REST API should be updated with these changes as well."
MAPREDUCE-5051,Combiner not used when NUM_REDUCES=0,"We have a M/R job that use Mapper + Combiner but have nothing to do in Reducer :
Bulk indexing of HBase data in ElasticSearch,
Map output is K / V : #bulk / json_data_to_be_indexed.

So job is launched maps work, combiners index and a reducer is created for nothing (sometimes waiting for other M/R job to free a tasktracker slot for reducer cf. MAPREDUCE-5019 )

When we put ```job.setNumReduceTasks(0);``` in our job .run(), mapper are started but combiner are not used."
MAPREDUCE-5049,CombineFileInputFormat counts all compressed files non-splitable,"In branch-1, CombineFileInputFormat doesn't take SplittableCompressionCodec into account and thinks that all compressible input files aren't splittable.  This is a regression from when handling for non-splitable compression codecs was originally added in MAPREDUCE-1597, and seems to have somehow gotten in when the code was pulled from 0.22 to branch-1.
"
MAPREDUCE-5047,keep.failed.task.files=true causes job failure on secure clusters,"To support IsolationRunner, split info is written to local directories.  This occurs inside MapTask#localizeConfiguration, which is called both tasktracker and by the child JVM.  On a secure cluster, the tasktacker's attempt to write it fails, because the tasktracker does not have permission to write to the user's directory. It is likely that the call to localizeConfiguration in the tasktracker can be removed. "
MAPREDUCE-5046,backport MAPREDUCE-1423 to mapred.lib.CombineFileInputFormat,"The CombineFileInputFormat class in org.apache.hadoop.mapred.lib (the old API) has a couple of issues. These issues were addressed in the new API (MAPREDUCE-1423), but the old class was not fixed.

The main issue the JIRA refers to is a performance problem. However, IMO there is a more serious problem which is a thread-safety issue (rackToNodes) which was fixed alongside.

What is the policy on addressing issues in the old API? Can we backport this to the old class?"
MAPREDUCE-5045,UtilTest#isCygwin method appears to be unused,"Method {{UtilTest#isCygwin}} in /hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/UtilTest.java appears to be unused.  If so, then we need to remove it.  If anything is calling it, then we need to update the naming to isWindows, or perhaps just change call sites to use {{Shell#WINDOWS}}."
MAPREDUCE-5044,Have AM trigger jstack on task attempts that timeout before killing them,"When an AM expires a task attempt it would be nice if it triggered a jstack output via SIGQUIT before killing the task attempt.  This would be invaluable for helping users debug their hung tasks, especially if they do not have shell access to the nodes."
MAPREDUCE-5043,Fetch failure processing can cause AM event queue to backup and eventually OOM,"Saw an MRAppMaster with a 3G heap OOM.  Upon investigating another instance of it running, we saw the UI in a weird state where the task table and task attempt tables in the job overview page weren't consistent.  The AM log showed the AsyncDispatcher had hundreds of thousands of events in the event queue, and jstacks showed it spending a lot of time in fetch failure processing.  It turns out fetch failure processing is currently *very* expensive, with a triple {{for}} loop where the inner loop is calling the quite-expensive {{TaskAttempt.getReport}}.  That function ends up type-converting the entire task report, counters and all, and performing locale conversions among other things.  It does this for every reduce task in the job, for every map task that failed.  And when it's done building up the large task report, it pulls out one field, the phase, then throws the report away.

While the AM is busy processing fetch failures, tasks attempts are continuing to send events to the AM including memory-expensive events like status updates which include the counters.  These back up in the AsyncDispatcher event queue and eventually even an AM with a large heap size will run out of memory and crash or expire because it thrashes in garbage collect."
MAPREDUCE-5042,Reducer unable to fetch for a map task that was recovered,"If an application attempt fails and is relaunched the AM will try to recover previously completed tasks.  If a reducer needs to fetch the output of a map task attempt that was recovered then it will fail with a 401 error like this:

{noformat}
java.io.IOException: Server returned HTTP response code: 401 for URL: http://xx:xx/mapOutput?job=job_1361569180491_21845&reduce=0&map=attempt_1361569180491_21845_m_000016_0
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1615)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:231)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:156)
{noformat}

Looking at the corresponding NM's logs, we see the shuffle failed due to ""Verification of the hashReply failed""."
MAPREDUCE-5036,Default shuffle handler port should not be 8080,"The shuffle handler port (mapreduce.shuffle.port) defaults to 8080.  This is a pretty common port for web services, and is likely to cause unnecessary port conflicts."
MAPREDUCE-5035,Update MR1 memory configuration docs,The pmem/vmem settings in the docs (http://hadoop.apache.org/docs/r1.1.1/cluster_setup.html#Memory+monitoring) have not been supported for a long time. The docs should be updated to reflect the new settings (mapred.cluster.map.memory.mb etc).
MAPREDUCE-5034,Class cast exception in MergeManagerImpl.java,"When reduce side merge spills to disk, the following exception was thrown:

org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$CompressAwarePath cannot be cast to java.lang.Comparable at java.util.TreeMap.put(TreeMap.java:542) at java.util.TreeSet.add(TreeSet.java:238) at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.closeOnDiskFile(MergeManagerImpl.java:340) at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl$InMemoryMerger.merge(MergeManagerImpl.java:495) at org.apache.hadoop.mapreduce.task.reduce.MergeThread.run(MergeThread.java:94)

It looks like a bug introduced by MAPREDUCE-2264"
MAPREDUCE-5033,mapred shell script should respect usage flags (--help -help -h),"Like in HADOOP-9267, the mapred shell script should respect the normal Unix-y help flags."
MAPREDUCE-5031,Maps hitting IndexOutOfBoundsException for higher values of mapreduce.task.io.sort.mb,"While trying to reproduce MAPREDUCE-5028 on trunk, ran into what seems to be a different issue. To reproduce:

Psuedo-dist mode: mapreduce.{map,reduce}.memory.mb=2048, mapreduce.{map,reduce}.java.opts=-Xmx2048m, mapreduce.task.io.sort.mb=1280

The map tasks fail with the following error: 
{noformat}
Error: java.lang.IndexOutOfBoundsException at java.nio.Buffer.checkIndex(Buffer.java:512) at
 java.nio.ByteBufferAsIntBufferL.put(ByteBufferAsIntBufferL.java:113) at 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1141) at 
org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:686) at 
org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89) at 
org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112) at 
org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:47) at 
org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:36) at 
org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144) at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:757) at 
org.apache.hadoop.mapred.MapTask.run(MapTask.java:339) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:158) at 
java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at 
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1488) at 
org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:153)
{noformat}
"
MAPREDUCE-5028,Maps fail when io.sort.mb is set to high value,"Verified the problem exists on branch-1 with the following configuration:

Pseudo-dist mode: 2 maps/ 1 reduce, mapred.child.java.opts=-Xmx2048m, io.sort.mb=1280, dfs.block.size=2147483648

Run teragen to generate 4 GB data
Maps fail when you run wordcount on this configuration with the following error: 
{noformat}
java.io.IOException: Spill failed
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1031)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:692)
	at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
	at org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:45)
	at org.apache.hadoop.examples.WordCount$TokenizerMapper.map(WordCount.java:34)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:766)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1149)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:375)
	at org.apache.hadoop.io.IntWritable.readFields(IntWritable.java:38)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:116)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:92)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:175)
	at org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1505)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1438)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.access$1800(MapTask.java:855)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1346)
{noformat}"
MAPREDUCE-5027,Shuffle does not limit number of outstanding connections,The ShuffleHandler does not have any configurable limits to the number of outstanding connections allowed.  Therefore a node with many map outputs and many reducers in the cluster trying to fetch those outputs can exhaust a nodemanager out of file descriptors.
MAPREDUCE-5024,JobHistory task attempts page sorts elapsed time wrong,"The JobHistory attempts UI sorts the ""Elapsed Time"" column lexicographically instead of numerically.

This means that 9 seconds > 12 seconds > 1 min in the sort order, which is misleading."
MAPREDUCE-5023,History Server Web Services missing Job Counters,"The History Server's Job Counters API is not returning all the counters seen on the Job's Counters webpage.  Specifically, I'm not seeing any of the counters in the ""org.apache.hadoop.mapreduce.JobCounter"" group:

TOTAL_LAUNCHED_MAPS
TOTAL_LAUNCHED_REDUCES
OTHER_LOCAL_MAPS
SLOTS_MILLIS_MAPS
SLOTS_MILLIS_REDUCES"
MAPREDUCE-5020,Compile failure with JDK8,"Compiling {{org/apache/hadoop/mapreduce/lib/partition/InputSampler.java}} fails with the Java 8 preview compiler due to its stricter enforcement of JLS 15.12.2.6 (for [Java 5|http://docs.oracle.com/javase/specs/jls/se5.0/html/expressions.html#15.12.2.6] or [Java 7|http://docs.oracle.com/javase/specs/jls/se7/html/jls-15.html#jls-15.12.2.6]), which demands that methods applicable via unchecked conversion have their return type erased:

{noformat}
[ERROR] hadoop-common/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/lib/partition/InputSampler.java:[320,35] error: incompatible types: Object[] cannot be converted to K[]
{noformat}

{code}
  @SuppressWarnings(""unchecked"") // getInputFormat, getOutputKeyComparator
  public static <K,V> void writePartitionFile(Job job, Sampler<K,V> sampler) 
      throws IOException, ClassNotFoundException, InterruptedException {
    Configuration conf = job.getConfiguration();
    final InputFormat inf = 
        ReflectionUtils.newInstance(job.getInputFormatClass(), conf);
    int numPartitions = job.getNumReduceTasks();
    K[] samples = sampler.getSample(inf, job); // returns Object[] according to JLS
{code}"
MAPREDUCE-5019,Fair scheduler should allow peremption on reducer only,"Fair scheduler is very good.
But having a big MR job running lots of mapper and reducer( 10M + 10R )
Then a small MR on the same pool (1M + 1R)
having slots for 10 mapper and 10 reducer

 - The big job take all the map slots
 - The small job wait for a map slot
 - 1rst big job map task finish
 - the small job take the map slot it needs
 - meanwhile all the reducer of the big job take all the reducer slot to copy and sort
 - the small job end is map and wait for the all maps to end and for 1 reducer to end before accessing for a reducer slot.
 - all the reducer stalled after sorting waiting for the mapper to end one  by one...

If I have a big job and a lot of small, I don't want new small arriving  and killing running map tasks of big job to get a slot.

I think it could be useful that the small job can kill a reducer tasks (and only reducer) to end before the big job finish all its map tasks and a reducer.

rules can be : a job having all its map finished and waiting for reducer slot can kill reducer tasks from a job that still have map slot running (assuming they are just waiting for copy and sort)"
MAPREDUCE-5017,Provide access to launcher job URL from web console when using Map Reduce action ,"there are applications where custom inputformat used in MR action, and log message from the inputformat is written on launcher task log. for debugging purpose, users need to check the launcher task log. but currently in MR action, oozie automatically swaps external ID, and do not expose the launcher ID in web-console. (now only way is to to grep oozie.log). this jira is to show launcher job URL on web console when using Map Reduce action 

"
MAPREDUCE-5015,Coverage fix for org.apache.hadoop.mapreduce.tools.CLI,"Coverage fix for org.apache.hadoop.mapreduce.tools.CLI
MAPREDUCE-5015-trunk.patch patch for trunk
MAPREDUCE-5015-branch-2.patch for branch-2
MAPREDUCE-5015-branch-0.23.patch for branch-0.23"
MAPREDUCE-5014,Extending DistCp through a custom CopyListing is not possible,"* While it is possible to implement a custom CopyListing in DistCp, DistCp driver class doesn't allow for using this custom CopyListing.

* Allow SimpleCopyListing to provide an option to exclude files (For instance it is useful to exclude FileOutputCommiter.SUCCEEDED_FILE_NAME during copy as premature copy can indicate that the entire data is available at the destination)"
MAPREDUCE-5013,mapred.JobStatus compatibility: MR2 missing constructors from MR1,"JobStatus is missing the following constructors in MR2 that were present in MR1

    public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID, float, float, float, int);
    public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID, float, float, int);
    public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID, float, float, float, int, org.apache.hadoop.mapred.JobPriority);
    public org.apache.hadoop.mapred.JobStatus(org.apache.hadoop.mapred.JobID, float, float, float, float, int, org.apache.hadoop.mapred.JobPriority);"
MAPREDUCE-5012,Typo in javadoc for IdentityMapper class,"IdentityMapper.map() is incorrectly documented as the ""identify"" function."
MAPREDUCE-5011,While Running Word Count in Hadoop showing following errors ,"We are running Word Count on Hadoop 1.1.1 by creating our own MANIFEST and jar file containing classes.The command which I entered is as following 

[/usr/local/hadoop]$bin/hadoop jar /home/hduser/joe/Wordcount.jar /home/hduser/joe/Wordcount/input /home/hduser/joe/Wordcount/output   
  
                                         
Exception in thread ""main"" java.lang.ClassNotFoundException: /home/hduser/joe/Wordcount/input
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:264)
at org.apache.hadoop.util.RunJar.main(RunJar.java:149"
MAPREDUCE-5009,Killing the Task Attempt slated for commit does not clear the value from the Task commitAttempt member,"A reduce task attempt was killed by the RM(pre-emptively), but had already been assigned to the commitAttempt member.  This causes all subsequent attempts to be killed by the AM."
MAPREDUCE-5008,Merger progress miscounts with respect to EOF_MARKER,"After MAPREDUCE-2264, a segment's raw data length is calculated without the EOF_MARKER bytes.  However, when the merge is counting how many bytes it processed, it includes the marker.  This can cause the merge progress to go above 100%.

Whether these EOF_MARKER bytes should count should be consistent between the two.

This a JIRA instead of an amendment because MAPREDUCE-2264 already went into 2.0.3."
MAPREDUCE-5007,fix coverage org.apache.hadoop.mapreduce.v2.hs,"fix coverage org.apache.hadoop.mapreduce.v2.hs 
MAPREDUCE-5007-trunk.patch patch for trunk
MAPREDUCE-5007-branch-2.patch patch for branch-2
MAPREDUCE-5007-branch-0.23.patch patch for branch-0.23
"
MAPREDUCE-5006,streaming tests failing,"The following 2 tests are failing in trunk

* org.apache.hadoop.streaming.TestStreamReduceNone
* org.apache.hadoop.streaming.TestStreamXmlRecordReader
"
MAPREDUCE-5004,Somebody working on Genetic Algorithm library on Map Reduce,
MAPREDUCE-5002,AM could potentially allocate a reduce container to a map attempt,"As discussed in MAPREDUCE-4982, after MAPREDUCE-4893 it is theoretically possible for the AM to accidentally assign a reducer container to a map attempt if the AM doesn't find a reduce attempt actively looking for the container (e.g.: the RM accidentally allocated too many reducer containers)."
MAPREDUCE-5001,LocalJobRunner has race condition resulting in job failures ,"Hive is hitting a race condition with LocalJobRunner and the Cluster class. The JobClient uses the Cluster class to obtain Job objects. The Cluster class uses the job.xml file to populate the JobConf object (https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/Cluster.java#L184). However, this file is deleted by the LocalJobRunner at the end of it's job (https://github.com/apache/hadoop-common/blob/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/main/java/org/apache/hadoop/mapred/LocalJobRunner.java#L484).

This results in the following exception:
{noformat}
2013-02-11 14:45:17,755 (main) [FATAL - org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:2001)] error parsing conf file:/tmp/hadoop-brock/mapred/staging/brock1916441210/.staging/job_local_0432/job.xml
java.io.FileNotFoundException: /tmp/hadoop-brock/mapred/staging/brock1916441210/.staging/job_local_0432/job.xml (No such file or directory)
	at java.io.FileInputStream.open(Native Method)
	at java.io.FileInputStream.<init>(FileInputStream.java:120)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1917)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1870)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1777)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:712)
	at org.apache.hadoop.mapred.JobConf.checkAndWarnDeprecation(JobConf.java:1951)
	at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:398)
	at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:388)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.<init>(JobClient.java:174)
	at org.apache.hadoop.mapred.JobClient.getJob(JobClient.java:655)
	at org.apache.hadoop.mapred.JobClient.getJob(JobClient.java:668)
	at org.apache.hadoop.mapreduce.TestMR2LocalMode.test(TestMR2LocalMode.java:40)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
{noformat}

Here is code which exposes this race fairly quickly:

{noformat}
    Configuration conf = new Configuration();
    conf.set(""mapreduce.framework.name"", ""local"");
    conf.set(""mapreduce.jobtracker.address"", ""local"");
    File inputDir = new File(""/tmp"", ""input-"" + System.currentTimeMillis());
    File outputDir = new File(""/tmp"", ""output-"" + System.currentTimeMillis());
    while(true) {
      Assert.assertTrue(inputDir.mkdirs());
      File inputFile = new File(inputDir, ""file"");
      FileUtils.copyFile(new File(""/etc/passwd""), inputFile);
      Path input = new Path(inputDir.getAbsolutePath());
      Path output = new Path(outputDir.getAbsolutePath());
      JobConf jobConf = new JobConf(conf, TestMR2LocalMode.class);
      FileInputFormat.addInputPath(jobConf, input);
      FileOutputFormat.setOutputPath(jobConf, output);      
      JobClient jobClient = new JobClient(conf);
      RunningJob runningJob = jobClient.submitJob(jobConf);
      while(!runningJob.isComplete()) {
        runningJob = jobClient.getJob(runningJob.getJobID());
      }      
      FileUtils.deleteQuietly(inputDir);
      FileUtils.deleteQuietly(outputDir);
    }
{noformat}"
MAPREDUCE-5000,TaskImpl.getCounters() can return the counters for the wrong task attempt when task is speculating,"When a task is speculating and one attempt completes then sometimes the counters for the wrong attempt are aggregated into the total counters for the job.  The scenario looks like this:

# Two task attempts are racing, _0 and _1
# _1 finishes first, causing the task to issue a TA_KILL to attempt _0
# _0 receives TA_KILL, sets progress to 1.0f and waits for container cleanup
# if TaskImpl.getCounters() is called now, TaskImpl.selectBestAttempt() can return _0 since it is not quite yet in the KILLED state yet progress is maxed out and no other attempt has more progress.
"
MAPREDUCE-4998,backport MAPREDUCE-3376: Old mapred API combiner uses NULL reporter to branch-1,"http://s.apache.org/eI9

backport MAPREDUCE-3376: Old mapred API combiner uses NULL reporter to branch-1"
MAPREDUCE-4994,-jt generic command line option does not work,"hadoop jar myjar.jar MyDriver -fs file:/// -jt local input.txt output/
should run a job using the local file system and the local job runner. Instead it tries to connect to a jobtracker.

hadoop jar myjar.jar MyDriver -fs file:/// -jt host:port input.txt output/
does not use the given host/port

This appears to be because Cluster#initialize, which loads the ClientProtocol, contains no special handling for mapred.job.tracker."
MAPREDUCE-4992,AM hangs in RecoveryService when recovering tasks with speculative attempts,A job hung in the Recovery Service on an AM restart. There were four map tasks events that were not processed and that prevented the complete task count from reaching zero which exits the recovery service. All four tasks were speculative
MAPREDUCE-4991,coverage for gridmix,"fix coverage for GridMix
MAPREDUCE-4991-trunk.patch patch for thunk
MAPREDUCE-4991-branch-2.patch for branch-2 and 
MAPREDUCE-4991-branch-0.23.patch for branch-0.23

known fail -org.apache.hadoop.mapred.gridmix.TestGridmixSummary.testExecutionSummarizer. It is for next issue

"
MAPREDUCE-4990,Construct debug strings conditionally in ShuffleHandler.Shuffle#sendMapOutput(),"In {{#sendMapOutput()}}, the debug statements are not wrapped in the customary {{#isDebugEnabled()}} condition. Given this piece of code is critical for performance, it would be nice to fix it."
MAPREDUCE-4989,JSONify DataTables input data for Attempts page,Use deferred rendering for the attempts page as was done in MAPREDUCE-4720. I'm sorry I didn't realize earlier that this table could be huge too. Thanks to [~jlowe] for pointing it out.
MAPREDUCE-4987,TestMRJobs#testDistributedCache fails on Windows due to classpath problems and unexpected behavior of symlinks,"On Windows, {{TestMRJobs#testDistributedCache}} fails on an assertion while checking the length of a symlink.  It expects to see the length of the target of the symlink, but Java 6 on Windows always reports that a symlink has length 0."
MAPREDUCE-4985,TestDFSIO supports compression but usages doesn't reflect,"https://issues.apache.org/jira/browse/MAPREDUCE-2786 introduced the ability to use a compression codec during TestDFSIO. However, the -compression parameter was never introduced to the usages printout.

This is a trivial patch to reveal the parameter to end users."
MAPREDUCE-4984,AM leaves unwanted node/rack requests after container has been assigned,"Consider the following situation:
node1, node2, and node3 are all on rack1
task1 is submitted with resource requests on node1, node2, rack1, and *
task2 is submitted with resource requests on node3, rack1, and *

The RM gives a container to the app on node1, on which the AM assigns task1.  While node1 is removed from the scheduler's bookkeeping, node2 is not, so its delay scheduling will try as hard to assign a container there is it would to node3.

The AM should cancel its request for node2 on its next heartbeat by sending a resource request with # containers = 0."
MAPREDUCE-4983,multiple MapReduce tests fail on Windows due to platform-specific assumptions in test code,"Multiple MapReduce tests have code that makes platform-specific assumptions which do not hold true on Windows.  This includes assumptions about file path manipulation, the path separator used between classpath elements, environment variable syntax, and order of files returned from a directory listing of the local file system."
MAPREDUCE-4982,AM hung with one pending map task,"Saw a job that hung with one pending map task that never ran.  The task was in the SCHEDULED state with a single attempt that was in the UNASSIGNED state.  The AM looked like it was waiting for a container from the RM, but the RM was never granting it the one container it needed.

I suspect the AM botched the container request bookkeeping somehow.  More details to follow."
MAPREDUCE-4981,"WordMean, WordMedian, WordStandardDeviation missing from ExamplesDriver","https://issues.apache.org/jira/browse/MAPREDUCE-2669 introduced 3 new MapReduce examples, but they were never added to the ExamplesDriver.

This JIRA proposes to add them to the ExamplesDriver. I have ran them myself and can confirm the examples still work as intended.

As a workaround for now, people can still run them by: 
bin/hadoop org.apache.hadoop.examples.WordMean <input file/dir path> <output dir path>
bin/hadoop org.apache.hadoop.examples.WordMedian <input file/dir path> <output dir path>
bin/hadoop org.apache.hadoop.examples.WordStandardDeviation <input file/dir path> <output dir path>

Post-patch, people will be able to run them by:
bin/hadoop jar /HADOOP_PATH/share/lib/mapreduce-examples.jar <wordmean|wordmedian|wordstandarddeviation> <input file/dir path> <output dir path>

Just like they do for running the wordcount example."
MAPREDUCE-4979,TestJvmReuse must be fixed or removed from branch-1,"{{TestJvmReuse}} on branch-1 is currently ignored.  If the test is not marked ignored, then it fails.  It's unclear if the test failure indicates that we need to fix a bug or if the test is irrelevant and needs to be deleted.  This jira tracks either fixing the test or removing it."
MAPREDUCE-4978,Add a updateJobWithSplit() method for new-api job,"HADOOP-1230 adds a method updateJobWithSplit(), which only works for old-api job. It's better to add another method for new-api job."
MAPREDUCE-4977,Documentation for pluggable shuffle and pluggable sort,Add documentation with basic information on pluggable shuffle and sort.
MAPREDUCE-4976,Use the new StringUtils methods added by HADOOP-9252,HADOOP-9252 slightly changed the format of some StringUtils outputs.  Some methods were deprecated by HADOOP-9252.  The use of them should be replaced with the new methods.
MAPREDUCE-4974,Optimising the LineRecordReader initialize() method,"I found there is a a scope of optimizing the code, over initialize() if we have compressionCodecs & codec instantiated only if its a compressed input.
Mean while Gelesh George Omathil, added if we could avoid the null check of key & value. This would time save, since for every next key value generation, null check is done. The intention being to instantiate only once and avoid NPE as well. Hope both could be met if initialize key & value over  initialize() method. We both have worked on it."
MAPREDUCE-4973,Backport history clean up configurations to branch-1,"In trunk-based versions, we can configure the max-age of files after which they will be cleaned up. This JIRA is to backport those configurations to branch-1."
MAPREDUCE-4972,Coverage fixing for org.apache.hadoop.mapreduce.jobhistory ,Coverage fixing for package org.apache.hadoop.mapreduce.jobhistory 
MAPREDUCE-4971,Minor extensibility enhancements ,Minor extensibility enhancements to Counters & FileOutputFormat.
MAPREDUCE-4970,Child tasks (try to) create security audit log files,"After HADOOP-8552, MR child tasks will attempt to create security audit log files with their user names.  On an insecure cluster, this has no effect, but on a secure cluster, log4j will try to create log files for tasks with names like SecurityAuth-joeuser.log."
MAPREDUCE-4969,TestKeyValueTextInputFormat test fails with Open JDK 7,"RawLocalFileSystem.delete fails on Windows even when the files are not expected to be in use. It does not reproduce with Sun JDK 6.



"
MAPREDUCE-4967,TestJvmReuse fails on assertion,{{TestJvmReuse}} on branch-1 consistently fails on an assertion.
MAPREDUCE-4966,Env variable for JobHistory JVM OPTS,There seems to be no option to set JVM OPTS for JobHistoryServer. One of the common setting is having Xmx value passed to it. As of now it can be done only via JVM_OPTS or HADOOP_CLIENT_OPTS. It would be good to have something specific for JobHistoryServer
MAPREDUCE-4965,"In merge, no ordering defined for CompressAwarePath","MAPREDUCE-2264 replaced Paths used in the merge with CompressAwarePaths. In MergeManagerImpl, onDiskMapOutputs is maintained as a TreeSet of CompressAwarePaths, but CompressAwarePath does not implement Comparable, and no Comparator is passed, so there is no defined ordering."
MAPREDUCE-4964,JobLocalizer#localizeJobFiles can potentially write job.xml to the wrong user's directory,"In the following code, if jobs corresponding to different users (X and Y) are localized simultaneously, it is possible that jobconf can be written to the wrong user's directory. (X's job.xml can be written to Y's directory)

{code}
  public void localizeJobFiles(JobID jobid, JobConf jConf,
      Path localJobTokenFile, TaskUmbilicalProtocol taskTracker)
      throws IOException, InterruptedException {
    localizeJobFiles(jobid, jConf,
        lDirAlloc.getLocalPathForWrite(JOBCONF, ttConf), localJobTokenFile,
        taskTracker);
  }
{code}
"
MAPREDUCE-4963,"StatisticsCollector improperly keeps track of ""Last Day"" and ""Last Hour"" statistics for new TaskTrackers","The StatisticsCollector keeps track of updates to the ""Total Tasks Last Day"", ""Succeed Tasks Last Day"", ""Total Tasks Last Hour"", and ""Succeeded Tasks Last Hour"" per Task Tracker which is displayed on the JobTracker web UI.  It uses buckets to manage when to shift task counts from ""Last Hour"" to ""Last Day"" and out of ""Last Day"".  After the JT has been running for a while, the connected TTs will have the max number of buckets and will keep shifting them at each update.  If a new TT connects (or an old on rejoins), it won't have the max number of buckets, but the code that drops the buckets uses the same counter for all sets of buckets.  This means that new TTs will prematurely drop their buckets and the stats will be incorrect.  

example:
# Max buckets is 5
# TaskTracker A has these values in its buckets [4, 2, 0, 3, 10] (i.e. 19)
# A new TaskTracker, B, connects; it has nothing in its buckets: [ ] (i.e. 0)
# TaskTracker B runs 3 tasks and TaskTracker A runs 5
# An update occurs
# TaskTracker A has [2, 0, 3, 10, 5] (i.e. 20)
# TaskTracker B should have [3] but it will drop that bucket after adding it during the update and instead have [ ] again (i.e. 0)
# TaskTracker B will keep doing that forever and always show 0 in the web UI

We can fix this by not using the same counter for all sets of buckets"
MAPREDUCE-4962,jobdetails.jsp uses display name instead of real name to get counters,"jobdetails.jsp displays details for a job including its counters.  Counters may have different real names and display names, but the display names are used to look the counter values up, so counter values can incorrectly show up as 0."
MAPREDUCE-4954,ShuffleHandler logs excessively when channel closed prematurely by reducer,"As initially reported in MAPREDUCE-4801, the shuffle protocol allows a reducer to hangup the connection to a nodemanager after receiving the shuffle header.  This can introduce a connection reset IOException or a ClosedChannelException on the nodemanager.  Logging these is not very interesting, and adds a lot of data to the NM log.

MAPREDUCE-4801 missed some places where these exceptions can occur, will post sample exceptions below for reference."
MAPREDUCE-4953,HadoopPipes misuses fprintf,"{code}
     [exec] /mnt/trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc:130:58: warning: format not a string literal and no format arguments [-Wformat-security]
{code}
"
MAPREDUCE-4952,FSSchedulerNode is always instantiated with a 0 virtual core capacity,"After YARN-2, FSSchedulerNode was not updated to initialize with the underlying RMNode's CPU capacity, and thus always has 0 virtual cores."
MAPREDUCE-4951,Container preemption interpreted as task failure,"When YARN reports a completed container to the MR AM, it always interprets it as a failure.  This can lead to a job failing because too many of its tasks failed, when in fact they only failed because the scheduler preempted them.

MR needs to recognize the special exit code value of -100 and interpret it as a container being killed instead of a container failure."
MAPREDUCE-4949,Enable multiple pi jobs to run in parallel,"Currently the hadoop pi example uses a hardcoded temporary directory to store its inputs and outputs.  This makes it so that only one pi job can run at a time, and that if it is cancelled, the temporary directory must be manually deleted.

I propose using a temporary directory based on a timestamp and random number to avoid these conflicts"
MAPREDUCE-4948,TestYARNRunner.testHistoryServerToken failed on trunk,"The failed log:
{noformat}
Error Message

null expected:<> but was:<null>

Stacktrace

junit.framework.ComparisonFailure: null expected:<> but was:<null>
	at junit.framework.Assert.assertEquals(Assert.java:81)
	at junit.framework.Assert.assertEquals(Assert.java:87)
	at org.apache.hadoop.mapred.TestYARNRunner$4.answer(TestYARNRunner.java:267)
	at org.apache.hadoop.mapred.TestYARNRunner$4.answer(TestYARNRunner.java:262)
	at org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:31)
	at org.mockito.internal.MockHandler.handle(MockHandler.java:97)
	at org.mockito.internal.creation.MethodInterceptorFilter.intercept(MethodInterceptorFilter.java:47)
	at org.apache.hadoop.mapreduce.v2.api.MRClientProtocol$$EnhancerByMockitoWithCGLIB$$128d95ae.getDelegationToken(<generated>)
	at org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:194)
	at org.apache.hadoop.mapred.TestYARNRunner$5.run(TestYARNRunner.java:288)
	at org.apache.hadoop.mapred.TestYARNRunner$5.run(TestYARNRunner.java:284)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1452)
	at org.apache.hadoop.mapred.TestYARNRunner.testHistoryServerToken(TestYARNRunner.java:283)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)

{noformat}"
MAPREDUCE-4946,Type conversion of map completion events leads to performance problems with large jobs,"We've seen issues with large jobs (e.g.: 13,000 maps and 3,500 reduces) where reducers fail to connect back to the AM after being launched due to connection timeout.  Looking at stack traces of the AM during this time we see a lot of IPC servers stuck waiting for a lock to get the application ID while type converting the map completion events.  What's odd is that normally getting the application ID should be very cheap, but in this case we're type-converting thousands of map completion events for *each* reducer connecting.  That means we end up type-converting the map completion events over 45 million times during the lifetime of the example job (13,000 * 3,500).

We either need to make the type conversion much cheaper (i.e.: lockless or at least read-write locked) or, even better, store the completion events in a form that does not require type conversion when serving them up to reducers."
MAPREDUCE-4942,mapreduce.Job has a bunch of methods that throw InterruptedException so its incompatible with MR1,"The following methods in MR2's {{org.apache.hadoop.mapreduce.Job}} throw an {{InterruptedException}} but don't in MR1, which makes them incompatible.  (Their Javadoc comments are also missing that they throw an {{InterruptedException}} anyway)

I propose that we wrap the {{InterruptedException}} in a {{RuntimeException}}.  

{code}
public float setupProgress() throws IOException, InterruptedException
public float mapProgress() throws IOException, InterruptedException
public float reduceProgress() throws IOException, InterruptedException
public boolean isComplete() throws IOException, InterruptedException
public boolean isSuccessful() throws IOException, InterruptedException
public void killJob() throws IOException, InterruptedException
public void killTask(org.apache.hadoop.mapreduce.TaskAttemptID) throws IOException, InterruptedException
public void failTask(org.apache.hadoop.mapreduce.TaskAttemptID) throws IOException, InterruptedException
public Counters getCounters() throws IOException, InterruptedException
{code}"
MAPREDUCE-4941,Use of org.apache.hadoop.mapred.lib.CombineFileRecordReader requires casting,"Unlike its counterpart in org.apache.hadoop.mapreduce.lib.input, the CombineFileRecordReader in mapred requires a user to cast to a RecordReader since the constructor specification says it must have the RecordReader<K,V> class as a parameter.  It should use {{Class<? extends RecordReader<K,V>>}} like its mapreduce counterpart to make it easier to use."
MAPREDUCE-4940,division by zero in getLocalPathForWrite(),"see https://builds.apache.org/job/HBase-TRUNK-on-Hadoop-2.0.0/345/testReport/org.apache.hadoop.hbase.mapreduce/TestImportExport/testSimpleCase/
{code}
2013-01-12 11:53:52,809 WARN  [AsyncDispatcher event handler] resourcemanager.RMAuditLogger(255): USER=jenkins	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1357991604658_0002 failed 1 times due to AM Container for appattempt_1357991604658_0002_000001 exited with  exitCode: -1000 due to: java.lang.ArithmeticException: / by zero
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:368)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:115)
	at org.apache.hadoop.yarn.server.nodemanager.LocalDirsHandlerService.getLocalPathForWrite(LocalDirsHandlerService.java:279)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:851)

.Failing this attempt.. Failing the application.	APPID=application_1357991604658_0002
{code}
Here is related code:
{code}
        // Keep rolling the wheel till we get a valid path
        Random r = new java.util.Random();
        while (numDirsSearched < numDirs && returnPath == null) {

          long randomPosition = Math.abs(r.nextLong()) % totalAvailable;
{code}
My guess is that totalAvailable was 0, meaning dirDF was empty."
MAPREDUCE-4938,Job submission to unknown queue can leave staging directory behind,"There is a race where submitting a job to an unknown queue can appear to succeed to the client and then subsequently fail later.  Since there was no AM ever launched, there was nothing left to cleanup the staging directory.  At that point the client is the only thing that can cleanup the staging directory."
MAPREDUCE-4937,MR AM handles an oversized split metainfo file poorly,"When an job runs with a split metainfo file that's larger than it has been configured to handle then it just crashes.  This leaves the user with a less-than-ideal debug session since there are no useful diagnostic messages sent to the client for this failure.  In addition it crashes before registering/unregistering with the RM and crashes without generating history, so the proxy URL is not very useful and there's no archived configuration to check to see what setting the AM was using when it encountered the error.

The AM should handle this error case more gracefully and treat the failure as it does any other failed job, with a proper unregistration from the RM and with history."
MAPREDUCE-4936,JobImpl uber checks for cpu are wrong,"The cpu checks for uberizing have two issues:
# the defaults are hardcoded instead of using the conf defaults
# the comparison against the sys cpu size is using {{<}} instead of {{<=}}

{code}

    boolean smallCpu =
        (
            Math.max(
                conf.getInt(MRJobConfig.MAP_CPU_VCORES, 1), 
                conf.getInt(MRJobConfig.REDUCE_CPU_VCORES, 1)) < 
             sysCPUSizeForUberSlot
        );
{code}

Everything is defaulting to 1, so uber cpu checks are now disabled causing {{TestUberAM}} to fail."
MAPREDUCE-4935,Support timeout limitation to MRv1 job end notifications ,"Since MAPREDUCE-3028 only added timeout limitation to MRv2 job end notification, please add it to MRv1 job end notification.

"
MAPREDUCE-4934,Maven RAT plugin is not checking all source files,"mapreduce side of HADOOP-9097



Running 'mvn apache-rat:check' passes, but running RAT by hand (by downloading the JAR) produces some warnings for Java files, amongst others.
"
MAPREDUCE-4933,MR1 final merge asks for length of file it just wrote before flushing it,"createKVIterator in ReduceTask contains the following code:
{code}

          try {
            Merger.writeFile(rIter, writer, reporter, job);
            addToMapOutputFilesOnDisk(fs.getFileStatus(outputPath));
          } catch (Exception e) {
            if (null != outputPath) {
              fs.delete(outputPath, true);
            }
            throw new IOException(""Final merge failed"", e);
          } finally {
            if (null != writer) {
              writer.close();
            }
          }
{code}

Merger#writeFile() does not close the file after writing it, so when fs.getFileStatus() is called on it, it may not return the correct length.  This causes bad accounting further down the line, which can lead to map output data being lost."
MAPREDUCE-4932,mapreduce.job#getTaskCompletionEvents incompatible with Hadoop 1,"In MR1, {{org.apache.hadoop.mapreduce.Job#getTaskCompletionEvents}} takes one argument: {{int startFrom}}.  In MR2, it now takes an additional argument: {{int numEvents}} (which is the max number of events to get).  This makes them incompatible.  

I propose we add a second {{getTaskCompletionEvents}} method that simply calls the other one with {{numEvents}} set to {{Integer.MAX_VALUE}} to replicate the behavior of the MR1 version.  "
MAPREDUCE-4931,Add user-APIs for classpath precedence control,"The feature config from MAPREDUCE-1938 of allowing tasks to start with user-classes-first is fairly popular and can use its own API hooks in Job/JobConf classes, making it easier to discover and use it rather than continuing to keep it as an advanced param.

I propose to add two APIs to Job/JobConf:

{code}
void setUserClassesTakesPrecedence(boolean)
boolean userClassesTakesPrecedence()
{code}

Both of which, depending on their branch of commit, set the property {{mapreduce.user.classpath.first}} (1.x) or {{mapreduce.job.user.classpath.first}} (trunk, 2.x and if needed, in 0.23.x)."
MAPREDUCE-4930,Backport MAPREDUCE-4678 and MAPREDUCE-4925 to branch-1,"MAPREDUCE-4678 adds convenient arguments to Pentomino, which would be nice to have in other branches as well.

However, MR-4678 introduces a bug - MR-4925 addresses this bug for all branches."
MAPREDUCE-4929,mapreduce.task.timeout is ignored,"In MR1, only mapred.task.timeout works.  Both should be made to work."
MAPREDUCE-4928,Use token request messages defined in hadoop common ,"MapReduce changes related to HADOOP-9192 to reuse the protobuf messages defined in common.
"
MAPREDUCE-4927,Historyserver 500 error due to NPE when accessing specific counters page for failed job,"Went to the historyserver page for a job that failed and examined the counters page.  When I clicked on a specific counter, the historyserver returned a 500 error.  The historyserver logs showed it encountered an NPE error, full traceback to follow."
MAPREDUCE-4926,Change documentation to use mapreduce.jobtracker.split.metainfo.maxsize,"Current 2.0 documentation points to mapreduce.job.split.metainfo.maxsize for restricting max size for job splits, while the code refers to mapreduce.jobtracker.split.metainfo.maxsize"
MAPREDUCE-4925,The pentomino option parser may be buggy,"MAPREDUCE-4678 adds an easier way to specify arguments to Pentomino, although it seems to carry a bug when fetching values.

This JIRA is for fixing that on trunk and backporting it onto branches."
MAPREDUCE-4924,flakey test: org.apache.hadoop.mapred.TestClusterMRNotification.testMR,"I occasionally get a failure like this on {{org.apache.hadoop.mapred.TestClusterMRNotification.testMR}}

{code}
junit.framework.AssertionFailedError: expected:<6> but was:<4>
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.failNotEquals(Assert.java:283)
	at junit.framework.Assert.assertEquals(Assert.java:64)
	at junit.framework.Assert.assertEquals(Assert.java:195)
	at junit.framework.Assert.assertEquals(Assert.java:201)
	at org.apache.hadoop.mapred.NotificationTestCase.testMR(NotificationTestCase.java:184)
	...
{code}

It looks like a race condition:
{code}
    // run a job with FAILED status
    System.out.println(UtilsForTests.runJobFail(this.createJobConf(), inDir,
                                                outDir).getID());
    Thread.sleep(2000);
    assertEquals(6, NotificationServlet.counter);
    assertEquals(0, NotificationServlet.failureCounter);
{code}
Instead of sleeping for 2 seconds, we should keep checking the counter and fail after a timeout.  There's a couple of similar places in the test that should be fixed too.  "
MAPREDUCE-4923,Add toString method to TaggedInputSplit,"Per MAPREDUCE-3678, map task logs now contain information about the input split being processed.  Because TaggedInputSplit has no overridden toString method, nothing useful gets printed out."
MAPREDUCE-4922,Request with multiple data local nodes can cause NPE in AppSchedulingInfo,"With the way that the schedulers work, each request for a container on a node must consist of 3 ResourceRequests - one on the node, one on the rack, and one with *.

AppSchedulingInfo tracks the outstanding requests.  When a node is assigned a node-local container, allocateNodeLocal decrements the outstanding requests at each level - node, rack, and *.  If the rack requests reach 0, it removes the mapping.

A mapreduce task with multiple data local nodes submits multiple container requests, one for each node.  It also submits one for each unique rack, and one for *.  If there are fewer unique racks than data local nodes, this means that fewer rack-local ResourceRequests will be submitted than node-local ResourceRequests, so the rack-local mapping will be deleted before all the node-local requests are allocated and an NPE will come up the next time a node-local request from that rack is allocated."
MAPREDUCE-4921,JobClient should acquire HS token with RM principal,"The job client may acquire a history server token during job submission.  The renewer is specified in a config value that the user must supply (for new api, a bit different for old api).  If this value is not the RM's principal, then the RM cannot renew the token and long running jobs will fail.  Since the token is implicitly acquired for the job, the HS token's renewer should always be the RM's principal."
MAPREDUCE-4920,Use security token protobuf definition from hadoop common,MR part of HADOOP-9173.
MAPREDUCE-4917,multiple BlockFixer should be supported in order to improve scalability and reduce too much work on single BlockFixer,"current implementation can only run single BlockFixer since the fsck (in RaidDFSUtil.getCorruptFiles) only check the whole DFS file system. multiple BlockFixer will do the same thing and try to fix same file if multiple BlockFixer launched.
the change/fix will be mainly in BlockFixer.java and RaidDFSUtil.getCorruptFile(), to enable fsck to check the different paths defined in separated Raid.xml for single RaidNode/BlockFixer"
MAPREDUCE-4916,TestTrackerDistributedCacheManager is flaky due to other badly written tests in branch-1,Credit to Xuan figuring this: TestTrackerDistributedCacheManager is flaky due to other badly written tests since it checks for existence of a directory upfront which might have bad perms.
MAPREDUCE-4915,TestShuffleExceptionCount fails with open JDK7,"{noformat}
Testcase: testShuffleExceptionTrailingSize took 0.203 sec
Testcase: testExceptionCount took 0 sec
Testcase: testShuffleExceptionTrailing took 0 sec
Testcase: testCheckException took 0 sec
        FAILED
abort called when set to off
junit.framework.AssertionFailedError: abort called when set to off
        at org.apache.hadoop.mapred.TestShuffleExceptionCount.testCheckException(TestShuffleExceptionCount.java:57)
{noformat}

This is a test order-dependency bug. The static variable abortCalled set by one test may affect the next tests."
MAPREDUCE-4914,TestMiniMRDFSSort fails with openJDK7,"
{noformat}
Testcase: testJvmReuse took 0.063 sec
        Caused an ERROR
Input path does not exist: hdfs://127.0.0.1:62473/sort/input
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://127.0.0.1:62473/sort/input
        at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:197)
        at org.apache.hadoop.mapred.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:40)
        at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:208)
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:989)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:981)
        at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:174)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:897)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:850)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:415)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:850)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:824)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1261)
        at org.apache.hadoop.mapred.TestMiniMRDFSSort.runJvmReuseTest(TestMiniMRDFSSort.java:150)
        at org.apache.hadoop.mapred.TestMiniMRDFSSort.testJvmReuse(TestMiniMRDFSSort.java:173)
        at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
        at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
        at junit.extensions.TestSetup.run(TestSetup.java:27)

Testcase: testMapReduceSort took 168.874 sec
Testcase: testNoJvmReuse took 88.628 sec{noformat}"
MAPREDUCE-4913,TestMRAppMaster#testMRAppMasterMissingStaging occasionally exits,"testMRAppMasterMissingStaging will sometimes cause the JVM to exit due to this error from AsyncDispatcher:

{noformat}
2013-01-05 02:14:54,682 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(137)) - Error in dispatcher thread
java.lang.Exception: No handler for registered for class org.apache.hadoop.mapreduce.jobhistory.EventType, cannot deliver EventType: AM_STARTED
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:132)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
        at java.lang.Thread.run(Thread.java:662)
2013-01-05 02:14:54,682 INFO  [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(140)) - Exiting, bbye..
{noformat}

This can cause a build to fail since the test process exits without unregistering from surefire which treats it as a build error rather than a test failure."
MAPREDUCE-4909,TestKeyValueTextInputFormat fails with Open JDK 7 on Windows,TestKeyValueTextInputFormat.testFormat fails with Open JDK 7. The root cause appears to be a failure to delete in-use files via LocalFileSystem.delete (RawLocalFileSystem.delete).
MAPREDUCE-4907,TrackerDistributedCacheManager issues too many getFileStatus calls,"TrackerDistributedCacheManager issues a number of redundant getFileStatus calls when determining the timestamps and visibilities of files in the distributed cache.  300 distributed cache files deep in the directory structure can hammer HDFS with a couple thousand requests.

A couple optimizations can reduce this load:
1. determineTimestamps and determineCacheVisibilities both call getFileStatus on every file.  We could cache the results of the former and use them for the latter.
2. determineCacheVisibilities needs to check that all ancestor directories of each file have execute permissions for everyone.  This currently entails a getFileStatus on each ancestor directory for each file.  The results of these getFileStatus calls could be cached as well."
MAPREDUCE-4906,testJobTrackerRestartsWithMissingJobFile failed in branch-1,"testJobTrackerRestartsWithMissingJobFile failed in branch-1 for timeout

{noformat}
Testcase: testJobTrackerRestartsWithMissingJobFile took 164.41 sec
        Caused an ERROR
test timed out after 120000 milliseconds
java.lang.Exception: test timed out after 120000 milliseconds

Testcase: testJobResubmission took 89.27 sec
Testcase: testJobTrackerRestartWithBadJobs took 122.568 sec
Testcase: testRestartCount took 10.896 sec
Testcase: testJobTrackerInfoCreation took 9.954 sec

{noformat}"
MAPREDUCE-4905,test org.apache.hadoop.mapred.pipes,"tests for  org.apache.hadoop.mapred.pipes
patch MAPREDUCE-4905-trunk.patch for trunk, branch-2, branch-0.23"
MAPREDUCE-4904,TestMultipleLevelCaching failed in branch-1,"TestMultipleLevelCaching will failed:
{noformat}
Testcase: testMultiLevelCaching took 30.406 sec
        FAILED
Number of local maps expected:<0> but was:<1>
junit.framework.AssertionFailedError: Number of local maps expected:<0> but was:<1>
        at org.apache.hadoop.mapred.TestRackAwareTaskPlacement.launchJobAndTestCounters(TestRackAwareTaskPlacement.java:78)
        at org.apache.hadoop.mapred.TestMultipleLevelCaching.testCachingAtLevel(TestMultipleLevelCaching.java:113)
        at org.apache.hadoop.mapred.TestMultipleLevelCaching.testMultiLevelCaching(TestMultipleLevelCaching.java:69)

{noformat}"
MAPREDUCE-4902,"Fix typo ""receievd"" should be ""received"" in log output","Noticed a typo in the log output, ""receievd"" should be ""received"" 

org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=8080/mapOutput?job=job_1356131733318_0002&reduce=0&map=attempt_1356131733318_0002_m_000001_0,attempt_1356131733318_0002_m_000003_0,attempt_1356131733318_0002_m_000000_0 sent hash and receievd reply

"
MAPREDUCE-4899,Provide a plugin to the Yarn Web App Proxy to generate tracking links for M/R appllications given the ID,"Create a Map/Reduce specific plugin for use with the Yarn RM Proxy to produce tracking links to the History server.
"
MAPREDUCE-4898,FileOutputFormat.checkOutputSpecs and FileOutputFormat.setOutputPath incompatible with MR1,"In MR1, {{org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs}} throws {{org.apache.hadoop.mapred.FileAlreadyExistsException}} but now it throws {{org.apache.hadoop.fs.FileAlreadyExistsException}} instead, making them incompatible.  

In MR1, {{org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath}} doesn't throw any exceptions but now it throws an {{IOException}}, making them incompatible.  "
MAPREDUCE-4896,"""mapred queue -info"" spits out ugly exception when queue does not exist",
MAPREDUCE-4895,Fix compilation failure of org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators,"Task https://issues.apache.org/jira/browse/YARN-223 breaks compilation of 'Apache Hadoop Gridmix' on branch-2.
There is an import of class org.apache.hadoop.yarn.util.ResourceCalculatorPlugin.ProcResourceValues. 
Class ProcResourceValues were removed by YARN-223.

this patch removes this import.

applicable to branch-2

"
MAPREDUCE-4894,Renewal / cancellation of JobHistory tokens,Equivalent of YARN-50 for JobHistory tokens.
MAPREDUCE-4893,MR AppMaster can do sub-optimal assignment of containers to map tasks leading to poor node locality,"Say the MR AppMaster asks the RM for 3 containers on nodes n1, n2 and n3. There are 10 node n1-n10 in the same rack. The RM can give it allocated containers in the list order n5, n2, n1. The way AM map->container assignment happens, the AM will try to assign node local maps to n5, failing which it will assign rack local maps to n5. These rack local maps could be node local on n2 and n1 and would have been assigned to containers on n1 and n2 if the AM had not made an early rack local match for them on n5. This can lead to poor locality."
MAPREDUCE-4892,CombineFileInputFormat node input split can be skewed on small clusters,The CombineFileInputFormat split generation logic tries to group blocks by node in order to create splits. It iterates through the nodes and creates splits on them until there aren't enough blocks left on a node that can be grouped into a valid split. If the first few nodes have a lot of blocks on them then they can end up getting a disproportionately large share of the total number of splits created. This can result in poor locality of maps. This problem is likely to happen on small clusters where its easier to create a skew in the distribution of blocks on nodes.
MAPREDUCE-4891,Pluggable merge at reduce side,"The current implementation of sort in MapReduce is cooperated by Map side sort and Reduce side merge.  MAPREDUCE-2454 provided pluggable sort at the Map side currently and pluggable shuffle at Reduce side, while no pluggable merger provided.

Considering a general need of hash grouping and join, we may need to replace both the Map Sort and Reduce merge with a more light weight hash grouping alorithm. A general pluggable merge would help support this need."
MAPREDUCE-4890,Invalid TaskImpl state transitions when task fails while speculating,"There are a couple of issues when a task fails while speculating (i.e.: multiple attempts are active):

# The other active attempts are not killed.
# TaskImpl's FAILED state does not handle the T_ATTEMPT_* set of events which can be sent from the other active attempts.  These all need to be handled since they can be sent asynchronously from the other active task attempts.

Failure to handle this properly means jobs that are configured to normally tolerate failures via mapreduce.map.failures.maxpercent or mapreduce.reduce.failures.maxpercent and also speculate can easily end up failing due to invalid state transitions rather than complete successfully with a few explicitly allowed task failures."
MAPREDUCE-4888,NLineInputFormat drops data in 1.1 and beyond,"When trying to root cause why MAPREDUCE-4782 did not cause us issues on 1.0.2, I found out that HADOOP-7823 introduced essentially the exact same error into org.apache.hadoop.mapred.lib.NLineInputFormat.

In 1.X org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapreduce.lib.input.NLineInputFormat are separate implementations.  The latter had an off by one error in it until MAPREDUCE-4782 fixed it. The former had no error in it until HADOOP-7823 introduced it in 1.1 and MAPREDUCE-375 combined the implementations together but picked the implementation with the off by one error in 0.21.

I will attach a patch that exposes the error."
MAPREDUCE-4887,Rehashing partitioner for better distribution,rehash value returned by Object.hashCode() to get better distribution
MAPREDUCE-4886,TestCapacityScheduler failed in branch-1,"The test failure on my local env is as following:
{noformat}
compile-test:
     [echo] contrib: capacity-scheduler
    [javac] /home/jdu/bdc/hadoop-branch1/hadoop-common/src/contrib/build-contrib.xml:221: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds

test:
     [echo] contrib: capacity-scheduler
   [delete] Deleting directory /home/jdu/bdc/hadoop-branch1/hadoop-common/build/contrib/capacity-scheduler/test/logs
    [mkdir] Created dir: /home/jdu/bdc/hadoop-branch1/hadoop-common/build/contrib/capacity-scheduler/test/logs
    [junit] Running org.apache.hadoop.mapred.TestCapacityScheduler
    [junit] Tests run: 35, Failures: 0, Errors: 12, Time elapsed: 370.574 sec

{noformat}"
MAPREDUCE-4885,Streaming tests have multiple failures on Windows,"There are multiple test failures due to ""Queue configuration missing child queue names for root""."
MAPREDUCE-4884,"streaming tests fail to start MiniMRCluster due to ""Queue configuration missing child queue names for root""","Multiple tests in hadoop-streaming, such as {{TestFileArgs}}, fail to initialize {{MiniMRCluster}} due to a {{YarnException}} with reason ""Queue configuration missing child queue names for root""."
MAPREDUCE-4883,Reducer's Maximum Shuffle Buffer Size should be enlarged for 64bit JVM,"In hadoop-0.20.2, hadoop-1.0.3 or other versions, reducer's shuffle buffer size cannot exceed 2048MB (i.e., Integer.MAX_VALUE). This is reasonable for 32bit JVM.
But for 64bit JVM, although reducer's JVM size can be set more than 2048MB (e.g., mapred.child.java.opts=-Xmx4000m), the heap size used for shuffle buffer is at most ""2048MB * maxInMemCopyUse (default 0.7)"" not ""4000MB * maxInMemCopyUse"". 

So the pointed piece of code in ReduceTask.java needs modification for 64bit JVM.
---------------------------------------------------------------------------------------
      private final long maxSize;
      private final long maxSingleShuffleLimit;
     
      private long size = 0;
     
      private Object dataAvailable = new Object();
      private long fullSize = 0;
      private int numPendingRequests = 0;
      private int numRequiredMapOutputs = 0;
      private int numClosed = 0;
      private boolean closed = false;
     
      public ShuffleRamManager(Configuration conf) throws IOException {
        final float maxInMemCopyUse =
          conf.getFloat(""mapred.job.shuffle.input.buffer.percent"", 0.70f);
        if (maxInMemCopyUse > 1.0 || maxInMemCopyUse < 0.0) {
          throw new IOException(""mapred.job.shuffle.input.buffer.percent"" +
                                maxInMemCopyUse);
        }
        // Allow unit tests to fix Runtime memory
-->   maxSize = (int)(conf.getInt(""mapred.job.reduce.total.mem.bytes"",
-->        (int)Math.min(Runtime.getRuntime().maxMemory(), Integer.MAX_VALUE))
-->      * maxInMemCopyUse);
        maxSingleShuffleLimit = (long)(maxSize * MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION);
        LOG.info(""ShuffleRamManager: MemoryLimit="" + maxSize +
                 "", MaxSingleShuffleLimit="" + maxSingleShuffleLimit);
      }
"
MAPREDUCE-4882,Error in estimating the length of the output file in Spill Phase,"The sortAndSpill() method in MapTask.java has an error in estimating the length of the output file. 
The ""long size"" should be ""(bufvoid - bufstart) + bufend"" not ""(bufvoid - bufend) + bufstart"" when ""bufend < bufstart"".

Here is the original code in MapTask.java.
 private void sortAndSpill() throws IOException, ClassNotFoundException,
                                       InterruptedException {
      //approximate the length of the output file to be the length of the
      //buffer + header lengths for the partitions
      long size = (bufend >= bufstart
          ? bufend - bufstart
          : (bufvoid - bufend) + bufstart) +
                  partitions * APPROX_HEADER_LENGTH;
      FSDataOutputStream out = null;
------------------------------------------------------------------------------
I had a test on ""TeraSort"". A snippet from mapper's log is as follows:

MapTask: Spilling map output: record full = true
MapTask: bufstart = 157286200; bufend = 10485460; bufvoid = 199229440
MapTask: kvstart = 262142; kvend = 131069; length = 655360
MapTask: Finished spill 3

In this occasioin, Spill Bytes should be (199229440 - 157286200) + 10485460 = 52428700 (52 MB) because the number of spilled records is 524287 and each record costs 100B."
MAPREDUCE-4880,TaskImpl interprets death of second attempt as RetroactiveKilledTransition even when first attempt succeeds,"Consider a reduce task with 2 attempts, one running and one unassigned.  Reduce task attempt 1 succeeds.  This causes reduce task attempt 2 to be killed.  This causes reduce task attempt 2 to issue a T_ATTEMPT_KILLED, which the TaskImpl interprets as a RetroactiveKilledTransition.  As RetroactiveKilledTransitions are supposed to only apply to map events, the TaskImpl errors with ""Unexpected event for REDUCE task T_ATTEMPT_KILLED""."
MAPREDUCE-4879,TeraOutputFormat may overwrite an existing output directory,"Unlike FileOutputFormat, TeraOutputFormat does not prevent TeraGen/Sort jobs from writing into an existing directory, and potentially overwriting previous runs."
MAPREDUCE-4878,JobID.forName() isn't strict enough,"If you have a job running as job_201208221603_0003, and then try to kill a job passing id job_201208221603_003, it will kill job_201208221603_0003 because the last part of the JobID is parsed as an integer.  We should make JobID.forName() stricter to prevent this and similar situations as the current behavior isn't so obvious.  

More specifically, we shouldn't accept JobIDs if the last part of the JobID is:
{{-}} less than 4 characters (e.g. _003, _123)
{{-}} more than 4 characters and has a leading zero (e.g. _00003, _01234)"
MAPREDUCE-4875,coverage fixing for org.apache.hadoop.mapred,"added  some tests for org.apache.hadoop.mapred
MAPREDUCE-4875-trunk.patch for trunk and branch-2
MAPREDUCE-4875-branch-0.23.patch for branch-0.23"
MAPREDUCE-4873,TestQueueManagerForJobKillAndJobPriority is failing on branch-1,
MAPREDUCE-4872,MapReduce JVM launch does not use correct working directory on Windows,"{{MapReduceChildJVM#getVMCommand}} sets java.io.tmpdir by using environment variable PWD as the root of the path.  On Windows, %PWD% likely will not be defined.  Instead, we need to use %CD%.  Any part of the codebase that uses {{Environment#PWD}} is likely to be impacted by this."
MAPREDUCE-4871,AM uses mapreduce.jobtracker.split.metainfo.maxsize but mapred-default has mapreduce.job.split.metainfo.maxsize,"When the user needs to configure a larger split metainfo file size, mapred-default.xml points to the mapreduce.job.split.metainfo.maxsize property.  However the ApplicationMaster actually uses the mapreduce.*jobtracker*.split.metainfo.maxsize property when determining the largest allowed size.  This leads to much confusion on the part of end-users trying to increase the allowed limit."
MAPREDUCE-4870,TestMRJobsWithHistoryService causes infinite loop if it fails,"{{TestMRJobsWithHistoryService#testJobHistoryData}} has a periodic poll and sleep after job execution, checking for the application state to reach {{RMAppState#FINISHED}}.  If the job fails, then the application could be in a different terminal state, and this polling loop will never terminate."
MAPREDUCE-4869,TestMapReduceChildJVM fails in branch-trunk-win,"The YARN-233 patch for getting YARN working on Windows forgot to include a corresponding change in {{TestMapReduceChildJVM}}, so the test is failing now."
MAPREDUCE-4861,Cleanup: Remove unused mapreduce.security.token.DelegationTokenRenewal,"mapreduce.security.token.DelegationTokenRenewal doesn't seem to be used in branch-2 at all. grep on trunk yields no results, not even ReflectionUtils related suff."
MAPREDUCE-4860,DelegationTokenRenewal attempts to renew token even after a job is removed,"mapreduce.security.token.DelegationTokenRenewal synchronizes on removeDelegationToken, but fails to synchronize on addToken, and renewing tokens in run().

This inconsistency is exposed by frequent failures of TestDelegationTokenRenewal:
{noformat}
Error Message

renew wasn't called as many times as expected expected:<4> but was:<5>
Stacktrace

junit.framework.AssertionFailedError: renew wasn't called as many times as expected expected:<4> but was:<5>
	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewal(TestDelegationTokenRenewal.java:317)
	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewalAfterClose(TestDelegationTokenRenewal.java:338)

{noformat}
"
MAPREDUCE-4859,TestRecoveryManager fails on branch-1,Looks like the tests are extremely flaky and just hang.
MAPREDUCE-4858,TestWebUIAuthorization fails on branch-1,TestWebUIAuthorization fails on branch-1
MAPREDUCE-4857,Fix 126 error during map/reduce phase,"There is rare happenings during map or reduce phase, but mostly in map phase, the Exception messages: 
java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:271)
Caused by: java.io.IOException: Task process exit with nonzero status of 126.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:258)

and error logs are cleaned, so It's very hard to debug.

but I compared DefaultTaskController.java with 0.22, they use ""bash command"" to start the job scritp, but 1.0.4 use ""bash, ""-c"", command"".

I removed ""-c"", everything is ok, 126 error code never happen again.

I read man document of bash, it indicates when fork a new thread with write command, another thread with ""bash -c"" also has a writable fd. so I think it could return 126 status occasionally.

So, there is only one line fix for this issue.
"
MAPREDUCE-4856,TestJobOutputCommitter uses same directory as TestJobCleanup,This can cause problems if one of the tests fails to delete.
MAPREDUCE-4854,TestRumenJobTraces is broken in branch-1,"TestRumenJobTraces is broken in branch-1, need to fix the 'gold' events it's checking against which is broken."
MAPREDUCE-4852,Reducer should not signal fetch failures for disk errors on the reducer's side,"Ran across a case where a reducer ran on a node where the disks were full, leading to an exception like this during the shuffle fetch:

{noformat}
2012-12-05 09:07:28,749 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.MergeManager: attempt_1352354913026_138167_m_000654_0: Shuffling to disk since 235056188 is greater than maxSingleShuffleLimit (155104064)
2012-12-05 09:07:28,755 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#25 failed to read map headerattempt_1352354913026_138167_m_000654_0 decomp: 235056188, 101587629
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1352354913026_138167_r_000189_0/map_654.out
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:398)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:150)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:131)
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFileForWrite(YarnOutputFiles.java:213)
	at org.apache.hadoop.mapreduce.task.reduce.MapOutput.<init>(MapOutput.java:81)
	at org.apache.hadoop.mapreduce.task.reduce.MergeManager.reserve(MergeManager.java:245)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:348)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:283)
	at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:155)
2012-12-05 09:07:28,755 WARN [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.Fetcher: copyMapOutput failed for tasks [attempt_1352354913026_138167_m_000654_0]
2012-12-05 09:07:28,756 INFO [fetcher#25] org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Reporting fetch failure for attempt_1352354913026_138167_m_000654_0 to jobtracker.
{noformat}

Even though the error was local to the reducer, it reported the error as a fetch failure to the AM than failing the reducer itself.  It then proceeded to run into the same error for many other maps, causing them to relaunch from reported fetch failures.  In this case it would have been better to fail the reducer and try another node rather than blame the mapper for what is an error on the reducer's side."
MAPREDUCE-4851,add lifecycle to Comparators,"current mapreduce api is using RawComparator interface in:

setGroupingComparatorClass
setSortComparatorClass

This interface has no lifecycle support. I propose to change that methods to take argument new class implements RawComparator with setup and cleanup methods. 

This will leave existing code with RawComparator alone, Providing some backward compatibility.

new class: 

class SortComparator implements RawComparator"
MAPREDUCE-4850,Job recovery may fail if staging directory has been deleted,"The job staging directory is deleted in the job cleanup task, which happens before the job-info file is deleted from the system directory (by the JobInProgress garbageCollect() method). If the JT shuts down between these two operations, then when the JT restarts and tries to recover the job, it fails since the job.xml and splits are no longer available."
MAPREDUCE-4848,TaskAttemptContext cast error during AM recovery,"Recently saw an AM that failed and tried to recover, but the subsequent attempt quickly exited with its own failure during recovery:

{noformat}
2012-12-05 02:33:36,752 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread
java.lang.ClassCastException: org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl cannot be cast to org.apache.hadoop.mapred.TaskAttemptContext
	at org.apache.hadoop.mapred.OutputCommitter.recoverTask(OutputCommitter.java:284)
	at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.handle(RecoveryService.java:361)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1211)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$ContainerAssignedTransition.transition(TaskAttemptImpl.java:1177)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:958)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:926)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:918)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
	at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.realDispatch(RecoveryService.java:285)
	at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:281)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
	at java.lang.Thread.run(Thread.java:619)
2012-12-05 02:33:36,752 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Exiting, bbye..
{noformat}

The RM then launched a third AM attempt which succeeded. The third attempt saw basically no progress after parsing the history file from the second attempt and ran the job again from scratch."
MAPREDUCE-4846,Some JobQueueInfo methods are public in MR1 but protected in MR2,"setQueueName, setSchedulingInfo, and setQueueState were public in MR1, but are private int MR2.  They should be made public with InterfaceAudience.Private.

getQueueState was public, but is now package private.  It has been replaced with getState, which returns a QueueState instead of a String.  It should be made public and deprecated, with a documentation reference to getState.

Should the other setter methods in JobQueueInfo that were not in MR1 be changed to public/InterfaceAudience.Private for consistency?
"
MAPREDUCE-4845,ClusterStatus.getMaxMemory() and getUsedMemory() exist in MR1 but not MR2 ,"For backwards compatibility, these methods should exist in both MR1 and MR2.

Confusingly, these methods return the max memory and used memory of the jobtracker, not the entire cluster.

I'd propose to add them to MR2 and return -1, and deprecate them in both MR1 and MR2.  Alternatively, I could add plumbing to get the resource manager memory stats."
MAPREDUCE-4844,Counters / AbstractCounters have constant references not declared final,"Counters have a number of immutable fields that have not been declared 'final'.

For example, the field groups is not final. It is, however, accessed in a couple of methods that are declared 'synchronized'. While there is a happens-before relationship between these methods calls, there is none between the Counters object initialization and these synchronized methods."
MAPREDUCE-4843,"When using DefaultTaskController, JobLocalizer not thread safe","In our cluster, some times job will failed due to below exception:
2012-12-03 23:11:54,811 WARN org.apache.hadoop.mapred.TaskTracker: Error initializing attempt_201212031626_1115_r_000023_0:
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/$username/jobcache/job_201212031626_1115/job.xml in any of the configured local directories
	at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:424)
	at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:160)
	at org.apache.hadoop.mapred.TaskTracker.initializeJob(TaskTracker.java:1175)
	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:1058)
	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:2213)

The root cause is JobLocalizer is not thread safe.
In DefaultTaskController.initializeJob method:
     JobLocalizer localizer = new JobLocalizer((JobConf)getConf(), user, jobid);
but in JobLocalizer, it just simply keep the reference of the conf.
When two TaskLauncher threads(mapLauncher and reduceLauncher) try to initializeJob at same time, it will have two JobLocalizer, but only one conf instance.
So some times ttConf.setStrings(JOB_LOCAL_CTXT, localDirs) will reset previous job's conf.
Then it will cause the previous job's job.xml stored at another user's dir."
MAPREDUCE-4842,Shuffle race can hang reducer,"Saw an instance where the shuffle caused multiple reducers in a job to hang.  It looked similar to the problem described in MAPREDUCE-3721, where the fetchers were all being told to WAIT by the MergeManager but no merge was taking place."
MAPREDUCE-4841,Application Master Retries fail due to FileNotFoundException,"Application attempt1 is deleting the job related files and these are not present in the HDFS for following retries.

{code:xml}
Application application_1353724754961_0001 failed 4 times due to AM Container for appattempt_1353724754961_0001_000004 exited with exitCode: -1000 due to: RemoteTrace: java.io.FileNotFoundException: File does not exist: hdfs://hacluster:8020/tmp/hadoop-yarn/staging/mapred/.staging/job_1353724754961_0001/appTokens at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:752) at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:88) at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:49) at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:157) at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:155) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232) at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:153) at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:49) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441) at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at java.util.concurrent.FutureTask.run(FutureTask.java:138) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:662) at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: File does not exist: hdfs://hacluster:8020/tmp/hadoop-yarn/staging/mapred/.staging/job_1353724754961_0001/appTokens at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217) at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147) at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:822) at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:492) at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:221) at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46) at org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:427) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:924) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1686) .Failing this attempt.. Failing the application. 
{code}
"
MAPREDUCE-4839,TextPartioner for hashing Text with good hashing function to get better distribution,partitioner for Text keys using util.Hash framework for hashing function
MAPREDUCE-4838,Add extra info to JH files,It will be useful to add more task-info to JH for analytics.
MAPREDUCE-4837,Add webservices for jobtracker,Add MR-AM web-services to branch-1
MAPREDUCE-4836,Elapsed time for running tasks on AM web UI tasks page is 0,Yeah! The summary
MAPREDUCE-4833,Task can get stuck in FAIL_CONTAINER_CLEANUP,"If an NM goes down and the AM still tries to launch a container on it the ContainerLauncherImpl can get stuck in an RPC timeout.  At the same time the RM may notice that the NM has gone away and inform the AM of this, this triggers a TA_FAILMSG.  If the TA_FAILMSG arrives at the TaskAttemptImpl before the TA_CONTAINER_LAUNCH_FAILED message then the task attempt will try to kill the container, but the ContainerLauncherImpl will not send back a TA_CONTAINER_CLEANED event causing the attempt to be stuck."
MAPREDUCE-4832,MR AM can get in a split brain situation,"It is possible for a networking issue to happen where the RM thinks an AM has gone down and launches a replacement, but the previous AM is still up and running.  If the previous AM does not need any more resources from the RM it could try to commit either tasks or jobs.  This could cause lots of problems where the second AM finishes and tries to commit too.  This could result in data corruption.  "
MAPREDUCE-4831,Task commit can occur more than once due to AM retries,"If a task attempt begins committing but the AM crashes before the task attempt completes then we could end up having the task commit again when the AM is relaunched.  The subsequent AM attempt will not see the task having completed, so it will re-run the task and it will commit again.  The output committer is user code, and the task commit may not be something repeatable.  Therefore we should treat an AM crash during a task attempt commit the same as we do for a commit failure by the task attempt, i.e.: the task should fail since we do not know how to recover from a commit failure.

This is similar to MAPREDUCE-4819, as this involves commit at the task level and that involves commit at the job-level."
MAPREDUCE-4829,Unit Test: TestMiniMRMapRedDebugScript fails when ran with ant-1.8.4 and not 1.7.x ,"Problem is caused by JUnit3 based testcases ran in Junit4 environment configured by ant 1.8.4..
in this case @Ignore tag is not getting ignored. 
This testcase has been removed from trunk"
MAPREDUCE-4828,Unit Test: TestTaskTrackerLocalization fails when ran with ant-1.8.4 and not 1.7.x,"Problem is caused by JUnit3 based testcases ran in Junit4 environment configured by ant 1.8.4..
in this case @Ignore tag is not getting ignored. 
This testcase has been removed from trunk"
MAPREDUCE-4827,Increase hash quality of HashPartitioner,"hash partitioner is using object.hashCode() for splitting keys into partitions. This results in bad distributions because hashCode() quality is poor. 

These hashCode() functions are sometimes written by hand (very poor quality) and sometimes generated from by commons lang code (poor quality). Applying some transformation on top of hashCode() provides better distribution."
MAPREDUCE-4825,JobImpl.finished doesn't expect ERROR as a final job state,"TestMRApp.testJobError is causing AsyncDispatcher to exit with System.exit due to an exception being thrown.  From the console output from testJobError:

{noformat}
2012-11-27 18:46:15,240 ERROR [AsyncDispatcher event handler] impl.TaskImpl (TaskImpl.java:internalError(665)) - Invalid event T_SCHEDULE on Task task_0_0000_m_000000
2012-11-27 18:46:15,242 FATAL [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(132)) - Error in dispatcher thread
java.lang.IllegalArgumentException: Illegal job state: ERROR
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.finished(JobImpl.java:838)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InternalErrorTransition.transition(JobImpl.java:1622)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl$InternalErrorTransition.transition(JobImpl.java:1)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:359)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:299)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:287)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:445)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:723)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:974)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:128)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:77)
	at java.lang.Thread.run(Thread.java:662)
2012-11-27 18:46:15,242 INFO  [AsyncDispatcher event handler] event.AsyncDispatcher (AsyncDispatcher.java:dispatch(135)) - Exiting, bbye..
{noformat}
"
MAPREDUCE-4824,Provide a mechanism for jobs to indicate they should not be recovered on restart,"Some jobs (like Sqoop or HBase jobs) are not idempotent, so should not be recovered on jobtracker restart. MAPREDUCE-2702 solves this problem for MR2, however the approach there is not applicable for MR1, since even if we only use the job-level part of the patch and add a isRecoverySupported method to OutputCommitter, there is no way to use that information from the JT (which initiates recovery), since the JT does not instantiate OutputCommitters - and it shouldn't since they are user-level code. (In MR2 it's OK since the MR AM calls the method.)

Instead, we can add a MR configuration property to say that a job is not recoverable, and the JT could safely read this from the job conf."
MAPREDUCE-4822,Unnecessary conversions in History Events,"There are a number of conversions in the Job History Event classes that are totally unnecessary.  It appears that they were originally used to convert from the internal avro format, but now many of them do not pull the values from the avro they store them internally.

For example:

{code:title=TaskAttemptFinishedEvent.java}
  /** Get the task type */
  public TaskType getTaskType() {
    return TaskType.valueOf(taskType.toString());
  }
{code}

The code currently is taking an enum, converting it to a string and then asking the same enum to convert it back to an enum.  If java work properly this should be a noop and a reference to the original taskType should be returned.

There are several places that a string is having toString called on it, and since strings are immutable it returns a reference to itself.

The various ids are not immutable and probably should not be changed at this point."
MAPREDUCE-4821,Unit Test: TestJobTrackerRestart fails when it is run with ant-1.8.4,"Problem:
JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4:
Solution:
Migrate the testcase to JUnit4, including:
* Remove extends TestCase""
* Remove import junit.framework.TestCase;
* Add import org.junit.*; 
* Use appropriate annotations such as @After, @Before, @Test.

uploading a patch shortly "
MAPREDUCE-4819,AM can rerun job after reporting final job status to the client,"If the AM reports final job status to the client but then crashes before unregistering with the RM then the RM can run another AM attempt.  Currently AM re-attempts assume that the previous attempts did not reach a final job state, and that causes the job to rerun (from scratch, if the output format doesn't support recovery).

Re-running the job when we've already told the client the final status of the job is bad for a number of reasons.  If the job failed, it's confusing at best since the client was already told the job failed but the subsequent attempt could succeed.  If the job succeeded there could be data loss, as a subsequent job launched by the client tries to consume the job's output as input just as the re-attempt starts removing output files in preparation for the output commit."
MAPREDUCE-4817,Hardcoded task ping timeout kills tasks localizing large amounts of data,"When a task is launched and spends more than 5 minutes localizing files, the AM will kill the task due to ping timeout.  The AM's TaskHeartbeatHandler currently tracks tasks via a progress timeout and a ping timeout.  The progress timeout can be controlled via mapreduce.task.timeout and even disabled by setting the property to 0.  The ping timeout, however, is hardcoded to 5 minutes and cannot be configured.  Therefore if the task takes too long localizing, it never gets running in order to ping back to the AM and the AM kills it due to ping timeout."
MAPREDUCE-4816,JobImpl Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED,"Saw this in an AM log of a task that had failed:

{noformat}
2012-11-21 23:26:44,533 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:690)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:113)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:904)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:900)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
	at java.lang.Thread.run(Thread.java:619)
{noformat}"
MAPREDUCE-4815,Speed up FileOutputCommitter#commitJob for many output files,"If a job generates many files to commit then the commitJob method call at the end of the job can take minutes.  This is a performance regression from 1.x, as 1.x had the tasks commit directly to the final output directory as they were completing and commitJob had very little to do.  The commit work was processed in parallel and overlapped the processing of outstanding tasks.  In 0.23/2.x, the commit is single-threaded and waits until all tasks have completed before commencing."
MAPREDUCE-4814,mr-jobhistory-daemon.sh does not parse --config options,
MAPREDUCE-4813,AM timing out during job commit,"The AM calls the output committer's {{commitJob}} method synchronously during JobImpl state transitions, which means the JobImpl write lock is held the entire time the job is being committed.  Holding the write lock prevents the RM allocator thread from heartbeating to the RM.  Therefore if committing the job takes too long (e.g.: the job has tons of files to commit and/or the namenode is bogged down) then the AM appears to be unresponsive to the RM and the RM kills the AM attempt."
MAPREDUCE-4812,Create reduce input merger plugin in ReduceTask.java and pass it to Shuffle,"This is part of MAPREDUCE-2454.  This further breaks down MAPREDUCE-4808
"
MAPREDUCE-4811,JobHistoryServer should show when it was started in WebUI About page,"Unlike the RM, the JHS doesn't show when it was started."
MAPREDUCE-4810,Add admin command options for ApplicationMaster,"It would be nice if the MR ApplicationMaster had the notion of admin options in addition to the existing user options much like we have for map and reduce tasks, e.g.: mapreduce.admin.map.child.java.opts vs. mapreduce.map.java.opts.  This allows site-wide configuration options for MR AMs but still allows a user to easily override the heap size of the AM without worrying about dropping other admin-specified options."
MAPREDUCE-4809,Change visibility of classes for pluggable sort changes,Make classes required for MAPREDUCE-2454 to be java public (with LimitedPrivate)
MAPREDUCE-4808,Refactor MapOutput and MergeManager to facilitate reuse by Shuffle implementations,"Now that Shuffle is pluggable (MAPREDUCE-4049), it would be convenient for alternate implementations to be able to reuse portions of the default implementation. 

This would come with the strong caveat that these classes are LimitedPrivate and Unstable.
"
MAPREDUCE-4807,Allow MapOutputBuffer to be pluggable,Allow MapOutputBuffer to be pluggable
MAPREDUCE-4806,Cleanup: Some (5) private methods in JobTracker.RecoveryManager are not used anymore after MAPREDUCE-3837,"MAPREDUCE-3837 re-organized the job recovery code, moving out the code that was using the methods in RecoveryManager.

Now, the following methods in {{JobTracker.RecoveryManager}}seem to be unused:
# {{updateJob()}}
# {{updateTip()}}
# {{createTaskAttempt()}}
# {{addSuccessfulAttempt()}}
# {{addUnsuccessfulAttempt()}}"
MAPREDUCE-4805,History files are not move to where the history server sees them,It looks like MAPREDUCE-4723 added in a default case to the JobHistoryEventHandler that is causing it to have lots of issues for events that should just be ignored.
MAPREDUCE-4803,Duplicate copies of TestIndexCache.java,"I am not sure whether it was intentional, but I found two identical copies of TestIndexCache.java one in hadoop-mapreduce-client-core and the other in hadoop-mapreduce-client-jobclient.

If someone confirms me it was not intentional, I can submit a small patch on this."
MAPREDUCE-4802,Takes a long time to load the task list on the AM for large jobs,We should turn on deferred rendering in DataTables as suggested by Luke here: https://issues.apache.org/jira/browse/YARN-151?focusedCommentId=13475811&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13475811
MAPREDUCE-4801,ShuffleHandler can generate large logs due to prematurely closed channels,"We ran into an instance where many nodes on a cluster ran out of disk space because the nodemanager logs were huge.  Examining the logs showed many, many shuffle errors due to either ClosedChannelException or IOException from ""Connection reset by peer"" or ""Broken pipe"".
"
MAPREDUCE-4800,Cleanup o.a.h.mapred.MapTaskStatus - remove unused code,"o.a.h.mapred.MapTaskStatus gets and sets sortFinishTime which is not accessed anywhere.

Also setFinishTime should getter/setter instead of accessing fields directly."
MAPREDUCE-4798,TestJobHistoryServer fails some times with 'java.lang.AssertionError: Address already in use',"UT Failure in IHC 1.0.3: org.apache.hadoop.mapred.TestJobHistoryServer. This UT fails sometimes.

The error message is:
'Testcase: testHistoryServerStandalone took 5.376 sec
	Caused an ERROR
Address already in use
java.lang.AssertionError: Address already in use
	at org.apache.hadoop.mapred.TestJobHistoryServer.testHistoryServerStandalone(TestJobHistoryServer.java:113)'"
MAPREDUCE-4797,LocalContainerAllocator can loop forever trying to contact the RM,"If LocalContainerAllocator has trouble communicating with the RM it can end up retrying forever if the nature of the error is not a YarnException.

This can be particulary bad if the connection went down because the cluster was reset such that the RM and NM have lost track of the process and therefore nothing else will eventually kill the process.  In this scenario, the looping AM continues to pelt the RM with connection requests every second using a stale token, and the RM logs the SASL exceptions over and over."
MAPREDUCE-4795,TestDelegationTokenRenewal should not use static variables in Renewer,"TestDelegationTokenRenewal uses static variables to access what's going on inside its Renewer class, making it so problems can occur if the tests are run in parallel."
MAPREDUCE-4794,DefaultSpeculator generates error messages on normal shutdown,"DefaultSpeculator can log the following error message on a normal shutdown of the ApplicationMaster:

{noformat}
2012-11-13 01:35:31,841 ERROR [DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: Background thread returning, interrupted : java.lang.InterruptedException
{noformat}

and in addition for some reason it logs the corresponding backtrace to stdout.

Like the errors fixed in MAPREDUCE-4741, this error message in the syslog and backtrace on stdout can be confusing to users as to whether the job really succeeded."
MAPREDUCE-4793,Problem with adding resources when using both -files and -file to hadoop streaming,"
It seems when
both -files and -file are present, it will trigger this IAE, and the error
message is just misleading. 

hadoop jar $HADOOP_PREFIX/share/hadoop/tools/lib/hadoop-streaming.jar
-files
hdfs://host:port/user/foo/access.log#test
-input 'input' -output 'output' -mapper ""egrep '.*'"" -file tmp.file

Below is the error message
12/11/02 07:37:54 INFO mapreduce.JobSubmitter: Cleaning up the staging area
/user/haiyang/.staging/job_1351804437209_0575
Exception in thread ""main"" java.lang.IllegalArgumentException: Resource name
must be relative
        at
org.apache.hadoop.mapreduce.v2.util.MRApps.parseDistributedCacheArtifacts(MRApps.java:383)
        at
org.apache.hadoop.mapreduce.v2.util.MRApps.setupDistributedCache(MRApps.java:324)
        at
org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(YARNRunner.java:419)
        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:288)"
MAPREDUCE-4792,Unit Test TestJobTrackerRestartWithLostTracker fails with ant-1.8.4,"Problem:
JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4:
Solution:
Migrate the testcase to JUnit4, including:
* Remove extends TestCase""
* Remove import junit.framework.TestCase;
* Add import org.junit.*; 
* Use appropriate annotations such as @After, @Before, @Test."
MAPREDUCE-4791,Javadoc for KeyValueTextInputFormat should include default separator and how to change it,"The javadoc for KeyValueTextInputFormat says ""Each line is divided into key and value parts by a separator byte"" but it doesn't say what the separator byte is or how to change it.

After some exploration I noticed that the default is the Tab character and that the value can be changed by the JobConf value ""key.value.separator.in.input.line"""
MAPREDUCE-4790,MapReduce build script would be more readable using abspath,"This is a follow-up to MAPREDUCE-4780, which was resolved before addressing some feedback to use abspath instead of normpath for improved readability in the build script."
MAPREDUCE-4789,Map Reduce Counters are 0 on the Job Tracker job details page,"Counters on the jobtracker details page are 0 for map and reduce columns.
This is reproduced using a simple wordcount. Of note is that customer counters show properly."
MAPREDUCE-4787,TestJobMonitorAndPrint is broken,"Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.169 sec <<< FAILURE!
testJobMonitorAndPrint(org.apache.hadoop.mapreduce.TestJobMonitorAndPrint)  Time elapsed: 1105 sec  <<< ERROR!
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint(TestJobMonitorAndPrint.java:97)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
"
MAPREDUCE-4786,Job End Notification retry interval is 5 milliseconds by default,"Courtesy [~stevenwillis] and [~qwertymaniac]
{quote}
From: Harsh J
I believe the configs of the latter of both of the above
classifications were meant to be added in as replacement names, but
the property names got added in wrong (as the former/older named ones)
in the XML.

the word ""seconds"" in the description of retries? The code in MR2's
JobEndNotifier seems to expect seconds but uses it directly in
Thread.sleep(…) without making it milliseconds, which may be a bug we
need to fix as well, perhaps in a same issue as the configs ones.

On Fri, Nov 9, 2012 at 11:21 PM, Steven Willis <swillis@compete.com> wrote:
> And I noticed that there are some duplicate properties with different values and different descriptions:
{quote}"
MAPREDUCE-4785,TestMRApp occasionally fails,"TestMRApp is failing occasionally with this error:

{noformat}
testUpdatedNodes(org.apache.hadoop.mapreduce.v2.app.TestMRApp): Expecting 2 more completion events for killed expected:<4> but was:<2>
{noformat}"
MAPREDUCE-4784,TestRecovery occasionally fails,"TestRecovery is occasionally failing with this error:

{noformat}
testCrashed(org.apache.hadoop.mapreduce.v2.app.TestRecovery): TaskAttempt state is not correct (timedout) expected:<FAILED> but was:<STARTING>
{noformat}"
MAPREDUCE-4783,data_join mavenization broke the mr1 build,MR-4238 didn't update build.xml and forgot to nuke the old data_join directory.
MAPREDUCE-4782,NLineInputFormat skips first line of last InputSplit,"NLineInputFormat creates FileSplits that are then used by LineRecordReader to generate Text values. To deal with an idiosyncrasy of LineRecordReader, the begin and length fields of the FileSplit are constructed differently for the first FileSplit vs. the rest.

After looping through all lines of a file, the final FileSplit is created, but the creation does not respect the difference of how the first vs. the rest of the FileSplits are created.

This results in the first line of the final InputSplit being skipped. I've created a patch to NLineInputFormat, and this fixes the problem."
MAPREDUCE-4780,MapReduce distribution build fails on Windows,Distribution build relies on sh scripts that do not work on Windows.
MAPREDUCE-4779,Unit test TestJobTrackerSafeMode fails with  ant 1.8.3+,"Problem:
  JUnit tag @Ignore is not recognized since the testcase is JUnit3 and not JUnit4:
Solution:
 Migrate the testcase to JUnit4"
MAPREDUCE-4778,Fair scheduler event log is only written if directory exists on HDFS,"The fair scheduler event log is supposed to be written to the local filesystem, at {hadoop.log.dir}/fairscheduler.  The event log will not be written unless this directory exists on HDFS."
MAPREDUCE-4777,"In TestIFile, testIFileReaderWithCodec relies on testIFileWriterWithCodec",The file used to test reading is expected to have been created by the file used to test writing
MAPREDUCE-4774,JobImpl does not handle asynchronous task events in FAILED state,"The test org.apache.hadoop.mapred.TestClusterMRNotification.testMR frequently  fails in mapred build (e.g. see https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2988/testReport/junit/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/ , or 
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/2982//testReport/org.apache.hadoop.mapred/TestClusterMRNotification/testMR/).

The test aims to check Job status notifications received through HTTP Servlet. It runs 3 jobs: successfull, killed, and failed. 
The test expects the servlet to receive some expected notifications in some expected order. It also tries to test the retry-on-failure notification functionality, so on each 1st notification the servlet answers ""400 forcing error"", and on each 2nd notification attempt it answers ""ok"". 
In general, the test fails because the actual number and/or type of the notifications differs from the expected.

Investigation shows that actual root cause of the problem is an incorrect job state transition: the 3rd job mapred task fails (by intentionally thrown  RuntimeException, see UtilsForTests#runJobFail()), and the state of the task changes from RUNNING to FAILED.
At this point JobEventType.JOB_TASK_ATTEMPT_COMPLETED event is submitted (in  method org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handleTaskAttemptCompletion(TaskAttemptId, TaskAttemptCompletionEventStatus)), and this event gets processed in AsyncDispatcher, but this transition is impossible according to the event transition map (see org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl#stateMachineFactory). This causes the following exception to be thrown upon the event processing:
2012-11-06 12:22:02,335 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:309)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$3(StateMachineFactory.java:290)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:454)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:716)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:1)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:917)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:1)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:130)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:79)
        at java.lang.Thread.run(Thread.java:662) 

So, the job gets into state ""INTERNAL_ERROR"", the job end notification like this is sent:
http://localhost:48656/notification/mapred?jobId=job_1352199715842_0002&amp;jobStatus=ERROR 
(here we can see ""ERROR"" status instead of ""FAILED"")
After that the notification servlet receives either only ""ERROR"" notification, or one more notification ""ERROR"" after ""FAILED"", which finally causes the test to fail. (Some variation in the test behavior caused by racing conditions because there are many asynchronous processings there, and the test is flaky, in fact).

In any way, it looks like the root cause of the problem is the possibility of the forbidden transition ""Invalid event: JOB_TASK_ATTEMPT_COMPLETED at FAILED"". 
Need an expert advice on how that should be fixed."
MAPREDUCE-4773,MultipleOutput with different output path for each ,"Is it possible to have multiple outputs in a map reduce code where each output is directed to a different path ?

e.g. 
FileOutputFormat.setOutputPath(job, new Path(outputPath));

MultipleOutputs.addNamedOutput(job, ""Output 1"", TextOutputFormat.class, Text.class, Text.class);

MultipleOutputs.addNamedOutput(job, ""Output 2"", TextOutputFormat.class, Text.class, Text.class);

Can ""Output 1"" & ""Output 2"" be alloted seperate paths ?"
MAPREDUCE-4772,Fetch failures can take way too long for a map to be restarted,"In one particular case we saw a NM go down at just the right time, that most of the reducers got the output of the map tasks, but not all of them.

The ones that failed to get the output reported to the AM rather quickly that they could not fetch from the NM, but because the other reducers were still running the AM would not relaunch the map task because there weren't more than 50% of the running reducers that had reported fetch failures.  Then because of the exponential back-off for fetches on the reducers it took until 1 hour 45 min for the reduce tasks to hit another 10 fetch failures and report in again. At that point the other reducers had finished and the job relaunched the map task.  If the reducers had still been running at 1:45 I have no idea how long it would have taken for each of the tasks to get to 30 fetch failures.

We need to trigger the map based off of percentage of reducers shuffling, not percentage of reducers running, we also need to have a maximum limit of the back off, so that we don't ever have the reducer waiting for days to try and fetch map output.  "
MAPREDUCE-4771,KeyFieldBasedPartitioner not partitioning properly when configured,"Relative to Hadoop 0.20/1.x, KeyFieldBasedPartitioner is not distributing across partitions properly when configured.  This is related to the double-configure issue as described in HADOOP-7425.  KeyFieldBasedPartitioner is getting configured twice, and that ends up duplicating the keyspecs and causing the keys to be hashed twice.

KeyFieldBasedPartitioner should not duplicate keyspecs when configured twice."
MAPREDUCE-4769,Pipes build problem with recent OpenSSL libs,"Seems to be a problem with CMake not figuring that the linker needs -lcrypto too with recent OpenSSL. Observed on two CentOS 6 build servers occurring after 'yum update' pulled down an openssl-devel update.

{noformat}
         [exec] Linking CXX executable examples/pipes-sort
         [exec] /usr/bin/cmake -E cmake_link_script CMakeFiles/pipes-sort.dir/li
         [exec] /usr/bin/c++    -g -Wall -O2 -D_REENTRANT -D_FILE_OFFSET_BITS=64
         [exec] /usr/bin/ld: libhadooppipes.a(HadoopPipes.cc.o): undefined refer
         [exec] /usr/bin/ld: note: 'BIO_ctrl' is defined in DSO /lib64/libcrypto
         [exec] /lib64/libcrypto.so.10: could not read symbols: Invalid operatio
         [exec] collect2: ld returned 1 exit status
         [exec] make[3]: *** [examples/pipes-sort] Error 1
         [exec] make[2]: *** [CMakeFiles/pipes-sort.dir/all] Error 2
         [exec] make[1]: *** [all] Error 2
{noformat}

This works around the problem:

{noformat}
diff --git hadoop-tools/hadoop-pipes/src/CMakeLists.txt hadoop-tools/hadoop-
index a1ee97d..29cfba7 100644
--- hadoop-tools/hadoop-pipes/src/CMakeLists.txt
+++ hadoop-tools/hadoop-pipes/src/CMakeLists.txt
@@ -71,5 +71,6 @@ add_library(hadooppipes STATIC
 )
 target_link_libraries(hadooppipes
     ${OPENSSL_LIBRARIES}
+    crypto
     pthread
 )

{noformat}

Builds with -Pnative won't complete without this."
MAPREDUCE-4765,Restarting the JobTracker programmatically can cause DelegationTokenRenewal to throw an exception,"The DelegationTokenRenewal class has a global Timer; when you stop the JobTracker by calling {{stopTracker()}} on it (or {{stopJobTracker()}} in MiniMRCluster), the JobTracker will call {{close()}} on DelegationTokenRenewal, which cancels the Timer.  If you then start up the JobTracker again by calling {{startTracker()}} on it (or {{startJobTracker()}} in MiniMRCluster), the Timer won't necessarily be re-created; and DelegationTokenRenewal will later throw an exception when it tries to use the Timer again (because you can't reuse a canceled Timer).  

DelegationTokenRenewal doesn't seem to be used in trunk, so we only need this for branch-1"
MAPREDUCE-4764,repair test org.apache.hadoop.mapreduce.security.TestBinaryTokenFile,"the test is @Ignore-ed, and fails being enabled.
Suggested to repair it to fill the coverage gap.

Problems fixed in the test: 
(1) MRConfig.FRAMEWORK_NAME and YarnConfiguration.RM_PRINCIPAL properties must be correctly set in the configuration to correctly enable the security in the way this test implies. 
(2) The property MRJobConfig.MAPREDUCE_JOB_CREDENTIALS_BINARY now is not passed into the Job configuration -- it is intentionally deleted from there. So, we pass the binary file name in another dedicated property. 
(3) The test was using deprecated cluster classes. All them are updated to the modern analogs.
(4) The delegation token found in the job context is now correctly compared to the one deserialized from the binary file.
"
MAPREDUCE-4763,repair test org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken,"The test was @Ignor-ed, however, it passes without any additional fixes, just being un-ignored."
MAPREDUCE-4762,repair test org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal,"The test org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal is @Ignor-ed. 
Due to that several classes in package org.apache.hadoop.mapreduce.security.token have zero unit-test coverage.

The problem is that the test assumed that class org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.Renewer is used as a custom implementation of the org.apache.hadoop.security.token.TokenRenewer service, but that did not happen, because this custom service implementation was not registered. 
We solved this problem by using special classloader that is invoked to find the resource META-INF/services/org.apache.hadoop.security.token.TokenRenewer , and supplies some custom content for it. This way the custom service implementation gets instantiated."
MAPREDUCE-4759,java.io.IOException: File too large,"when running mr job.one of cluster lost tasktracker some times。

see the hadoop-root-tasktracker-xxx.out ：

java.io.IOException: File too large
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:260)
        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)
        at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:272)
        at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:276)
        at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:122)
        at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:212)
        at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:58)
        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:316)
        at org.apache.log4j.DailyRollingFileAppender.subAppend(DailyRollingFileAppender.java:359)
        at org.apache.log4j.WriterAppender.append(WriterAppender.java:160)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.apache.commons.logging.impl.Log4JLogger.info(Log4JLogger.java:133)
        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:2972)
  
see files hs_err_pid20204.log and hadoop-root-tasktracker-t0928.log to get more details"
MAPREDUCE-4758,jobhistory web ui not showing correct # failed reducers,"we had a job fail due to a reducer failing 4 times.  Unfortunately the job history UI didn't show  this particular failed reducer which lead to confusion as to why the job failed. 

This reducer failed to launch all 4 task attempts with a Token Expiration error and the jobhistory file only gets an event when the task attempt transitions to launched.  The webapp JobInfo object only counts the task attempts in the jobhistory file to display under the ""Attempt Type"" table, so since this task didn't have an attempt with it, it did show it on the UI.

We need to reconcile the task list with the task attempts or also shows more stats for the tasks vs task attempts."
MAPREDUCE-4755,Rewrite MapOutputBuffer to use direct buffers & allow parallel sort+collect,"The MapOutputBuffer has been written with a very severe constraint on the amount of memory it can consume. This results in code that has to page-in & page-out (i.e spill) data as it passes through the map buffers.

With the advent of the java.nio package, there is a fast and portable MMap alternative to handling your own buffers. This exists outside the GC space of Java and yet provides decently fast memory access to all the data.

The suggestion is that using mmap() direct buffers can be faster when a spill is involved and simpler than the current spill logic when given enough address space & uses the buffer caches to deliver best effort I/O."
MAPREDUCE-4754,Job is marked as FAILED and also throwing the TransitonException instead of KILLED when issues a KILL command,"{code}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_TASK_COMPLETED at KILLED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:695)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:119)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:893)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:889)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
	at java.lang.Thread.run(Thread.java:662)
{code}"
MAPREDUCE-4752,Reduce MR AM memory usage through String Interning,"There are a lot of strings that are duplicates of one another in the AM.  This comes from all of the PB events the come across the wire and also tasks heart-beating in through the umbilical.  There are even several duplicates from Configuration.  By ""interning"" all of these strings on the Heap I have been able to reduce the resting memory usage of the AM to be about 5KB per task attempt.  With about half of this coming from counters.  This results in a 5MB heap for a typical 1000 task job, or a 500MB heap for a 100,000 task attempt job.  I think I could cut the size of the counters in half by completely rewriting how counters work in the AM and History Server, but I don't think it is worth it at this point.

I am still investigating what the memory usage of the AM is like when running very large jobs, and I will probably have a follow-up JIRA for reducing that memory usage as well.
"
MAPREDUCE-4751,AM stuck in KILL_WAIT for days,"We found some jobs were stuck in KILL_WAIT for days on end. The RM shows them as RUNNING. When you go to the AM, it shows it in the KILL_WAIT state, and a few maps running. All these maps were scheduled on nodes which are now in the RM's Lost nodes list. The running maps are in the FAIL_CONTAINER_CLEANUP state"
MAPREDUCE-4750,Enable NNBenchWithoutMR in MapredTestDriver,"Right now, we could run nnbench from MapredTestDriver only, there's no entry for NNBenchWithoutMR, it would be better enable it explicitly, such that we can do namenode benchmark with less influence factors"
MAPREDUCE-4749,Killing multiple attempts of a task taker longer as more attempts are killed,"The following was noticed on a mr job running on hadoop 1.1.0

1. Start an mr job with 1 mapper

2. Wait for a min

3. Kill the first attempt of the mapper and then subsequently kill the other 3 attempts in order to fail the job

The time taken to kill the task grew exponentially.

1st attempt was killed immediately.
2nd attempt took a little over a min
3rd attempt took approx. 20 mins
4th attempt took around 3 hrs.

The command used to kill the attempt was ""hadoop job -fail-task""

Note that the command returned immediately as soon as the fail attempt was accepted but the time the attempt was actually killed was as stated above.
"
MAPREDUCE-4748,Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED,"We saw this happen when running a large pig script.

{noformat}
2012-10-23 22:45:24,986 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Can't handle this event at current state for task_1350837501057_21978_m_040453
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: T_ATTEMPT_SUCCEEDED at SUCCEEDED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:604)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:89)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:914)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:908)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
{noformat}

Speculative execution was enabled, and that task did speculate so it looks like this is an error in the state machine either between the task attempts or just within that single task."
MAPREDUCE-4746,The MR Application Master does not have a config to set environment variables,"There is no mechanism for defining environment variables (i.e. LD_LIBRARY_PATH) for the MRAppMaster.

"
MAPREDUCE-4745,Application Master is hanging when the TaskImpl gets T_KILL event and completes attempts by the time  ,
MAPREDUCE-4744,Application Master is running forever when the TaskAttempt gets TA_KILL event at the state SUCCESS_CONTAINER_CLEANUP,"When the Task issues KILL event to TaskAttempt, It is expecting to get event back to the Task from TaskAttempt. If the Task Attempt state SUCCESS_CONTAINER_CLEANUP state then it is ignoring and Task is waiting."
MAPREDUCE-4743,Job is marking as FAILED and also throwing the Transition exception instead of KILLED when issues a KILL command,"{code:xml}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: T_KILL at SUCCEEDED
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:605)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl.handle(TaskImpl.java:89)
   at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:903)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskEventDispatcher.handle(MRAppMaster.java:897)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
	at java.lang.Thread.run(Thread.java:662)
{code}"
MAPREDUCE-4742,Fix typo in nnbench#displayUsage,
MAPREDUCE-4741,WARN and ERROR messages logged during normal AM shutdown,"The ApplicationMaster is logging WARN and ERROR messages during normal shutdown, and some users are misinterpreting these as serious problems.  For example:

{noformat}
2012-10-02 13:58:50,247 ERROR [ContainerLauncher Event Handler] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Returning, interrupted : java.lang.InterruptedException
[...]
2012-10-02 13:58:50,248 ERROR [Thread-47] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Returning, interrupted : java.lang.InterruptedException
2012-10-02 13:58:50,248 WARN [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Allocated thread interrupted. Returning.
[...]
2012-10-02 13:58:50,367 ERROR [TaskCleaner Event Handler] org.apache.hadoop.mapreduce.v2.app.taskclean.TaskCleanerImpl: Returning, interrupted : java.lang.InterruptedException
{noformat}

Warnings or errors should not be logged if everything is working as intended."
MAPREDUCE-4740,only .jars can be added to the Distributed Cache classpath,"Koji tracked down this one.


{noformat}
$ cat mycat.sh
#!/bin/sh
cat >& /dev/null
$JAVA_HOME/bin/jinfo $PPID | grep java.class.path
export | grep CLASSPATH
ls -l 

$ myfile=/user/me/myclasses.zip; yarn jar
hadoop-streaming.jar
-Dmapreduce.job.cache.archives=hdfs:///${myfile}
-Dmapreduce.job.classpath.archives=${myfile} -input in.txt -output out -reducer NONE -mapper mycat.sh  -file mycat.sh
{noformat}

So, cachearchive like class.zip or class.tar.gz were never set as part of the
classpath even though they were properly set by DistributedCache.addArchiveToClassPath.

It looks like we are parsing the classpath out of the configs, but then throwing that away.  It looks simple enough to add them in the correct place."
MAPREDUCE-4739,Some MapReduce tests fail to find winutils.,"All modules inherit a setting in the Surefire configuration for HADOOP_HOME via the hadoop-project pom.xml.  This setting is a relative path used in Shell.java to find winutils when running on Windows.  The MapReduce modules have a deeper directory structure, which makes the inherited value of HADOOP_HOME invalid and causes some tests to fail while calling winutils."
MAPREDUCE-4737, Hadoop does not close output file / does not call Mapper.cleanup if exception in map,"Find this in Pig unit test TestStore under Windows. There are dangling files because map does not close the file when exception happens in map(). In Windows, Hadoop will not remove a file if it is not closed. This happens in reduce() as well."
MAPREDUCE-4736,Remove obsolete option [-rootDir] from TestDFSIO,Looks like this option is obsolete. Remove it to avoid confusion. 
MAPREDUCE-4735,Make arguments in TestDFSIO case insensitive,"It would be convenient if the arguments in TestDFSIO were case insensitive.  For example, it should allow ""-read"", ""-Read"", etc.  "
MAPREDUCE-4733,Reducer can fail to make progress during shuffle if too many reducers complete consecutively,"TaskAttemptListenerImpl implements getMapCompletionEvents by calling Job.getTaskAttemptCompletionEvents with the same fromEvent and maxEvents passed in from the reducer and then filtering the result for just map events. We can't filter the task completion event list and expect the caller's ""window"" into the list to match up.  As soon as a reducer event appears in the list it means we are redundantly sending map completion events that were already seen by the reducer.

Worst case the reducer will hang if all of the events in the requested window are reducer events.  In that case zero events will be reported back to the caller and it won't bump up fromEvent on the next call.  Reducer then never sees the final map completion events needed to complete the shuffle. This could happen in a case where all maps complete, more than MAX_EVENTS reducers complete consecutively, but some straggling reducers get fetch failures and cause a map to be restarted."
MAPREDUCE-4730,AM crashes due to OOM while serving up map task completion events,We're seeing a repeatable OOM crash in the AM for a task with around 30000 maps and 3000 reducers.  Details to follow.
MAPREDUCE-4729,job history UI not showing all job attempts,"We are seeing a case where a job runs but the AM is running out of memory in the first 3 attempts. The job eventually finishes on the 4th attempt.  When you go to the job history UI for that job, it only shows the last attempt.  This is bad since we want to see why the first 3 attempts failed.

The RM web ui shows all 4 attempts. 

Also I tested this locally by running ""kill"" on the app master and in that case the history server UI does show all attempts."
MAPREDUCE-4727,[MAPREDUCE-3902] Handle a successful NM stop request,"The branch currently ignores successful container stop requests to the NodeManager, and waits instead for a ContainerFinished message from the RM.
These stop requests should be handled."
MAPREDUCE-4726,Empty catch blocks cause findbugs 2 warnings,Debug messages can be logged.
MAPREDUCE-4725,Setting local variables to null causes findbugs 2 warnings,"In a couple places, local variables are set to null when they are no longer used.  This is unnecessary as the compiler is able to figure this out, and causes findbugs warnings."
MAPREDUCE-4724,job history web ui applications page should be sorted to display last app first,"The job history server jobs web page defaults the sort order to ascending, which has oldest jobs first (smallest job id).   I think its more useful to sort descending so that the newest jobs show first since those are more likely what people are going to look at.  YARN-159 changed this for RM apps page. "
MAPREDUCE-4723,Fix warnings found by findbugs 2,The MAPREDUCE side of HADOOP-8594. Umbrella jira for fixing the warnings found by findbugs 2.
MAPREDUCE-4722,LocalJobRunner random ID should not be chosen with Math.abs(rand.nextInt()),"According to findbugs 2, this can cause problems if the randomly generated int is Integer.MIN_VALUE because Math.abs(Integer.MIN_VALUE) == Integer.MIN_VALUE."
MAPREDUCE-4721,Task startup time in JHS is same as job startup time.,"As Bobby pointed out in https://issues.apache.org/jira/browse/MAPREDUCE-4711?focusedCommentId=13471696&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13471696

In the Map and Reduce tasks page, it should print the earliest task attempt launch time as TaskImpl:getLaunchTime() does."
MAPREDUCE-4720,Browser thinks History Server main page JS is taking too long,"The main History Server page with the default settings of 20,000 jobs can cause browsers to think that the JS on the page is stuck and ask you if you want to kill it. This is a big usability problem."
MAPREDUCE-4719,mapred.TaskInProgress should be public,"In Cloudera's CDH3 distributions, mapred.TaskInProgress has been made public along with its generateSingleReport() and getDiagnosticInfo() methods.

Should this change be brought back into the main source tree?

"
MAPREDUCE-4717,Mapreduce job fails to run after configuring multiple namespaces [HDFS Federation],"I am having setup of 4 nodes with following details -

Standalone Desktop-1 -> NameNode1,Tasktracker,Zookeeper,Jobtracker,datanode,HMaster

Standalone Desktop-2 -> NameNode2,Tasktracker,datanode.RegionServer

Virtual Machine-1 -> Namenode3,Datanode,Tasktracker

Virtual Machine-2 -> Namenode4,Datanode,Tasktracker


I have configured HDFS Federation with following name service -
a) nameservice1
b) oss-hadoop-nameservice

While executing Mapreduce job I am getting following error -

================================================================
-bash-4.1$ id
uid=496(hdfs) gid=496(hdfs) groups=496(hdfs),497(hadoop)
-bash-4.1$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount /hbase/install.log.syslog /hbase/testing
12/10/10 12:30:21 ERROR security.UserGroupInformation: PriviledgedActionException as:hdfs (auth:SIMPLE) cause:java.io.IOException: viewfs://cluster6/
java.io.IOException: viewfs://cluster6/
        at org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:338)
        at org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:178)
        at org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:178)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2150)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:80)
        at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2184)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2166)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:302)
        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:194)
        at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:103)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:850)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:844)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:844)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:481)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:511)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:67)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:64)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:208)
-bash-4.1$
================================================================"
MAPREDUCE-4716,TestHsWebServicesJobsQuery.testJobsQueryStateInvalid fails with jdk7,"Using jdk7 TestHsWebServicesJobsQuery.testJobsQueryStateInvalid  fails.

It looks like the string changed from ""const class"" to ""constant"" in jdk7.


Tests run: 25, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 9.713 sec <<< FAILURE!
testJobsQueryStateInvalid(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery)  Time elapsed: 0.371 sec  <<< FAILURE!
java.lang.AssertionError: exception message doesn't match, got: No enum constant org.apache.hadoop.mapreduce.v2.api.records.JobState.InvalidState expected: No enum const class org.apache.hadoop.mapreduce.v2.api.records.JobState.InvalidState
        at org.junit.Assert.fail(Assert.java:91)        at org.junit.Assert.assertTrue(Assert.java:43)
        at org.apache.hadoop.yarn.webapp.WebServicesTestUtils.checkStringMatch(WebServicesTestUtils.java:77)
        at org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery.testJobsQueryStateInvalid(TestHsWebServicesJobsQuery.java:286)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
"
MAPREDUCE-4713,mr-jobhistory-daemon.sh --config option doesn't work,"I was trying to start the job history server with --config option (mr-jobhistory-daemon.sh --config /conf start historyserver)  but it fails and simply prints the usage:


Usage: mr-jobhistory-daemon.sh [--config <conf-dir>] (start|stop) <mapred-command>


The only way I could get it to start is remove the --config option."
MAPREDUCE-4712,mr-jobhistory-daemon.sh doesn't accept --config,"It says
{code}
$ $HADOOP_MAPRED_HOME/sbin/mr-jobhistory-daemon.sh --config /Users/vinodkv/tmp/conf/ start historyserver
Usage: mr-jobhistory-daemon.sh [--config <conf-dir>] (start|stop) <mapred-command>
{code}"
MAPREDUCE-4711,Append time elapsed since job-start-time for finished tasks,"In 0.20.x/1.x, the analyze job link gave this information

bq. The last Map task task_<sometask> finished at (relative to the Job launch time): 5/10 20:23:10 (1hrs, 27mins, 54sec)

The time it took for the last task to finish needs to be calculated mentally in 0.23. I believe we should print it next to the finish time."
MAPREDUCE-4710,Add peak memory usage counter for each task,"Each task has counters PHYSICAL_MEMORY_BYTES and VIRTUAL_MEMORY_BYTES, which are snapshots of memory usage of that task. They are not sufficient for users to understand peak memory usage by that task, e.g. in order to diagnose task failures, tune job parameters or change application design. This new feature will add two more counters for each task: PHYSICAL_MEMORY_BYTES_MAX and VIRTUAL_MEMORY_BYTES_MAX. "
MAPREDUCE-4707,Add a comment to explain why FairScheduler#dump()'s body is synchronized on eventLog,"FairScheduler#dump() is a synchronized method. In addition to that, the entire method body is in a synchronized block on eventLog. However, there is no other portion of the code that tries to acquire a lock on eventLog. So, it seems like the second synchronized block is redundant, and can be removed."
MAPREDUCE-4706,FairScheduler#dump(): Computing of # running maps and reduces is commented out,"In FairScheduler#dump(), we conveniently comment the updating of number of running maps and reduces. It needs to be fixed for the dump to throw out meaningful information."
MAPREDUCE-4705,Historyserver links expire before the history data does,"The historyserver can serve up links to jobs that become useless well before the job history files are purged.  For example on a large, heavily used cluster we can end up rotating through the maximum number of jobs the historyserver can track fairly quickly.  If a user was investigating an issue with a job using a saved historyserver URL, that URL can become useless because the historyserver has forgotten about the job even though the history files are still sitting in HDFS.

We can tell the historyserver to keep track of more jobs by increasing {{mapreduce.jobhistory.joblist.cache.size}}, but this has a direct impact on the responsiveness of the main historyserver page since it serves up all the entries to the client at once.  It looks like Hadoop 1.x avoided this issue by encoding the history file location into the URLs served up by the historyserver, so it didn't have to track a mapping between job ID and history file location."
MAPREDUCE-4703,Add the ability to start the MiniMRClientCluster using the configurations used before it is being stopped.,"The objective here is to enable starting back the cluster, after being stopped, using the same configurations/port numbers used before stopping."
MAPREDUCE-4699,TestFairScheduler & TestCapacityScheduler fails due to JobHistory exception,"TestFairScheduler fails due to exception from mapred.JobHistory

{code}
null
java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobHistory$JobInfo.logJobPriority(JobHistory.java:1975)
	at org.apache.hadoop.mapred.JobInProgress.setPriority(JobInProgress.java:895)
	at org.apache.hadoop.mapred.TestFairScheduler.testFifoPool(TestFairScheduler.java:2617)
{code}

TestCapacityScheduler fails due to

{code}
java.lang.NullPointerException
    at org.apache.hadoop.mapred.JobHistory$JobInfo.logJobPriority(JobHistory.java:1976)
    at org.apache.hadoop.mapred.JobInProgress.setPriority(JobInProgress.java:895)
    at org.apache.hadoop.mapred.TestCapacityScheduler$FakeTaskTrackerManager.setPriority(TestCapacityScheduler.java:653)
    at org.apache.hadoop.mapred.TestCapacityScheduler.testHighPriorityJobInitialization(TestCapacityScheduler.java:2666)
{code}

Update UtilsForTest::getJobTracker to call initialize()/initializeFileSystem() to match behaviour in pre-safe mode constructor."
MAPREDUCE-4698,TestJobHistoryConfig throws Exception in testJobHistoryLogging,"TestJobHistoryConfig cannot find the LOG_DIR and throws 

{code}
Can not create a Path from a null string
java.lang.IllegalArgumentException: Can not create a Path from a null string
    at org.apache.hadoop.fs.Path.checkPathArg(Path.java:78)
    at org.apache.hadoop.fs.Path.<init>(Path.java:90)
    at org.apache.hadoop.mapred.JobHistory$JobInfo.getJobHistoryFileName(JobHistory.java:1337)
    at org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:1660)
    at org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:1641)
    at org.apache.hadoop.mapred.TestJobHistoryConfig.testJobHistoryLogging(TestJobHistoryConfig.java:123)
{code}"
MAPREDUCE-4697,TestMapredHeartbeat fails assertion on HeartbeatInterval,"TestMapredHeartbeat fails test on heart beat interval

{code}
    FAILED
expected:<300> but was:<500>
junit.framework.AssertionFailedError: expected:<300> but was:<500>
    at org.apache.hadoop.mapred.TestMapredHeartbeat.testJobDirCleanup(TestMapredHeartbeat.java:68)
{code}

Replicate math for getNextHeartbeatInterval() in the test-case to ensure MRConstants changes do not break test-case."
MAPREDUCE-4696,TestMRServerPorts throws NullReferenceException,"TestMRServerPorts throws 

{code}
java.lang.NullPointerException
    at org.apache.hadoop.mapred.TestMRServerPorts.canStartJobTracker(TestMRServerPorts.java:99)
    at org.apache.hadoop.mapred.TestMRServerPorts.testJobTrackerPorts(TestMRServerPorts.java:152)
{code}

Use the JobTracker.startTracker(string, string, boolean initialize) factory method to get a pre-initialized JobTracker for the test.
"
MAPREDUCE-4695,Fix LocalRunner on trunk after MAPREDUCE-3223 broke it,"MAPREDUCE-3223 removed mapreduce.cluster.local.dir property from mapred-default.xml (since NM local dirs are now used) but failed to counter that LocalJobRunner, etc. still use it.

{code}
mr-3223.txt:-  <name>mapreduce.cluster.local.dir</name>
mr-3223.txt--  <value>${hadoop.tmp.dir}/mapred/local</value>
{code}

All local job tests have been failing since then.

This JIRA is to reintroduce it or provide an equivalent new config for fixing it."
MAPREDUCE-4694,Inconsistency in reduce input record counters between the stable and evolving APIs,"In the stable (mapred) API execution, if the values iterator is skipped by a user, the records underneath it aren't counted in the ""Reduce input records"" counter as the key progresses to the next unique one. In the evolving API (mapreduce) API execution, if the values iterator is skipped by a user, the records underneath it is still counted as the key progresses to the next unique one.

This behavior comes to me as a faulty one in the old API. A ""Reduce input records"" counter must always define all the records that have been passed into a reducer (cause they are read regardless of skipping), and both API's record counting despite user applications must be consistent.

I'll post a test case illustrating this shortly."
MAPREDUCE-4693,Historyserver should provide counters for failed tasks,"Currently the historyserver is not providing counters for failed tasks, even though they are available via the AM as long as the job is still running.  Those counters are lost when the client needs to redirect to the historyserver after the job completes."
MAPREDUCE-4691,"Historyserver can report ""Unknown job"" after RM says job has completed","Example traceback from the client:

{noformat}
2012-09-27 20:28:38,068 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-09-27 20:28:38,530 [main] WARN  org.apache.hadoop.mapred.ClientServiceDelegate - Error from remote end: Unknown job job_1348097917603_3019
2012-09-27 20:28:38,530 [main] ERROR org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:xxx (auth:KERBEROS) cause:org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019
2012-09-27 20:28:38,531 [main] WARN  org.apache.pig.tools.pigstats.JobStats - Failed to get map task report
RemoteTrace: 
 at LocalTrace: 
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1348097917603_3019
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:156)
        at $Proxy11.getJobReport(Unknown Source)
        at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:116)
        at sun.reflect.GeneratedMethodAccessor6.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:298)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:383)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:482)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:184)
...
{noformat}
"
MAPREDUCE-4690,remove deprecated properties in the default configurations,"We need to remove the deprecated properties included in the default configurations, such as core-default.xml and core-site.xml."
MAPREDUCE-4689,JobClient.getMapTaskReports on failed job results in NPE,"When calling JobClient.getMapTaskReports for a job that has failed results in an NPE.  For example:

{noformat}
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.counters.AbstractCounters.<init>(AbstractCounters.java:107)
	at org.apache.hadoop.mapred.Counters.<init>(Counters.java:71)
	at org.apache.hadoop.mapred.Counters.downgrade(Counters.java:80)
	at org.apache.hadoop.mapred.TaskReport.downgrade(TaskReport.java:81)
	at org.apache.hadoop.mapred.TaskReport.downgradeArray(TaskReport.java:88)
	at org.apache.hadoop.mapred.JobClient.getTaskReports(JobClient.java:691)
	at org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobClient.java:681)
...
{noformat}
"
MAPREDUCE-4687,Add compilation of 'classic' MR1 (ant based) to jenkins builds,
MAPREDUCE-4686,hadoop-mapreduce-client-core fails compilation in Eclipse due to missing Avro-generated classes,"After importing all of hadoop-common trunk into Eclipse with the m2e plugin, the Avro-generated classes in hadoop-mapreduce-client-core don't show up on Eclipse's classpath.  This causes compilation errors for anything that depends on those classes.
"
MAPREDUCE-4685,DBCount should not use ACCESS ,"DBCount uses ACCESS as table name which is not supported for Oracle DBs since it is a keyword in Oracle as per http://docs.oracle.com/cd/B10501_01/appdev.920/a42525/apb.htm

Also, BIGINT isn't supported.

I will shortly post a patch to address this."
MAPREDUCE-4683,Create and distribute hadoop-mapreduce-client-core-tests.jar,"We need to fix our build to create/distribute hadoop-mapreduce-client-core-tests.jar, need this before MAPREDUCE-4253"
MAPREDUCE-4682,TestKillSubProcess & TestTaskTrackerMemoryManager fail to compile on trunk due to MAPREDUCE-4253,"Fail with:

 /Users/acmurthy/dev/apache/hadoop/hadoop-trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestKillSubProcesses.java:411: cannot find symbol
    [javac] symbol  : variable TestProcfsBasedProcessTree
    [javac] location: class org.apache.hadoop.mapred.TestKillSubProcesses
    [javac]         childPid = TestProcfsBasedProcessTree.getPidFromPidFile(scriptDirName
    [javac]                    ^
    [javac] /Users/acmurthy/dev/apache/hadoop/hadoop-trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerMemoryManager.java:449: cannot find symbol
    [javac] symbol  : variable TestProcfsBasedProcessTree
    [javac] location: class org.apache.hadoop.mapred.TestTaskTrackerMemoryManager
    [javac]       TestProcfsBasedProcessTree.setupProcfsRootDir(procfsRootDir);
"
MAPREDUCE-4681,HDFS-3910 broke MR tests,HDFS-3910 changed signatures of DFSTestUtil functions and didn't change MR tests.
MAPREDUCE-4680,Job history cleaner should only check timestamps of files in old enough directories,"Job history files are stored in yyyy/mm/dd folders.  Currently, the job history cleaner checks the modification date of each file in every one of these folders to see whether it's past the maximum age.  The load on HDFS could be reduced by only checking the ages of files in directories that are old enough, as determined by their name."
MAPREDUCE-4678,Running the Pentomino example with defaults throws java.lang.NegativeArraySizeException,"HADOOP_HOME/hadoop-examples.jar pentomino <output_dir> will fail with the following error message: 
{code}
INFO util.NativeCodeLoader: Loaded the native-hadoop library 
INFO mapred.FileInputFormat: Total input paths to process : 1 
INFO mapred.JobClient: Running job: job_xxxxx
INFO mapred.JobClient: map 0% reduce 0% 
INFO mapred.JobClient: Task Id : attempt_xxxx, Status : FAILED 
java.lang.NegativeArraySizeException 
at org.apache.hadoop.examples.dancing.DistributedPentomino$PentMap.map(Di 
stributedPentomino.java:95) 
at org.apache.hadoop.examples.dancing.DistributedPentomino$PentMap.map(Di 
stributedPentomino.java:51) 
at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50) 
at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:391) 
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325) 
at org.apache.hadoop.mapred.Child$4.run(Child.java:270) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:396) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformat 
ion.java:1177) 
at org.apache.hadoop.mapred.Child.main(Child.java:264)
{code}"
MAPREDUCE-4675,TestKillSubProcesses fails as the process is still alive after the job is done,"I ran this test in branch 1 and branch 1.1 and they both failed with the following

{code}
Testcase: testJobKillFailAndSucceed took 82.219 sec
        FAILED
null
junit.framework.AssertionFailedError: null
        at org.apache.hadoop.mapred.TestKillSubProcesses.validateKillingSubprocesses(TestKillSubProcesses.java:245)
        at org.apache.hadoop.mapred.TestKillSubProcesses.runKillingJobAndValidate(TestKillSubProcesses.java:97)
        at org.apache.hadoop.mapred.TestKillSubProcesses.runTests(TestKillSubProcesses.java:336)
        at org.apache.hadoop.mapred.TestKillSubProcesses.testJobKillFailAndSucceed(TestKillSubProcesses.java:320)
{code}"
MAPREDUCE-4674,"Hadoop examples secondarysort has a typo ""secondarysrot"" in the usage","$ hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar secondarysort
Usage: secondarysrot <in> <out>
"
MAPREDUCE-4673,make TestRawHistoryFile and TestJobHistoryServer more robust,"these unit tests fail if 2 different users run them on the same host as they are using /tmp/input path

following is the info from the test log

{code}
testcase classname=""org.apache.hadoop.mapred.TestJobHistoryServer"" name=""testHistoryServerStandalone"" time=""4.572"">
    <failure message=""/tmp/.input.crc (Permission denied)"" type=""junit.framework.AssertionFailedError"">junit.framework.AssertionFailedError: /tmp/.input.crc (Permission denied)
        at org.apache.hadoop.mapred.TestJobHistoryServer.testHistoryServerStandalone(TestJobHistoryServer.java:113)
</failure>
{code}"
MAPREDUCE-4672,RM with lost NMs results in massive log of AppAttemptId doesnt exist in cache,"Hey Guys,

I'm running a 9 node cluster with 8 NMs and a single RM node. If I run an app master and have that app master start a container, then shut down all NMs, but leave the RM up (to simulate a failure), the containers timeout and fail, as expected.

What's unexpected is that my log then starts filling with:


2012-09-21 18:02:02,614 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:03,617 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:04,618 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:05,620 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:06,621 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:07,623 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001
2012-09-21 18:02:08,624 ERROR resourcemanager.ApplicationMasterService (ApplicationMasterService.java:allocate(247)) - AppAttemptId doesnt exist in cache appattempt_1348248013002_0001_000001

Is there any way to shut this off/fix it? It just keeps going forever, until I bounce the RM node.

Thanks!
Chris"
MAPREDUCE-4671,AM does not tell the RM about container requests that are no longer needed,"Say the AM wanted a container at hosts h1, h2, h3. After getting a container at h1 it should tell RM that it no longer needs containers at h2, h3. Otherwise on the RM h2, h3 remain valid allocation locations.
The AM RMContainerAllocator does remove these resource requests internally. When the resource request container count drops to 0 then it drops the resource request from its tables but forgets to send the 0 sized request to the RM."
MAPREDUCE-4670,HadoopServiceTestDFSIOBenchmark could switch to hadoop version of TestDFSIO,"Assuming I've got my versions right, that 1.0.3 is after 0.20.2, then MAPREDUCE-1832 is fixed, so after WHIRR-661 is in the local copy of TestDFSIO can be pulled. "
MAPREDUCE-4669,MRAM web UI does not work with HTTPS,"With Kerberos enable, the MRAM runs as the user that submitted the job, thus the MRAM process cannot read the cluster keystore files to get the certificates to start its HttpServer using HTTPS.

We need to decouple the keystore used by RM/NM/NN/DN (which are cluster provided) from the keystore used by AMs (which ought to be user provided).
"
MAPREDUCE-4666,JVM metrics for history server,It would be nice if the job history server provided the same JVM metrics via metrics2 that other Hadoop daemons are already providing.
MAPREDUCE-4665,[MAPREDUCE-3902] Use the configured shuffle port and application ACLs,
MAPREDUCE-4664,[MAPREDUCE-3902] ContainerHeartbeatHandler should be pinged on a getTask call,
MAPREDUCE-4663,[MAPREDUCE-3902] Container Launch should be independent of o.a.h.m.Task,Since a container/JVM can be used across TaskAttempts - launching the jvm should not depend on an individual task.
MAPREDUCE-4662,JobHistoryFilesManager thread pool never expands,"The job history file manager creates a threadpool with core size 1 thread, max pool size 3.   It never goes beyond 1 thread though because its using a LinkedBlockingQueue which doesn't have a max size. 

    void start() {
      executor = new ThreadPoolExecutor(1, 3, 1,
          TimeUnit.HOURS, new LinkedBlockingQueue<Runnable>());
    }

According to the ThreadPoolExecutor java doc page it only increases the number of threads when the queue is full. Since the queue we are using has no max size it never fills up and we never get more then 1 thread. "
MAPREDUCE-4660,Update task placement policy for NetworkTopology with 'NodeGroup' layer,
MAPREDUCE-4658,Move tools JARs into separate lib directories and have common bootstrap script.,"This is a follow up of the discussion going on on MAPREDUCE-4644

--
Moving each tools JARs into separate lib/ dirs it is quite easy (modifying a single assembly). What we should think is a common bootstrap script for that so each tool does not have to duplicate (and get wrong) such script. I'll open a JIRA for that.
--
"
MAPREDUCE-4657,WindowsResourceCalculatorPlugin has NPE,"When Shell command execution is interrupted then WindowsResourceCalculatorPlugin has NPE.
code}
2012-08-31 13:01:00,140 ERROR [Thread-771] util.WindowsResourceCalculatorPlugin(69): java.io.IOException: java.lang.InterruptedException^M
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:424)^M
        at org.apache.hadoop.util.Shell.run(Shell.java:336)^M
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:540)^M
        at org.apache.hadoop.util.WindowsResourceCalculatorPlugin.getSystemInfoInfoFromShell(WindowsResourceCalculatorPlugin.java:66)^M
        at org.apache.hadoop.util.WindowsResourceCalculatorPlugin.refreshIfNeeded(WindowsResourceCalculatorPlugin.java:81)^M
        at org.apache.hadoop.util.WindowsResourceCalculatorPlugin.getAvailableVirtualMemorySize(WindowsResourceCalculatorPlugin.java:126)^M
        at org.apache.hadoop.mapred.TaskTracker.getAvailableVirtualMemoryOnTT(TaskTracker.java:1933)^M
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:1834)^M
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1664)^M
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2516)^M
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner.run(MiniMRCluster.java:217)^M
        at java.lang.Thread.run(Thread.java:662)^M
^M
2012-08-31 13:01:00,140 ERROR [Thread-771] mapred.TaskTracker(1766): Caught exception: java.lang.NullPointerException^M
        at org.apache.hadoop.util.WindowsResourceCalculatorPlugin.refreshIfNeeded(WindowsResourceCalculatorPlugin.java:83)^M
        at org.apache.hadoop.util.WindowsResourceCalculatorPlugin.getAvailableVirtualMemorySize(WindowsResourceCalculatorPlugin.java:126)^M
        at org.apache.hadoop.mapred.TaskTracker.getAvailableVirtualMemoryOnTT(TaskTracker.java:1933)^M
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:1834)^M
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1664)^M
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:2516)^M
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner.run(MiniMRCluster.java:217)^M
        at java.lang.Thread.run(Thread.java:662)^M
{code}"
MAPREDUCE-4656,Can't run TestDFSIO due to junit dependency,"TestDFSIO can't be run from the tarball any more.  The tarball does not bundle junit, and TestDFSIO makes use of that library."
MAPREDUCE-4655,MergeManager.reserve can OutOfMemoryError if more than 10% of max memory is used on non-MapOutputs,"The MergeManager does a memory check, using a limit that defaults to 90% of Runtime.getRuntime().maxMemory(). Allocations that would bring the total memory allocated by the MergeManager over this limit are asked to wait until memory frees up. Disk is used for single allocations that would be over 25% of the memory limit.

If some other part of the reducer were to be using more than 10% of the memory. the current check wouldn't stop an OutOfMemoryError.

Before creating an in-memory MapOutput, a check can be done using Runtime.getRuntime().freeMemory(), waiting until memory is freed up if it fails.

12/08/17 10:36:29 INFO mapreduce.Job: Task Id : attempt_1342723342632_0010_r_000005_0, Status : FAILED 
Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#6 
at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:123) 
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:371) 
at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:152) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:416) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232) 
at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:147) 
Caused by: java.lang.OutOfMemoryError: Java heap space 
at org.apache.hadoop.io.BoundedByteArrayOutputStream.<init>(BoundedByteArrayOutputStream.java:58) 
at org.apache.hadoop.io.BoundedByteArrayOutputStream.<init>(BoundedByteArrayOutputStream.java:45) 
at org.apache.hadoop.mapreduce.task.reduce.MapOutput.<init>(MapOutput.java:97) 
at org.apache.hadoop.mapreduce.task.reduce.MergeManager.unconditionalReserve(MergeManager.java:286) 
at org.apache.hadoop.mapreduce.task.reduce.MergeManager.reserve(MergeManager.java:276) 
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:327) 
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:273) 
at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:153)
"
MAPREDUCE-4654,TestDistCp is @ignored,"We should fix TestDistCp so that it actually runs, rather than being ignored.

{code}
@ignore
public class TestDistCp {
  private static final Log LOG = LogFactory.getLog(TestDistCp.class);
  private static List<Path> pathList = new ArrayList<Path>();
  ...
{code}"
MAPREDUCE-4653,"TestRandomAlgorithm has an unused ""import"" statement ","need to remove the import statement usinf below patch. will attach a patch shortly .
 
Index: TestRandomAlgorithm.java
===================================================================
--- TestRandomAlgorithm.java	(revision 1380737)
+++ TestRandomAlgorithm.java	(working copy)
@@ -30,8 +30,6 @@
 
 import org.junit.Test;
 
-import com.sun.tools.javac.code.Attribute.Array;
-
 public class TestRandomAlgorithm {
   private static final int[][] parameters = new int[][] {
     {5, 1, 1}, 
"
MAPREDUCE-4652,ValueAggregatorJob sets the wrong job jar,"Using branch-1 tarball, if the user tries to submit an example aggregatewordcount, the job fails with the following error:

{code}
ahmed@ubuntu:~/demo/deploy/hadoop-1.2.0-SNAPSHOT$ bin/hadoop jar hadoop-examples-1.2.0-SNAPSHOT.jar aggregatewordcount input examples-output/aggregatewordcount 2 textinputformat
12/09/12 17:09:46 INFO mapred.JobClient: originalJarPath: /home/ahmed/demo/deploy/hadoop-1.2.0-SNAPSHOT/hadoop-core-1.2.0-SNAPSHOT.jar
12/09/12 17:09:48 INFO mapred.JobClient: submitJarFile: hdfs://localhost:9000/tmp/hadoop-ahmed/mapred/staging/ahmed/.staging/job_201209121702_0008/job.jar
12/09/12 17:09:48 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
12/09/12 17:09:48 WARN snappy.LoadSnappy: Snappy native library not loaded
12/09/12 17:09:48 INFO mapred.FileInputFormat: Total input paths to process : 21
12/09/12 17:09:49 INFO mapred.JobClient: Running job: job_201209121702_0008
12/09/12 17:09:50 INFO mapred.JobClient:  map 0% reduce 0%
12/09/12 17:09:58 INFO mapred.JobClient: Task Id : attempt_201209121702_0008_m_000000_0, Status : FAILED
java.lang.RuntimeException: Error in configuring object
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)
	... 9 more
Caused by: java.lang.RuntimeException: Error in configuring object
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:93)
	at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:64)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:117)
	at org.apache.hadoop.mapred.MapRunner.configure(MapRunner.java:34)
	... 14 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ReflectionUtils.setJobConf(ReflectionUtils.java:88)
	... 17 more
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hadoop.examples.AggregateWordCount$WordCountPlugInClass
	at org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor.createInstance(UserDefinedValueAggregatorDescriptor.java:57)
	at org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor.createAggregator(UserDefinedValueAggregatorDescriptor.java:64)
	at org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor.<init>(UserDefinedValueAggregatorDescriptor.java:76)
	at org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase.getValueAggregatorDescriptor(ValueAggregatorJobBase.java:54)
	at org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase.getAggregatorDescriptors(ValueAggregatorJobBase.java:65)
	at org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase.initializeMySpec(ValueAggregatorJobBase.java:74)
	at org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJobBase.configure(ValueAggregatorJobBase.java:42)
	... 22 more
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.examples.AggregateWordCount$WordCountPlugInClass
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:247)
	at org.apache.hadoop.mapred.lib.aggregate.UserDefinedValueAggregatorDescriptor.createInstance(UserDefinedValueAggregatorDescriptor.java:52)
	... 28 more
{code}"
MAPREDUCE-4651,Benchmarking random reads with DFSIO,"TestDFSIO measures throughput of HDFS write, read, and append operations. It will be useful to have an option to use it for benchmarking random reads."
MAPREDUCE-4649,mr-jobhistory-daemon.sh needs to be updated post YARN-1,"Even today, JHS is assuming that YARN_HOME will be same as HADOOP_MAPRED_HOME besides other such assumptions. We need to fix it."
MAPREDUCE-4647,We should only unjar jobjar if there is a lib directory in it.,For backwards compatibility we recently added made is so we would unjar the job.jar and add anything to the classpath in the lib directory of that jar.  But this also slows job startup down a lot if the jar is large.  We should only unjar it if actually doing so would add something new to the classpath.
MAPREDUCE-4646,client does not receive job diagnostics for failed jobs,"When a job fails the client is not showing any diagnostics.  For example, running a fail job results in this not-so-helpful message from the client:

{noformat}
2012-09-07 21:12:00,649 INFO  [main] mapreduce.Job (Job.java:monitorAndPrintJob(1308)) - Job job_1347052207658_0001 failed with state FAILED due to:
{noformat}

...and nothing else to go with it indicating what went wrong.  The job diagnostics are apparently not making it back to the client.
"
MAPREDUCE-4645,Providing a random seed to Slive should make the sequence of filenames completely deterministic,"Using the -random seed option still doesn't produce a deterministic sequence of filenames. Hence there's no way to replicate the performance test. If I'm providing a seed, its obvious that I want the test to be reproducible."
MAPREDUCE-4644,mapreduce-client-jobclient-tests do not run from dist tarball,"The mapreduce jobclient tests rely on junit which is missing from the dist tarball.  This prevents running often-used tests like sleep jobs.
"
MAPREDUCE-4643,Make job-history cleanup-period configurable,"Job history cleanup should be made configurable. Currently, it is set to 1 month by default. The DEBUG_MODE (to be removed, see MAPREDUCE-4629) sets it to 20 minutes, but it should be configurable."
MAPREDUCE-4642,MiniMRClientClusterFactory should not use job.setJar(),"Currently, MiniMRClientClusterFactory does {{job.setJar(callerJar)}} so that the {{callerJar}} is added to the cache in MR2.  However, this makes the resulting configuration inconsistent between MR1 and MR2 as in MR1 the job jar is not set and in MR2 its set to the {{callerJar}}.  This difference can also cause some tests to fail in Oozie.  We should instead use the {{job.addCacheFile()}} method.  "
MAPREDUCE-4641,Exception in commitJob marks job as successful in job history,"If the job committer throws an {{IOException}} from {{commitJob}} then the job will be marked as FINISHED/FAILED on the RM apps page, but the history server will show the job as SUCCEEDED."
MAPREDUCE-4638,MR AppMaster shouldn't rely on YARN_APPLICATION_CLASSPATH providing MR jars,Currently YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH provides $YARN_HOME/share/hadoop/mapreduce/* & $YARN_HOME/share/hadoop/mapreduce/lib/*. It should not depend on this post YARN-86.
MAPREDUCE-4637,Killing an unassigned task attempt causes the job to fail,Attempting to kill a task attempt that has been scheduled but is not running causes an invalid state transition and the AM to stop with an error. 
MAPREDUCE-4635,MR side of YARN-83. Changing package of YarnClient,
MAPREDUCE-4634,Change TestUmbilicalProtocolWithJobToken to use RPC builder,"In HADOOP-8736, a Builder is introduced to replace all the getServer() variants. This JIRA is the change in MapReduce."
MAPREDUCE-4633,history server doesn't set permissions on all subdirs ,"The job history server creates a bunch of subdirectories under the ""done"" directory.  They are like 2012/09/03/000000.  It only sets the permissions on the last one, ie 000000 to 770.    So the 2012/09/03 aren't explicitly set so if the umask is more restrictive, they won't be set as it expects."
MAPREDUCE-4630,API for setting dfs.block.size,"Add API for setting block size in Tool while creating MR job.

I propose

FileOutputFormat.setBlockSize(Job job, int blocksize);

which sets dfs.block.size"
MAPREDUCE-4629,Remove JobHistory.DEBUG_MODE,"Remove JobHistory.DEBUG_MODE for the following reasons:

1. No one seems to be using it - the config parameter corresponding to enabling it does not even exist in mapred-default.xml
2. The logging being done in DEBUG_MODE needs to move to LOG.debug() and LOG.trace()
3. Buggy handling of helper methods in DEBUG_MODE; e.g. directoryTime() and timestampDirectoryComponent()."
MAPREDUCE-4626,[MAPREDUCE-3902] Fix and re-enable RMContaienrAllocator unit tests,
MAPREDUCE-4625,[MAPREDUCE-3902] Statistics logging in the AM scheduler,
MAPREDUCE-4624,"[MAPREDUCE-3902] Reduce scheduling fixes, factor in MR-4437",
MAPREDUCE-4621,[MAPREDUCE-3902] Disable AM blacklisting if #blacklistedNodes crosses the configured threshold,
MAPREDUCE-4620,[MAPREDUCE-3902] RMContainerAllocator should factor in nodes being blacklisted,Needs to modify the request table to remove these nodes.
MAPREDUCE-4619,[MAPREDUCE-3902] Change AMContainerMap to extend AbstractService,
MAPREDUCE-4618,[MAPREDUCE-3902] Re-wire LocalContainerAllocator / UberAM,
MAPREDUCE-4617,[MAPREDUCE-3902] Re-wire AM Recovery,
MAPREDUCE-4616,Improvement to MultipleOutputs javadocs,"In the new API, and using MultipleOutputs it is possible to segment output into directories by using MultipleOutputs.write(KEYOUT key, VALUEOUT value, String baseOutputPath) in the Reducer to determine the output directory, and by using LazyOutputFormat at the job-level config to suppress normal output [eg use LazyOutputFormat.setOutputFormatClass(job, TextOutputFormat.class); instead of job.setOutputFormatClass(TextOutputFormat.class);]

This recreates the functionality previously provided in the old API by using MultipleTextOutputFormat (etc)
"
MAPREDUCE-4614,Simplify debugging a job's tokens,"It's exceedingly difficult to debug token issues with a job.  Sometimes tokens appear to be missing, or have the wrong service, etc.  It would be much easier if job submission logged the tokens submitted, and if tasks logged the tokens they received."
MAPREDUCE-4613,Scheduling of reduce tasks results in starvation,"If a job has more reduce tasks than there are containers available, then the reduce tasks can occupy all containers causing starvation. The attached graph illustrates the behaviour. Scheduler used is fifo.

I understand that the correct behaviour when all containers are taken by reducers while mappers are still pending, is for the running reducers to be ""pre-empted"". However, pre-emption does not occur.

A work-around is to set the number of reducers < available containers.
"
MAPREDUCE-4612,job summary file permissions not set when its created,"The job summary file permissions are not set when its written out by to the done intermediate directory. The conf and jhist files are both set properly but the summary file doesn't follow the same path.  

This can cause the summary file to not be copied to the done directory if the default umask is set to be restrictive (like 600) and the mapred user can't read it."
MAPREDUCE-4611,MR AM dies badly when Node is decomissioned,"The MR AM always thinks that it is being killed by the RM when it gets a kill signal and it has not finished processing yet.  In reality the RM kill signal is only sent when the client cannot communicate directly with the AM, which probably means that the AM is in a bad state already.  The much more common case is that the node is marked as unhealthy or decomissioned.

I propose that in the short term the AM will only clean up if 

 # The process has been asked by the client to exit (kill)
 # The process job has finished cleanly and is exiting already
 # This is that last retry of the AM retries.

The downside here is that the .staging directory will be leaked and the job will not show up in the history server on an kill from the RM in some cases.

At least until the full set of AM cleanup issues can be addressed, probably as part of MAPREDUCE-4428"
MAPREDUCE-4610,Support deprecated mapreduce.job.counters.limit property in MR2,"The property mapreduce.job.counters.limit was introduced in MAPREDUCE-1943, but the mechanism was changed in MAPREDUCE-901 where the property name was changed to mapreduce.job.counters.max without supporting the old name. We should deprecate but honour the old name to make it easier for folks to move from Hadoop 1 to Hadoop 2."
MAPREDUCE-4609,[MAPREDUCE-3902] RMContainerAllocator#scheduleInterval should be configurable,"Currently, RMContainerAllocator#scheduleInterval is fixed. It should be configurable."
MAPREDUCE-4608,hadoop-mapreduce-client is missing some dependencies,"
commons-logging/commons-lang/commons-cli/commons-codec/guava should be defined with provided scope as they are used directly by mapreduce.

While Maven gets them transitively from hadoop-common (also provided), not being there makes IntelliJ to break (it seems intellij does not do a transitive closure with provided dependencies)"
MAPREDUCE-4607,Race condition in ReduceTask completion can result in Task being incorrectly failed,"Problem reported by chackaravarthy in MAPREDUCE-4252

This problem has been handled when speculative task launched for map task and other attempt got failed (not killed)
Can the similar kind of scenario can happen in case of reduce task?
Consider the following scenario for reduce task in case of speculation (one attempt got killed):
1. A task attempt is started.
2. A speculative task attempt for the same task is started.
3. The first task attempt completes and causes the task to transition to SUCCEEDED.
4. Then speculative task attempt will be killed because of the completion of first attempt.
As a result, internal error will be thrown from this attempt (TaskImpl.MapRetroactiveKilledTransition) and hence task attempt failure leads to job failure.
TaskImpl.MapRetroactiveKilledTransition
if (!TaskType.MAP.equals(task.getType())) {
        LOG.error(""Unexpected event for REDUCE task "" + event.getType());
        task.internalError(event.getType());
      }
So, do we need to have following code in MapRetroactiveKilledTransition also just like in MapRetroactiveFailureTransition.
if (event instanceof TaskTAttemptEvent) {
        TaskTAttemptEvent castEvent = (TaskTAttemptEvent) event;
        if (task.getState() == TaskState.SUCCEEDED &&
            !castEvent.getTaskAttemptID().equals(task.successfulAttempt)) {
          // don't allow a different task attempt to override a previous
          // succeeded state
          return TaskState.SUCCEEDED;
        }
      }
please check whether this is a valid case and give your suggestion."
MAPREDUCE-4604,"In mapred-default, mapreduce.map.maxattempts & mapreduce.reduce.maxattempts defaults are set to 4 as well as mapreduce.job.maxtaskfailures.per.tracker. ","This causes the AM to fail the job at the same time as it blacklists a node, thus never actually trying another node.

Marking as critical because we need this in 0.23.3 before it releases."
MAPREDUCE-4603,Allow JobClient to retry job-submission when JT is in safemode,"Similar to HDFS-3504, it would be useful to allow JobClient to retry job-submission when JT is in safemode (via MAPREDUCE-4328).

This way applications like Pig/Hive don't bork midway when the NN/JT are not operational."
MAPREDUCE-4602,[MAPREDUCE-3902] Re-create ask list correctly in case of a temporary error in the AM-RM allocate call,"This isn't applicable to trunk - since modification of the table happens in one of two RMCommunicator specific threads, which allows for the methods to be synchronized.
"
MAPREDUCE-4600,TestTokenCache.java from MRV1 no longer compiles,"{noformat}
    [javac] hadoop-mapreduce-project/build.xml:569: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 95 source files to hadoop-mapreduce-project/build/test/mapred/classes
    [javac] hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapreduce/security/TestTokenCache.java:291: cannot find symbol
    [javac] symbol  : method getDelegationToken(org.apache.hadoop.security.Credentials,java.lang.String)
    [javac] location: class org.apache.hadoop.mapreduce.security.TokenCache
    [javac]     Token<DelegationTokenIdentifier> nnt = TokenCache.getDelegationToken(
    [javac]                                                      ^
    [javac] hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapreduce/security/TestTokenCache.java:350: cannot find symbol
    [javac] symbol  : method getDelegationTokens(java.lang.String)
    [javac] location: class org.apache.hadoop.hdfs.HftpFileSystem
    [javac]       }}).when(hfs).getDelegationTokens(renewer);
    [javac]                    ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 errors
{noformat}"
MAPREDUCE-4599,[MAPREDUCE-3902] Ensure not to launch container on blacklisted hosts,"The current implementation of RMContainerAllocator doesn't ensure not to launch containers on blacklisted nodes. This may cause some skews by tasks on bad nodes.
"
MAPREDUCE-4598,Support for node health scripts on Windows,"Currently, it is not possible to have node health scripts on Windows, as NodeHealthCheckerService tries to directly launch (CreateProcess()) .sh scripts. TestNodeHealthService test fails because of this issue also leading to a subsequent TestNodeRefresh test failure."
MAPREDUCE-4597,TestKillSubProcesses intermittently fails,The test starts a mapper that spawns subprocesses. The test then checks if sufficient number of subprocesses have been spawned. The check can happen before all the processes have been spawned and can sometimes fail.
MAPREDUCE-4596,"Split StateMachine state from states seen by MRClientProtocol (for Job, Task, TaskAttempt)","State machine states are currently exposed via MRClienProtocol. This makes it tough to modify the AM state machines, or have an alternate AM with different state machines (MR-3902) without the changes being visible in MRClientProtocol (MRv2 equivalent of ClientProtocol)."
MAPREDUCE-4595,TestLostTracker failing - possibly due to a race in JobHistory.JobHistoryFilesManager#run(),"The source for occasional failure of TestLostTracker seems like the following:

On job completion, JobHistoryFilesManager#run() spawns another thread to move history files to done folder. TestLostTracker waits for job completion, before checking the file format of the history file. However, the history files move might be in the process or might not have started in the first place.

The attachment (force-TestLostTracker-failure.patch) helps reproducing the error locally, by increasing the chance of hitting this race."
MAPREDUCE-4593,CombineFileInputFormat must ensure it doesn't dupe locations in its InputSplit objects,"Currently it seems possible for CombineFileInputFormat's InputSplit objects to grow to very large sizes due to its non-de-duplication of the locations field. We should probably use a set structure to prevent dupe locations from rising the block locations size of InputSplits sent over by CombineFileInputFormat, as that will help performance and help fix unnecessary warnings/errors over block location limits at the JT/MR AM."
MAPREDUCE-4583,Wrong paths for CapacityScheduler/FairScheduler jar in documentation,"Both documentations
http://hadoop.apache.org/common/docs/r1.0.3/fair_scheduler.html
http://hadoop.apache.org/common/docs/r1.0.3/capacity_scheduler.html

say that the jar should be copied from the contrib/*scheduler directory.

But that's not the case ; both jars are actually in the lib folder"
MAPREDUCE-4581,[MAPREDUCE-3902] TaskHeartbeatHandler should extends HeartbeatHandlerBase,"TaskHeartbeatHandler extends AbstractService currently, however, this causes code duplication between TaskHeartbeatHandler and HeartbeatHandlerBase. TaskHeartbeatHandler should extends HeartbeatHandlerBase to solve the problem."
MAPREDUCE-4580,Change MapReduce to use the yarn-client module,Mapreduce needs to be changed to use the yarn-client module added via YARN-29.
MAPREDUCE-4579,TestTaskAttempt fails jdk7,"-------------------------------------------------------------------------------
Test set: org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt
-------------------------------------------------------------------------------
Tests run: 10, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.205 sec <<< FAILURE!testAttemptContainerRequest(org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttempt)  Time elapsed: 0.032 sec  <<< ERROR!
java.io.EOFException
        at java.io.DataInputStream.readByte(DataInputStream.java:267)
        at org.apache.hadoop.io.WritableUtils.readVLong(WritableUtils.java:308)
        at org.apache.hadoop.io.WritableUtils.readVInt(WritableUtils.java:329)
        at org.apache.hadoop.io.Text.readFields(Text.java:280)
        at org.apache.hadoop.security.token.Token.readFields(Token.java:165)"
MAPREDUCE-4577,HDFS-3672 broke TestCombineFileInputFormat.testMissingBlocks() test,"Before HDFS-3672, locally applying MAPREDUCE-4470 made TestCombineFileInputFormat to pass all it tests.

After HDFS-3672, TestCombineFileInputFormat.testMissingBlocks() fails:

{code}
$ mvn clean test -Dtest=TestCombineFileInputFormat

Running org.apache.hadoop.mapred.TestCombineFileInputFormat
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.698 sec
Running org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
Tests run: 6, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.526 sec <<< FAILURE!

Results :

Tests in error: 
  testMissingBlocks(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat): org.apache.hadoop.fs.BlockLocation

Tests run: 7, Failures: 0, Errors: 1, Skipped: 0
{code}
"
MAPREDUCE-4576,Large dist cache can block tasktracker heartbeat,
MAPREDUCE-4574,Fix TotalOrderParitioner to work with non-WritableComparable key types,"The current TotalOrderPartitioner class will not work with an alternative serialization library such as Avro.

To make it work, we may edit the readPartitions bits in it to support non-WritableComparable keys and also remove the WritableComparable check in the class types definition.

That is, since we do not use the values at all (NullWritable), we may as well do:

{code}
  private K[] readPartitions(FileSystem fs, Path p, Class<K> keyClass,
      Configuration conf) throws IOException {
    …
    while ((key = (K) reader.next(key)) != null) {
      parts.add(key);
      key = ReflectionUtils.newInstance(keyClass, conf);
    }
    …
  }
{code}"
MAPREDUCE-4572,Can not access user logs - Jetty is not configured by default to serve aliases/symlinks,The task log servlet can no longer access user logs because MAPREDUCE-2415 introduce symlinks to the logs and jetty is not configured by default to serve symlinks. 
MAPREDUCE-4571,TestHsWebServicesJobs fails on jdk7,"TestHsWebServicesJobs fails on jdk7. 

Tests run: 22, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 7.561 sec <<< FAILURE!testJobIdSlash(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs)  Time elapsed: 0.334 sec  <<< FAILURE!
java.lang.AssertionError: mapsTotal incorrect expected:<0> but was:<1>

"
MAPREDUCE-4570,ProcfsBasedProcessTree#constructProcessInfo() prints a warning if procfsDir/<pid>/stat is not found.,"I think a warning is misleading in this case. What is happening here is that the list of all processes in the system is found, and then later the procfsDir/<pid>/stat file for each is opened. This warning is thrown when the process finishes before the stat file is opened, and hence the file is no longer there. This could normally happen, and shouldn't signify a waring. An info message is sufficient. I'll be uploading a patch momentarily."
MAPREDUCE-4569,TestHsWebServicesJobsQuery fails on jdk7,"TestHsWebServicesJobsQuery fails on jdk7 due to the test order no longer being constant.


testJobsQueryStateNone(org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery)  Time elapsed: 0.279 sec  <<< FAILURE!
java.lang.AssertionError: jobs is not null expected:<null> but was:<{""job"":[{""startTime"":1345559717819,""finishTime"":1345560891194,""id"":""job_1345560632472_0002"",""name"":""RandomWriter"",""queue"":""mockqueue"",""user"":""mock"",""state"":""KILL_WAIT"",""mapsTotal"":0,""mapsCompleted"":0,""reducesTotal"":1,""reducesCompleted"":1}]}>
        at org.junit.Assert.fail(Assert.java:91)
        at org.junit.Assert.failNotEquals(Assert.java:645)
        at org.junit.Assert.assertEquals(Assert.java:126)
        at org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobsQuery.testJobsQueryStateNone(TestHsWebServicesJobsQuery.java:226)

It looks like the issues is that the mock jobs just iterate through the JOBSTATE and since other tests run first we just happen to hit the state KILL_WAIT that we don't expect any jobs to be in.  "
MAPREDUCE-4565,Backport MR-2855 to branch-1: ResourceBundle lookup during counter name resolution takes a lot of time,"Loading a job status page in trunk takes a lot of time, and it seems like most of the time is spent resolving counter names. Looking through the JDK source, ResourceBundle.getBundle(String) ends up calling getClassContext() which is not very efficient. I think if we pass our own classloader manually it will be faster. In Counters.incrAllCounters, we may also be able to avoid setting the counter name if one is already set."
MAPREDUCE-4564,Shell timeout mechanism does not work for processes spawned using winutils,"Upon timeout, Shell calls Java process.destroy() to terminate the spawned process. This would destroy the winutils process but not the real process spawned by winutils.
"
MAPREDUCE-4562,"Support for ""FileSystemCounter"" legacy counter group name for compatibility reasons is creating incorrect counter name","Hi Guys,
I was investigating issue in Sqoop project(http://sqoop.apache.org/). Problem is that we are reporting number of written filesystem bytes back to the user and on Hadoop 0.23/2.x we're always getting 0. I've noticed that there was some refactorization in FileSystem counter related code and found MAPREDUCE-3542 requesting backward compatibility.

Included patch seems to be adding counter ""FileSystemCounter"":

{code:title=hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapreduce/counters/AbstractCounters.java:84}
legacyMap.put(""FileSystemCounter"", FileSystemCounter.class.getName());
{code}

But it appears that original name is ""FileSystemCounters"" (Notice the plural ""s"" at the end of name):
{code:title=src/mapred/org/apache/hadoop/mapred/Task.java:91 (0.20.2)}
protected static final String FILESYSTEM_COUNTER_GROUP = ""FileSystemCounters"";
{code}
{code:title=src/mapred/org/apache/hadoop/mapred/Task.java:109 (1.0.3)}
protected static final String FILESYSTEM_COUNTER_GROUP = ""FileSystemCounters"";
{code}

I therefore believe that this counter should be renamed in order to provide backward compatibility. I might fix this discrepancy in Sqoop, but I believe that other projects/users might also be affected and therefore it would be better to fix it in upstream."
MAPREDUCE-4561,Support for node health scripts on Windows ,TestNodeHealthService fails because NodeHealthServiceChecker tries to run a shell script directly. That wont work on Windows. Need to launch it via cmd or winutils.
MAPREDUCE-4560,Job can get stuck in a deadlock between mappers and reducers for low values of mapreduce.job.reduce.slowstart.completedmaps (<<1),"This issue has been seen with MapReduceV2, never with MapReduceV1 in our lab systems.

The parameter mapreduce.job.reduce.slowstart.completedmaps=0.05 (the default value).

We found Application master stuck in a deadlock between mappers and reducers with no progress in the job; the sequence appears to be:

1. Initial available map/reduce slots were allocated to mappers
2. Once mappers made progress and few of them completed, reducers started occupying few of the slots due to low values of above config param.
3. The scheduler appears to not give priority to mappers over reducers; after a while in our system we saw all slots occupied by reducers.
4. Since there were still mapper tasks not yet assigned any slot, the map phase never completed.
5. The system entered a deadlock state where reducers occupy all available slots, but are waiting for mappers to be complete; mappers cannot move forward because of no slot available.

The workaround in our system was to set 
mapreduce.job.reduce.slowstart.completedmaps=1 and the issue was no longer seen."
MAPREDUCE-4558,TestJobTrackerSafeMode is failing,"MAPREDUCE-1906 exposed an issue with this unit test. It has 3 TTs running, but has a check for the TT count to reach exactly 2 (which would be reached with a higher heartbeat interval).

The test ends up getting stuck, with the following message repeated multiple times.
{code}
    [junit] 2012-08-15 11:26:46,299 INFO  mapred.TestJobTrackerSafeMode (TestJobTrackerSafeMode.java:checkTrackers(201)) - Waiting for Initialize all Task Trackers
    [junit] 2012-08-15 11:26:47,301 INFO  mapred.TestJobTrackerSafeMode (TestJobTrackerSafeMode.java:checkTrackers(201)) - Waiting for Initialize all Task Trackers
    [junit] 2012-08-15 11:26:48,302 INFO  mapred.TestJobTrackerSafeMode (TestJobTrackerSafeMode.java:checkTrackers(201)) - Waiting for Initialize all Task Trackers
    [junit] 2012-08-15 11:26:49,303 INFO  mapred.TestJobTrackerSafeMode (TestJobTrackerSafeMode.java:checkTrackers(201)) - Waiting for Initialize all Task Trackers
{code}

"
MAPREDUCE-4556,FairScheduler: PoolSchedulable#updateDemand() has potential redundant computation,
MAPREDUCE-4555,make user's mapred .staging area permissions configurable,"The directories are created in JobTracker and LocalRunner, but they are currently forced to be 0700. There is even a segment of the source code that will check the permissions are 0700, and if not it will change the permissions to match 0700. For monitoring purposes the permissions should be configurable.

Please note:
1. We can make the hard-coded 700 configurable at clients (its the client who creates it) but there's two issues here: 
1.1. It violates security principals (as its client sided and overridable) 
1.2. It can't be consistent, since some user may ignore configs provided to them and create it with 0700.

"
MAPREDUCE-4554,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes.

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.
In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be changed for two reasons:
1) It is not backward compatible. 
2) Credentials should be passed even if security is turned off .
"
MAPREDUCE-4553,Key Protection :  Implement KeyProvider to read key from a WebService Based KeyStore,"Normally keys have to be stored in a central location using custom key management system.  organizations can implement KeyProvider to integrate their custom key management system to Hadoop. This interface is specified in MAPREDUCE-4550

Optionally , developers can use Safe to integrate custom key management system with Hadoop. 
Safe is an open source web service based keystore to securely store secret keys and passwords. 
Safe authenticates the user using SPNego, checks whether the user is authorized to read the secret and returns the secret. 
It is easy to plug in different mechanisms for authentication,authorization and Key storage. 
Safe is kept as a separate open source project at (http://benoyantony.github.com/safe/)

The hadoop proxy to safe is added as a contrib project -  hadoop-safe. 
"
MAPREDUCE-4552,Encryption:  Add support for PGP Encryption,"Provide support for PGP encryption by implementing Encrypter and Decrypter interfaces defined in MAPREDUCE-4450.  This can be used by the cluster to protect the job secrets. This also be used map reduce jobs to encrypt/decrypt data. 

Add PGPCodec as a CompressionCodec  so that encrypted data can be processed transparently like compressed data . The aliases to the keys can be specified as part of Job. 

Based on PGPCodec, a number of utilities are provided to encrypt, decrypt the data in cluster.  They include

1.	DistributedSplitter – Split an encrypted file into smaller files.
2.	DistributedEncrypter – encrypt files in a cluster.
3.	DistributedDecrypter – decrypt encrypted files in a cluster.
4.	DistributedRecrypter – decrypt an encrypted file and encrypt it with another key.

Uitlities are added to encrypt/decrypt files in local file system

1.	Genkey - Generate an asymmetric key pair (public and private keys) of a specified strength
2.	Encrypt - Encrypt a file 
3.	Decrypt – Decrypt a file

Added as a contrib project -  hadoop-crypto.
"
MAPREDUCE-4551,Key Protection :  Add ability to read keys and protect keys  in  JobClient and TTS/NodeManagers,"Based on Cluster configuration, NodeManager/TaskTrackers set up Decrypters  to decrypt the job's secrets.
Based on Job configuration, JobClient reads secrets from a KeyStore using a Keyprovider implementation and encrypts them using the cluster's public key.

The encrypted secrets are stored in Job Credentials.

The task addresses the following requirements:


•	Plug in different key store mechanisms.
•	Retrieve specified keys from a configured keystore as part of job submission
•	Protect keys during its transport through the cluster.
•	Make sure that keys are handed over only to the tasks of the correct job.
"
MAPREDUCE-4550,Key Protection : Define Encryption and Key Protection interfaces and default implementations,"A secret key is read from a Key Store and then encrypted during transport between JobClient and Task. The tasktrackers/nodemanagers decrypt the secrets and provide the secrets to child tasks which part of the job.

This jira defines the interfaces to accomplish the above :

1) KeyProvider - to read keys from a KeyStore

2) Encrypter and Decrypter - to and encrypt and decrypt secrets/data.

The default/dummy implementations will also be added. This includes a KeyProvider implementation to read keys from a Java KeyStore."
MAPREDUCE-4549,Distributed cache conflicts breaks backwards compatability,"I recently put in MAPREDUCE-4503 which went a bit too far, and broke backwards compatibility with 1.0 in distribtued cache entries.  instead of changing the behavior of the distributed cache to more closely match 1.0 behavior I want to just change the exception to a warning message informing the users that it will become an error in 2.0"
MAPREDUCE-4547,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .
"
MAPREDUCE-4546,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.
"
MAPREDUCE-4545,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4544,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4543,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4542,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed as part of a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2, these credentials are transmitted only when security is turned on.

This should be changed in HADOOP 2 for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off."
MAPREDUCE-4541,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4540,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed as part of a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2, these credentials are transmitted only when security is turned on.

This should be changed in HADOOP 2 for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off."
MAPREDUCE-4539,Please delete me,I am in a bad state will someone please delete me?
MAPREDUCE-4538,Please delete me,I am in a bad state will someone please delete me.
MAPREDUCE-4537,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4536,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4535,"Test failures with ""Container .. is running beyond virtual memory limits""","Tests org.apache.hadoop.tools.TestHadoopArchives.{testRelativePath,testPathWithSpaces} fail with the following message:

{code}
Container [pid=7785,containerID=container_1342495768864_0001_01_000001] is running beyond virtual memory limits. Current usage: 143.6mb of 1.5gb physical memory used; 3.4gb of 3.1gb virtual memory used. Killing container.
Dump of the process-tree for container_1342495768864_0001_01_000001 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7797 7785 7785 7785 (java) 573 38 3517018112 36421 /usr/java/jdk1.6.0_33/jre/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 
{code}

This is not a stably reproducible problem, but adding MALLOC_ARENA_MAX resolves the problem."
MAPREDUCE-4534,"Test failures with ""Container .. is running beyond virtual memory limits""","Tests org.apache.hadoop.tools.TestHadoopArchives.{testRelativePath,testPathWithSpaces} fail with the following message:

{code}
Container [pid=7785,containerID=container_1342495768864_0001_01_000001] is running beyond virtual memory limits. Current usage: 143.6mb of 1.5gb physical memory used; 3.4gb of 3.1gb virtual memory used. Killing container.
Dump of the process-tree for container_1342495768864_0001_01_000001 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7797 7785 7785 7785 (java) 573 38 3517018112 36421 /usr/java/jdk1.6.0_33/jre/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 
	|- 7785 7101 7785 7785 (bash) 1 1 108605440 332 /bin/bash -c /usr/java/jdk1.6.0_33/jre/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1>/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001/stdout 2>/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001/stderr
{code}

This is not a stably reproducible problem, but adding MALLOC_ARENA_MAX resolves the problem."
MAPREDUCE-4533,"Test failures with ""Container .. is running beyond virtual memory limits""","Tests org.apache.hadoop.tools.TestHadoopArchives.{testRelativePath,testPathWithSpaces} fail with the following message:

{code}
Container [pid=7785,containerID=container_1342495768864_0001_01_000001] is running beyond virtual memory limits. Current usage: 143.6mb of 1.5gb physical memory used; 3.4gb of 3.1gb virtual memory used. Killing container.
Dump of the process-tree for container_1342495768864_0001_01_000001 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 7797 7785 7785 7785 (java) 573 38 3517018112 36421 /usr/java/jdk1.6.0_33/jre/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 
	|- 7785 7101 7785 7785 (bash) 1 1 108605440 332 /bin/bash -c /usr/java/jdk1.6.0_33/jre/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001 -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1>/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001/stdout 2>/var/lib/jenkins/workspace/Hadoop_gd-branch0.23_integration/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1342495768864_0001/container_1342495768864_0001_01_000001/stderr
{code}

This is not a stably reproducible problem, but adding MALLOC_ARENA_MAX resolves the problem."
MAPREDUCE-4532,Job Credentials are not transmitted if security is turned off," Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4531,Job Credentials are not transmitted if security is turned off," Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4530,Job Credentials are not transmitted if security is turned off," Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off ."
MAPREDUCE-4529,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .
"
MAPREDUCE-4528,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .

 "
MAPREDUCE-4527,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be fixed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .

 "
MAPREDUCE-4526,Job Credentials are not transmitted if security is turned off,"Credentials (secret keys) can be passed to a job via mapreduce.job.credentials.json or  mapreduce.job.credentials.binary .

These credentials get submitted during job submission and are made available to the task processes. 

In HADOOP 1, these credentials get submitted and routed to task processes even if security was off.

In HADOOP 2 , these credentials are transmitted only when the security is turned on.

This should be changed for two reasons:

1) It is not backward compatible.
2) Credentials should be passed even if security is turned off .

 "
MAPREDUCE-4521,mapreduce.user.classpath.first incompatibility with 0.20/1.x,"In Hadoop 0.20 or 1.x, jobs can specify the user's classpath should appear first by setting the property mapreduce.user.classpath.first to true in the job configuration.  However in Hadoop 0.23 or 2.x, this has no effect, as the corresponding property there is mapreduce.job.user.classpath.first."
MAPREDUCE-4520,Add experimental support for MR AM to schedule CPUs along-with memory,
MAPREDUCE-4517,Too many INFO messages written out during AM to RM heartbeat,"Too many INFO log messages written out during AM to RM heartbeat. Based on default frequency of 1000ms (scheduler.heartbeat.interval-ms) either 2 or 4 INFO messages are written out per second:

LOG.info(""Before Scheduling: "" + getStat());
List<Container> allocatedContainers = getResources();
LOG.info(""After Scheduling: "" + getStat());
if (allocatedContainers.size() > 0) {
  LOG.info(""Before Assign: "" + getStat());
  scheduledRequests.assign(allocatedContainers);
  LOG.info(""After Assign: "" + getStat());
}

These should probably be changed to DEBUG message to save the log growing too quickly."
MAPREDUCE-4515,Add test to check if userlogs are retained across TaskTracker restarts,
MAPREDUCE-4511,Add IFile readahead,This ticket is to add IFile readahead as part of HADOOP-7714.
MAPREDUCE-4510,"Avoid logging ""Cannot run program getconf"" on Windows",ProcfsbasesProcessTree logs error messages when it cannot run getconf to determine system attributes on linux. this causes a lot of log spew on windows. need to fix this code because linux is not longer the only OS supported for hadoop.
MAPREDUCE-4504,SortValidator writes to wrong directory,"SortValidator tries to write to jobConf.get(""hadoop.tmp.dir"", ""/tmp""), but it is not intended to be an HDFS directory. it should just be /tmp."
MAPREDUCE-4503,Should throw InvalidJobConfException if duplicates found in cacheArchives or cacheFiles,"in 1.0 if a file was both in a jobs cache archives and cache files, and InvalidJobConfException was thrown.  We should replicate this behavior on mrv2.  We should also extend it so that if a cache archive or cache file is not going to be downloaded at all because of conflicts in the names of the symlinks a similar exception is thrown."
MAPREDUCE-4500,TestUlimit is failing locally,"ant clean test -Dtestcase=TestUlimit -Dtest.output=yes fails locally

Attaching the dump"
MAPREDUCE-4499,Looking for speculative tasks is very expensive in 1.x,"When there are lots of jobs and tasks active in a cluster, the process of figuring out whether or not to launch a speculative task becomes very expensive. 

I could be missing something but it certainly looks like on every heartbeat we could be scanning 10's of thousands of tasks looking for something which might need to be speculatively executed. In most cases, nothing gets chosen so we completely trashed our data cache and didn't even find a task to schedule, just to do it all over again on the next heartbeat.

On busy jobtrackers, the following backtrace is very common:

""IPC Server handler 32 on 50300"" daemon prio=10 tid=0x00002ab36c74f800
nid=0xb50 runnable [0x0000000045adb000]
  java.lang.Thread.State: RUNNABLE
       at java.util.TreeMap.valEquals(TreeMap.java:1182)
       at java.util.TreeMap.containsValue(TreeMap.java:227)
       at java.util.TreeMap$Values.contains(TreeMap.java:940)
       at
org.apache.hadoop.mapred.TaskInProgress.hasRunOnMachine(TaskInProgress.java:1072)
       at
org.apache.hadoop.mapred.JobInProgress.findSpeculativeTask(JobInProgress.java:2193)
       - locked <0x00002aaefde82338> (a
org.apache.hadoop.mapred.JobInProgress)
       at
org.apache.hadoop.mapred.JobInProgress.findNewMapTask(JobInProgress.java:2417)
       - locked <0x00002aaefde82338> (a
org.apache.hadoop.mapred.JobInProgress)
       at
org.apache.hadoop.mapred.JobInProgress.obtainNewNonLocalMapTask(JobInProgress.java:1432)
       - locked <0x00002aaefde82338> (a
org.apache.hadoop.mapred.JobInProgress)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler$MapSchedulingMgr.obtainNewTask(CapacityTaskScheduler.java:525)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.getTaskFromQueue(CapacityTaskScheduler.java:322)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.assignTasks(CapacityTaskScheduler.java:419)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.access$500(CapacityTaskScheduler.java:150)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler.addMapTasks(CapacityTaskScheduler.java:1075)
       at
org.apache.hadoop.mapred.CapacityTaskScheduler.assignTasks(CapacityTaskScheduler.java:1044)
       - locked <0x00002aab6e27a4c8> (a
org.apache.hadoop.mapred.CapacityTaskScheduler)
       at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3398)
       - locked <0x00002aab6e191278> (a org.apache.hadoop.mapred.JobTracker)
...)"
MAPREDUCE-4498,Remove hsqldb jar from Hadoop runtime classpath,"The hsqldb jar is included in hadoop for the DBCountPageView example only.  Currently the example is using hsqldb version 2.x; however, 2.x is incompatible with 1.8.x -- having this jar in the hadoop class path conflicts with dependent projects like Oozie, Hive, and Pig which still use 1.8.x.  As there are no features hsqldb 2.x that are used by the example, we should remove it from Hadoop's runtime classpath."
MAPREDUCE-4496,AM logs link is missing user name,The link to the ApplicationMaster's logs on the MRAppMaster's web page is missing the user name.
MAPREDUCE-4494,"TestFifoScheduler failing with Metrics source QueueMetrics,q0=default already exists!","TestFifoScheduler is failing:

{code}
Running org.apache.hadoop.yarn.server.resourcemanager.TestFifoScheduler
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 14.614 sec <<< FAILURE!

Results :

Tests in error: 
  test(org.apache.hadoop.yarn.server.resourcemanager.TestFifoScheduler): Metrics source QueueMetrics,q0=default already exists!
{code}"
MAPREDUCE-4493,Distibuted Cache Compatability Issues,"The distributed cache does not work like it does in 1.0.

mapreduce.job.cache.symlink.create is completely ignored and symlinks are always created no matter what.  Files and archives without a fragment will also have symlinks created.

If two cache archives or cache files happen to have the same name, or same symlink fragment only the last one in the list is localized.

The localCacheArchives and LocalCacheFiles are not set correctly when these duplicates happen causing off by one or more errors for anyone trying to use them.

The reality is that use of symlinking is so common currently that these incompatibilities are not that likely to show up, but we still need to fix them."
MAPREDUCE-4492,Configuring total queue capacity between 100.5 and 99.5 at perticular level is sucessfull,"Scenario:
1.Configure a,b queues with capacities 40.0 and 60.5 respectively under root queue
2.Start process
Observe that process is started sucessfully with configured queue capacity though the total capacity is 100.5(40.0+60.5)"
MAPREDUCE-4491,Encryption and Key Protection,"When dealing with sensitive data, it is required to keep the data encrypted wherever it is stored. Common use case is to pull encrypted data out of a datasource and store in HDFS for analysis. The keys are stored in an external keystore. 

The feature adds a customizable framework to integrate different types of keystores, support for Java KeyStore, read keys from keystores, and transport keys from JobClient to Tasks.
The feature adds PGP encryption as a codec and additional utilities to perform encryption related steps.


The design document is attached. It explains the requirement, design and use cases.
Kindly review and comment. Collaboration is very much welcome.

I have a tested patch for this for 1.1 and will upload it soon as an initial work for further refinement.

Update: The patches are uploaded to subtasks. 






"
MAPREDUCE-4490,JVM reuse is incompatible with LinuxTaskController (and therefore incompatible with Security),"When using LinuxTaskController, JVM reuse (mapred.job.reuse.jvm.num.tasks > 1) with more map tasks in a job than there are map slots in the cluster will result in immediate task failures for the second task in each JVM (and then the JVM exits). We have investigated this bug and the root cause is as follows. When using LinuxTaskController, the userlog directory for a task attempt (../userlogs/job/task-attempt) is created only on the first invocation (when the JVM is launched) because userlogs directories are created by the task-controller binary which only runs *once* per JVM. Therefore, attempting to create log.index is guaranteed to fail with ENOENT leading to immediate task failure and child JVM exit.

{quote}
2012-07-24 14:29:11,914 INFO org.apache.hadoop.mapred.TaskLog: Starting logging for a new task attempt_201207241401_0013_m_000027_0 in the same JVM as that of the first task /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_000006_0
2012-07-24 14:29:11,915 WARN org.apache.hadoop.mapred.Child: Error running child
ENOENT: No such file or directory
        at org.apache.hadoop.io.nativeio.NativeIO.open(Native Method)
        at org.apache.hadoop.io.SecureIOUtils.createForWrite(SecureIOUtils.java:161)
        at org.apache.hadoop.mapred.TaskLog.writeToIndexFile(TaskLog.java:296)
        at org.apache.hadoop.mapred.TaskLog.syncLogs(TaskLog.java:369)
        at org.apache.hadoop.mapred.Child.main(Child.java:229)
{quote}

The above error occurs in a JVM which runs tasks 6 and 27.  Task6 goes smoothly. Then Task27 starts. The directory /var/log/hadoop/mapred/userlogs/job_201207241401_0013/attempt_201207241401_0013_m_0000027_0 is never created so when mapred.Child tries to write the log.index file for Task27, it fails with ENOENT because the attempt_201207241401_0013_m_0000027_0 directory does not exist. Therefore, the second task in each JVM is guaranteed to fail (and then the JVM exits) every time when using LinuxTaskController. Note that this problem does not occur when using the DefaultTaskController because the userlogs directories are created for each task (not just for each JVM as with LinuxTaskController).

For each task, the TaskRunner calls the TaskController's createLogDir method before attempting to write out an index file.

* DefaultTaskController#createLogDir: creates log directory for each task
* LinuxTaskController#createLogDir: does nothing
** task-controller binary creates log directory [create_attempt_directories] (but only for the first task)

Possible Solution: add a new command to task-controller *initialize task* to create attempt directories.  Call that command, with ShellCommandExecutor, in the LinuxTaskController#createLogDir method




"
MAPREDUCE-4486,issues in POM of hadoop-yarn-applications-unmanaged-am-launcher,"Incorrectly the dependency for distributed shell has a version, this should be in the dependencies management section of hadoop-project POM

backport to branch-2 didn't set the right Hadoop version in the POM and parent.

"
MAPREDUCE-4484,Incorrect IS_MINI_YARN_CLUSTER property name in YarnConfiguration,"Noticed that the IS_MINI_YARN_CLUSTER property name in YarnConfiguration ended up having an extra ""."" after appending to YARN_PREFIX."
MAPREDUCE-4483,2.0 build does not work ,Seems like hadoop-yarn-applications-unmanaged-am-launcher/pom.xml is pointing to the wrong <parent>
MAPREDUCE-4482,Backport MR sort plugin(MAPREDUCE-2454) to Hadoop 1.2,
MAPREDUCE-4480,T_ATTEMPT_KILLED after SUCCEEDED can happen for reduces too ,"This does not seem to impact 0.23.  If speculative execution is enabled then a T_ATTEMPT_KILLED event can come in after the task has transitioned to SUCCEEDED.  This causes the MapRetroactiveKilledTransition to kill the Job, because it expects to only handle map tasks."
MAPREDUCE-4479,Fix parameter order in assertEquals() in TestCombineInputFileFormat.java,
MAPREDUCE-4478,TaskTracker's heartbeat is out of control,
MAPREDUCE-4475,testForEmptyFile failed,"This test failed in a recent test run:

testForEmptyFile(org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat): expected:<0> but was:<1>

https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1146/"
MAPREDUCE-4473,tasktracker rank on machines.jsp?type=active,sometimes we need to simple judge which tasktracker is down from the page of machines.jsp?type=active
MAPREDUCE-4471,TestClientRMService.testGetQueueInfo failing after MR-4427,"TestClientRMService.testGetQueueInfo has been consistently failing since MAPREDUCE-4427.

{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl.createAndGetApplicationReport(RMAppImpl.java:407)
	at org.apache.hadoop.yarn.server.resourcemanager.ClientRMService.getQueueInfo(ClientRMService.java:393)
	at org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService.testGetQueueInfo(TestClientRMService.java:138)
{noformat}"
MAPREDUCE-4470,Fix TestCombineFileInputFormat.testForEmptyFile,"TestCombineFileInputFormat.testForEmptyFile started failing after HADOOP-8599. 

It expects one split on an empty input file, but with HADOOP-8599 it gets zero. The new behavior seems correct, but is it breaking anything else?"
MAPREDUCE-4467,IndexCache failures due to missing synchronization,"TestMRJobs.testSleepJob fails randomly due to synchronization error in IndexCache:

{code}
2012-07-20 19:32:34,627 ERROR [New I/O server worker #2-1] mapred.ShuffleHandler (ShuffleHandler.java:exceptionCaught(528)) - Shuffle error: 
java.lang.IllegalMonitorStateException
	at java.lang.Object.wait(Native Method)
	at org.apache.hadoop.mapred.IndexCache.getIndexInformation(IndexCache.java:74)
	at org.apache.hadoop.mapred.ShuffleHandler$Shuffle.sendMapOutput(ShuffleHandler.java:471)
	at org.apache.hadoop.mapred.ShuffleHandler$Shuffle.messageReceived(ShuffleHandler.java:397)
	at org.jboss.netty.handler.stream.ChunkedWriteHandler.handleUpstream(ChunkedWriteHandler.java:148)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:116)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:302)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.unfoldAndfireMessageReceived(ReplayingDecoder.java:522)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:506)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:443)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:274)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:261)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:349)
	at org.jboss.netty.channel.socket.nio.NioWorker.processSelectedKeys(NioWorker.java:280)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:200)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:662)
{code}

A related issue is MAPREDUCE-4384. The change introduced there removed ""synchronized"" keyword and hence ""info.wait()"" call fails. Tbis needs to be wrapped into a ""synchronized"" block."
MAPREDUCE-4465,Update description of yarn.nodemanager.address property,"The description for the property 'yarn.nodemanager.address' says 'address of node manager IPC.', which is not clear enough. It should be changed to something as 'The address of the container manager in the NM'."
MAPREDUCE-4464,Reduce tasks failing with NullPointerException in ConcurrentHashMap.get(),"If DNS does not resolve hostnames properly, reduce tasks can fail with a very misleading exception.

as per my peer Ahmed's diagnosis:

In ReduceTask, it seems that event.getTaskTrackerHttp() returns a malformed URI, and so host from:
{code}
String host = u.getHost();
{code}
is evaluated to null and the NullPointerException is thrown afterwards in the ConcurrentHashMap.

I have written a patch to check for a null hostname condition when getHost is called in the getMapCompletionEvents method and print an intelligible warning message rather than suppressing it until later when it becomes confusing and misleading.
"
MAPREDUCE-4463,JobTracker recovery fails with HDFS permission issue,Recovery fails when the job user is different to the JT owner (i.e. on anything bigger than a pseudo-distributed cluster).
MAPREDUCE-4461,Resourcemanager UI does not show the queue details in IE,Resourcemanager UI does not show the queue details in IE
MAPREDUCE-4458,Warn if java.library.path is used for AM or Task,"If java.library.path is used on the command line for launching an MRAppMaster or an MR Task, it could conflict with how standard Hadoop/HDFS JNI libraries and dependencies are found.  At a minimum the client should output a warning and ask the user to switch to LD_LIBRARY_PATH.  It would be nice to automatically do this for them but parsing the command line is scary so just a warning is probably good enough for now."
MAPREDUCE-4457,mr job invalid transition TA_TOO_MANY_FETCH_FAILURE at FAILED,"we saw a job go into the ERROR state from an invalid state transition.

3,600 INFO [AsyncDispatcher event handler]
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:
attempt_1342238829791_2501_m_007743_0 TaskAttempt Transitioned from SUCCEEDED
to FAILED
2012-07-16 08:49:53,600 INFO [AsyncDispatcher event handler]
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:
attempt_1342238829791_2501_m_008850_0 TaskAttempt Transitioned from SUCCEEDED
to FAILED
2012-07-16 08:49:53,600 INFO [AsyncDispatcher event handler]
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:
attempt_1342238829791_2501_m_017344_1000 TaskAttempt Transitioned from RUNNING
to SUCCESS_CONTAINER_CLEANUP
2012-07-16 08:49:53,601 ERROR [AsyncDispatcher event handler]
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this
event at current state for attempt_1342238829791_2501_m_000027_0
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event:
TA_TOO_MANY_FETCH_FAILURE at FAILED
    at
org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
    at
org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
    at
org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
    at
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:954)
    at
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:133)
    at
org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:913)
    at
org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:905)
    at
org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:126)
    at
org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.realDispatch(RecoveryService.java:285)
    at
org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:281)
    at
org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
    at java.lang.Thread.run(Thread.java:619)
2012-07-16 08:49:53,601 INFO [AsyncDispatcher event handler]
org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl:
attempt_1342238829791_2501_m_029091_1000 TaskAttempt Transitioned from RUNNING
to SUCCESS_CONTAINER_CLEANUP
2012-07-16 08:49:53,601 INFO [IPC Server handler 17 on 47153]
org.apache.hadoop.mapred.TaskAttemptListenerImpl: Status update from
attempt_1342238829791_2501_r_000461_1000


It looks like we possibly got 2 TA_TOO_MANY_FETCH_FAILURE events. The first one moved it to FAILED and then the second one failed because no valid transition."
MAPREDUCE-4456,LocalDistributedCacheManager can get an ArrayIndexOutOfBounds when creating symlinks,"{noformat}
java.lang.ArrayIndexOutOfBoundsException: 1
        at
org.apache.hadoop.mapred.LocalDistributedCacheManager.setup(LocalDistributedCacheManager.java:194)
        at
org.apache.hadoop.mapred.LocalJobRunner$Job.<init>(LocalJobRunner.java:154)
        at
org.apache.hadoop.mapred.LocalJobRunner.submitJob(LocalJobRunner.java:620)
        at
org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:385)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1215)
        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1212)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1212)
        at
org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:336)
        at
org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl.run(JobControl.java:233)
        at java.lang.Thread.run(Thread.java:619)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:260)
{noformat}"
MAPREDUCE-4453,Jobs should be executed as same user in hadoop-validate-setup.sh,"'su -c' command should be removed in hadoop-validate-setup.sh as
TeraGen, Terasort and teravalidate jobs should be executed as same user."
MAPREDUCE-4451,fairscheduler fail to init job with kerberos authentication configured,"Using FairScheduler in Hadoop 1.0.3 with kerberos authentication configured. Job initialization fails:

{code}
2012-07-17 15:15:09,220 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:
java.io.IOException: Call to /192.168.7.80:8020 failed on local exception: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1129)
        at org.apache.hadoop.ipc.Client.call(Client.java:1097)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)
        at $Proxy7.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:411)
        at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:125)
        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:329)
        at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:294)
        at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)
        at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1411)
        at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
        at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1429)
        at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
        at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
        at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:169)
        at org.apache.hadoop.mapred.JobInProgress.generateAndStoreTokens(JobInProgress.java:3558)
        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:696)
        at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:3911)
        at org.apache.hadoop.mapred.FairScheduler$JobInitializer$InitJob.run(FairScheduler.java:301)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:662)
Caused by: java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:543)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
        at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:488)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:590)
        at org.apache.hadoop.ipc.Client$Connection.access$2100(Client.java:187)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1228)
        at org.apache.hadoop.ipc.Client.call(Client.java:1072)
        ... 20 more
Caused by: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)]
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:194)
        at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:134)
        at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:385)
        at org.apache.hadoop.ipc.Client$Connection.access$1200(Client.java:187)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:583)
        at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:580)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:579)
        ... 23 more
Caused by: GSSException: No valid credentials provided (Mechanism level: Failed to find any Kerberos tgt)
        at sun.security.jgss.krb5.Krb5InitCredential.getInstance(Krb5InitCredential.java:130)
        at sun.security.jgss.krb5.Krb5MechFactory.getCredentialElement(Krb5MechFactory.java:106)
        at sun.security.jgss.krb5.Krb5MechFactory.getMechanismContext(Krb5MechFactory.java:172)
        at sun.security.jgss.GSSManagerImpl.getMechanismContext(GSSManagerImpl.java:209)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:195)
        at sun.security.jgss.GSSContextImpl.initSecContext(GSSContextImpl.java:162)
        at com.sun.security.sasl.gsskerb.GssKrb5Client.evaluateChallenge(GssKrb5Client.java:175)
        ... 32 more

{code}

When a job is submitted, fairscheduler calls JobTracker.initJob, which calls JobInProgress.generateAndStoreTokens to write security keys to hdfs. However, the operation is involved in the server side rpc call path, using UGI created by UserGroupInformation.createRemoteUser in rpc server, which have no tgt. This should be done with UGI used by JobTracker."
MAPREDUCE-4449,Incorrect MR_HISTORY_STORAGE property name in JHAdminConfig,Just noticed that MR_HISTORY_STORAGE has an extra period in the its name (i.e. the name is mapreduce.jobhistory..store.class).
MAPREDUCE-4448,Nodemanager crashes upon application cleanup if aggregation failed to start,"When log aggregation is enabled, the nodemanager can crash if log aggregation for an application failed to start."
MAPREDUCE-4447,Remove aop from cruft from the ant build ,The nop aop build dirs and remaining reference (MR ant build) should be removed. 
MAPREDUCE-4445,TestFSSchedulerApp should be in scheduler.fair package,"MAPREDUCE-3451 added Fair Scheduler to MRv2

TestFSSchedulerApp was added under src/test/java/org/apache/hadoop/yarn/server/resourcemanager/scheduler/fair but its package was declared to be org.apache.hadoop.yarn.server.resourcemanager.scheduler"
MAPREDUCE-4444,nodemanager fails to start when one of the local-dirs is bad,
MAPREDUCE-4441,Fix build issue caused by MR-3451,TestFSSchedulerApp is in the wrong package and missing some imports.
MAPREDUCE-4440,Change SchedulerApp & SchedulerNode to be a minimal interface ,Schedulers should manage their own implementations of SchedulerApp and SchedulerNode.
MAPREDUCE-4439,MAPREDUCE-3451 introduced a bunch of findbugs warnings,"Committed findbugs exclusions (hadoop-mapreduce-project/hadoop-yarn/dev-support/findbugs-exclude.xml) as an amendment of MAPREDUCE-3451. 

Lower priority to major as warnings are excluded.

Reassigning to Patrick to verify&disregard or fix the warning issues. If the warnings are invalid please close this JIRA as won't fix.





"
MAPREDUCE-4437,Race in MR ApplicationMaster can cause reducers to never be scheduled,If the MR AM is notified of container completion by the RM before the AM receives notification of the container cleanup from the NM then it can fail to schedule reducers indefinitely.  Logs showing the issue to follow.
MAPREDUCE-4434,Backport MR-2779 (JobSplitWriter.java can't handle large job.split file) to branch-1,
MAPREDUCE-4432,Confusing warning message when GenericOptionsParser is not used,"The warning that is issued in JobSubmitter -- ""Use GenericOptionsParser for parsing the arguments. Applications should implement Tool for the same."" -- is confusing and (probably) grammatically incorrect.

This can be improved by having an updated warning message which gives clearer directions on what can be improved in the application to avoid the warning in the future."
MAPREDUCE-4431,mapred command should print the reason on killing already completed jobs,"If we try to kill the already completed job by the following command it gives ambiguous message as ""Killed job <job id>""

./mapred job -kill <already completed job id>
"
MAPREDUCE-4430,"Adding child queues to any queue need the process restart ""./yarn rmadmin -refreshQueues"" throws IO exception","1.Configure different queues for capacity scheduler say a,b under root.
2.Start the process
3.Now add the child queue b1,b2 under b
4.Now do refresh queues with command ./yarn rmadmin -refreshQueues
Observed that it throws the following IO exception

{noformat}
java.io.IOException: Failed to re-init queues
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:216)
        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues(AdminService.java:174)
        at org.apache.hadoop.yarn.server.resourcemanager.api.impl.pb.service.RMAdminProtocolPBServiceImpl.refreshQueues(RMAdminProtocolPBServiceImpl.java:62)
        at org.apache.hadoop.yarn.proto.RMAdminProtocol$RMAdminProtocolService$2.callBlockingMethod(RMAdminProtocol.java:122)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:427)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:916)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1686)
Caused by: java.io.IOException: Trying to reinitialize root.b from root.b
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.reinitialize(LeafQueue.java:554)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.reinitialize(ParentQueue.java:387)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitializeQueues(CapacityScheduler.java:257)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.reinitialize(CapacityScheduler.java:213)
        ... 11 more
 at LocalTrace:
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Failed to re-init queues
        at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:50)
        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:40)
        at org.apache.hadoop.yarn.server.resourcemanager.AdminService.refreshQueues(AdminService.java:184)
        at org.apache.hadoop.yarn.server.resourcemanager.api.impl.pb.service.RMAdminProtocolPBServiceImpl.refreshQueues(RMAdminProtocolPBServiceImpl.java:62)
        at org.apache.hadoop.yarn.proto.RMAdminProtocol$RMAdminProtocolService$2.callBlockingMethod(RMAdminProtocol.java:122)
        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:427)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:916)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1692)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1688)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1232)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1686)
Caused by: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Trying to reinitialize root.b from root.b
        at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.getCause(YarnRemoteExceptionPBImpl.java:94)
        at org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl.getCause(YarnRemoteExceptionPBImpl.java:32)
        at java.lang.Throwable.printStackTrace(Throwable.java:514)
        at org.apache.hadoop.yarn.exceptions.YarnRemoteException.printStackTrace(YarnRemoteException.java:48)
        at org.apache.hadoop.util.StringUtils.stringifyException(StringUtils.java:69)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1715)
{noformat}"
MAPREDUCE-4425,Speculation + Fetch failures can lead to a hung job,"After a task goes to SUCCEEDED, FAILED/KILLED attempts are ignored.
1. attemp1 starts
2. speculative attempt starts
3. attempt 1 completes - Task moves to SUCCEEDED state
4. speculative attempt is KILLED
5. T_ATTEMPT_KILLED is ignored.
6. attemp1 1 fails with TOO_MANY_FETCH_FAILURES
The job will effectively hang, since a new task attempt isn't started."
MAPREDUCE-4424,'mapred job -list' command should show the job name as well,"Currently the {{mapred job -list}} command does not show the Job Name, just the Job ID. It would be good to display the Job name too. Idea originally from HADOOP-5555."
MAPREDUCE-4423,Potential infinite fetching of map output,"Inside Fetcher.java there are a few cases where an error can happen and the corresponding map task is not marked as a fetch failure.  One of these is if the Shuffle server returns a malformed result.

MAPREDUCE-3992 makes this case a lot less common, but it is still possible.  IF the shuffle handler always returns a malformed result, but a OK response the Fetcher will never stop trying to fetch those results. "
MAPREDUCE-4422,YARN_APPLICATION_CLASSPATH needs a documented default value in YarnConfiguration,"MAPREDUCE-3505 allowed YARN_APPLICATION_CLASSPATH to be configurable.

However, we didn't add a default value to YarnConfiguration, as-is the norm.

Ran into it while investigating MAPREDUCE-4421."
MAPREDUCE-4421,Run MapReduce framework via the distributed cache,"Currently MR AM depends on MR jars being deployed on all nodes via implicit dependency on YARN_APPLICATION_CLASSPATH. 

We should stop adding mapreduce jars to YARN_APPLICATION_CLASSPATH and, probably, just rely on adding a shaded MR jar along with job.jar to the dist-cache."
MAPREDUCE-4420,./mapred queue -info <queuename> -showJobs displays containers and memory as zero always,./mapred queue -info <queuename> -showJobs displays containers and memory as zero always.
MAPREDUCE-4419,./mapred queue -info <queuename> -showJobs displays all the jobs irrespective of <queuename> ,"./mapred queue -info <queuename> -showJobs shows all the jobs irrespective of <queuename>

In Queue name field all the jobs are showing as default queue but they are submitted to the configured queue(see screenshots attached)."
MAPREDUCE-4417,add support for encrypted shuffle,"Currently Shuffle fetches go on the clear. While Kerberos provides comprehensive authentication for the cluster, it does not provide confidentiality. 

When processing sensitive data confidentiality may be desired (at the expense of job performance and resources utilization for doing encryption).
"
MAPREDUCE-4416,Some tests fail if Clover is enabled,"There are number of tests running under hadoop-mapreduce-client-jobclient that fail if Clover is enabled. Whenever a job is launched, AM doesn't start because it can't locate the clover jar file.

I thought MAPREDUCE-4253 had something to do with this, but I can reproduce the issue on an older revision. Although unrelated, MAPREDUCE-4253 does have a problem and it has been reported to the jira."
MAPREDUCE-4415,Backport the Job.getInstance methods from MAPREDUCE-1505 to branch-1,"In 2.x MR, the Job constructors have all been deprecated in favor of Job.getInstance() calls to get a Job object.

However, these getInstance methods do not appear to be present in the 1.x MR API, and thereby may cause additional pain to users moving from 1.x to 2.x going forward.

This patch proposes to add in the getInstance style of methods with suitable test coverage for both style of constructors, while not pulling in anything else from MAPREDUCE-1505 (as we lack 'Cluster' in 1.x). As we're not going to be deprecating the regular ctors in a 1.x release, this is not an incompatible change in any way."
MAPREDUCE-4414,"Add main methods to JobConf and YarnConfiguration, for debug purposes","Just like Configuration has a main() func that dumps XML out for debug purposes, we should have a similar function under the JobConf and YarnConfiguration classes that do the same. This is useful in testing out app classpath setups at times."
MAPREDUCE-4413,MR lib dir contains jdiff (which is gpl),"A tarball built from trunk contains the following:

./share/hadoop/mapreduce/lib/jdiff-1.0.9.jar

jdiff is gplv2, we need to exclude it from the build artifact."
MAPREDUCE-4408,allow jobs to set a JAR that is in the distributed cached,"Setting a job JAR with JobConf.setJar(String) and Job.setJar(String) assumes that the JAR is local to the client submitting the job, thus it triggers copying the JAR to HDFS and injecting it to the distributed cached.

AFAIK, this is the only way to use uber JARs (JARs with JARs inside) in MR jobs.

For jobs launched by Oozie, all JARs are already in HDFS. In order for Oozie to suport uber JARs (OOZIE-654) there should be a way for specifying as JAR a JAR that is already in HDFS.

"
MAPREDUCE-4407,Add hadoop-yarn-server-tests-<version>-tests.jar to hadoop dist package,This change basically adds hadoop-yarn-server-tests-<version>-tests.jar to the package. 
MAPREDUCE-4406,Users should be able to specify the MiniCluster ResourceManager and JobHistoryServer ports,"There is use-cases where users may need to specify the ports used for the resource manager and history server for the minicluster.

In the current implementation, the MiniCluster sets these addresses regardless of them being already set by the user in the conf.

Users should be able to add these properties to the conf and in such case the MiniCluster will use the specified addresses. If not specified then the current behavior of the MiniCluster for explicitly setting the addresses will be used.

I'll be uploading a patch momentarily."
MAPREDUCE-4405,Adding test case for HierarchicalQueue in TestJobQueueClient,Adding test case for HierarchicalQueue in TestJobQueueClient
MAPREDUCE-4404,Adding Test case for TestMRJobClient to verify the user name,Adding Test case for TestMRJobClient to verify the user name
MAPREDUCE-4403,Adding test case for resubmission of jobs in TestRecoveryManager,"In Hadoop 22 Test recovery Manager does not have resubmission test case which checks after the resubmission jobs get succeeded.

There is some refactoring is also needed. 

Thanks,
Mayank"
MAPREDUCE-4402,TestFileInputFormat fails intermittently,TestFileInputFormat#testLocality is failing intermittently when verifying each file split has two block locations.
MAPREDUCE-4401,Enhancements to MapReduce for Windows Server and Windows Azure development and runtime environments,This JIRA tracks the work that needs to be done on trunk to enable Hadoop to run on Windows Server and Azure environments. This incorporates porting relevant work from the similar effort on branch 1 tracked via HADOOP-8079.
MAPREDUCE-4400,Fix performance regression for small jobs/workflows,There is a significant performance regression for small jobs/workflows (vs 0.20.2) in the Hadoop 1.x series. Most noticeable with Hive and Pig jobs. PigMix has an average 40% regression against 0.20.2.
MAPREDUCE-4399,Fix performance regression in shuffle ,There is a significant (up to 3x) performance regression in shuffle (vs 0.20.2) in the Hadoop 1.x series. Most noticeable with high-end switches.
MAPREDUCE-4398,Fix mapred.system.dir permission error with FairScheduler,Incorrect job initialization logic in FairScheduler causes mysterious intermittent mapred.system.dir permission errors.
MAPREDUCE-4397,Introduce HADOOP_SECURITY_CONF_DIR for task-controller,The linux task controller currently hard codes the directory in which to look for its config file at compile time (via the HADOOP_CONF_DIR macro). Adding a new environment variable to look for task-controller's conf dir (with strict permission checks) would make installation much more flexible.
MAPREDUCE-4396,Make LocalJobRunner work with private distributed cache,Some LocalJobRunner related unit tests fails if user directory permission and/or umask is too restrictive.
MAPREDUCE-4395,Possible NPE at ClientDistributedCacheManager#determineTimestamps,"{code:title=ClientDistributedCacheManager#determineTimestamps|borderStyle=solid}
URI[] tfiles = DistributedCache.getCacheFiles(job);
{code}

It may be possible that tfiles array contains *null* as it's entry, and subsequently leads to NPE."
MAPREDUCE-4394,ReduceTask.MapOutputCopier.copyOutput() signature doesn't match the corresponding Javadoc,
MAPREDUCE-4392,Counters.makeCompactString() changed behavior from 0.20,"In 0.20, makeCompactString() returned a comma-separated list, but MAPREDUCE-3697 changed it to be equivalent to makeEscapedCompactString().  Users moving from 0.20 to 0.23 are expecting the original behavior from makeCompactString()."
MAPREDUCE-4391,datanode.DataNode (DataNode.java:handshake(820)) - Problem connecting to server: master/192.168.100.140:9000,"datanode cannot able to connect to namenode, and in turn resulting in future errors during running examples.
2012-07-04 15:25:09,636 WARN  datanode.DataNode (DataNode.java:handshake(820)) - Problem connecting to server: master/192.168.100.140:9000
2012-07-04 15:25:15,638 INFO  ipc.Client (Client.java:handleConnectionFailure(671)) - Retrying connect to server: master/192.168.100.140:9000. Already tried 0 time(s).
2012-07-04 15:25:16,640 INFO  ipc.Client (Client.java:handleConnectionFailure(671)) - Retrying connect to server: master/192.168.100.140:9000. Already tried 1 time(s).
2012-07-04 15:25:17,642 INFO  ipc.Client (Client.java:handleConnectionFailure(671)) - Retrying connect to server: master/192.168.100.140:9000. Already tried 2 time(s).
2012-07-04 15:25:18,643 INFO  ipc.Client (Client.java:handleConnectionFailure(671)) - Retrying connect to server: master/192.168.100.140:9000. Already tried 3 time(s)."
MAPREDUCE-4390,java.io.IOException: File /user/XXXX/QuasiMonteCarlo_TMP_3_141592654/in/part0 could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.,"Tried to run an example program on hadoop0.23.0 and getting the following error.
error:
java.io.IOException: File /user/XXXXX/QuasiMonteCarlo_TMP_3_141592654/in/part0 could only be replicated to 0 nodes instead of minReplication (=1).  There are 0 datanode(s) running and no node(s) are excluded in this operation.
        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget(BlockManager.java:1181)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1486)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:390)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:365)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1490)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1486)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1484)
"
MAPREDUCE-4387,RM gets fatal error and exits during TestRM,"It doesn't happen on my desktop, but it happens frequently during the builds with clover enabled. Surefire will report it as fork failure.

"
MAPREDUCE-4385,FairScheduler.maxTasksToAssign() should check for fairscheduler.assignmultiple.maps < TaskTracker.availableSlots,"FairScheduler.maxTasksToAssign() can potentially return a value greater than the available slots. Currently, we rely on canAssignMaps()/canAssignReduces() to reject such requests.

These additional calls can be avoided by check against the available slots in maxTasksToAssign()."
MAPREDUCE-4384,Race conditions in IndexCache,"TestIndexCache is intermittently failing due to a race condition. Up on inspection of IndexCache implementation, more potential issues have been discovered."
MAPREDUCE-4383,HadoopPipes.cc needs to include unistd.h,"Since MAPREDUCE-4267 I've seen ""mvn -Pnative compile"" failing with:
{quote}
     [exec] /usr/bin/c++    -g -Wall -O2 -D_REENTRANT -D_FILE_OFFSET_BITS=64 -I/home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/utils/api -I/home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/api -I/home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src    -o CMakeFiles/hadooppipes.dir/main/native/pipes/impl/HadoopPipes.cc.o -c /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc: In member function ‘std::string HadoopPipes::BinaryProtocol::createDigest(std::string&, std::string&)’:
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc:439:21: warning: value computed is not used [-Wunused-value]
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc: In function ‘void* HadoopPipes::ping(void*)’:
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc:1049:16: error: ‘sleep’ was not declared in this scope
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc:1067:30: error: ‘close’ was not declared in this scope
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc: In function ‘bool HadoopPipes::runTask(const HadoopPipes::Factory&)’:
     [exec] /home/adi/w/apache-hadoop-trunk/hadoop-tools/hadoop-pipes/src/main/native/pipes/impl/HadoopPipes.cc:1162:28: error: ‘close’ was not declared in this scope
     [exec] make[2]: *** [CMakeFiles/hadooppipes.dir/main/native/pipes/impl/HadoopPipes.cc.o] Error 1
{quote}

I believe the failure is new simply because I wasn't compiling pipes before.

The fix is pretty simple, just include unistd.h in HadoopPipes.cc.

My environment is debian unstable, amd64, g++ 4.7.0-6, openjdk-6-jdk 6b24-1.11.1-6."
MAPREDUCE-4380,Empty Userlogs directory is getting created under logs directory,Empty Userlogs directory is getting created under logs directory.
MAPREDUCE-4379,Node Manager throws java.lang.OutOfMemoryError: Java heap space due to org.apache.hadoop.fs.LocalDirAllocator.contexts,"{code:xml}
Exception in thread ""Container Monitor"" java.lang.OutOfMemoryError: Java heap space
	at java.io.BufferedReader.<init>(BufferedReader.java:80)
	at java.io.BufferedReader.<init>(BufferedReader.java:91)
	at org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree.java:410)
	at org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTree(ProcfsBasedProcessTree.java:171)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl$MonitoringThread.run(ContainersMonitorImpl.java:389)
	Exception in thread ""LocalizerRunner for container_1340690914008_10890_01_000003"" java.lang.OutOfMemoryError: Java heap space
	at java.util.Arrays.copyOfRange(Arrays.java:3209)
	at java.lang.String.<init>(String.java:215)
	at com.sun.org.apache.xerces.internal.xni.XMLString.toString(XMLString.java:185)
	at com.sun.org.apache.xerces.internal.parsers.AbstractDOMParser.characters(AbstractDOMParser.java:1188)
	at com.sun.org.apache.xerces.internal.xinclude.XIncludeHandler.characters(XIncludeHandler.java:1084)
	at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:464)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:808)
	at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:737)
	at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:119)
	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:235)
	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:284)
	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:180)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:1738)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:1689)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:1635)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:722)
	at org.apache.hadoop.conf.Configuration.setStrings(Configuration.java:1300)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.initDirs(ContainerLocalizer.java:375)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.runLocalization(ContainerLocalizer.java:127)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.startLocalizer(DefaultContainerExecutor.java:103)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:862)
{code}"
MAPREDUCE-4378,hadoop-validate-setup.sh fails to execute kinit command in secure mode,hadoop-validate-setup.sh is refering to the invalid kinit location.
MAPREDUCE-4376,TestClusterMRNotification times out,"The TestClusterMRNotification test is often timing out.  git bisect tests narrowed it down to MAPREDUCE-3921, as the test consistently passes before that change and times out most of the time after picking up that change."
MAPREDUCE-4375,Show Configuration Tracability in MR UI,Once HADOOP-8525 goes in we should provide a way for the Configuration UI to display the traceability information.
MAPREDUCE-4374,Fix child task environment variable config and add support for Windows,"In HADOOP-2838, a new feature was introduced to set environment variables via the Hadoop config 'mapred.child.env' for child tasks. There are some further fixes and improvements around this feature, e.g. HADOOP-5981 were a bug fix; MAPREDUCE-478 broke the config into 'mapred.map.child.env' and 'mapred.reduce.child.env'.  However the current implementation is still not complete. It does not match its documentation or original intend as I believe. Also, by using ‘:’ (colon) and ‘;’ (semicolon) in the configuration syntax, we will have problems using them on Windows because ‘:’ appears very often in Windows path as in “C:\”, and environment variables are used very often to hold path names. The Jira is created to fix the problem and provide support on Windows."
MAPREDUCE-4373,Fix Javadoc warnings in JobClient.,"It looks like MAPREDUCE-4355 added in two new javadoc warnings.

{code}
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-MAPREDUCE-Build/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java:651: warning - @param argument ""jobid"" is not a parameter name.
[WARNING] /home/jenkins/jenkins-slave/workspace/PreCommit-MAPREDUCE-Build/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/java/org/apache/hadoop/mapred/JobClient.java:669: warning - @param argument ""jobid"" is not a parameter name.
{code}"
MAPREDUCE-4372,Deadlock in Resource Manager between SchedulerEventDispatcher.EventProcessor and Shutdown hook manager,Please find the attached resource manager thread dump for the issue.
MAPREDUCE-4371,Check for cyclic dependencies in Jobcontrol job DAG,"In current implementation of JobControl, whenever there is a cyclic dependency between the jobs it throws a Stack overflow exception. This jira adds a cyclic check to jobcontrol."
MAPREDUCE-4369,Fix streaming job failures with WindowsResourceCalculatorPlugin,"Some streaming jobs use local mode job runs that do not start tasks trackers. In these cases, the jvm context is not setup and hence local mode execution causes the code to crash.
Fix is to not not use ResourceCalculatorPlugin in such cases or make the local job run creating dummy jvm contexts. Choosing the first option because thats the current implicit behavior in Linux. The ProcfsBasedProcessTree (used inside the LinuxResourceCalculatorPlugin) does no real work when the process pid is not setup correctly. This is what happens when local job mode runs.
"
MAPREDUCE-4368,TaskRunner fails to start jars when the java.library.path contains a quoted path with embedded spaces,"TaskRunner splits arguments by space before it adds them back to the vargs list, so it loses all context of quote escaped strings with embedded spaces.  This gets fixed up later by wrapping all arguments with "" -- so you get something like java ""-D<opt>=<value>"".  This is problematic for paths with embedded spaces, where we end up creating ""-D<opt>=<first part"" ""last part>"".  To java, the jar being run is last part.  So with the environment above, you will see ""ClassNoDefFoundError: memorable"" and the jar will fail to start.  In this particular case, we know that java.libarary.path contains paths and the tests often use %PATH% to seed this, so the fix is to remove embedded quotes in listed path elements because we know the aggregate will be quoted when the JVM is started."
MAPREDUCE-4366,mapred metrics shows negative count of waiting maps and reduces,"Negative waiting_maps and waiting_reduces count is observed in the mapred metrics.  MAPREDUCE-1238 partially fixed this but it appears there is still issues as we are seeing it, but not as bad.
"
MAPREDUCE-4365,Shipping Profiler Libraries by DistributedCache,"Hadoop profiling is great for performance tuning and debugging, but currently we can only use Java built-in profilers such as HProf, and for other profilers we need to install them on all slave nodes first, which is inconvenient for large clusters and sometimes impossible for production clusters. 

Supporting shipping profiler libraries using DistributedCache will solve this problem. For example, in mapred.task.profile.params, we specify a profiler library from the DistributedCache using special place holders such as <foo.jar>, and Hadoop can look at the DistributedCache to replace <foo.jar> with the localized path before launching the child jvm.

"
MAPREDUCE-4363,"Hadoop 1.X, 2.X and trunk do not build on Fedora 17","I upgraded my machine to the latest Fedora 17 and now Apache Hadoop is failing to build. This seems related to the bump in version of gcc to 4.7.0
"
MAPREDUCE-4361,Fix detailed metrics for protobuf-based RPC on 0.23,RPC detailed metrics for any protobuf-based RPC ports are always zero.  ProtoOverHadoopRpcEngine needs the same detailed metric logic as in WritableRpcEngine.  This is effectively the same change as in HADOOP-8085 except tailored for branch-0.23 which didn't take the full protobuf branch changes that went into branch-2 and trunk.
MAPREDUCE-4360,Capacity Scheduler Hierarchical leaf queue does not honor the max capacity of container queue,
MAPREDUCE-4359,Potential deadlock in Counters,"jcarder identified this deadlock in branch-1 (though it may also be present in trunk):
- Counters.size() is synchronized and locks Counters before Group
- Counters.Group.getCounterForName() is synchronized and calls through to Counters.size()

This creates a potential cycle which could cause a deadlock (though probably quite rare in practice)"
MAPREDUCE-4358,Reducers are assigned containers before all maps are assigned containers,"Reducers start to get containers before all maps are. We have seen this issue and it is problematic since if there is no avaialable resources for the remaining maps, the job will just stall where reducers are waiting for mappers which are unable to start because there is no containers available."
MAPREDUCE-4356,Provide access to ParsedTask.obtainTaskAttempts(),Change the access modifier of obtainTaskAttempts() in ParsedTask.java from default to public sothat it is accessible for everyone.
MAPREDUCE-4355,Add RunningJob.getJobStatus(),"Usecase: Read the start/end-time of a particular job.

Currently, one has to iterate through JobClient.getAllJobStatuses() and iterate through them. JobClient.getJob(JobID) returns RunningJob, which doesn't hold the job's start time.

Adding RunningJob.getJobStatus() solves the issue."
MAPREDUCE-4354,Performance improvement with compressor object reinit restriction,"HADOOP-5879 patch aimed at picking the conf (instead of default) settings for GzipCodec. It also involved re-initializing the recycled compressor object. 
On our performance tests, this re-initialization led to performance degradation of 15% for LzoCodec because re-initialization for Lzo involves reallocation of buffers. LzoCodec takes the initial settings from config so it is not necessary to re-initialize it. This patch checks for the codec class and calls reinit only if the codec class is Gzip. This led to significant performance improvement of 15% for LzoCodec.
"
MAPREDUCE-4349,Distributed Cache gives inconsistent result if cache Archive files get deleted from task tracker ,Add test to verify Distributed Cache consistency when cached archives are deleted.
MAPREDUCE-4348,"JobSubmissionProtocol should be made public, not package private","The JobSubmissionProtocol interface is package private, yet it is the only way to remotely query the status of the JT or the cluster. 

Even if Job Submission is considered private, probing JT state shouldn't be."
MAPREDUCE-4347,joined PhD. Intrested to do research in cloud especially in Hadoop. need suggession for problems to work.,
MAPREDUCE-4343,ZK recovery support for ResourceManager,"MAPREDUCE-279 included bits and pieces of possible ZK integration for YARN's RM, but looks like it failed to complete it (for scalability reasons? etc?) and there seems to be no JIRA tracking this feature that has been already claimed publicly as a good part about YARN.

If it did complete it, we should document how to use it. Setting the following only yields:

{code}
<property>
<name>yarn.resourcemanager.store.class</name>
<value>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore</value>
</property>
<property>
<name>yarn.resourcemanager.zookeeper-store.address</name>
<value>test.vm:2181/yarn-recovery-store</value>
</property>
{code}

{code}
Error starting ResourceManager
java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore.<init>()
at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:128)
at org.apache.hadoop.yarn.server.resourcemanager.recovery.StoreFactory.getStore(StoreFactory.java:32)
at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:621)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKStore.<init>()
at java.lang.Class.getConstructor0(Class.java:2706)
at java.lang.Class.getDeclaredConstructor(Class.java:1985)
at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:122)
... 2 more
{code}

This JIRA is hence filed to track the addition/completion of recovery via ZK."
MAPREDUCE-4342,Distributed Cache gives inconsistent result if cache files get deleted from task tracker ,
MAPREDUCE-4341,add types to capacity scheduler properties documentation,"MAPREDUCE-4311 is changing capacity/max capacity configuration to be floats. We should document that in the capacity scheduler properties docs (http://hadoop.apache.org/common/docs/r0.23.1/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html#Configuration).

"
MAPREDUCE-4340,Node Manager leaks socket connections connected to Data Node,"I am running simple wordcount example with default configurations, for every job run it increases one datanode socket connection and it will be there in CLOSE_WAIT state forever."
MAPREDUCE-4339,pi example job hangs on when run on hadoop 0.23.0 when capacity scheduler is included in the setting environment.,"Tried to include default capacity scheduler in hadoop and tried to run an example pi program. The job hangs and no more output is getting displayed.
Starting Job
2012-06-12 22:10:02,524 INFO  ipc.YarnRPC (YarnRPC.java:create(47)) - Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2012-06-12 22:10:02,538 INFO  mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:<init>(95)) - Connecting to ResourceManager at localhost/127.0.0.1:8030
2012-06-12 22:10:02,539 INFO  ipc.HadoopYarnRPC (HadoopYarnProtoRPC.java:getProxy(48)) - Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol
2012-06-12 22:10:02,665 INFO  mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:<init>(99)) - Connected to ResourceManager at localhost/127.0.0.1:8030
2012-06-12 22:10:02,727 WARN  conf.Configuration (Configuration.java:handleDeprecation(326)) - fs.default.name is deprecated. Instead, use fs.defaultFS
2012-06-12 22:10:02,728 WARN  conf.Configuration (Configuration.java:handleDeprecation(343)) - mapred.used.genericoptionsparser is deprecated. Instead, use mapreduce.client.genericoptionsparser.used
2012-06-12 22:10:02,831 INFO  input.FileInputFormat (FileInputFormat.java:listStatus(245)) - Total input paths to process : 10
2012-06-12 22:10:02,900 INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(362)) - number of splits:10
2012-06-12 22:10:03,044 INFO  mapred.YARNRunner (YARNRunner.java:createApplicationSubmissionContext(279)) - AppMaster capability = memory: 2048
2012-06-12 22:10:03,286 INFO  mapred.YARNRunner (YARNRunner.java:createApplicationSubmissionContext(355)) - Command to launch container for ApplicationMaster is : $JAVA_HOME/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.mapreduce.container.log.dir=<LOG_DIR> -Dyarn.app.mapreduce.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Xmx1536m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
2012-06-12 22:10:03,370 INFO  mapred.ResourceMgrDelegate (ResourceMgrDelegate.java:submitApplication(304)) - Submitted application application_1339507608976_0002 to ResourceManager
2012-06-12 22:10:03,432 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1207)) - Running job: job_1339507608976_0002
2012-06-12 22:10:04,443 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1227)) -  map 0% reduce 0%"
MAPREDUCE-4338,NodeManager daemon is failing to start.,"Node manager daemons is not getting started on the slave machines. and giving an error like stated below.
2012-06-12 19:05:56,172 FATAL nodemanager.NodeManager (NodeManager.java:main(233)) - Error starting NodeManager
org.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager
        at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:163)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:231)
Caused by: org.apache.avro.AvroRuntimeException: java.lang.reflect.UndeclaredThrowableException
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:132)
        at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
        ... 2 more
Caused by: java.lang.reflect.UndeclaredThrowableException
        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:66)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:161)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:128)
        ... 3 more
Caused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call From mvm5/192.168.100.177 to mvm4:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
        at $Proxy14.registerNodeManager(Unknown Source)
        at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)
        ... 5 more
Caused by: java.net.ConnectException: Call From mvm5/192.168.100.177 to mvm4:8025 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:617)
        at org.apache.hadoop.ipc.Client.call(Client.java:1089)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
        ... 7 more
Caused by: java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:419)
        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:460)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:557)
        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:205)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1195)
        at org.apache.hadoop.ipc.Client.call(Client.java:1065)
        ... 8 more
2012-06-12 19:05:56,184 INFO  ipc.Server (Server.java:stop(1709)) - Stopping server on 47645
2012-06-12 19:05:56,184 INFO  ipc.Server (Server.java:stop(1709)) - Stopping server on 4344
2012-06-12 19:05:56,190 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(199)) - Stopping NodeManager metrics system...
2012-06-12 19:05:56,190 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stopSources(408)) - Stopping metrics source JvmMetrics
2012-06-12 19:05:56,191 INFO  nodemanager.NodeManager (StringUtils.java:run(605)) - SHUTDOWN_MSG:"
MAPREDUCE-4336,Distributed Shell fails when used with the CapacityScheduler,DistributedShell attempts to get queue info without providing a queue name - which ends up in an NPE.
MAPREDUCE-4328,Add the option to quiesce the JobTracker,"In several failure scenarios it would be very handy to have an option to quiesce the JobTracker.

Recently, we saw a case where the NameNode had to be rebooted at a customer due to a random hardware failure - in such a case it would have been nice to not lose jobs by quiescing the JobTracker."
MAPREDUCE-4324,JobClient can perhaps set mapreduce.job.credentials.binary rather than expect its presence?,"HDFS-1007 added in this requirement property ""mapreduce.job.credentials.binary"", that has lead Oozie to add the following duplicate snippet to all its Job-launching main classes such as the Pig, Hive, MR and Sqoop actions:

{code}
if (System.getenv(""HADOOP_TOKEN_FILE_LOCATION"") != null) {
            jobConf.set(""mapreduce.job.credentials.binary"", System.getenv(""HADOOP_TOKEN_FILE_LOCATION""));
}
{code}

Same is required for any client program that launches a job from within a task.

Why can't this simply be set by the JobClient initialization bits itself? If no one imagines it causing issues, I'd like to add this snippet somewhere in JobSubmitter before it requests NN/JT, as otherwise we'd get…

{code}
org.apache.hadoop.ipc.RemoteException: java.io.IOException: Delegation Token can be issued only with kerberos or web authentication 
at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:5509) 
at org.apache.hadoop.hdfs.server.namenode.NameNode.getDelegationToken(NameNode.java:536) 
at sun.reflect.GeneratedMethodAccessor31.invoke(Unknown Source) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 
at java.lang.reflect.Method.invoke(Method.java:597) 
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:396) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157) 
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)

at org.apache.hadoop.ipc.Client.call(Client.java:1107) 
at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:226) 
at $Proxy6.getDelegationToken(Unknown Source) 
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) 
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) 
at java.lang.reflect.Method.invoke(Method.java:597) 
at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82) 
at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59) 
at $Proxy6.getDelegationToken(Unknown Source) 
at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:331) 
at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:605) 
at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:115) 
at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:79) 
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:851) 
at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:833) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:396) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157) 
at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:833) 
at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:807) 
at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1242) 
{code}

… or similar errors when a user submits a job from a task running in a secured cluster.

Let me know your thoughts on this!"
MAPREDUCE-4322,Fix command-line length abort issues on Windows,"When a task is started on the tasktracker, it creates a small batch file to invoke java and runs that batch.  Within the batch file, the invocation of Java currently has -classpath ${CLASSPATH} inline to the command.  That line often exceeds 8000 characters.  This is ok for most linux distributions because the line limit env variable is often set much higher than this.  However, for Windows this cause cmd to abort execution.  This surfaces in Hadoop as an unknown failure mode for the task.

I think the easiest and most natural way to fix this is to push the -classpath option into a config file to take the longest variable part of the line and put it somewhere that scales better."
MAPREDUCE-4321,DefaultTaskController fails to launch tasks on Windows,"DefaultTaskController#launchTask tries to run the child JVM task with the following command line:
{code}cmd.exe /c /c:/some/path.../taskjvm.cmd{code}
And this fails because the given path is prefixed with a forward slash. This also causes a number of tests to fail:

org.apache.hadoop.conf.TestNoDefaultsJobConf
org.apache.hadoop.fs.TestCopyFiles
org.apache.hadoop.mapred.TestBadRecords
org.apache.hadoop.mapred.TestClusterMRNotification
org.apache.hadoop.mapred.TestCompressedEmptyMapOutputs
org.apache.hadoop.mapred.TestControlledMapReduceJob
org.apache.hadoop.mapred.TestCustomOutputCommitter
org.apache.hadoop.mapred.TestEmptyJob
org.apache.hadoop.mapred.TestFileOutputFormat
org.apache.hadoop.mapred.TestIsolationRunner
org.apache.hadoop.mapred.TestJavaSerialization
org.apache.hadoop.mapred.TestJobCleanup
org.apache.hadoop.mapred.TestJobCounters
org.apache.hadoop.mapred.TestJobHistoryServer
org.apache.hadoop.mapred.TestJobInProgressListener
org.apache.hadoop.mapred.TestJobKillAndFail
org.apache.hadoop.mapred.TestJobName
..."
MAPREDUCE-4320,gridmix mainClass wrong in pom.xml,"when trying to run gridmix its actually trying to run org.apache.hadoop.tools.HadoopArchives.

the pom.xml needs to be fixed to have correct mainClass: org.apache.hadoop.mapred.gridmix.Gridmix"
MAPREDUCE-4318,TestRecoveryManager should not use raw and deprecated configuration parameters.,"TestRecoveryManager should not use deprecated config keys, and should use constants for the keys where possible."
MAPREDUCE-4317,Job view ACL checks are too permissive,"The class that does view-based checks, JSPUtil.JobWithViewAccessCheck, has the following internal member:

{code}private boolean isViewAllowed = true;{code}

Note that its true.

Now, in the method that sets proper view-allowed rights, has:

{code}
if (user != null && job != null && jt.areACLsEnabled()) {
      final UserGroupInformation ugi =
        UserGroupInformation.createRemoteUser(user);
      try {
        ugi.doAs(new PrivilegedExceptionAction<Void>() {
          public Void run() throws IOException, ServletException {

            // checks job view permission
            jt.getACLsManager().checkAccess(job, ugi,
                Operation.VIEW_JOB_DETAILS);
            return null;
          }
        });
      } catch (AccessControlException e) {
        String errMsg = ""User "" + ugi.getShortUserName() +
            "" failed to view "" + jobid + ""!<br><br>"" + e.getMessage() +
            ""<hr><a href=\""jobtracker.jsp\"">Go back to JobTracker</a><br>"";
        JSPUtil.setErrorAndForward(errMsg, request, response);
        myJob.setViewAccess(false);
      } catch (InterruptedException e) {
        String errMsg = "" Interrupted while trying to access "" + jobid +
        ""<hr><a href=\""jobtracker.jsp\"">Go back to JobTracker</a><br>"";
        JSPUtil.setErrorAndForward(errMsg, request, response);
        myJob.setViewAccess(false);
      }
    }
    return myJob;
{code}

In the above snippet, you can notice that if user==null, which can happen if user is not http-authenticated (as its got via request.getRemoteUser()), can lead to the view being visible since the default is true and we didn't toggle the view to false for user == null case.

Ideally the default of the view job ACL must be false, or we need an else clause that sets the view rights to false in case of a failure to find the user ID."
MAPREDUCE-4315,jobhistory.jsp throws 500 when a .txt file is found in /done,"if a .txt file located in /done the parser throws an 500 error.
Trace:
java.lang.ArrayIndexOutOfBoundsException: 1
        at org.apache.hadoop.mapred.jobhistory_jsp$2.compare(jobhistory_jsp.java:295)
        at org.apache.hadoop.mapred.jobhistory_jsp$2.compare(jobhistory_jsp.java:279)
        at java.util.Arrays.mergeSort(Arrays.java:1270)
        at java.util.Arrays.mergeSort(Arrays.java:1282)
        at java.util.Arrays.mergeSort(Arrays.java:1282)
        at java.util.Arrays.mergeSort(Arrays.java:1282)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.mergeSort(Arrays.java:1282)
        at java.util.Arrays.mergeSort(Arrays.java:1281)
        at java.util.Arrays.sort(Arrays.java:1210)
        at org.apache.hadoop.mapred.jobhistory_jsp._jspService(jobhistory_jsp.java:279)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:864)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:326)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

Reproduce:

cd ../done
touch test.txt
reload jobhistory"
MAPREDUCE-4314,Synchronization in JvmManager for 0.22 branch,Changes to JvmManager due to MR-2178 for branch 0.22.
MAPREDUCE-4313,TestTokenCache doesn't compile due TokenCache.getDelegationToken compilation error,"Saw this on the trunk Jenkins job:

{noformat}
compile-mapred-test:
    [mkdir] Created dir: /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/build/test/mapred/classes
    [mkdir] Created dir: /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/build/test/mapred/testjar
    [mkdir] Created dir: /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/build/test/mapred/testshell
    [javac] Compiling 95 source files to /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/build/test/mapred/classes
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapreduce/security/TestTokenCache.java:292: incompatible types
    [javac] found   : org.apache.hadoop.security.token.Token<capture#315 of ?>
    [javac] required: org.apache.hadoop.security.token.Token<org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier>
    [javac]     Token<DelegationTokenIdentifier> nnt = TokenCache.getDelegationToken(
    [javac]                                                                         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error
{noformat}"
MAPREDUCE-4312,Add metrics to RM for NM heartbeats,"It would be nice to have a metric in the ResourceManager to track the number of NodeManager heartbeats processed.  The JobTracker in 1.0 has a tasktracker heartbeat metric, and it would be nice if the RM had the equivalent metric."
MAPREDUCE-4311,Capacity scheduler.xml does not accept decimal values for capacity and maximum-capacity settings,"if capacity scheduler capacity or max capacity set with decimal it errors:

- Error starting ResourceManager

java.lang.NumberFormatException: For input string: ""10.5""
        at
java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
        at java.lang.Integer.parseInt(Integer.java:458)
        at java.lang.Integer.parseInt(Integer.java:499)
        at org.apache.hadoop.conf.Configuration.getInt(Configuration.java:713)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration.getCapacity(CapacitySchedulerConfiguration.java:147)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.<init>(LeafQueue.java:147)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.parseQueue(CapacityScheduler.java:297)
        at

0.20 used to take decimal and this could be an issue on large clusters that would have queues with small allocations."
MAPREDUCE-4307,TeraInputFormat calls FileSystem.getDefaultBlockSize() without a Path - Failure when using ViewFileSystem,ViewFileSystem.getDefaultBlockSize() throws NotInMountpointException (see HADOOP-8014). I'll upload a patch momentarily.
MAPREDUCE-4306,Problem running Distributed Shell applications as a user other than the one started the daemons,"Using the tarball, if you start the yarn daemons using one user and then switch to a different user. You can successfully run MR jobs, but DS jobs fail to run. Only able to run DS jobs using the user who started the daemons."
MAPREDUCE-4303,Look at using String.intern to dedupe some Strings,"MAPREDUCE-4301 fixes one issue with too many duplicate strings, but there are other places where it is not as simple to remove the duplicates.  In these cases the source of the strings is an incoming RPC call or from parsing and reading in a file.  The only real way to dedupe these is to either use String.intern() which if not used properly could result in the permgen space being filled up, or by playing games with our own cache, and trying to do the same sort of thing as String.intern, but in the heap.

The following are some that I saw lots of duplicate strings that we should look at doing something about.

TaskAttemptStatusUpdateEvent$TaskAttemptState.stateString
MapTaskAttemptImpl.diagnostics
The keys to Counters.groups
GenericGroup.displayName
The keys to GenericGroup.counters
and GenericCounter.displayName"
MAPREDUCE-4302,NM goes down if error encountered during log aggregation,"When a container launch request is sent to the NM, if _any_ exception occurs during the init of log aggregation then the NM goes down.  The problem can be induced by situations including, but certainly not limited to: transient rpc connection issues, missing tokens, expired tokens, permissions, full/quota exceeded dfs, etc.  The problem may occur with and without security enabled.

The ramification is an entire cluster can be rather easily brought down either maliciously, accidentally, or via a submission bug."
MAPREDUCE-4301,Dedupe some strings in MRAM for memory savings,"Recently an OutOfMemoryError caused one of our jobs to become a zombie (MAPREDUCE-4300).  It was a rather large job with 78000+ map tasks and only 750MB of heap configured.  I took a heap dump to see if there were any obvious memory leaks, and I could not find any, but yourkit and some digging found some potential memory optimizations that we could do.

In this particular case we could save about 20MB if SplitMetaInfoReader.readSplitMetaInfo only computed the JobSplitFile once instead of for each split. (a 2 line change)

I will look into some others and see if there are more savings I can come up with."
MAPREDUCE-4300,OOM in AM can turn it into a zombie.,"It looks like 4 threads in the AM died with OOM but not the one pinging the RM.

stderr for this AM
{noformat}
WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
May 30, 2012 4:49:55 AM com.google.inject.servlet.InternalServletModule$BackwardsCompatibleServletContextProvider get
WARNING: You are attempting to use a deprecated API (specifically, attempting to @Inject ServletContext inside an eagerly created singleton. While we allow this for backwards compatibility, be warned that this MAY have unexpected behavior if you have more than one injector (with ServletModule) running in the same JVM. Please consult the Guice documentation at http://code.google.com/p/google-guice/wiki/Servlets for more information.
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver as a provider class
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.yarn.webapp.GenericExceptionHandler as a provider class
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory register
INFO: Registering org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices as a root resource class
May 30, 2012 4:49:55 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.8 06/24/2011 12:17 PM'
May 30, 2012 4:49:55 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.JAXBContextResolver to GuiceManagedComponentProvider with the scope ""Singleton""
May 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.yarn.webapp.GenericExceptionHandler to GuiceManagedComponentProvider with the scope ""Singleton""
May 30, 2012 4:49:56 AM com.sun.jersey.guice.spi.container.GuiceComponentProviderFactory getComponentProvider
INFO: Binding org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices to GuiceManagedComponentProvider with the scope ""PerRequest""
Exception in thread ""ResponseProcessor for block BP-1114822160-<IP>-1322528669066:blk_-6528896407411719649_34227308"" java.lang.OutOfMemoryError: Java heap space
	at com.google.protobuf.CodedInputStream.(CodedInputStream.java:538)
	at com.google.protobuf.CodedInputStream.newInstance(CodedInputStream.java:55)
	at com.google.protobuf.AbstractMessageLite$Builder.mergeFrom(AbstractMessageLite.java:201)
	at com.google.protobuf.AbstractMessage$Builder.mergeFrom(AbstractMessage.java:738)
	at org.apache.hadoop.hdfs.protocol.proto.DataTransferProtos$PipelineAckProto.parseFrom(DataTransferProtos.java:7287)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:95)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:656)
Exception in thread ""DefaultSpeculator background processing"" java.lang.OutOfMemoryError: Java heap space
	at java.util.HashMap.resize(HashMap.java:462)
	at java.util.HashMap.addEntry(HashMap.java:755)
	at java.util.HashMap.put(HashMap.java:385)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTasks(JobImpl.java:632)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleASpeculation(DefaultSpeculator.java:465)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.maybeScheduleAMapSpeculation(DefaultSpeculator.java:433)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.computeSpeculations(DefaultSpeculator.java:509)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.access$100(DefaultSpeculator.java:56)
	at org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator$1.run(DefaultSpeculator.java:176)
	at java.lang.Thread.run(Thread.java:619)
Exception in thread ""Timer for 'MRAppMaster' metrics system"" java.lang.OutOfMemoryError: Java heap space
Exception in thread ""Socket Reader #4 for port 50500"" java.lang.OutOfMemoryError: Java heap space
{noformat}"
MAPREDUCE-4299,Terasort hangs with MR2 FifoScheduler,"What happens is that the number of reducers ramp up until they occupy all of the job's containers, at which point the maps no longer make any progress and the job hangs.

When the same job is run with the CapacityScheduler it succeeds, so this looks like a FifoScheduler bug."
MAPREDUCE-4298,NodeManager crashed after running out of file descriptors,A node on one of our clusters fell over because it ran out of open file descriptors.  Log details with stack traceback to follow.
MAPREDUCE-4297,Usersmap file in gridmix should not fail on empty lines,An empty line (e.g. at the end of the file) in the usersmap file will cause gridmix to fail. Empty lines should be silently ignored.
MAPREDUCE-4295,RM crashes due to DNS issue,"we had a DNS outage and the RM crashed with the following backtrace:

2012-05-29 19:17:34,492 FATAL
org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in
handling event type NODE_UPDATE to the scheduler
java.lang.IllegalArgumentException: java.net.UnknownHostException:
host.com        at
org.apache.hadoop.security.SecurityUtil.buildTokenService(SecurityUtil.java:430)
        at
org.apache.hadoop.yarn.util.BuilderUtils.newContainerToken(BuilderUtils.java:261)
       at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.createContainer(LeafQueue.java:1184)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer(LeafQueue.java:1167)
        at
org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1213)"
MAPREDUCE-4294,Submitting job by enabling task profiling gives IOException,"{noformat}
java.io.IOException: Server returned HTTP response code: 400 for URL: http://HOST-10-18-52-224:8080/tasklog?plaintext=true&attemptid=attempt_1338370885386_0006_m_000000_0&filter=profile
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1290)
        at org.apache.hadoop.mapreduce.Job.downloadProfile(Job.java:1421)
        at org.apache.hadoop.mapreduce.Job.printTaskEvents(Job.java:1376)
        at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1310)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1247)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:200)
{noformat}"
MAPREDUCE-4292,Job is hanging forever when some maps are failing always,"Set property ""mapred.reduce.tasks"" to some value greater than zero

I have a job in which some maps are failing always. 
Observations:
1.Map phase is completing with 100%(with succeeded and failed maps). 
2.Reduce phase is not progressing further after 32%.
3.After map phase is completed job is hanging forever.

Expected that job should be failed after waiting for some time.
"
MAPREDUCE-4290,JobStatus.getState() API is giving ambiguous values,For failed job getState() API is giving status as SUCCEEDED if we use JobClient.getAllJobs() for retrieving all jobs info from RM.
MAPREDUCE-4286,TestClientProtocolProviderImpls passes on failure conditions,
MAPREDUCE-4283,Display tail of aggregated logs by default,"Similar to the manner in which the nodemanager webUI displays container logs, it would be very useful if the historyserver showed the trailing 4K or so of the aggregated logs with a link to see the full log.

When debugging issues the relevant errors are usually at the end of the log, so showing just the last few K can enable quick diagnosis without waiting for what can be many megabytes of log data to download. "
MAPREDUCE-4282,Convert Forrest docs to APT,"MR side of HADOOP-8427. Not all of the old forrest docs in src/documentation/content/xdocs have been converted over to APT yet, let's do that and remove the forrest docs.

 "
MAPREDUCE-4279,getClusterStatus() fails with null pointer exception when running jobs in local mode,"While migrating code from 0.20.2 hadoop codebase to 0.23.1 we encountered this issue for jobs run in local mode of execution:
{code}

java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobClient.arrayToStringList(JobClient.java:783)
	at org.apache.hadoop.mapred.JobClient.access$600(JobClient.java:138)
	at org.apache.hadoop.mapred.JobClient$4.run(JobClient.java:815)
	at org.apache.hadoop.mapred.JobClient$4.run(JobClient.java:812)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.mapred.JobClient.getClusterStatus(JobClient.java:812)
{code}

We are using cloudera distribution CDH4b2 for testing, however the underlying code is 0.23.1 and I could see no difference in this implementation."
MAPREDUCE-4278,cannot run two local jobs in parallel from the same gateway.,"I cannot run two local mode jobs from Pig in parallel from the same gateway, this is a typical use case. If I re-run the tests sequentially, then the test pass. This seems to be a problem from Hadoop.

Additionally, the pig harness, expects to be able to run Pig-version-undertest against Pig-version-stable from the same gateway.


To replicate the error:

I have two clusters running from the same gateway.
If I run the Pig regression suites nightly.conf in local mode in paralell - once on each cluster. Conflicts in M/R local mode result in failures in the tests. 


ERROR1:

org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find
output/file.out in any of the configured local directories
        at
org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:429)
        at
org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:160)
        at
org.apache.hadoop.mapred.MapOutputFile.getOutputFile(MapOutputFile.java:56)
        at org.apache.hadoop.mapred.Task.calculateOutputSize(Task.java:944)
        at org.apache.hadoop.mapred.Task.sendLastUpdate(Task.java:924)
        at org.apache.hadoop.mapred.Task.done(Task.java:875)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:374)
---

ERROR2:

2012-05-17 20:25:36,762 [main] INFO
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher
-
HadoopJobId: job_local_0001
2012-05-17 20:25:36,778 [Thread-3] INFO  org.apache.hadoop.mapred.Task -
Using ResourceCalculatorPlugin : org.apache.
hadoop.util.LinuxResourceCalculatorPlugin@ffa490e
2012-05-17 20:25:36,837 [Thread-3] WARN
org.apache.hadoop.mapred.LocalJobRunner - job_local_0001
java.lang.IndexOutOfBoundsException: Index: 1, Size: 1
        at java.util.ArrayList.RangeCheck(ArrayList.java:547)
        at java.util.ArrayList.get(ArrayList.java:322)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getLoadFunc(PigInputFormat.java
:153)
        at
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.createRecordReader(PigInputForm
at.java:106)
        at
org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.<init>(MapTask.java:489)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:731)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:370)
        at
org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:212)
2012-05-17 20:25:41,291 [main] INFO
org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher
"
MAPREDUCE-4276,"Allow setting yarn.nodemanager.delete.debug-delay-sec property to ""-1"" for easier container debugging.","Allow setting yarn.nodemanager.delete.debug-delay-sec property to ""-1"" to have it never clear (like older TT time)."
MAPREDUCE-4274,MapOutputBuffer should use native byte order for kvmeta,"I don't have a benchmark to support this, but this should give a small CPU improvement on the map output buffer: currently, we create {{kvmeta}} as {{ByteBuffer.wrap(kvbuffer).asIntBuffer()}}. According to the javadocs, the resulting int buffer will inherit its byte order from the ByteBuffer it comes from, and the byte buffer defaults to BIG_ENDIAN. Thus, all of our int access to/from the buffer will require byte-swapping."
MAPREDUCE-4272,SortedRanges.Range#compareTo is not spec compliant,"SortedRanges.Range#compareTo does not satisfy the requirement of Comparable#compareTo, where ""the implementor must ensure {noformat}sgn(x.compareTo(y)) == -sgn(y.compareTo(x)){noformat} for all x and y.""

This is manifested as TestStreamingBadRecords failures in alternative JDKs."
MAPREDUCE-4270,data_join test classes are in the wrong packge,"There are three Sample*.java files in this directory

http://svn.apache.org/repos/asf/hadoop/common/trunk/hadoop-tools/hadoop-datajoin/src/test/java/

but they should be in 

http://svn.apache.org/repos/asf/hadoop/common/trunk/hadoop-tools/hadoop-datajoin/src/test/java/org/apache/hadoop/contrib/utils/join/

based on their package."
MAPREDUCE-4269,documentation: Gridmix has javadoc warnings in StressJobFactory,
MAPREDUCE-4267,mavenize pipes,We are still building pipes out of the old mrv1 directories using ant.  Move it over to the mrv2 dir structure.  
MAPREDUCE-4266,remove Ant remnants from MR,"Remove:

hadoop-mapreduce-project/src/*
hadoop-mapreduce-project/ivy/*
hadoop-mapreduce-project/build.xml
hadoop-mapreduce-project/ivy.xml
"
MAPREDUCE-4264,Got ClassCastException when using mapreduce.history.server.delegationtoken.required=true,"Oozie fails to run on branch-0.23 with the following exception. This only affects branch-0.23 not branch-2 or trunk. 


12/05/16 15:08:45 INFO mapreduce.JobSubmitter: Cleaning up the staging area /tmp/hadoop-yarn/staging/tgraves/.staging/job_1337177706246_0001java.lang.ClassCastException: org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker cannot be cast to org.apache.hadoop.ipc.RpcInvocationHandler        at org.apache.hadoop.ipc.RPC.getConnectionIdForProxy(RPC.java:330)        at org.apache.hadoop.ipc.RPC.getServerAddress(RPC.java:320)        at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getConnectAddress(MRClientProtocolPBClientImpl.java:108)        at org.apache.hadoop.mapred.YARNRunner.getDelegationTokenFromHS(YARNRunner.java:195)        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:272)        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:385)        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1226)        at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1223)        at java.security.AccessController.doPrivileged(Native Method)        at javax.security.auth.Subject.doAs(Subject.java:396)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)


Note that this is caused because oozie passes in the options:  -Dmapreduce.history.server.delegationtoken.required=true -Dmapreduce.history.server.delegationtoken.renewer=""mr token"""
MAPREDUCE-4263,Use taskkill /T to terminate tasks on Windows,On Linux setsid is used to link the processes spawned by the tasks into the same session. So termination of the task terminates the entire tree. We need to do the same for Windows. This is not fool proof but should be sufficient until we have a potentially better solution in MAPREDUCE-4260.
MAPREDUCE-4262,"NM gives wrong log message saying ""Connected to ResourceManager"" before trying to connect","{code:xml}
2012-05-16 18:04:25,844 INFO org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl: Connected to ResourceManager at /xx.xx.xx.xx:8025
2012-05-16 18:04:26,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-xx-xx-xx-xx/xx.xx.xx.xx:8025. Already tried 0 time(s).
2012-05-16 18:04:27,870 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-xx-xx-xx-xx/xx.xx.xx.xx:8025. Already tried 1 time(s).
2012-05-16 18:04:28,871 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-xx-xx-xx-xx/xx.xx.xx.xx:8025. Already tried 2 time(s).
2012-05-16 18:04:29,872 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-xx-xx-xx-xx/xx.xx.xx.xx:8025. Already tried 3 time(s).
2012-05-16 18:04:30,873 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: host-xx-xx-xx-xx/xx.xx.xx.xx:8025. Already tried 4 time(s).
{code}"
MAPREDUCE-4260,Use JobObject to spawn tasks on Windows,"Currently, the Windows version spawns the task as a normal cmd shell from which other downstream exe's are spawned. However, this is not bullet proof because if an intermediate process exits before its child exits, then the parent child process tree relationship cannot be constructed. Windows has a concept of JobObject that is similar to the setsid behavior used in Linux. The initial spawned task could be launched within its JobObject. Thereafter, process termination, memory management etc could be operated on the JobObject."
MAPREDUCE-4257,Support fair-sharing option within a MR2 Capacity Scheduler queue,"The fair scheduler can run jobs in a single pool (queue) in FIFO or fair share mode. In FIFO mode one job runs at a time, in priority order, while in fair share mode multiple jobs can run at the same time, and they share the capacity of the pool. This JIRA is to add the latter feature to Capacity Scheduler as an option - the default would remain FIFO.

"
MAPREDUCE-4256,Improve resource scheduling,"Currently resource manager supports only Memory resource during container allocation.

I propose following improvements:

1. add support for CPU utilization. Node CPU used information can be obtained by ResourceCalculatorPlugin.

2. add support for custom resources. In node configuration will be something like:

name=node.resource.GPU, value=1 (node has 1 GPU).

If job will need to use GPU for computation, it will add ""GPU=1"" requirement to its job config and Resource Manager will allocate container on node with GPU available.
"
MAPREDUCE-4255,Job History Server throws NPE if it fails to get keytab,"{code:xml}
2012-05-14 17:59:41,906 FATAL org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: Error starting JobHistoryServer
org.apache.hadoop.yarn.YarnException: History Server Failed to login
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.init(JobHistoryServer.java:69)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:132)
Caused by: java.io.IOException: Running in secure mode, but config doesn't have a keytab
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:258)
	at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:229)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.doSecureLogin(JobHistoryServer.java:98)
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.init(JobHistoryServer.java:67)
	... 1 more
2012-05-14 17:59:41,918 INFO org.apache.hadoop.yarn.service.CompositeService: Error stopping org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.stop(JobHistoryServer.java:115)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:122)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
2012-05-14 17:59:41,918 INFO org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer: SHUTDOWN_MSG: 
{code}"
MAPREDUCE-4252,MR2 job never completes with 1 pending task,"This was found by ATM:

bq. I ran a teragen with 1000 map tasks. Many task attempts failed, but after 999 of the tasks had completed, the job is now sitting forever with 1 task ""pending""."
MAPREDUCE-4251,API Incompatibility - Sampler," org.apache.hadoop.mapred.lib.InputSampler#Sampler in Hadoop 0.20 has been moved to org.apache.hadoop.mapreduce.lib.partition.InputSampler#Sampler in Hadoop 0.22

The arguments of the getSample method in the Sampler class have also been changed, 0.22 use the new InputFormat, and 0.20 use the deprecated InputFormat, 0.22 use org.apache.hadoop.mapreduce.Job and 0.20use org.apache.hadoop.mapred.JobConf.

So the programs compiled with old api has to be changed. "
MAPREDUCE-4250,"hadoop-config.sh missing variable exports, causes Yarn jobs to fail with ClassNotFoundException MRAppMaster","This is the MR side of HADOOP-8393

If you start a pseudo distributed yarn using ""start-yarn.sh"" you need to specify exports for HADOOP_COMMON_HOME, HADOOP_HDFS_HOME, YARN_HOME, YARN_CONF_DIR, and HADOOP_MAPRED_HOME in hadoop-env.sh (or elsewhere), otherwise the spawned node manager will be missing 
these in it's environment. This is due to start-yarn using yarn-daemons. With this fix it's possible to start yarn (etc...) with only HADOOP_CONF_DIR specified in the environment. Took some time to track down this failure, so seems worthwhile to fix."
MAPREDUCE-4249,Fix failures in streaming test TestFileArgs,"The streaming (contrib module) testcase - TestFileArgs fails with the following error

<testcase classname=""org.apache.hadoop.streaming.TestFileArgs"" name=""testCommandLine"" time=""28.0"">
<failure message=""expected:<job.jar 
[]sidefile 
tmp 
> but was:<job.jar 
[org 
]sidefile 
tmp "
MAPREDUCE-4248,TestRecoveryManager fails,"Error Message shown from jenkins

Timeout occurred. Please note the time in the report does not reflect the time until the timeout.
Stacktrace

junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout."
MAPREDUCE-4247,TestTaskTrackerLocalization fails ,"There are 11 failures on TestTaskTrackerLocalization .

org.apache.hadoop.mapred.TestTaskTrackerLocalization.testUserLocalization
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobLocalization
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobLocalizationFailsIfLogDirUnwritable
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskLocalization
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskFilesRemoval
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testFailedTaskFilesRemoval
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTaskFilesRemovalWithJvmUse
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobFilesRemoval
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTrackerRestart
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testTrackerReinit
org.apache.hadoop.mapred.TestTaskTrackerLocalization.testCleanupTaskLocalization"
MAPREDUCE-4246,Failure in deleting user directories in Secure hadoop,"This happens when security is enabled on 22

When TaskTracker starts p, it invokes MRAsyncDiskService moves the contents of scratch/tasktracker to toBeDeleted under a directory created with the current timestamp.
The owner of this directory is hadoop (owner of tasktracker)

The contents of this directory are various usernames and they are owned by individual users. But MRAsyncDiskService tries to delete the newly created directory as hadoop and it fails.

2012-05-01 16:04:58,805 DEBUG org.apache.hadoop.mapred.LinuxTaskController: deleteAsUser: [/apache/hadoop-assemble-argon-0.228/hadoop-0.22-argon-0.105/bin/../bin/task-controller, hadoop, 3, /hadoop00/scratch/toBeDeleted/2012-04-17_16-22-03.965_0]
2012-05-01 16:04:58,809 WARN org.apache.hadoop.mapreduce.util.MRAsyncDiskService: Failure in deletion of toBeDeleted/2012-04-17_16-22-03.965_0 on /hadoop00/scratch with original name /hadoop00/scratch/toBeDeleted/2012-04-17_16-22-03.965_0 with exception org.apache.hadoop.util.Shell$ExitCodeException:
at org.apache.hadoop.util.Shell.runCommand(Shell.java:256)
at org.apache.hadoop.util.Shell.run(Shell.java:183)
at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:376)
at org.apache.hadoop.mapred.LinuxTaskController.deleteAsUser(LinuxTaskController.java:273)
at org.apache.hadoop.mapreduce.util.MRAsyncDiskService$DeleteTask.run(MRAsyncDiskService.java:237)
at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:662)"
MAPREDUCE-4244,Fix an issue related to do with setting of correct groups for tasks,There was a recent fix related supplemental groups.
MAPREDUCE-4243,Modify mapreduce build to include task-controller,"Secure hadoop requires task-controller.
Task-controller has to be built as part of mapreduce build."
MAPREDUCE-4242,port gridmix tests to yarn,"jira MAPREDUCE-3543 is mavenizing gridmix, however some of the tests were not pulled over since they need to be ported to Yarn.

This jira is to port the remaining tests.  The ones under  contrib/gridmix/src/test/system should be looked at and then there is TestSleepJob, TestGridmixSubmission, and TestDistCacheEmulation."
MAPREDUCE-4241,Pipes examples do not compile on Ubuntu 12.04,-lssl alone won't work for compiling the pipes examples on 12.04. -lcrypto needs to be added explicitly.
MAPREDUCE-4240,Revert MAPREDUCE-2767 ,"MAPREDUCE-2767 removed LinuxTaskController. 
This task is revert that so LinuxtaskController is introduced back."
MAPREDUCE-4239,gridmix has 11 findbugs warnings,"jira MAPREDUCE-3543 is mavenizing gridmix.  I found that gridmix has 11 findbugs warnings while doing that jira that should be fixed or have excludes added for them.


Code	Warning
Se	org.apache.hadoop.mapred.gridmix.GridmixRecord$Comparator implements Comparator but not Serializable
Malicious code vulnerability Warnings

Code	Warning
EI	org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit.getLocations() may expose internal representation by returning SleepJob$SleepSplit.locations
EI2	new org.apache.hadoop.mapred.gridmix.SleepJob(Configuration, long, JobStory, Path, UserGroupInformation, int, int, String[]) may expose internal representation by storing an externally mutable object into SleepJob.hosts
EI2	new org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit(int, long, long[], int, String[]) may expose internal representation by storing an externally mutable object into SleepJob$SleepSplit.locations
EI2	new org.apache.hadoop.mapred.gridmix.SleepJob$SleepSplit(int, long, long[], int, String[]) may expose internal representation by storing an externally mutable object into SleepJob$SleepSplit.reduceDurations
MS	org.apache.hadoop.mapred.gridmix.emulators.resourceusage.TotalHeapUsageEmulatorPlugin.ONE_MB isn't final but should be
MS	org.apache.hadoop.mapred.gridmix.emulators.resourceusage.TotalHeapUsageEmulatorPlugin$DefaultHeapUsageEmulator.heapSpace isn't final but should be
Multithreaded correctness Warnings

Code	Warning
JLM	Synchronization performed on java.util.concurrent.LinkedBlockingQueue in org.apache.hadoop.mapred.gridmix.JobMonitor.add(Statistics$JobStats)
JLM	Synchronization performed on java.util.concurrent.BlockingQueue in org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.run()
JLM	Synchronization performed on java.util.concurrent.BlockingQueue in org.apache.hadoop.mapred.gridmix.JobMonitor$MonitorThread.run()
Dodgy Warnings

Code	Warning
REC	Exception is caught when Exception is not thrown in org.apache.hadoop.mapred.gridmix.ExecutionSummarizer.processJobState(Statistics$JobStats)"
MAPREDUCE-4238,mavenize data_join,mavenize the contrib data_join package
MAPREDUCE-4237,TestNodeStatusUpdater can fail if localhost has a domain associated with it,"On some systems, RHEL where I work, localhost can resolve to localhost.localdomain.  TestNodeStatusUpdater can fail because the nodeid containes .localdomain which is not expected by the hard coded localhost string."
MAPREDUCE-4236,Failing tests in branch-2,"Running org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 7.872 sec <<< FAILURE!
--
Running org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEvents
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 3.862 sec <<< FAILURE!
--
Running org.apache.hadoop.conf.TestNoDefaultsJobConf
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 10.865 sec <<< FAILURE!
--
Running org.apache.hadoop.mapreduce.security.TestJHSSecurity
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 1.372 sec <<< FAILURE!"
MAPREDUCE-4235,Killing app can lead to inconsistent app status between RM and HS,"If a client tries to kill an application that is about to complete, the application states between the ResourceManager's web UI and the history server can be inconsistent.  When the problem occurs, the ResourceManager shows the Status/FinalStatus as KILLED/KILLED and the history link will redirect to a broken link.  The history link still references the ApplicationMaster which is now missing.  The history server entry will show the application state as SUCCEEDED.

"
MAPREDUCE-4234,SortValidator.java is incompatible with multi-user or parallel use (due to a /tmp file with static name),The SortValidator.java file checkRecords method creates a file in the /tmp/sortvalidator directory using a static filename. This can result in failures due to name collisions when the hadoop-mapreduce-client-jobclient-*-tests jar is used by more than one task or one user simultaneously. We use this jar when testing compression codecs and after we started running tests in parallel (four at a time to reduce overall test time) we started experiencing random test failures due to name collisions. Creating a random or unique per thread filename may resolve this issue. We have developed a change to introduce per use unique file names. 
MAPREDUCE-4233,NPE can happen in RMNMNodeInfo.,"{noformat}
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.getLiveNodeManagers(RMNMInfo.java:96)
        at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:93)
        at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:27)
        at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:208)
        at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:65)
        at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:216)
        at javax.management.StandardMBean.getAttribute(StandardMBean.java:358)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:666)
{noformat}

Looks like rmcontext.getRMNodes() is not kept in sync with scheduler.getNodeReport(), so that the report can be null even though the context still knowns about the node.

The simple fix is to add in a null check."
MAPREDUCE-4231,Update RAID to not to use FSInodeInfo,FSInodeInfo was removed by HDFS-3363.  We should update RAID.
MAPREDUCE-4229,Counter names' memory usage can be decreased by interning,"In our experience, most of the memory in production JTs goes to storing counter names (String objects and character arrays). Since most counter names are reused again and again, it would be a big memory savings to keep a hash set of already-used counter names within a job, and refer to the same object from all tasks."
MAPREDUCE-4228,mapreduce.job.reduce.slowstart.completedmaps is not working properly to delay the scheduling of the reduce tasks,"If no more map tasks need to be scheduled but not all have completed, the ApplicationMaster will start scheduling reducers even if the number of completed maps has not met the mapreduce.job.reduce.slowstart.completedmaps threshold.  For example, if the property is set to 1.0 all maps should complete before any reducers are scheduled.  However the reducers are scheduled as soon as the last map task is assigned to a container.  For a job with very long-running maps, a cluster with enough capacity to launch all map tasks could cause reducers to launch prematurely and waste cluster resources.

Thanks to Phil Su for discovering this issue."
MAPREDUCE-4227,TimeWindow statistics are not updated for TaskTrackers which have been restarted.,"Whenever a TaskTracker is restarted after the JobTracker has been running for a while (an hour / day maybe), the TimeWindow statistics on the JobTracker Active nodes page are stuck at 0."
MAPREDUCE-4226,ConcurrentModificationException in FileSystemCounterGroup,This was seen in a Hive job. I'll attach a failing test case.
MAPREDUCE-4225,RM/AM scheduling debug statement not adequate on #asks,"The debug statements in the AM and RM about the scheduling ask information is not adequate.  There are many places it prints out #asks, but that just always says 1.  We need to display the # containers in that ask and possibly other info to make it useful.  It would be useful to see this on both the AM side and the RM side. The RM side should be showing the total #'s it stored for that application."
MAPREDUCE-4224,TestFifoScheduler throws org.apache.hadoop.metrics2.MetricsException ,"{code:xml}
2012-05-04 15:18:47,180 WARN  [main] util.MBeans (MBeans.java:getMBeanName(95)) - Error creating MBean object name: Hadoop:service=ResourceManager,name=RMNMInfo
org.apache.hadoop.metrics2.MetricsException: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=RMNMInfo already exists!
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:117)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newMBeanName(DefaultMetricsSystem.java:102)
	at org.apache.hadoop.metrics2.util.MBeans.getMBeanName(MBeans.java:93)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:55)
	at org.apache.hadoop.yarn.server.resourcemanager.RMNMInfo.<init>(RMNMInfo.java:59)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.init(ResourceManager.java:225)
	at org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.TestFifoScheduler.setUp(TestFifoScheduler.java:62)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:46)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
Caused by: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=RMNMInfo already exists!
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:113)
	... 30 more
{code}"
MAPREDUCE-4220,RM apps page starttime/endtime sorts are incorrect,Sorting by start time and end time sort lexically instead of temporally.
MAPREDUCE-4219,make default container-executor.conf.dir be a path relative to the container-executor binary,"Currently, container-executor binary has an absolute pathname of its configuration file baked in. This prevents an easy relocation of the configuration files when dealing with multiple Hadoop installs on the same node. It would be nice to at least allow for a relative path resolution starting from the location of the container-executor binary itself. Something like
{noformat}
../etc/hadoop/
{noformat}

Thoughts?"
MAPREDUCE-4217,Task commit waits for up to 3 seconds,"Following MAPREDUCE-2450, TaskReporter#stopCommunicationThread may wait up to 3 seconds (the value of PROGRESS_INTERVAL) before it returns. This can be noticeable for short running tasks."
MAPREDUCE-4215,RM app page shows 500 error on appid parse error,"For example, cluster/app/application_1335823499485_000a has displays this error"
MAPREDUCE-4212,TestJobClientGetJob sometimes fails,{{TestJobClientGetJob}} sometimes fails because it doesn't delete the job's output dir prior to submission.
MAPREDUCE-4211,"Error conditions (missing appid, appid not found) are masked in the RM app page",
MAPREDUCE-4210,Expose listener address for WebApp,It should be possible to get the listener address from a {{WebApp}} instance.  This will greatly simplify some of the yarn host/port manipulation.
MAPREDUCE-4209,junit dependency in hadoop-mapreduce-client is missing scope test,pom.xml in hadoop-mapreduce-client has declared junit as compile time dependency while it must be test scope dependency.
MAPREDUCE-4208,The job is hanging up but never continuing until you kill the child process ,"I use the hive MR query on hbase,but the job is never end.
The job is hanging but never continuing util you kill the child process 


2012-04-28 18:22:33,661 Stage-1 map = 0%,  reduce = 0%
2012-04-28 18:22:59,760 Stage-1 map = 25%,  reduce = 0%
2012-04-28 18:23:04,782 Stage-1 map = 38%,  reduce = 0%
2012-04-28 18:23:07,796 Stage-1 map = 50%,  reduce = 0%
2012-04-28 18:23:08,801 Stage-1 map = 50%,  reduce = 8%
2012-04-28 18:23:17,839 Stage-1 map = 50%,  reduce = 17%
2012-04-28 18:23:19,848 Stage-1 map = 63%,  reduce = 17%
2012-04-28 18:23:32,909 Stage-1 map = 63%,  reduce = 21%
2012-04-28 18:23:57,017 Stage-1 map = 75%,  reduce = 21%
2012-04-28 18:24:09,075 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:25:09,397 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:26:09,688 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:27:09,980 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:28:10,262 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:29:10,522 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:30:10,742 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:31:10,985 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:32:11,238 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:33:11,467 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:34:11,731 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:35:11,968 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:36:12,213 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:37:12,508 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:38:12,747 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:39:12,970 Stage-1 map = 75%,  reduce = 25%
2012-04-28 18:40:13,205 Stage-1 map = 75%,  reduce = 25%

I checked the TT log,

2012-04-28 18:31:53,879 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:31:56,883 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:31:59,887 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:02,892 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:05,897 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:08,902 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:11,906 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:14,910 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:17,915 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:20,920 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:23,924 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:26,929 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:29,934 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:32,938 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:35,943 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:38,948 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:41,953 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:44,957 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:47,961 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:50,966 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:53,970 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:56,974 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:32:59,979 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:02,983 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:05,987 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:08,992 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:11,997 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:15,001 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:18,006 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:21,011 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:24,015 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:27,020 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:30,025 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:33,029 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:36,034 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:39,038 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:42,043 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:45,047 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:48,051 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:51,057 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%
2012-04-28 18:33:54,062 INFO org.apache.hadoop.mapred.TaskTracker: attempt_201204281725_0002_m_000002_0 0.0%




[hadoop@mem1 logs]$ jps
3282 Child
31547 QuorumPeerMain
1840 TaskTracker
3469 Jps
31070 HRegionServer
30120 DataNode


[hadoop@mem1 logs]$  kill 3282

When I kill the child process , then the job continue and complete.

2012-04-28 18:40:51,324 Stage-1 map = 88%,  reduce = 25%
2012-04-28 18:41:04,364 Stage-1 map = 88%,  reduce = 29%
2012-04-28 18:41:31,448 Stage-1 map = 100%,  reduce = 29%
2012-04-28 18:41:43,485 Stage-1 map = 100%,  reduce = 100%"
MAPREDUCE-4207,Remove System.out.println() in FileInputFormat,MAPREDUCE-3607 accidentally left the println statement. 
MAPREDUCE-4206,Sorting by Last Health-Update on the RM nodes page sorts does not work correctly,column is mistakenly sorted lexically
MAPREDUCE-4205,retrofit all JVM shutdown hooks to use ShutdownHookManager,"to avoid JVM shutdownhook race conditions, all shutdown hooks should be retrofitted to use ShutdownHookManager (HADOOP-8325)"
MAPREDUCE-4204,Refactor ProcfsBasedProcessTree to make the resource collection object pluggable,Making it a pluggable interface will allow replacing the procfs based implementation with ones for other platforms.
MAPREDUCE-4203,Create equivalent of ProcfsBasedProcessTree for Windows,"ProcfsBasedProcessTree is used by the TaskTracker to get process information like memory and cpu usage. This information is used to manage resources etc. The current implementation is based on Linux procfs functionality and hence does not work on other platforms, specifically windows."
MAPREDUCE-4202,TestYarnClientProtocolProvider is broken,The test fails because a cluster is unexpectedly created with an empty conf.
MAPREDUCE-4201,Getting PID not working on Windows. Termination of Task/TaskJVM's not working,"Child Task not reporting PID because of Linux specific shell script implementation.
Signaling task termination currently disabled by the initial Windows patch."
MAPREDUCE-4200,packaging tar ball of trunk failed,"A command ""mvn clean package -Dtar -DskipTests"" executed on the root directory ""hadoop-common"" failed.
Its output logs are in an attached file.

A command ""mvn clean package -Pdist -DskipTests"" succeeded.
"
MAPREDUCE-4198,Update RackResolver and related tests to resolve host with new API from HADOOP-8304 (DNSToSwitchMapping should add interface to resolve individual host besides a list of host),HADOOP-8304  (DNSToSwitchMapping should add interface to resolve individual host besides a list of host) will induce a new API to resolve individual host rather than a list of host. Here is update on MapReduce part to use new API.
MAPREDUCE-4197,Include the hsqldb jar in the hadoop-mapreduce tar file,"Courtesy Brahma

{quote}
In the previuos hadoop releases(20.XX) hsqldb was provided.
But in hadoop-2.0.0 it is not present.Is it intentionally deleted or missing?
{quote}

"
MAPREDUCE-4195,"With invalid queueName request param, jobqueue_details.jsp shows NPE","When you access /jobqueue_details.jsp manually, instead of via a link, it has queueName set to null internally and this goes for a lookup into the scheduling info maps as well.

As a result, if using FairScheduler, a Pool with String name = null gets created and this brings the scheduler down. I have not tested what happens to the CapacityScheduler, but ideally if no queueName is set in that jsp, it should fall back to 'default'. Otherwise, this brings down the JobTracker completely.

FairScheduler must also add a check to not create a pool with 'null' name.

The following is the strace that ensues:

{code}
ERROR org.mortbay.log: /jobqueue_details.jsp 
java.lang.NullPointerException 
at org.apache.hadoop.mapred.jobqueue_005fdetails_jsp._jspService(jobqueue_005fdetails_jsp.java:71) 
at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97) 
at javax.servlet.http.HttpServlet.service(HttpServlet.java:820) 
at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511) 
at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221) 
at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:829) 
at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) 
at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) 
at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) 
at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) 
at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) 
at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) 
at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) 
at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) 
at org.mortbay.jetty.Server.handle(Server.java:326) 
at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) 
at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) 
at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) 
at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) 
at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) 
at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) 
at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) 
INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001, call heartbeat from XYZ:MNOP: error: java.io.IOException: java.lang.NullPointerException 
java.io.IOException: java.lang.NullPointerException 
at org.apache.hadoop.mapred.SchedulingAlgorithms$FairShareComparator.compare(SchedulingAlgorithms.java:95) 
at org.apache.hadoop.mapred.SchedulingAlgorithms$FairShareComparator.compare(SchedulingAlgorithms.java:68) 
at java.util.Arrays.mergeSort(Unknown Source) 
at java.util.Arrays.sort(Unknown Source) 
at java.util.Collections.sort(Unknown Source) 
at org.apache.hadoop.mapred.FairScheduler.assignTasks(FairScheduler.java:435) 
at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3226) 
at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) 
at java.lang.reflect.Method.invoke(Unknown Source) 
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Unknown Source) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127) 
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)
{code}"
MAPREDUCE-4194,ConcurrentModificationError in DirectoryCollection,"As found as part of work on MAPREDUCE-4169, it is possible for a ConcurrentModificationException to be thrown upon disk failure. DirectoryCollection hands out its internal list structure that is accessed across multiple threads. Upon disk failure its internal list is modified, invalidating all current iterators to that structure."
MAPREDUCE-4193,broken doc link for yarn-default.xml in site.xml,"the link to yarn-default.xml in site.xml is incorrect, generated docs link is broken."
MAPREDUCE-4190, Improve web UI for task attempts userlog link,"Users have reported being confused about the user logs link on the MR app master and history server task attempts page.  The logs link shows up in the same column as the node link and the users didn't realize it was a separate link.  

job history web address for this page is like: jobhistoryserver:19888/jobhistory/task/task_1334686840316_0003_m_000000"
MAPREDUCE-4189,TestContainerManagerSecurity is failing,"{code:xml}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.yarn.server.TestDiskFailures
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.519 sec
Running org.apache.hadoop.yarn.server.TestContainerManagerSecurity
Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 10.673 sec <<< FAILURE!

Results :

Tests in error:
  testAuthenticatedUser(org.apache.hadoop.yarn.server.TestContainerManagerSecurity)
  testMaliceUser(org.apache.hadoop.yarn.server.TestContainerManagerSecurity)
  testUnauthorizedUser(org.apache.hadoop.yarn.server.TestContainerManagerSecurity)

Tests run: 5, Failures: 0, Errors: 3, Skipped: 0

{code}"
MAPREDUCE-4188,Clean up yarn-server-web-proxy,"Clean up a bunch of existing javac warnings in hadoop-yarn-server-web-proxy module.
"
MAPREDUCE-4187,Clean up yarn-server-tests,"Clean up a bunch of existing javac warnings in hadoop-yarn-server-tests module.
"
MAPREDUCE-4186,Clean up yarn-server-resourcemanager,Clean up a bunch of existing javac warnings in hadoop-yarn-server-resourcemanager module.
MAPREDUCE-4185,Clean up yarn-server-nodemanager,"Clean up a bunch of existing javac warnings in hadoop-yarn-server-nodemanager module.
"
MAPREDUCE-4184,Clean up yarn-server-common,"Clean up a bunch of existing javac warnings in hadoop-yarn-server-common module.
"
MAPREDUCE-4183,Clean up yarn-common,"Clean up a bunch of existing javac warnings in hadoop-yarn-common module.
"
MAPREDUCE-4182,Remove an used import from TestDistributedShell,"Clean up a bunch of existing javac warnings in hadoop-yarn-applications-distributedshell module.
"
MAPREDUCE-4181,Remove the unused maybeInitBuilder() method from various classes in hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/,"Clean up a bunch of existing javac warnings in hadoop-yarn-api module.
"
MAPREDUCE-4180,Clean up hadoop-streaming,Clean up a bunch of existing javac warnings in hadoop-streaming module.
MAPREDUCE-4179,Clean up hadoop-mapreduce-examples,"Clean up a bunch of existing javac warnings in hadoop-mapreduce-examples module.
"
MAPREDUCE-4178,Clean up hadoop-rumen,"Clean up a bunch of existing javac warnings in hadoop-rumen module.
"
MAPREDUCE-4177,Clean up hadoop-mapreduce-client-jobclient,"Clean up a bunch of existing javac warnings in hadoop-mapreduce-client-jobclient module.
"
MAPREDUCE-4176,Clean up hadoop-mapreduce-client-hs,"Clean up a bunch of existing javac warnings in hadoop-mapreduce-client-hs module.
"
MAPREDUCE-4175,Clean up hadoop-mapreduce-client-core,"Clean up a bunch of existing javac warnings in hadoop-mapreduce-client-core module.
"
MAPREDUCE-4174,Clean up hadoop-mapreduce-client-common,"Clean up a bunch of existing javac warnings in hadoop-mapreduce-client-common module.
"
MAPREDUCE-4173,Clean up hadoop-mapreduce-client-app,Clean up a bunch of existing javac warnings in hadoop-mapreduce-client-app module.
MAPREDUCE-4172,Clean up java warnings in the hadoop-mapreduce-project sub projects,"There are lots of warnings in the hadoop-mapreduce-project presently. We can clear almost all of this away:

* Unused imports
* Unused variables
** For loops that can be replaced with while instead to save an unused variable
* Unused methods
* Deprecation warnings where an alternative can be used (Especially SequenceFile reader/writer usage and MiniDFSCluster usage)
* Deprecation warnings where an alternative isn't clear (Especially MiniMRCluster usage and DistributedCache API usage where a Job object may not be available)
* Unchecked conversions
* Raw type usage
* (etc.)

I'm going to open one sub-task per sub-project we have, with patches attached to them."
MAPREDUCE-4169,Container Logs appear in unsorted order,"container logs (stdout, stderr, syslog) in the nodemanager ui and jobhistory ui appear in unsorted order where the order displayed is based on what file was created first. This jira will have the results be displayed in a consistent order."
MAPREDUCE-4165,Committing is misspelled as commiting in task logs,
MAPREDUCE-4164,Hadoop 22 Exception thrown after task completion causes its reexecution,"2012-02-28 19:17:08,504 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1969310 bytes
2012-02-28 19:17:08,694 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000094_0 is done. And is in the process of commiting
2012-02-28 19:18:08,774 INFO org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Call to /127.0.0.1:35400 failed on local exception: java.nio.channels.ClosedByInterruptException
at org.apache.hadoop.ipc.Client.wrapException(Client.java:1094)
at org.apache.hadoop.ipc.Client.call(Client.java:1062)
at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
at $Proxy0.statusUpdate(Unknown Source)
at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:650)
at java.lang.Thread.run(Thread.java:662)
Caused by: java.nio.channels.ClosedByInterruptException
at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:184)
at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:341)
at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:60)
at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:151)
at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:112)
at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
at java.io.DataOutputStream.flush(DataOutputStream.java:106)
at org.apache.hadoop.ipc.Client$Connection.sendParam(Client.java:769)
at org.apache.hadoop.ipc.Client.call(Client.java:1040)
... 4 more

2012-02-28 19:18:08,825 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000094_0' done.


================>>>>>> SHOULD be <++++++++++++++
2012-02-28 19:17:02,214 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 3 segments left of total size: 1974104 bytes
2012-02-28 19:17:02,408 INFO org.apache.hadoop.mapred.Task: Task:attempt_201202272306_0794_m_000000_0 is done. And is in the process of commiting
2012-02-28 19:17:02,519 INFO org.apache.hadoop.mapred.Task: Task 'attempt_201202272306_0794_m_000000_0' done. "
MAPREDUCE-4163,consistently set the bind address,Use {{NetUtils.getConnectAddress}} for determining the bind address used for setting a token's service.
MAPREDUCE-4162,Correctly set token service,Use {{SecurityUtils.setTokenService}} to set token services.
MAPREDUCE-4161,create sockets consistently,Use getSocketAddr from HADOOP-8286 to ensure sockets are created consistently and compatible for host-based service generation.
MAPREDUCE-4160,some mrv1 ant tests fail with timeout - due to 4156,"Looks like the old mrv1 history server is getting null error when trying to parse the a null for the TaskFinishedEvent successfulAttemptId which was added in jira 4156.  This is causing the ant tests to take like 9 hours to run.


[junit] java.io.IOException: java.lang.NullPointerException: null of string in field successfulAttemptId of org.apache.hadoop.mapreduce.jobhistory.TaskFinished of union in field event of org.apache.hadoop.mapreduce.jobhistory.Event
    [junit] 	at org.apache.avro.generic.GenericDatumWriter.npe(GenericDatumWriter.java:92)
    [junit] 	at org.apache.avro.generic.GenericDatumWriter.write(GenericDatumWriter.java:86)
    [junit] 	at org.apache.avro.generic.GenericDatumWriter.write(GenericDatumWriter.java:57)
    [junit] 	at org.apache.hadoop.mapreduce.jobhistory.EventWriter.write(EventWriter.java:66)
    [junit] 	at org.apache.hadoop.mapreduce.jobhistory.JobHistory$MetaInfo.writeEvent(JobHistory.java:512)
    [junit] 	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.logEvent(JobHistory.java:345)
    [junit] 	at org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2717)
    [junit] 	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1221)
"
MAPREDUCE-4159,"Job is running in Uber mode after setting ""mapreduce.job.ubertask.maxreduces"" to zero","1.Configure ""mapreduce.job.ubertask.enable"" to true
2.Configure ""mapreduce.job.ubertask.maxreduces"" to 0(zero)
3.Run job such that it has one reducer(more than ""mapreduce.job.ubertask.maxreduces"" value) 

Observe that job is running in Uber mode instead of normal mode(non uber mode)"
MAPREDUCE-4157,ResourceManager should not kill apps that are well behaved,"Currently when the ApplicationMaster unregisters with the ResourceManager, the RM kills (via the NMs) all the active containers for an application.  This introduces a race where the AM may be trying to clean up and may not finish before it is killed.  The RM should give the AM a chance to exit cleanly on its own rather than always race with a pending kill on shutdown.
"
MAPREDUCE-4156,ant build fails compiling JobInProgress,"The ant build fails trying to compile jobInProgress.  Looks like TaskFinishedEvent has a new parameter (added in MAPREDUCE-4128) so we probably need to update the old mrv1 source so it atleast compiles.


compile-mapred-classes:
[jsp-compile] 2012-04-13 08:43:33,175 WARN  [main] compiler.TldLocationsCache (TldLocationsCache.java:processWebDotXml(284)) - Internal Error: File /WEB-INF/web.xml not found
    [javac] Compiling 86 source files to /home/y/var/builds/thread2/workspace/Cloud-Hadoop-All-0.23.3-Secondary/hadoop-mapreduce-project/build/classes
    [javac] /home/y/var/builds/thread2/workspace/Cloud-Hadoop-All-0.23.3-Secondary/hadoop-mapreduce-project/src/java/org/apache/hadoop/mapred/JobInProgress.java:2712: cannot find symbol
    [javac] symbol  : constructor TaskFinishedEvent(org.apache.hadoop.mapred.TaskID,long,org.apache.hadoop.mapreduce.TaskType,java.lang.String,org.apache.hadoop.mapreduce.Counters)
    [javac] location: class org.apache.hadoop.mapreduce.jobhistory.TaskFinishedEvent
    [javac]     TaskFinishedEvent tfe = new TaskFinishedEvent(tip.getTIPId(),
    [javac]                             ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error
"
MAPREDUCE-4154,streaming MR job succeeds even if the streaming command fails,"Hadoop 1.0.1 behaves as expected - The task fails for streaming MR job if the streaming command fails. But it succeeds in hadoop 1.0.2 .
"
MAPREDUCE-4152,map task left hanging after AM dies trying to connect to RM,"We had an instance where the RM went down for more then an hour.  The application master exited with ""Could not contact RM after 360000 milliseconds""

2012-04-11 10:43:36,040 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1333003059741_15999Job Transitioned from RUNNING to ERROR


"
MAPREDUCE-4151,RM scheduler web page should filter apps to those that are relevant to scheduling,"On the ResourceManager's scheduler web page, the bottom of the page shows the apps block.  When the cluster has run a lot of applications (e.g.: 10,000+) loading the apps table can take a long time, and that prolongs the plotting of the queue status which is the most interesting portion of the page.

If the user is bothering to go to the scheduler page, they're probably not interested in apps that are not affecting what the scheduler is doing (e.g.: FINISHED, FAILED, KILLED, etc.).  Having the RM filter the apps for this page should significantly reduce the time it takes to load this page on the client, and it also helps reduce the amount of apps the user has to sift through when looking for the apps that are affecting what the scheduler is doing."
MAPREDUCE-4149,Rumen fails to parse certain counter strings,"If a counter name contains ""{"" or ""}"", Rumen is not able to parse it and throws ParseException."
MAPREDUCE-4148,MapReduce should not have a compile-time dependency on HDFS,MapReduce depends on HDFS's DelegationTokenIdentifier (for printing token debug information). We should remove this dependency and MapReduce's compile-time dependency on HDFS.
MAPREDUCE-4147,YARN should not have a compile-time dependency on HDFS,"YARN doesn't (and shouldn't) use any HDFS-specific APIs, so it should not declare HDFS as a compile-time dependency."
MAPREDUCE-4146,Support limits on task status string length and number of block locations in branch-2,This brings MAPREDUCE-1943 to branch-2. Counter limits were introduced in MAPREDUCE-901.
MAPREDUCE-4144,ResourceManager NPE while handling NODE_UPDATE,"The RM on one of our clusters has exited twice in the past few days because of an NPE while trying to handle a NODE_UPDATE:

{noformat}
2012-04-12 02:09:01,672 FATAL org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler
 [ResourceManager Event Processor]java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:261)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:223)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:246)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1229)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1078)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:1048)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignReservedContainer(LeafQueue.java:859)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:756)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:573)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:622)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:78)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:302)
        at java.lang.Thread.run(Thread.java:619)
{noformat}

This is very similar to the failure reported in MAPREDUCE-3005."
MAPREDUCE-4142,MR test failures on branch-1,"The following test classes are failing on branch-1: TestJobTrackerRestartWithLostTracker, TestJobTrackerSafeMode, TestMiniMRMapRedDebugScript, TestRecoveryManager, TestTaskTrackerLocalization.

Recent MR changes, believe these tests were passing before these failures:
- MAPREDUCE-4012 Hadoop Job setup error leaves no useful info to users. (tgrav
- MAPREDUCE-1238. mapred metrics shows negative count of waiting maps and redu
- MAPREDUCE-4017. Add jobname to jobsummary log (tgraves and Koji Noguchi via 
- MAPREDUCE-4003. log.index (No such file or directory) AND Task process exit 
    
"
MAPREDUCE-4141,"clover integration broken, also mapreduce poms are pulling in clover as a dependency","Some of the poms are specifying clover as a dependency, rather than exclusively as a plugin.

Also I tried running with the clover profile on trunk and the build is failing due to some issue with protobufs code generation."
MAPREDUCE-4140,"mapreduce classes incorrectly importing ""clover.org.apache.*"" classes","A number of classes in mapreduce are importing clover.org.apache.* classes

e.g. hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/java/org/apache/hadoop/mapreduce/v2/hs/PartialJob.java"
MAPREDUCE-4139,Potential ResourceManager deadlock when SchedulerEventDispatcher is stopped,"When the main thread calls ResourceManager$SchedulerEventDispatcher.stop() it grabs a lock on the object, kicks the event processor thread, and then waits for the thread to exit.  However the interrupted event processor thread can end up trying to call the synchronized getConfig() method which results in deadlock."
MAPREDUCE-4138,Reduce memory usage of counters due to non-static nested classes,"FrameworkCounter is a non-static nested class of FrameworkCounterGroup which means it retains a reference to the outer class, which isn't really needed."
MAPREDUCE-4137,MRAppMaster shutdown hook should not call FileSystem.closeAll(),"Filesystem.closeAll() attempts to remove the FileSystem shutdown hook.

This triggers an exception

{code}
Exception in thread ""Thread-1"" java.lang.IllegalStateException: Shutdown in progress
	at java.lang.ApplicationShutdownHooks.remove(ApplicationShutdownHooks.java:55)
	at java.lang.Runtime.removeShutdownHook(Runtime.java:220)
	at org.apache.hadoop.fs.FileSystem$Cache.remove(FileSystem.java:2101)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2133)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2110)
	at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:361)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1013)
{code}

Besides, because the FileSystem has its own shutdown hook that does a closeAll() the call from MRAppMaster is not needed."
MAPREDUCE-4135,MRAppMaster throws IllegalStateException while shutting down,"Always MRAppMaster throws IllegalStateException in the stderr while shutting down. It doesn't look good having this exception in the stderr file of MRAppMaster container.

{code:xml}
WARNING: org.apache.hadoop.metrics.jvm.EventCounter is deprecated. Please use org.apache.hadoop.log.metrics.EventCounter in all the log4j.properties files.
Exception in thread ""Thread-1"" java.lang.IllegalStateException: Shutdown in progress
	at java.lang.ApplicationShutdownHooks.remove(ApplicationShutdownHooks.java:55)
	at java.lang.Runtime.removeShutdownHook(Runtime.java:220)
	at org.apache.hadoop.fs.FileSystem$Cache.remove(FileSystem.java:2148)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2180)
	at org.apache.hadoop.fs.FileSystem$Cache.closeAll(FileSystem.java:2157)
	at org.apache.hadoop.fs.FileSystem.closeAll(FileSystem.java:361)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$MRAppMasterShutdownHook.run(MRAppMaster.java:1014)
{code}"
MAPREDUCE-4134,Remove references of mapred.child.ulimit etc. since they are not being used any more,"Courtesy Philip Su, we found that (mapred.child.ulimit, mapreduce.map.ulimit, mapreduce.reduce.ulimit) were not being used at all. The configuration exists but is never used. Its also mentioned in mapred-default.xml and templates/../mapred-site.xml . Also the method getUlimitMemoryCommand in Shell.java is now useless and can be removed.

"
MAPREDUCE-4133,MR over viewfs is broken,"After the changes in HADOOP-8014 went in, MR programs using viewfs broke. This is because, viewfs now expects getDefaultBlockSize, getDefaultReplication, and getServerDefaults to pass in a {{path}} as an argument. In the existing MR source, these are called with no arguments."
MAPREDUCE-4129,Lots of unneeded counters log messages,"Huge number of the same WARN messages are written. We only need to write each distinct message once. The messages are of the form:

{code}
2012-04-05 03:55:04,166 WARN mapreduce.Counters: Group {oldGroup} is deprecated. Use {newGroup} instead
{code}"
MAPREDUCE-4128,AM Recovery expects all attempts of a completed task to also be completed.,"The AM seems to assume that all attempts of a completed task (from a previous AM incarnation) would also be completed. There is at least one case in which this does not hold. Case being cancellation of a completed task resulting in a new running attempt.
"
MAPREDUCE-4127,Resource manager UI does not show the Job Priority,In RM UI the priority of job is not displayed
MAPREDUCE-4123,./mapred groups gives NoClassDefFoundError,"linux-168:/home/v2/hadoop-3.0.0-SNAPSHOT/bin # ./mapred groups
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/mapred/tools/GetGroups
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.tools.GetGroups
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:303)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:316)
Could not find the main class: org.apache.hadoop.mapred.tools.GetGroups.  Program will exit.
"
MAPREDUCE-4122,The MRAppmaster process killed count is being added to the Apps Pending value(with -ve sign) in Cluster Metrics page.,"Application will retry ""yarn.resourcemanager.am.max-retries"" times before the job is failed,if the MRAppmaster process is getting killed continously.This killed count is considered for Pending applications with -ve value on CLuster metrics page.
  This will mis-interpret the exact number of jobs in the Pending state for the cluster.Even if the MRAppmaster kill count is monitored:should be done at the job level and not at the cluster level."
MAPREDUCE-4121,dump the threads stack trace to stdout before killing a Task in timeout,"Typically when a job fails because of tasks timing out we investigate the issue by running the job again and triggering a dump of the thread stack traces of one of the tasks with jstack/""kill -3"" before it times out.
It would be convenient if the Task tracker could do the same right before killing tasks in time out. This usually points at the offending code.
"
MAPREDUCE-4120,mapred job -list-attempt-ids fails to get attempt ids,"{code:xml}
dev@ubuntudev-linux:~/hadoop/install/hadoop-3.0.0-SNAPSHOT/bin$ ./mapred job -list-attempt-ids job_1333786831666_0001
Usage: CLI [-list-attempt-ids <job-id> <task-type> <task-state>]. Valid values for <task-type> are MAP REDUCE JOB_SETUP JOB_CLEANUP TASK_CLEANUP. Valid values for <task-state> are running, completed
{code}
\\
\\
In the above command it gives valid <task-type> are MAP REDUCE JOB_SETUP JOB_CLEANUP TASK_CLEANUP. If we give the <task-type> as MAP, it says as invalid type.
{code:xml}
dev@ubuntudev-linux:~/hadoop/install/hadoop-3.0.0-SNAPSHOT/bin$ ./mapred job -list-attempt-ids job_1333786831666_0001 MAP completed
12/04/07 19:51:21 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
Exception in thread ""main"" java.lang.IllegalArgumentException: Invalid type: MAP. Valid types for task are: map, reduce, setup, cleanup.
	at org.apache.hadoop.mapreduce.tools.CLI.displayTasks(CLI.java:564)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:316)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1244)
{code}
\\
\\
In the above command it gives valid types for task are: map, reduce, setup, cleanup.. If we give the <task-type> as map, it fails with the below error.
{code:xml}
dev@ubuntudev-linux:~/hadoop/install/hadoop-3.0.0-SNAPSHOT/bin$ ./mapred job -list-attempt-ids job_1333786831666_0001 map completed
12/04/07 19:51:42 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
Exception in thread ""main"" java.lang.IllegalArgumentException: No enum const class org.apache.hadoop.mapreduce.TaskType.map
	at java.lang.Enum.valueOf(Enum.java:214)
	at org.apache.hadoop.mapreduce.TaskType.valueOf(TaskType.java:27)
	at org.apache.hadoop.mapreduce.tools.CLI.displayTasks(CLI.java:572)
	at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:316)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1244)
{code}"
MAPREDUCE-4118,"Update tests to not use MiniMRCluster Internally, and filter out duplicate tests","There are a number of tests from MRV1 that are being pulled into MRV2.  Many of these tests use MiniMRCluster, but the MiniMRCluser shim was added so that projects like Oozie and Pig can have a single test that will work for either Yarn or MRV1.  Internally our tests are never going to go back to be run on MRV1 so we should update them to use the new code.

Also there are some places where older tests and newer tests are almost duplicates of one another, or where the same results are archived through through mock objects.  For the sake of runtime of the tests it would be better to remove some of these duplicates."
MAPREDUCE-4117,mapred job -status throws NullPointerException,"{code:xml}
dev@ubuntudev-linux:~/hadoop/hadoop-trunk/bin$ ./mapred job -status job_1333408894669_0001

Exception in thread ""main"" java.lang.NullPointerException
    at org.apache.hadoop.mapreduce.Job.getTaskFailureEventString(Job.java:512)
    at org.apache.hadoop.mapreduce.Job.toString(Job.java:463)
    at java.lang.String.valueOf(String.java:2838)
    at java.io.PrintStream.println(PrintStream.java:788)
    at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:255)
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
    at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1244)
{code}"
MAPREDUCE-4116,Missing POM dependency for hadoop-yarn-common,hadoop-yarn-common is missing dependency on hadoop-common. some things like Configured from it are used. This dependency should be added to POM
MAPREDUCE-4115,hadoop-project-dist/pom.xml is invalid,"Mentioned POM is invalid. It fails XML validation and can not be deployed into repository with validating repository manager, such as Artifactory.

Problematic are "">"" inside antrun-plugin configuration. It should be &gt;

Line 342 and 379
"
MAPREDUCE-4114,saveVersion.sh fails if build directory contains space ,"if you rename build directory to something without space like /tmp/hadoop then it works


[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building hadoop-yarn-common 0.23.3-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-antrun-plugin:1.6:run (create-testdirs) @ hadoop-yarn-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.6:run (create-protobuf-generated-sources-directory) @ hadoop-yarn-common ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- exec-maven-plugin:1.2:exec (generate-sources) @ hadoop-yarn-common ---
[INFO] 
[INFO] --- exec-maven-plugin:1.2:exec (generate-version) @ hadoop-yarn-common ---
scripts/saveVersion.sh: cannot create /usr/local/jboss/.jenkins/jobs/Hadoop 0.23 branch/workspace/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/generated-sources/version/org/apache/hadoop/yarn/package-info.java: No such file or directory
[JENKINS] Archiving /usr/local/jboss/.jenkins/jobs/Hadoop 0.23 branch/workspace/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/pom.xml to /usr/local/jboss/.jenkins/jobs/Hadoop 0.23 branch/modules/org.apache.hadoop$hadoop-yarn-common/builds/2012-04-05_19-44-16/archive/org.apache.hadoop/hadoop-yarn-common/0.23.3-SNAPSHOT/hadoop-yarn-common-0.23.3-SNAPSHOT.pom
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Apache Hadoop Main ................................ SUCCESS [5.124s]
[INFO] Apache Hadoop Project POM ......................... SUCCESS [1.692s]
[INFO] Apache Hadoop Annotations ......................... SUCCESS [1.672s]
[INFO] Apache Hadoop Project Dist POM .................... SUCCESS [1.823s]
[INFO] Apache Hadoop Assemblies .......................... SUCCESS [0.796s]
[INFO] Apache Hadoop Auth ................................ SUCCESS [2.456s]
[INFO] Apache Hadoop Auth Examples ....................... SUCCESS [1.093s]
[INFO] Apache Hadoop Common .............................. SUCCESS [23.648s]
[INFO] Apache Hadoop Common Project ...................... SUCCESS [0.434s]
[INFO] Apache Hadoop HDFS ................................ SUCCESS [22.124s]
[INFO] Apache Hadoop HttpFS .............................. SUCCESS [3.251s]
[INFO] Apache Hadoop HDFS Project ........................ SUCCESS [0.443s]
[INFO] hadoop-yarn ....................................... SUCCESS [1.175s]
[INFO] hadoop-yarn-api ................................... SUCCESS [7.049s]
[INFO] hadoop-yarn-common ................................ FAILURE [5.565s]
[INFO] hadoop-yarn-server ................................ SKIPPED
[INFO] hadoop-yarn-server-common ......................... SKIPPED
[INFO] hadoop-yarn-server-nodemanager .................... SKIPPED
[INFO] hadoop-yarn-server-web-proxy ...................... SKIPPED
[INFO] hadoop-yarn-server-resourcemanager ................ SKIPPED
[INFO] hadoop-yarn-server-tests .......................... SKIPPED
[INFO] hadoop-mapreduce-client ........................... SKIPPED
[INFO] hadoop-mapreduce-client-core ...................... SKIPPED
[INFO] hadoop-yarn-applications .......................... SKIPPED
[INFO] hadoop-yarn-applications-distributedshell ......... SKIPPED
[INFO] hadoop-yarn-site .................................. SKIPPED
[INFO] hadoop-mapreduce-client-common .................... SKIPPED
[INFO] hadoop-mapreduce-client-shuffle ................... SKIPPED
[INFO] hadoop-mapreduce-client-app ....................... SKIPPED
[INFO] hadoop-mapreduce-client-hs ........................ SKIPPED
[INFO] hadoop-mapreduce-client-jobclient ................. SKIPPED
[INFO] Apache Hadoop MapReduce Examples .................. SKIPPED
[INFO] hadoop-mapreduce .................................. SKIPPED
[INFO] Apache Hadoop MapReduce Streaming ................. SKIPPED
[INFO] Apache Hadoop Distributed Copy .................... SKIPPED
[INFO] Apache Hadoop Archives ............................ SKIPPED
[INFO] Apache Hadoop Rumen ............................... SKIPPED
[INFO] Apache Hadoop Extras .............................. SKIPPED
[INFO] Apache Hadoop Tools Dist .......................... SKIPPED
[INFO] Apache Hadoop Tools ............................... SKIPPED
[INFO] Apache Hadoop Distribution ........................ SKIPPED
[INFO] Apache Hadoop Client .............................. SKIPPED
[INFO] Apache Hadoop Mini-Cluster ........................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 1:27.313s
[INFO] Finished at: Thu Apr 05 19:45:49 CEST 2012
[INFO] Final Memory: 86M/313M
[INFO] ------------------------------------------------------------------------
mavenExecutionResult exceptions not empty
message : Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-version) on project hadoop-yarn-common: Command execution failed.
cause : Command execution failed.
Stack trace : 
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-version) on project hadoop-yarn-common: Command execution failed."
MAPREDUCE-4113,Fix tests org.apache.hadoop.mapred.TestClusterMRNotification,"Sub Project : *hadoop-mapreduce-client-jobclient*

{code:xml}
Running org.apache.hadoop.mapred.TestClusterMRNotification
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 sec
{code}
"
MAPREDUCE-4112,Fix tests org.apache.hadoop.mapred.TestClusterMapReduceTestCase,"Sub Project : *hadoop-mapreduce-client-jobclient*

{code:xml}
Running org.apache.hadoop.mapred.TestClusterMapReduceTestCase
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.032 sec
{code}"
MAPREDUCE-4111,Fix tests in org.apache.hadoop.mapred.TestJobName,"Sub Project : *hadoop-mapreduce-client-jobclient*


{code:xml}
Running org.apache.hadoop.mapred.TestJobName
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 sec
{code}

"
MAPREDUCE-4110,Fix tests in org.apache.hadoop.mapred.TestMiniMRClasspath & org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers,"Sub Project : *hadoop-mapreduce-client-jobclient*


{code:xml}
Running org.apache.hadoop.mapred.TestMiniMRClasspath
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.032 sec
{code}

{code:xml}
Running org.apache.hadoop.mapred.TestMiniMRWithDFSWithDistinctUsers
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 sec
{code}"
MAPREDUCE-4109,availability of a job info in HS should be atomic,"It seems that the HS starts serving info about a job before it has all the info available.

In the trace below, a RunningJob throws a NPE when trying to access the counters.

This is happening on & off, thus I assume it is related to either the AM not flushing all job info to HDFS before notifying HS or the HS not loading all the job info from HDFS before start serving it.

In case it helps to diagnose the issue, this is happening in a secure cluster.

This makes Oozie to mark jobs as failed.

{code}
java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$MRClientProtocolHandler.getCounters(HistoryClientService.java:214)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getCounters(MRClientProtocolPBServiceImpl.java:149)
	at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:206)
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:355)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1660)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1656)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1654)
 at LocalTrace: 
	org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: 
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:163)
	at $Proxy31.getCounters(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getCounters(MRClientProtocolPBClientImpl.java:162)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:296)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:325)
	at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:472)
	at org.apache.hadoop.mapreduce.Job$8.run(Job.java:714)
	at org.apache.hadoop.mapreduce.Job$8.run(Job.java:711)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:416)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:711)
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.getCounters(JobClient.java:396)
	at org.apache.oozie.action.hadoop.LauncherMapper.hasIdSwap(LauncherMapper.java:296)
	at org.apache.oozie.action.hadoop.JavaActionExecutor.check(JavaActionExecutor.java:886)
	at org.apache.oozie.command.wf.ActionCheckXCommand.execute(ActionCheckXCommand.java:162)
	at org.apache.oozie.command.wf.ActionCheckXCommand.execute(ActionCheckXCommand.java:51)
	at org.apache.oozie.command.XCommand.call(XCommand.java:260)
	at org.apache.oozie.service.CallableQueueService$CallableWrapper.run(CallableQueueService.java:166)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
{code}
 "
MAPREDUCE-4108,Fix tests in org.apache.hadoop.util.TestRunJar,"Project : *hadoop-mapreduce-client-jobclient*

{code:xml}
Running org.apache.hadoop.util.TestRunJar
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 sec
{code}"
MAPREDUCE-4107,Fix tests in org.apache.hadoop.ipc.TestSocketFactory,"Project : *hadoop-mapreduce-client-jobclient*

{code:xml}
Running org.apache.hadoop.ipc.TestSocketFactory
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.031 sec
{code}"
MAPREDUCE-4106,Fix skipping tests in mapreduce,"There are 22 tests skipping in hadoop-mapreduce-client-jobclient module, all these can be corrected as part of this umbrella jira."
MAPREDUCE-4105,Yarn RackResolver ignores rack configurations,"Incorrect mappings because the Yarn RackResolver ignores rack configurations. This can be verified by inspecting the resource manager web ui that lists all the nodes, all of them show up with /default-rack regardless of the output from the script specified using net.topology.script.file.name configuration property."
MAPREDUCE-4103,Fix HA docs for changes to shell command fencer args,"HADOOP-8007 changes the way in which shell command fencers are invoked. For whatever reason, the docs live in the MR tree. This JIRA is to update the docs."
MAPREDUCE-4102,job counters not available in Jobhistory webui for killed jobs,"Run a simple wordcount or sleep, and kill the job before it finishes.  Go to the job history web ui and click the ""Counters"" link for that job. It displays ""500 error"".

The job history log has:

Caused by: com.google.inject.ProvisionException: Guice provision errors:

2012-04-03 19:42:53,148 ERROR org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /jobhistory/jobcounters/job_1333482028750_0001
java.lang.reflect.InvocationTargetException
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
...
..
...

1) Error injecting constructor, java.lang.NullPointerException
  at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.<init>(CountersBlock.java:56)
  while locating org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock
...
..
...
Caused by: java.lang.NullPointerException    at org.apache.hadoop.mapreduce.counters.AbstractCounters.incrAllCounters(AbstractCounters.java:328)
    at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters(CountersBlock.java:188)
    at org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.<init>(CountersBlock.java:57)
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)


There are task counters available if you drill down into successful tasks though."
MAPREDUCE-4100,Sometimes gridmix emulates data larger much larger then acutal counter for map only jobs,"While running 1400+ jobs trace I encountered this issue.
For map-only jobs, observed that some Maps generating data of around 9 GB (From HDFS_BYTES_WRITTEN) whereas actual value is around 5GB in trace.
This can sometimes also cause jobs to fail intermittently.

Other GridMix version coming be Hadoop-1.1.X and above might also effected "
MAPREDUCE-4099,ApplicationMaster may fail to remove staging directory,"When the ApplicationMaster shuts down it's supposed to remove the staging directory, assuming properties weren't set to override this behavior. During shutdown the AM tells the ResourceManager that it has finished before it cleans up the staging directory.  However upon hearing the AM has finished, the RM turns right around and kills the AM container.  If the AM is too slow, the AM will be killed before the staging directory is removed.

We're seeing the AM lose this race fairly consistently on our clusters, and the lack of staging directory cleanup quickly leads to filesystem quota issues for some users."
MAPREDUCE-4098,TestMRApps testSetClasspath fails,"The assertion of this test is testing for equality, as the generated classpath file is in the classpath the test fails.

Instead, the test should test for the expected path elements to be in the classspath."
MAPREDUCE-4097,tools testcases fail because missing mrapp-generated-classpath file in classpath,"The mrapp-generated-classpath file is created in hadoop-mapreduce-client-apptarget/classes/ dir but it is excluded from the JAR.

When running tools testcases from root level, mvn uses hadoop-mapreduce-client-app/target/classes/ dir to create the classpath.

When running tools testcases from tools level, mvn uses the hadoop-mapreduce-client-app JAR from M2 cache to create the classpath.

In the later the mrapp-generated-classpath is not present."
MAPREDUCE-4096,tests seem to be randomly failing,"Looking at the output from test-patch from jenkins recently it seems that tests are randomly failing:  jira MAPREDUCE-4089 is an example where 22 failed, the next time patch was put up 4 failed and in both cases the patch had nothing to do with those tests.

I also manually ran mvn test in mapreduce directory and had 20 failures and saw a couple of processes still laying around. One was using port 10020 which other tests were trying to use and you saw a bind address error come out of the tests."
MAPREDUCE-4095,TestJobInProgress#testLocality uses a bogus topology,"The following in TestJobInProgress#testLocality:

{code}
    Node r2n4 = new NodeBase(""/default/rack2/s1/node4"");
    nt.add(r2n4);
{code}

violates the check introduced by HADOOP-8159:

{noformat}
Testcase: testLocality took 0.005 sec
        Caused an ERROR
Invalid network topology. You cannot have a rack and a non-rack node at the same level of the network topology.
org.apache.hadoop.net.NetworkTopology$InvalidTopologyException: Invalid network topology. You cannot have a rack and a non-rack node at the same level of the network topology.
        at org.apache.hadoop.net.NetworkTopology.add(NetworkTopology.java:349)
        at org.apache.hadoop.mapred.TestJobInProgress.testLocality(TestJobInProgress.java:232)
{noformat}"
MAPREDUCE-4094,Mapreduce-trunk test cases are failing,"https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1037/

{code:xml}
Failed tests:   testDefaultCleanupAndAbort(org.apache.hadoop.mapred.TestJobCleanup): Done file ""/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/test-job-cleanup/output-0/_SUCCESS"" missing for job job_1333287145240_0001
  testCustomAbort(org.apache.hadoop.mapred.TestJobCleanup): Done file ""/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/test-job-cleanup/output-1/_SUCCESS"" missing for job job_1333287145240_0002
  testCustomCleanup(org.apache.hadoop.mapred.TestJobCleanup): Done file ""/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/target/test-dir/test-job-cleanup/output-2/_custom_cleanup"" missing for job job_1333287145240_0003
  testHeapUsageCounter(org.apache.hadoop.mapred.TestJobCounters): Job job_1333287188908_0001 failed!
  testTaskTempDir(org.apache.hadoop.mapred.TestMiniMRChildTask)
  testTaskEnv(org.apache.hadoop.mapred.TestMiniMRChildTask): The environment checker job failed.
  testTaskOldEnv(org.apache.hadoop.mapred.TestMiniMRChildTask): The environment checker job failed.
  testJob(org.apache.hadoop.mapred.TestMiniMRClientCluster)
  testLazyOutput(org.apache.hadoop.mapreduce.TestMapReduceLazyOutput)
  testSpeculativeExecution(org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution)
  testSleepJob(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testRandomWriter(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testDistributedCache(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testValidProxyUser(org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser)

Tests in error: 
  testReduceFromPartialMem(org.apache.hadoop.mapred.TestReduceFetchFromPartialMem): Job failed!
  testWithDFS(org.apache.hadoop.mapred.TestJobSysDirWithDFS): Job failed!
  testReduceFromPartialMem(org.apache.hadoop.mapred.TestReduceFetchFromPartialMem): Job failed!
  testLazyOutput(org.apache.hadoop.mapred.TestLazyOutput): Job failed!
  testFailingMapper(org.apache.hadoop.mapreduce.v2.TestMRJobs): 0
  org.apache.hadoop.mapreduce.v2.TestMROldApiJobs: Failed to Start org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
  org.apache.hadoop.mapreduce.v2.TestUberAM: Failed to Start org.apache.hadoop.mapreduce.v2.TestMRJobs
  testDefaultCleanupAndAbort(org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter): Failed to Start org.apache.hadoop.mapred.MiniMRCluster
  testCustomAbort(org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter): Failed to Start org.apache.hadoop.mapred.MiniMRCluster
  testCustomCleanup(org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter): Failed to Start org.apache.hadoop.mapred.MiniMRCluster
  testChild(org.apache.hadoop.mapreduce.TestChild): Failed to Start org.apache.hadoop.mapred.MiniMRCluster

Tests run: 404, Failures: 14, Errors: 11, Skipped: 22
{code}"
MAPREDUCE-4093,Improve RM WebApp start up when proxy address is not set,"{code:title=ResourceManager.java|borderStyle=solid}
  protected void startWepApp() {
    Builder<ApplicationMasterService> builder = 
      WebApps.$for(""cluster"", ApplicationMasterService.class, masterService, ""ws"").at(
          this.conf.get(YarnConfiguration.RM_WEBAPP_ADDRESS,
          YarnConfiguration.DEFAULT_RM_WEBAPP_ADDRESS)); 
    if(YarnConfiguration.getRMWebAppHostAndPort(conf).
        equals(YarnConfiguration.getProxyHostAndPort(conf))) {
      AppReportFetcher fetcher = new AppReportFetcher(conf, getClientRMService());
      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME, 
          ProxyUriUtils.PROXY_PATH_SPEC, WebAppProxyServlet.class);
      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);
      String proxy = YarnConfiguration.getProxyHostAndPort(conf);
      String[] proxyParts = proxy.split("":"");
      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);

    }
    webApp = builder.start(new RMWebApp(this));
  }
{code} 

In the above code, YarnConfiguration.getProxyHostAndPort(conf) is invoking twice. getProxyHostAndPort() internally invokes getRMWebAppHostAndPort() which resolves RM web app address when proxy address is not set."
MAPREDUCE-4092,commitJob Exception does not fail job (regression in 0.23 vs 0.20),"If commitJob throws an exception JobImpl will swallow the exception with a warning and succeed the Job. This is a break from 0.20 and 1.0 where commitJob exception will fail the job

Exception logged in the AM as WARN
  org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Could not do commit for Job
Job still finishes as succeeded"
MAPREDUCE-4091,tools testcases failing because of MAPREDUCE-4082,"MAPREDUCE-4082 moved the generated-classpath file used by MRApp from the main classpath to the test classpath.

The objective of MAPREDUCE-4082 was to remove the generated-classpath file from the hadoop-mapreduce-client-app JAR. I've thought that moving it to the test-classpath would do the trick.

This is breaking tools testcases (most likely) because of different classloader being used by maven for main classpath and test classpath.

"
MAPREDUCE-4090,Branch 1 pipes doesn't work on MR2 clusters,"If I compile pipes examples on branch 1: 

{code}
ant -Dcompile.c++=yes examples
{code}

And then try to run it on an MR2 cluster, the pipes job hangs forever at map 0% reduce 0%, I can see in the maps stderr:

{code}
Hadoop Pipes Exception: Illegal text protocol command 
{code}

The issue here is that if users have older pipes job, they won't be able to run it on MR2 (without recompilation). Is this expected or there is something to be fixed so jobs can be used interchangeably? Or should we document it as an incompatibility?"
MAPREDUCE-4089,Hung Tasks never time out. ,"The AM will timeout a task through mapreduce.task.timeout only when it does not hear from the task within the given timeframe.  On 1.0 a task must be making progress, either by reading input from HDFS, writing output to HDFS, writing to a log, or calling a special method to inform it that it is still making progress.

This is because on 0.23 a status update which happens every 3 seconds is counted as progress."
MAPREDUCE-4088,Task stuck in JobLocalizer prevented other tasks on the same node from committing,"We saw that as a result of HADOOP-6963, one task was stuck in this

Thread 23668: (state = IN_NATIVE)
 - java.io.UnixFileSystem.getBooleanAttributes0(java.io.File) @bci=0 (Compiled frame; information may be imprecise)
 - java.io.UnixFileSystem.getBooleanAttributes(java.io.File) @bci=2, line=228 (Compiled frame)
 - java.io.File.exists() @bci=20, line=733 (Compiled frame)
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=3, line=446 (Compiled frame)
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=52, line=455 (Compiled frame)
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=52, line=455 (Compiled frame)
....
.... TONS MORE OF THIS SAME LINE
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=52, line=455 (Compiled frame)
.....
.....
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=52, line=455 (Compiled frame)
 - org.apache.hadoop.fs.FileUtil.getDU(java.io.File) @bci=52, line=455 (Interpreted frame)
ne=451 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer.downloadPrivateCacheObjects(org.apache.hadoop.conf.Configuration, java.net.URI[], org.apache.hadoop.fs.Path[], long[], boolean[], boolean) @bci=150, line=324 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer.downloadPrivateCache(org.apache.hadoop.conf.Configuration) @bci=40, line=349 (Interpreted frame) 51, line=383 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer.runSetup(java.lang.String, java.lang.String, org.apache.hadoop.fs.Path, org.apache.hadoop.mapred.TaskUmbilicalProtocol) @bci=46, line=477 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer$3.run() @bci=20, line=534 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer$3.run() @bci=1, line=531 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Interpreted frame)
 - javax.security.auth.Subject.doAs(javax.security.auth.Subject, java.security.PrivilegedExceptionAction) @bci=42, line=396 (Interpreted frame)
 - org.apache.hadoop.security.UserGroupInformation.doAs(java.security.PrivilegedExceptionAction) @bci=14, line=1082 (Interpreted frame)
 - org.apache.hadoop.mapred.JobLocalizer.main(java.lang.String[]) @bci=266, line=530 (Interpreted frame)

While all other tasks on the same node were stuck in 
Thread 32141: (state = BLOCKED)
 - java.lang.Thread.sleep(long) @bci=0 (Interpreted frame)
 - org.apache.hadoop.mapred.Task.commit(org.apache.hadoop.mapred.TaskUmbilicalProtocol, org.apache.hadoop.mapred.Task$TaskReporter, org.apache.hadoop.mapreduce.OutputCommitter) @bci=24, line=980 (Compiled frame)
 - org.apache.hadoop.mapred.Task.done(org.apache.hadoop.mapred.TaskUmbilicalProtocol, org.apache.hadoop.mapred.Task$TaskReporter) @bci=146, line=871 (Interpreted frame)
 - org.apache.hadoop.mapred.ReduceTask.run(org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.TaskUmbilicalProtocol) @bci=470, line=423 (Interpreted frame)
 - org.apache.hadoop.mapred.Child$4.run() @bci=29, line=255 (Interpreted frame)
 - java.security.AccessController.doPrivileged(java.security.PrivilegedExceptionAction, java.security.AccessControlContext) @bci=0 (Interpreted frame)
 - javax.security.auth.Subject.doAs(javax.security.auth.Subject, java.security.PrivilegedExceptionAction) @bci=42, line=396 (Interpreted frame)
 - org.apache.hadoop.security.UserGroupInformation.doAs(java.security.PrivilegedExceptionAction) @bci=14, line=1082 (Interpreted frame)
 - org.apache.hadoop.mapred.Child.main(java.lang.String[]) @bci=738, line=249 (Interpreted frame)

This should never happen. A stuck task should never prevent other tasks from different jobs on the same node from committing."
MAPREDUCE-4087,[Gridmix] GenerateDistCacheData job of Gridmix can become slow in some cases,"In map() method of GenerateDistCacheData job of Gridmix, val.setSize() is done every time based on the bytes to be written to a distributed cache file. When we try to write data to next distributed cache file in the same map task, the size of random data generated in each iteration can become small based on the particular case. This can make this dist cache data generation slow."
MAPREDUCE-4085,Kill task attempts longer than a configured queue max time,"For some environments, it is desirable to have certain queues have an SLA with regards to task turnover.  (i.e., a slot will be free in X minutes and scheduled to the appropriate job)  Queues should have a 'task time limit' that would cause task attempts over this time to be killed. This leaves open the possibility that if the task was on a bad node, it could still be rescheduled up to max.task.attempt times."
MAPREDUCE-4083,GridMix emulated job tasks.resource-usage emulator for CPU usage throws NPE when Trace contains cumulativeCpuUsage value of 0 at attempt level,GridMix emulated job tasks.resource-usage emulator for CPU usage throws NPE when Trace contains cumulativeCpuUsage value of 0 at attempt level
MAPREDUCE-4082,hadoop-mapreduce-client-app's mrapp-generated-classpath file should not be in the module JAR,"Currently the mrapp-generated-classpath file containing the 'built' classpath, which only makes sense during building/testing in the machine where the build happens, is bundled in the hadoop-mapreduce-client-app JAR.

Because the file is bundled in the hadoop-mapreduce-client-app JAR, its contents are added to the classpath of all MR jobs. 

All this entries are useless and just pollute the classpath.

This file should not be bundled in the hadoop-mapreduce-client-app JAR.

As an example, the contents of this file in my local built are:

{code}
/Users/tucu/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/tucu/.m2/repository/asm/asm/3.2/asm-3.2.jar:/Users/tucu/.m2/repository/com/cenqua/clover/clover/3.0.2/clover-3.0.2.jar:/Users/tucu/.m2/repository/com/google/guava/guava/r09/guava-r09.jar:/Users/tucu/.m2/repository/com/google/inject/guice/3.0/guice-3.0.jar:/Users/tucu/.m2/repository/com/google/inject/extensions/guice-servlet/3.0/guice-servlet-3.0.jar:/Users/tucu/.m2/repository/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar:/Users/tucu/.m2/repository/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.jar:/Users/tucu/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-client/1.8/jersey-client-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-grizzly2/1.8/jersey-grizzly2-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.8/jersey-guice-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-test-framework/jersey-test-framework-core/1.8/jersey-test-framework-core-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-test-framework/jersey-test-framework-grizzly2/1.8/jersey-test-framework-grizzly2-1.8.jar:/Users/tucu/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/Users/tucu/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/Users/tucu/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/tucu/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/tucu/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/tucu/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/Users/tucu/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/tucu/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/tucu/.m2/repository/commons-daemon/commons-daemon/1.0.3/commons-daemon-1.0.3.jar:/Users/tucu/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/tucu/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/tucu/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/tucu/.m2/repository/commons-io/commons-io/2.1/commons-io-2.1.jar:/Users/tucu/.m2/repository/commons-lang/commons-lang/2.5/commons-lang-2.5.jar:/Users/tucu/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/Users/tucu/.m2/repository/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar:/Users/tucu/.m2/repository/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar:/Users/tucu/.m2/repository/hsqldb/hsqldb/1.8.0.7/hsqldb-1.8.0.7.jar:/Users/tucu/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/Users/tucu/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/Users/tucu/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/Users/tucu/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/tucu/.m2/repository/javax/xml/bind/jaxb-api/2.1/jaxb-api-2.1.jar:/Users/tucu/.m2/repository/jdiff/jdiff/1.0.9/jdiff-1.0.9.jar:/Users/tucu/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/tucu/.m2/repository/junit/junit/4.8.2/junit-4.8.2.jar:/Users/tucu/.m2/repository/log4j/log4j/1.2.15/log4j-1.2.15.jar:/Users/tucu/.m2/repository/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar:/Users/tucu/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/Users/tucu/.m2/repository/org/apache/avro/avro/1.5.4/avro-1.5.4.jar:/Users/tucu/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-annotations/0.23.1-cdh4b2-SNAPSHOT/hadoop-annotations-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-auth/0.23.1-cdh4b2-SNAPSHOT/hadoop-auth-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-common-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-common-0.23.1-cdh4b2-SNAPSHOT-tests.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-hdfs/0.23.1-cdh4b2-SNAPSHOT/hadoop-hdfs-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-mapreduce-client-common-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/0.23.1-cdh4b2-SNAPSHOT/hadoop-mapreduce-client-core-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/0.23.1-cdh4b2-SNAPSHOT/hadoop-mapreduce-client-shuffle-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-api/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-api-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-common-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-common-0.23.1-cdh4b2-SNAPSHOT-tests.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-server-common-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-server-nodemanager/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-server-nodemanager-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-server-resourcemanager-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-server-resourcemanager/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-server-resourcemanager-0.23.1-cdh4b2-SNAPSHOT-tests.jar:/Users/tucu/.m2/repository/org/apache/hadoop/hadoop-yarn-server-web-proxy/0.23.1-cdh4b2-SNAPSHOT/hadoop-yarn-server-web-proxy-0.23.1-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/zookeeper/zookeeper/3.4.3-cdh4b2-SNAPSHOT/zookeeper-3.4.3-cdh4b2-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/aspectj/aspectjrt/1.6.5/aspectjrt-1.6.5.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.8.8/jackson-jaxrs-1.8.8.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-xc/1.8.8/jackson-xc-1.8.8.jar:/Users/tucu/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/Users/tucu/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/Users/tucu/.m2/repository/org/glassfish/javax.servlet/3.0/javax.servlet-3.0.jar:/Users/tucu/.m2/repository/org/glassfish/external/management-api/3.0.0-b012/management-api-3.0.0-b012.jar:/Users/tucu/.m2/repository/org/glassfish/gmbal/gmbal-api-only/3.0.0-b023/gmbal-api-only-3.0.0-b023.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-framework/2.1.1/grizzly-framework-2.1.1-tests.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-framework/2.1.1/grizzly-framework-2.1.1.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-http/2.1.1/grizzly-http-2.1.1.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-http-server/2.1.1/grizzly-http-server-2.1.1.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-http-servlet/2.1.1/grizzly-http-servlet-2.1.1.jar:/Users/tucu/.m2/repository/org/glassfish/grizzly/grizzly-rcm/2.1.1/grizzly-rcm-2.1.1.jar:/Users/tucu/.m2/repository/org/jboss/netty/netty/3.2.3.Final/netty-3.2.3.Final.jar:/Users/tucu/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/Users/tucu/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/Users/tucu/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/Users/tucu/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/Users/tucu/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/Users/tucu/.m2/repository/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar:/Users/tucu/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/tucu/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/Users/tucu/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/tucu/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/tucu/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
{code}"
MAPREDUCE-4081,TestMROutputFormat.java does not compile,"[ERROR] /hadoop/src/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMROutputFormat.java:[36,7] class TestConfInCheckSpec is public, should be declared in a file named TestConfInCheckSpec.java
"
MAPREDUCE-4080,FileNotFoundException while accessing job configuration from UI.,"Tried to access the job configuration from UI, when the job history files were still in the intermediate directory. JHS displayed the configurations of the job. Again tried to access the configurations of the same job, when the job history files were in the done directory. This time got the following exception

{noformat}
java.io.FileNotFoundException: File does not exist: /jobhistory/intermediate/kamesh/job_1332999698561_0005_conf.xml
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1153)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1115)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1087)
{noformat}"
MAPREDUCE-4079,Allow MR AppMaster to limit ephemeral port range.,"Having the MapReduce Application Masters bind to any ephemeral port makes it very difficult to setup ACLs.  mapreduce.job.am-access-disabled from MAPREDUCE-3251 is not a practical permanent solution for all jobs.  Especially for tools like pig where they are not aware of mapreduce.job.am-access-disabled and may deal with it properly.

We should add in a config option that would allow someone to restrict the range of ports that the MR-AM can bind to.  It will slow down startup in some cases because we will have to probe for open ports instead of just asking the OS to find one for us.  But we can make that conditional on this config so users who do not set this config do not see any performance degradation. "
MAPREDUCE-4078,Hadoop-Mapreduce-0.23-Build - Build # 239 - Still Failing ,"See https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/239/


{code:xml}
See https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/239/

###################################################################################
########################## LAST 60 LINES OF THE CONSOLE ###########################
Started by timer
Building remotely on hadoop2 in workspace /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build
Location 'http://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.23' does not exist
One or more repository locations do not exist anymore for Hadoop-Mapreduce-0.23-Build, project will be disabled.
Retrying after 10 seconds
Location 'http://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.23' does not exist
One or more repository locations do not exist anymore for Hadoop-Mapreduce-0.23-Build, project will be disabled.
Retrying after 10 seconds
Location 'http://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.23' does not exist
One or more repository locations do not exist anymore for Hadoop-Mapreduce-0.23-Build, project will be disabled.
Archiving artifacts
Email was triggered for: Failure
Sending email for trigger: Failure



###################################################################################
############################## FAILED TESTS (if any) ##############################
No tests ran.
{code}"
MAPREDUCE-4077,Issues while using Hadoop Streaming job,"When we use -file option it says deprecated and use -files.
{code:xml}
linux-f330:/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin # ./hadoop jar 
../share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -input /hadoop 
-output /test/output/3 -mapper cat -reducer wc -file hadoop
02/02/19 10:55:51 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.
{code}

But when we use -files option, it says unrecognized option.
{code:xml}
linux-f330:/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin # ./hadoop jar 
../share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -input /hadoop -output 
/test/output/3 -mapper cat -reducer wc -files hadoop
02/02/19 10:56:42 ERROR streaming.StreamJob: Unrecognized option: -files
Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]
{code}


When we use -archives option,  it says unrecognized option.
{code:xml}
linux-f330:/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin # ./hadoop jar 
../share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -input /hadoop -output 
/test/output/3 -mapper cat -reducer wc -archives testarchive.rar
02/02/19 11:05:43 ERROR streaming.StreamJob: Unrecognized option: -archives
Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]
{code}

But in the options it will display the usage of the -archives.
{code:xml}
linux-f330:/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin # ./hadoop jar 
../share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -input /hadoop -output 
/test/output/3 -mapper cat -reducer wc -archives testarchive.rar
02/02/19 11:05:43 ERROR streaming.StreamJob: Unrecognized option: -archives
Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]
..........
..........
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.
{code}"
MAPREDUCE-4076,Stream job fails with ZipException when use yarn jar command,"Stream job fails with ZipException when use yarn jar command and executes successfully with hadoop jar command.

{code:xml}
linux-f330:/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin # ./yarn jar ../share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -input /hadoop -output /test/output/1 -mapper cat -reducer wc
packageJobJar: [] [/home/devaraj/hadoop/trunk/hadoop-0.24.0-SNAPSHOT/bin/$%7Bhadoop.home.dir%7D/hadoop-$%7Buser.name%7D/hadoop-unjar4241129353499211360/] /tmp/streamjob7683981905208294893.jar tmpDir=null
Exception in thread ""main"" java.io.IOException: java.util.zip.ZipException: ZIP file must have at least one entry
        at org.apache.hadoop.streaming.JarBuilder.merge(JarBuilder.java:82)
        at org.apache.hadoop.streaming.StreamJob.packageJobJar(StreamJob.java:707)
        at org.apache.hadoop.streaming.StreamJob.setJobConf(StreamJob.java:948)
        at org.apache.hadoop.streaming.StreamJob.run(StreamJob.java:127)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
        at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:50)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:200)
{code}
"
MAPREDUCE-4075,Incorrect NM's hyperlink and  NM's information ,"While accessing task attempt log of sucessfully completed *uber-job* from *jobhistory/attempts/job_<id>/m/SUCCESSFUL*, noticed the following 

* NM information displayed while accessing logs hyperlink is
{noformat}Aggregation may not be complete, Check back later or try the nodemanager at localhost:1234{noformat}

* Node's hyperlink is displayed as +localhost:8042+

In the above case, I *think* we should update localhost and port numbers to reflect the actual values to make hyperlink work."
MAPREDUCE-4074,Client continuously retries to RM When RM goes down before launching Application Master,"Client continuously tries to RM and logs the below messages when the RM goes down before launching App Master. 

I feel exception should be thrown or break the loop after finite no of retries.

{code:xml}
28/03/12 07:15:03 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 0 time(s).
28/03/12 07:15:04 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 1 time(s).
28/03/12 07:15:05 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 2 time(s).
28/03/12 07:15:06 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 3 time(s).
28/03/12 07:15:07 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 4 time(s).
28/03/12 07:15:08 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 5 time(s).
28/03/12 07:15:09 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 6 time(s).
28/03/12 07:15:10 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 7 time(s).
28/03/12 07:15:11 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 8 time(s).
28/03/12 07:15:12 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 9 time(s).
28/03/12 07:15:13 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 0 time(s).
28/03/12 07:15:14 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 1 time(s).
28/03/12 07:15:15 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 2 time(s).
28/03/12 07:15:16 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 3 time(s).
28/03/12 07:15:17 INFO ipc.Client: Retrying connect to server: linux-f330.site/10.18.40.182:8032. Already tried 4 time(s).
{code}"
MAPREDUCE-4073,CS assigns multiple off-switch containers when using multi-level-queues,"CS is supposed to be allocating a single off-switch container per node heartbeat (MAPREDUCE-3641). This works for queues directly under root, but not in the case of multi-level queues.
"
MAPREDUCE-4072,User set java.library.path seems to overwrite default creating problems native lib loading,"This was found by Peeyush Bishnoi.

While running a distributed cache example with Hadoop-0.23,
tasks are failing as follows:
------------------------------------------------------------------------------------------------------------

Exception from container-launch:
org.apache.hadoop.util.Shell$ExitCodeException: at
org.apache.hadoop.util.Shell.runCommand(Shell.java:261) at
org.apache.hadoop.util.Shell.run(Shell.java:188) at
org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:381) at
org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:207)
at
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:241)
at
org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:68)
at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303) at
java.util.concurrent.FutureTask.run(FutureTask.java:138) at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
at java.lang.Thread.run(Thread.java:619) main : command provided 1 main : user
is <user>
------------------------------------------------------------------------------------------------------------

Same Pig script and command work successfully on 0.20

See this in the stderr:

Exception in thread ""main"" java.lang.ExceptionInInitializerError
    at java.lang.Class.forName0(Native Method)
    at java.lang.Class.forName(Class.java:247)
    at
org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:1179)
    at
org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1149)
    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1238)
    at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:1264)
    at org.apache.hadoop.security.Groups.(Groups.java:54)
    at
org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:178)
    at
org.apache.hadoop.security.UserGroupInformation.initUGI(UserGroupInformation.java:252)
    at
org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:223)
    at
org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:265)
    at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:75)
Caused by: java.lang.RuntimeException: Bailing out since native library
couldn't be loaded
    at
org.apache.hadoop.security.JniBasedUnixGroupsMapping.(JniBasedUnixGroupsMapping.java:48)
    ... 12 more

Pig command:
$ pig -Dmapred.job.queue.name=<queue> -Dmapred.cache.archives=<archives> -Dmapred.child.java.opts=""-Djava.library.path=./ygeo/lib
-Dip2geo.preLoadLibraries=<some other libs>"" -Djava.io.tmpdir=/grid/0/tmp -Dmapred.create.symlink=yes -Dmapred.job.map.memory.mb=3072 piggeoscript.pig

"
MAPREDUCE-4069,Cleanup task tokens interface,"This tracks a couple of cleanup issues that were identified in MAPREDUCE-4043:

* It seems unnecessary to pass the job token and credentials separately when we always combine the job token into the credentials before building the container launch context.  The TaskImpl and TaskAttemptImpl constructors could simply take credentials with the job token already added rather than separate job token and credential parameters.
* It's unclear whether we still need the appTokens file that is placed into HDFS by the job submitter, localized by the NM, and finally read in by the AM. I believe the AM's credentials sent in the AM's container launch context already contains the same information.  If that's the case, we should remove the code related to the appTokens file.
"
MAPREDUCE-4068,Jars in lib subdirectory of the submittable JAR are not added to the classpath,"Prior to hadoop 0.23, users could add third party jars to the lib subdirectory of the submitted job jar and they become available in the task's classpath. I see this functionality was in TaskRunner.java, but I can't see similar functionality in hadoop 0.23 (neither in MapReduceChildJVM.java nor other places)."
MAPREDUCE-4067,Replace YarnRemoteException with IOException in MRv2 APIs,"YarnRemoteException is defined as a generic wrapper for all the exceptions in yarn. I think we should instead throw IOExceptions in the API, which can later be extended for more specialized exceptions without breaking compatibility."
MAPREDUCE-4066,"To get ""yarn.app.mapreduce.am.staging-dir"" value, should set the default value","when submit the job use the windows eclipse, and the yarn.app.mapreduce.am.staging-dir value is null.
{code:title=MRApps.java|borderStyle=solid}

  public static Path getStagingAreaDir(Configuration conf, String user) {
    return new Path(
        conf.get(MRJobConfig.MR_AM_STAGING_DIR) + 
        Path.SEPARATOR + user + Path.SEPARATOR + STAGING_CONSTANT);
  }
{code}

should modify to:
{code:title=MRApps.java|borderStyle=solid}

  public static Path getStagingAreaDir(Configuration conf, String user) {
    return new Path(
        conf.get(MRJobConfig.MR_AM_STAGING_DIR,""/tmp/hadoop-yarn/staging"") + 
        Path.SEPARATOR + user + Path.SEPARATOR + STAGING_CONSTANT);
  }


{code}
"
MAPREDUCE-4065,Add .proto files to built tarball,"Please add the .proto files to the built tarball so that users can build 3rd party tools that use protocol buffers without having to do an svn checkout of the source code.

Sorry I don't know more about Maven, or I would provide a patch.
"
MAPREDUCE-4062,AM Launcher thread can hang forever,"We saw an instance where the RM stopped launch Application masters.  We found that the launcher thread was hung because something weird/bad happened to the NM node. Currently there is only 1 launcher thread (jira 4061 to fix that). We need this to not happen.  Even once we increase the number of threads  to > 1 if that many nodes go bad the RM would be stuck.  Note that this was stuck like this for approximately 9 hours.

Stack trace on hung AM launcher:

""pool-1-thread-1"" prio=10 tid=0x000000004343e800 nid=0x3a4c in Object.wait()
[0x000000004fad2000]
   java.lang.Thread.State: WAITING (on object monitor)
    at java.lang.Object.wait(Native Method)
    at java.lang.Object.wait(Object.java:485)
    at org.apache.hadoop.ipc.Client.call(Client.java:1076)
    - locked <0x00002aab05a4f3f0> (a org.apache.hadoop.ipc.Client$Call)
    at
org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:135)
    at $Proxy76.startContainer(Unknown Source)
    at
org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:87)
    at
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.launch(AMLauncher.java:118)
    at
org.apache.hadoop.yarn.server.resourcemanager.amlauncher.AMLauncher.run(AMLauncher.java:265)
    at
java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
    at
java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
    at java.lang.Thread.run(Thread.java:619)"
MAPREDUCE-4061,RM only has 1 AM launcher thread,"The application master launcher has a thread pool that is configured with core size 1, maximum 10.  The thread pool will not create over
the core size thread unless the queue it is using is full. We are using an unbounded queue, so the thread pool will only ever create 1 thread.  We need to have more then 1 AM launch thread.

If that thread becomes hung for some reason, the RM can no longer launch any application masters.  We have seen an instance of this when a NM become unresponsive - something bad happened to host, not sure what yet.  "
MAPREDUCE-4060,Multiple SLF4J binding warning,"This is the MAPREDUCE portion of HADOOP-8005.  We should remove slf4j from the assembly and use the one provided by hadoop-common so we don't end up with multiple binding warnings for SLF4J.
"
MAPREDUCE-4059,The history server should have a separate pluggable storage/query interface,The history server currently caches all parsed jobs in RAM.  These jobs can be very large because of counters.  It would be nice to have a pluggable interface for the cacheing and querying of the cached data so that we can play around with different implementations.  Also just for cleanness of the code it would be nice to split the very large JobHistoryServer.java into a few smaller ones that are more understandable and readable.
MAPREDUCE-4058,adjustable task priority,"For those of us that completely destroy our CPUs, it is beneficial to be able to run user tasks at a different priority than the tasktracker. This would allow for TTs (and by extension, DNs) to get more CPU clock cycles so that things like heartbeats don't disappear."
MAPREDUCE-4057,Compilation error in RAID ,"{noformat}
    [javac] Compiling 33 source files to /Users/szetszwo/hadoop/t2/hadoop-mapreduce-project/build/contrib/raid/classes
    [javac] /Users/szetszwo/hadoop/t2/hadoop-mapreduce-project/src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/namenode/NameNodeRaidUtil.java:42:
 unreported exception org.apache.hadoop.ipc.StandbyException; must be caught or declared to be thrown
    [javac]     return namesystem.getFileInfo(src, resolveLink);
    [javac]                                  ^
{noformat}
"
MAPREDUCE-4056,Remove MR1 src/test/system,"hadoop-mapreduce-project/src/test/system is MR1 specific (eg built against the JT/TT), is already maintained in branch-1 can be removed from trunk/23."
MAPREDUCE-4055,"Job history files are not getting copied from ""intermediate done"" directory to ""done"" directory ","1.Submit job
2.After successful execution of job before the Job history files are copied from intermediate done directory to done directory,NameNode got killed.
3.Restart the NameNode after mapreduce.jobhistory.move.interval-ms time is elapsed(default is 3 min).
Observe that Job history files are not copied from intermediate done directory to done directory and also logs are not updated with any message

Now submit another job observe that Job history files are not copied from intermediate done directory to done directory and also nothing is logged into historyserver logs.

"
MAPREDUCE-4053,"Counters group names deprecation is wrong, iterating over group names deprecated names don't show up","This is similar to the deprecation of Configuration properties bug HADOOP-8167, interator() retrieval of counter names only returns new names.

Oozie breaks here because it is using the deprecate name and iterating over values (OOZIE-777). While it can be worked around easily in Oozie, this is breaking backwards compatibility."
MAPREDUCE-4052,Windows eclipse cannot submit job from Windows client to Linux/Unix Hadoop cluster.,"when I use the eclipse on the windows to submit the job. and the applicationmaster throw the exception:
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/mapreduce/v2/app/MRAppMaster
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapreduce.v2.app.MRAppMaster
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.hadoop.mapreduce.v2.app.MRAppMaster.  Program will exit.

The reasion is :
class Apps addToEnvironment function, use the
private static final String SYSTEM_PATH_SEPARATOR =
      System.getProperty(""path.separator"");

and will result the MRApplicationMaster classpath use the "";"" separator.

I suggest that nodemanger do the replace.

"
MAPREDUCE-4051,Remove the empty hadoop-mapreduce-project/assembly/all.xml file,"Jenkins picks up this XML and looks for ""test results"" in it. This file should be empty and removed. I could tell Jenkins not to pick this file up, but I'd rather also remove this empty file."
MAPREDUCE-4050,Invalid node link,"When a task is in *UNASSIGNED* state, node link is displayed as +null+.
But I think it is better to display the link as *N/A* rather than +null+."
MAPREDUCE-4049,plugin for generic shuffle service,"Support generic shuffle service as set of two plugins: ShuffleProvider & ShuffleConsumer.
This will satisfy the following needs:
# Better shuffle and merge performance. For example: we are working on shuffle plugin that performs shuffle over RDMA in fast networks (10gE, 40gE, or Infiniband) instead of using the current HTTP shuffle. Based on the fast RDMA shuffle, the plugin can also utilize a suitable merge approach during the intermediate merges. Hence, getting much better performance.
# Satisfy MAPREDUCE-3060 - generic shuffle service for avoiding hidden dependency of NodeManager with a specific version of mapreduce shuffle (currently targeted to 0.24.0).

References:
# Hadoop Acceleration through Network Levitated Merging, by Prof. Weikuan Yu from Auburn University with others, [http://pasl.eng.auburn.edu/pubs/sc11-netlev.pdf]
# I am attaching 2 documents with suggested Top Level Design for both plugins (currently, based on 1.0 branch)
# I am providing link for downloading UDA - Mellanox's open source plugin that implements generic shuffle service using RDMA and levitated merge.  Note: At this phase, the code is in C++ through JNI and you should consider it as beta only.  Still, it can serve anyone that wants to implement or contribute to levitated merge. (Please be advised that levitated merge is mostly suit in very fast networks) - [http://www.mellanox.com/content/pages.php?pg=products_dyn&product_family=144&menu_section=69]"
MAPREDUCE-4048,NullPointerException exception while accessing the Application Master UI,"{code:xml}
2012-03-21 10:21:31,838 ERROR [2145015588@qtp-957250718-801] org.apache.hadoop.yarn.webapp.Dispatcher: error handling URI: /mapreduce/attempts/job_1332261815858_2_8/m/KILLED
java.lang.reflect.InvocationTargetException
        at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:150)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)
        at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)
        at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
        .......
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: java.lang.NullPointerException
        at com.google.common.base.Joiner.toString(Joiner.java:317)
        at com.google.common.base.Joiner.appendTo(Joiner.java:97)
        at com.google.common.base.Joiner.appendTo(Joiner.java:127)
        at com.google.common.base.Joiner.join(Joiner.java:158)
        at com.google.common.base.Joiner.join(Joiner.java:166)
        at org.apache.hadoop.yarn.util.StringHelper.join(StringHelper.java:102)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.badRequest(AppController.java:319)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.attempts(AppController.java:286)
        ... 36 more
{code}"
MAPREDUCE-4045,RM UI -> Applications -> Application Master Link -> Job Link -> New Maps/Reduces leads to circular redirect error,"{code:xml}
HTTP ERROR 500

Problem accessing /proxy/application_1332261815858_0002/mapreduce/attempts/job_1332261815858_2_2/m/NEW. Reason:

    Circular redirect to 'http://HOST-192-168-47-207:41992/mapreduce/attempts/job_1332261815858_2_2/m/NEW'

Caused by:

org.apache.commons.httpclient.CircularRedirectException: Circular redirect to 'http://HOST-192-168-47-207:41992/mapreduce/attempts/job_1332261815858_2_2/m/NEW'
	at org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse(HttpMethodDirector.java:638)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:179)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:148)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:269)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:66)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
	at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
	at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:109)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:940)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

Powered by Jetty://
{code}"
MAPREDUCE-4044,YarnClientProtocolProvider does not honor mapred.job.tracker property,"The YarnClientProtocolProvider/YARNRunner/ResourceMgrDelegate bootstrap only looks for 'yarn.resourcemanager.address', they ignore 'mapred.job.tracker'

This breaks backward compatibility and creates issues in Oozie."
MAPREDUCE-4043,Secret keys set in Credentials are not seen by tasks,"The following scenario works in 0.20.205 but no longer works in 0.23:

1) During job submission, a secret key is set by calling jobConf.getCredentials().addSecretKey(Text, byte[])
2) A map task retrieves the secret key by calling jobConf.getCredentials().getSecretKey(Text)

In 205 the secret key is retrieved successfully but in 0.23 the secret key is missing."
MAPREDUCE-4042,unit test TestControlledMapReduceJob.testControlledMapReduceJob  fails,"unit test TestControlledMapReduceJob.testControlledMapReduceJob  fails.

This is an ant test: ant test -Dtestcase=TestControlledMapReduceJob

error:
Timeout occurred. Please note the time in the report does not reflect the time until the timeout.

"
MAPREDUCE-4041,TestMapredGroupMappingServiceRefresh unit test failures,"On branch-0.23 the following unit tests fail:

>>> org.apache.hadoop.security.TestMapredGroupMappingServiceRefresh.testGroupMappingRefresh 	
>>> org.apache.hadoop.security.TestMapredGroupMappingServiceRefresh.testRefreshSuperUserGroupsConfiguration "
MAPREDUCE-4040,History links should use hostname rather than IP address.,"While navigating from web page (eg: */cluster/app/<app-id>* ) to HS, browser displays IP address rather than hostname.

{code:title=JobHistoryUtils.java|borderStyle=solid}
    if (address.getAddress().isAnyLocalAddress() || 
        address.getAddress().isLoopbackAddress()) {
      sb.append(InetAddress.getLocalHost().getHostAddress());
    }	
}
{code} 

I *think* it is better to use hostname rather than IP address."
MAPREDUCE-4038,null pointer exception and invocationtarget exception in jobtracker logs,"I have written the code for scheduling in hadoop in which i have written two function schedule() and call() the schedule function calls the resource calculator for knowing the CPU usage and reliability values(explicitly i gave) but i am getting null pointer exception in the end. even i have written the code for getting active tracker names it shows null pointer exception. help me!

ERROR IN JOB TRACKER LOG FILE

2012-03-12 14:37:01,198 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = slavenode2.yahoo/192.168.1.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.20.1
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/common/tags/release-0.20.1-rc1 -r 810220; compiled by 'oom' on Tue Sep  1 20:55:56 UTC 2009
************************************************************/
2012-03-12 14:37:01,451 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2012-03-12 14:37:01,515 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.2 CPU usage: 0.0
2012-03-12 14:37:01,532 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.3 CPU usage: 0.0
2012-03-12 14:37:01,546 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.4 CPU usage: 0.0
2012-03-12 14:37:01,556 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.5 CPU usage: 0.0
2012-03-12 14:37:01,566 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.7 CPU usage: 0.0
2012-03-12 14:37:01,579 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.8 CPU usage: 0.0
2012-03-12 14:37:01,589 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.11 CPU usage: 0.0
2012-03-12 14:37:01,599 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.12 CPU usage: 0.0
2012-03-12 14:37:01,615 INFO org.apache.hadoop.mapred.resourcecalculator: 192.168.1.254 CPU usage: 0.0
2012-03-12 14:37:01,616 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:115)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1573)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:180)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:172)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:3699)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:113)
	... 4 more
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobQueueTaskScheduler1.schedule(JobQueueTaskScheduler1.java:75)
	at org.apache.hadoop.mapred.JobQueueTaskScheduler1.call(JobQueueTaskScheduler1.java:139)
	at org.apache.hadoop.mapred.JobQueueTaskScheduler1.<init>(JobQueueTaskScheduler1.java:50)
	... 9 more

2012-03-12 14:37:01,617 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at slavenode2.yahoo/192.168.1.2
************************************************************/


"
MAPREDUCE-4037,Fails to start proxy server due to webapps/proxy not found in CLASSPATH,"{code:xml}
2012-03-20 10:41:35,688 FATAL org.apache.hadoop.yarn.server.webproxy.WebAppProxy: Could not start proxy web server
java.io.FileNotFoundException: webapps/proxy not found in CLASSPATH
	at org.apache.hadoop.http.HttpServer.getWebAppsPath(HttpServer.java:532)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:224)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:164)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxy.start(WebAppProxy.java:90)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer.main(WebAppProxyServer.java:76)
2012-03-20 10:41:35,689 ERROR org.apache.hadoop.yarn.service.CompositeService: Error starting services org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer
org.apache.hadoop.yarn.YarnException: Could not start proxy web server
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxy.start(WebAppProxy.java:100)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer.main(WebAppProxyServer.java:76)
Caused by: java.io.FileNotFoundException: webapps/proxy not found in CLASSPATH
	at org.apache.hadoop.http.HttpServer.getWebAppsPath(HttpServer.java:532)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:224)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:164)
	at org.apache.hadoop.yarn.server.webproxy.WebAppProxy.start(WebAppProxy.java:90)
	... 2 more
{code}"
MAPREDUCE-4036,Streaming TestUlimit fails on CentOS 6,"CentOS 6 seems to have higher memory requirements than other distros and together with the new MALLOC library makes the TestUlimit to fail with exit status 134.
"
MAPREDUCE-4034,Unable to view task logs on history server with mapreduce.job.acl-view-job=*,"With log aggregation enabled, users other than the app owner or admins are sometimes unable to view the task logs on the history server even though they are in the ACL for the app.  The same users are able to see the configuration and counters.  Sometimes the users can see some task logs but not other task logs for the same application."
MAPREDUCE-4033,MiniMRClientClusterFactory is not setting the temp dir correctly in the conf used to init MiniMRYarnCluster,"Oozie testcases are failing randomly because MR2 reports the job as unknown.

This seems to happen when Oozie queries via JobClient.getJob(<JOBID>) for a <JOBID> that just finished.

{code}
org.apache.oozie.action.ActionExecutorException: JA017: Unknown hadoop job [job_1332176678205_0011] associated with action [0000000-120319101023910-oozie-tucu-W@pig-action].  Failing this action!
{code}

Oozie reports this error when JobClient.getJob(<JOBID>) returns NULL.

Looking at the mini cluster logs the job definitely run.

{code}
 find . -name ""*1332176678205_0011*""
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_0/application_1332176678205_0011
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_0/application_1332176678205_0011/container_1332176678205_0011_01_000002
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_0/application_1332176678205_0011/container_1332176678205_0011_01_000001
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_2/application_1332176678205_0011
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_2/application_1332176678205_0011/container_1332176678205_0011_01_000002
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_2/application_1332176678205_0011/container_1332176678205_0011_01_000001
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1332176678205_0011
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1332176678205_0011/container_1332176678205_0011_01_000002
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_3/application_1332176678205_0011/container_1332176678205_0011_01_000001
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_1/application_1332176678205_0011
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_1/application_1332176678205_0011/container_1332176678205_0011_01_000002
./core/target/org.apache.hadoop.mapred.MiniMRCluster/org.apache.hadoop.mapred.MiniMRCluster-logDir-nm-0_1/application_1332176678205_0011/container_1332176678205_0011_01_000001
{code}

It seems there is a gap until the the job is avail in the JH server.


If this gap is unavoidable we need to ensure Oozie always waits at least the gap time before querying for a job."
MAPREDUCE-4031,Node Manager hangs on shut down,"I have the MAPREDUCE-3862 changes which fixed this issue earlier and ""yarn.nodemanager.delete.debug-delay-sec"" set to default value but still getting this issue."
MAPREDUCE-4030,"If the nodemanager on which the maptask is executed is going down before the mapoutput is consumed by the reducer,then the job is failing with shuffle error","My cluster has 2 NM's.
The value of ""mapreduce.job.reduce.slowstart.completedmaps"" is set to 1.
When the job execution is in progress and Mappers has finished about 99% completion,one of the NM has gone down.
The job has failed with the following trace

""Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in fetcher#1 at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:123) at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:371) at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177) at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143) Caused by: java.io.IOException: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out. at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.checkReducerHealth(ShuffleScheduler.java:253) at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.copyFailed(ShuffleScheduler.java:187) at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:240) at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:152) """
MAPREDUCE-4028,Hadoop Capacity-Scheduler,"I config success capacity-scheduler
But when i run job has error:
  
Queue ""default"" does not exist

this error is :

12/01/18 16:21:04 ERROR security.UserGroupInformation: PriviledgedActionException as:adtech cause:org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.io.IOException: Queue ""default"" does not exist
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3943)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:563)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1083)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)
Caused by: java.io.IOException: Queue ""default"" does not exist
        at org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:437)
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3941)
        ... 11 more


i check hadoop queue 


hadoop queue -showacls
Queue acls for user :  john

Queue  Operations
=====================
queue1  submit-job,administer-jobs
queue2  submit-job,administer-jobs
queue3  submit-job,administer-jobs
queue4  submit-job,administer-jobs
queue5  submit-job,administer-jobs
queue6  submit-job,administer-jobs

my config in mapresite.xml:

       <property>
                <name>mapred.jobtracker.taskScheduler</name>
                <value>org.apache.hadoop.mapred.CapacityTaskScheduler</value>
        </property>

        <property>
                <name>mapred.queue.names</name>
                <value>queue1,queue2,queue3,queue4,queue5,queue6</value>
        </property>
        <property>

        <name>mapred.acls.enabled</name>
        <value>false</value>
        </property>
"
MAPREDUCE-4027,Document the minimum-allocation-mb and maximum-allocation-mb configurations,"None of the current yarn.scheduler.fifo.minimum/maximum-allocation-mb and yarn.scheduler.capacity.minimum/maximum-allocation-mb are documented anywhere. Without knowledge of these params, one can't change the default allocations. And the default allocations are pretty high btw (MAPREDUCE-4026).

We should document these in the Cluster Setup page at least."
MAPREDUCE-4026,Lower minimum-allocation-mb to sensible defaults,"The CapacityScheduler's minimum-allocation-mb is set to 1024.

The FIFO's minimum-allocation-mb meanwhile, is 128.

I propose changing the formers' minimum to that amount as well. 1024 is way too much as a default, wastes ""slots"" on NMs - and I also do not see why CS has to deviate that settings from the FIFO default."
MAPREDUCE-4025,AM can crash if task attempt reports bogus progress value,"If a task attempt reports a bogus progress value (e.g.: something above 1.0) then the AM can crash like this:

{noformat}
java.lang.ArrayIndexOutOfBoundsException: 12
	at org.apache.hadoop.mapred.PeriodicStatsAccumulator.extend(PeriodicStatsAccumulator.java:185)
	at org.apache.hadoop.mapred.WrappedPeriodicStatsAccumulator.extend(WrappedPeriodicStatsAccumulator.java:31)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.updateProgressSplits(TaskAttemptImpl.java:1043)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.access$4100(TaskAttemptImpl.java:136)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:1509)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$StatusUpdater.transition(TaskAttemptImpl.java:1490)
	at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:931)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:886)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:878)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:74)
	at java.lang.Thread.run(Thread.java:619)
{noformat}"
MAPREDUCE-4024,RM webservices can't query on finalStatus,The resource manager web service api to get the list of apps doesn't have a query parameter for finalStatus.  It has one for the state but since that isn't what is reported by app master so we really need to be able to query on both state and finalStatus.
MAPREDUCE-4020,Web services returns incorrect JSON for deep queue tree,"When the capacity scheduler is configured for more than two levels of queues, the web services API returns incorrect JSON for the subQueues field of some parent queues.  The ""subQueues"" field for parent queues should always be an array, but sometimes the field appears multiple times for a queue and as what looks like a CapacityQueueInfo object instead of an array.  Besides the sometimes-an-array-sometimes-not problem, parsing the result into a JSON object causes all but the last ""subQueues"" field to be discarded since they are overwritten by subsequent fields with the same name."
MAPREDUCE-4019,-list-attempt-ids  is not working,"while executing {noformat}bin/mapred  job -list-attempt-ids job_id map running{noformat}, we are getting IllegalArgumentexception."
MAPREDUCE-4017,Add jobname to jobsummary log,"We occasionally use jobsummary from the JobTracker to collect users' slot usage on our clusters.  It would be useful if the jobname was part of this jobsummary so that I don't need to join with other logs.

Same jobsummary.
  2012-03-15 16:05:55,919 INFO mapred.JobInProgress$JobSummary: jobId=job_201202160624_1089972,submitTime=1331827523632,launchTime=1331827528197,firstMapTaskLaunchTime=1331827536917,firstReduceTaskLaunchTime=1331827541251,firstJobSetupTaskLaunchTime=1331827528200,firstJobCleanupTaskLaunchTime=1331827551655,finishTime=1331827555919,numMaps=1,numSlotsPerMap=1,numReduces=1,numSlotsPerReduce=1,user=tortuga,queue=queue1,status=SUCCEEDED,mapSlotSeconds=13,reduceSlotsSeconds=10,clusterMapCapacity=____,clusterReduceCapacity=____

I'd like to see ""jobName"" added to the end.
"
MAPREDUCE-4013,Reduce task gets stuck when a M/R job is configured to tolerate failures,"When a M/R job is configured to run with some tolerance to task failures (via mapreduce.map.failures.maxpercent), then the reduce task of that job gets stuck in the shuffle phase. "
MAPREDUCE-4012,Hadoop Job setup error leaves no useful info to users (when LinuxTaskController is used),"When distributed cache pull fail on the TaskTracker, job webUI only shows 
{noformat}
Job initialization failed (255)
{noformat}
leaving users confused.  

On the TaskTracker log, there is a log with useful info 
{noformat}
2012-03-14 21:44:17,083 INFO org.apache.hadoop.mapred.TaskController: org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: 
Permission denied: user=user1, access=READ, inode=""testfile"":user3:users:rw-------
...
2012-03-14 21:44:17,083 INFO org.apache.hadoop.mapred.TaskController:   at org.apache.hadoop.filecache.TrackerDistributedCacheManager.downloadCacheObject(TrackerDistributedCacheManager.java:415)
...
2012-03-14 21:44:17,083 INFO org.apache.hadoop.mapred.TaskController:   at org.apache.hadoop.mapred.JobLocalizer.main(JobLocalizer.java:530)
{noformat}

	"
MAPREDUCE-4011,fix TestWritableJobConf failures,I think I broke this testcase with HADOOP-8167 as now deprecated/non-deprecated keys show in the iterator.
MAPREDUCE-4010,TestWritableJobConf fails on trunk,"TestWritableJobConf is currently failing two tests on trunk:

* testEmptyConfiguration
* testNonEmptyConfiguration

Appears to have been caused by HADOOP-8167."
MAPREDUCE-4009,AM container log links need to be clicked twice to get to the actual log file,"On the RM page->click on an application->Click on the link for ""AM Container logs""
This page contains links to stdout, stderr and syslog (i.e. <hostname>/node/containerlogs/container_1331751290995_0001_01_000001/*stdout*/?start=-4096 )

Clicking on any of them still shows the same page. NOW clicking on any of them will take you to the log. e.g. hostname/node/containerlogs/container_1331751290995_0001_01_000001/*stdout/stdout*/?start=-4096"
MAPREDUCE-4008,ResourceManager throws MetricsException on start up saying QueueMetrics MBean already exists,"{code:xml}
2012-03-14 15:22:23,089 WARN org.apache.hadoop.metrics2.util.MBeans: Error creating MBean object name: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default
org.apache.hadoop.metrics2.MetricsException: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default already exists!
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:117)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newMBeanName(DefaultMetricsSystem.java:102)
	at org.apache.hadoop.metrics2.util.MBeans.getMBeanName(MBeans.java:91)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:55)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:218)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:93)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:243)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl$1.postStart(MetricsSystemImpl.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl$3.invoke(MetricsSystemImpl.java:288)
	at $Proxy6.postStart(Unknown Source)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:183)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:155)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:54)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.start(ResourceManager.java:454)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:588)
Caused by: org.apache.hadoop.metrics2.MetricsException: Hadoop:service=ResourceManager,name=QueueMetrics,q0=default already exists!
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newObjectName(DefaultMetricsSystem.java:113)
	... 19 more
2012-03-14 15:22:23,090 WARN org.apache.hadoop.metrics2.util.MBeans: Failed to register MBean ""null""
javax.management.RuntimeOperationsException: Exception occurred trying to register the MBean
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:969)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
	at org.apache.hadoop.metrics2.util.MBeans.register(MBeans.java:57)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.startMBeans(MetricsSourceAdapter.java:218)
	at org.apache.hadoop.metrics2.impl.MetricsSourceAdapter.start(MetricsSourceAdapter.java:93)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSource(MetricsSystemImpl.java:243)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl$1.postStart(MetricsSystemImpl.java:227)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl$3.invoke(MetricsSystemImpl.java:288)
	at $Proxy6.postStart(Unknown Source)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.start(MetricsSystemImpl.java:183)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(MetricsSystemImpl.java:155)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.init(DefaultMetricsSystem.java:54)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.initialize(DefaultMetricsSystem.java:50)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.start(ResourceManager.java:454)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:588)
Caused by: java.lang.IllegalArgumentException: No object name specified
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:967)
	... 20 more
{code}"
MAPREDUCE-4007,JobClient getJob(JobID) should return NULL if the job does not exist (for backwards compatibility),To preserve backwards compatibility with MR1 JobClient.getJob() should return NULL if the job does not exist.
MAPREDUCE-4006,history server container log web UI sometimes combines stderr/stdout/syslog contents together,"When log aggregation is enabled, going to the job history server UI for the AM container log can show the log contents combined together.  Examples I've seen are portions of the syslog contents appended to either the stderr or stdout contents.  The log corruption does not occur when using the mapred job -logs command, so this appears to be something specific to the history server web UI."
MAPREDUCE-4005,AM container logs URL is broken for completed apps when log aggregation is enabled,"With log aggregation enabled and yarn.log.server.url pointing to the job history server, the AM container logs URL for a completed application fails with the error ""Cannot get container logs without an app owner"".  Looking at the code in the nodemanager to handle redirects to the log server, it appears the AM container log URL is missing a user name for the job.  I verified that tacking on the app's user name after the AM container log URL reported by the RM works."
MAPREDUCE-4003,log.index (No such file or directory) AND Task process exit with nonzero status of 126,"hello，I have dwelled on this hadoop(cdhu3) problem for 2 days,I have tried every google method.This is the issue: when ran hadoop example ""wordcount"" ,the tasktracker's log in one slave node presented such errors

 1.WARN org.apache.hadoop.mapred.DefaultTaskController: Task wrapper stderr: bash: /var/tmp/mapred/local/ttprivate/taskTracker/hdfs/jobcache/job_201203131751_0003/attempt_201203131751_0003_m_000006_0/taskjvm.sh: Permission denied

2.WARN org.apache.hadoop.mapred.TaskRunner: attempt_201203131751_0003_m_000006_0 : Child Error java.io.IOException: Task process exit with nonzero status of 126.

3.WARN org.apache.hadoop.mapred.TaskLog: Failed to retrieve stdout log for task: attempt_201203131751_0003_m_000003_0 java.io.FileNotFoundException: /usr/lib/hadoop-0.20/logs/userlogs/job_201203131751_0003/attempt_201203131751_0003_m_000003_0/log.index (No such file or directory)

I could not find similar issues in google,just got some posts seem a little relevant ,which suggest: A. the ulimit of hadoop user----but my ulimit is set large enough for this bundled example;B. the memory used by jvm,but my jvm only use Xmx200m,too small to exceed the limit of my machine ;C.the privilege of the mapred.local.dir and logs dir----I set them by ""chmod 777"";D .the disk space is full----there are enough space for hadoop in my log directory and mapred.local.dir.

Thanks for you all,I am really at my wit's end,I have spend days on it. I really appreciate any light!
"
MAPREDUCE-4002,MultiFileWordCount job fails if the input path is not from default file system,"In the MultiFileWordCount#CombineFileLineRecordReader, filesystem object has been initialized in the following way

{noformat}fs = FileSystem.get(context.getConfiguration());{noformat}

This causes, *fs* to be initialized with default filesystem. Therefore *fs* searchs for the input files on the default file system, which fails if the input path is from different source."
MAPREDUCE-4001,Improve MAPREDUCE-3789's fix logic by looking at job's slot demands instead,"In MAPREDUCE-3789, the fix had unfortunately only covered the first time assignment scenario, and the test had not really caught the mistake of using the condition of looking at available TT slots (instead of looking for how many slots a job's task demands).

We should change the condition of reservation in such a manner:

{code}
          if ((getPendingTasks(j) != 0 &&
               !hasSufficientReservedTaskTrackers(j)) &&
-                (taskTracker.getAvailableSlots(type) !=
+                !(j.getNumSlotsPerTask(type) >
                  getTTMaxSlotsForType(taskTrackerStatus, type))) {
{code}

I had not realized during the earlier ticket that j.getNumSlotsPerTask(type) did exist."
MAPREDUCE-3999,Tracking link gives an error if the AppMaster hasn't started yet,"Courtesy [~sseth]
{quote}
""The MRAppMaster died before writing anything.""

Steps to generate the error:
1. Setup a queue with 1 max active application per user
2. Submit a long running job to this queue.
3. Submit another job to the queue as the same user. Access the tracking URL
for job 2 directly or via Oozie (not via the RM link - which is rewritten once
the app starts).

This would exist in situations where the queue doesn't have enough capacity -
or for the small period of time between app submission and AM start.
{quote}"
MAPREDUCE-3998,taskjvm.sh: Permission denied,"run a simple code under cdh3u3, the slave node's map task and reduce task failed, this is the error info from the tasktracker's log:
2012-03-09 17:25:56,562 WARN org.apache.hadoop.mapred.DefaultTaskController: Exit code from task is : 126
2012-03-09 17:25:56,563 WARN org.apache.hadoop.mapred.DefaultTaskController: Task wrapper stderr: bash: /home/mapred/local/ttprivate/taskTracker/hdfs/jobcache/job_201203091543_0003/attempt_201203091543_0003_m_000002_0/taskjvm.sh: Permission denied
__I think the privilige of the /home/mapred/local/ is properly set"
MAPREDUCE-3996,zookeeper artifact is missing from the hadoop-dist assembly,"According to maven, zookeeper happens to be a dependency of hadoop-yarn-server-common. Yet it is missing from the final distribution assembly (and hence from the binary tarball)"
MAPREDUCE-3993,Graceful handling of codec errors during decompression,"When using a compression codec for intermediate compression, some cases of corrupt data can cause the codec to throw exceptions other than IOException (eg java.lang.InternalError). This will currently cause the whole reduce task to fail, instead of simply treating it like another case of a failed fetch."
MAPREDUCE-3992,Reduce fetcher doesn't verify HTTP status code of response,"Currently, the reduce fetch code doesn't check the HTTP status code of the response. This can lead to the following situation:
- the map output servlet gets an IOException after setting the headers but before the first call to flush()
- this causes it to send a response with a non-OK result code, including the exception text as the response body (response.sendError() does this if the response isn't committed)
- it will still include the response headers indicating it's a valid response

In the case of a merge-to-memory, the compression codec might then try to interpret the HTML response as compressed data, resulting in either a huge allocation (OOME) or some other nasty error. This bug seems to be present in MR1, but haven't checked trunk/MR2 yet."
MAPREDUCE-3991,Streaming FAQ has some wrong instructions about input files splitting,"Steaming docs say, at: http://hadoop.apache.org/common/docs/current/streaming.html#How+do+I+process+files%2C+one+per+map%3F

""Generate a file containing the full HDFS path of the input files. Each map task would get one file name as input.""

This is incorrect, as a file isn't split by lines, rather by size - for MR."
MAPREDUCE-3990,MRBench allows Long-sized input-lines value but parses CLI argument as an Integer,"MRBench has the following method:

{code}
public void generateTextFile(FileSystem fs, Path inputFile, long numLines, Order sortOrder) { ... }
{code}

The method is already set to accept a long datatype for numLines, for generating very large amount of data.

However, in {{MRBench#run(...)}}, the inputLines CLI parameter is parsed via an Integer.parseInt, causing numbers passed > Integer.MAX_VALUE to throw NumberFormatExceptions as a result.

The parsing should be Long.parseLong and the inputLines datatype should be switched to the same type as passed to the method (long)."
MAPREDUCE-3989,cap space usage of default log4j rolling policy (mr specific changes),see HADOOP-8149 for background on this.
MAPREDUCE-3988,mapreduce.job.local.dir doesn't point to a single directory on a node.,"After MAPREDUCE-3975, mapreduce.job.local.dir is set correctly for the tasks but it doesn't point to the same directory for all tasks running on the node.

It is a public API. Either we should point to a single directory or point it to all directories and change the documentation to say that it points to all dirs."
MAPREDUCE-3985,handleTaskAttemptCompletion() called twice for same task attempt from KillWaitAttemptKilledTransition & AttemptKilledTransition,"TaskImpl state changes to KILL_WAIT after an AttemptKilledTransition. When the attempt reports that it has actually been killed then KILL_WAIT transitions out via the KillWaitAttemptKilledTransition. Both these transitions send task completion events to Job with the same Killed state.

The handler simply puts them in a list and so nothing bad has happened till now."
MAPREDUCE-3984,TestDBJob and TestDataDrivenDBInputFormat timeout,org.apache.hadoop.mapreduce.lib.db.TestDBJob.testRun and org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits bith timeout.  They look like they timeout trying to shutdown the DB that is used as part of the testing.
MAPREDUCE-3983,"TestTTResourceReporting can fail, and should just be deleted",TestTTResourceReporting can fail.  It is an ant test for task trackers which shoudl just be removed because task trackers are no longer supported outside of the ant tests.
MAPREDUCE-3982,TestEmptyJob fails with FileNotFound,TestEmptyJob fails because teh FileOutputCommitter expects a directory to be created that is not created.  The FileOutputCommitter should either ignore the error or create the directory itself.
MAPREDUCE-3980,mr-jobhistory-daemon.sh should look for mapred script in HADOOP_MAPRED_HOME,"The following:

{noformat}
nohup nice -n $YARN_NICENESS ""$YARN_HOME""/bin/mapred --config $YARN_CONF_DIR $command ""$@"" > ""$log"" 2>&1 < /dev/null &
{noformat}

should be this instead:

{noformat}
nohup nice -n $YARN_NICENESS ""$HADOOP_MAPRED_HOME""/bin/mapred --config $YARN_CONF_DIR $command ""$@"" > ""$log"" 2>&1 < /dev/null &
{noformat}"
MAPREDUCE-3977,LogAggregationService leaks log aggregator objects,LogAggregationService adds log aggregator objects to the {{appLogAggregators}} map but never removes them.
MAPREDUCE-3976,TestRMContainerAllocator failing,"The following stack trace is being generated
========
org.apache.hadoop.metrics2.MetricsException: Metrics source JvmMetrics already exists!
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:126)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:107)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:216)
	at org.apache.hadoop.metrics2.source.JvmMetrics.create(JvmMetrics.java:80)
	at org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.create(MRAppMetrics.java:58)
	at org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.create(MRAppMetrics.java:54)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.<init>(MRAppMaster.java:186)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster.<init>(MRAppMaster.java:170)
	at org.apache.hadoop.mapreduce.v2.app.MRApp.<init>(MRApp.java:160)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator$1.<init>(TestRMContainerAllocator.java:372)
	at org.apache.hadoop.mapreduce.v2.app.TestRMContainerAllocator.testReportedAppProgress(TestRMContainerAllocator.java:371)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
========

This test fails when git trunk is reset to - commit 6689d99b38c7c562e8cae484207ad30ad7b56eb5
but passes when git trunk is reset to - commit f429fdaf78a02211c4faee54b1ee92822edc5741

"
MAPREDUCE-3975,Default value not set for Configuration parameter mapreduce.job.local.dir,"mapreduce.job.local.dir (formerly job.local.dir in 0.20) is not set by default. This is a regression from 0.20.205.

In 0.20.205, JobLocalizer.createWorkDir() constructs the ""$mapred.local.dir/taskTracker/$user/jobcache/$jobid/work"" path based on $user and $jobid, and then sets TaskTracker.JOB_LOCAL_DIR in the job's JobConf.

So far, I haven't found where this is done in 0.23. It could be that this is what should be done by LocalJobRunner.setupChildMapredLocalDirs(), but I am still investigating.

"
MAPREDUCE-3974,TestSubmitJob in MR1 tests doesn't compile after HDFS-1623 merge,"TestSubmitJob in MR1 tests doesn't compile after HDFS-1623 merge.

'ant compile-tests' doesn't work (since it's ant for MR1)."
MAPREDUCE-3972,Locking and exception issues in JobHistory Server.,"The JobHistory server's locking is inconsistent and wrong in some cases.  This is not super critical because the issues would only show up if a job is being cleaned up or moved from intermediate done to done, at the same time it is being parsed into a CompletedJob.  However the locking is slowing down the server in some cases, and is a ticking time bomb that needs to be addressed.

As part of this too we need to be sure that the Cleaner and Intermediate to Done migration threads handle exceptions properly.  Now it appears that the exception is logged, and the thread just shuts down.  This means that the history server could still be up and running for weeks and never remove old jobs.  "
MAPREDUCE-3969,ConcurrentModificationException in JobHistory.java,"{code}
2012-03-01 04:24:47,479 INFO org.apache.hadoop.mapred.JobInProgress: Task 'attempt_201202150320_3709_m_000148_0' has completed task_201202150320_3709_m_000148 successfully.
2012-03-01 04:24:47,479 INFO org.apache.hadoop.mapred.JobHistory: Logging failed for job job_201202150320_3709removing PrintWriter from FileManager
2012-03-01 04:24:47,479 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 8021, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@61069281, false, false, true, -21317) from <TASKTRACKER-IP>:450
41: error: java.io.IOException: java.util.ConcurrentModificationException
java.io.IOException: java.util.ConcurrentModificationException
        at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
        at java.util.AbstractList$Itr.next(AbstractList.java:343)
        at org.apache.hadoop.mapred.JobHistory.log(JobHistory.java:591)
        at org.apache.hadoop.mapred.JobHistory$MapAttempt.logFinished(JobHistory.java:1735)
        at org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2515)
        at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1200)
        at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4539)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3503)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3202)
        at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)
{code}

Task task_201202150320_3709_m_000148 was being marked as failed (but had not been restarted) at that moment and job execution was being freezed."
MAPREDUCE-3968,add support for getNumMapTasks() into mapreduce JobContext,"In old mapred api there was way to query number of mappers:

job.getNumMapTasks())

No such function exists in new mapreduce api"
MAPREDUCE-3964,ResourceManager does not have JVM metrics,ResourceManager is not creating a JvmMetrics instance on startup.
MAPREDUCE-3963,NodeManagers die on startup if they can't connect to the RM,"Steps to reproduce.
Start the NM when the RM is down. The NM tries 10 times, then exits. It should keep trying forever."
MAPREDUCE-3961,Map/ReduceSlotMillis computation incorrect,"Map/ReduceSlot millis are currently computed based on a fixed container size. They should instead be based on the minimum container size offered by the cluster.
There's another jira to rename these Counters - based on the resource type. This jira isn't to do that - just to fix the values. "
MAPREDUCE-3960,web proxy doesn't forward request to AM with configured hostname/IP,"If the host the web proxy is running on has an ip alias or similar and the config file is pointing to the hostname that is the aliased ip of the box, the web proxy will send the request from the base ip rather then the aliased ip and the AM will redirect that request to the proxy again instead of accepting it."
MAPREDUCE-3958,RM: Remove RMNodeState and replace it with NodeState,"RMNodeState is being sent over the wire after MAPREDUCE-3353. This has been done by cloning the enum into NodeState in yarn protocol records.
That makes RMNodeState redundant and it should be replaced with NodeState."
MAPREDUCE-3956,Remove the use of the deprecated Syncable.sync() method,This is a part of HADOOP-8124.
MAPREDUCE-3955,Replace ProtoOverHadoopRpcEngine with ProtobufRpcEngine.,We shouldn't have two rpc engines based on protocol buffers. ProtoOverHadoopRpcEngine in hadoop-yarn-common should be replaced by ProtobufRpcEngine in hadoop-common. 
MAPREDUCE-3954,Clean up passing HEAPSIZE to yarn and mapred commands.,"Currently the heap size for all of these is set in yarn-env.sh.  JAVA_HEAP_MAX is set to -Xmx1000m unless YARN_HEAPSIZE is set.  If it is set it will override JAVA_HEAP_MAX.  However, we do not always want to have the RM, NM, and HistoryServer with the exact same heap size.  It would be logical to have inside of yarn and mapred to set JAVA_HEAP_MAX if YARN_RESOURCEMANAGER_HEAPSIZE, YARN_NODEMANAGER_HEAPSIZE or HADOOP_JOB_HISTORYSERVER_HEAPSIZE are set respectively.  This is a bug because it is easy to configure the history server to store more entires then the heap can hold.  It is also a performance issue if we do not allow the history server to cache many entries on a large cluster.  "
MAPREDUCE-3953,Gridmix throws NPE and does not simulate a job if the trace contains null taskStatus for a task,"In a trace file, if a succeeded job contains a failed task, then that task's taskStatus will be null. This is causing NPE in Gridmix and then Gridmix is ignoring/not-considering such jobs for simulation. The job could succeed even with failed tasks if the job submitter in original cluster configured that job to tolerate failures using mapreduce.map.failures.maxpercent and mapreduce.reduce.failures.maxpercent."
MAPREDUCE-3952,"In MR2, when Total input paths to process == 1, CombinefileInputFormat.getSplits() returns 0 split.","Hive get unexpected result when using MR2(When using MR1, always get expected result).

In MR2, when Total input paths to process == 1, CombinefileInputFormat.getSplits() returns 0 split.

The calling code in Hive, in Hadoop23Shims.java:

InputSplit[] splits = super.getSplits(job, numSplits);

this get splits.length == 0.

In MR1, everything goes fine, the calling code in Hive, in Hadoop20Shims.java:

CombineFileSplit[] splits = (CombineFileSplit[]) super.getSplits(job, numSplits);

this get splits.length == 1."
MAPREDUCE-3951,Tasks are not evenly spread throughout cluster in MR2,"In MR1 (at least with the fair and fifo schedulers), if you submit a job that needs fewer resources than the cluster can provide, the tasks are spread relatively evenly across the node. For example, submitting a 100-map job to a 50-node cluster, each with 10 slots, results in 2 tasks on each machine. In MR2, however, the tasks would pile up on the first 10 nodes of the cluster, leaving the other nodes unused. This is highly suboptimal for many use cases."
MAPREDUCE-3947,yarn.app.mapreduce.am.resource.mb not documented,This configuration is useful but doesn't appear to be documented anywhere. 
MAPREDUCE-3946,"If a resource requirement is higher than available on any node, job should fail early","If you configure the NMs to have 1GB of RAM each, and then try to submit a job which has an AM resource requirement of 1.5GB, the job will neither run nor fail. Instead, it will slowly sop of all of the resources in the cluster as ""reservations"" despite the fact that it will never be able to schedule something. Instead, it should fail early indicating that the required memory allocation is infeasible."
MAPREDUCE-3945,JobHistoryServer should store tokens to authenticate clients across restart,JobHistoryServer gives off delegation tokens so that clients can talk to it. It needs to store them off somewhere to authenticate clients across the server restart
MAPREDUCE-3944,JobHistory web services are slower then the UI and can easly overload the JH,"When our first customer started using the Job History web services today the History Server ground to a halt.  We found 250 Jetty threads stuck on the following stack trace.

{noformat}
   java.lang.Thread.State: BLOCKED (on object monitor)
        at org.apache.hadoop.mapreduce.v2.hs.JobHistory.getJob(JobHistory.java:898)
        - waiting to lock <0x00002aaab364ba60> (a org.apache.hadoop.mapreduce.v2.hs.JobHistory)
        at org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getJobs(HsWebServices.java:188)
{noformat}

HsWebServices.java:188 corresponds to the /mapreduce/jobs service.

Looking at the code there are a number of optimizations that need to be done to improve its performance."
MAPREDUCE-3942,Randomize master key generation for ApplicationTokenSecretManager and roll it every so often," - Master key for authentication of AMs need to be automatically generated.
 - The key needs to be rolled every so often but AMs with old keys should continue to be able to talk to the RM."
MAPREDUCE-3940,ContainerTokens should have an expiry interval," - RM should generate the expiry time for a container
 - A ContainerToken should have its expire time encoded
 - NMs should reject containers with expired tokens.
 - Expiry interval for a ContainerToken is same as the expiry interval for a container."
MAPREDUCE-3936,Clients should not enforce counter limits ,"The code for enforcing counter limits (from MAPREDUCE-1943) creates a static JobConf instance to load the limits, which may throw an exception if the client limit is set to be lower than the limit on the cluster (perhaps because the cluster limit was raised from the default)."
MAPREDUCE-3935,Annotate Counters.Counter and Counters.Group as @Public,For clarity these inner classes should be marked as public stable.
MAPREDUCE-3933,Failures because MALLOC_ARENA_MAX is not set,"We have noticed a bunch of MapReduce test failures on CentOS 6 due to ""running beyond virtual memory limits"".

These tests fail with messages of the form:
{code}
[Node Status Updater] nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:getNodeStatus(254)) - Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1330401645767, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: ""Container [pid=16750,containerID=container_1330401645767_0001_01_000001] is running beyond virtual memory limits. Current usage: 220.5mb of 2.0gb physical memory used; 7.1gb of 4.2gb virtual memory used. Killing container
{code}

The failing tests are:
{code}
TestJobCounters
TestJobSysDirWithDFS
TestLazyOutput
TestMiniMRChildTask
TestMiniMRClientCluster
TestReduceFetchFromPartialMem
TestChild
TestMapReduceLazyOutput
TestJobOutputCommitter
TestMRAppWithCombiner
TestMRJobs
TestMRJobsWithHistoryService
TestMROldApiJobs
TestSpeculativeExecution
TestUberAM
{code}

I'll upload a patch momentarily."
MAPREDUCE-3932,MR tasks failing and crashing the AM when available-resources/headRoom becomes zero,"[~karams] reported this offline. One reduce task gets preempted because of zero headRoom and crashes the AM.
{code}
2012-02-23 11:30:15,956 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544
2012-02-23 11:30:16,959 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 44544
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Before Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:23 AssignedMaps:0 AssignedReduces:0 completedMaps:4 completedReduces:0 containersAllocated:4 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Got allocated containers 3
2012-02-23 11:30:16,965 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000006 to attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000007 to attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned to reduce
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container container_1329995034628_0983_01_000008 to attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Assign: PendingReduces:377 ScheduledMaps:6 ScheduledReduces:20 AssignedMaps:0 AssignedReduces:3 completedMaps:4 completedReduces:0 containersAllocated:7 containersReleased:0 hostLocalAssigned:0 rackLocalAssigned:4 availableResources(headroom):memory: 0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:20
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 2
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Recalculating schedule...
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.4 totalMemLimit:4608 finalMapMemLimit:2765 finalReduceMemLimit:1843 netScheduledMapMem:9216 netScheduledReduceMem:4608
2012-02-23 11:30:16,966 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down 0
2012-02-23 11:30:16,968 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host6 to /$rack6
2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,976 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host1 to /$rack1
2012-02-23 11:30:16,977 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,981 INFO [AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved $host9 to /$rack9
2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from UNASSIGNED to ASSIGNED
2012-02-23 11:30:16,982 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000002_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP
2012-02-23 11:30:16,983 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from ASSIGNED to KILL_CONTAINER_CLEANUP
2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,983 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,983 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000000_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:16,984 INFO [ContainerLauncher #3] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_CLEANUP for taskAttempt attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,987 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: CONTAINER_REMOTE_LAUNCH for taskAttempt attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,988 INFO [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Launching attempt_1329995034628_0983_r_000001_0
2012-02-23 11:30:16,988 ERROR [ContainerLauncher #9] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container was killed before it was launched
2012-02-23 11:30:17,061 INFO [ContainerLauncher #8] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000000_0 : 53990
2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000001_0 TaskAttempt Transitioned from KILL_CONTAINER_CLEANUP to KILL_TASK_CLEANUP
2012-02-23 11:30:17,077 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1329995034628_0983_r_000001_0: Container was killed before it was launched
2012-02-23 11:30:17,078 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Can't handle this event at current state for attempt_1329995034628_0983_r_000001_0
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_LAUNCH_FAILED at KILL_TASK_CLEANUP
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:926)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:135)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:870)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:862)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
	at java.lang.Thread.run(Thread.java:619)
2012-02-23 11:30:17,080 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: [attempt_1329995034628_0983_r_000000_0] using containerId: [container_1329995034628_0983_01_000006 on NM: [$host6:51529]
2012-02-23 11:30:17,081 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: attempt_1329995034628_0983_r_000000_0 TaskAttempt Transitioned from ASSIGNED to RUNNING
2012-02-23 11:30:17,207 INFO [ContainerLauncher #0] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for attempt_1329995034628_0983_r_000002_0 : 47960
2012-02-23 11:30:17,207 INFO [ContainerLauncher #1] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING attempt_1329995034628_0983_r_000002_0
2012-02-23 11:30:17,215 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: job_1329995034628_0983Job Transitioned from RUNNING to ERROR
2012-02-23 11:30:17,216 ERROR [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_COUNTER_UPDATE at ERROR
	at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:301)
	at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
	at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:657)
	at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.handle(JobImpl.java:111)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:848)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobEventDispatcher.handle(MRAppMaster.java:844)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
	at java.lang.Thread.run(Thread.java:619)

{code}"
MAPREDUCE-3931,MR tasks failing due to changing timestamps on Resources to download,"[~karams] reported this offline. Seems that tasks are randomly failing during gridmix runs:
{code}
2012-02-24 21:03:34,912 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1330116323296_0140_m_003868_0: RemoteTrace:
java.io.IOException: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875
       at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:90)
       at org.apache.hadoop.yarn.util.FSDownload.access$000(FSDownload.java:49)
       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:157)
       at org.apache.hadoop.yarn.util.FSDownload$1.run(FSDownload.java:155)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:396)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:153)
       at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:49)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
       at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
       at java.util.concurrent.FutureTask.run(FutureTask.java:138)
       at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
       at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
       at java.lang.Thread.run(Thread.java:619)
 at LocalTrace:
       org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Resource hdfs://hostname.com:8020/user/hadoop15/.staging/job_1330116323296_0140/job.jar changed on src filesystem (expected 2971811411, was 1330116705875
       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217)
       at org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:827)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:497)
       at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:222)
       at org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46)
       at org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57)
       at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:342)
       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1493)
       at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
       at java.security.AccessController.doPrivileged(Native Method)
       at javax.security.auth.Subject.doAs(Subject.java:396)
       at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
       at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1487)
{code}"
MAPREDUCE-3930,The AM page for a Reducer that has not been launched causes an NPE,"{noformat}
java.lang.reflect.InvocationTargetException
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:150)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:263)
        at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:178)
        at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:91)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:62)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)
        at com.google.inject.servlet.FilterDefinition.doFilter(FilterDefinition.java:163)
        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:58)
        at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:118)
        at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:113)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:120)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:940)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
        at org.mortbay.jetty.Server.handle(Server.java:322)
        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.yarn.util.ConverterUtils.toString(ConverterUtils.java:145)
        at org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskAttemptInfo.<init>(TaskAttemptInfo.java:69)
        at org.apache.hadoop.mapreduce.v2.app.webapp.dao.TaskAttemptInfo.<init>(TaskAttemptInfo.java:60)
        at org.apache.hadoop.mapreduce.v2.app.webapp.TaskPage$AttemptsBlock.render(TaskPage.java:76)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
        at org.apache.hadoop.yarn.webapp.View.render(View.java:233)
        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
        at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:80)
        at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:210)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.task(AppController.java:250) 
        ... 37 more
{noformat}"
MAPREDUCE-3929,output of mapred -showacl is not clear,output of 'mapred queue -showacls' is not very clear. This JIRA is aimed at either fixing that or adding something to the document to make it clear.
MAPREDUCE-3928,App GUI Cluster->Applications UI has confusing job status report,"The 0.23.1 Application GUI has some potential usability issues and confusion
points with respect to job status, from a user's perspective. 

Currently, when starting from the App UI base link of
http://<RM_HOST>:8088/cluster, the main window shows ""All Applications"", and in
the upper left corner is the ""Cluster"" pulldown, opened up showing the
following list:

About
Nodes
Applications
- New
- Submitted
- Accepted
- Running
- Finished
- Failed
- Killed
Scheduler

When jobs are submitted, they show up in the pre-final states, like Accepted
and Running. however after completion, no matter on the final outcome of a job
(SUCCESS, KILLED or FAILED), all jobs are listed under FINISHED, this is okay
since any completion result qualifies as Finished, but the FAILED and KILLED
jobs do not appear in the corresponding links for FAILED or KILLED. 

Clicking on FAILED or KILLED reports ""No data available in table"", even with
Failed or Killed jobs showing up in the FINISHED link. This can be very
confusing to a user checking on their jobs, especially for someone using the
direct URL links, such as:

http://<RM_HOST>:8088/cluster/apps/FAILED
http://<RM_HOST>:8088/cluster/apps/KILLED

Another potential issue is that the RM and AM each have their own
interpretation of a job's result, so the State and FinalStatus reported in the
Cluster Metrics display may not align with the defined states in the Cluster
pulldown. It would be useful to clearly delineate areas of the GUI wrt the
component visible states of a user's job."
MAPREDUCE-3927,Shuffle hang when set map.failures.percent,"When set mapred.max.map.failures.percent and there does have some failed maps, then shuffle will hang"
MAPREDUCE-3924,Partioning Failing in certain scenarios for Hadoop Streaming using Ruby,"We noticed a wierd scenario. The partitioning option fails in scenario below. The map reduce just aggregates values like a word count. However the key is having 2 parts.

Eg:
Input Records: (<key1|key2><tab><qty1|amt1|qty2|amt2|qty3|amt3>
1201|420 1|24.0|2|26.0|0|0.0
1200|420 1|24.0|2|26.0|0|0.0
1200|420 1|25.0|3|52.0|1|55.0
1403|400 1|25.0|3|52.0|1|55.0
1201|420 1|24.0|2|26.0|0|0.0
1201|420 1|24.0|2|26.0|0|0.0
1403|400 1|25.0|3|52.0|1|55.0

Partioning option: -k1,1 and Comparator option -k1,1n -k2,2n works fine and the output we get is expected output
1200|420 2|49.0|5|78.0|1|55.0
1201|420 3|72.0|6|78.0|0|0.0
1403|400 2|50.0|6|104.0|2|110.0

However if we use
Partioning option: -k1,1 -k2,2 and Comparator option -k1,1n -k2,2n then the output is faulty. Seems the same key does not go to same reducer in output we see duplicate records, however this does not happen to all records. A hypothetical faulty output based on above input is:
1200|420 1|24.0|2|26.0|0|0.0
1201|420 3|72.0|6|78.0|0|0.0
1403|400 2|50.0|6|104.0|2|110.0
1200|420 1|25.0|3|52.0|1|55.0

See that records with the key (1200|420) is not aggregated. This can happen only if the record does not go to the same reducer after partioning.

Any clue why this is happening? I could not understanding what is going wrong.




"
MAPREDUCE-3922,Fix the potential problem compiling 32 bit binaries on a x86_64 host.,"MAPREDUCE-3880 specifies that {{-m32}} be passed to gcc to ensure that a 32-bit binary is built. On my Amazon Linux with a x86_64 architecture, I could not build the native container-executor because the configure script exited with an error when trying to use gcc (version 4.4.5) with this flag.

Adds a comment to {{hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/pom.xml}} regarding package requirement for glibc-devel.i686 or glibc-devel.i386 package on yum-based (RHEL, Centos, Amazon) Linux distributions.

"
MAPREDUCE-3921,MR AM should act on the nodes liveliness information when nodes go up/down/unhealthy,
MAPREDUCE-3920,Revise yarn default port number selection,"The default port numbers chosen for nodemanager and resourcemanager are random and widely spread out creating unnecessary overhead in deployments where site operators care, and deploy many clusters.

Current and proposed new default ports are as follows:

Current		New		Config Property	
------- 	---             ---------------
4344		8040		yarn.nodemanager.localizer.address	
45454		8041		yarn.nodemanager.address	
9999		8042		yarn.nodemanager.webapp.address	

8030		8030(NC)	yarn.resourcemanager.scheduler.address
8025		8031		yarn.resourcemanager.resource-tracker.address
8040		8032		yarn.resourcemanager.address
8141		8033		yarn.resourcemanager.admin.address


Affected files include:  embedded defaults (YarnConfiguration.java), yarn-default.xml, documentation and unit tests.
 "
MAPREDUCE-3919,Redirecting to job history server takes hours,"Saw the following message happening regularly, the job end up success, but reconnecting job history server takes a long time (>10 hours sometimes).

2012-02-24 03:49:05,226 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: hrt11n31.cc1.ygridcore.net/98.137.234.159:44716. Already tried 0 time(s).
2012-02-24 03:49:05,229 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-02-24 03:49:06,233 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s).
2012-02-24 03:49:07,236 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s).
2012-02-24 03:49:08,239 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s).
2012-02-24 03:49:09,242 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 3 time(s).
2012-02-24 03:49:10,245 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 4 time(s).
2012-02-24 03:49:11,248 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 5 time(s).
2012-02-24 03:49:12,251 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 6 time(s).
2012-02-24 03:49:13,254 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 7 time(s).
2012-02-24 03:49:14,257 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 8 time(s).
2012-02-24 03:49:15,260 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 9 time(s).
......
2012-02-24 18:10:35,711 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-02-24 18:10:36,714 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s).
2012-02-24 18:10:37,717 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s).2012-02-24 18:10:38,784 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s).2012-02-24 18:10:39,787 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 3 time(s).
2012-02-24 18:10:40,791 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 4 time(s).
2012-02-24 18:10:41,793 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 5 time(s).2012-02-24 18:10:42,796 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 6 time(s).2012-02-24 18:10:43,799 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 7 time(s).
2012-02-24 18:10:44,802 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 8 time(s).
2012-02-24 18:10:45,805 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 9 time(s).
2012-02-24 18:10:45,808 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-02-24 18:10:46,810 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 0 time(s).2012-02-24 18:10:47,813 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 1 time(s).2012-02-24 18:10:48,815 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: 0.0.0.0/0.0.0.0:10020. Already tried 2 time(s).
2012-02-24 18:10:49,120 [main] WARN  org.apache.hadoop.mapred.ClientServiceDelegate - Error from remote end: Unknown job job_1330051901509_0017
2012-02-24 18:10:49,120 [main] ERROR org.apache.hadoop.security.UserGroupInformation - PriviledgedActionException as:pigtester (auth:SIMPLE) cause:org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1330051901509_0017"
MAPREDUCE-3918,proc_historyserver no longer in command line arguments for HistoryServer,This java arg is missing from the command line and needs to be replaced
MAPREDUCE-3916,various issues with running yarn proxyserver,"Seem like yarn proxyserver is not operational when running out of the 0.23.1 RC2 tarball.

# Setting yarn.web-proxy.address to match yarn.resourcemanager.address doesn't disable the proxyserver (althought not setting yarn.web-proxy.address at all correctly disable it and produces a message: org.apache.hadoop.yarn.YarnException: yarn.web-proxy.address is not set so the proxy will not run). This contradicts the documentation provided for yarn.web-proxy.address in yarn-default.xml

# Setting yarn.web-proxy.address and running the service results in the following:

{noformat}
$ ./sbin/yarn-daemon.sh start proxyserver 
starting proxyserver, logging to /tmp/hadoop-0.23.1/logs/yarn-rvs-proxyserver-ahmed-laptop.out
/usr/java/64/jdk1.6.0_22/bin/java -Dproc_proxyserver -Xmx1000m -Dhadoop.log.dir=/tmp/hadoop-0.23.1/logs -Dyarn.log.dir=/tmp/hadoop-0.23.1/logs -Dhadoop.log.file=yarn-rvs-proxyserver-ahmed-laptop.log -Dyarn.log.file=yarn-rvs-proxyserver-ahmed-laptop.log -Dyarn.home.dir= -Dyarn.id.str=rvs -Dhadoop.root.logger=INFO,DRFA -Dyarn.root.logger=INFO,DRFA -Djava.library.path=/tmp/hadoop-0.23.1/lib/native -Dyarn.policy.file=hadoop-policy.xml -Dhadoop.log.dir=/tmp/hadoop-0.23.1/logs -Dyarn.log.dir=/tmp/hadoop-0.23.1/logs -Dhadoop.log.file=yarn-rvs-proxyserver-ahmed-laptop.log -Dyarn.log.file=yarn-rvs-proxyserver-ahmed-laptop.log -Dyarn.home.dir=/tmp/hadoop-0.23.1 -Dhadoop.root.logger=INFO,DRFA -Dyarn.root.logger=INFO,DRFA -Djava.library.path=/tmp/hadoop-0.23.1/lib/native -classpath /tmp/hadoop-0.23.1/etc/hadoop:/tmp/hadoop-0.23.1/etc/hadoop:/tmp/hadoop-0.23.1/etc/hadoop:/tmp/hadoop-0.23.1/share/hadoop/common/lib/*:/tmp/hadoop-0.23.1/share/hadoop/common/*:/tmp/hadoop-0.23.1/share/hadoop/hdfs:/tmp/hadoop-0.23.1/share/hadoop/hdfs/lib/*:/tmp/hadoop-0.23.1/share/hadoop/hdfs/*:/tmp/hadoop-0.23.1/share/hadoop/mapreduce/lib/*:/tmp/hadoop-0.23.1/share/hadoop/mapreduce/*:/tmp/hadoop-0.23.1/share/hadoop/mapreduce/*:/tmp/hadoop-0.23.1/share/hadoop/mapreduce/lib/* org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer
{noformat}

with the following message found in the logs:

{noformat}
2012-02-24 09:26:31,099 FATAL org.apache.hadoop.yarn.server.webproxy.WebAppProxy: Could not start proxy web server
java.io.FileNotFoundException: webapps/proxy not found in CLASSPATH
        at org.apache.hadoop.http.HttpServer.getWebAppsPath(HttpServer.java:532)
        at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:224)
        at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:164)
        at org.apache.hadoop.yarn.server.webproxy.WebAppProxy.start(WebAppProxy.java:85)
        at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
        at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServer.main(WebAppProxyServer.java:76)
{noformat}"
MAPREDUCE-3914,Mismatched free() / delete / delete [] in HadoopPipes,"When running valgrind on a simple MapReduce pipes job, valgrind identifies a mismatched new / delete:

==20394== Mismatched free() / delete / delete []
==20394==    at 0x4C27FF2: operator delete(void*) (vg_replace_malloc.c:387)
==20394==    by 0x4328A5: HadoopPipes::runTask(HadoopPipes::Factory const&) (HadoopPipes.cc:1171)
==20394==    by 0x424C33: main (ProcessRow.cpp:118)
==20394==  Address 0x9c5b540 is 0 bytes inside a block of size 131,072 alloc'd
==20394==    at 0x4C2864B: operator new[](unsigned long) (vg_replace_malloc.c:305)
==20394==    by 0x431E5D: HadoopPipes::runTask(HadoopPipes::Factory const&) (HadoopPipes.cc:1121)
==20394==    by 0x424C33: main (ProcessRow.cpp:118)
==20394== 
==20394== Mismatched free() / delete / delete []
==20394==    at 0x4C27FF2: operator delete(void*) (vg_replace_malloc.c:387)
==20394==    by 0x4328AF: HadoopPipes::runTask(HadoopPipes::Factory const&) (HadoopPipes.cc:1172)
==20394==    by 0x424C33: main (ProcessRow.cpp:118)
==20394==  Address 0x9c7b580 is 0 bytes inside a block of size 131,072 alloc'd
==20394==    at 0x4C2864B: operator new[](unsigned long) (vg_replace_malloc.c:305)
==20394==    by 0x431E6A: HadoopPipes::runTask(HadoopPipes::Factory const&) (HadoopPipes.cc:1122)
==20394==    by 0x424C33: main (ProcessRow.cpp:118)

The new [] calls in Lines 1121 and 1122 of HadoopPipes.cc:
        bufin = new char[bufsize];
        bufout = new char[bufsize];
should have matching delete [] calls but are instead bracketed my delete on lines 1171 and 1172:
      delete bufin;
      delete bufout;
So these should be replaced by delete[]
"
MAPREDUCE-3913,RM application webpage is unresponsive after 2000 jobs,"After >2000 jobs have been submitted, trying to load the resourcemanager's applications page results in the following exception on the RM:

{code}
java.lang.IllegalArgumentException: No enum cons
t class org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState.json
        at java.lang.Enum.valueOf(Enum.java:196)
        at org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState.valueOf(RMAppState.java:21)
        at org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlock.render(AppsBlock.java:66)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
        at org.apache.hadoop.yarn.webapp.View.render(View.java:233)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock$Block.subView(HtmlBlock.java:38)
        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet._(Hamlet.java:30345)
        at org.apache.hadoop.yarn.server.resourcemanager.webapp.AppsBlockWithMetrics.render(AppsBlockWithMetrics.java:29)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
        at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
        at org.apache.hadoop.yarn.webapp.View.render(View.java:233)
        at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
        at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
        at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
        at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
....
{code}

"
MAPREDUCE-3912,getPriority() method within the JobHistoryParser JobInfo class fails,"When you use the following set of statements:
{code}
JobHistoryParser.JobInfo jobInfo;
jobInfo.getPriority(); //fails
{code}

The problem is that {code}   public String getPriority() { return priority.toString(); } {code} will fail if the ""priority"" is null. 

I was expecting priority to return a ""NORMAL"" value

Viraj
"
MAPREDUCE-3910,user not allowed to submit jobs even though queue -showacls shows it allows,User is not allowed to submit applications to a queue even though the queue is configured correctly and mapred queue -showacls shows that the user is allowed to submit
MAPREDUCE-3909,javadoc the Service interfaces,"The {{Service}} interface doesn't describe what it does.

The {{ServiceStateChangeListener}} interface doesn't define when the method is called, whether it is sync or async with a state change etc -you have to look in the code for this.

Document for others"
MAPREDUCE-3908,jobhistory server trying to load job conf file from wrong location,"I have seen a few instance where I try to click on the job configuration link from the job history server web ui and it gives a 500 message.  Looking at the job history server log file it shows an exception like:

2012-02-23 22:16:32,519 ERROR org.apache.hadoop.yarn.webapp.View: Error while reading hdfs://host.com:9000/home/hadoop/mapred/history/done_intermediate/user/job_1330033607650_0001_conf.xml
java.io.FileNotFoundException: File does not exist: /home/hadoop/mapred/history/done_intermediate/user/job_1330033607650_0001_conf.xml
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:746)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:709)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:681)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:302)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:2

If I go look in hdfs, it doesn't exist in the done_intermediate directory anymore, it exists in the done directory structure.  hdfs://host.com:9000/home/hadoop/mapred/history/done/2012/02/23/000000/job_1330033607650_0001_conf.xml

I'm not exactly sure how to reproduce this, but I definitely see it every once in a while."
MAPREDUCE-3907,Document entries mapred-default.xml for the jobhistory server.,"The following configuration properties are documented in http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/ClusterSetup.html#Running_Hadoop_in_Secure_Mode

* mapreduce.jobhistory.address	
* mapreduce.jobhistory.keytab
* mapreduce.jobhistory.principal

Create a {{hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs/src/main/resources/mapred-default.xml}} that documents these properties and provides default values.


"
MAPREDUCE-3906,Fix inconsistency in documentation regarding mapreduce.jobhistory.principal,"Currently the documentation on http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/ClusterSetup.html#Running_Hadoop_in_Secure_Mode is inconsistent on the recommended or default value of {{{mapreduce.jobhistory.principal}}}. In the section with the header: ""MapReduce JobHistory Server"" the principal ""jhs/..."" is used, but later, in the section with the header: ""Configurations for MapReduce JobHistory Server:"", the principal ""mapred/..."" is used. 

Fix is to replace ""mapred/..."" with ""jhs/...""."
MAPREDUCE-3904,[NPE] Job history produced with mapreduce.cluster.acls.enabled false can not be viewed with mapreduce.cluster.acls.enabled true,"Job history page displays 'null'. It looks like job history files only populate job acls when mapreduce.cluster.acls.enabled is true. Upon reading job history files, getAcls can return null, throwing an exception on the HsJobBlock page."
MAPREDUCE-3903,no admin override to view jobs on mr app master and job history server,"in 1.0 there was a config mapreduce.cluster.administrators that allowed administrators to view anyones job.  That no longer works on yarn.
yarn has the new config yarn.admin.acl but it appears the mr app master and job history server don't use that.  "
MAPREDUCE-3901,lazy load JobHistory Task and TaskAttempt details,The job history UI and MRClientProtocol calls routed via JobHistory are very slow for large jobs. Some of this time is spent parsing the history file. A good chunk is spent pre-creating lots of objects which may never be used. Those can be create when required - bringing down the load times of job history pages and getJobReport etc calls to approximately the history file parse time.
MAPREDUCE-3900,mr-jobhistory-daemon.sh should rely on MAPREDUCE env. variables instead of the YARN ones,"It nice to see yarn-deamo.sh be split into a separate script for managing MR service(s), but once that has happened we should go all the way and make it configurable as an MR entity."
MAPREDUCE-3898,Hadoop for Windows - Interfacing with Windows to manage MR tasks,
MAPREDUCE-3897,capacity scheduler - maxActiveApplicationsPerUser calculation can be wrong,"The capacity scheduler calculates the maxActiveApplications and the maxActiveApplicationsPerUser based on the config yarn.scheduler.capacity.maximum-applications or default 10000.  

MaxActiveApplications = max ( ceil ( clusterMemory/minAllocation * maxAMResource% * absoluteMaxCapacity), 1)  

MaxActiveAppsPerUser = max( ceil (maxActiveApplicationsComputedAbove * (userLimit%/100) * userLimitFactor), 1) 

maxActiveApplications is already multiplied by the queue absolute MAXIMUM capacity, so if max capacity > capacity and if you have user limit factor 1 (which is the default) and only 1 user is running, that user will not be allowed to use over the queue capacity, so having it relative to MAX capacity doesn't make sense.  That user could easily end up in a deadlock and all its space used by application masters.
"
MAPREDUCE-3896,pig job through oozie hangs ,running pig job on oozie hangs due to race condition
MAPREDUCE-3894,0.23 and trunk MR builds fail intermittently,"The builds occasionally report ABORTED or FAILURE, which is not caused by the new code change included in the builds. We are not sure since when they have been broken this way, but Bobby's guess is around Feb 10."
MAPREDUCE-3893,allow capacity scheduler configs maximum-applications and maximum-am-resource-percent configurable on a per queue basis,"The capacity scheduler configs for  maximum-applications and maximum-am-resource-percent are currently configured globally and then made proportional to each queue based on its capacity. There are times when this may not work well.  some exampless -  if you have a queue that is running on uberAM jobs, the jobs a queue is running always has a small number of containers, and then you have the opposite where in a queue with very small capacity, you may want to limit the am resources even more so you don't end up deadlocked with all your capacity being used for app masters.

I think we should make those configurable on a per queue basis."
MAPREDUCE-3890,Change to nodemanager build now requires 32-bit libraries,"Sometime during the last week, someone committed a change to:

hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/pom.xml

that inserted a -m32 in:


               <configureEnvironment>
                 <property>
                   <name>CFLAGS</name>
                  <value>-DHADOOP_CONF_DIR=${container-executor.conf.dir} -m32</value>


This breaks the build on 64-bit systems that do not have 32-bit libraries installed. The change was actually not required as 64-bit support for JNI and JVMs is readily available and installed by default on many 64-bit systems. Removing the flag results in a completed and functional build.

If mandating 32-bit builds is desired, then a better solution would be to provide a configure flag such as -DHADOOP_32bit_MODE, perhaps with a corresponding flag for 64-bit. Regardless, locking the system to 32-bit builds seems a tad extreme.

"
MAPREDUCE-3889,"job client tries to use /tasklog interface, but that doesn't exist anymore","if you specify  -Dmapreduce.client.output.filter=SUCCEEDED option when running a job it tries to fetch task logs to print out on the client side from a url like: http://nodemanager:8080/tasklog?plaintext=true&attemptid=attempt_1329857083014_0003_r_000000_0&filter=stdout

It always errors on this request with: Required param job, map and reduce

We saw this error when using distcp and the distcp failed. I'm not sure if it is mandatory for distcp or just informational purposes.  I'm guessing the latter.

"
MAPREDUCE-3887,Jenkins mapred commit build tries an unknown target,"I saw the following in the mrv1 ant build portion of Hadoop-Mapreduce-trunk-Commit. The 0.23 build might have the same thing.

{panel}
+ /home/jenkins/tools/ant/latest/bin/ant -Dversion=0.24.0-SNAPSHOT -Dresolvers=internal -Declipse.home=/home/jenkins/tools/eclipse/latest -Dfindbugs.home=/home/jenkins/tools/findbugs/latest -Dforrest.home=/home/jenkins/tools/forrest/latest -Dcompile.c++=true -Dcompile.native=true create-c++-configure binary

....

BUILD FAILED
Target ""binary"" does not exist in the project ""Hadoop"". 
{panel}"
MAPREDUCE-3885,Apply the fix similar to HADOOP-8084,Apply the fix similar to HADOOP-8084
MAPREDUCE-3884,PWD should be first in the classpath of MR tasks,"Currently the current directory is not part of the classpath, this is a regression from MR1 and existing applications assuming this fail to work properly."
MAPREDUCE-3883,Document yarn.nodemanager.delete.debug-delay-sec configuration property,"If you are using Yarn's nodemanager, you can add to your configuration:

{noformat}
  <property>
    <name>yarn.nodemanager.delete.debug-delay-sec</name>
    <value>10000000</value>
  </property>
{noformat}

to save the environmental directories of the applications (by default in {{/tmp/nm-local-dir}}) that the nodemanager starts so that you can examine them later.

Set the above value long enough so that you have time to examine the contents before the nodemanager's {{DeletionService}} removes them.

This setting is defined in {{hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java}}, and used in {{hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/DeletionService.java}}.

It's a useful configuration setting for developers, but seems not to be documented currently (see http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/yarn-default.xml).


"
MAPREDUCE-3881,building fail under Windows,"hadoop-mapreduce-project\hadoop-yarn\hadoop-yarn-common\pom.xml is not portable.

     <execution>
            <id>generate-version</id>
            <phase>generate-sources</phase>
            <configuration>
              <executable>scripts/saveVersion.sh</executable>
              <arguments>
                <argument>${project.version}</argument>
                <argument>${project.build.directory}</argument>
              </arguments>
            </configuration>
            <goals>
              <goal>exec</goal>
            </goals>
          </execution>

when I built it under windows , I got a such error:

[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (gen
erate-version) on project hadoop-yarn-common: Command execution failed. Cannot r
un program ""scripts\saveVersion.sh"" (in directory ""D:\os\hadoopcommon\hadoop-map
reduce-project\hadoop-yarn\hadoop-yarn-common""): CreateProcess error=2, ????????
? -> [Help 1]

we should modify it like this: (copied from hadoop-common-project\hadoop-common\pom.xml)
            <configuration>
              <target>
                <mkdir dir=""${project.build.directory}/generated-sources/java""/>
                <exec executable=""sh"">
                  <arg
                      line=""${basedir}/dev-support/saveVersion.sh ${project.version} ${project.build.directory}/generated-sources/java""/>
                </exec>
              </target>
            </configuration>
          </execution>"
MAPREDUCE-3880,Allow for 32-bit container-executor,Currently we can't pass in -m32 to LCE build.
MAPREDUCE-3879,yarn script has vestiges of jsvc that need to be cleaned up,"If nodemanager is started under root (I know, I know). The following is displayed:

{noformat}
/usr/lib/jvm/java-6-sun/bin/java -Dproc_nodemanager -Xmx1000m -jvm server -Dhadoop.log.dir=/var/log/yarn -Dyarn.log.dir=/var/log/yarn -Dhadoop.log.file=yarn-yarn-nodemanager-ahmed-laptop.log -Dyarn.log.file=yarn-yarn-nodemanager-ahmed-laptop.log -Dyarn.home.dir=/usr/lib/hadoop -Dhadoop.root.logger=INFO,DRFA -Dyarn.root.logger=INFO,DRFA -Djava.library.path=/usr/lib/hadoop/lib/native -classpath /etc/hadoop/conf:/etc/hadoop/conf:/etc/hadoop/conf:/usr/lib/hadoop/share/hadoop/common/*::/usr/lib/hadoop/*:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/:/usr/lib/hadoop/share/hadoop/hdfs/*:/usr/lib/hadoop/share/hadoop/mapreduce/*:/share/hadoop/mapreduce/*:/usr/lib/hadoop/share/hadoop/mapreduce/*:/usr/lib/hadoop/share/hadoop/mapreduce/lib/*:/etc/hadoop/conf/nm-config/log4j.properties org.apache.hadoop.yarn.server.nodemanager.NodeManager
Unrecognized option: -jvm
Could not create the Java virtual machine.
{noformat}

The culprit is this bit of code that looks suspiciously like what used to be in bin/hdfs in support of jsvc launch:

{noformat}
elif [ ""$COMMAND"" = ""nodemanager"" ] ; then
  CLASSPATH=${CLASSPATH}:$YARN_CONF_DIR/nm-config/log4j.properties
  CLASS='org.apache.hadoop.yarn.server.nodemanager.NodeManager'
  if [[ $EUID -eq 0 ]]; then
    YARN_OPTS=""$YARN_OPTS -jvm server $YARN_NODEMANAGER_OPTS""
  else
    YARN_OPTS=""$YARN_OPTS -server $YARN_NODEMANAGER_OPTS""
  fi
{noformat}"
MAPREDUCE-3878,Null user on filtered jobhistory job page,"If jobhistory/job.* is filtered to bypass acl, resulting page will always show Null user. This differs from 0.20 where filtering on this page, bypasses security to allow all access to the page. essentially passes a null user to AppController where an exception is thrown. If a null user is detected, we should acl checking is disabled on this page."
MAPREDUCE-3877,Add a test to formalise the current state transitions of the yarn lifecycle,"Add a test service that counts the number of times it's state methods are called; and can be set to raise an exception on any such entry. Use it to show what the current lifecycle state model is, so that unintentional regressions can be detected. 

It will also act as a foundation for intentional changes to that lifecycle"
MAPREDUCE-3874,Decommission nodes link is not working,Decommisioned node link  is not displaying the nodes that got decommissioned
MAPREDUCE-3873,Nodemanager is not getting decommisioned if the absolute ip is given in exclude file.,"Configure absolute ip in ""yarn.resourcemanager.nodes.exclude-path"" and try to decommission the node.
It is not getting decommisioned.But if the hostname is given, decommissioning is happening.

I have also given the ip-host mapping of each machine in /etc/hosts.(i,e in every machine the other machines ip-host mapping is specified)."
MAPREDUCE-3872,event handling races in ContainerLauncherImpl and TestContainerLauncher,"TestContainerLauncher is failing intermittently for me.

{noformat}
junit.framework.AssertionFailedError: Expected: <null> but was: Expected 22 but found 21
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertNull(Assert.java:233)
	at junit.framework.Assert.assertNull(Assert.java:226)
	at org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testPoolSize(TestContainerLauncher.java:117)
{noformat}

Patch momentarily."
MAPREDUCE-3871,Allow symlinking in LocalJobRunner DistributedCache,Currently the LocalJobRunner doesn't create symlinks for files in the DistributedCache. It is safe to create symlinks if files of the same name don't exist. LocalJobRunner should also delete the symlinks when the job has completed.
MAPREDUCE-3870,Invalid App Metrics,I have observed incorrect *Apps Completed* and *Apps Pending* metrics when an application has failed or finished (successful) after multiple attempts(failures).
MAPREDUCE-3869,Distributed shell application fails with NoClassDefFoundError,"Distributed shell application always fails to start the application master with the following error.
\\

{code:xml}
12/02/16 05:35:25 FATAL distributedshell.ApplicationMaster: Error running ApplicationMaster
java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/ipc/YarnRPC
	at org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.<init>(ApplicationMaster.java:252)
	at org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.main(ApplicationMaster.java:195)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.ipc.YarnRPC
	at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:303)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
	at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:316)
	... 2 more
{code}
"
MAPREDUCE-3868,Reenable Raid,Currently Raid is outdated and not compiled. Make it compile.
MAPREDUCE-3867,MiniMRYarn/MiniYarn uses fixed ports,"This presents issues if there are other processes using those ports. Also, if multitasking among dev environments using Mini* things start to fail."
MAPREDUCE-3866,bin/yarn prints the command line unnecessarily,"For commands like rmadmin, version etc, it also prints the whole command line unnecessarily.

This was /me from long time ago, pre alpha :)"
MAPREDUCE-3864,Fix cluster setup docs for correct SNN HTTPS parameters,"Currently the docs reference dfs.namenode.secondary.https-address, which does not exist. Instead it should reference dfs.namenode.secondary.https-port (new name of dfs.secondary.https.port as of HDFS-2950)"
MAPREDUCE-3863,0.22 branch mvn deploy is not publishing hadoop-streaming JAR,Without this JAR Oozie cannot be built/tested against 0.22
MAPREDUCE-3862,Nodemanager can appear to hang on shutdown due to lingering DeletionService threads,"When a nodemanager attempts to shutdown cleanly, it's possible for it to appear to hang due to lingering DeletionService threads.  This can occur when yarn.nodemanager.delete.debug-delay-sec is set to a relatively large value and one or more containers executes on the node shortly before the shutdown.

The DeletionService is never calling {{setExecuteExistingDelayedTasksAfterShutdownPolicy()}} on the ScheduledThreadPoolExecutor, and it defaults to waiting for all scheduled tasks to complete before exiting."
MAPREDUCE-3861,Oozie job status couldn't be updated correctly after Pig job SUCCEEDED from hadoop.,"Submit an Oozie job having Pig action, the job is SUCCEEDED from hadoop and the output file is generated on HDFS, but oozie status is KILLED.

Marcy Chen reported this issue while testing a pig job through oozie."
MAPREDUCE-3859,CapacityScheduler incorrectly utilizes extra-resources of queue for high-memory jobs,"Imagine, we have a queue A with capacity 10 slots and 20 as extra-capacity, jobs which use 3 map slots will never consume more than 9 slots, regardless how many free slots on a cluster."
MAPREDUCE-3858,Task attempt failure during commit results in task never completing,"On a terasort job a task attempt failed during the commit phase. Another attempt was rescheduled, but when it tried to commit it failed.

{noformat}
attempt_1329019187148_0083_r_000586_0 already given a go for committing the task output, so killing attempt_1329019187148_0083_r_000586_1
{noformat}

The job hung as new attempts kept getting scheduled only to fail during commit.

"
MAPREDUCE-3857,Grep example ignores mapred.job.queue.name,Grep example creates two jobs as part of its implementation. The first job correctly uses the configuration settings. The second job ignores configuration settings.
MAPREDUCE-3856,Instances of RunningJob class givs incorrect job tracking urls when mutiple jobs are submitted from same client jvm.,"When multiple jobs are submitted from the same client JVM, each call to RunningJob.getTrackingURL() always returns the tracking URL from the first job.

This happens even if the jobs are submitted and the client waits for the job to complete before submitting the subsequent job. Each job runs fine and is definitely a new, unique job, but the call to getTrackingURL() still returns the URL for the first job."
MAPREDUCE-3855,TestSubmitJob should use FileSystem instead of private HDFS classes.,TestSubmitJob uses ClientNamenodeProtocolTranslatorPB which is marked InterfaceAudience.Private. This causes build failures in mapreduce when HDFS changes internal/private classes. Test should be changed to use FileSystem.
MAPREDUCE-3854,Reinstate environment variable tests in TestMiniMRChildTask,"MAPREDUCE-3716 reinstated one of the tests in TestMiniMRChildTask, but there are two more which should be run."
MAPREDUCE-3853,TestLinuxResourceCalculatorPlugin is failing on trunk and 0.23 branch.,"Looks like the test is failing:
https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-0.23-Build/188/console"
MAPREDUCE-3852,test TestLinuxResourceCalculatorPlugin failing,"tests are failing:
org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.testParsingProcStatAndCpuFile
org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.testParsingProcMemFile 

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1831/testReport/junit/org.apache.hadoop.yarn.util/TestLinuxResourceCalculatorPlugin/testParsingProcStatAndCpuFile/

both with similar error:
java.io.FileNotFoundException: /home/jenkins/jenkins-slave/workspace/PreCommit-MAPREDUCE-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/test-dir/MEMINFO_238849741 (No such file or directory)

"
MAPREDUCE-3851,Allow more aggressive action on detection of the jetty issue,"MAPREDUCE-2529 added the useful failure detection mechanism. In this jira, I propose we add a periodic check inside TT and configurable action to self-destruct. Blacklisting helps but is not enough. Hung jetty still accepts connection and it takes very long time for clients to fail out. Short jobs are delayed for hours because of this. This feature will be a nice companion to MAPREDUCE-3184."
MAPREDUCE-3850,Avoid redundant calls for tokens in TokenCache,The {{TokenCache}} will repeatedly call the same filesystem for tokens.  This is inefficient and can easily be changed to only call each filesystem once.
MAPREDUCE-3849,Change TokenCache's reading of the binary token file,"When obtaining the tokens for a {{FileSystem}}, the {{TokenCache}} will read the binary token file if a token is not already in the {{Credentials}}.  However, it will overwrite any existing tokens in the {{Credentials}} with the contents of the binary token file if a single token is missing.  This may cause new tokens to be replaced with invalid/cancelled tokens from the binary file.  The new tokens will not be canceled, and thus ""leak"" in the namenode until they expire.

The binary tokens should be merged with, but not replace, existing tokens in the {{Credentials}}.

The code that reads the binary token file is prefaced with:
{code}
//TODO: Need to come up with a better place to put
//this block of code to do with reading the file
{code}

Also, the loading of the binary token file is the only reason that the {{TokenCache}} has to use {{getCanonicalService}}.  If this linkage can be broken, then the 1-to-1 filesystem to token service coupling may be removed.  And use of {{getCanonicalService}} can be removed in a subsequent jira."
MAPREDUCE-3847,Job in running state without any progress and no tasks running,"Hi All,

TestDFSIO program running with write option , number of files is 250 and file size is 256 MB (block size is also 256 MB)

NN went to safemode so JT was trying to connect to NN continuously..

later NN switched and it became proper..

Then JT is trying to kill some taskattempts and it's not able to do so as the task is not in TaskInProgress state at TT side

Also TaskTracker didnt respond before 10mins to it was declared lost marking all the tasks on that.

Has someone faced similar issue?

I couldnt reproduce this problem again.

Anyone can give any directions?

Thanks in advance.

Regards,
Abhijit





 

"
MAPREDUCE-3846,Restarted+Recovered AM hangs in some corner cases,"[~karams] found this while testing AM restart/recovery feature. After the first generation AM crashes (manually killed by kill -9), the second generation AM starts, but hangs after a while."
MAPREDUCE-3845,hadoop distcp fails to run with java.lang.NoClassDefFoundError,"Here's how to reproduce:

{noformat}
$ cd /tmnp
$ curl http://people.apache.org/~acmurthy/hadoop-0.23.1-rc0/hadoop-0.23.1.tar.gz | tar xzvf -
$ cd hadoop-0.23.1
$ ./bin/hadoop distcp
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/tools/DistCp
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.tools.DistCp
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
Could not find the main class: org.apache.hadoop.tools.DistCp.  Program will exit.
{noformat}"
MAPREDUCE-3844,Problem in setting the childTmpDir in MapReduceChildJVM,"We have seen this issue during a Hive test. Where Hive tries to create a temp file using File.createTempFile(..) and it throws:

{code}
Exception in thread ""main"" java.io.IOException: No such file or directory
	at java.io.UnixFileSystem.createFileExclusively(Native Method)
	at java.io.File.checkAndCreate(File.java:1704)
	at java.io.File.createTempFile(File.java:1792)
	at java.io.File.createTempFile(File.java:1828)
	at Test.main(Test.java:13)
{code}

Because it literally sees ""$PWD/tmp"" as the temp directory path.

$PWD need to be evaluated before being used in setting the property ""java.io.tmpdir"" in MapReduceChildJVM.java.
"
MAPREDUCE-3843,Job summary log file found missing on the RM host,"This bug was found by Phil Su as part of our testing.

After MAPREDUCE-3354 went in, the Job summary log file seems to have gone missing on the
RM host.

The job summary log appears to be interspersed in yarn-mapredqa-historyserver-<host>.out. 
e.g. 
12/02/09 15:57:21 INFO jobhistory.JobSummary:
jobId=job_1328658619341_0011,submitTime=1328802904381,launchTime=1328802909977,firstMapTaskLaunchTime=1328802912116,firstReduceTaskLaunchTime=1328802915074,finishTime=1328802933797,resourc
esPerMap=1024,resourcesPerReduce=2048,numMaps=10,numReduces=10,user=hadoopqa,queue=default,status=KILLED,mapSlotSeconds=0,reduceSlotSeconds=0

1) On the RM with older hadoop version where the job summary log does not exist
mapredqa 10903  0.0  1.2 1424404 210240 ?      Sl   Feb07   0:19 /home/gs/java/jdk64/current/bin/java -Xmx1000m
-Djava.net.preferIPv4Stack=true
-Djava.library.path=/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/
home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64 -Dhadoop.log.dir=/home/gs/var/log/mapredqa
-Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/home/gs/gridre/theoden/share/hadoop -Dhadoop.id.str=mapredqa
-Dhadoop
.root.logger=INFO,console
-Djava.library.path=/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/home/gs/gridre/theoden/share/hadoop/lib/native/Linux-amd64-64:/home/gs/gridre/theoden/share/hadoop/lib/nat
ive -Dhadoop.policy.file=hadoop-policy.xml -Djava.net.preferIPv4Stack=true -Dmapred.jobsummary.logger=INFO,console
-Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer

2) On the RM with older hadoop version where the job summary log exists
mapredqa 24851  0.0  0.5 1463280 90516 ?       Sl   Jan25   0:37 /home/gs/java/jdk64/current/bin/java
-Dproc_historyserver -Xmx1000m -Dmapred.jobsummary.logger=INFO,JSA -Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.file=yarn.log -Dyarn.home.dir= -Dyarn.id.str= -Dyarn.root.logger=INFO,console
-Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64
-Dyarn.policy.file=hadoop-policy.xml -Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.file=yarn-mapredqa-historyserver-<host>.log -Dyarn.home.dir= -Dyarn.id.str=mapredqa
-Dyarn.root.logger=INFO,DRFA -Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64
-Dyarn.policy.file=hadoop-policy.xml -Dmapred.jobsummary.logger=INFO,JSA -Dhadoop.log.dir=/home/gs/var/log/mapredqa
-Dyarn.log.dir=/home/gs/var/log/mapredqa
-Dhadoop.log.file=yarn-mapredqa-historyserver-<host>.log
-Dyarn.log.file=yarn-mapredqa-historyserver-<host>.log
-Dyarn.home.dir=/home/gs/gridre/shelob/share/hadoop -Dhadoop.root.logger=INFO,DRFA -Dyarn.root.logger=INFO,DRFA
-Djava.library.path=/home/gs/gridre/shelob/share/hadoop/lib/native/Linux-amd64-64 -classpath
/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/conf/hadoop:/home/gs/gridre/shelob/share/hadoop/share/hadoop/common/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/common/*:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/hadoop-*-capacity-scheduler.jar:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/hdfs/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/lib/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/*:/home/gs/java/jdk64/current/lib/tools.jar:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/*:/home/gs/gridre/shelob/share/hadoop/share/hadoop/mapreduce/lib/*
org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer

1) On the RM with older hadoop version where the job summary log does not exist
jobhistory ps shows using the option:
-Dmapred.jobsummary.logger=INFO,console 

2) On the RM with older hadoop version where the job summary log exists
jobhistory ps shows using the option:
-Dmapred.jobsummary.logger=INFO,JSA 
-Dmapred.jobsummary.logger=INFO,JSA

"
MAPREDUCE-3842,stop webpages from automatic refreshing,"The automatic refresh makes quiet hard to look at something specific as it makes the page jump and sometime resets its position. 

This is specially painful when looking at jobs with large number of tasks."
MAPREDUCE-3841,Broken Server metrics and Local logs link under the tools menu,Local logs link redirects to the cluster page and Server metrics opens an empty page on the RM/JHS homepage. So does the links from nodemanager UI.
MAPREDUCE-3840,JobEndNotifier doesn't use the proxyToUse during connecting,"I stupidly removed the proxyToUse from openConnection() in MAPREDUCE-3649.
"
MAPREDUCE-3839,Improve the single node setup docs for MR,"I'm gonna be recording all nits I can about the page at http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/SingleCluster.html here:

* The section at http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/SingleCluster.html#Mapreduce_Tarball is suitable to developers, not users. We should instead just point to releases page for tarball.
* On http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/SingleCluster.html#Setting_up_the_environment since the tarball structure is definite, we could do better to either point to a link to configure HDFS and Common or provide instructions ourselves. Same applies to path the MR envs ought to be set to -- none of these are mentioned.
* Under http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/SingleCluster.html#Setting_up_Configuration. one of the ""Add the following configs"" text is defined as a heading, while other isn't.
* The ""Create Symlinks"" and ""Running daemons"" sections do not appear in the index on top.
* Remove the ""Good luck."" at the end -- Users shouldn't need luck to setup good stuff :)

OT comment: The ""Create Symlinks"" part is curious. That we need symlinks to run MR looks very wrong to me.

"
MAPREDUCE-3837,Job tracker is not able to recover job in case of crash and after that no user can submit job.,"If job tracker is crashed while running , and there were some jobs are running , so if job tracker's property mapreduce.jobtracker.restart.recover is true then it should recover the job.

However the current behavior is as follows
jobtracker try to restore the jobs but it can not . And after that jobtracker closes its handle to hdfs and nobody else can submit job. 

Thanks,
Mayank"
MAPREDUCE-3836,TestContainersMonitor failing intermittently,See https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1814//testReport/ for an example failure.
MAPREDUCE-3835,RM capacity scheduler web UI doesn't show active users,"On the jobtracker, the web ui showed the active users for each queue and how much resources each of those users were using. That currently isn't being displayed on the RM capacity scheduler web ui."
MAPREDUCE-3834,"If multiple hosts for a split belong to the same rack, the rack is added multiple times in the AM request table",Should be added only once - so that the RM doesn't think there's multiple rack local requests for that particular rack.
MAPREDUCE-3833,Capacity scheduler queue refresh doesn't recompute queue capacities properly,Refreshing the capacity scheduler configuration (e.g.: via yarn rmadmin -refreshQueues) can fail to compute the proper absolute capacity for leaf queues.
MAPREDUCE-3831,RM scalability runtime is worse than 0.20.204 by 14.2%,"RM scalability runtime is worse than 0.20.204 by 14.2%

Overall runtime against 0.20.204 in a 350 nodes cluster is 2155 secs.
Overall runtime against .23 in 350 nodes cluster is 2462 secs."
MAPREDUCE-3829,[Gridmix] Gridmix should give better error message when input-data directory already exists and -generate option is given,"Instead of throwing exception messages on to the console, Gridmix should give better error message when input-data directory already exists and -generate option is given."
MAPREDUCE-3828,Broken urls: AM tracking url and jobhistory url in a single node setup.,"If the user doesn't explicitly set the yarn.resourcemanager.address conf property, in a single node setup, and tries to connect to the web UI from a remote machine, then all links (AM tracking url and jobhistory url) in the Web UI are broken (pointing to IP address 0.0.0.0).
"
MAPREDUCE-3827,Counters aggregation slowed down significantly after MAPREDUCE-3749,
MAPREDUCE-3826,RM UI when loaded throws a message stating Data Tables warning and then the column sorting stops working,
MAPREDUCE-3825,MR should not be getting duplicate tokens for a MR Job.,"This is the counterpart to HADOOP-7967.  
MR gets tokens for all input, output and the default filesystem when a MR job is submitted. 

The APIs in FileSystem make it challenging to avoid duplicate tokens when there are file systems that have embedded
filesystems.


Here is the original description that Daryn wrote: 
The token cache currently tries to assume a filesystem's token service key.  The assumption generally worked while there was a one to one mapping of filesystem to token.  With the advent of multi-token filesystems like viewfs, the token cache will try to use a service key (ie. for viewfs) that will never exist (because it really gets the mounted fs tokens).

The descriop"
MAPREDUCE-3824,Distributed caches are not removed properly,Distributed caches are not being properly removed by the TaskTracker when they are expected to be expired. 
MAPREDUCE-3823,Counters are getting calculated twice at job-finish and delaying clients.,
MAPREDUCE-3822,TestJobCounters is failing intermittently on trunk and 0.23.,TestJobCounters fails sometimes on trunk. I have tracked it down to stats issue in FileSystem. Still working on it. 
MAPREDUCE-3821,NPE while running Shuffle benchmark,"hadoop jar hadoop-mapreduce-test.jar loadgen -outKey org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text
The tasks fail with the following exception:
{noformat}
Error: java.lang.NullPointerException
	at org.apache.hadoop.fs.Path.<init>(Path.java:69)
	at org.apache.hadoop.fs.Path.<init>(Path.java:58)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath(FileOutputCommitter.java:118)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:167)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:149)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(FileOutputCommitter.java:185)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:209)
	at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:100)
	at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:94)
	at org.apache.hadoop.mapred.FileOutputCommitter.needsTaskCommit(FileOutputCommitter.java:176)
	at org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(OutputCommitter.java:248)
	at org.apache.hadoop.mapred.Task.isCommitRequired(Task.java:955)
	at org.apache.hadoop.mapred.Task.done(Task.java:912)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{noformat}"
MAPREDUCE-3818,Trunk MRV1 compilation is broken.,"Seeing this:
{code}
    [javac] /Users/vinodkv/Workspace/eclipse-workspace/apache-git/hadoop-common/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:155: cannot find symbol
    [javac] symbol  : class ClientNamenodeWireProtocol
    [javac] location: class org.apache.hadoop.mapred.TestSubmitJob
    [javac]       RPC.getProxy(ClientNamenodeWireProtocol.class,
    [javac]                    ^
{code}"
MAPREDUCE-3817,bin/mapred command cannot run distcp and archive jobs,
MAPREDUCE-3816,capacity scheduler web ui bar graphs for used capacity wrong,"The capacity scheduler web ui has bar graphs showing the capacity/used capacity/max capacity for each queue. The used capacity it is showing is actually the % of its parents queue it is using, which doesn't make sense on the bar graphs when compared to the capacity and max capacity of that particular queue.  The bar graphs should be using utilization so that the user can see that its using x% or the y% allocated to that queue.

I will attach some screen shots showing the issue."
MAPREDUCE-3815,Data Locality suffers if the AM asks for containers using IPs instead of hostnames,"BlockLocation.getHosts() returns IP addresses occasionally. Data locality is affected - since the RM requires hostnames.
"
MAPREDUCE-3814,MR1 compile fails,"$ ant veryclean all-jars -Dversion=0.23.1 -Dresolvers=internal


BUILD FAILED
/grid/0/dev/acm/hadoop-0.23/hadoop-mapreduce-project/build.xml:537: srcdir ""/grid/0/dev/acm/hadoop-0.23/hadoop-mapreduce-project/src/test/mapred/testjar"" does not exist!
"
MAPREDUCE-3813,RackResolver should maintain a cache to avoid repetitive lookups.,"With the current code, during task creation, we repeatedly resolve hosts and RackResolver doesn't cache any of the results. Caching will improve performance."
MAPREDUCE-3812,"Lower default allocation sizes, fix allocation configurations and document them","After a few performance improvements tracked at MAPREDUCE-3561, like MAPREDUCE-3511 and MAPREDUCE-3567, even a 100K maps job can also run within 1GB vmem. We earlier increased AM slot size from 1 slot to two slots to work around the issues with AM heap. Now that those are fixed, we should go back to 1GB.

This is just a configuration change.

[P.s.]:
- Currently min/max alloc is set at a per-scheduler config level, which makes no sense as there's no way to run multiple schedulers anyway. Switch configs to use a generic RM-config.
- The min/max alloc configs aren't documented and we ought to document it (i.e. MAPREDUCE-4027)
- 1 GB is perhaps too high for a slot's minimum. While job defaults can be left at such values, we should lower the minimum alloc to 128 MB to allow special requests of low memory out of the box itself. Shouldn't impact MR App in any way."
MAPREDUCE-3811,Make the Client-AM IPC retry count configurable,
MAPREDUCE-3810,MR AM's ContainerAllocator is assigning the allocated containers very slowly,This is mostly due to logging and other not-so-cheap operations we are doing as part of the AM->RM heartbeat cycle.
MAPREDUCE-3809,Tasks may take upto 3 seconds to exit after completion,Task.TaskReporter.stopCommunicationThread can end up waiting for a thread.sleep(3000) before stopping the thread.
MAPREDUCE-3808,NPE in FileOutputCommitter when running a 0 reduce job,"This was while running LoadGen.

{noformat}
Error: java.lang.NullPointerException at org.apache.hadoop.fs.Path.<init>(Path.java:67) 
at org.apache.hadoop.fs.Path.<init>(Path.java:56) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingJobAttemptsPath(FileOutputCommitter.java:118) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:167) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getJobAttemptPath(FileOutputCommitter.java:149) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getPendingTaskAttemptsPath(FileOutputCommitter.java:185) 
at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:209) 
at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:100) 
at org.apache.hadoop.mapred.FileOutputCommitter.getTaskAttemptPath(FileOutputCommitter.java:94) 
at org.apache.hadoop.mapred.FileOutputCommitter.needsTaskCommit(FileOutputCommitter.java:176) 
at org.apache.hadoop.mapred.OutputCommitter.needsTaskCommit(OutputCommitter.java:248) 
at org.apache.hadoop.mapred.Task.isCommitRequired(Task.java:955) 
at org.apache.hadoop.mapred.Task.done(Task.java:912) 
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:331) 
at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Subject.java:396) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157) 
at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{noformat}"
MAPREDUCE-3807,JobTracker needs fix similar to HDFS-94,"1.0 JobTracker's jobtracker.jsp page currently shows:

{code}
<h2>Cluster Summary (Heap Size is <%= StringUtils.byteDesc(Runtime.getRuntime().totalMemory()) %>/<%= StringUtils.byteDesc(Runtime.getRuntime().maxMemory()) %>)</h2>
{code}

It could use an improvement same as HDFS-94 to reflect live heap usage more accurately."
MAPREDUCE-3806,[Gridmix] TestGridmixSubmission fails due to incorrect version of jackson,"{{TestGridmixSubmission}} fails with the following error
{code}
org.codehaus.jackson.type.JavaType.isMapLikeType()Z
java.lang.NoSuchMethodError: org.codehaus.jackson.type.JavaType.isMapLikeType()Z
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._createDeserializer(StdDeserializerProvider.java:374)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._createAndCache2(StdDeserializerProvider.java:307)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._createAndCacheValueDeserializer(StdDeserializerProvider.java:287)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider.findValueDeserializer(StdDeserializerProvider.java:136)
        at org.codehaus.jackson.map.deser.StdDeserializer.findDeserializer(StdDeserializer.java:551)
        at org.codehaus.jackson.map.deser.BeanDeserializer.resolve(BeanDeserializer.java:268)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._resolveDeserializer(StdDeserializerProvider.java:404)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._createAndCache2(StdDeserializerProvider.java:349)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider._createAndCacheValueDeserializer(StdDeserializerProvider.java:287)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider.findValueDeserializer(StdDeserializerProvider.java:136)
        at org.codehaus.jackson.map.deser.StdDeserializerProvider.findTypedValueDeserializer(StdDeserializerProvider.java:157)
        at org.codehaus.jackson.map.ObjectMapper._findRootDeserializer(ObjectMapper.java:2468)
        at org.codehaus.jackson.map.ObjectMapper._readValue(ObjectMapper.java:2383)
        at org.codehaus.jackson.map.ObjectMapper.readValue(ObjectMapper.java:1094)
        at org.apache.hadoop.tools.rumen.JsonObjectMapperParser.getNext(JsonObjectMapperParser.java:84)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:117)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:29)
        at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testTraceReader(TestGridmixSubmission.java:440)
{code}"
MAPREDUCE-3804,yarn webapp interface vulnerable to cross scripting attacks,"Yarn webapp interface may be vulnerable to certain cross scripting attacks, injected through URL request.

"
MAPREDUCE-3803,HDFS-2864 broke ant compilation,"compile:
     [echo] contrib: raid
    [javac] <somePath>/hadoop-mapreduce-project/src/contrib/build-contrib.xml:194: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 28 source files to <somepath>/hadoop-mapreduce-project/build/contrib/raid/classes
    [javac] <somepath>/hadoop-mapreduce-project/src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/datanode/RaidBlockSender.java:111: cannot find symbol
    [javac] symbol  : variable METADATA_VERSION
    [javac] location: class org.apache.hadoop.hdfs.server.datanode.FSDataset
    [javac]         if (version != FSDataset.METADATA_VERSION) {
    [javac]                                 ^
    [javac] <somepath>/hadoop-mapreduce-project/src/contrib/raid/src/java/org/apache/hadoop/raid/BlockFixer.java:649: cannot find symbol
    [javac] symbol  : variable METADATA_VERSION
    [javac] location: class org.apache.hadoop.hdfs.server.datanode.FSDataset
    [javac]       mdOut.writeShort(FSDataset.METADATA_VERSION);
    [javac]                                 ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 2 errors

BUILD FAILED

"
MAPREDUCE-3802,If an MR AM dies twice  it looks like the process freezes,"It looks like recovering from an RM AM dieing works very well on a single failure.  But if it fails multiple times we appear to get into a live lock situation.

{noformat}
yarn jar hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*-SNAPSHOT.jar wordcount -Dyarn.app.mapreduce.am.log.level=DEBUG -Dmapreduce.job.reduces=30 input output
12/02/03 21:06:57 WARN conf.Configuration: fs.default.name is deprecated. Instead, use fs.defaultFS
12/02/03 21:06:57 WARN conf.Configuration: mapred.used.genericoptionsparser is deprecated. Instead, use mapreduce.client.genericoptionsparser.used
12/02/03 21:06:57 INFO input.FileInputFormat: Total input paths to process : 17
12/02/03 21:06:57 INFO util.NativeCodeLoader: Loaded the native-hadoop library
12/02/03 21:06:57 WARN snappy.LoadSnappy: Snappy native library not loaded
12/02/03 21:06:57 INFO mapreduce.JobSubmitter: number of splits:17
12/02/03 21:06:57 INFO mapred.ResourceMgrDelegate: Submitted application application_1328302034486_0003 to ResourceManager at HOST/IP:8040
12/02/03 21:06:57 INFO mapreduce.Job: The url to track the job: http://HOST:8088/proxy/application_1328302034486_0003/
12/02/03 21:06:57 INFO mapreduce.Job: Running job: job_1328302034486_0003
12/02/03 21:07:03 INFO mapreduce.Job: Job job_1328302034486_0003 running in uber mode : false
12/02/03 21:07:03 INFO mapreduce.Job:  map 0% reduce 0%
12/02/03 21:07:09 INFO mapreduce.Job:  map 5% reduce 0%
12/02/03 21:07:10 INFO mapreduce.Job:  map 17% reduce 0%
#KILLED AM with kill -9 here
12/02/03 21:07:16 INFO mapreduce.Job:  map 29% reduce 0%
12/02/03 21:07:17 INFO mapreduce.Job:  map 35% reduce 0%
12/02/03 21:07:30 INFO mapreduce.Job:  map 52% reduce 0%
12/02/03 21:07:35 INFO mapreduce.Job:  map 58% reduce 0%
12/02/03 21:07:37 INFO mapreduce.Job:  map 70% reduce 0%
12/02/03 21:07:41 INFO mapreduce.Job:  map 76% reduce 0%
12/02/03 21:07:43 INFO mapreduce.Job:  map 82% reduce 0%
12/02/03 21:07:44 INFO mapreduce.Job:  map 88% reduce 0%
12/02/03 21:07:47 INFO mapreduce.Job:  map 94% reduce 0%
12/02/03 21:07:49 INFO mapreduce.Job:  map 100% reduce 0%
12/02/03 21:07:53 INFO mapreduce.Job:  map 100% reduce 3%
12/02/03 21:08:00 INFO mapreduce.Job:  map 100% reduce 6%
12/02/03 21:08:06 INFO mapreduce.Job:  map 100% reduce 10%
12/02/03 21:08:12 INFO mapreduce.Job:  map 100% reduce 13%
12/02/03 21:08:18 INFO mapreduce.Job:  map 100% reduce 16%
#killed AM with kill -9 here
12/02/03 21:08:20 INFO ipc.Client: Retrying connect to server: HOST/IP:44223. Already tried 0 time(s).
12/02/03 21:08:21 INFO ipc.Client: Retrying connect to server: HOST/IP:44223. Already tried 1 time(s).
12/02/03 21:08:22 INFO ipc.Client: Retrying connect to server: HOST/IP:44223. Already tried 2 time(s).
12/02/03 21:08:26 INFO mapreduce.Job:  map 64% reduce 16%
#It never makes any more progress...
{noformat}"
MAPREDUCE-3801,org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators.testExponentialEstimator fails intermittently,"org.apache.hadoop.mapreduce.v2.app.TestRuntimeEstimators,testExponentialEstimator fails intermittently"
MAPREDUCE-3800,TestHarFileSystem testRelativeArchives,"*Error Message*
failed test
*Stacktrace*
junit.framework.AssertionFailedError: failed test
	at org.apache.hadoop.tools.TestHarFileSystem.testRelativeArchives(TestHarFileSystem.java:227)
"
MAPREDUCE-3799,TestServiceLevelAuthorization testServiceLevelAuthorization failing,"*Error Message*

Expected file distcache not found

*Stacktrace*

junit.framework.AssertionFailedError: Expected file distcache not found
	at org.apache.hadoop.mapred.TestMiniMRWithDFS.verifyContents(TestMiniMRWithDFS.java:200)
	at org.apache.hadoop.mapred.TestMiniMRWithDFS.checkTaskDirectories(TestMiniMRWithDFS.java:149)
	at org.apache.hadoop.mapred.TestMiniMRWithDFS.runWordCount(TestMiniMRWithDFS.java:240)
	at org.apache.hadoop.security.authorize.TestServiceLevelAuthorization.testServiceLevelAuthorization(TestServiceLevelAuthorization.java:95)
"
MAPREDUCE-3798,TestJobCleanup testCustomCleanup is failing,"File <somepath>/hadoop-mapreduce-project/build/test/data/test-job-cleanup/output-8/_custom_cleanup missing for job job_20120203035807432_0009

junit.framework.AssertionFailedError: File <somepath>/hadoop-mapreduce-project/build/test/data/test-job-cleanup/output-8/_custom_cleanup missing for job job_20120203035807432_0009
	at org.apache.hadoop.mapred.TestJobCleanup.testKilledJob(TestJobCleanup.java:228)
	at org.apache.hadoop.mapred.TestJobCleanup.testCustomCleanup(TestJobCleanup.java:302)
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
	at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
	at junit.extensions.TestSetup.run(TestSetup.java:27)
"
MAPREDUCE-3797,lGridMix fails to Run with NPE with latest branch-0.23 code,GridMix fails to start trowing NPE after gendata 
MAPREDUCE-3795,"""job -status"" command line output is malformed",Misses new lines after numMaps and numReduces. Caused by MAPREDUCE-3720.
MAPREDUCE-3794,Support mapred.Task.Counter and mapred.JobInProgress.Counter enums for compatibility,"The new counters are mapreduce.TaskCounter and mapreduce.JobCounter, but we should support the old ones too since they are public in Hadoop 1.x."
MAPREDUCE-3792,job -list displays only the jobs submitted by a particular user,"""mapred job -list"" lists only the jobs submitted by the user who ran the command. This behavior is different from 1.x. 
"
MAPREDUCE-3791,can't build site in hadoop-yarn-server-common,"Here's how to reproduce:

{noformat}
$ mvn site site:stage -DskipTests -DskipTest -DskipITs
....
main:
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] Apache Hadoop Main ................................ SUCCESS [49.017s]
[INFO] Apache Hadoop Project POM ......................... SUCCESS [5.152s]
[INFO] Apache Hadoop Annotations ......................... SUCCESS [4.973s]
[INFO] Apache Hadoop Project Dist POM .................... SUCCESS [4.514s]
[INFO] Apache Hadoop Assemblies .......................... SUCCESS [4.334s]
[INFO] Apache Hadoop Auth ................................ SUCCESS [5.215s]
[INFO] Apache Hadoop Auth Examples ....................... SUCCESS [4.051s]
[INFO] Apache Hadoop Common .............................. SUCCESS [4.111s]
[INFO] Apache Hadoop Common Project ...................... SUCCESS [4.198s]
[INFO] Apache Hadoop HDFS ................................ SUCCESS [5.373s]
[INFO] Apache Hadoop HttpFS .............................. SUCCESS [22.549s]
[INFO] Apache Hadoop HDFS Project ........................ SUCCESS [4.440s]
[INFO] hadoop-yarn ....................................... SUCCESS [5.250s]
[INFO] hadoop-yarn-api ................................... SUCCESS [4.579s]
[INFO] hadoop-yarn-common ................................ SUCCESS [4.268s]
[INFO] hadoop-yarn-server ................................ SUCCESS [4.408s]
[INFO] hadoop-yarn-server-common ......................... FAILURE [0.035s]
[INFO] hadoop-yarn-server-nodemanager .................... SKIPPED
[INFO] hadoop-yarn-server-web-proxy ...................... SKIPPED
[INFO] hadoop-yarn-server-resourcemanager ................ SKIPPED
[INFO] hadoop-yarn-server-tests .......................... SKIPPED
[INFO] hadoop-mapreduce-client ........................... SKIPPED
[INFO] hadoop-mapreduce-client-core ...................... SKIPPED
[INFO] hadoop-yarn-applications .......................... SKIPPED
[INFO] hadoop-yarn-applications-distributedshell ......... SKIPPED
[INFO] hadoop-yarn-site .................................. SKIPPED
[INFO] hadoop-mapreduce-client-common .................... SKIPPED
[INFO] hadoop-mapreduce-client-shuffle ................... SKIPPED
[INFO] hadoop-mapreduce-client-app ....................... SKIPPED
[INFO] hadoop-mapreduce-client-hs ........................ SKIPPED
[INFO] hadoop-mapreduce-client-jobclient ................. SKIPPED
[INFO] Apache Hadoop MapReduce Examples .................. SKIPPED
[INFO] hadoop-mapreduce .................................. SKIPPED
[INFO] Apache Hadoop MapReduce Streaming ................. SKIPPED
[INFO] Apache Hadoop Distributed Copy .................... SKIPPED
[INFO] Apache Hadoop Archives ............................ SKIPPED
[INFO] Apache Hadoop Rumen ............................... SKIPPED
[INFO] Apache Hadoop Extras .............................. SKIPPED
[INFO] Apache Hadoop Tools Dist .......................... SKIPPED
[INFO] Apache Hadoop Tools ............................... SKIPPED
[INFO] Apache Hadoop Distribution ........................ SKIPPED
[INFO] Apache Hadoop Client .............................. SKIPPED
[INFO] Apache Hadoop Mini-Cluster ........................ SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 2:18.427s
[INFO] Finished at: Thu Feb 02 10:31:35 PST 2012
[INFO] Final Memory: 321M/1012M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.6:run (default) on project hadoop-yarn-server-common: An Ant BuildException has occured: Warning: Could not find file /home/rvs/src/apache/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/main/resources/yarn-default.xml to copy. -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hadoop-yarn-server-common
{noformat}"
MAPREDUCE-3790,Broken pipe on streaming job can lead to truncated output for a successful job,"If a streaming job doesn't consume all of its input then the job can be marked successful even though the job's output is truncated.

Here's a simple setup that can exhibit the problem.  Note that the job output will most likely be truncated compared to the same job run with a zero-length input file.

{code}
$ hdfs dfs -cat in
foo
$ yarn jar ./share/hadoop/tools/lib/hadoop-streaming-0.24.0-SNAPSHOT.jar -Dmapred.map.tasks=1 -Dmapred.reduce.tasks=1 -mapper /bin/env -reducer NONE -input in -output out
{code}

Examining the map task log shows this:

{code:title=Excerpt from map task stdout log}
2012-02-02 11:27:25,054 WARN [main] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Broken pipe
2012-02-02 11:27:25,054 INFO [main] org.apache.hadoop.streaming.PipeMapRed: mapRedFinished
2012-02-02 11:27:25,056 WARN [Thread-12] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: Bad file descriptor
2012-02-02 11:27:25,124 INFO [main] org.apache.hadoop.mapred.Task: Task:attempt_1328203555769_0001_m_000000_0 is done. And is in the process of commiting
2012-02-02 11:27:25,127 WARN [Thread-11] org.apache.hadoop.streaming.PipeMapRed: java.io.IOException: DFSOutputStream is closed
2012-02-02 11:27:25,199 INFO [main] org.apache.hadoop.mapred.Task: Task attempt_1328203555769_0001_m_000000_0 is allowed to commit now
2012-02-02 11:27:25,225 INFO [main] org.apache.hadoop.mapred.FileOutputCommitter: Saved output of task 'attempt_1328203555769_0001_m_000000_0' to hdfs://localhost:9000/user/somebody/out/_temporary/1
2012-02-02 11:27:27,834 INFO [main] org.apache.hadoop.mapred.Task: Task 'attempt_1328203555769_0001_m_000000_0' done.
{code}

In PipeMapRed.mapRedFinished() we can see it will eat IOExceptions and return without waiting for the output threads or throwing a runtime exception to fail the job.  Net result is that the DFS streams could be shutdown too early if the output threads are still busy and we could lose job output.

Fixing this brings up the bigger question of what *should* happen when a streaming job doesn't consume all of its input.  Should we have grabbed all of the output from the job and still marked it successful or should we have failed the job?  If the former then we need to fix some other places in the code as well, since feeding a much larger input file (e.g.: 600K) to the same sample streaming job results in the job failing with the exception below.  It wouldn't be consistent to fail the job that doesn't consume a lot of input but pass the job that leaves just a few leftovers.

{code}
2012-02-02 10:29:37,220 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1270)) - Running job: job_1328200108174_0001
2012-02-02 10:29:44,354 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1291)) - Job job_1328200108174_0001 running in uber mode : false
2012-02-02 10:29:44,355 INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1298)) -  map 0% reduce 0%
2012-02-02 10:29:46,394 INFO  mapreduce.Job (Job.java:printTaskEvents(1386)) - Task Id : attempt_1328200108174_0001_m_000000_0, Status : FAILED
Error: java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:282)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:105)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)
	at java.io.DataOutputStream.write(DataOutputStream.java:90)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeUTF8(TextInputWriter.java:72)
	at org.apache.hadoop.streaming.io.TextInputWriter.writeValue(TextInputWriter.java:51)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:106)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:34)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:394)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:329)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1177)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{code}

Assuming the job returns a successful exit code, I think we should allow the job to complete successfully even though it doesn't consume all of its inputs.  Part of the reasoning is that there's already this comment in PipeMapper.java that implies we desire that behavior:

{code:title=PipeMapper.java}
        // terminate with success:
        // swallow input records although the stream processor failed/closed
{code}"
MAPREDUCE-3789,CapacityTaskScheduler may perform unnecessary reservations in heterogenous tracker environments,"Briefly, to reproduce:

* Run JT with CapacityTaskScheduler [Say, Cluster max map = 8G, Cluster map = 2G]
* Run two TTs but with varied capacity, say, one with 4 map slot, another with 3 map slots.
* Run a job with two tasks, each demanding mem worth 4 slots at least (Map mem = 7G or so).
* Job will begin running on TT #1, but will also end up reserving the 3 slots on TT #2 cause it does not check for the maximum limit of slots when reserving (as it goes greedy, and hopes to gain more slots in future).
* Other jobs that could've run on the TT #2 over 3 slots are thereby blocked out due to this illogical reservation.

I've not yet tested MR2 for this so feel free to weigh in if it affects MR2 as well.

For MR1, I've attached a test case initially to indicate this. A fix that checks reservations vs. max slots, to follow."
MAPREDUCE-3787,[Gridmix] Improve STRESS mode,"Gridmix STRESS mode can be improved as follows:
1. The sleep time in JobMonitor can be reduced and/or made configurable
2. Map and reduce load calculation in StressJobFactory can be done in one loop
3. Updating the overload status from the job submitter thread (inline)
4. Optimizations to avoid un-necessary progress check (which inturn would result into delay)"
MAPREDUCE-3784,maxActiveApplications(|PerUser) per queue is too low for small clusters,"We ran into this issue while testing on small clusters. 
On a 7node cluster with 8G per node,  for a queue with absolute capacity 30%, user limit 100%, maxActiveApplications and maxActiveApplicationsPerUser is calculated to be 1.
This means that even though the queue has 17GB(0.3*8*7), only 1 user can run 1 app at a given time queuing up rest of the apps/users. This hurts performance on small clusters.
"
MAPREDUCE-3782,teragen terasort jobs fail when using webhdfs:// ,"When running a teragen job with a webhdfs:// url the delegation token that is retrieved is an hdfs delegation token. 

And the subsequent terasort job on the output fails with java io exception"
MAPREDUCE-3781,Fix history for apps which were terminated before the AM launch,Currently the history for applications which were terminated/killed/failed before the AM was launched redirects to a page that does not exist. 
MAPREDUCE-3780,RM assigns containers to killed applications,RM attempts to assign containers to killed applications. The applications were killed when they were inactive and waiting for AM allocation.
MAPREDUCE-3779,Create hard and soft limits for job counters,"The mapreduce.job.counters.limit is not overridable at the job level.  While it is necessary to limit the number of counters to reduce overhead, there are times when exceeding the limit is required.  Currently, the only solution is to increase the limit cluster wide.

I would like to see a soft limit set in the mapred-site.xml that can be overridden at the job level, in addition to the hard limit that exists today."
MAPREDUCE-3777,used mem and util have negative values after a queue addition,"After a queue addition to capacity scheduler and submission of an application, root queue utilization and used memory have negative values. 
"
MAPREDUCE-3775,Change MiniYarnCluster to escape special chars in testname,"When using MiniYarnCluster with the testname set to a nested classname, the ""$"" within the class name creates issues with the container launch scripts as they try to expand the $... within the paths/variables in use.  "
MAPREDUCE-3774,yarn-default.xml should be moved to hadoop-yarn-common.,yarn-default.xml right now resides in hadoop-yarn-server-common jars which is not the right thing to do since this jar might not be needed in some cases when depending upon yarn. We should move it to hadoop-yarn-common which is a required dependency for all the yarn components (client/server).
MAPREDUCE-3773,Add queue metrics with buckets for job run times,"It would be nice to have queue metrics that reflect the number of jobs in each queue that have been running for different ranges of time.

Reasonable time ranges are probably 0-1 hr, 1-5 hr, 5-24 hr, 24+ hrs; but they should be configurable."
MAPREDUCE-3772,MultipleOutputs output lost if baseOutputPath starts with ../,"Lets say you have output directory set:

FileOutputFormat.setOutputPath(job, ""/tmp/multi1/out"");

and want to place output from MultipleOutputs into /tmp/multi1/extra

I expect following code to work:

mos = new MultipleOutputs<Text, IntWritable>(context);
mos.write(new Text(""zrr""), value, ""../extra/"");

but no Exception is throw and expected output directory /tmp/multi1/extra does not even exists. All data written to this output vanish without trace.

To make it work fullpath must be used
mos.write(new Text(""zrr""), value, ""/tmp/multi1/extra/"");

Output is listed in statistics from MultipleOutputs correctly:

        org.apache.hadoop.mapreduce.lib.output.MultipleOutputs
                ../gaja1/=13333 (* everything is lost *)
                /tmp/multi1/out/../ksd34/=13333 (* this using full path works *)
                list1=6667"
MAPREDUCE-3771,Port MAPREDUCE-1735 to trunk/0.23,"Per discussion in general@, we should port MAPREDUCE-1735 to 0.23 & trunk to 'undeprecate' old mapred api:
http://s.apache.org/undeprecate-mapred-apis"
MAPREDUCE-3770,[Rumen] Zombie.getJobConf() results into NPE,"The error trace is as follows
{code}
java.lang.NullPointerException
        at java.util.Hashtable.put(Hashtable.java:394)
        at java.util.Properties.setProperty(Properties.java:143)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:623)
        at org.apache.hadoop.mapred.JobConf.setJobName(JobConf.java:1322)
        at org.apache.hadoop.tools.rumen.ZombieJob.getJobConf(ZombieJob.java:139)
        at org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.updateHDFSDistCacheFilesList(DistributedCacheEmulator.java:315)
        at org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.buildDistCacheFilesList(DistributedCacheEmulator.java:280)
        at org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.setupGenerateDistCacheData(DistributedCacheEmulator.java:253)
        at org.apache.hadoop.mapred.gridmix.Gridmix.setupDistCacheEmulation(Gridmix.java:528)
        at org.apache.hadoop.mapred.gridmix.Gridmix.setupEmulation(Gridmix.java:501)
        at org.apache.hadoop.mapred.gridmix.Gridmix.start(Gridmix.java:433)
        at org.apache.hadoop.mapred.gridmix.Gridmix.runJob(Gridmix.java:380)
        at org.apache.hadoop.mapred.gridmix.Gridmix.access$000(Gridmix.java:56)
        at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:313)
        at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:311)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)
        at org.apache.hadoop.mapred.gridmix.Gridmix.run(Gridmix.java:311)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.mapred.gridmix.Gridmix.main(Gridmix.java:606)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:200)
{code}

The bug seems to be in {{ZombieJob#getName()}} where a not-null check for jobName.getValue() is missing. "
MAPREDUCE-3767,Fix and enable env tests in TestMiniMRChildTask,This test is ported to YARN+MR via MAPREDUCE-3716. We should try to enable the env tests also.
MAPREDUCE-3766,dumptb fails with filenotfound,"dumptb can't find an existing file


antonio@ip-10-9-65-123:~$ hadoop jar /usr/lib/hadoop/contrib/streaming/hadoop-streaming-0.20.2-cdh3u3.jar dumptb /tmp/Rtmp5h8lIO/file179e4fc
12/01/31 00:27:48 INFO security.UserGroupInformation: JAAS Configuration already set up for Hadoop, not re-installing.
12/01/31 00:27:49 WARN snappy.LoadSnappy: Snappy native library is available
12/01/31 00:27:49 INFO util.NativeCodeLoader: Loaded the native-hadoop library
12/01/31 00:27:49 INFO snappy.LoadSnappy: Snappy native library loaded
Exception in thread ""main"" java.io.FileNotFoundException: File does not exist: /tmp/Rtmp5h8lIO/file179e4fc/_logs
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:1822)
	at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.<init>(DFSClient.java:1813)
	at org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:544)
	at org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:187)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:456)
	at org.apache.hadoop.streaming.AutoInputFormat.getRecordReader(AutoInputFormat.java:56)
	at org.apache.hadoop.streaming.DumpTypedBytes.dumpTypedBytes(DumpTypedBytes.java:102)
	at org.apache.hadoop.streaming.DumpTypedBytes.run(DumpTypedBytes.java:83)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:41)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:197)


But the file is there

antonio@ip-10-9-65-123:~$ hadoop dfs -ls /tmp/Rtmp5h8lIO/file179e4fc/_logs
12/01/31 00:28:47 INFO security.UserGroupInformation: JAAS Configuration already set up for Hadoop, not re-installing.
Found 1 items
drwxrwxrwx   - antonio supergroup          0 2012-01-31 00:18 /tmp/Rtmp5h8lIO/file179e4fc/_logs/history
"
MAPREDUCE-3765,FifoScheduler does not respect yarn.scheduler.fifo.minimum-allocation-mb setting,FifoScheduler uses default min 1 GB regardless of the configuration value set for minimum memory allocation.
MAPREDUCE-3764,AllocatedGB etc metrics incorrect if min-allocation-mb isn't a multiple of 1GB,"MutableGaugeInt incremented as {{allocatedGB.incr(res.getMemory() / GB * containers);}}

Setting yarn.scheduler.capacity.minimum-allocation-mb to 1536 - each increment is counted as 1GB.
Trying to analyze the metrics - looks like the cluster is never over 67-68% utilized, depending on high ram requests."
MAPREDUCE-3762,Resource Manager fails to come up with default capacity scheduler configs.,"Thanks to [~harip] for pointing out the issue. This is the stack trace for bringing up RM with default CS configs:

{code}
java.lang.IllegalArgumentException: Illegal value  of maximumCapacity -0.01 used in call to setMaxCapacity for queue default
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueueUtils.checkMaxCapacity(CSQueueUtils.java:28)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.setupQueueConfigs(LeafQueue.java:210)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.<init>(LeafQueue.java:184)
{code}"
MAPREDUCE-3761,AM info in job -list does not reflect the actual AM hostname,"The AM info field on ""bin/mapred job -list"" currently has a value <resourcemanager hostname>:8088/proxy/appID. This info is irrelevant unless it shows the real information of where the AM was launched. This needs to be fixed to show the AM host details."
MAPREDUCE-3760,Blacklisted NMs should not appear in Active nodes list,"Blacklisted NMs appear in both ""Active Nodes"" and ""Unhealthy nodes"" on the RM UI. This should be fixed."
MAPREDUCE-3759,ClassCastException thrown in -list-active-trackers when there are a few unhealthy nodes,"When there are a few blacklisted nodes in the cluster, ""bin/mapred job -list-active-trackers"" throws ""java.lang.ClassCastException: org.apache.hadoop.yarn.server.resourcemanager.resource.Resources$1 cannot be cast to org.apache.hadoop.yarn.api.records.impl.pb.ResourcePBImpl"""
MAPREDUCE-3758,NPE while submitting job through Oozie,"NPE while submitting job through oozie. 
Caused by: java.lang.NullPointerException
        at
org.apache.hadoop.mapreduce.v2.util.MRApps.setMRFrameworkClasspath(MRApps.java:212)
        at"
MAPREDUCE-3757,Rumen Folder is not adjusting the shuffleFinished and sortFinished times of reduce task attempts,Rumen Folder is not adjusting the shuffleFinished and sortFinished times of reduce task attempts when it is adjusting the attempt-start-time and attempt-finish-time. This is leading to wrong values which are greater than the attempt-finish-time in trace file.
MAPREDUCE-3756,Make single shuffle limit configurable,"Make single shuffle limit configurable, currently it's hard-coded."
MAPREDUCE-3755,Add the equivalent of JobStatus to end of JobHistory file ,"In MR1 we have the notion of CompletedJobStatus store to aid fast responses to job.getStatus. We need the equivalent for MR2, an option is to add the jobStatus to the end of the JobHistory file to which the JHS can easily jump ahead to and serve the query, it should also cache this for a fair number of recently completed jobs."
MAPREDUCE-3754,RM webapp should have pages filtered based on App-state,Helps a lot when we have lot of apps. Already having difficulties with gridmix with a single big list of apps of all states.
MAPREDUCE-3753,Reduce output data is not written to disk,"I run into a critical issue with Hadoop 18.2 on my Linux boxes:

The jobs executes without any complains and they are listed in the
succeeded list but there is no output data beside the ""_logs"" directory.
The same code works with .17.2.1
 

Here are some sections of the logs:

[logfile]
hadoop@bock:~/logs$ tail hadoop-hadoop-jobtracker-bock.log

2008-12-23 13:30:56,707 INFO org.apache.hadoop.mapred.JobInProgress:
Choosing a data-local task task_200812231229_0031_m_000001 for
speculation

2008-12-23 13:30:56,707 INFO org.apache.hadoop.mapred.JobTracker: Adding
task 'attempt_200812231229_0031_m_000001_1' to tip
task_200812231229_0031_m_000001, for tracker
'tracker_bock:localhost/127.0.0.1:15260'

2008-12-23 13:31:01,065 INFO org.apache.hadoop.mapred.JobInProgress:
Task 'attempt_200812231229_0031_m_000001_1' has completed
task_200812231229_0031_m_000001 successfully.

2008-12-23 13:31:03,177 INFO org.apache.hadoop.mapred.TaskRunner: Saved
output of task 'attempt_200812231229_0031_r_000000_0' to
hdfs://BOCK:9000/ana/oiprocessed/2008/12/23/Sen1/92a74190-2038-4c79-82c4-2de6fdc615db

[/logfile]

But the folder contains only a ""_logs"" folder which has a history file
which contains:

[logfile]

Job JOBID=""job_200812231415_0001"" FINISH_TIME=""1230038377844""
JOB_STATUS=""SUCCESS"" FINISHED_MAPS=""2"" FINISHED_REDUCES=""1""
FAILED_MAPS=""0"" FAILED_REDUCES=""0"" COUNTERS=""Job Counters .Data-local
map tasks:2,Job Counters .Launched reduce tasks:1,Job Counters .Launched
map tasks:3,Map-Reduce Framework.Reduce input records:61,Map-Reduce
Framework.Map output records:61,Map-Reduce Framework.Map output
bytes:7194,Map-Reduce Framework.Combine output records:0,Map-Reduce
Framework.Map input records:61,Map-Reduce Framework.Reduce input
groups:12,Map-Reduce Framework.Combine input records:0,Map-Reduce
Framework.Map input bytes:36396,Map-Reduce Framework.Reduce output
records:12,File Systems.HDFS bytes written:1533,File Systems.Local bytes
written:14858,File Systems.HDFS bytes read:38679,File Systems.Local
bytes
read:7388,com..ana.scheduling.HadoopTask$Counter.MAPPEED:61
""
[/logfile]

So what I see is that the system runs successful and it even says it
writes data! (""Map-Reduce Framework.Reduce output records:12,File Systems.HDFS bytes written:1533"")

If I run the same code with .17.2.1 or in local mode with .18.2 it works
and I get a part-0000 file with the expected data.
 

Please tell me if you need additional information.

"
MAPREDUCE-3752,Headroom should be capped by queue max-cap,Headroom should be capped by queue max-cap.
MAPREDUCE-3750,ConcurrentModificationException in counter groups,Iterating over a counter's groups while adding more groups results in a ConcurrentModificationException. This was discovered while running Hive unit tests on a recent 0.23 version of Hadoop.
MAPREDUCE-3749,ConcurrentModificationException in counter groups,"Iterating over a counter's groups while adding more groups will cause a ConcurrentModificationException.

This was found while running Hive unit tests against a recent 0.23 version."
MAPREDUCE-3748,Move CS related nodeUpdate log messages to DEBUG,"Currently, the RM has nodeUpdate logs per NM per second such as the following:
2012-01-27 21:51:32,429 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <nodemanager1>:<port1> clusterResources: memory: 57344
2012-01-27 21:51:32,510 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <nodemanager2>:<port2> clusterResources: memory: 57344
2012-01-27 21:51:33,094 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <nodemanager1>:<port1> clusterResources: memory: 57344

Debugging is difficult with huge amount of logs such as this. These logs need to be moved to DEBUG."
MAPREDUCE-3747,Memory Total is not refreshed until an app is launched,"Memory Total on the RM UI is not refreshed until an application is launched. This is a problem when the cluster is started for the first time or when there are any lost/decommissioned NMs.
When the cluster is started for the first time, Active Nodes is > 0 but the Memory Total=0. Also when there are any lost/decommissioned nodes, Memory Total has wrong value.
This is a useful tool for cluster admins and has to be updated correctly without having the need to submit an app each time."
MAPREDUCE-3746,Nodemanagers are not automatically shut down after decommissioning,Nodemanagers are not automatically shutdown after decommissioning. MAPREDUCE-2775 does not seem to fix the issue.
MAPREDUCE-3745,mapred/yarn scripts should use lib/'*' instead looping the dir for jar to create the classpath,"The scripts do a for loop on the JAR contents of the directory, they should just use '*' in the classpath, ie lib/'*'

This will reduce the length of the generated classpath significantly"
MAPREDUCE-3744,"Unable to retrieve application logs via ""yarn logs"" or ""mapred job -logs""","Trying to retrieve application logs via the ""yarn logs"" shell command results in an error similar to this:

Exception in thread ""main"" java.io.FileNotFoundException: File /tmp/logs/application_1327694122989_0001 does not exist.
	at org.apache.hadoop.fs.Hdfs$DirListingIterator.<init>(Hdfs.java:226)
	at org.apache.hadoop.fs.Hdfs$DirListingIterator.<init>(Hdfs.java:217)
	at org.apache.hadoop.fs.Hdfs$2.<init>(Hdfs.java:192)
	at org.apache.hadoop.fs.Hdfs.listStatusIterator(Hdfs.java:192)
	at org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1371)
	at org.apache.hadoop.fs.FileContext$20.next(FileContext.java:1)
	at org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2319)
	at org.apache.hadoop.fs.FileContext.listStatus(FileContext.java:1373)
	at org.apache.hadoop.yarn.logaggregation.LogDumper.dumpAllContainersLogs(LogDumper.java:191)
	at org.apache.hadoop.yarn.logaggregation.LogDumper.run(LogDumper.java:107)
	at org.apache.hadoop.yarn.logaggregation.LogDumper.main(LogDumper.java:226)

Trying to grab the logs via the ""mapred jobs -logs"" command results in this error:

2012-01-27 14:05:52,040 INFO  mapred.ClientServiceDelegate (ClientServiceDelegate.java:getProxy(246)) - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
2012-01-27 14:05:52,041 WARN  mapred.ClientServiceDelegate (ClientServiceDelegate.java:checkAndGetHSProxy(257)) - Job History Server is not configured.
Unable to get log information for job: job_1327694122989_0001

Even though the historyserver process is running."
MAPREDUCE-3742,"""yarn logs"" command fails with ClassNotFoundException","Executing ""yarn logs"" at a shell prompt fails with this error:

Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/LogDumper
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogDumper
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
Could not find the main class: org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogDumper.  Program will exit.

Appears to have been caused by the code reorg in MAPREDUCE-3297."
MAPREDUCE-3741,Conflicting dependency in hadoop-mapreduce-examples,"{code:xml}
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-mapreduce-client-hs</artifactId>
       <scope>provided</scope>
     </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-mapreduce-client-hs</artifactId>
       <scope>test</scope>
     </dependency>
{code}

Are we missing <type> here?"
MAPREDUCE-3740,Mapreduce Trunk compilation fails,"{code:xml}
[INFO] -------------------------------------------------------------
[ERROR] COMPILATION ERROR :
[INFO] -------------------------------------------------------------
[ERROR] /home/hadoop/hadoop-trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/ipc/ProtoOverHadoopRpcEngine.java:[61,7] org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine is not abstract and does not override abstract method 
getProtocolMetaInfoProxy(org.apache.hadoop.ipc.Client.ConnectionId,org.apache.hadoop.conf.Configuration,javax.net.SocketFactory) in org.apache.hadoop.ipc.RpcEngine
[INFO] 1 error
[INFO] -------------------------------------------------------------

{code}"
MAPREDUCE-3738,NM can hang during shutdown if AppLogAggregatorImpl thread dies unexpectedly,"If an AppLogAggregator thread dies unexpectedly (e.g.: uncaught exception like OutOfMemoryError in the case I saw) then this will lead to a hang during nodemanager shutdown.  The NM calls AppLogAggregatorImpl.join() during shutdown to make sure log aggregation has completed, and that method internally waits for an atomic boolean to be set by the log aggregation thread to indicate it has finished.  Since the thread was killed off earlier due to an uncaught exception, the boolean will never be set and the NM hangs during shutdown repeating something like this every second in the log file:

2012-01-25 22:20:56,366 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AppLogAggregatorImpl: Waiting for aggregation to complete for application_1326848182580_2806"
MAPREDUCE-3737,The Web Application Proxy's is not documented very well,"The Web Application Proxy is a security feature, but there is no documentation for what it does, why it does it, and more importantly what attacks it is known not protect against.  This is so that anyone addopting Hadoop can know exactly what they potential security issues they may encounter."
MAPREDUCE-3736,Variable substitution depth too large for fs.default.name causes jobs to fail,"I'm seeing the same failure as MAPREDUCE-3462 in downstream projects running against a recent build of branch-23. MR-3462 modified the tests rather than fixing the framework. In that jira Ravi mentioned ""I'm still ignorant of the change which made the tests start to fail. I should probably understand better the reasons for that change before proposing a more generalized fix."" Let's figure out the general fix (rather than require all projects to set mapreduce.job.hdfs-servers in their conf we should fix this in the framework). Perhaps we should not default this config to ""$fs.default.name""?"
MAPREDUCE-3735,Add distcp jar to the distribution (tar),Distcp jar isnt getting added to the tarball as of now. We need to add it along with archives/streaming and others.
MAPREDUCE-3734,Provide a way to access,
MAPREDUCE-3733,Add Apache License Header to hadoop-distcp/pom.xml,Looks like I missed the Apache Headers in the review. Adding it now.
MAPREDUCE-3732,CS should only use 'activeUsers with pending requests' for computing user-limits,"CS should only use 'activeUsers with pending requests' for computing user-limits, similar to what is done in hadoop-1."
MAPREDUCE-3730,Allow restarted NM to rejoin cluster before RM expires it,"When a node in the RUNNING state (healthy or unhealthy) is rebooted, the resourcemanager rejects the nodemanager's registration request as a duplicate because it is convinced that the nodemanager is already running on that node.  It won't allow that node to rejoin the cluster until the node expiration time elapses which is 10min+ by default.  We should allow the NM to rejoin the cluster if it re-registers within the expiration timeout.

Note that this problem occurs with NMs that are configured to specific ports.  If ephemeral ports are used then a NM reboot ""works"" because the RM thinks the NM registration is for a new node.  See the discussions in MAPREDUCE-3070 and MAPREDUCE-3363.
"
MAPREDUCE-3729,"Commit build failing TestJobClientGetJob, TestMRWithDistributedCache, TestLocalModeWithNewApis","See https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1671//testReport/.
"
MAPREDUCE-3728,ShuffleHandler can't access results when configured in a secure mode,"While running the simplest of jobs (Pi) on MR2 in a fully secure configuration I have noticed that the job was failing on the reduce side with the following messages littering the nodemanager logs:

{noformat}
2012-01-19 08:35:32,544 ERROR org.apache.hadoop.mapred.ShuffleHandler: Shuffle error
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find usercache/rvs/appcache/application_1326928483038_0001/output/attempt_1326928483038_0001_m_000003_0/file.out.index in any of the configured local directories
{noformat}

While digging further I found out that the permissions on the files/dirs were prohibiting nodemanager (running under the user yarn) to access these files:

{noformat}
$ ls -l /data/3/yarn/usercache/testuser/appcache/application_1327102703969_0001/output/attempt_1327102703969_0001_m_000001_0
-rw-r----- 1 testuser testuser 28 Jan 20 15:41 file.out
-rw-r----- 1 testuser testuser 32 Jan 20 15:41 file.out.index
{noformat}

Digging even further revealed that the group-sticky bit that was faithfully put on all the subdirectories between testuser and application_1327102703969_0001 was gone from output and attempt_1327102703969_0001_m_000001_0. 

Looking into how these subdirectories are created (org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.initDirs())
{noformat}
      // $x/usercache/$user/appcache/$appId/filecache
      Path appFileCacheDir = new Path(appBase, FILECACHE);
      appsFileCacheDirs[i] = appFileCacheDir.toString();
      lfs.mkdir(appFileCacheDir, null, false);
      // $x/usercache/$user/appcache/$appId/output
      lfs.mkdir(new Path(appBase, OUTPUTDIR), null, false);
{noformat}

Reveals that lfs.mkdir ends up manipulating permissions and thus clears sticky bit from output and filecache.

At this point I'm at a loss about how this is supposed to work. My understanding was
that the whole sequence of events here was predicated on a sticky bit set so
that daemons running under the user yarn (default group yarn) can have access
to the resulting files and subdirectories down at output and below. Please let
me know if I'm missing something or whether this is just a bug that needs to be fixed.

On a related note, when the shuffle side of the Pi job failed the job itself didn't.
It went into the endless loop and only exited when it exhausted all the local storage
for the log files (at which point the nodemanager died and thus the job ended). Perhaps
this is even more serious side effect of this issue that needs to be investigated 
separately."
MAPREDUCE-3727,jobtoken location property in jobconf refers to wrong jobtoken file,"Oozie launcher job (for MR/Pig/Hive/Sqoop action) reads the location of the jobtoken file from the *HADOOP_TOKEN_FILE_LOCATION* ENV var and seeds it as the *mapreduce.job.credentials.binary* property in the jobconf that will be used to launch the real (MR/Pig/Hive/Sqoop) job.

The MR/Pig/Hive/Sqoop submission code (via Hadoop job submission) uses correctly the injected *mapreduce.job.credentials.binary* property to load the credentials and submit their MR jobs.

The problem is that the *mapreduce.job.credentials.binary* property also makes it to the tasks of the MR/Pig/Hive/Sqoop MR jobs.

If for some reason the MR/Pig/Hive/Sqoop MR code does some logic that triggers the credential loading, because the property is set, the credential loading fails trying to load a jobtoken file of the launcher job which does not exists in the context of the MR/Pig/Hive/Sqoop jobs.

More specifically, we are seeing this happening with certain hive queries that trigger a conditional code within their RowContainer which then uses the FileInputFormat.getSplits() and then the TokenCache tries to load credentials for a file that is for the wrong job.
"
MAPREDUCE-3725,Hadoop 22 hadoop job -list returns user name as NULL,Hadoop 22 hadoop job -list returns user name as NULL
MAPREDUCE-3724,jobclient-tests.jar 's MapredTestDriver doesn't contain the newly added examples/test programs,"MR Example jobs which are used in QE have been copied (not moved) into jobclient-tests.jar. However the MapredTestsDriver.java file does not include the two added tests. We should decide if we want to get rid of the mapreduce-examples.jar and move all the tests to jobclients-tests.jar, or keep the current setup."
MAPREDUCE-3723,TestAMWebServicesJobs & TestHSWebServicesJobs incorrectly asserting tests,"While testing a patch for one of the MR issues, I found TestAMWebServicesJobs & TestHSWebServicesJobs incorrectly asserting tests. 
Moreover tests may fail if
{noformat}
	index of counterGroups > #counters in a particular counterGroup
{noformat}
{code:title=TestAMWebServicesJobs.java|borderStyle=solid}
for (int j = 0; j < counters.length(); j++) {
 JSONObject counter = counters.getJSONObject(i);
{code}

where is *i* is index of outer loop. It should be *j* instead of *i*."
MAPREDUCE-3721,Race in shuffle can cause it to hang,"If all current {{Fetcher}}s complete while an in-memory merge is in progress - shuffle could hang. 
Specifically - if the memory freed by an in-memory merge does not bring {{MergeManager.usedMemory}} below {{MergeManager.memoryLimit}} and all current Fetchers complete before the in-memory merge completes, another in-memory merge will not be triggered - and shuffle will hang. (All new fetchers are asked to WAIT).
"
MAPREDUCE-3720,Command line listJobs should not visit each AM,"When the RM has a large number of jobs, {{bin/mapred job -list}} takes a long time as it visits each AM to get information like num-maps, num-reduces etc.

We should move all per-AM information to {{bin/mapred job -status}} and keep the list just a list."
MAPREDUCE-3719,Make gridmix performance on YARN+MR to match or exceed that on 1.0,
MAPREDUCE-3718,Default AM heartbeat interval should be one second,"Helps in improving app performance. RM should be able to handle this, as the heartbeats aren't really costly."
MAPREDUCE-3717,JobClient test jar has missing files to run all the test programs.,Looks like MAPREDUCE-3582 forgot to move couple of files from the ant builds. The current test jar from jobclient does not work. 
MAPREDUCE-3716,java.io.File.createTempFile fails in map/reduce tasks,container-launch.sh specifies java option java.io.tmpdir when executing the java process for the child container but fails to create the tmpdir. All uses of createTempFile and other commands relying on java.io.tmpdir will fail when called from child container jvms.
MAPREDUCE-3714,Reduce hangs in a corner case,"[~karams] found this long time back and we(Sid/I) ran into this again.

Logs to follow.."
MAPREDUCE-3713,Incorrect headroom reported to jobs,"With multiple jobs submitted per user, and multiple users submitting jobs - the headroom reported to the AppMasters is incorrect (very high).
Leads to a deadlock - reduces started, map tasks not complete... and reduces are not preempted by the AM due to the incorrect headroom."
MAPREDUCE-3712,The mapreduce tar does not contain the hadoop-mapreduce-client-jobclient-tests.jar. ,"Working MRv1 tests were moved into the maven build as part of MAPREDUCE-3582. Some classes like MRBench, SleepJob, FailJob which are essential for QE got moved to jobclient-tests.jar. However the tar.gz file does not contain this jar."
MAPREDUCE-3711,AppMaster recovery for Medium to large jobs take long time,"Reported by [~karams]

yarn.resourcemanager.am.max-retries=2
Ran test cases with sort job on 350 scale having 16800 maps and 680 reduces -:
1. After 70 secs of Job Sumbission Am is killed using kill -9, around 3900 maps were completed and 680 reduces were
scheduled, Second AM got restart. Job got completed in 980 secs. AM took very less time to recover.
2. After 150 secs of Job Sumbission AM is killed using kill -9, around 90% maps were completed and 680 reduces were
scheduled , Second AM got restart Job got completed in 1000 secs. AM got revocer.
3. After 150 secs of Job Sumbission AM as killed using kill -9, almost all maps were completed and only 680 reduces
were running, Recovery was too slow, AM was still revocering after 1hr :40 mis when I killed the run."
MAPREDUCE-3710,last split generated by FileInputFormat.getSplits may not have the best locality,"The last split generated by FileInputFormat.getSplits considers {{blkLocations.length-1}} to be the hosts for the split.
The last split may be larger than the rest (SPLIT_SLOP=1.1 by default) - in which case locality is picked up from a smaller block.
e.g. 1027MB file with a 128MB split size. The last split ends up being 131MB. The hosts for locality end up being the nodes containing the 3MB block instead of the 128MB block.
"
MAPREDUCE-3709,TestDistributedShell is failing,"TestDistributedShell#testDSShell is failing the assert on line 90 on branch-23.
"
MAPREDUCE-3708,Metrics: Incorrect Apps Submitted Count,"Submitted an application with the following configuration
{code:xml}
<property>
 <name>yarn.resourcemanager.am.max-retries</name>
 <value>2</value>
</property>
{code}
In the above case, application had failed first time. So AM attempted the same application again. 
While attempting the same application, *Apps Submitted* counter also has been incremented."
MAPREDUCE-3706,HTTP Circular redirect error on the job attempts page,"submitted job and tried to go to following url:

http://rmhost.domain.com:8088/proxy/application_1326992308313_0004/mapreduce/attempts/job_1326992308313_4_4/m/NEW

This resulted in the following HTTP ERROR:

HTTP ERROR 500

Problem accessing /proxy/application_1326992308313_0004/mapreduce/attempts/job_1326992308313_4_4/m/NEW. Reason:

    Circular redirect to 'http://amhost.domain.com:44869/mapreduce/attempts/job_1326992308313_4_4/m/NEW'

Caused by:

org.apache.commons.httpclient.CircularRedirectException: Circular redirect to 'http://amhost.domain.com:44869/mapreduce/attempts/job_1326992308313_4_4/m/NEW'
        at org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse(HttpMethodDirector.java:638)
        at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:179)
        at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
        at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
        at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.proxyLink(WebAppProxyServlet.java:148)        at org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(WebAppProxyServlet.java:269)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511)
        at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221)        at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:66)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:900)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:834)
        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:795)


Note that if you first go to the proxy at: http://rmhost.domain.com:8088/proxy/application_1326992308313_0004/ and then click the links to get here you don't get the error."
MAPREDUCE-3705,ant build fails on 0.23 branch ,"running the ant build in mapreduce on the latest 23 branch fails.  Looks like the ivy properties file still has 0.24.0 and then the gridmix dependencies need to have rumen as dependency.

The gridmix errors look like:
   [javac] /home/tgraves/anttest/hadoop-mapreduce-project/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/DistributedCacheEmulator.java:249: cannot find symbol
    [javac] symbol  : class JobStoryProducer
    [javac] location: class org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator
    [javac]   int setupGenerateDistCacheData(JobStoryProducer jsp)
    [javac]                                  ^"
MAPREDUCE-3704,Yarn client goes into tight loop upon connection failure,"If the client fails to connect to the AM or HS, it will go into a tight loop retrying the connection.  The log rapidly grows with multiple log lines per attempt.  Based one of the logs, the client was pounding on the AM ~1000/sec."
MAPREDUCE-3703,ResourceManager should provide node lists in JMX output,"In 0.20.*, the JMX UI for the JobTracker (http://<JobTrackerHost>:50030/jmx) showed lists of Live and BlackListed Nodes under the JobTrackerInfo section.

In 0.23, the ResourceManager JMX UI shows the number of active, decommissioned, lost, unhealthy, and rebooted nodes under the ClusterMetrics section, but does not give the list of nodes.

At least the list of active nodes is needed in JSON format."
MAPREDUCE-3702,internal server error trying access application master via proxy with filter enabled,"I had a hadoop.http.filter.initializers in place to do user authentication, but was purposely trying to let it bypass authentication on certain pages.  One of those was the proxy and the application master main page. When I then tried to go to the application master through the proxy it throws an internal server error:

Problem accessing /mapreduce. Reason:

    INTERNAL_SERVER_ERROR
Caused by:

java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:100)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:940)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)


It looks like the problem is that AmIpFilter doesn't check for null returned from httpReq.getCookies()"
MAPREDUCE-3701,Delete HadoopYarnRPC from 0.23 branch.,HadoopYarnRPC file exists in 0.23 (should have been removed with the new HadoopYarnProtoRPC). Trunk does not have this issue.
MAPREDUCE-3699,Default RPC handlers are very low for YARN servers,"Mainly NM has a default of 5, RM has 10 and AM also has 10 irrespective of num-slots, num-nodes and num-tasks respectively. Though ideally we want to scale according to slots/nodes/tasks, for now increasing the defaults should be enough."
MAPREDUCE-3698,Client cannot talk to the history server in secure mode,"{noformat}
12/01/19 02:56:22 ERROR security.UserGroupInformation: PriviledgedActionException as:XXX@XXX(auth:KERBEROS) cause:java.io.IOException: Failed to specify server's Kerberos principal name
12/01/19 02:56:22 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
{noformat}"
MAPREDUCE-3697,Hadoop Counters API limits Oozie's working across different hadoop versions,"Oozie uses Hadoop Counters API, by invoking Counters.getGroup(). However, in
hadoop 23, org.apache.hadoop.mapred.Counters does not implement getGroup(). Its
parent class AbstractCounters implements it. This is different from hadoop20X.
As a result, Oozie compiled with either hadoop version does not work with the
other version.
A specific scenario, Oozie compiled with .23 and run against 205, does not
update job status owing to a Counters API exception.

Will explicit re-compilation against the relevant hadoop jars be required each
time? This will prevent launching a uniform Oozie version across different
clusters."
MAPREDUCE-3696,MR job via oozie does not work on hadoop 23,"NM throws an error on submitting an MR job via oozie on the latest Hadoop 23.
*Courtesy: Mona Chitnis (ooize)"
MAPREDUCE-3694,JobClient.getJob(JobID) broken in 0.23 for LocalJobRunner?,"In LocalJobRunner, when a job is submitted through old JobClient, and when its status is queried from getJob(JobID), it returns null. The issue seen on HIVE-2708.
"
MAPREDUCE-3693,Add admin env to mapred-default.xml,"I have noticed that org.apache.hadoop.mapred.MapReduceChildJVM doesn't forward the value of -Djava.library.path= from the parent JVM to the child JVM. Thus if one wants to use native libraries for compression the only option seems to be to manually include relevant java.library.path settings into the mapred-site.xml (as mapred.[map|reduce].child.java.opts).

This seems to be a change in behavior compared to MR1 where TaskRunner.java used to do that:

{noformat}
String libraryPath = System.getProperty(""java.library.path"");
    if (libraryPath == null) {
      libraryPath = workDir.getAbsolutePath();
    } else {
      libraryPath += SYSTEM_PATH_SEPARATOR + workDir;
    }
    boolean hasUserLDPath = false;
    for(int i=0; i<javaOptsSplit.length ;i++) {
      if(javaOptsSplit[i].startsWith(""-Djava.library.path="")) {
        javaOptsSplit[i] += SYSTEM_PATH_SEPARATOR + libraryPath;
        hasUserLDPath = true;
        break;
      }
    }
    if(!hasUserLDPath) {
      vargs.add(""-Djava.library.path="" + libraryPath);
    }
    for (int i = 0; i < javaOptsSplit.length; i++) {
      vargs.add(javaOptsSplit[i]);
    }
{noformat}

Is this a regression or a deliberate choice?"
MAPREDUCE-3692,yarn-resourcemanager out and log files can get big,"I'm seeing 8gb resourcemanager out files and big log files, seeing lots of repeated logs (eg every rpc call or event) looks like we're being too verbose in  a couple of places.
"
MAPREDUCE-3691,webservices add support to compress response," The web services currently don't support header 'Accept-Encoding: gzip'

Given that the responses have a lot of duplicate data like the property names in JSON or the tag names in XML, it should
compress very well, and would save on bandwidth and download time when fetching a potentially large response, like the
ones from ws/v1/cluster/apps and ws/v1/history/mapreduce/jobs"
MAPREDUCE-3690,mapred.ClientServiceDelegate.java:getProxy prints the proxy without http:// prefix,"Example job client stdout capture

2012-01-18 10:30:00,980 INFO  mapred.ClientServiceDelegate (ClientServiceDelegate.java:getProxy(178)) - The url to
track the job: machine.example.com:8088/proxy/application_1326903944546_0002/"
MAPREDUCE-3689,RM web UI doesn't handle newline in job name,"a user submitted a mapreduce job with a newline (\n) in the job name. This caused the resource manager web ui to get a javascript exception when loading the application and scheduler pages and the pages were pretty well useless after that since they didn't load everything.  Note that this only happens when the data is returned in the JS_ARRAY, which is when you get over 100 applications.

errors:
Uncaught SyntaxError: Unexpected token ILLEGAL
Uncaught ReferenceError: appsData is not defined

It seems odd that we allow the \n in the job name.  It appears we allow it in 1.0 also, although when I ran a test the job itself failed in taskrunner. 0.23 seems to run the job fine with the \n in the job name. "
MAPREDUCE-3687,"If AM dies before it returns new tracking URL, proxy redirects to http://N/A/ and doesn't return error code","I tried to turn on Uber AM and put 9223372036854775807l (last char is an L) for maxbytes.  This caused a
NumberFormatException in the AM and killed it.

When I try to go to the RM proxy, it redirects me to http://N/A/

curl -i http://resource.manager.example.com:$port/proxy/application_1326504761991_0001/
HTTP/1.1 302 Found
Content-Type: text/plain; charset=utf-8
Location: http://N/A/
Content-Length: 0
Server: Jetty(6.1.26)

Since the AM has no tracker URL, I would expect the return code to be 400~ or 500~ and return an error."
MAPREDUCE-3686,history server web ui - job counter values for map/reduce not shown properly,"Looking at the job counters page on the history server for a finished job, it shows 3 columns for each counter - map, reduce, total. The total appears correct, but map and reduce columns are always zero.  If you click on a particular column it does show you the map/reduce task and the value of each one.

Going to attach screenshots shortly."
MAPREDUCE-3685,There are some bugs in implementation of MergeManager,
MAPREDUCE-3684,LocalDistributedCacheManager does not shut down its thread pool,This was observed by running a Hive job in local mode. The job completed but the client process did not exit for 60 seconds.
MAPREDUCE-3683,Capacity scheduler LeafQueues maximum capacity calculation issues,"In the Capacity scheduler if you configure the queues to be hierarchical where you have root -> parent queue -> leaf queue, the leaf queue doesn't take into account its parents maximum capacity when calculate its own maximum capacity, instead it seems to use the parents capacity.  Looking at the code its using the parents absoluteCapacity and I think it should be using the parents absoluteMaximumCapacity.

It also seems to only use the parents capacity in the leaf queues max capacity calculation when the leaf queue has a max capacity configured. If the leaf queues maximum-capacity is not configured, then it can use 100% of the cluster.  "
MAPREDUCE-3682,Tracker URL says AM tasks run on localhost,"If you look at the task page, it will show you the node the task ran on.  For jobs that run in UberAM they point to http://localhost:9999 and logs points to http://localhost:9999/node/containerlogs/$container_id/

This was run on a multi node cluster."
MAPREDUCE-3681,capacity scheduler LeafQueues calculate used capacity wrong,"In the Capacity scheduler if you configure the queues to be hierarchical where you have root -> parent queue -> leaf queue, the leaf queue doesn't calculate the used capacity properly. It seems to be using the entire cluster memory rather then its parents memory capacity. 

In updateResource in LeafQueue:
    setUsedCapacity(
        usedResources.getMemory() / (clusterResource.getMemory() * capacity));

I think the clusterResource.getMemory() should be something like getParentsMemory()."
MAPREDUCE-3680,FifoScheduler web service rest API can print out invalid JSON,"running a GET on the scheduler web services rest api (RM:port/ws/cluster/scheduler) with the FifoScheduler configured with no nodemanagers up yet and it prints out invalid json of NaN for the used Capacity:

{""scheduler"":{""schedulerInfo"":{""type"":""fifoScheduler"",""capacity"":1.0,""usedCapacity"":NaN,""qstate"":""RUNNING"",""minQueueMemoryCapacity"":1024,""maxQueueMemoryCapacity"":10240,""numNodes"":0,""usedNodeCapacity"":0,""availNodeCapacity"":0,""totalNodeCapacity"":0,""numContainers"":0}}}"
MAPREDUCE-3679,AM logs and others should not automatically refresh after every 1 second.,"If you are looking through the logs for AM or containers, the page is automatically refreshed after 1 second or so which makes it problematic to search through the page or debug using the content on the page. We should not refresh the logs page. There should be a button to manually refresh if the user needs to."
MAPREDUCE-3678,The Map tasks logs should have the value of input split it processed,"It would be easier to debug some corner in tasks if we knew what was the input split processed by that task. Map reduce task tracker log should accommodate the same. Also in the jobdetails web UI, the split also should be displayed along with the Split Locations. 

Sample as
Input Split
hdfs://myserver:9000/userdata/sampleapp/inputdir/file1.csv - <split no>/<offset from beginning of file>

This would be much beneficial to nail down some data quality issues in large data volume processing.
"
MAPREDUCE-3677,"If ""hadoop.security.authorization"" is set to true, NM is not starting.","I have the hadoop cluster setup with root user.Accidentally i have set hadoop.security.authorization to true.I have not set any permissions in policy.xml.When i am trying to start the NM with root user ...it is throwing the following error

Exception in thread ""main"" java.lang.NoClassDefFoundError: nodemanager
Caused by: java.lang.ClassNotFoundException: nodemanager
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:303)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:316)
Could not find the main class: nodemanager.  Program will exit."
MAPREDUCE-3675,A job must not be submitted when there are no mappers to run,"Right now, one's able to run a job with an empty input directory and a job is indeed scheduled.

The job runs no mappers, but any number of specified reducers are run anyway as dummy tasks.

This should be/could be avoided. I do not see a use for such an allowance, and it looks mostly like a logic slip to me with empty arrays involved and accepted.

The fix could be simply in the job submission code, where we can avoid submitting if the splits are nil."
MAPREDUCE-3674,"If invoked with no queueName request param, jobqueue_details.jsp injects a null queue name into schedulers.","When you access /jobqueue_details.jsp manually, instead of via a link, it has queueName set to null internally and this goes for a lookup into the scheduling info maps as well.

As a result, if using FairScheduler, a Pool with String name = null gets created and this brings the scheduler down. I have not tested what happens to the CapacityScheduler, but ideally if no queueName is set in that jsp, it should fall back to 'default'. Otherwise, this brings down the JobTracker completely.

FairScheduler must also add a check to not create a pool with 'null' name.

The following is the strace that ensues:

{code}
ERROR org.mortbay.log: /jobqueue_details.jsp 
java.lang.NullPointerException 
at org.apache.hadoop.mapred.jobqueue_005fdetails_jsp._jspService(jobqueue_005fdetails_jsp.java:71) 
at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97) 
at javax.servlet.http.HttpServlet.service(HttpServlet.java:820) 
at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:511) 
at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1221) 
at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:829) 
at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212) 
at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399) 
at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216) 
at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182) 
at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766) 
at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450) 
at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230) 
at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152) 
at org.mortbay.jetty.Server.handle(Server.java:326) 
at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542) 
at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928) 
at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549) 
at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212) 
at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404) 
at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410) 
at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582) 
INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001, call heartbeat from XYZ:MNOP: error: java.io.IOException: java.lang.NullPointerException 
java.io.IOException: java.lang.NullPointerException 
at org.apache.hadoop.mapred.SchedulingAlgorithms$FairShareComparator.compare(SchedulingAlgorithms.java:95) 
at org.apache.hadoop.mapred.SchedulingAlgorithms$FairShareComparator.compare(SchedulingAlgorithms.java:68) 
at java.util.Arrays.mergeSort(Unknown Source) 
at java.util.Arrays.sort(Unknown Source) 
at java.util.Collections.sort(Unknown Source) 
at org.apache.hadoop.mapred.FairScheduler.assignTasks(FairScheduler.java:435) 
at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:3226) 
at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source) 
at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) 
at java.lang.reflect.Method.invoke(Unknown Source) 
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:557) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1434) 
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1430) 
at java.security.AccessController.doPrivileged(Native Method) 
at javax.security.auth.Subject.doAs(Unknown Source) 
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1127) 
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1428)
{code}"
MAPREDUCE-3672,Killed maps shouldn't be counted towards JobCounter.NUM_FAILED_MAPS,"We count maps that are killed, say by speculator, towards JobCounter.NUM_FAILED_MAPS. We should instead have a separate JobCounter for killed maps.

Same with reduces too."
MAPREDUCE-3669,Getting a lot of PriviledgedActionException / SaslException when running a job,"On a secure cluster, when running a job we are seeing a lot of PriviledgedActionException / SaslExceptions.  The job runs fine, its just the jobclient can't connect to the AM to get the progress information.

Its in a very tight loop retrying while getting the exceptions.

snip of the client log is:
12/01/13 15:33:45 INFO security.SecurityUtil: Acquired token Ident: 00 1c 68 61 64 6f 6f 70 71 61 40 44 45 56 2e 59 47
52 49 44 2e 59 41 48 4f 4f 2e 43 4f 4d 08 6d 61 70 72 65 64 71 61 00 8a 01 34 d7 b3 ff f5 8a 01 34 fb c0 83 f5 08 02,
Kind: HDFS_DELEGATION_TOKEN, Service: 10.10.10.10:8020
12/01/13 15:33:45 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 8 for user1 on 10.10.10.10:8020
12/01/13 15:33:45 INFO security.TokenCache: Got dt for
hdfs://host1.domain.com:8020;uri=10.10.10.10:8020;t.service=10.10.10.10:8020
12/01/13 15:33:45 WARN conf.Configuration: mapred.used.genericoptionsparser is deprecated. Instead, use
mapreduce.client.genericoptionsparser.used
12/01/13 15:33:45 INFO mapreduce.JobSubmitter: number of splits:2
12/01/13 15:33:45 INFO mapred.ResourceMgrDelegate: Submitted application application_1326410042859_0008 to
ResourceManager at rmhost.domain/10.10.10.11:8040
12/01/13 15:33:45 INFO mapreduce.Job: Running job: job_1326410042859_0008
12/01/13 15:33:52 INFO mapred.ClientServiceDelegate: The url to track the job:
rmhost.domain:8088/proxy/application_1326410042859_0008/
12/01/13 15:33:52 ERROR security.UserGroupInformation: PriviledgedActionException as:user1@DEV.YGRID.YAHOO.COM
(auth:SIMPLE) cause:javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (Mechanism level: Fail
ed to find any
Kerberos tgt)]
12/01/13 15:33:52 WARN ipc.Client: Exception encountered while connecting to the server :
javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided
(Mechanism level: Failed to find any Kerberos tgt)]
12/01/13 15:33:52 ERROR security.UserGroupInformation: PriviledgedActionException as:user1@DEV.YGRID.YAHOO.COM
(auth:SIMPLE) cause:java.io.IOException: javax.security.sasl.SaslException: GSS initiate failed [Caused by GSSException: No valid credentials provided (
Mechanism level:
Failed to find any Kerberos tgt)]
12/01/13 15:33:52 INFO mapred.ClientServiceDelegate: The url to track the job:
rmhost.domain:8088/proxy/application_1326410042859_0008/"
MAPREDUCE-3668,AccessControlException when running mapred job -list command,"If a user tries to examine the status of all jobs running on a secure cluster the mapred client can fail with an AccessControlException.  For example, submitting two jobs each from a different user then trying to query the status as the second user can fail like this:

$ mapred job -list all
12/01/12 20:01:12 WARN conf.Configuration: mapred.used.genericoptionsparser is deprecated. Instead, use
mapreduce.client.genericoptionsparser.used
Total jobs:2
JobId   State   StartTime       UserName        Queue   Priority        Maps    Reduces UsedContainers  RsvdContainers UsedMem RsvdMem NeededMem       AM info
12/01/12 20:01:14 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
job_1326396427223_0002  SUCCEEDED       1326398424244   user2        default NORMAL  2       2       0       0      0M      0M      0M     
hostremoved:8088/proxy/application_1326396427223_0002/jobhistory/job/job_1326396427223_2_2
12/01/12 20:01:14 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
12/01/12 20:01:14 WARN mapred.ClientServiceDelegate: Error from remote end: User user2 cannot perform operation VIEW_JOB on job_1326396427223_0001
Exception in thread ""main"" RemoteTrace: 
java.security.AccessControlException: User user2 cannot perform operation VIEW_JOB on job_1326396427223_0001
        at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$MRClientProtocolHandler.checkAccess(HistoryClientService.java:293)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$MRClientProtocolHandler.verifyAndGetJob(HistoryClientService.java:184)
        at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService$MRClientProtocolHandler.getJobReport(HistoryClientService.java:200)
        at org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getJobReport(MRClientProtocolPBServiceImpl.java:106)
        at org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:187)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:344)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1490)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1486)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1157)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1484)
 at Local Trace: 
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: User user2 cannot perform operation VIEW_JOB on job_1326396427223_0001
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151)
        at $Proxy10.getJobReport(Unknown Source)
        at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getJobReport(MRClientProtocolPBClientImpl.java:104)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:328)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:405)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:431)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:186)
        at org.apache.hadoop.mapreduce.tools.CLI.displayJobList(CLI.java:571)
        at org.apache.hadoop.mapreduce.tools.CLI.listAllJobs(CLI.java:500)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:298)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1209)


The information provided by the command is similar to what is presented on the ResourceManager web UI, and that page has no security.

Marking this as a blocker since many of our automated acceptance tests use this command to obtain the status of jobs running in the cluster."
MAPREDUCE-3667,Gridmix jobs are failing with OOM in reduce shuffle phase.,Roll up bug for gridmix3 benchmark
MAPREDUCE-3665,Hadoop ignores old-style config options for enabling compressed output,"Hadoop seems to ignore the config options even though they are printed as deprecation warnings in the log:  mapred.output.compress and
mapred.output.compression.codec

-- settings that work on 0.20 but not on 0.23
mapred.output.compress=true
mapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec

-- settings that work on 0.23
mapreduce.output.fileoutputformat.compress=true
mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.BZip2Codec

This breaks backwards compatibility and causes existing jobs to fail."
MAPREDUCE-3664,HDFS Federation Documentation has incorrect configuration example,"HDFS Federation documentation example (1) has the following

<property>
    <name>dfs.namenode.rpc-address.ns1</name>
    <value>hdfs://nn-host1:rpc-port</value>
</property>

dfs.namenode.rpc-address.* should be set to hostname:port, hdfs:// should not be there.

(1) - http://hadoop.apache.org/common/docs/r0.23.0/hadoop-yarn/hadoop-yarn-site/Federation.html"
MAPREDUCE-3663,"After submitting a job. If the Runjar process gets killed ,then the job is hanging","When the job is submitted...Runjar process is created and the YarnChild processes also start running.If at this time ,the RunJar process is getting killed, the job is hanging."
MAPREDUCE-3662,Command line ask: NM info where containers are launched,"Courtesy [~rramya]
{quote}
we had requested for the NM information where the containers are scheduled to be made available in job
-list-attempt-ids. This will be helpful in automation, debugging and avoid grepping through the AM logs.
{quote}
"
MAPREDUCE-3659,Host-based token support,Need to port the 205 host-based token support into MR and yarn.
MAPREDUCE-3657,State machine visualize build fails,Attempting to build the state machine graphs with {{mvn -Pvisualize compile}} fails for the resourcemanager and nodemanager projects.  The build fails because org.apache.commons.logging.LogFactory isn't in the classpath.
MAPREDUCE-3656,Sort job on 350 scale is consistently failing with latest MRV2 code ,"With the code checked out on last two days. 
Sort Job on 350 node scale with 16800 maps and 680 reduces consistently failing for around last 6 runs
When around 50% of maps are completed, suddenly job jumps to failed state.
On looking at NM log, found RM sent Stop Container Request to NM for AM container.
But at INFO level from RM log not able find why RM is killing AM when job is not killed manually.
One thing found common on failed AM logs is -:
org.apache.hadoop.yarn.state.InvalidStateTransitonException
With with different.
For e.g. One log says -:
{code}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_UPDATE at ASSIGNED 
{code}
Whereas other logs says -:
{code}
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: JOB_COUNTER_UPDATE at ERROR
{code}

"
MAPREDUCE-3654,"MiniMRYarnCluster should set MASTER_ADDRESS to ""local""",I needed to make the attached change in order for MiniMRCluster based HBase tests to get past job client initialization.
MAPREDUCE-3653,Improvements to CapacityScheduler doc,"I noticed the following issues with the capacity scheduler doc: ./hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/CapacityScheduler.apt.vm

- In overview section, 3rd paragraph,  sentence ""There is an added benefit that an organization can access any excess capacity no being used by others"".  No should be not. 
- in overview section, 4th paragraph. dispropotionate misspelled 
- in features section, under multitenancy - monopolizing is misspelled. 
- in features section, under operability - it doesn't say if you can delete queues at runtime?  I see there is a note at the end but perhaps that can be added into the other sections to since its easy to miss that Note at the very end. 
- in features section - hierarchy and Hierarchical mispelled. 
- under configuration section the class to turn on to use capacity scheduler should be: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler 
- section on setting up queues, 4th sentence - hierarchy misspelled as heirarcy  and heirarchy. 
- I think specifying how a user has to specify the queue when running a job/app would be useful information.  Especially with the new hierarchical queues.  Does the user have to specify the entire path like a.b.c or can they just specify c. 
- under ""Running and Pending Application Limits"" section, property ""yarn.scheduler.capacity.maximum-applications"", they are referred to them as jobs, I believe that should be applications. 
- misspelled concurrently as concurently in same section of maximum-applications. 
- I think it should specify the defaults (if any) for the config vars.   Also what format are they specified in - int, float,etc? 
- might be nice to say it doesn't support preemption. 
- under admin options yarn.scheduler.capacity.<queue-path>.state - queues misspelled as queueus 
- under changing queue configuration it should have ""yarn"" in front of the ""rmadmin -refreshQueues"". Similarly a few lines down at ""$YARN_HOME/bin/rmadmin -refreshQueues"""
MAPREDUCE-3652,org.apache.hadoop.mapred.TestWebUIAuthorization.testWebUIAuthorization fails,"org.apache.hadoop.mapred.TestWebUIAuthorization.testWebUIAuthorization fails.

This is testing the old jsp web interfaces.  I think this test should just be removed.


Any objections?"
MAPREDUCE-3651,TestQueueManagerRefresh fails,"The following tests fail:
org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshWithRemovedQueues 
org.apache.hadoop.mapred.TestQueueManagerRefresh.testRefreshOfSchedulerProperties 

It looks like its simply trying to remove one of the queues but the remove is failing.It looks like MAPREDUCE-3328. mapred queue -list output inconsistent and missing child queues - change the getChilren routine to do a new JobQueueInfo on each one when returning it which is making the remove routine fail since they aren't the same object now."
MAPREDUCE-3650,testGetTokensForHftpFS() fails," org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForHftpFS  fails.

Looks like it may have been introduced with HADOOP-7808"
MAPREDUCE-3649,Job End notification gives an error on calling back.,"When calling job end notification for oozie the AM fails with the following trace:

{noformat}
2012-01-09 23:45:41,732 WARN [AsyncDispatcher event handler] org.mortbay.log: Job end notification to http://HOST:11000/oozie/v0/callback?id=0000000-120109234442311-oozie-oozi-W@mr-node&status=SUCCEEDED& failed
java.net.UnknownServiceException: no content-type
	at java.net.URLConnection.getContentHandler(URLConnection.java:1192)
	at java.net.URLConnection.getContent(URLConnection.java:689)
	at org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notifyURLOnce(JobEndNotifier.java:95)
	at org.apache.hadoop.mapreduce.v2.app.JobEndNotifier.notify(JobEndNotifier.java:139)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:388)
	at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$JobFinishEventHandler.handle(MRAppMaster.java:375)
	at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:125)
	at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:82)
{noformat}"
MAPREDUCE-3648,TestJobConf failing,"TestJobConf is failing:



testFindContainingJar 
testFindContainingJarWithPlus 

java.lang.ClassNotFoundException: ClassWithNoPackage
	at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:247)
	at org.apache.hadoop.mapred.TestJobConf.testJarAtPath(TestJobConf.java:78)
	at org.apache.hadoop.mapred.TestJobConf.testFindContainingJar(TestJobConf.java:44)


Looks like perhaps a classpath issue.


TestQueueManagerRefresh also has failures and I'm wondering might be related as it doesn't seem to pick up a config file written out to build/test/extraconf"
MAPREDUCE-3647,"Pipes job fails with ""Illegal text protocol""","Pipes job fail with ""Hadoop Pipes Exception: Illegal text protocol command"""
MAPREDUCE-3646,"Remove redundant URL info from ""mapred job"" output","The URL information to track the job is printed for all the ""mapred job""mrv2 commands. This information is redundant and has to be removed.

E.g:
{noformat}
-bash-3.2$ mapred job -list 

Total jobs:3
JobId   State   StartTime       UserName        Queue   Priority        Maps    Reduces UsedContainers  RsvdContainers  UsedMem RsvdMem NeededMem       AM info
12/01/09 22:20:15 INFO mapred.ClientServiceDelegate: The url to track the job: <RM host>:8088/proxy/<application ID 1>/
<job ID 1>  RUNNING 1326147596446   ramya  default NORMAL  10      10      21      0       22528M  0M      22528M  <RM host>:8088/proxy/<application ID 1>/
12/01/09 22:20:15 INFO mapred.ClientServiceDelegate: The url to track the job: <RM host>:8088/proxy/<application ID 2>/
<job ID 2>  RUNNING 1326147603726   ramya  default NORMAL  10      10      11      0       12288M  0M      12288M  <RM host>:8088/proxy/<application ID 2>/
12/01/09 22:20:16 INFO mapred.ClientServiceDelegate: The url to track the job: <RM host>:8088/proxy/<application ID 3>/
<job ID 3>  RUNNING 1326147520126   ramya  default NORMAL  10      10      21      0       22528M  0M      22528M  <RM host>:8088/proxy/<application ID 3>/
{noformat}
"
MAPREDUCE-3645,TestJobHistory fails,"TestJobHistory fails.

>>> org.apache.hadoop.mapred.TestJobHistory.testDoneFolderOnHDFS 	
>>> org.apache.hadoop.mapred.TestJobHistory.testDoneFolderNotOnDefaultFileSystem 	
>>> org.apache.hadoop.mapred.TestJobHistory.testHistoryFolderOnHDFS 	
>>> org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile 

It looks like this was introduced by MAPREDUCE-3349 and the issue is that the test expects the hostname to be in the format rackname/hostname, but with 3349 it split those apart into 2 different fields."
MAPREDUCE-3644,Snapshot builds have confusing jar file names in share/hadoop/mapreduce in tarball,"If you build a Hadoop tarball with a non-release version, the moduleSet used in hadoop-assemblies/src/main/resources/assemblies/hadoop-mapreduce-dist.xml results in jar files going into share/hadoop/mapreduce with unique snapshot versions - i.e., the timestamp they were built. This isn't an issue in release builds. It can be fixed by adding "" <outputFileNameMapping>${module.artifactId}-${project.version}${dashClassifier?}.${module.extension}</outputFileNameMapping>"" to the binaries tag of the moduleSet."
MAPREDUCE-3642,Remove hardcoded strings from the JC#displayTasks() call.,"This is to address Eli's comments on the parent task:

bq. 1. The error messages should generate the lists of valid states and types from their definitions rather than hard-coding them into the error messages.

bq. 2. Aren't these types and states defined somewhere already? Seems like they're a public API and therefore shouldn't have to duplicate the definition of them in taskTypes and taskStates.

"
MAPREDUCE-3641,CapacityScheduler should be more conservative assigning off-switch requests,"In hadoop-1, the CS is very conservative handing out off-switch assignments, we need to do the same in YARN.

We noticed performance regressions due to this, particularly for reduces."
MAPREDUCE-3640,AMRecovery should pick completed task form partial JobHistory files,"Currently, if the JobHistory file has a partial record, AMRecovery will start from scratch. This will become more relevant after MAPREDUCE-3512."
MAPREDUCE-3639,TokenCache likely broken for FileSystems which don't issue delegation tokens,Ref HADOOP-7963.
MAPREDUCE-3638,Yarn trying to download cacheFile to container but Path is a local file,"It looks like the AM, which is running on
host1.com, is trying to access a local file but the file is on host2.com
(where the command was run).

ran:
hadoop --config conf/hadoop/ 
jar hadoop-streaming.jar          -Dmapreduce.job.acl-view-job=*   
      -input Streaming/streaming-610/input.txt           -mapper 'xargs cat'           -reducer cat          -output
Streaming/streaming-610/Output          -cacheFile
file://Streaming/data/streaming-610//InputFile#testlink
         -jobconf mapred.map.tasks=1           -jobconf mapred.reduce.tasks=1          -jobconf
mapred.job.name=streamingTest-610          -jobconf mapreduce.job.acl-view-job=*

failure:

11/11/10 07:48:06 INFO mapreduce.Job: Job job_1320887371559_0215 failed with state FAILED due to: Application
application_1320887371559_0215 failed 1 times due to AM Container for appattempt_1320887371559_0215_000001 exited with 
exitCode: -1000 due to: java.io.FileNotFoundException: File
file:/Streaming/data/streaming-610/InputFile
does not exist
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:431)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:315)
        at org.apache.hadoop.yarn.util.FSDownload.copy(FSDownload.java:85)
        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:152)
        at org.apache.hadoop.yarn.util.FSDownload.call(FSDownload.java:50)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

"
MAPREDUCE-3637,Health checker interval does not appear to work - according to web ui,"reported by QE, I think this is probably a web ui not updating issue, but not positive.


1. The property yarn.nodemanager.health-checker.interval-ms on the RM and the DN are set to 135000 ms, or 2 minutes and
15 sec. 

$ grep -A 2 ""health-checker.interval-ms"" yarn-site.xml 
  <name>yarn.nodemanager.health-checker.interval-ms</name>
  <value>135000</value>
</property>

2. According to the web ui (e.g http://rm:8088/cluster/nodes), the 'last health-update'
column does not get updated, except when the RM is restated.
"
MAPREDUCE-3635,Improve Hadoop subcomponent integration in Hadoop 0.23,Please see HADOOP-7939 for a complete description and discussion. This JIRA is for patch tracking purposes only.
MAPREDUCE-3634,All daemons should crash instead of hanging around when their EventHandlers get exceptions,We should make sure that the daemons crash in case the dispatchers get exceptions and stop processing. That way we will be debugging RM/NM/AM crashes instead of hard-to-track hanging jobs. 
MAPREDUCE-3633,MAPREDUCE-1938 isn't present in 0.22 nor 0.23 nor trunk. Breaks API.,"MAPREDUCE-1938 introduced an API call in JobConf and the likes. This is not present in 0.22 nor 0.23.

Even if it isn't needed, the method must be still present as @Deprecated and perhaps made defunct inside if it should not do anything.

Not having this method is API breakage.

Let me know if am grossly wrong here."
MAPREDUCE-3632,Need better error message on the Web UI when NM can't find the container logs instead of NPEno,"If for some reason NM could not find container logs, then an NPE is seen while trying to access from web UI. Instead an error message should be displayed."
MAPREDUCE-3631,Corner case in headroom calculation,"When there is a single queue and a large job fills up the whole cluster, a lost NM can lead to wrong headroom when all
slots are taken up by reduces since at that point headroom isn't recomputed."
MAPREDUCE-3630,NullPointerException running teragen,"CMD = /grid/0/gs/gridre/yroot.omegab/share/hadoopcommon/bin/hadoop --config /grid/0/gs/gridre/yroot.omegab/conf/hadoop/
jar /grid/0/gs/gridre/yroot.omegab/share/hadoopmapred/hadoop-mapreduce-examples-*.jar teragen
-Dmapred.job.queue.name=audience -Dmapreduce.job.acl-view-job=* -Dyarn.app.mapreduce.am.staging-dir=/user
-Dmapreduce.jobtracker.staging.root.dir=/user 1 teraInputDir

Error:
11/09/21 21:59:59 INFO mapreduce.Job:  map 50% reduce 0%
11/09/21 22:00:00 INFO mapreduce.Job: Task Id : attempt_1316132655177_0533_m_000001_0, Status : FAILED
java.lang.NullPointerException
        at org.apache.hadoop.examples.terasort.TeraGen$SortGenMapper.cleanup(TeraGen.java:241)
        at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:708)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)

11/09/21 22:00:00 WARN mapreduce.Job: Error reading task output Server returned HTTP response code: 400 for URL: http://.../tasklog?plaintext=true&attemptid=attempt_1316132655177_0533_m_000001_0&filter=stdout
11/09/21 22:00:00 WARN mapreduce.Job: Error reading task output Server returned HTTP response code: 400 for URL: http://.../tasklog?plaintext=true&attemptid=attempt_1316132655177_0533_m_000001_0&filter=stderr
"
MAPREDUCE-3628,DFSIO read throughput is decreased by 16% in 0.23.1 than Hadoop-0.20.204 on 350 nodes size cluster.,DFSIO read throughput is decreased by 16% in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.
MAPREDUCE-3627,ClusterSetup docs for permissions on mapreduce.jobhistory.done-dir don't match jobhistory server startup,"The ClusterSetup docs for 0.23 list the permissions on mapreduce.jobhistory.done-dir should be drwxr-x---, but the job history server which will create that directory for you if its not there sets them to be 0770.

"
MAPREDUCE-3626,Findbugs warning in ContainerRemoteLaunchEvent,"Warning: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode
"
MAPREDUCE-3625,CapacityScheduler web-ui display of queue's used capacity is broken,"The display of the queue's used capacity at runtime is broken because it display's 'used' relative to the queue's capacity and not the parent's capacity as shown in the above attachment.

The display should be relative to parent's capacity and not leaf queues as everything else in the display is relative to parent's capacity.
"
MAPREDUCE-3624,bin/yarn script adds jdk tools.jar to the classpath.,"Thanks to Roman for pointing it out. Looks like we have the following lines in bin/yarn:

{code}
CLASSPATH=${CLASSPATH}:$JAVA_HOME/lib/tools.jar
{code}

We dont really have a dependency on the tools jar. We should remove this."
MAPREDUCE-3623,Authorization of NM <=> RM with simple authentication mistakenly attempts kerberos when yarn.nodemanager.principal is defined,"MAPREDUCE-3617 addresses the default values of yarn.nodemanager.principal and yarn.resourcemanager.principal

I have enabled authorization with simple authentication. NM <=> RM still attempts kerberos authentication. If simple authentication is enabled yarn.nodemanager.principal and yarn.resourcemanager.principal values should be ignored and simple authentication should be used.

{code:xml|title=core-site.xml snippet}
  <property>
    <name>hadoop.security.authentication</name>
    <value>simple</value>
    <description></description>
  </property>
  <property>
    <name>hadoop.security.authorization</name>
    <value>true</value>
    <description></description>
  </property>
{code}

{code:xml|title=yarn-site.xml snippet}
<property>
  <description>The Kerberos principal for the resource manager.</description>
  <name>yarn.resourcemanager.principal</name>
  <value>rm/sightbusy-lx@LOCALHOST</value>
</property>
<property>
  <description>The kerberos principal for the node manager.</description>
  <name>yarn.nodemanager.principal</name>
  <value>nm/sightbusy-lx@LOCALHOST</value>
</property>
{code}

{noformat:title=nodemanager.out snippet}
2012-01-03 16:40:00,793 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(176)) - Connected to ResourceManager at machine.example.com:8025
2012-01-03 16:40:00,845 ERROR service.CompositeService (CompositeService.java:start(72)) - Error starting services org.apache.hadoop.yarn.server.nodemanager.NodeManager
org.apache.avro.AvroRuntimeException: java.lang.reflect.UndeclaredThrowableException
    at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:149)
    at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
    at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:167)
    at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:242)
Caused by: java.lang.reflect.UndeclaredThrowableException
    at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:66)
    at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:182)
    at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:145)
    ... 3 more
Caused by: com.google.protobuf.ServiceException: org.apache.hadoop.security.authorize.AuthorizationException: User user (auth:SIMPLE) is not authorized for protocol interface org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, expected client Kerberos principal is nm/sightbusy-lx@LOCALHOST
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
    at $Proxy24.registerNodeManager(Unknown Source)
    at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)
    ... 5 more
Caused by: org.apache.hadoop.security.authorize.AuthorizationException: User user (auth:SIMPLE) is not authorized for protocol interface org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, expected client Kerberos principal is nm/sightbusy-lx@LOCALHOST
    at org.apache.hadoop.ipc.Client.call(Client.java:1085)
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
    ... 7 more
2012-01-03 16:40:00,846 WARN  event.AsyncDispatcher (AsyncDispatcher.java:run(78)) - AsyncDispatcher thread interrupted
java.lang.InterruptedException
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1961)
    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1996)
    at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:399)
    at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:76)
    at java.lang.Thread.run(Thread.java:662)
2012-01-03 16:40:00,846 INFO  service.AbstractService (AbstractService.java:stop(75)) - Service:Dispatcher is stopped.
{noformat}"
MAPREDUCE-3622,findbug error during test-patch: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode,"
findbug error: org.apache.hadoop.mapreduce.v2.app.launcher.ContainerRemoteLaunchEvent defines equals but not hashCode

first time I see this is build 1540:

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1540//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-app.html"
MAPREDUCE-3621,TestDBJob and TestDataDrivenDBInputFormat ant tests fail,"The following mapred ant tests fail and have been failing for a very long time:

[junit] Running org.apache.hadoop.mapreduce.lib.db.TestDBJob
[junit] Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat"
MAPREDUCE-3620,GrimdMix Stats at the end of GridMix are not reported correctly,"Courtesy [~vinaythota]
{quote}
Job trace contains 1205 jobs and Gridmix start processing 1200 jobs after processing. However, after completion of
gridmix run, execution summary details, it showed 1196 jobs are processed and remaining 4 jobs are missing. One log shows 1196 jobs processed and another
log shows 1200 jobs are processed.
{quote}
"
MAPREDUCE-3619,Change streaming code to use new mapreduce api.,"If we run a streaming job with following python script as mapper or reducer, the job will throws NullPointerException.
{code:}
#!/usr/bin/python
import sys,os
class MyTask:
  def __init__(self, file=sys.stdin):
    self.file = file
    print >>sys.stderr, ""reporter:counter:spam,disp_flag_record,0""
    print >>sys.stderr, ""reporter:counter:spam,spam_record,0""
  def process(self):
    while True:
      line = self.file.readline()
      if not line:
        break;
      print line

if __name__ == ""__main__"":
  task = MyTask()
  task.process()
{code}

Here is the NPE related log:
2011-12-22 14:14:06,310 WARN org.apache.hadoop.streaming.PipeMapRed: java.lang.NullPointerException
	at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.incrCounter(PipeMapRed.java:502)
	at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.run(PipeMapRed.java:444)

This is because the above script's ""print >>sys.stderr"" will invoke reporter.incrCounter() during PipeMapper|PipeReducer.configure(). While we can not get reporter in configure() function. 
To fix this problem, we should change streaming code to use new-api. Then we can call context.getCounter() in Mapper|Reducer.setup() function."
MAPREDUCE-3618,TaskHeartbeatHandler holds a global lock for all task-updates,
MAPREDUCE-3617,Remove yarn default values for resource manager and nodemanager principal,Default values should be empty since no use can be made of them without correct values defined.
MAPREDUCE-3616,Thread pool for launching containers in MR AM not expanding as expected,Found this while running some benchmarks on 350 nodes. The thread pool stays at 60 for a long time and only expands to 350 towards the fag end of the job.
MAPREDUCE-3615,mapred ant test failures,"The following mapred ant tests are failing.  This started on December 22nd.


    [junit] Running org.apache.hadoop.mapred.TestTrackerBlacklistAcrossJobs
    [junit] Running org.apache.hadoop.mapred.TestMiniMRDFSSort
    [junit] Running org.apache.hadoop.mapred.TestBadRecords
    [junit] Running org.apache.hadoop.mapred.TestClusterMRNotification
    [junit] Running org.apache.hadoop.mapred.TestDebugScript
    [junit] Running org.apache.hadoop.mapred.TestJobCleanup
    [junit] Running org.apache.hadoop.mapred.TestJobClient
    [junit] Running org.apache.hadoop.mapred.TestJobHistory
    [junit] Running org.apache.hadoop.mapred.TestJobInProgressListener
    [junit] Running org.apache.hadoop.mapred.TestJobKillAndFail
    [junit] Running org.apache.hadoop.mapred.TestJvmReuse
    [junit] Running org.apache.hadoop.mapred.TestKillSubProcesses
    [junit] Running org.apache.hadoop.mapred.TestNodeRefresh
    [junit] Running org.apache.hadoop.mapred.TestSetupAndCleanupFailure
    [junit] Running org.apache.hadoop.mapred.TestTaskFail
    [junit] Running org.apache.hadoop.mapred.TestTaskOutputSize
    [junit] Running org.apache.hadoop.mapred.TestTaskTrackerSlotManagement
    [junit] Running org.apache.hadoop.mapreduce.TestMRJobClient
    [junit] Running org.apache.hadoop.mapreduce.lib.db.TestDBJob
    [junit] Running org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat
"
MAPREDUCE-3614, finalState UNDEFINED if AM is killed by hand,"Courtesy [~dcapwell]

{quote}
If the AM is running and you kill the process (sudo kill #pid), the State in Yarn would be FINISHED and FinalStatus is UNDEFINED.  The Tracking UI would say ""History"" and point to the proxy url (which will redirect to the history server).

The state should be more descriptive that the job failed and the tracker url shouldn't point to the history server.
{quote}"
MAPREDUCE-3613,web service calls header contains 2 content types,"when doing requesting info from the web services rest API, curl seems to return content-type of both text and json or xml:

> Accept: application/xml
>
< HTTP/1.1 200 OK
< Content-Type: text/plain; charset=utf-8
< Content-Type: application/xml"
MAPREDUCE-3611,trunk build failure,"https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/144/

{code}
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 6:47.415s
[INFO] Finished at: Thu Dec 29 23:37:00 UTC 2011
[INFO] Final Memory: 101M/760M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:testCompile (default-testCompile) on project hadoop-yarn-server-resourcemanager: Compilation failure: Compilation failure:
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[96,36] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[97,38] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[99,38] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[103,38] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[212,36] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
[ERROR] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-0.23-Build/trunk/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/test/java/org/apache/hadoop/yarn/server/resourcemanager/webapp/TestRMWebServicesCapacitySched.java:[256,34] cannot find symbol
[ERROR] symbol  : variable ROOT
[ERROR] location: class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
{code}"
MAPREDUCE-3610,Some parts in MR use old property dfs.block.size,"Some parts in MR use old property dfs.block.size.
dfs.blocksize should be used instead."
MAPREDUCE-3608,MAPREDUCE-3522 commit causes compilation to fail,There are compilation errors after MAPREDUCE-3522 was committed. Some more changes were need to webapps to fix the compilation issue.
MAPREDUCE-3607,Port missing new API mapreduce lib classes to 1.x,"There are a number of classes under mapreduce.lib that are not present in the 1.x series. Including these would help users and downstream projects using the new MapReduce API migrate to later versions of Hadoop in the future.

A few examples of where this would help:
* Sqoop uses mapreduce.lib.db.DBWritable and mapreduce.lib.input.CombineFileInputFormat (SQOOP-384).
* Mahout uses mapreduce.lib.output.MultipleOutputs (MAHOUT-822).
* HBase has a backport of mapreduce.lib.partition.InputSampler and TotalOrderPartitioner (in org.apache.hadoop.hbase.mapreduce.hadoopbackport) - it would be better if it used the ones in Hadoop.
"
MAPREDUCE-3605,Allow mr commands to be run via bin/hadoop,"MR command line options are not supported in bin/hadoop.
{noformat}
bin/hadoop job
Exception in thread ""main"" java.lang.NoClassDefFoundError: job
Caused by: java.lang.ClassNotFoundException: job
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: job.  Program will exit.
{noformat}

A deprecated message like ""DEPRECATED: Use of this script to execute mapred command is deprecated. Instead use the mapred command for it."" should be displayed along with the correct output."
MAPREDUCE-3604,Streaming's check for local mode is broken,Streaming isn't checking for mapreduce.framework.name as part of check for 'local' mode.
MAPREDUCE-3603,Add Web UI to MR2 Fair Scheduler,
MAPREDUCE-3602,Add Preemption to MR2 Fair Scheduler,
MAPREDUCE-3601,Add Delay Scheduling to MR2 Fair Scheduler,JIRA for delay scheduling component.
MAPREDUCE-3600,Add Minimal Fair Scheduler to MR2,"This covers the addition of the Fair Scheduler to the MR2 infrastructure. This patch will represent the minimum functional FairScheduler in MR2. It will be limited to a configuration file reader, functionality to calculate fair shares, and hooks into the actual MR2 scheduling code. 

It will not include delay scheduling, preemption, or a web UI, which will be handled in separate JIRA's. "
MAPREDUCE-3598,"Old combiner doesn't support counter, progress","After HADOOP-5382, old combiner's reduce is invoked with Reporter.NULL. So all the features in Reporter, e.g. counter, progress are not supported any more. The related code is as follows:
{code:}
        while (values.more()) {
          combiner.reduce(values.getKey(), values, combineCollector,
              Reporter.NULL);
          values.nextKey();
        }
{code}"
MAPREDUCE-3597,Provide a way to access other info of history file from Rumentool,"As the trace file generated by Rumen TraceBuilder is skipping some of the info like job counters, task counters, etc. we need a way to access ""other info available in history file which is not dumped to trace file"". This is useful for components which want to parse history files and get info. These components can directly use/leverage ""Rumen's parsing of history files across hadoop releases"" and get history info in a consistent way for further analysis/processing."
MAPREDUCE-3596,Sort benchmark got hang after completion of 99% map phase,"Courtesy [~vinaythota]
{quote}
Ran sort benchmark couple of times and every time the job got hang after completion 99% map phase. There are some map tasks failed. Also it's not scheduled some of the pending map tasks.
Cluster size is 350 nodes.

Build Details:
==============

Compiled:       Fri Dec 9 16:25:27 PST 2011 by someone from branches/branch-0.23/hadoop-common-project/hadoop-common 
ResourceManager version:        revision 1212681 by someone source checksum on Fri Dec 9 16:52:07 PST 2011
Hadoop version:         revision 1212592 by someone Fri Dec 9 16:25:27 PST 2011
{quote}


"
MAPREDUCE-3595,Add missing TestCounters#testCounterValue test from branch 1 to 0.23,
MAPREDUCE-3593,MAPREDUCE Impersonation is not working in 22,
MAPREDUCE-3588,bin/yarn broken after MAPREDUCE-3366,"bin/yarn broken after MAPREDUCE-3366, doesn't add yarn jars to classpath. As a result no servers can be started."
MAPREDUCE-3587,The deployment tarball should have different directories for yarn jars and mapreduce jars.,Currently all the jars in the mr tarball go to share/hadoop/mapreduce. The jars should be split into: share/hadoop/yarn and share/hadoop/mapreduce for clear seperation between yarn framework and mr.
MAPREDUCE-3586,Lots of AMs hanging around in PIG testing,"[~daijy] found this. Here's what he says:
bq. I see hundreds of MRAppMaster process on my machine, and lots of tests fail for ""Too many open files""."
MAPREDUCE-3585,RM unable to detect NMs restart,"Suppose say in a single host, there have been multiple NMs configured. In this case, there should be mechanism to detect the NMs comeback."
MAPREDUCE-3583,ProcfsBasedProcessTree#constructProcessInfo() may throw NumberFormatException,"HBase PreCommit builds frequently gave us NumberFormatException.

From https://builds.apache.org/job/PreCommit-HBASE-Build/553//testReport/org.apache.hadoop.hbase.mapreduce/TestHFileOutputFormat/testMRIncrementalLoad/:
{code}
2011-12-20 01:44:01,180 WARN  [main] mapred.JobClient(784): No job jar file set.  User classes may not be found. See JobConf(Class) or JobConf#setJar(String).
java.lang.NumberFormatException: For input string: ""18446743988060683582""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Long.parseLong(Long.java:422)
	at java.lang.Long.parseLong(Long.java:468)
	at org.apache.hadoop.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree.java:413)
	at org.apache.hadoop.util.ProcfsBasedProcessTree.getProcessTree(ProcfsBasedProcessTree.java:148)
	at org.apache.hadoop.util.LinuxResourceCalculatorPlugin.getProcResourceValues(LinuxResourceCalculatorPlugin.java:401)
	at org.apache.hadoop.mapred.Task.initialize(Task.java:536)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:353)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1083)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
{code}
From hadoop 0.20.205 source code, looks like ppid was 18446743988060683582, causing NFE:
{code}
        // Set (name) (ppid) (pgrpId) (session) (utime) (stime) (vsize) (rss)
         pinfo.updateProcessInfo(m.group(2), Integer.parseInt(m.group(3)),
{code}
You can find information on the OS at the beginning of https://builds.apache.org/job/PreCommit-HBASE-Build/553/console:
{code}
asf011.sp2.ygridcore.net
Linux asf011.sp2.ygridcore.net 2.6.32-33-server #71-Ubuntu SMP Wed Jul 20 17:42:25 UTC 2011 x86_64 GNU/Linux
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 20
file size               (blocks, -f) unlimited
pending signals                 (-i) 16382
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 60000
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 2048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
60000
Running in Jenkins mode
{code}

From Nicolas Sze:
{noformat}
It looks like that the ppid is a 64-bit positive integer but Java long is signed and so only works with 63-bit positive integers.  In your case,

  2^64 > 18446743988060683582 > 2^63.

Therefore, there is a NFE. 
{noformat}

I propose changing allProcessInfo to Map<String, ProcessInfo> so that we don't encounter this problem by avoiding parsing large integer."
MAPREDUCE-3582,Move successfully passing MR1 tests to MR2 maven tree.,This ticket will track moving mr1 tests that are passing successfully to mr2 maven tree.
MAPREDUCE-3579,ConverterUtils should not include a port in a path for a URL with no port,"In {{ConverterUtils#getPathFromYarnURL}}, it's incorrectly assumed that if a URL includes a valid host it must also include a valid port."
MAPREDUCE-3578,"starting nodemanager as 'root' gives ""Unknown -jvm option""","
running ""sudo HADOOP_ROOT/bin/yarn-daemon.sh start nodemanager"" I get ""unknown -jvm option"" (jdk version 1.6.0.26). The problem seems to be with line 204 in yarn:

elif [ ""$COMMAND"" = ""nodemanager"" ] ; then
CLASSPATH=${CLASSPATH}:$YARN_CONF_DIR/nm-config/log4j.properties
CLASS='org.apache.hadoop.yarn.server.nodemanager.NodeManager'
if [[ $EUID -eq 0 ]]; then
YARN_OPTS=""$YARN_OPTS -jvm server $YARN_NODEMANAGER_OPTS""
else
YARN_OPTS=""$YARN_OPTS -server $YARN_NODEMANAGER_OPTS""
fi

using -server seems to solve the problem for me.

I tested using build 929 from https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk/.

"
MAPREDUCE-3575,Streaming/tools Jar does not get included in the tarball.,The streaming jar used to be available in the mapreduce tarballs before we created the hadoop-tools package. The streaming and tools jars are not being shipped with any tars. Our mapreduce tarballs should include the streaming and tools jar.
MAPREDUCE-3574,Streaming/tools Jar does not get includes in the tarball.,The streaming jar used to be available in the mapreduce tarballs before we created the hadoop-tools package. The streaming and tools jars are not being shipped with any tars. Our mapreduce tarballs should include the streaming and tools jar.
MAPREDUCE-3572,MR AM's dispatcher is blocked by heartbeats to ResourceManager,"All the heartbeat processing is done in {{RMContainerAllocator}} locking the object. The event processing is also locked on this, causing the dispatcher to be blocked and the rest of the AM getting stalled.

The event processing should be in a separate thread."
MAPREDUCE-3571,SleepJob is missing from hadoop 0.23 examples,I have noticed that Sleepjob is missing from the examples in 0.23
MAPREDUCE-3569,TaskAttemptListener holds a global lock for all task-updates,"This got added via MAPREDUCE-3274. We really don't need the lock if we just implement what I mentioned on that ticket [here|https://issues.apache.org/jira/browse/MAPREDUCE-3274?focusedCommentId=13137214&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13137214].

This has performance implications on MR AM with lots of tasks."
MAPREDUCE-3568,Optimize Job's progress calculations in MR AM,"Besides catering to client requests, Job progress is calculated in every heartbeat to the RM so as to print the MR AM's progress. Today the map and reduce progresses are calculated by looking up of each task in a big map while we can simply make do with a scan and aggregate. With large number of tasks, this can make a difference."
MAPREDUCE-3567,Extraneous JobConf objects in AM heap,"MR AM creates new JobConf objects unnecessarily in a couple of places in JobImpl and TaskImpl which occupy non-trivial amount of heap.

While working with a 64 bit JVM on 100K maps jobs, with uncompressed pointers, removing those extraneous objects helped in addressing OOM with 2GB AM heap size."
MAPREDUCE-3566,MR AM slows down due to repeatedly constructing ContainerLaunchContext,"The construction of the context is expensive, includes per-task trips to NameNode for obtaining the information about job.jar, job splits etc which is redundant across all tasks.

We should have a common job-level context and a task-specific context inheriting from the common job-level context."
MAPREDUCE-3564,TestStagingCleanup and TestJobEndNotifier are failing on trunk.,"From recent jenkins test runs:


-1 core tests. The patch failed these unit tests:
org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup
org.apache.hadoop.mapreduce.v2.app.TestJobEndNotifier

https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1457//testReport/
"
MAPREDUCE-3563,LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter,"LocalJobRunner doesn't handle Jobs using o.a.h.mapreduce.OutputCommitter, ran into this debugging PIG-2347."
MAPREDUCE-3561,[Umbrella ticket] Performance issues in YARN+MR,"Been working on measuring performance of YARN+MR relative to the 0.20.xx release line together with [~karams].

This is an umbrella ticket to track all the issues related to performance."
MAPREDUCE-3560,TestRMNodeTransitions is failing on trunk,"Apparently Jenkins is screwed up. It is happily blessing patches, even though tests are failing.

Link to logs: https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1454//testReport/org.apache.hadoop.yarn.server.resourcemanager/TestRMNodeTransitions/testExpiredContainer/"
MAPREDUCE-3557,MR1 test fail to compile because of missing hadoop-archives dependency,"MAPREDUCE-3544 added hadoop-archives as dependency to gridmix and raid, but missed to add it to the main ivy.xml for the MR1 testcases thus the ant target 'compile-mapred-test' fails.

I was under the impression that this stuff was not used anymore but trunk is failing on that target."
MAPREDUCE-3556,Resource Leaks in key flows,"{code:title=MapTask.java|borderStyle=solid}

{code} 

{code:xml} 
 if (combinerRunner == null || numSpills < minSpillsForCombine) {
            Merger.writeFile(kvIter, writer, reporter, job);
          } else {
            combineCollector.setWriter(writer);
            combinerRunner.combine(kvIter, combineCollector);
          }

          //close
          writer.close();
{code} 



{code:title=InputSampler.java|borderStyle=solid}

{code} 

{code:xml} 
 for(int i = 1; i < numPartitions; ++i) {
      int k = Math.round(stepSize * i);
      while (last >= k && comparator.compare(samples[last], samples[k]) == 0) {
        ++k;
      }
      writer.append(samples[k], nullValue);
      last = k;
    }
    writer.close();{code} 


The key flows have potential resource leaks. 

{code:title=JobSplitWriter.java|borderStyle=solid}

{code} 

{code:xml} 

    SplitMetaInfo[] info = writeNewSplits(conf, splits, out);
    out.close();

    SplitMetaInfo[] info = writeOldSplits(splits, out);
    out.close();
{code} "
MAPREDUCE-3553,Add support for data returned when exceptions thrown from web service apis to be in either xml or in JSON,"When the web services apis for rm, nm, app master, and job history server throw an exception - like bad request, not found, they always return the data in JSON format.  It would be nice to return based on what they requested - xml or JSON."
MAPREDUCE-3551,web proxy returns internal server error when application invalid,"querying for an absent app i.e. say http://RM:8088/proxy/application_1323054018624_0004/ws/v1/mapreduce/info - returns a 500 with a stack trace instead of a 404. From an api spec point of view, this is not really an error but just a not found.  This occurs with web services as well as any web ui page."
MAPREDUCE-3549,"write api documentation for web service apis for RM, NM, mapreduce app master, and job history server","write api documentation for web service apis for RM, NM, mapreduce app master, and job history server. web services were added in MAPREDUCE-2863"
MAPREDUCE-3548,write unit tests for web services for mapreduce app master and job history server,write more unit tests for mapreduce application master and job history server web services added in MAPREDUCE-2863
MAPREDUCE-3547,finish unit tests for web services for RM and NM,Write more unit tests for the web services added for rm and nm.
MAPREDUCE-3546,slf4j versions mismatched between yarn and hdfs,"Running a cluster on trunk, I ran into an issue caused by the differing slf4j versions between YARN and HDFS. YARN is currently using 1.6.1 whereas HDFS is using 1.5.11. Unclear whether we should upgrade HDFS or downgrade YARN."
MAPREDUCE-3545,Remove Avro RPC,"Please see the discussion in HDFS-2660 for more details. I have created a branch HADOOP-6659 to save the Avro work, if in the future some one wants to use the work that existed to add support for Avro RPC."
MAPREDUCE-3544,"gridmix build is broken, requires hadoop-archives to be added as ivy dependency","Having moved HAR/HadoopArchives to common/tools makes gridmix to fail as HadoopArchives is not in the mr1 classpath anymore.

hadoop-archives artifact should be added to gridmix dependencies
"
MAPREDUCE-3543,Mavenize Gridmix.,Gridmix codebase still resides in src/contrib and needs to be compiled via ant. We should move it to maven.
MAPREDUCE-3542,"Support ""FileSystemCounter"" legacy counter group name for compatibility","The group name changed from ""FileSystemCounter"" to ""org.apache.hadoop.mapreduce.FileSystemCounter"", but we should support the old one for compatibility's sake. This came up in PIG-2347. "
MAPREDUCE-3541,Fix broken TestJobQueueClient test,"Ant build complains 
    [javac] /hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestJobQueueClient.java>:80: printJobQueueInfo(org.apache.hadoop.mapred.JobQueueInfo,java.io.Writer,java.lang.String) in org.apache.hadoop.mapred.JobQueueClient cannot be applied to (org.apache.hadoop.mapred.JobQueueInfo,java.io.StringWriter)
    [javac]     client.printJobQueueInfo(root, writer);
"
MAPREDUCE-3540,saveVersion.sh script fails in windows/cygwin (hadoop-yarn-common),"{code}
[ERROR] Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.2:exec (generate-version) on project hadoop-yarn-common: Comman
d execution failed. Cannot run program ""scripts\saveVersion.sh"" (in directory ""C:\cygwin\home\tucu\src\hadoop\hadoop-mapreduce-proje
ct\hadoop-yarn\hadoop-yarn-common""): CreateProcess error=2, The system cannot find the file specified -> [Help 1]
[ERROR]
{code}"
MAPREDUCE-3539,possible Cases for NullPointerException,"in DistCh.java

{noformat}
in setup method
opWriter.close();
if opWriter is null then if we will try to close will throw NPE.
{noformat}

{noformat}
in checkDuplication method
in.close();
if in is null then if we will try to close will throw NPE.
{noformat}"
MAPREDUCE-3537,DefaultContainerExecutor has a race condn. with multiple concurrent containers,"DCE relies cwd before calling ContainerLocalizer.runLocalization. However, with multiple containers setting cwd on same localFS reference leads to race. "
MAPREDUCE-3536,consider whether the same instance of a ServiceStateChangeListener should be allowed to listen to events,"Currently there is no limit on the number of times a listener can register for events; it's a simple list. A service must unregister the same number of times that it registers.

Is this the desired behaviour? If so it should be documented in the {{Service}} interface rather than just implicitly in the {{AbstractService}} implementation. "
MAPREDUCE-3534,Compression benchmark run-time increased by 13% in 0.23,"Compression runtime is increased by 13% as well as throughput is decreased by 24% in 0.23 when compared to 0.20.204 on
a 350 node size cluster."
MAPREDUCE-3533,have the service interface extend Closeable and use close() as its shutdown operation,"This is probably going be marked down as a wontfix on the basis that it is (almost) encoded in the interfaces, but it may not be too late.

If the service interface interface extended Closeable and used close() instead of stop(), it would work automatically in the java7 automatic resource management blocks..."
MAPREDUCE-3532,"When 0 is provided as port number in yarn.nodemanager.webapp.address, NMs webserver component picks up random port, NM keeps on Reporting 0 port to RM","I tried following -:
yarn.nodemanager.address=0.0.0.0:0
yarn.nodemanager.webapp.address=0.0.0.0:0
yarn.nodemanager.localizer.address=0.0.0.0:0
mapreduce.shuffle.port=0

When 0 is provided as number in yarn.nodemanager.webapp.address. 
NM instantiate WebServer as 0 piort e.g.
{code}
2011-12-08 11:33:02,467 INFO org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer: Instantiating NMWebApp at 0.0.0.0:0
{code}

After that WebServer pick up some random port e.g.
{code}
2011-12-08 11:33:02,562 INFO org.apache.hadoop.http.HttpServer: Jetty bound to port 36272
2011-12-08 11:33:02,562 INFO org.mortbay.log: jetty-6.1.26
2011-12-08 11:33:02,831 INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:36272
2011-12-08 11:33:02,831 INFO org.apache.hadoop.yarn.webapp.WebApps: Web app /node started at 36272
{code}

And NM WebServer responds correctly but
 RM's cluster/Nodes page shows the following -:
{code}
/Rack RUNNING NM:57963 NM:0 Healthy 8-Dec-2011 11:33:01 Healthy 8 12 GB 0 KB
{code}
Whereas NM:0 is not clickable.
Seems even NM's webserver pick random port but it never gets updated and so NM report 0 as HTTP port to RM causing NM Hyperlinks un-clickable
But verified that MR job runs successfully with random.
"
MAPREDUCE-3531,Sometimes java.lang.IllegalArgumentException: Invalid key to HMAC computation in NODE_UPDATE also causing RM to stop scheduling ,"Filling this Jira a bit late
Started 350 cluster
sbummited large sleep job.
Foud that job was not running as RM has not allocated resouces to it.
{code}
2011-12-01 11:56:25,200 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: nodeUpdate: <NMHost>:48490 clusterResources: memory: 3225600
2011-12-01 11:56:25,202 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event
type NODE_UPDATE to the scheduler
java.lang.IllegalArgumentException: Invalid key to HMAC computation
        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:141)
        at org.apache.hadoop.yarn.server.security.ContainerTokenSecretManager.createPassword(ContainerTokenSecretManager.java:61)
        atorg.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.createContainer(LeafQueue.java:1108)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getContainer(LeafQueue.java:1091)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1137)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:1001)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:973)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:760)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:583)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:513)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:569)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:611)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:77)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:294)
        at java.lang.Thread.run(Thread.java:619)
Caused by: java.security.InvalidKeyException: Secret key expected
        at com.sun.crypto.provider.HmacCore.a(DashoA13*..)
        at com.sun.crypto.provider.HmacSHA1.engineInit(DashoA13*..)
        at javax.crypto.Mac.init(DashoA13*..)
        at org.apache.hadoop.security.token.SecretManager.createPassword(SecretManager.java:139)
        ... 14 more
{code}
As this stack is from 30 Nov checkou line number may be different"
MAPREDUCE-3530,Sometimes NODE_UPDATE to the scheduler throws an NPE causing the scheduling to stop,"Sometimes NODE_UPDATE to the scheduler throws NPE causes scheduling to stop but ResourceManager keeps on running.
I have been observing intermitently for last 3 weeks.
But with latest svn code. I tried to run sort twice and both times Job got stuck due to NPE.
{code}
java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.containerLaunchedOnNode(SchedulerApp.java:181)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.containerLaunchedOnNode(CapacityScheduler.java:596)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:539)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:617)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:77)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:294)
        at java.lang.Thread.run(Thread.java:619)
{code}"
MAPREDUCE-3529,TokenCache does not cache viewfs credentials correctly,"viewfs returns a list of delegation tokens for the actual namenodes. TokenCache caches these based on the actual service name - subsequent calls to TokenCache end up trying to get a new set of tokens.

Tasks which happen to access TokenCache fail when using viewfs - since they end up trying to get a new set of tokens even though the tokens are already available.

{noformat}
Error: java.io.IOException: Delegation Token can be issued only with kerberos or web authentication
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getDelegationToken(FSNamesystem.java:4027)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getDelegationToken(NameNodeRpcServer.java:281)
        at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:365)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1490)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1486)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1484)

        at org.apache.hadoop.ipc.Client.call(Client.java:1085)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:193)
        at $Proxy8.getDelegationToken(Unknown Source)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:100)
        at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:65)
        at $Proxy8.getDelegationToken(Unknown Source)
        at org.apache.hadoop.hdfs.DFSClient.getDelegationToken(DFSClient.java:456)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationToken(DistributedFileSystem.java:812)
        at org.apache.hadoop.hdfs.DistributedFileSystem.getDelegationTokens(DistributedFileSystem.java:839)
        at org.apache.hadoop.fs.viewfs.ChRootedFileSystem.getDelegationTokens(ChRootedFileSystem.java:311)
        at org.apache.hadoop.fs.viewfs.ViewFileSystem.getDelegationTokens(ViewFileSystem.java:490)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:144)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:91)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:84)
{noformat}


This will likely require some changes in viewfs/hdfs - will open a Jira with details."
MAPREDUCE-3528,The task timeout check interval should be configurable independent of mapreduce.task.timeout,TaskHeartbeatHandler sleeps for 'mapreduce.task.timeout' - between each check. If a task/NM goes bad immediately after starting a task - the timeout is detected in ~2x the configured timeout interval.
MAPREDUCE-3527,Fix minor API incompatibilities between 1.0 and 0.23,There are a few minor incompatibilities that were found in HADOOP-7738 and are straightforward to fix.
MAPREDUCE-3525,Shuffle benchmark is nearly 1.5x slower in 0.23,Shuffle benchmark is nearly 1.5X slower(almost 55% increased) in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.
MAPREDUCE-3524,Scan benchmark is more than 1.5x slower in 0.23,"Scan benchmark is more than 1.5X slower(almost 92% increased) in 0.23 than Hadoop-0.20.204 on 350 nodes size cluster.

"
MAPREDUCE-3522,Capacity Scheduler ACLs not inherited by default,"Hierarchical Queues do not inherit parent ACLs correctly by default. Instead, if no value is specified for submit or administer acls, then all access is granted."
MAPREDUCE-3521,Hadoop Streaming ignores unknown parameters,"The hadoop streaming command will ignore any command line arguments to it.

{code}
hadoop jar streaming.jar -input input -output output -mapper cat -reducer cat ThisIsABadArgument
{code}

Works just fine.  This can mask issues where quotes were mistakenly missed like

{code}
hadoop jar streaming.jar -input input -output output -mapper xargs cat -reducer cat -archive someArchive.tgz
{code}

Streaming should fail if it encounters an unexpected command line parameter"
MAPREDUCE-3519,Deadlock in LocalDirsHandlerService and ShuffleHandler,"MAPREDUCE-3121 cloned Configuration object in LocalDirsHandlerService.init() to avoid others to access that configuration object. But since it is used in local FileSystem object creation in LocalDirAllocator.AllocatorPerContext and the same FileSystem object is used in ShuffleHandler.Shuffle.localDirAllocator, this is causing a deadlock when accessing this configuration object from LocalDirsHandlerService and ShuffleHandler along with AllocatorPerContext object."
MAPREDUCE-3518,mapred queue -info <queue> -showJobs throws NPE,"mapred queue -info default -showJobs

Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.tools.CLI.displayJobList(CLI.java:572)
        at org.apache.hadoop.mapred.JobQueueClient.displayQueueInfo(JobQueueClient.java:190)
        at org.apache.hadoop.mapred.JobQueueClient.run(JobQueueClient.java:103)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobQueueClient.main(JobQueueClient.java:234)
"
MAPREDUCE-3515,hadoop 0.23: native compression libraries not being loaded,"I installed the hadoop package from the Bigtop hadoop 0.23 branch. Among other files, the package installs

/usr/lib/hadoop/lib/native
/usr/lib/hadoop/lib/native/libhadoop.a
/usr/lib/hadoop/lib/native/libhadoop.so.1
/usr/lib/hadoop/lib/native/libhadoop.so.1.0.0
/usr/lib/hadoop/lib/native/libhdfs.a

I ran a simple job using compression:

hadoop jar /usr/lib/hadoop/hadoop-mapreduce-examples.jar wordcount -D mapreduce.output.fileoutputformat.compress=true -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec examples/text wordcount-gz

I see

11/12/06 13:42:06 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
11/12/06 13:42:06 WARN snappy.LoadSnappy: Snappy native library not loaded

and at the end, I see

-rw-r--r--   1 root supergroup          0 2011-12-06 13:42 wordcount-gz/_SUCCESS
-rw-r--r--   1 root supergroup      46228 2011-12-06 13:42 wordcount-gz/part-r-00000.gz

so the output is compressed, but from the log message, I assume that the native library is not being loaded and that the java gzip is being used.
"
MAPREDUCE-3513,Capacity Scheduler web UI has a spelling mistake for Memory.,"The web page for capacity scheduler has a column named ""Memopry Total"", a spelling mistake which needs to be fixed."
MAPREDUCE-3512,Batch jobHistory disk flushes,"The mr-am flushes each individual job history event to disk for AM recovery. The history even handler ends up with a significant backlog for tests like MAPREDUCE-3402. 
History events could be batched up based on num records / time / TaskFinishedEvents to reduce the number of DFS writes - with the potential drawback of having to rerun some tasks during AM recovery."
MAPREDUCE-3511,Counters occupy a good part of AM heap,"Per task counters seem to be occupying a good part of an AMs heap. Looks like more than 50% of what's used by a TaskAttemptImpl object.
This could be optimized by interning strings or possibly using mrv1 counters which are optimized. Currently counters are converted from mrv1 to mrv2 format for in memory storage. The conversion could be delayed till it's actually required for RPC transfers."
MAPREDUCE-3510,Capacity Scheduler inherited ACLs not displayed by mapred queue -showacls,mapred queue -showacls does not show inherited acls
MAPREDUCE-3506,Calling getPriority on JobInfo after parsing a history log with JobHistoryParser throws a NullPointerException,Somehow the priority field under JobHistoryParser.JobInfo is not set. Calling getPriority on Jobinfo after parsing a Job hisotry log throws NPE
MAPREDUCE-3505,yarn APPLICATION_CLASSPATH needs to be overridable,"Right now MRApps sets the classpath to just being mrapp-generated-classpath, its content and a hardcoded list of directories.
If I understand correctly mrapp-generated-classpath is only there for testing and may change or disappear at any time

The list of hardcoded directories is defined in hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/api/ApplicationConstants.java at line 92.
For convenience, here is its current content:
{noformat}
  /**
   * Classpath for typical applications.
   */
  public static final String[] APPLICATION_CLASSPATH =
      new String[] {
        ""$HADOOP_CONF_DIR"",
        ""$HADOOP_COMMON_HOME/share/hadoop/common/*"",
        ""$HADOOP_COMMON_HOME/share/hadoop/common/lib/*"",
        ""$HADOOP_HDFS_HOME/share/hadoop/hdfs/*"",
        ""$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*"",
        ""$YARN_HOME/modules/*"",
        ""$YARN_HOME/lib/*""
      };
{noformat}

Not all deployment scenarii fit in this layout and therefore we need a standardized way to customize this class path.
"
MAPREDUCE-3504,capacity scheduler allow capacity greater then 100% as long as its less then 101%,"When sum of all capacities >=101 or <100, we got the following error when starting jobtracker. However, when the 100 <= sum < 101, jobtracker does not report exception and started with all queues initialized.
for instance (capacity sum = 29.5+60+11.4 = 100.9) does not cause exception.

"
MAPREDUCE-3503,capacity scheduler allow capacity greater then 100% as long as its less then 101%,"When sum of all capacities >=101 or <100, we got the following error when starting jobtracker. However, when the 100 <= sum < 101, jobtracker does not report exception and started with all queues initialized.
for instance (capacity sum = 29.5+60+11.4 = 100.9) does not cause exception.

"
MAPREDUCE-3502,Review all Service.stop() operations and make sure that they work before a service is started,"MAPREDUCE-3431 has shown that some of the key services's shutdown operations are not robust against being invoked before the service is started. They need to be by

# not calling other things if the other things are null
# not being re-entrant (i.e. make synchronized if possible), 

Maybe 
# have a StopService operation that only stops a service if it is live
# factor out the is-running test from the base service class and make it a pre-check for all the child services, so they bail out sooner rather than later. This would be the best as it would be the one guaranteed to work consistently across all instances, so only one or two would need testing

my first iteration will skip the sync though it's something to consider. 

Testing: try to create each instance; call stop() straight after construction. "
MAPREDUCE-3500,MRJobConfig creates an LD_LIBRARY_PATH using the platform ARCH,"With HADOOP-7874 we are removing the arch from the java.library.path.

The LD_LIBRARY_PATH being set should not include the ARCH.

{code}
  public static final String DEFAULT_MAPRED_ADMIN_USER_ENV =
      ""LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native/"" + PlatformName.getPlatformName();
{code}

"
MAPREDUCE-3499,"New MiniMR does not setup proxyuser configuration correctly, thus tests using doAs do not work","The new MiniMR implementation is not taking proxyuser settings.

Because of this, testcases using/testing doAs functionality fail.

This affects all Oozie testcases that use MiniMR."
MAPREDUCE-3497,missing documentation for yarn cli and subcommands - similar to commands_manual.html,the yarn cli and sub-commands aren't documented anywhere.  Should have documentation similar to the commands_manual.html
MAPREDUCE-3496,Yarn initializes ACL operations from capacity scheduler config in a non-deterministic order,'mapred queue -showacls' does not output put acls in a predictable manner. This is a regression from previous versions.
MAPREDUCE-3495,Remove my personal email address from the pipes build file.,"When I first wrote the pipes autoconf/automake stuff, I incorrectly put my email address in the AC_INIT line, which means if something goes wrong, you get:

{quote}
> configure: WARNING:     ## Report this to <my-email> ##
{quote}"
MAPREDUCE-3493,Add the default mapreduce.shuffle.port property to mapred-default.xml,"I faced this issue when trying to run multiple Hadoop MR2 instances on the same node. The default value for this property is hardcoded in the ShuffleHandler.java class so it results in port conflicts. The issue is resolved if you set the property value in your conf files. But the absence of this property from *-default.xml files is confusing. So It'll be cleaner to move this property to mapred-default.xml, so its default value can be easily identified and changed if needed. "
MAPREDUCE-3491,TestContainerManagerWithLCE is failing,"$ mvn test -Dtest=TestContainerManagerWithLCE -Dapplication.submitter=nobody -Dyarn.nodemanager.linux-container-executor.path=<path of container-executor binary>


TestContainerManagerWithLCE is failing with the error:

Test set: org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE
-------------------------------------------------------------------------------
Tests run: 6, Failures: 5, Errors: 0, Skipped: 0, Time elapsed: 26.219 sec <<< FAILURE!
testContainerSetup(org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE)  Time elapsed: 2.476 sec  <<< FAILURE!
junit.framework.AssertionFailedError: workspace/gitTrunk/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE-localDir/usercache/nobody/appcache/application_0_0000 doesn't exist!!
  at junit.framework.Assert.fail(Assert.java:47)
  at junit.framework.Assert.assertTrue(Assert.java:20)
  at org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup(TestContainerManager.java:179)
  at org.apache.hadoop.yarn.server.nodemanager.TestContainerManagerWithLCE.testContainerSetup(TestContainerManagerWithLCE.java:83)"
MAPREDUCE-3490,RMContainerAllocator counts failed maps towards Reduce ramp up,"The RMContainerAllocator does not differentiate between failed and successful maps while calculating whether reduce tasks are ready to launch. Failed tasks are also counted towards total completed tasks. 
Example. 4 failed maps, 10 total maps. Map%complete = 4/14 * 100 instead of being 0."
MAPREDUCE-3488,Streaming jobs are failing because the main class isnt set in the pom files.,Streaming jobs are failing since the main MANIFEST file isnt being set in the pom files.
MAPREDUCE-3487,jobhistory web ui task counters no longer links to singletakecounter page,"The task counters on the job history task counter web ui page ( ie host:19888/jobhistory/taskcounters/task_1322451030861_9_9_m_0) are no longer links. They are supposed to be links that take you to the singletaskcounter page and show you the task attempts that affected the counter.

Looks like MAPREDUCE-3258  changed CounterBlock.java so it doesn't show the link on the counter:
 if (mg == null && rg == null) {
           groupRow.td().$title(counter.getName())._(counter.getDisplayName()).
            _();
          } else {


"
MAPREDUCE-3485,DISKS_FAILED -101 error code should be defined in same location as ABORTED_CONTAINER_EXIT_STATUS,"With MAPREDUCE-3121, it is defined in ContainerExecutor as part of yarn-nodemanager which would be a problem for client-side code if it needs to understand the exit code. 

A short term fix would be to move it into YarnConfiguration where ABORTED_CONTAINER_EXIT_STATUS is defined. A longer term fix would be to find a more formal and extensible approach for new yarn framework error codes to be added and be easily accessible to client-side code or other AMs. "
MAPREDUCE-3484,JobEndNotifier is getting interrupted before completing all its retries.,"We noticed JobEndNotifier was getting an InterruptedException before completing all its retries.

To fix this, Job end notification method should be called before stop() in handle(JobFinishEvent)."
MAPREDUCE-3482,Enable HTTP proxy to be specified for job end notification,"Courtesy Ratandeep Singh Ratti
{quote}
The AM should be able to notify the job.end.notification.url. Hence this request has to go through HTTP proxy, since ACLs won't be open from the AM to external machines. 
{quote}
"
MAPREDUCE-3481,[Gridmix] Improve STRESS mode locking,Gridmix STREES mode code doesnt sufficiently load the cluster due to improper locking.
MAPREDUCE-3480,TestJvmReuse fails in 1.0,"TestJvmReuse is failing in apache builds, although it passes in my local machine."
MAPREDUCE-3479,JobClient#getJob cannot find local jobs,"The problem is that JobClient#submitJob doesn't pass the Cluster object to Job for the submission process, which means that two Cluster objects and two LocalJobRunner objects are created. LocalJobRunner keeps an instance map of job IDs to Jobs, and when JobClient#getJob is called the LocalJobRunner with the unpopulated map is used which results in the job not being found."
MAPREDUCE-3478,Cannot build against ZooKeeper 3.4.0,"I tried to see if one could build Hadoop 0.23.0 against ZooKeeper 3.4.0, rather than 3.3.1 (3.3.3 does work, fwiw) and hit compilation errors:

{quote}
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:2.3.2:testCompile (default-testCompile) on project hadoop-yarn-server-common: Compilation failure: Compilation failure:
[ERROR] /Volumes/EssEssDee/abayer/src/asf-git/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/test/java/org/apache/hadoop/yarn/lib/TestZKClient.java:[48,25] cannot find symbol
[ERROR] symbol  : class Factory
[ERROR] location: class org.apache.zookeeper.server.NIOServerCnxn
[ERROR] /Volumes/EssEssDee/abayer/src/asf-git/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/src/test/java/org/apache/hadoop/yarn/lib/TestZKClient.java:[150,33] cannot find symbol
[ERROR] symbol  : class Factory
[ERROR] location: class org.apache.zookeeper.server.NIOServerCnxn
[ERROR] -> [Help 1]
{quote}

Presumably, Yarn needs to build against newer ZK releases eventually, hence this bug. =)"
MAPREDUCE-3477,Hadoop site documentation cannot be built anymore on trunk and branch-0.23,"Maven fails and here is the issue I get:

[ERROR] Failed to execute goal org.apache.maven.plugins:maven-site-plugin:3.0:site (default-site) on project hadoop-yarn-site: Error during page generation: Error parsing '/home/bruno/freesoftware/bigtop/build/hadoop/rpm/BUILD/apache-hadoop-common-e127450/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/SingleCluster.apt.vm': line [23] Unable to execute macro in the APT document: ParseException: expected SECTION2, found SECTION3 -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
[ERROR] 
[ERROR] After correcting the problems, you can resume the build with the command
[ERROR]   mvn <goals> -rf :hadoop-yarn-site
error: Bad exit status from /var/tmp/rpm-tmp.OFegWv (%build)

"
MAPREDUCE-3476,Optimize YARN API calls,Several YARN API calls are taking inordinately long. This might be a performance blocker.
MAPREDUCE-3475,JT can't renew its own tokens,"When external systems submit jobs whose tasks need to submit additional jobs (such as oozie/pig), they include their own MR token used to submit the job.  The token's renewer may not allow the JT to renew the token.  The JT log will include very long SASL/GSSAPI exceptions when the job is submitted.  It is also dubious for the JT to renew its token because it renders the expiry as meaningless since the JT will renew its own token until the max lifetime is exceeded.

After speaking with Owen & Jitendra, the immediate solution is for the JT to not attempt to renew its own tokens."
MAPREDUCE-3470,Jobtracker sets permissions on mapred.system.dir to 700 preventing non-superusers from submitting jobs to multi-user cluster,"(See thread discussing here - https://mail-archives.apache.org/mod_mbox/hadoop-common-user/201111.mbox/%3C4EBAC2B3.6090806@deri.org%3E)

I have installed a hadoop 0.20.205.0 cluster for use by multiple users, each of which will submit their jobs from remote client systems. I have disabled security

<property>
  <name>hadoop.security.authorization</name>
  <value>false</value>
</property>

<property>
  <name>hadoop.security.authentication</name>
  <value>simple</value>
</property> 

When a user other than super-user attempts to submit a job, they get the following error

11/11/09 16:32:53 INFO mapred.FileInputFormat: Total input paths to process : 2
11/11/09 16:32:53 INFO mapred.JobClient: Running job: job_201111091731_0003
11/11/09 16:32:54 INFO mapred.JobClient:  map 0% reduce 0%
11/11/09 16:32:54 INFO mapred.JobClient: Job complete: job_201111091731_0003
11/11/09 16:32:54 INFO mapred.JobClient: Counters: 0
11/11/09 16:32:54 INFO mapred.JobClient: Job Failed: Job initialization failed:
org.apache.hadoop.security.AccessControlException: org.apache.hadoop.security.AccessControlException: Permission denied: user=smulcahy, access=EXECUTE, inode=""system"":hadoop:supergroup:rwx------
..... 

which seems to be due to not being able to create a jobToken file in <mapred.system.dir>/<job id>/jobToken 

I can reset the permissions on mapred.system.dir to something like 777 but when I restart the jobtracker, it resets the permissions back to 700, requiring another permissions reset.

This gives rise to a few questions,

1. Should I be able to use a hadoop cluster in this fashion or is this not supported (if not, supported, I guess close this bug as invalid). If it is not supported, it reduces the usability of hadoop for a class of users like myself (but maybe thats a small class).
2. If I should be able to use the cluster like this, should <mapred.system.dir>/<job id>/jobToken need to be created if security is disabled? If no, then I guess is the bug that needs to be fixed. If yes, then the jobtracker needs to be modified to allow everyone to create dirs in mapred.system.dir (or the method of creation of the jobToken file needs to be changed).

Apologies if this was operator error but I didn't get much feedback on the mailing lists so not sure where/how else to raise this.


Changed introduced in MAPREDUCE-2219"
MAPREDUCE-3469,"Port to 0.22 - Implement limits on per-job JobConf, Counters, StatusReport, Split-Sizes","We have come across issues in production clusters wherein users abuse counters, statusreport messages and split sizes. One such case was when one of the users had 100 million counters. This leads to jobtracker going out of memory and being unresponsive. In this jira I am proposing to put sane limits on the status report length, the number of counters and the size of block locations returned by the input split. "
MAPREDUCE-3468,Change version to 0.23.1 for ant builds on the 23 branch,Maven version has been changed to 0.23.1-SNAPSHOT. The ant build files need to change as well.
MAPREDUCE-3467,Mavenizing har,"As part of mapreduce mavenization, har should also be mavenized and added to maven repo"
MAPREDUCE-3466,hadoop-mapreduce-tools*.jar does not seem to be updated on maven repo,I do not see any listing for hadoop-mapreduce-tools at https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/. There is one for hadoop-mapred-tools but that has not been updated in a long time.
MAPREDUCE-3465,org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin fails on 0.23 ,"Running org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.121 sec <<< FAILURE!
Tests in error: 
  testParsingProcStatAndCpuFile(org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin): /homes/hortonhi/dev/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/test-dir/CPUINFO_943711651 (No such file or directory)
  testParsingProcMemFile(org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin): /homes/hortonhi/dev/hadoop-common/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/test-dir/MEMINFO_943711651 (No such file or directory)
"
MAPREDUCE-3464,mapreduce jsp pages missing DOCTYPE [post-split branches],"Some jsp pages in the UI are missing a DOCTYPE declaration. This causes the pages to render incorrectly on some browsers, such as IE9. Please see parent bug HADOOP-7827 for details and patch."
MAPREDUCE-3463,Second AM fails to recover properly when first AM is killed with java.lang.IllegalArgumentException causing lost job,"Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn 4 Node cluster.
First Ran Randowriter/Sort/Sort-validate successfully
Then again sort, when job was 50% complete
Login node running AppMaster, and killed AppMaster with kill -9
On Client side failed with following:
{code}
11/11/23 10:57:27 INFO mapreduce.Job:  map 58% reduce 8%
11/11/23 10:57:27 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1322040898409_0005 retrying..
11/11/23 10:57:28 INFO mapreduce.Job:  map 0% reduce 0%
11/11/23 10:57:37 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=UNDEFINED. Redirecting to job history server
11/11/23 10:57:37 INFO client.ClientTokenSelector: Looking for a token with service <RM Host>:Port
11/11/23 10:57:37 INFO client.ClientTokenSelector: Token kind is YARN_CLIENT_TOKEN and the token's service name is <New AM Host>:Port
11/11/23 10:57:38 WARN mapred.ClientServiceDelegate: Error from remote end: Unknown job job_1322040898409_0005
RemoteTrace: 
 at Local Trace: 
	org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Unknown job job_1322040898409_0005
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151)
	at $Proxy10.getTaskAttemptCompletionEvents(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:172)
	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:273)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:320)
	at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:438)
	at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:621)
	at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1231)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1179)
	at org.apache.hadoop.examples.Sort.run(Sort.java:181)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.examples.Sort.main(Sort.java:192)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
{code}

On lookig RM logs found second AM was also lauched, it was saying -:
{code}
011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1322040898409_0005_000002 State change from RUNNING to FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: Processing event for application_1322040898409_0005 of type ATTEMPT_FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl: application_1322040898409_0005 State change from RUNNING to FINISHED
2011-11-23 10:57:37,737 INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler: Application appattempt_1322040898409_0005_000002 is done. finalState=FINISHED
{code}

Now looking at AM logs and found Second AM was shutdown gracefully due to :-
{code}
2011-11-23 10:57:37,640 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService: Sending assigned event to attempt_1322040898409_0005_m_000000_0
2011-11-23 10:57:37,641 FATAL [AsyncDispatcher event handler] org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..
java.lang.IllegalArgumentException: Invalid NodeId [<NMHostName>]. Expected host:port
        at org.apache.hadoop.yarn.util.ConverterUtils.toNodeId(ConverterUtils.java:144)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.sendAssignedEvent(RecoveryService.java:410)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$InterceptingEventHandler.handle(RecoveryService.java:314)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:1010)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl$RequestContainerTransition.transition(TaskAttemptImpl.java:985)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:851)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:128)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:853)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:845)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)
        at org.apache.hadoop.mapreduce.v2.app.recover.RecoveryService$RecoveryDispatcher.dispatch(RecoveryService.java:270)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
2011-11-23 10:57:37,642 INFO [CompositeServiceShutdownHook for org.apache.hadoop.mapreduce.v2.app.MRAppMaster] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler
{code}"
MAPREDUCE-3462,Job submission failing in JUnit tests,"When I run JUnit tests (e.g. TestDistCacheEmulation, TestSleepJob and TestCompressionEmulationUtils), I see job submission failing with the following error:
{noformat}
java.lang.IllegalStateException: Variable substitution depth too large: 20 ${fs.default.name}
        at org.apache.hadoop.conf.Configuration.substituteVars(Configuration.java:551)
        at org.apache.hadoop.conf.Configuration.get(Configuration.java:569)
        at org.apache.hadoop.conf.Configuration.getStrings(Configuration.java:1020)
        at org.apache.hadoop.mapreduce.JobSubmitter.populateTokenCache(JobSubmitter.java:564)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:353)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1159)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1156)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1156)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1176)
        at org.apache.hadoop.mapred.gridmix.Gridmix.launchGridmixJob(Gridmix.java:190)
        at org.apache.hadoop.mapred.gridmix.Gridmix.writeInputData(Gridmix.java:150)
        at org.apache.hadoop.mapred.gridmix.Gridmix.start(Gridmix.java:425)
        at org.apache.hadoop.mapred.gridmix.Gridmix.runJob(Gridmix.java:380)
        at org.apache.hadoop.mapred.gridmix.Gridmix.access$000(Gridmix.java:56)
        at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:313)
        at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:311)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.mapred.gridmix.Gridmix.run(Gridmix.java:311)
{noformat}"
MAPREDUCE-3460,MR AM can hang if containers are allocated on a node blacklisted by the AM,"When an AM is assigned a FAILED_MAP (priority = 5) container on a nodemanager which it has blacklisted - it tries to
find a corresponding container request.
This uses the hostname to find the matching container request - and can end up returning any of the ContainerRequests which may have requested a container on this node. This container request is cleaned to remove the bad node - and then added back to the RM 'ask' list.
The AM cleans the 'ask' list after each heartbeat - The RM Allocator is still aware of the priority=5 container (in 'remoteRequestsTable') - but this never gets added back to the 'ask' set - which is what is sent to the RM."
MAPREDUCE-3459,ant build is broken in branch-23,"ant build is broken in 0.23. A small snippet:

  [javac] Compiling 330 source files to /home/<>/hadoop/branch-0.23/hadoop-mapreduce-project/build/test/mapred/classes
    [javac] /home/<>/hadoop/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/NotificationTestCase.java:28: cannot find symbol
    [javac] symbol  : class MapReduceTestUtil
    [javac] location: package org.apache.hadoop.mapreduce
    [javac] import org.apache.hadoop.mapreduce.MapReduceTestUtil;
    [javac]                                   ^
    [javac] /home/<>/hadoop/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestBadRecords.java:43: cannot find symbol

    [javac] symbol: class ClusterMapReduceTestCase
    [javac] public class TestBadRecords extends ClusterMapReduceTestCase {
    [javac]                                     ^
"
MAPREDUCE-3458,Fix findbugs warnings in hadoop-examples,"I see 12 findbugs warnings in hadoop-examples: 
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1336//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-examples.html"
MAPREDUCE-3456,$HADOOP_PREFIX/bin/yarn should set defaults for $HADOOP_*_HOME,"If the $HADOOP_PREFIX/hadoop-dist/target/hadoop-0.23.0-SNAPSHOT.tar.gz tarball is used to distribute hadoop, all of the HADOOP components (HDFS, MAPRED, COMMON) are all under one directory. In this use case, HADOOP_PREFIX should be set and should point to the root directory for all components, and it should not be necessary to set HADOOP_HDFS_HOME, HADOOP_COMMON_HOME, and HADOOP_MAPRED_HOME. However, the $HADOOP_PREFIX/bin/yarn script requires these 3 to be set explicitly in the calling environment or it won't run.

$HADOOP_PREFIX/bin/yarn should check if $HADOOP_PREFIX is set and, if it is, use that value for the 3 other HADOOP_*_HOME variables."
MAPREDUCE-3454,[Gridmix] TestDistCacheEmulation is broken,TestDistCacheEmulation is broken as 'MapReduceTestUtil' no longer exists.
MAPREDUCE-3453,RM web ui application details page shows RM cluster about information,"Go to the RM Web ui page.  Click on the Applications link, then click on a particular application. The applications details page inadvertently includes the RM about page information after the application details:

Cluster ID: 	1321943597242
ResourceManager state: 	STARTED
ResourceManager started on: 	22-Nov-2011 06:33:17
ResourceManager version: 	0.23.0-SNAPSHOT from 1203458 by user source checksum 0c288fc0971ed28c970272a62f547eae on Tue Nov 22 06:31:09 UTC 2011
Hadoop version: 	0.23.0-SNAPSHOT from 1204629 by user source checksum 421c41e5cfbed4a9d473b123425ad94f on Tue Nov 22 06:29:17 UTC 2011 "
MAPREDUCE-3452,fifoscheduler web ui page always shows 0% used for the queue,"When the fifo scheduler is configured to be on, go to the RM web ui page and click the scheduler link.  Hover over the default queue to see the used%.  It always shows used% as 0.0% even when jobs are running."
MAPREDUCE-3451,Port Fair Scheduler to MR2,"The Fair Scheduler is in widespread use today in MR1 clusters, but not yet ported to MR2. This is to track the porting of the Fair Scheduler to MR2 and will be updated to include design considerations and progress."
MAPREDUCE-3450,NM port info no longer available in JobHistory,The NM RPC port used to be part of the hostname field in JobHistory. That seems to have gone missing. Required for the task log link on the history server.
MAPREDUCE-3448,TestCombineOutputCollector javac unchecked warning on mocked generics,"  [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] /home/jeagles/hadoop/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestCombineOutputCollector.java:125: warning: [unchecked] unchecked conversion
    [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 warnings
"
MAPREDUCE-3447,mapreduce examples not working,"Since the mavenization went in the mapreduce examples jar no longer works.  

$ hadoop jar ./hadoop-0.23.0-SNAPSHOT/modules/hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar  wordcount input output
Exception in thread ""main"" java.lang.ClassNotFoundException: wordcount
        at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
        at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:247)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:193)


"
MAPREDUCE-3444,trunk/0.23 builds broken ,"https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/208/ 
https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1310/
"
MAPREDUCE-3443,Oozie jobs are running as oozie user even though they create the jobclient as doAs.,"Oozie is having issues with job submission, since it does the following:

{code}
doAs(userwhosubmittedjob) {
 jobclient = new JobClient(jobconf);
}

jobclient.submitjob()

{code}

In 0.20.2** this works because the JT proxy is created as soon as we call new JobClient(). But in 0.23 this is no longer true since the client has to talk to multiple servers (AM/RM/JHS). To keep this behavior we will have to store the ugi in new JobClient() and make sure all the calls are run with a doAs() inside the jobclient."
MAPREDUCE-3438,"TestRaidNode fails because of ""Too many open files""",TestRaidNode fails because it opens many connections.
MAPREDUCE-3437,Branch 23 fails to build with Failure to find org.apache.hadoop:hadoop-project:pom:0.24.0-SNAPSHOT,"[INFO] Scanning for projects...
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project org.apache.hadoop:hadoop-mapreduce-examples:0.24.0-SNAPSHOT (/home/jeagles/hadoop/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/pom.xml) has 1 error
[ERROR]     Non-resolvable parent POM: Failure to find org.apache.hadoop:hadoop-project:pom:0.24.0-SNAPSHOT in http://stormwalk.champ.corp.yahoo.com:8081/nexus/content/groups/public was cached in the local repository, resolution will not be reattempted until the update interval of nexus has elapsed or updates are forced and 'parent.relativePath' points at wrong local POM @ line 17, column 11 -> [Help 2]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException
[ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/UnresolvableModelException
"
MAPREDUCE-3436,JobHistory webapp address should use the host from the jobhistory address,"On the following page : http://<RESOURCE_MANAGER>:8088/cluster/apps
There are links to the history for each application. None of them can be reached since they all point to the ip 0.0.0.0. For instance:
http://0.0.0.0:8088/proxy/application_1321658790349_0002/jobhistory/job/job_1321658790349_2_2

Am I missing something?

[root@bigtop-fedora-15 ~]# jps
9968 ResourceManager
1495 NameNode
1645 DataNode
12935 Jps
11140 -- process information unavailable
5309 JobHistoryServer
10237 NodeManager

[root@bigtop-fedora-15 ~]# netstat -tlpn | grep 8088
tcp        0      0 :::8088                     :::*                        LISTEN      9968/java    

For reference, here is my configuration:
root@bigtop-fedora-15 ~]# cat /etc/yarn/conf/yarn-site.xml 
<?xml version=""1.0""?>
<configuration>

<!-- Site specific YARN configuration properties -->

   <property>
      <name>yarn.nodemanager.aux-services</name>
      <value>mapreduce.shuffle</value>
    </property>
    <property>
      <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
      <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
      <name>mapreduce.admin.user.env</name>
      <value>CLASSPATH=/etc/hadoop/conf/*:/usr/lib/hadoop/*:/usr/lib/hadoop/lib/*</value>
    </property>

</configuration>


[root@bigtop-fedora-15 ~]# cat /etc/hadoop/conf/hdfs-site.xml 
<?xml version=""1.0""?>

<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
     <name>dfs.permissions</name>
     <value>false</value>
  </property>
  <property>
     <!-- specify this so that running 'hadoop namenode -format' formats the right dir -->
     <name>dfs.name.dir</name>
     <value>/var/lib/hadoop/cache/hadoop/dfs/name</value>
  </property>
</configuration>

[root@bigtop-fedora-15 ~]# cat /etc/hadoop/conf/core-site.xml 
<?xml version=""1.0""?>
<configuration>
  <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost:8020</value>
  </property>

  <property>
     <name>hadoop.tmp.dir</name>
     <value>/var/lib/hadoop/cache/${user.name}</value>
  </property>

  <!-- OOZIE proxy user setting -->
  <property>
    <name>hadoop.proxyuser.oozie.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.oozie.groups</name>
    <value>*</value>
  </property>

</configuration>
"
MAPREDUCE-3434,Nightly build broken ,"https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk/901/

Results :

Failed tests:   testSleepJob(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testRandomWriter(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testDistributedCache(org.apache.hadoop.mapreduce.v2.TestMRJobs)

Tests in error: 
  org.apache.hadoop.mapreduce.v2.TestMROldApiJobs: Failed to Start org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
  org.apache.hadoop.mapreduce.v2.TestUberAM: Failed to Start org.apache.hadoop.mapreduce.v2.TestMRJobs

Likely due to either of:
MAPREDUCE-3415. improve MiniMRYarnCluster & DistributedShell JAR resolution (tucu)
MAPREDUCE-3169. Create a new MiniMRCluster equivalent which only provides client APIs cross MR1 and MR2. (Ahmed via tucu)
"
MAPREDUCE-3433,Finding counters by legacy group name returns empty counters,Attempting to find counters with a legacy group name (e.g. org.apache.hadoop.mapred.Task$Counter rather than the new org.apache.hadoop.mapreduce.TaskCounter) returns empty counters. This causes TestStreamingCombiner to fail when run with YARN.
MAPREDUCE-3432,Yarn doesn't work if JAVA_HOME isn't set,"libexec/hadoop-config.sh does reliably work out JAVA_HOME for many platforms. unfortunately, the yarn scripts don't use it. As such you get told off when you try to run yarn

{code}
$ bin/yarn resourcemanager
Error: JAVA_HOME is not set.

{code}

To make things more interesting, if you set the value in the shell, it still doesn't propagate down to the scripts
{code}
$ echo $JAVA_HOME

$ source libexec/hadoop-config.sh 
$ echo $JAVA_HOME
/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home
$ bin/yarn resourcemanager
Error: JAVA_HOME is not set.
$echo $JAVA_HOME
/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home
{code}

"
MAPREDUCE-3431,NPE in Resource Manager shutdown,bringing up a resource manager failed; shutdown triggered an NPE
MAPREDUCE-3429,Few contrib tests are failing because of the missing commons-lang dependency,As the result of MAPREDUCE-3311 fix a transient {{commons-lang}} isn't available anymore to contrib tests. This causing silent failure with timeout. The problem is only seeing if tests are ran with {{-Dtest.output=yes}}
MAPREDUCE-3428,MR AppMaster CLASSPATH is dependent on the compile-time environment ,"The CLASSPATH for the MapReduce Application master is set using compile time path information, which is typically different from run-time. This will cause failure when running on different environments.

Specifically, the YarnRunner, and as part ApplicationSubmissionContext creation, sets the classpath for the application master using MRApps.setClasspath(environment), and then the setMRFrameworkClasspath(..) method uses compile time path information present in the ""mrapp-generated-classpath"" file (created at compile-time)."
MAPREDUCE-3427,streaming tests fail with MR2,"After Mavenizing streaming and getting its testcases to use the MiniMRCluster wrapper (MAPREDUCE-3169), 4 testcases fail to pass.

Following is an assessment of those failures. Note that the testcases have been tweaked only to set the streaming JAR and yarn as the  framework.
 
(If these issues are unrelated we should create sub-tasks for each one of them).

*TestStreamingCombiner*, fails because returned counters don't match assertion. However, counters printed in the test output indicate values that would satisfy the assertion. As Tom has indicated it seems MR/YARN are not passing back counter information to the client API.

*TestStreamingBadRecords*, the job is failing with the following exception

{code}
Application application_1321575850006_0001 failed 1 times due to AM Container for 
appattempt_1321575850006_0001_000001 exited with  exitCode: 127 due to: 
.Failing this attempt.. Failing the application.
{code}

Difficult to troubleshoot because there are not task logs from Mini MR/YARN  run.

*TestStreamingStatus* fails in validateTaskStatus() in the following assertion

{code}
expected:<[before consuming input > sort]> but was:<[SUCCEEDED]>
{code}

*TestUlimit* fails with

{code}
org.junit.ComparisonFailure: output is wrong expected:<[786432]> but was:<[unlimited]>
{code}
"
MAPREDUCE-3426,uber-jobs tried to write outputs into wrong dir,Incorrect setup of the uber tasks causes tasks to try to write intermidiate outputs into dirs that the user does not have permissions to write to on a secure cluster. 
MAPREDUCE-3425,uber job hangs and fails to get killed properly on a job kill signal,
MAPREDUCE-3424,Some LinuxTaskController cleanup,MR-2415 had some tabs and weird indenting and spacing. Also would be more clear if LTC explicitly overrides createLogDir. Let's clean this up. 
MAPREDUCE-3422,Counter display names are not being picked up,"When running a job I see ""MAP_INPUT_RECORDS"" rather than ""Map input records"" for the counter name. To fix this the resource bundle properties files need to be moved to the src/main/resources tree. "
MAPREDUCE-3421,Error in MR AM shutdown when running an uber-job,Exception thrown during the un-registration process in the ContainerAllocator#stop. Exception trace in next comment. 
MAPREDUCE-3420,[Umbrella ticket] Make uber jobs functional,Umbrella jira for getting uber jobs to work correctly with YARN/MRv2
MAPREDUCE-3419,Don't mark exited TT threads as dead in MiniMRCluster  ,"MAPREDUCE-2850 flagged all TT threads that exited in the MiniMRCluster as dead, this breaks a number of the other tests that use MiniMRCluster across restart."
MAPREDUCE-3417,job access controls not working app master and job history UI's,"tested with security on, no filters defined for httpserver, job acls set so that only I could view/modify the job.  Then went to the web ui to app master and job history server and both allowed me to view the job details.  The webui shows the user ""webuser"".   The RM properly rejected my request although it was using user ""Dr.Who"".    


The exception shown in the log is:
11/11/16 18:58:53 INFO mapred.JobACLsManager: job checkAccess user is: webuser
11/11/16 18:58:53 WARN security.ShellBasedUnixGroupsMapping: got exception trying to get groups for user webuser
org.apache.hadoop.util.Shell$ExitCodeException: id: webuser: No such user

        at org.apache.hadoop.util.Shell.runCommand(Shell.java:261)
        at org.apache.hadoop.util.Shell.run(Shell.java:188)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:381)
        at org.apache.hadoop.util.Shell.execCommand(Shell.java:467)
        at org.apache.hadoop.util.Shell.execCommand(Shell.java:450)
        at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:86)
        at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:55)
        at org.apache.hadoop.security.Groups.getGroups(Groups.java:88)
        at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1043)
        at org.apache.hadoop.security.authorize.AccessControlList.isUserAllowed(AccessControlList.java:221)
        at org.apache.hadoop.mapred.JobACLsManager.checkAccess(JobACLsManager.java:103)
        at org.apache.hadoop.mapreduce.v2.hs.CompletedJob.checkAccess(CompletedJob.java:325)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.checkAccess(AppController.java:292)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.requireJob(AppController.java:313)
        at org.apache.hadoop.mapreduce.v2.app.webapp.AppController.job(AppController.java:97)"
MAPREDUCE-3416,"Rename {start,stop}-all.sh to {start,stop}-yarn.sh for consistency with HDFS","There are already {start,stop}-all.sh scripts for starting and stopping all Hadoop daemons which conflict with the YARN {start,stop}-all.sh scripts. The latter should be renamed {start,stop}-yarn.sh."
MAPREDUCE-3415,improve MiniMRYarnCluster & DistributedShell JAR resolution ,"Current JAR resolution assumes the following:

# The class used for JAR lookup is effectively in a JAR
# A System property is set for testing with the location of the JAR

The problem with #1 is that in some cases (when using the class in the same Maven module where the class is, the class is not in a JAR but in a directory 'target/test-classes').

The problem with #2 is the JAR does not exists at the time of running the test (packaging comes after test and we are not doing integration testing yet thus won't work)

In addition, this is required for streaming testcases, to have the JAR with streaming classes for testing."
MAPREDUCE-3413,RM web ui applications not sorted in any order by default,
MAPREDUCE-3412,'ant docs' is broken,'ant docs' no longer work.
MAPREDUCE-3411,Performance Upgrade for jQuery,"jQuery 1.6.4 is almost twice as fast as current version 1.4.4 on modern browsers on some operations. There are also many modern browser compatibility fixes

http://jsperf.com/jquery-15-unique-traversal/15"
MAPREDUCE-3408,yarn-daemon.sh unconditionnaly sets yarn.root.logger,"yarn-daemon.sh unconditionnaly sets yarn.root.logger which then prevent any override from happening.
From ./hadoop-mapreduce-project/hadoop-yarn/bin/yarn-daemon.sh:
> export YARN_ROOT_LOGGER=""INFO,DRFA""
> export YARN_JHS_LOGGER=""INFO,JSA""

and then yarn-daemon.sh will call ""$YARN_HOME""/bin/yarn which does the following:
> YARN_OPTS=""$YARN_OPTS -Dhadoop.root.logger=${YARN_ROOT_LOGGER:-INFO,console}""
> YARN_OPTS=""$YARN_OPTS -Dyarn.root.logger=${YARN_ROOT_LOGGER:-INFO,console}""

This has at least 2 issues:
* I cannot override hadoop.root.logger when using the yarn-daemon.sh script
* I cannot have different values for hadoop.root.logger and yarn.root.logger

I currently see two different ways to proceed forward:
1/ Make the script yarn-daemon.sh only sets a default value for YARN_ROOT_LOGGER if this variable is not defined
2/ Remove the quoted code from yarn-daemon.sh since yarn already does something similar
3/ Entirely remove that chunk and let people define their logging however they want through some properties files (see log4j.properties in the conf directories for instance)

I would also use the variable HADOOP_ROOT_LOGGER for hadoop.root.logger if either option 1/ or 2/ would be taken.

I don't really have any preference toward any of these solutions. What would you recommend? What is the Apache Hadoop way for this matter?

Note: This is probably happening as well for the other daemons, and I will take a look at it once this issue is resolved."
MAPREDUCE-3407,Wrong jar getting used in TestMR*Jobs* for MiniMRYarnCluster,pom for mapreduce-client-jobclient sets system property to incorrect jar name. 
MAPREDUCE-3406,Add node information to bin/mapred job -list-attempt-ids and other improvements,"From [~rramya]
Providing the NM information where the containers are scheduled in bin/mapred job -list-attempt-ids will be helpful in automation, debugging and to avoid grepping through the AM logs.

From my own observation, the list-attempt-ids should list the attempt ids and not require the arguments. The arguments if given, can be used to filter the results. From the usage:
bq. [-list-attempt-ids <job-id> <task-type> <task-state>]. Valid values for <task-type> are MAP REDUCE JOB_SETUP JOB_CLEANUP TASK_CLEANUP. Valid values for <task-state> are running, completed

"
MAPREDUCE-3405,MAPREDUCE-3015 broke compilation of contrib scheduler tests,"MAPREDUCE-3015 added a new argument to the TaskTrackerStatus constructor, which is used by a few of the scheduler tests, but didn't update those tests. So, the contrib test build is now failing on 0.20-security"
MAPREDUCE-3404,Speculative Execution: speculative map tasks launched even if -Dmapreduce.map.speculative=false,"When forcing a mapper to take significantly longer than other map tasks, speculative map tasks are
launched even if the mapreduce.job.maps.speculative.execution parameter is set to 'false'.

Testcase: ran default WordCount job with spec execution set to false for both map and reduce but still saw a fifth mapper
task launch, ran job as follows:

hadoop --config <config>  jar   /tmp/testphw/wordcount.jar   WordCount  
-Dmapreduce.job.maps.speculative.execution=false  -Dmapreduce.job.reduces.speculative.execution=false 
/tmp/test_file_of_words* /tmp/file_of_words.out

Input data was 4 text files >hdfs blocksize, with same word pattern plus one diff text line in each file, fourth
file was 4 times as large as others:

hadoop --config <config>  fs -ls  /tmp
Found 5 items
drwxr-xr-x   - user hdfs          0 2011-10-20 16:17 /tmp/file_of_words.out
-rw-r--r--   3 user hdfs   62800021 2011-10-20 14:45 /tmp/test_file_of_words1
-rw-r--r--   3 user hdfs   62800024 2011-10-20 14:46 /tmp/test_file_of_words2
-rw-r--r--   3 user hdfs   62800024 2011-10-20 14:46 /tmp/test_file_of_words3
-rw-r--r--   3 user hdfs  271708312 2011-10-20 15:50 /tmp/test_file_of_words4

Job launched 5 mappers despite spec exec set to false, output snippet:

        org.apache.hadoop.mapreduce.JobCounter
                NUM_FAILED_MAPS=1
                TOTAL_LAUNCHED_MAPS=5
                TOTAL_LAUNCHED_REDUCES=1
                RACK_LOCAL_MAPS=5
                SLOTS_MILLIS_MAPS=273540
                SLOTS_MILLIS_REDUCES=212876


Reran same case as above only set both spec exec params to 'true', same results only this time the fifth task being
launched is expected since spec exec = true.

job run:

hadoop --config <config>  jar   /tmp/testphw/wordcount.jar   WordCount  
-Dmapreduce.job.maps.speculative.execution=true  -Dmapreduce.job.reduces.speculative.execution=true 
/tmp/test_file_of_words* /tmp/file_of_words.out

output snippet:

        org.apache.hadoop.mapreduce.JobCounter
                NUM_FAILED_MAPS=1
                TOTAL_LAUNCHED_MAPS=5
                TOTAL_LAUNCHED_REDUCES=1
                RACK_LOCAL_MAPS=5
                SLOTS_MILLIS_MAPS=279653
                SLOTS_MILLIS_REDUCES=211474"
MAPREDUCE-3402,AMScalability test of Sleep job with 100K 1-sec maps regressed into running very slowly,"The world was rosier before October 19-25, [~karams] says.

The 100K 1 second sleep job used to take around 800mins or 13-14 mins. It now runs till 45 mins and still manages to complete only about 45K tasks.

One/more of the flurry of commits for 0.23.0 deserve(s) the blame."
MAPREDUCE-3399,ContainerLocalizer should request new resources after completing the current one,"Currently, the ContainerLocalizer to NM heartbeats to the NM every second. Not very significant, but this causes a ~4second delay in jobs (job jar, splits, etc). Instead, it should heartbeat to ask for additional resources to localize as soon as the previous one is localzied. There's already a TODO in the ContainerLocalizer for this."
MAPREDUCE-3398,Log Aggregation broken in Secure Mode,"Log aggregation in secure mode does not work with MAPREDUCE-2977. The nodemanager relies on the users credentials to write out logs to HDFS. These credentials are currently cancelled once a job completes, before the NM can write out the logs."
MAPREDUCE-3396,Mumak compilation is broken (for a while?),{{contrib/mumak}} compilation is broken because of the missing {{commons-lang}} dependency
MAPREDUCE-3395,Add mapred.disk.healthChecker.interval to mapred-default.xml,Let's add mapred.disk.healthChecker.interval to mapred-default.xml.
MAPREDUCE-3394,Add log guard for a debug message in ReduceTask,There's a LOG.debug message in ReduceTask that stringifies a task ID and uses a non-negligible amount of CPU in some cases. We should guard it with {{isDebugEnabled}}
MAPREDUCE-3393,"TestMRJobs, TestMROldApiJobs, and TestUberAM failures","Check out branch 0.23 and run mvn test from hadoop-mapreduce-project directory

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.mapred.TestClientServiceDelegate
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 5.717 sec
Running org.apache.hadoop.mapred.TestClientRedirect
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 15.436 sec
Running org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.975 sec
Running org.apache.hadoop.mapreduce.v2.TestMRJobs
Tests run: 4, Failures: 3, Errors: 1, Skipped: 0, Time elapsed: 67.999 sec <<< FAILURE!
Running org.apache.hadoop.mapreduce.v2.TestYARNRunner
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 11.976 sec
Running org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
Tests run: 2, Failures: 2, Errors: 0, Skipped: 0, Time elapsed: 31.879 sec <<< FAILURE!
Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService
^NRunning org.apache.hadoop.mapreduce.v2.TestUberAM
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 101.096 sec <<< FAILURE!

Results :

Failed tests:   testSleepJob(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testRandomWriter(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testDistributedCache(org.apache.hadoop.mapreduce.v2.TestMRJobs)
  testJobSucceed(org.apache.hadoop.mapreduce.v2.TestMROldApiJobs): Job expected to succeed failed
  testJobFail(org.apache.hadoop.mapreduce.v2.TestMROldApiJobs)

Tests in error: 
  testFailingMapper(org.apache.hadoop.mapreduce.v2.TestMRJobs): 0
  org.apache.hadoop.mapreduce.v2.TestUberAM: Failed to Start org.apache.hadoop.mapreduce.v2.TestMRJobs

Tests run: 19, Failures: 5, Errors: 2, Skipped: 0"
MAPREDUCE-3392,Cluster.getDelegationToken() throws NPE if client.getDelegationToken() returns null.,"Caused by: java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.Cluster.getDelegationToken(Cluster.java:399)
        at org.apache.hadoop.mapred.JobClient.getDelegationToken(JobClient.java:1074)
        at
org.apache.oozie.service.KerberosHadoopAccessorService.createJobClient(KerberosHadoopAccessorService.java:139)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.createJobClient(JavaActionExecutor.java:810)
        at org.apache.oozie.action.hadoop.JavaActionExecutor.submitLauncher(JavaActionExecutor.java:551)"
MAPREDUCE-3391,Connecting to CM is logged as Connecting to RM,"In class *org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster*
{code}
private void connectToCM() {
      String cmIpPortStr = container.getNodeId().getHost() + "":"" 
          + container.getNodeId().getPort();		
      InetSocketAddress cmAddress = NetUtils.createSocketAddr(cmIpPortStr);		
      LOG.info(""Connecting to ResourceManager at "" + cmIpPortStr);
      this.cm = ((ContainerManager) rpc.getProxy(ContainerManager.class, cmAddress, conf));
    }
{code}"
MAPREDUCE-3390,NPE while submitting job,"Caused by: java.lang.NullPointerException
        at java.io.Reader.<init>(Reader.java:61)
        at java.io.InputStreamReader.<init>(InputStreamReader.java:55)
        at org.apache.hadoop.mapreduce.v2.util.MRApps.setMRFrameworkClasspath(MRApps.java:183)
        at org.apache.hadoop.mapreduce.v2.util.MRApps.setClasspath(MRApps.java:220)
        at org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(YARNRunner.java:360)
        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:237)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:377)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1159)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1156)
        at java.security.AccessController.doPrivileged(Native Method)        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1156)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:571)"
MAPREDUCE-3389,MRApps loads the 'mrapp-generated-classpath' file with classpath from the build machine,"The 'mrapp-generated-classpath' file contains the classpath from where Hadoop was build. This classpath is not useful under any circumstances.

For example the content of the 'mrapp-generated-classpath' in my dev environment is:

/Users/tucu/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/Users/tucu/.m2/repository/asm/asm/3.2/asm-3.2.jar:/Users/tucu/.m2/repository/com/cenqua/clover/clover/3.0.2/clover-3.0.2.jar:/Users/tucu/.m2/repository/com/google/guava/guava/r09/guava-r09.jar:/Users/tucu/.m2/repository/com/google/inject/guice/2.0/guice-2.0.jar:/Users/tucu/.m2/repository/com/google/inject/extensions/guice-servlet/2.0/guice-servlet-2.0.jar:/Users/tucu/.m2/repository/com/google/protobuf/protobuf-java/2.4.0a/protobuf-java-2.4.0a.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar:/Users/tucu/.m2/repository/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar:/Users/tucu/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/Users/tucu/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/Users/tucu/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/tucu/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/tucu/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/tucu/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/Users/tucu/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/tucu/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/tucu/.m2/repository/commons-daemon/commons-daemon/1.0.3/commons-daemon-1.0.3.jar:/Users/tucu/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/tucu/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/tucu/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/tucu/.m2/repository/commons-io/commons-io/2.1/commons-io-2.1.jar:/Users/tucu/.m2/repository/commons-lang/commons-lang/2.5/commons-lang-2.5.jar:/Users/tucu/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/Users/tucu/.m2/repository/commons-logging/commons-logging-api/1.1/commons-logging-api-1.1.jar:/Users/tucu/.m2/repository/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar:/Users/tucu/.m2/repository/hsqldb/hsqldb/1.8.0.7/hsqldb-1.8.0.7.jar:/Users/tucu/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/Users/tucu/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/Users/tucu/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/tucu/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/tucu/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/tucu/.m2/repository/jdiff/jdiff/1.0.9/jdiff-1.0.9.jar:/Users/tucu/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/tucu/.m2/repository/junit/junit/4.8.2/junit-4.8.2.jar:/Users/tucu/.m2/repository/log4j/log4j/1.2.15/log4j-1.2.15.jar:/Users/tucu/.m2/repository/net/java/dev/jets3t/jets3t/0.6.1/jets3t-0.6.1.jar:/Users/tucu/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/Users/tucu/.m2/repository/org/apache/avro/avro/1.5.3/avro-1.5.3.jar:/Users/tucu/.m2/repository/org/apache/avro/avro-ipc/1.5.3/avro-ipc-1.5.3.jar:/Users/tucu/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/Users/tucu/src/apache/hadoop/git/hadoop-common-project/hadoop-annotations/target/hadoop-annotations-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-common-project/hadoop-auth/target/hadoop-auth-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-common-project/hadoop-common/target/hadoop-common-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-common-project/hadoop-common/target/hadoop-common-0.24.0-SNAPSHOT-tests.jar:/Users/tucu/src/apache/hadoop/git/hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/target/hadoop-mapreduce-client-common-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/hadoop-mapreduce-client-core-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle/target/hadoop-mapreduce-client-shuffle-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-api/target/hadoop-yarn-api-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-common/target/hadoop-yarn-common-0.24.0-SNAPSHOT-tests.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-common/target/hadoop-yarn-server-common-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/target/hadoop-yarn-server-nodemanager-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/hadoop-yarn-server-resourcemanager-0.24.0-SNAPSHOT.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/target/hadoop-yarn-server-resourcemanager-0.24.0-SNAPSHOT-tests.jar:/Users/tucu/src/apache/hadoop/git/hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/target/hadoop-yarn-server-web-proxy-0.24.0-SNAPSHOT.jar:/Users/tucu/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/Users/tucu/.m2/repository/org/apache/zookeeper/zookeeper/3.3.1/zookeeper-3.3.1.jar:/Users/tucu/.m2/repository/org/aspectj/aspectjrt/1.6.5/aspectjrt-1.6.5.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.7.1/jackson-core-asl-1.7.1.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.7.1/jackson-mapper-asl-1.7.1.jar:/Users/tucu/.m2/repository/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar:/Users/tucu/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/Users/tucu/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/Users/tucu/.m2/repository/org/jboss/netty/netty/3.2.3.Final/netty-3.2.3.Final.jar:/Users/tucu/.m2/repository/org/mockito/mockito-all/1.8.5/mockito-all-1.8.5.jar:/Users/tucu/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/Users/tucu/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/Users/tucu/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/Users/tucu/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/Users/tucu/.m2/repository/org/xerial/snappy/snappy-java/1.0.3.2/snappy-java-1.0.3.2.jar:/Users/tucu/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/tucu/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/Users/tucu/.m2/repository/tomcat/jasper-compiler/5.5.23/jasper-compiler-5.5.23.jar:/Users/tucu/.m2/repository/tomcat/jasper-runtime/5.5.23/jasper-runtime-5.5.23.jar:/Users/tucu/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar
"
MAPREDUCE-3388,Streaming task with special char gets wrong output ,"In 0.20.204:
{noformat}
hadoop jar $HADOOP_HOME/hadoop-streaming.jar '-Dmapreduce.job.acl-view-job=*' -files 'file:///tmp/InputDir#testlink!@$&*()-_+=' -input input.txt -mapper 'xargs cat' -reducer cat -output output -jobconf mapred.job.name=streamingTest-1000 -jobconf 'mapreduce.job.acl-view-job=*'
{noformat}

Output:
{noformat}
hadoop fs -cat output/*
and-so-is-the-c#
c++-also-supports-object-oriented-concepts
hadoop-apache-org-core  
hadoop-streaming
hod-is-the-part-of-hadoop
it-is-residing-on-apache-under-repos-asf
java-an object-oriented-language
smalltalk-is-also-object-oriented-language
streaming-is-also-part-of-it
{noformat}

For 0.23:
{noformat}
hadoop jar $HADOOP_MAPRED_HOME/hadoop-streaming.jar -Dmapreduce.job.acl-view-job=* -files 'file:///tmp/InputDir#testlink!@$&*()-_+=' -input input.txt  -mapper 'xargs cat' -reducer cat -output output -jobconf mapred.job.name=streamingTest-1000 -jobconf 'mapreduce.job.acl-view-job=*'
{noformat}

Output:
{noformat}
testlink!@$&*()-_+=/input1.txt testlink!@$&*()-_+=/input2.txt
{noformat}

The contents of input.txt are as follows:
{noformat}
hadoop fs -cat Streaming/streaming-1000/input.txt
testlink!@$&*()-_+=/input1.txt
testlink!@$&*()-_+=/input2.txt
{noformat}"
MAPREDUCE-3387,A tracking URL of N/A before the app master is launched breaks oozie,"When oozie launches a map/reduce job it retrieves the tracking URL of that job to display in its own UI.  Previously this tracking URL did not change except when the job completed.  Currently the URL starts out as N/A and then changes to the real URL once the AppMaster launches.  This breaks oozie, as oozie expects to be able to get that information quickly and get back to processing other requests.

Because the web app proxy is now available we can maintain backwards compatibility by instead of returning N/A we can return the URL of the proxy for that application.  This relies on the fact that the application master's UI will display the correct thing for the URI http://<host>:<port>/, which MR and others now do."
MAPREDUCE-3386,Streaming and Gridmix tests are failing in trunk,"Streaming and Gridmix tests are failing. Following error occurs in TestGridmixSummary:
{noformat}
Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
java.io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addr
esses.
        at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:123)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:85)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:78)
        at org.apache.hadoop.mapred.JobClient.init(JobClient.java:460)
        at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:450)
        at org.apache.hadoop.mapred.gridmix.TestGridmixSummary.testClusterSummarizer(TestGridmixSummary.java:365)
{noformat}"
MAPREDUCE-3385,Add warning message for the overflow in reduce() of org.apache.hadoop.mapreduce.lib.reduce.IntSumReducer,"When we call the function reduce() of IntSumReducer,the result may overflow.
We should send a warning message to users if overflow occurs."
MAPREDUCE-3383,Duplicate job.getOutputValueGroupingComparator() in ReduceTask,"This is probably just a small error by mistake.
"
MAPREDUCE-3382,Network ACLs can prevent AMs to ping the Job-end notification URL,MAPREDUCE-3028 added support for job-end notification from MR AMs after the job finishes. Network ACLs can have an implication on this one - outgoing connections from the compute nodes may be restricted in some settings and so job-end notification( that can originate from the AMs which may run on random nodes in the cluster) may have issues.
MAPREDUCE-3381,[Rumen] TestRumenJobTraces fails after MAPREDUCE-3035,TestRumenJobTraces fails after MAPREDUCE-3035. The issue is due to the null value passed for rackName.
MAPREDUCE-3380,Token infrastructure for running clients which are not kerberos authenticated,"The JobClient.getDelegationToken() method is returning NULL, this makes Oozie fail when trying to get the delegation token to use it for starting a job.

What is seems to be happing is that Jobclient.getDelegationToken() calls Cluster.getDelegationToken() that calls YarnRunner.getDelegationToken() that calls ResourceMgrDelegate.getDelegationToken(). And the last one is not implemented. (Thanks Ahmed for tracing this in MR2 code)
"
MAPREDUCE-3379,LocalResourceTracker should not tracking deleted cache entries,
MAPREDUCE-3378,Create a single 'hadoop-mapreduce' Maven artifact,"In 0.23.0 there are multiple artifacts (hadoop-mapreduce-client-app, hadoop-mapreduce-client-common, hadoop-mapreduce-client-core, etc). It would be simpler for users to declare a dependency on hadoop-mapreduce (much like there's hadoop-common and hadoop-hdfs). (This would also be a step towards MAPREDUCE-2600.)"
MAPREDUCE-3377,Compatibility issue with 0.20.203.,"I have an OutputFormat which implements Configurable.  I set new config entries to a job configuration during checkOutputSpec() so that the tasks will get the config entries through the job configuration.  This works fine in 0.20.2, but stopped working starting from 0.20.203.  With 0.20.203, my OutputFormat still has the configuration set, but the copy a task gets does not have the new entries that are set as part of checkOutputSpec().  

I believe that the problem is with JobClient.  The job configuration needs to wait till checkOutputSpec() is returned before being cloned and submitted."
MAPREDUCE-3376,Old mapred API combiner uses NULL reporter,"The OldCombinerRunner class inside Task.java uses a NULL Reporter.  If the combiner code runs for an extended period of time, even with reporting progress as it should, the map task can timeout and be killed.  It appears that the NewCombinerRunner class uses a valid reporter and as such is not impacted by this bug."
MAPREDUCE-3375,Memory Emulation system tests.,"1. Test the Gridmix memory emulation feature for gridmix jobs with default progress interval, different input data, submission policies and user resolver modes . Verify the maps phase of total heap usage of gridmix jobs with corresponding the original job in the trace.

2. Test the Gridmix memory emulation feature for gridmix jobs with custom progress interval, different input data, submission policies and user resolver modes . Verify the maps phase of total heap usage of gridmix jobs with corresponding the original job in the trace.

3. Test the Gridmix memory emulation feature for gridmix jobs with default progress interval, different input data, submission policies and user resolver modes. Verify the maps and reduces phase of total heap usage metric of gridmix jobs with corresponding the original job in the trace.

4. Disable Gridmix memory emulation option and verify the jobs whether it emulates the heap memory or not.
 
"
MAPREDUCE-3374,src/c++/task-controller/configure is not set executable in the tarball and that prevents task-controller from rebuilding,ant task-controller fails because src/c++/task-controller/configure is not set executable
MAPREDUCE-3373,"Hadoop scripts unconditionally source ""$bin""/../libexec/hadoop-config.sh.",It would be nice to be able to specify some other location for hadoop-config.sh
MAPREDUCE-3372,HADOOP_PREFIX cannot be overriden,"hadoop-config.sh forces HADOOP_prefix to a specific value:
export HADOOP_PREFIX=`dirname ""$this""`/..

It would be nice to make this overridable.
"
MAPREDUCE-3371,Review and improve the yarn-api javadocs.,Review and improve the yarn-api javadocs.
MAPREDUCE-3370,MiniMRYarnCluster uses a hard coded path location for the MapReduce application jar,MiniMRYarnCluster uses a hard coded relative path location for the MapReduce application jar. It is better to have this location as a system property so tests can pick the application jar regardless of their working directory.
MAPREDUCE-3369,Migrate MR1 tests to run on MR2 using the new interfaces introduced in MAPREDUCE-3169,"This ticket tracks the migration of MR1 tests (currently residing in ""hadoop-mapreduce-project/src/test/"") to run on MR2. The migration is using the new interfaces introduced in MAPREDUCE-3169."
MAPREDUCE-3368,compile-mapred-test fails,"compile-mapred-test target is failing once again.
Details: https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-0.23-Build/83/consoleFull"
MAPREDUCE-3367,Consolidate MRv2 maven modules,"Maven modules for MRv2 has been splitter into many small pieces, like this:

{noformat}
[INFO] hadoop-yarn ....................................... SUCCESS [0.312s]
[INFO] hadoop-yarn-api ................................... SUCCESS [24.184s]
[INFO] hadoop-yarn-common ................................ SUCCESS [18.243s]
[INFO] hadoop-yarn-server ................................ SUCCESS [0.094s]
[INFO] hadoop-yarn-server-common ......................... SUCCESS [5.394s]
[INFO] hadoop-yarn-server-nodemanager .................... SUCCESS [7.056s]
[INFO] hadoop-yarn-server-web-proxy ...................... SUCCESS [2.295s]
[INFO] hadoop-yarn-server-resourcemanager ................ SUCCESS [10.217s]
[INFO] hadoop-yarn-server-tests .......................... SUCCESS [0.395s]
[INFO] hadoop-yarn-applications .......................... SUCCESS [0.069s]
[INFO] hadoop-yarn-applications-distributedshell ......... SUCCESS [2.534s]
[INFO] hadoop-yarn-site .................................. SUCCESS [0.144s]
[INFO] hadoop-mapreduce-client ........................... SUCCESS [0.073s]
[INFO] hadoop-mapreduce-client-core ...................... SUCCESS [13.727s]
[INFO] hadoop-mapreduce-client-common .................... SUCCESS [13.045s]
[INFO] hadoop-mapreduce-client-shuffle ................... SUCCESS [1.909s]
[INFO] hadoop-mapreduce-client-app ....................... SUCCESS [6.676s]
[INFO] hadoop-mapreduce-client-hs ........................ SUCCESS [3.317s]
[INFO] hadoop-mapreduce-client-jobclient ................. SUCCESS [2.575s]
[INFO] hadoop-mapreduce .................................. SUCCESS [4.952s]
{noformat}

The excessive use of directory structure is slowing down development and compile time.  For example, hadoop-yarn-server-tests and hadoop-yarn-site should not be stand alone modules.  There are better ways to organize the source code.  The proposal is to rearrange the code to:

{noformat}
Apache Hadoop Mapreduce Project
  - Apache Hadoop Mapreduce Client
  - Apache Hadoop YARN
{noformat}

This is a nice to have for 0.23, but optional."
MAPREDUCE-3366,Mapreduce component should use consistent directory structure layout as HDFS/common,"Directory structure for MRv2 layout looks like:

{noformat}
hadoop-mapreduce-0.23.0-SNAPSHOT/bin
                                /conf
                                /lib
                                /modules
{noformat}

The directory structure layout should be updated to reflect changes implemented in HADOOP-6255.

{noformat}
hadoop-mapreduce-0.23.0-SNAPSHOT/bin
                                /etc/hadoop
                                /lib
                                /libexec
                                /sbin
                                /share/hadoop
                                /share/hadoop/lib
{noformat}"
MAPREDUCE-3365,Uncomment eventlog settings from the documentation,"Two fair scheduler debug options ""mapred.fairscheduler.eventlog.enabled"" and ""mapred.fairscheduler.dump.interval"" are commented out in fair scheduler doc file.
It's useful for debugging."
MAPREDUCE-3363,"The ""totalnodes""  and ""memorytotal"" fields show wrong information if the nodes are going down and coming up early(before 10min) ","The node details is not moved from Totalnodes to lostnodes for 600000 ms.So if the node is going down and coming up before the expiry interval, the cluster status in terms of the total nodes and Total cluster memory displays wrong values. 
Atleast, if the same node is coming up again...should not consider as new node.No point of time duplicate nodes should be displayed in Totalnodes list.
"
MAPREDUCE-3360,Provide information about lost nodes in the UI.,Currently there is no information provided about *lost nodes*. Provide information in the UI. 
MAPREDUCE-3359,Yarn clients / AM should be able to provide config options to the RM / NM,"The RM and NM do not read a job's configuration. Clients / AMs should however be able to configure certain parameters for the RM/NM on a per app basis - like the Log Retention policy, token cancellation."
MAPREDUCE-3357,TestMRWithDistributedCache fails on branch-20-security,"TestMRWithDistributedCache testLocalJobRunner fails on branch-20-security:

{noformat}
Testcase: testLocalJobRunner took 5.501 sec
        FAILED
null
junit.framework.AssertionFailedError: null
        at org.apache.hadoop.filecache.TestMRWithDistributedCache.testWithConf(TestMRWithDistributedCache.java:154)
        at org.apache.hadoop.filecache.TestMRWithDistributedCache.testLocalJobRunner(TestMRWithDistributedCache.java:162)
{noformat}
"
MAPREDUCE-3356,TestTrackerDistributedCacheManager fails on branch-20-security,The testReferenceCount and testPublicPrivateCache tests fail reproducibly on branch-20-security. Details in follow up comment.
MAPREDUCE-3355,AM scheduling hangs frequently with sort job on 350 nodes,"Another collaboration with [~karams]. Sort job hangs not so rarely on a 350 node cluster. Found this in AM logs:
{code}

Exception in thread ""ContainerLauncher #60"" org.apache.hadoop.yarn.YarnException: java.lang.InterruptedException
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:170)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:379)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.InterruptedException
            at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1199)
            at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:312)
            at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:294)
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:168)
            ... 4 more

Exception in thread ""ContainerLauncher #53"" org.apache.hadoop.yarn.YarnException: java.lang.InterruptedException
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:170)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.sendContainerLaunchFailedMsg(ContainerLauncherImpl.java:405)
            at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:330)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
Caused by: java.lang.InterruptedException
            at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1199)
            at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:312)
            at java.util.concurrent.LinkedBlockingQueue.put(LinkedBlockingQueue.java:294)
            at org.apache.hadoop.yarn.event.AsyncDispatcher$GenericEventHandler.handle(AsyncDispatcher.java:168)
            ... 5 more
{code}"
MAPREDUCE-3354,JobHistoryServer should be started by bin/mapred and not by bin/yarn,JobHistoryServer belongs to mapreduce land.
MAPREDUCE-3353,Need a RM->AM channel to inform AMs about faulty/unhealthy/lost nodes,"When a node gets lost or turns faulty, AM needs to know about that event so that it can take some action like for e.g. re-executing map tasks whose intermediate output live on that faulty node."
MAPREDUCE-3350,Per-app RM page should have the list of application-attempts like on the app JHS page,
MAPREDUCE-3349,No rack-name logged in JobHistory for unsuccessful tasks,"Found this while running jobs on a cluster with [~Karams].

This is because TaskAttemptUnsuccessfulCompletionEvent history record doesn't have a rack field."
MAPREDUCE-3348,mapred job -status fails to give info even if the job is present in History,"It is trying to get the app report from the RM  for the job, RM throws exception when it doesn't find and then it is giving the same exception without trying from History Server.

{code}
11/11/03 08:47:27 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapred                                                                                  uce.v2.api.MRClientProtocol
11/11/03 08:47:28 WARN mapred.ClientServiceDelegate: Exception thrown by remote end.
RemoteTrace:
 at LocalTrace:
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Trying to get information for an absent applicat                                                                                  ion application_1320278804241_0002
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:142)
        at $Proxy6.getApplicationReport(Unknown Source)
        at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getApplicationReport(ClientRMProtocolPBClie                                                                                  ntImpl.java:111)
        at org.apache.hadoop.mapred.ResourceMgrDelegate.getApplicationReport(ResourceMgrDelegate.java:321)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getProxy(ClientServiceDelegate.java:137)
        at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:273)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:353)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:429)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:186)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:240)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1106)
Exception in thread ""main"" RemoteTrace:
 at Local Trace:
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Trying to get information for an absent applicat                                                                                  ion application_1320278804241_0002
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:142)
        at $Proxy6.getApplicationReport(Unknown Source)
        at org.apache.hadoop.yarn.api.impl.pb.client.ClientRMProtocolPBClientImpl.getApplicationReport(ClientRMProtocolPBClie                                                                                  ntImpl.java:111)
        at org.apache.hadoop.mapred.ResourceMgrDelegate.getApplicationReport(ResourceMgrDelegate.java:321)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getProxy(ClientServiceDelegate.java:137)
        at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:273)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:353)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:429)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:186)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:240)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1106)

{code}"
MAPREDUCE-3347,Resource manager is not respawning MRAppMaster process if it goes down in the middle of job execution and the job is getting failed.,ApplicationMaster service should recover the job if MRAppMaster process goes down in the middle of job execution.If not MRAppMaster process becomes the single point of failure for the job and losses the advantage of MRV1 framework.
MAPREDUCE-3346,Rumen LoggedTaskAttempt  getHostName call returns hostname as null,"After MAPREDUCE-3035 and MAPREDUCE-3317
Now MRV2 job history contains hostName and rackName.
when rumen trace builder is ran on jobhistory, its generated trace contains hostname in form of 
hostName : /raclname/hostname

But getHostName for LoggedTaskAttempt returns hostname as null
Seems that TraceBuilder is setting hostName properly but JobTraceReader is not able read it."
MAPREDUCE-3345,Race condition in ResourceManager causing TestContainerManagerSecurity to fail sometimes,See https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1247//testReport/org.apache.hadoop.yarn.server/TestContainerManagerSecurity/testUnauthorizedUser/
MAPREDUCE-3344,o.a.h.mapreduce.Reducer since 0.21 blindly casts to ReduceContext.ValueIterator,"0.21 mapreduce.Reducer introduced a blind cast to ReduceContext.ValueIterator. There should an instanceof check around this block to ensure we don't throw a CastClassException:
{code}
       // If a back up store is used, reset it
      ((ReduceContext.ValueIterator)
          (context.getValues().iterator())).resetBackupStore();
{code}"
MAPREDUCE-3343,TaskTracker Out of Memory because of distributed cache,"This Out of Memory happens when you run large number of jobs (using the distributed cache) on a TaskTracker. 

Seems the basic issue is with the distributedCacheManager (instance of TrackerDistributedCacheManager in TaskTracker.java), this gets created during TaskTracker.initialize(), and it keeps references to TaskDistributedCacheManager for every submitted job via the jobArchives Map, also references to CacheStatus via cachedArchives map. I am not seeing these cleaned up between jobs, so this can out of memory problems after really large number of jobs are submitted. We have seen this issue in a number of cases."
MAPREDUCE-3342,JobHistoryServer doesn't show job queue,"The job history server doesn't show the queue the jobwas run in.  It is inserted into the job history file.

It seems like this should be part of the Job interface.

JobImpl current gets it from the job config to insert into the history.  "
MAPREDUCE-3341,Enhance logging of initalized queue limit values,"Currently the RM log shows only a partial set of the limits that are configured when a queue is initialized / reinitialized.

For example, this is what is currently shown in the RM log for an initialized queue:
# <datestamp> INFO org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue: Initializing
default, capacity=0.25, asboluteCapacity=0.25, maxCapacity=25.0, asboluteMaxCapacity=0.25, userLimit=100,
userLimitFactor=20.0, maxApplications=2500, maxApplicationsPerUser=50000, state=RUNNING,
acls=ADMINISTER_QUEUE:*SUBMIT_JOB:*ADMINISTER_JOBS:*

Breaking down the line above, shows: 

capacity=0.25
asboluteCapacity=0.25
maxCapacity=25.0
asboluteMaxCapacity=0.25
userLimit=100
userLimitFactor=20.0
maxApplications=2500
maxApplicationsPerUser=50000

It might be nice if we could include more information such as maxActiveApplications, maxActiveApplicationsPerUser, utilization, and usedCapacity along with information on how each of these is computed (i.e. formulae used) (Thanks to Phil Su for requesting this).

"
MAPREDUCE-3339,"Job is getting hanged indefinitely,if the child processes are killed on the NM.  KILL_CONTAINER eventtype is continuosly sent to the containers that are not existing","I have only one NM running.
I have submitted a job and all the child processes on the NM got killed continuosly.This made the Job to hang indefinitely.

In the NM logs it is logging WARN message :org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl: Event EventType: KILL_CONTAINER sent to absent container container_1320301910500_0004_01_001359 "
MAPREDUCE-3338,Remove hardcoded version of mr-app jar from the tests,"MiniMRYarnCluster and its related tests, and TestDistributedShell depend on a hard-coded version of mr-app jar. We need to figure out if we can avoid this. Otherwise, for every release, we have to keep changing these files manually - a pain."
MAPREDUCE-3337,Missing license headers for some files,Missing apache license headers for some files
MAPREDUCE-3336,com.google.inject.internal.Preconditions not public api - shouldn't be using it,"com.google.inject.internal.Preconditions does not exist in guice 3.0 and from in guice 2.0 it was an internal api and shouldn't have been used.   We should use com.google.common.base.Preconditions instead.

This is currently being used in hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/main/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/monitor/ContainersMonitorImpl.java.

"
MAPREDUCE-3335,rat check seems to be broken,"The rat check seems broken, we don't get warned for files without license headers."
MAPREDUCE-3334,TaskRunner should log its activities,"TaskRunner has little to no information that it logs, making it impossible to debug when something goes wrong."
MAPREDUCE-3333,MR AM for sort-job going out of memory,"[~Karams] just found this. The usual sort job on a 350 node cluster hung due to OutOfMemory and eventually failed after an hour instead of the usual odd 20 minutes.
{code}
2011-11-02 11:40:36,438 ERROR [ContainerLauncher #258] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Container launch failed for container_1320233407485_0002
_01_001434 : java.lang.reflect.UndeclaredThrowableException
        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:88)
        at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:290)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
Caused by: com.google.protobuf.ServiceException: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: ""gsbl91281.blue.ygrid.yahoo.com/98.137.101.189""; destination host is: """"gsbl91525.blue.ygrid.yahoo.com"":45450; 
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
        at $Proxy20.startContainer(Unknown Source)
        at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:81)
        ... 4 more
Caused by: java.io.IOException: Failed on local exception: java.io.IOException: Couldn't set up IO streams; Host Details : local host is: ""gsbl91281.blue.ygrid.yahoo.com/98.137.101.189""; destination host is: """"gsbl91525.blue.ygrid.yahoo.com"":45450; 
        at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:655)
        at org.apache.hadoop.ipc.Client.call(Client.java:1089)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
        ... 6 more
Caused by: java.io.IOException: Couldn't set up IO streams
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:621)
        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:205)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1195)
        at org.apache.hadoop.ipc.Client.call(Client.java:1065)
        ... 7 more
Caused by: java.lang.OutOfMemoryError: unable to create new native thread
        at java.lang.Thread.start0(Native Method)
        at java.lang.Thread.start(Thread.java:597)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:614)
        ... 10 more
{code}"
MAPREDUCE-3332,contrib/raid compile breaks due to changes in hdfs/protocol/datatransfer/Sender#writeBlock related to checksum handling ,"    [javac] /Users/Hitesh/dev/hadoop-common/hadoop-mapreduce-project/src/contrib/raid/src/java/org/apache/hadoop/raid/BlockFixer.java:783: writeBlock(org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token<org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier>,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],org.apache.hadoop.hdfs.protocol.DatanodeInfo,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,int,long,long,long,org.apache.hadoop.util.DataChecksum) in org.apache.hadoop.hdfs.protocol.datatransfer.Sender cannot be applied to (org.apache.hadoop.hdfs.protocol.ExtendedBlock,org.apache.hadoop.security.token.Token<org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier>,java.lang.String,org.apache.hadoop.hdfs.protocol.DatanodeInfo[],<nulltype>,org.apache.hadoop.hdfs.protocol.datatransfer.BlockConstructionStage,int,long,long,long)
    [javac]         new Sender(out).writeBlock(block.getBlock(), block.getBlockToken(), """",
    [javac]                        ^
"
MAPREDUCE-3331,Improvement to single node cluster setup documentation for 0.23,"This JIRA is to track some minor corrections and suggestions for improvement for the documentation for the setup of a single node cluster using 0.23 currently available at http://people.apache.org/~acmurthy/hadoop-0.23/hadoop-yarn/hadoop-yarn-site/SingleCluster.html

"
MAPREDUCE-3329,capacity schedule maximum-capacity allowed to be less then capacity,"When configuring the capacity scheduler capacity and maximum-capacity, it allows the maximum-capacity to be less then the capacity.  I did not test to see what true limit is, I assume maximum capacity.

output from mapred queue -list where capacity = 10%, max capacity = 5%.

Queue Name : test2 
Queue State : running 
Scheduling Info : queueName: ""test2"", capacity: 0.1, maximumCapacity: 5.0, currentCapacity: 0.0, state: Q_RUNNING,  
"
MAPREDUCE-3328,mapred queue -list output inconsistent and missing child queues,"When running mapred queue -list on a 0.23.0 cluster with capacity scheduler configured with child queues.  In my case I have queues default, test1, and test2.  test1 has subqueues of a1, a2.  test2 has subqueues of a3 and a4.

- the child queues do not show up
- The output of maximum capacity doesn't match the format of the current capacity and capacity.  the latter two use float while the maximum is specified as int:

Queue Name : default 
Queue State : running 
Scheduling Info : queueName: ""default"", capacity: 0.7, maximumCapacity: 90.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================
Queue Name : test 
Queue State : running 
Scheduling Info : queueName: ""test"", capacity: 0.2, maximumCapacity: -1.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================
Queue Name : test2 
Queue State : running 
Scheduling Info : queueName: ""test2"", capacity: 0.1, maximumCapacity: 5.0, currentCapacity: 0.0, state: Q_RUNNING,  
======================


here default is configured to have capacity=70% and maximum capacity = 90%"
MAPREDUCE-3327,RM web ui scheduler link doesn't show correct max value for queues,"Configure a cluster to use the capacity scheduler and then specifying a maximum-capacity < 100% for a queue.  If you go to the RM Web UI and hover over the queue, it always shows the max at 100%."
MAPREDUCE-3326,RM web UI scheduler link not as useful as should be,"The resource manager web ui page for scheduler doesn't have all the information about the configuration like the jobtracker page used to have.  The things it seems to show you are the current queues - each queues used, set, and max percent and then what apps are running in that queue.  

It doesn't list any of yarn.scheduler.capacity.maximum-applications, yarn.scheduler.capacity.maximum-am-resource-percent, yarn.scheduler.capacity.<queue-path>.user-limit-factor, yarn.scheduler.capacity.<queue-path>.minimum-user-limit-percent, queue state, active users and percent used by user "
MAPREDUCE-3325,Improvements to CapacityScheduler doc,"I noticed the following issues with the capacity scheduler doc: ./hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-site/src/site/apt/CapacityScheduler.apt.vm

- In overview section, 3rd paragraph,  sentence ""There is an added benefit that an organization can access any excess capacity no being used by others"".  No should be not. 
- in overview section, 4th paragraph. dispropotionate misspelled 
- in features section, under multitenancy - monopolizing is misspelled. 
- in features section, under operability - it doesn't say if you can delete queues at runtime?  I see there is a note at the end but perhaps that can be added into the other sections to since its easy to miss that Note at the very end. 
- in features section - hierarchy and Hierarchical mispelled. 
- under configuration section the class to turn on to use capacity scheduler should be: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler 
- section on setting up queues, 4th sentence - hierarchy misspelled as heirarcy  and heirarchy. 
- I think specifying how a user has to specify the queue when running a job/app would be useful information.  Especially with the new hierarchical queues.  Does the user have to specify the entire path like a.b.c or can they just specify c. 
- under ""Running and Pending Application Limits"" section, property ""yarn.scheduler.capacity.maximum-applications"", they are referred to them as jobs, I believe that should be applications. 
- misspelled concurrently as concurently in same section of maximum-applications. 
- I think it should specify the defaults (if any) for the config vars.   Also what format are they specified in - int, float,etc? 
- might be nice to say it doesn't support preemption. 
- under admin options yarn.scheduler.capacity.<queue-path>.state - queues misspelled as queueus 
- under changing queue configuration it should have ""yarn"" in front of the ""rmadmin -refreshQueues"". Similarly a few lines down at ""$YARN_HOME/bin/rmadmin -refreshQueues"""
MAPREDUCE-3324,"Not All HttpServer tools links (stacks,logs,config,metrics) are accessible through all UI servers","Nodemanager has no tools listed under tools UI.
Jobhistory server has no logs tool listed under tools UI."
MAPREDUCE-3323,"Add new interface for Distributed Cache, which special  for Map or Reduce,but not Both.","We put some file into Distributed Cache, but sometimes, only Map or Reduce use thses cached files, not useful for both. but TaskTracker always download cached files from HDFS, if there are some little bit big files in cache, it's time expensive.

so, this patch add some new API in the DistributedCache.java as follow:

addArchiveToClassPathForMap
addArchiveToClassPathForReduce

addFileToClassPathForMap
addFileToClassPathForReduce

addCacheFileForMap
addCacheFileForReduce

addCacheArchiveForMap
addCacheArchiveForReduce


New API doesn't affect original interface. User can use these features like the following two methods:

1) 
hadoop job **** -files file1 -mapfiles file2 -reducefiles file3 -archives arc1 -maparchives arc2 -reduce archives arc3

2)
DistributedCache.addCacheFile(conf, file1);
DistributedCache.addCacheFileForMap(conf, file2);
DistributedCache.addCacheFileForReduce(conf, file3);

DistributedCache.addCacheArchives(conf, arc1);
DistributedCache.addCacheArchivesForMap(conf, arc2);
DistributedCache.addCacheFArchivesForReduce(conf, arc3);


These two methods have the same result, That's mean: 

You put six files to the distributed cache: file1 ~ file3, arc1 ~ arc3, 
but file1 and arc1 are cached for both map and reduce;
file2 and arc2 are only cached for map;
file3 and arc3 are only cached for reduce;
"
MAPREDUCE-3322,Create a better index.html for maven docs,Create a better index.html for maven docs.
MAPREDUCE-3321,Disable some failing legacy tests for MRv2 builds to go through,By-product of MR-3214. Disable tests for the short term until fixes are available for all tests.
MAPREDUCE-3320,Error conditions in web apps should stop pages from rendering.,"There are several places in the web apps where an error condition should short circuit the page from rendering, but it does not.  Ideally the web app framework should be extended to support exceptions similar to Jersey that can have an HTTP return code associated with them.  Then all of the places that produce custom error pages can just throw these exceptions instead. "
MAPREDUCE-3319,multifilewc from hadoop examples seems to be broken in 0.20.205.0,"{noformat}
/usr/lib/hadoop/bin/hadoop jar /usr/lib/hadoop/hadoop-examples-0.20.205.0.22.jar multifilewc  examples/text examples-output/multifilewc
11/10/31 16:50:26 INFO mapred.FileInputFormat: Total input paths to process : 2
11/10/31 16:50:26 INFO mapred.JobClient: Running job: job_201110311350_0220
11/10/31 16:50:27 INFO mapred.JobClient:  map 0% reduce 0%
11/10/31 16:50:42 INFO mapred.JobClient: Task Id : attempt_201110311350_0220_m_000000_0, Status : FAILED
java.lang.ClassCastException: org.apache.hadoop.io.IntWritable cannot be cast to org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.lib.LongSumReducer.reduce(LongSumReducer.java:44)
	at org.apache.hadoop.mapred.Task$OldCombinerRunner.combine(Task.java:1431)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1436)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1298)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:437)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:255)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.Child.main(Child.java:249)
{noformat}"
MAPREDUCE-3318,ant test TestSeveral timing out in commit builds,
MAPREDUCE-3317,Rumen TraceBuilder is emiting null as hostname,Trace generated by Rumen TraceBuilder contains null as hostname even though hostName and rackName are seen in history file. This is after MAPREDUCE-3035.
MAPREDUCE-3316,Rebooted link is not working properly,"While clicking on the *Rebooted Nodes* link, it is showing the following error message
             {color:red}Sorry, got error 500{color}"
MAPREDUCE-3313,TestResourceTrackerService failing in trunk some times,"TestResourceTrackerService is failing in trunk sometimes with the following error:

testDecommissionWithIncludeHosts(org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService)  Time elapsed: 0.876 sec  <<< ERROR!
java.lang.NullPointerException
  at org.apache.hadoop.yarn.server.resourcemanager.ClusterMetrics.getNumDecommisionedNMs(ClusterMetrics.java:78)
  at org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.testDecommissionWithIncludeHosts(TestResourceTrackerService.java:70)"
MAPREDUCE-3312,Make MR AM not send a stopContainer w/o corresponding start container,"This is a follow on to MAPREDUCE-3274.  It is possible, although rare, for the MR AM to send a stop container before it sends a start container.  This needs to stop that from happening.  If a stop is found first it should prevent the start from being sent.  It tries to do this, but only if the stop is currently pending."
MAPREDUCE-3311,Bump jetty to 6.1.26,MapReduce part of HADOOP-7450
MAPREDUCE-3310,Custom grouping comparator cannot be set for Combiners,"Combiners are often described as 'Reducers running on the Map side'.

As Reducers, Combiners are fed <K,{V}>, where {V} is built by grouping values associated with the 'same' key.

For Reducers, the comparator used for grouping values can be set independently of that used to sort the keys (using Job.setGroupingComparatorClass).

Such a configuration is not possible for Combiners, meaning some things done in Reducers cannot be done in Combiners (such as secondary sort).

It would be handy to have a Job.setCombinerGroupingComparatorClass method that would allow the setting of the grouping comparator used when applying a Combiner.
"
MAPREDUCE-3309,Report the AM of an application in the UI,"Make provision to report the AM hostname of an application in the RM/JHS UI. 
It is difficult to trace back the AM on which an app ran when there are 100+ jobs in history. Digging through the logs is an option but since there is no consistency maintained in naming of apps in UI/logs/local dirs (MAPREDUCE-2793), debugging is all the more harder. "
MAPREDUCE-3308,MR builds failing due to download failure,"MR builds are failing due to unresolved dependencies.

[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: WARNINGS
[ivy:resolve] 		[FAILED     ] org.apache.commons#commons-daemon;1.0.3!commons-daemon.jar:  (0ms)
[ivy:resolve] 	==== fs: tried
[ivy:resolve] 	  /home/jenkins/.m2/repository/org/apache/commons/commons-daemon/1.0.3/commons-daemon-1.0.3.jar
[ivy:resolve] 	==== apache-snapshot: tried
[ivy:resolve] 	  https://repository.apache.org/content/repositories/snapshots/org/apache/commons/commons-daemon/1.0.3/commons-daemon-1.0.3.jar
[ivy:resolve] 	==== maven2: tried
[ivy:resolve] 	  http://repo1.maven.org/maven2/org/apache/commons/commons-daemon/1.0.3/commons-daemon-1.0.3.jar
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		::              FAILED DOWNLOADS            ::
[ivy:resolve] 		:: ^ see resolution messages for details  ^ ::
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 		:: org.apache.commons#commons-daemon;1.0.3!commons-daemon.jar
[ivy:resolve] 		::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
"
MAPREDUCE-3307,Improve logging on the console during job execution,There is a lot of redundant information being printed on the console and a not so intuitive flow of events. We should improve the logging on console during job execution. More details in the next comment.
MAPREDUCE-3306,Cannot run apps after MAPREDUCE-2989,"Seeing this in NM logs when trying to run jobs.
{code}
2011-10-28 21:40:21,263 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application: Processing application_1319818154209_0001 of type APPLICATION_INITED
2011-10-28 21:40:21,264 FATAL org.apache.hadoop.yarn.event.AsyncDispatcher: Error in dispatcher thread. Exiting..
java.util.NoSuchElementException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:796)
        at java.util.HashMap$ValueIterator.next(HashMap.java:822)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:251)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl$AppInitDoneTransition.transition(ApplicationImpl.java:245)
        at org.apache.hadoop.yarn.state.StateMachineFactory$SingleInternalArc.doTransition(StateMachineFactory.java:357)
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:298)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:43)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:443)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:385)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationImpl.handle(ApplicationImpl.java:58)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:407)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher.handle(ContainerManagerImpl.java:399)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:116)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:662)
{code}"
MAPREDUCE-3304,TestRMContainerAllocator#testBlackListedNodes fails intermittently,"Thanks to Hitesh for verifying!

bq. The heartbeat event should be drained before the schedule call.
bq. -- Hitesh

I can see this test fail intermittently on my Mac OSX 10.5 and Fedora 14 machines. "
MAPREDUCE-3303,MR part of removing RecordIO (HADOOP-7781),"This is the MR part of removing deprecated RecordIO packages - parented by HADOOP-7781.

Basically, we need to remove {{/hadoop-mapreduce-project/src/c++/librecordio}} and all associated build helpers around it.

(For posterity, RecordIO has been replaced by Apache Avro http://avro.apache.org)"
MAPREDUCE-3302,Remove the last dependency call from org.apache.hadoop.record package in MR.,"SecureShuffleUtils provides the following helper:

{code}
  /**
   * verify that hash equals to HMacHash(msg)
   * @param newHash
   * @return true if is the same
   */
  private static boolean verifyHash(byte[] hash, byte[] msg, SecretKey key) {
    byte[] msg_hash = generateByteHash(msg, key);
    return Utils.compareBytes(msg_hash, 0, msg_hash.length, hash, 0, hash.length) == 0;
  }
{code}

The {{Utils}} class used there is {{org.apache.hadoop.record.Utils}}. With the {{record}} common package going away via HADOOP-7781, the internal (and also deprecated on the whole) {{compareBytes}} utility must be moved elsewhere.

The {{Utils#compareBytes}} contains:

{code}
/** Lexicographic order of binary data. */
  public static int compareBytes(byte[] b1, int s1, int l1,
                                 byte[] b2, int s2, int l2) {
    return WritableComparator.compareBytes(b1, s1, l1, b2, s2, l2);
  }
{code}

Which looks like it can be replaced inline, as it appears to be a dummy wrapper call. I'll put up a patch with this inline replacement shortly for review."
MAPREDUCE-3299,Add AMInfo table to the AM job page,JobHistory has a table to list all AMs. A similar table can be added to the AM for info on past failed AMs and the current running one.
MAPREDUCE-3297,Move Log Related components from yarn-server-nodemanager to yarn-common,or to a separate module.
MAPREDUCE-3296,Pending(9) findBugs warnings,
MAPREDUCE-3295,TestAMAuthorization failing on branch 0.23.,The test seems to fail both on Mac and linux. Trace in the next comment.
MAPREDUCE-3294,Log the reason for killing a task during speculative execution,"The reason for killing a speculated task has to be logged. Currently, a speculated task is killed with a note of ""Container killed by the ApplicationMaster. Container killed on request. Exit code is 137"" which is not very useful. Better logging of this message stating the task was killed due to completion of its speculative task would be useful.

Also, this message is lost once the app is moved to history. All we are left with is a list of killed tasks without a reason being notified to the user."
MAPREDUCE-3293,Reason for application failure is not correctly reported,"When apps fail, the reason for failure is not correctly reflected in the UI. For one such app failure, the UI reports ""Application <appID> failed 1 times due to . Failing the application."" which is not very helpful."
MAPREDUCE-3292,In secure mode job submission fails with Provider org.apache.hadoop.mapreduce.security.token.JobTokenIndentifier$Renewer not found.,"This happens when you submit a job to a secure cluster. Also, its only the first time the error shows up. On the next submission of the job, the job passes."
MAPREDUCE-3291,App fail to launch due to delegation token not found in cache,"In secure mode, saw an app failure due to ""org.apache.hadoop.security.token.SecretManager$InvalidToken: token (HDFS_DELEGATION_TOKEN token <id> for <user>) can't be found in cache"" Exception in the next comment."
MAPREDUCE-3290,list-active-trackers throws NPE,"bin/mapred -list-active-trackers throws NPE in mrV2. Trace in the next comment.

"
MAPREDUCE-3289,Make use of fadvise in the NM's shuffle handler,"Using the new NativeIO fadvise functions, we can make the NodeManager prefetch map output before it's send over the socket, and drop it out of the fs cache once it's been sent (since it's very rare for an output to have to be re-sent). This improves IO efficiency and reduces cache pollution."
MAPREDUCE-3288,Mapreduce 23 builds failing,Hadoop mapreduce 0.23 builds are failing.
MAPREDUCE-3286,Unit tests for MAPREDUCE-3186 - User jobs are getting hanged if the Resource manager process goes down and comes up while job is getting executed.,"If the resource manager is restarted while the job execution is in progress, the job is getting hanged.
UI shows the job as running.
In the RM log, it is throwing an error ""ERROR org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AppAttemptId doesnt exist in cache appattempt_1318579738195_0004_000001""
In the console MRAppMaster and Runjar processes are not getting killed"
MAPREDUCE-3285,Tests on branch-0.23 failing ,"Most are failing with some kerberos login exception:

Running org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks
Tests run: 3, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.548 sec <<< FAILURE!
--
Running org.apache.hadoop.yarn.server.resourcemanager.TestAppManager
Tests run: 8, Failures: 0, Errors: 6, Skipped: 0, Time elapsed: 0.125 sec <<< FAILURE!
Running org.apache.hadoop.yarn.server.resourcemanager.TestRMAuditLogger
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.065 sec <<< FAILURE!
--
Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationCleanup
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.033 sec <<< FAILURE!
--
Running org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.024 sec <<< FAILURE!
--
Running org.apache.hadoop.yarn.server.resourcemanager.TestRM
Tests run: 3, Failures: 0, Errors: 3, Skipped: 0, Time elapsed: 0.072 sec <<< FAILURE!
Running org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 90.167 sec <<< FAILURE!
Running org.apache.hadoop.yarn.server.resourcemanager.TestFifoScheduler
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.056 sec <<< FAILURE!

TestLinuxContainerExecutorWithMocks is tracked via MAPREDUCE-3281"
MAPREDUCE-3284,bin/mapred queue fails with JobQueueClient ClassNotFoundException,"bin/mapred queue fails with the following exception:

{code}

-bash$ bin/mapred queue
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/mapred/JobQueueClient
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.JobQueueClient
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.hadoop.mapred.JobQueueClient.  Program will exit.

{code}"
MAPREDUCE-3283,mapred classpath CLI does not display the complete classpath,"bin/yarn classpath does not display the complete classpath. Below is how the classpath looks like:
{noformat}
$HADOOP_CONF_DIR:$HADOOP_CONF_DIR::$TOOLS_JAR:$HADOOP_COMMON_HOME/*:$HADOOP_COMMON_HOME/lib/*:$HADOOP_HDFS_HOME/*:$HADOOP_HDFS_HOME/lib/*:
$HADOOP_MAPRED_HOME/bin/../modules/*:$HADOOP_MAPRED_HOME/bin/../lib/*
{noformat}

""*"" has to be substituted with the actual jars. Also, $HADOOP_CONF_DIR appears twice in the classpath"
MAPREDUCE-3282,bin/mapred job -list throws exception,"bin/mapred job -list throws exception when mapreduce.framework.name is set to ""yarn""
"
MAPREDUCE-3281,TestLinuxContainerExecutorWithMocks failing on trunk.,
MAPREDUCE-3280,MR AM should not read the username from configuration,"MR AM reads the value for mapreduce.job.user.name from the configuration in several places. It should instead get the app-submitter name from the RM.

Once that is done, we can remove the default value for mapreduce.job.user.name from mapred-default.xml"
MAPREDUCE-3279,TestJobHistoryParsing broken,"Broken after 3264, the test was verifying against the default user."
MAPREDUCE-3278,0.20: avoid a busy-loop in ReduceTask scheduling,"Looking at profiling results, it became clear that the ReduceTask has the following busy-loop which was causing it to suck up 100% of CPU in the fetch phase in some configurations:
- the number of reduce fetcher threads is configured to more than the number of hosts
- therefore ""busyEnough()"" never returns true
- the ""scheduling"" portion of the code can't schedule any new fetches, since all of the pending fetches in the mapLocations buffer correspond to hosts that are already being fetched (the hosts are in the {{uniqueHosts}} map)
- {{getCopyResult()}} immediately returns null, since there are no completed maps.
Hence ReduceTask spins back and forth between trying to schedule things (and failing), and trying to grab completed results (of which there are none), with no waits."
MAPREDUCE-3277,TestSeveral is failing in 0.23,"Haven't looked into it yet, but TestSeveral has been failing in the 0.23 MR build since 10/24"
MAPREDUCE-3276,hadoop dfs -copyToLocal/copyFromLocal called within Hadoop Streaming returns early,"I'm using the Cloudera hadoop realease 0.20.2.+737 to parallelize bash scripts with Hadoop Streaming.

Below is an example script that i've been running which simply copies a file from hdfs to a local node.
{code:title=SampleMapper.sh|borderStyle=solid}
 hadoop dfs -copyToLocal /path/to/some/large/file/myFile myFile
 # Spin until the file is fully copied.
 while [ ! -f myFile ]
 do 
  echo ""spin""
  sleep 1 
 done
{code}

Surprisingly, the copy call returns before the file is copied, if the file is sufficiently large, and the while loop spins for several iterations.  I'm seeing similar behavior with copyFromLocal.

I've asked about this issue on other forms and no one else seems to have had the problem, although I don't know how many peoplpe are attempting to do this particular task.

Has this been fixed in more recent versions of hadoop?"
MAPREDUCE-3275,Add docs for WebAppProxy,In my haste to get the WebAppProxy code in the documentation for it was neglected.  This is to fix that.  Docs need to be added to ClusterSetup.html about how to configure and use the WebAppProxy.
MAPREDUCE-3274,Race condition in MR App Master Preemtion can cause a dead lock,There appears to be a race condition in the MR App Master in relation to preempting reducers to let a mapper run.  In the particular case that I have been debugging a reducer was selected for preemption that did not have a container assigned to it yet. When the container became available that reduce started running and the previous TA_KILL event appears to have been ignored.
MAPREDUCE-3272,Lost NMs fail to rejoin,"Lost nodemanagers fail to join back. 

When the NM is lost, RM log reads
{noformat}
INFO org.apache.hadoop.yarn.util.AbstractLivelinessMonitor: Expired:<host:port> Timed out after 600 secs
INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Processing <host:port> of type EXPIRE
INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: Removed Node <host:port>
INFO org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl: <host:port> Node Transitioned from RUNNING to LOST
{noformat}
When the NM joins back, RM log reads
{noformat}
INFO org.apache.hadoop.yarn.server.resourcemanager.ResourceTrackerService: Node not found rebooting <host:port>
{noformat}"
MAPREDUCE-3271,Lost nodes list and count not updated,"When nodemanagers are lost, the ""Lost Nodes"" list and the count is not incremented. Either we,

1. Fix the lost nodes list when a nodemanager is lost - The problem with tracking lost nodes is, if the nodemanager joins back, there would be duplicate entries in active and lost nodes with different port numbers.
2. Do not track lost nodemanagers"
MAPREDUCE-3270,Decommissioned node not removed from active NM list,"A decommissioned node is not being removed from the ""Total nodes"" list and is not added to the ""Decommissioned nodes"" list. 
The list of nodes to decommission is added in a file defined by ""yarn.resourcemanager.nodes.exclude-path"" and excluded via refreshNodes CLI.

"
MAPREDUCE-3269,Jobsummary logs not being moved to a separate file,"The jobsummary logs are not being moved to a separate file. Below is the configuration in log4j.properties:

{noformat}
mapred.jobsummary.logger=INFO,console
log4j.logger.org.apache.hadoop.mapreduce.jobhistory.JobSummary=${mapred.jobsummary.logger}
log4j.additivity.org.apache.hadoop.mapreduce.jobhistory.JobSummary=false
log4j.appender.JSA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.JSA.File=${hadoop.log.dir}/mapred-jobsummary.log
log4j.appender.JSA.layout=org.apache.log4j.PatternLayout
log4j.appender.JSA.layout.ConversionPattern=%d{ISO8601} %p %c{2}: %m%n
log4j.appender.JSA.DatePattern=.yyyy-MM-dd
{noformat}"
MAPREDUCE-3267,MR2 reduce tasks showing >100% complete,"My job is currently showing >100% reduce completion. Some reduce tasks are much higher than 100% complete. they appear to be in the ""last merge pass"" stage"
MAPREDUCE-3266,"NM resource allocation should be in MB, not GB","Currently, the resource allocation for tasks on the NM is expressed in GB. This is inconsistent with the per-task resources which are in units of MBs. We should use MB throughout for better consistency."
MAPREDUCE-3265,"Reduce log level on MR2 IPC construction, etc","Currently MR's IPC logging is very verbose. For example, I see a lot of:

11/10/25 12:14:06 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/10/25 12:14:06 INFO mapred.ResourceMgrDelegate: Connecting to ResourceManager at c0309.hal.cloudera.com/172.29.81.91:40012
11/10/25 12:14:06 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol
11/10/25 12:14:07 INFO mapred.ResourceMgrDelegate: Connected to ResourceManager at c0309.hal.cloudera.com/172.29.81.91:40012
11/10/25 12:14:08 INFO mapred.ClientCache: Connecting to HistoryServer at: c0309.hal.cloudera.com:10020
11/10/25 12:14:08 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/10/25 12:14:08 INFO mapred.ClientCache: Connected to HistoryServer at: c0309.hal.cloudera.com:10020
11/10/25 12:14:08 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol
... when submitting a job. This should be DEBUG level."
MAPREDUCE-3264,mapreduce.job.user.name needs to be set automatically,"Currently in MR2 I have to manually specify mapreduce.job.user.name for each job. It's not picking it up from the security infrastructure, at least when running with DefaultContainerExecutor. This is obviously incorrect."
MAPREDUCE-3263,compile-mapred-test target fails,"Compile mapred test target is broken due to which the builds are not archiving the test jars.

"
MAPREDUCE-3262,A few events are not handled by the NodeManager in failure scenarios,"Need to handle kill container event in localization failed state. 
Need to handle resource localized in localization failed state. "
MAPREDUCE-3261,AM unable to release containers,"I'm probably doing something wrong here, but I can't figure it out.

My ApplicationMaster is sending an AllocateRequest with ContainerIds to release. My ResourceManager logs say:

2011-10-25 10:02:52,236 WARN  resourcemanager.RMAuditLogger (RMAuditLogger.java:logFailure(207)) - USER=criccomi	IP=127.0.0.1	OPERATION=AM Released Container	TARGET=FifoScheduler	RESULT=FAILURE	DESCRIPTION=Trying to release container not owned by app or with invalid id	PERMISSIONS=Unauthorized access or invalid container	APPID=application_1319485153554_0028	CONTAINERID=container_1319485153554_0028_01_000003

The container ID is valid, as is the app id:

[criccomi@criccomi-ld logs]$ pwd
/tmp/logs
[criccomi@criccomi-ld logs]$ find .
.
./application_1319485153554_0028
./application_1319485153554_0028/container_1319485153554_0028_01_000002
./application_1319485153554_0028/container_1319485153554_0028_01_000002/stderr
./application_1319485153554_0028/container_1319485153554_0028_01_000002/stdout
./application_1319485153554_0028/container_1319485153554_0028_01_000001
./application_1319485153554_0028/container_1319485153554_0028_01_000001/stderr
./application_1319485153554_0028/container_1319485153554_0028_01_000001/stdout
./application_1319485153554_0028/container_1319485153554_0028_01_000003
./application_1319485153554_0028/container_1319485153554_0028_01_000003/stderr
./application_1319485153554_0028/container_1319485153554_0028_01_000003/stdout
./application_1319485153554_0028/container_1319485153554_0028_01_000006
./application_1319485153554_0028/container_1319485153554_0028_01_000006/stderr
./application_1319485153554_0028/container_1319485153554_0028_01_000006/stdout

The containers are still running.

My code to start a container, and then to release it:
{code}
  // ugi = UserGroupInformation.getCurrentUser
  // security is not enabled
  def startContainer(packagePath: Path, container: Container, ugi: UserGroupInformation, env: Map[String, String], cmds: String*) {
    info(""%s starting container %s %s %s %s %s"" format (appAttemptId, packagePath, container, ugi, env, cmds))
    // connect to container manager (based on similar code in the ContainerLauncher in Hadoop MapReduce)
    val contToken = container.getContainerToken
    val address = container.getNodeId.getHost + "":"" + container.getNodeId.getPort
    var user = ugi

    if (UserGroupInformation.isSecurityEnabled) {
      debug(""%s security is enabled"" format (appAttemptId))
      val hadoopToken = new Token[ContainerTokenIdentifier](contToken.getIdentifier.array, contToken.getPassword.array, new Text(contToken.getKind), new Text(contToken.getService))
      user = UserGroupInformation.createRemoteUser(address)
      user.addToken(hadoopToken)
      info(""%s changed user to %s"" format (appAttemptId, user))
    }

    val containerManager = user.doAs(new PrivilegedAction[ContainerManager] {
      def run(): ContainerManager = {
        return YarnRPC.create(conf).getProxy(classOf[ContainerManager], NetUtils.createSocketAddr(address), conf).asInstanceOf[ContainerManager]
      }
    })

    // set the local package so that the containers and app master are provisioned with it
    val packageResource = Records.newRecord(classOf[LocalResource])
    val packageUrl = ConverterUtils.getYarnUrlFromPath(packagePath)
    val fileStatus = packagePath.getFileSystem(conf).getFileStatus(packagePath)

    packageResource.setResource(packageUrl)
    packageResource.setSize(fileStatus.getLen)
    packageResource.setTimestamp(fileStatus.getModificationTime)
    packageResource.setType(LocalResourceType.ARCHIVE)
    packageResource.setVisibility(LocalResourceVisibility.APPLICATION)

    // start the container
    val ctx = Records.newRecord(classOf[ContainerLaunchContext])
    ctx.setEnvironment(env)
    ctx.setContainerId(container.getId())
    ctx.setResource(container.getResource())
    ctx.setUser(user.getShortUserName())
    ctx.setCommands(cmds.toList)
    ctx.setLocalResources(Collections.singletonMap(""package"", packageResource))

    debug(""%s setting package to %s"" format (appAttemptId, packageResource))
    debug(""%s setting context to %s"" format (appAttemptId, ctx))

    val startContainerRequest = Records.newRecord(classOf[StartContainerRequest])
    startContainerRequest.setContainerLaunchContext(ctx)
    containerManager.startContainer(startContainerRequest)
  }
{code}
-----
{code}
  def sendResourceRequest(requests: List[ResourceRequest], release: List[ContainerId]): AMResponse = {
    info(""%s sending resource request %s %s"" format (appAttemptId, requests, release))
    val req = Records.newRecord(classOf[AllocateRequest])
    req.setResponseId(requestId)
    req.setApplicationAttemptId(appAttemptId)
    req.addAllAsks(requests)
    req.addAllReleases(release)
    requestId += 1
    debug(""%s RM resource request %s"" format (appAttemptId, req))
    resourceManager.allocate(req).getAMResponse
  }
{code}

I have double checked that my ContainerIds are accurate, and they are.

Any idea what I'm doing wrong here?"
MAPREDUCE-3260,Yarn app stuck in KILL_WAIT state,"Last night I killed an MR2 app using ""hadoop job -kill"". This morning I noticed it's still running, but in ""KILL_WAIT"" state with no tasks running."
MAPREDUCE-3259,ContainerLocalizer should get the proper java.library.path from LinuxContainerExecutor,"As seen in MAPREDUCE-2915, java.library.path is not being passed when the LCE spawns a JVM for ContainerLocalizer. 

However, unlike branch-0.20-security, the task runtime in 0.23 is unaffected by this. This is because tasks' run-time environment is specified in the launch script by client. Setting LD_LIBRARY_PATH is the primary way of specifying the locations of required native library in this case. The config property, mapreduce.admin.user.env is always set in the job environment and the default value is to add the path to the hadoop native library to LD_LABRARY_PATH.

For JVM's being launched by the hadoop system scripts, java.library.path is set."
MAPREDUCE-3258,Job counters missing from AM and history UI,
MAPREDUCE-3257,Authorization checks needed for AM->RM protocol,"This is like MAPREDUCE-3256, but for AM->RM protocol."
MAPREDUCE-3256,Authorization checks needed for AM->NM protocol,"We already authenticate requests to NM from any AM. We also need to authorize the requests, otherwise a rogue AM, *but with proper tokens and thus authenticated to talk to NM*, could either launch or kill a container with different ContainerID. We have two options:
 - Remove the explicit passing of the ContainerId as part of the API and instead get it from the RPC layer. In this case, we will need a ContainerToken for each container.
 - Do explicit authorization checks without relying on getting ContainerID from the RPC.

One ContainerToken per container is a serious restriction. We anyways want to be able to use application-ACLS to, say, stop containers owned by others. So I am going to take the later route of explicit checks."
MAPREDUCE-3254,Streaming jobs failing with PipeMapRunner ClassNotFoundException,"ClassNotFoundException: org.apache.hadoop.streaming.PipeMapRunner encountered while running streaming jobs. Stack trace in the next comment.
"
MAPREDUCE-3253,ContextFactory throw NoSuchFieldException,"I see exceptions from ContextFactory when I am running Pig unit test:
Caused by: java.lang.IllegalArgumentException: Can't find field
        at org.apache.hadoop.mapreduce.ContextFactory.<clinit>(ContextFactory.java:139)
Caused by: java.lang.NoSuchFieldException: reporter
        at java.lang.Class.getDeclaredField(Class.java:1882)
        at org.apache.hadoop.mapreduce.ContextFactory.<clinit>(ContextFactory.java:126)"
MAPREDUCE-3252,MR2: Map tasks rewrite data once even if output fits in sort buffer,"I found that, even if the output of a map task fits entirely in its sort buffer, it was rewriting the output entirely rather than just renaming the first spill into place. This is due to RawLocalFileSystem.rename() falling back to a copy if renameTo() fails. The first rename attempt was failing because no one has called mkdir for the output directory yet."
MAPREDUCE-3251,Network ACLs can prevent some clients to talk to MR ApplicationMaster,"In 0.20.xxx, the JobClient while polling goes to JT to get the job status. With YARN, AM can be launched on any port and the client will have to have ACL open to that port to talk to AM and get the job status. When the client is within the same grid network access to AM is not a problem. But some applications may have one installation per set of clusters and may launch jobs even across such sets (on job trackers in another set of clusters). For that to work only the JT port needs to be open currently. In case of YARN, all ports will have to be opened up for things to work. That would be a security no-no.

There are two possible solutions:
  1) Make the job client only talk to RM (as an option) to get the job status. 
  2) Limit the range of ports AM can listen on.

Option 2) may not be favorable as there is no direct OS API to find a free port.
"
MAPREDUCE-3250,"When AM restarts, client keeps reconnecting to the new AM and prints a lots of logs.",
MAPREDUCE-3249,Recovery of MR AMs with reduces fails the subsequent generation of the job,
MAPREDUCE-3248,Log4j logs from unit tests are lost,"Can't find log4j logs in tests, all of them complain:

{noformat}
log4j:WARN No appenders could be found for logger (org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer).
log4j:WARN Please initialize the log4j system properly.
{noformat}

I suspect MAPREDUCE-3199."
MAPREDUCE-3243,Invalid tracking URL for streaming jobs,"The tracking URL for streaming jobs currently display ""http://N/A""

{noformat}
INFO streaming.StreamJob: To kill this job, run:
INFO streaming.StreamJob: hadoop job -kill <jobID>
INFO streaming.StreamJob: Tracking URL: http://N/A
INFO mapreduce.Job: Running job: <jobID>
INFO mapreduce.Job:  map 0% reduce 0%
INFO mapred.ClientServiceDelegate: Tracking Url of JOB is <host:port>

{noformat}
"
MAPREDUCE-3242,Trunk compilation broken with bad interaction from MAPREDUCE-3070 and MAPREDUCE-3239.,Looks like patch command threw away some of the changes when I committed MAPREDUCE-3239 after MAPREDUCE-3070.
MAPREDUCE-3241,(Rumen)TraceBuilder throws IllegalArgumentException,"When we run the TraceBuilder, we get this exception. Output of the TraceBuilder doesn't contain the map and reduce task information.

{code}
2011-10-21 22:07:17,268 WARN  rumen.TraceBuilder (TraceBuilder.java:run(272)) - TraceBuilder got an error while processing the [possibly virtual] file job_1319214405771_0002-1319214846458-root-word+count-1319214871038-1-1-SUCCEEDED.jhist within Path hdfs://10.18.52.57:9000/user/root/null/history/done_intermediate/root/job_1319214405771_0002-1319214846458-root-word+count-1319214871038-1-1-SUCCEEDED.jhist
java.lang.IllegalArgumentException: JobBuilder.process(HistoryEvent): unknown event type
        at org.apache.hadoop.tools.rumen.JobBuilder.process(JobBuilder.java:165)
        at org.apache.hadoop.tools.rumen.TraceBuilder.processJobHistory(TraceBuilder.java:304)
        at org.apache.hadoop.tools.rumen.TraceBuilder.run(TraceBuilder.java:258)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.tools.rumen.TraceBuilder.main(TraceBuilder.java:185)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)

{code}"
MAPREDUCE-3240,NM should send a SIGKILL for completed containers also,"This is to address the containers which exit properly after spawning sub-processes themselves. We don't want to leave these sub-process-tree or else they can pillage the NM's resources.

Today, we already have code to send SIGKILL to the whole process-trees (because of single sessionId resulting from  setsid) when the container is alive. We need to obtain the PID of the containers when they start and use that PID to send signal for completed containers' case also."
MAPREDUCE-3239,Use new createSocketAddr API in MRv2 to give better error messages on misconfig,"HADOOP-7749 added a NetUtils call which will include the configuration name as part of the exception message. This is handy if you accidentally specify some invalid string, or forget to specify a required parameter. This JIRA is to make MR2 use the new API."
MAPREDUCE-3238,Small cleanup in SchedulerApp,"While reading this code, I did a little bit of cleanup:
- added some javadoc
- rather than using a Map<Priority, Integer> for keeping counts, switched to Guava's HashMultiset, which makes a simpler API."
MAPREDUCE-3237,Move LocalJobRunner to hadoop-mapreduce-client-core module,"LocalJobRunner works independently of MR1 (jobtracker and tasktrackers) and MR2 (YARN). The MR1 directory is being kept around only to support unit tests, so LocalJobRunner should be moved out to somewhere more permanent."
MAPREDUCE-3236,Distcp with hdfs:// passed with error in JT log while copying from .20.204  to .20.205 ( with useIp=false),"I tried to copy file from .20.204 to .20.205 by distcp over hdfs:// while using hadoop.security.token.service.use_ip=false in core-site.xml. The copy was successful but found error "" org.apache.hadoop.mapreduce.security.token.DelegationTokenRenewal:"" exception in .20.205 JT.


"
MAPREDUCE-3234,Locality scheduling broken due to mismatch between IPs and hosts,"I noticed that, on a single-rack cluster, I wasn't getting hardly any data locality. The issue appears to be the code in RMContainerAllocator which changes the resource requests to use IP addresses instead of hostnames:
{code}
           //host comes from data splitLocations which are hostnames. Containers
           // use IP addresses.
           //TODO Temporary fix for locality. Use resolvers from h-common. 
           // Cache to make this more efficient ?
{code}
However, at least on my cluster, the resource manager sees node resources as hostnames, not IPs. Removing this code fixed data locality."
MAPREDUCE-3233,AM fails to restart when first AM is killed,"Set yarn.resourcemanager.am.max-retries=5 in yarn-site.xml. Started yarn cluster.
Sumbitted Sleep Job of 100K maps tasks as following -:
$HADOOP_COMMON_HOME/bin/hadoop jar $HADOOP_MAPRED_HOME/hadoop-test.jar sleep -m 100000 -r 0 -mt 1000 -rt 1000

when around 53K tasks go, login node running AppMaster, and killed AppMaster with kill -9

Resource Manager tried restart AM uptio max-retris but failed with following -:
{code}
11/10/19 15:29:09 INFO mapreduce.Job: Job job_1319036155027_0002 failed with state FAILED due to: Application
application_1319036155027_0002 failed 5 times due to AM Container for appattempt_1319036155027_0002_000005 exited with 
exitCode: -1000 due to: RemoteTrace: 
java.io.IOException: Resource
hdfs://<NN>:<PORT>/user/<JOBUSER>/.staging/job_1319036155027_0002/appTokens changed on src
filesystem (expected 1319037705427, was 1319037714496
            at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload.copy(FSDownload.java:80)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload.access$000(FSDownload.java:49)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload$1.run(FSDownload.java:149)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload$1.run(FSDownload.java:147)
            at java.security.AccessController.doPrivileged(Native Method)
            at javax.security.auth.Subject.doAs(Subject.java:396)
            at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload.call(FSDownload.java:145)
            at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.FSDownload.call(FSDownload.java:49)
            at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
            at java.util.concurrent.FutureTask.run(FutureTask.java:138)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
 at LocalTrace: 
            org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Resource
hdfs://<NN>:<PORT>/user/<JOBUSER>/.staging/job_1319036155027_0002/appTokens changed on src
filesystem (expected 1319037705427, was 1319037714496
            at
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.convertFromProtoFormat(LocalResourceStatusPBImpl.java:217)
            at
org.apache.hadoop.yarn.server.nodemanager.api.protocolrecords.impl.pb.LocalResourceStatusPBImpl.getException(LocalResourceStatusPBImpl.java:147)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.update(ResourceLocalizationService.java:798)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker.processHeartbeat(ResourceLocalizationService.java:483)
            at
org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.heartbeat(ResourceLocalizationService.java:228)
            at
org.apache.hadoop.yarn.server.nodemanager.api.impl.pb.service.LocalizationProtocolPBServiceImpl.heartbeat(LocalizationProtocolPBServiceImpl.java:46)
            at
org.apache.hadoop.yarn.proto.LocalizationProtocol$LocalizationProtocolService$2.callBlockingMethod(LocalizationProtocol.java:57)
            at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:343)
            at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1486)
            at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1482)
            at java.security.AccessController.doPrivileged(Native Method)
            at javax.security.auth.Subject.doAs(Subject.java:396)
            at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
            at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1480)

.Failing this attempt.. Failing the application.
11/10/19 15:29:09 INFO mapreduce.Job: Counters: 0
{code}
"
MAPREDUCE-3232,AM should  handle reboot from Resource Manager,"When the RM doesn't have last response id for app attempt(or the request response id is less than the last response id), RM sends reboot response but AM doesn't handle this."
MAPREDUCE-3230,No information about Data Local maps from Job client CLI and in JobHistory ,"Size of cluster is 350 NMs. I have topology.node.switch.mapping.impl set to enable rack-locality. Ran randomwriter/sort and scan jobs. Both jobs ran completed successfully.

On Job client sort job says :
{code}
Launched map tasks=16800
Launched reduce tasks=700
Other local map tasks=10
Rack-local map tasks=16790
{code}

JobHistory files also don't have information about Data Local Maps.

There used to be information about data local maps before, till about a month back, like so:

For sort with 349 NMs :
{code}
Launched map tasks=16754 
Launched reduce tasks=700
Other local map tasks=48
Data-local map tasks=16459
Rack-local map tasks=248
{code}"
MAPREDUCE-3228,MR AM hangs when one node goes bad,"Found this on one of the gridmix runs, again. One of the nodes went real bad, the job had three containers running on the node. Eventually, AM marked the tasks as timedout and initiated cleanup of the failed containers via {{stopContainer()}}. The later got stuck at the faulty node, the tasks are stuck in FAIL_CONTAINER_CLEANUP stage and the job lies in there waiting for ever.

Thanks to [~Karams] for helping with this."
MAPREDUCE-3226,Few reduce tasks hanging in a gridmix-run,"In a gridmix run with ~1000 jobs, one job is getting stuck because of 2-3 hanging reducers. All of the them are stuck after downloading all map outputs and have the following thread dump.

{code}
""EventFetcher for fetching Map Completion Events"" daemon prio=10 tid=0xa325fc00 nid=0x1ca4 waiting on condition [0xa315c000]
   java.lang.Thread.State: TIMED_WAITING (sleeping)
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.mapreduce.task.reduce.EventFetcher.run(EventFetcher.java:71)

""main"" prio=10 tid=0x080ed400 nid=0x1c71 in Object.wait() [0xf73a2000]
   java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        - waiting on <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)
        at java.lang.Thread.join(Thread.java:1143)
        - locked <0xa94b23d8> (a org.apache.hadoop.mapreduce.task.reduce.EventFetcher)
        at java.lang.Thread.join(Thread.java:1196)
        at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:135)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:367)
        at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:147)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:142)
{code}

Thanks to [~karams] for helping track this down."
MAPREDUCE-3225,Killing an unkown job throws NPE.,"On a job -kill of an unkown job, the code currently throws a NPE. Stack trace on the next comment."
MAPREDUCE-3223,Remove MR1 configs from mapred-default.xml,"All of the MRv1 configs are still in mapred-default.xml. This is confusing when trying to make config changes. Since a lot of the input/output format tests still depend on MR1, I'd like to move these to src/test/mapred-site.xml for now, and once that dependency is broken, we can remove them entirely."
MAPREDUCE-3222,ant test TestTaskContext failing on trunk,"Testcase: testContextStatus took 29.977 sec
        FAILED
null expected:<map[ > sort]> but was:<map[]>
junit.framework.ComparisonFailure: null expected:<map[ > sort]> but was:<map[]>
        at org.apache.hadoop.mapreduce.TestTaskContext.testContextStatus(TestTaskContext.java:120)

Testcase: testMapContextProgress took 17.371 sec
Testcase: testReduceContextProgress took 16.267 sec
"
MAPREDUCE-3221,ant test TestSubmitJob failing on trunk,"Testcase: testJobWithInvalidMemoryReqs took 2.588 sec
Testcase: testSecureJobExecution took 4.089 sec
        FAILED
java.io.IOException: org.apache.hadoop.ipc.RPC$VersionMismatch: Protocol org.apache.hadoop.hdfs.protocol.ClientProtocol version mismatch. (client = 69, server = 70)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:617)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

junit.framework.AssertionFailedError: java.io.IOException: org.apache.hadoop.ipc.RPC$VersionMismatch: Protocol org.apache.hadoop.hdfs.protocol.ClientProtocol version mismatch. (client = 69, server = 70)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:617)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)
        at org.apache.hadoop.mapred.TestSubmitJob.testSecureJobExecution(TestSubmitJob.java:270)
"
MAPREDUCE-3220,ant test TestCombineOutputCollector failing on trunk,"Testsuite: org.apache.hadoop.mapred.TestCombineOutputCollector
Tests run: 2, Failures: 2, Errors: 0, Time elapsed: 1.591 sec

Testcase: testCustomCollect took 0.363 sec
        FAILED

taskReporter.progress();
Never wanted here:
-> at org.apache.hadoop.mapred.TestCombineOutputCollector.testCustomCollect(TestCombineOutputCollector.java:118)
But invoked here:
-> at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1202)

junit.framework.AssertionFailedError:
taskReporter.progress();
Never wanted here:
-> at org.apache.hadoop.mapred.TestCombineOutputCollector.testCustomCollect(TestCombineOutputCollector.java:118)
But invoked here:
-> at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1202)

        at org.apache.hadoop.mapred.TestCombineOutputCollector.testCustomCollect(TestCombineOutputCollector.java:118)

Testcase: testDefaultCollect took 1.211 sec
        FAILED

taskReporter.progress();
Wanted 1 time:
-> at org.apache.hadoop.mapred.TestCombineOutputCollector.testDefaultCollect(TestCombineOutputCollector.java:139)
But was 10000 times. Undesired invocation:
-> at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1202)

junit.framework.AssertionFailedError:
taskReporter.progress();
Wanted 1 time:
-> at org.apache.hadoop.mapred.TestCombineOutputCollector.testDefaultCollect(TestCombineOutputCollector.java:139)
But was 10000 times. Undesired invocation:
-> at org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1202)

        at org.apache.hadoop.mapred.TestCombineOutputCollector.testDefaultCollect(TestCombineOutputCollector.java:139)
"
MAPREDUCE-3219,ant test TestDelegationToken failing on trunk,"Testcase: testDelegationToken took 2.043 sec
        Caused an ERROR
Client Hitesh tries to renew a token with renewer specified as alice
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:239)
        at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:4829)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:632)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

org.apache.hadoop.security.AccessControlException: Client Hitesh tries to renew a token with renewer specified as alice
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:239)
        at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:4829)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:632)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:90)
        at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:57)
        at org.apache.hadoop.mapreduce.Cluster.renewDelegationToken(Cluster.java:399)
        at org.apache.hadoop.mapred.JobClient$Renewer.renew(JobClient.java:475)
        at org.apache.hadoop.security.token.Token.renew(Token.java:310)
        at org.apache.hadoop.mapred.JobClient.renewDelegationToken(JobClient.java:1088)
        at org.apache.hadoop.mapreduce.security.token.delegation.TestDelegationToken.testDelegationToken(TestDelegationToken.java:89)
Caused by: org.apache.hadoop.security.AccessControlException: Client Hitesh tries to renew a token with renewer specified as alice
        at org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.renewToken(AbstractDelegationTokenSecretManager.java:239)
        at org.apache.hadoop.mapred.JobTracker.renewDelegationToken(JobTracker.java:4829)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:632)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

        at org.apache.hadoop.ipc.Client.call(Client.java:1085)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
        at $Proxy11.renewDelegationToken(Unknown Source)
        at org.apache.hadoop.mapreduce.Cluster.renewDelegationToken(Cluster.java:397)"
MAPREDUCE-3218,ant test TestTokenCache failing on trunk,"Testcase: testTokenCache took 11.607 sec
Testcase: testLocalJobTokenCache took 12.224 sec
Testcase: testGetTokensForNamenodes took 0.009 sec
Testcase: testGetTokensForHftpFS took 0.676 sec
Testcase: testGetJTPrincipal took 0.023 sec
        FAILED
Failed to substitute HOSTNAME_PATTERN with hostName expected:<jt/foo@BAR> but was:<null>
junit.framework.AssertionFailedError: Failed to substitute HOSTNAME_PATTERN with hostName expected:<jt/foo@BAR> but was:<null>
        at org.apache.hadoop.mapreduce.security.TestTokenCache.testGetJTPrincipal(TestTokenCache.java:392)

Testcase: testGetTokensForViewFS took 0.019 sec
"
MAPREDUCE-3217,ant test TestAuditLogger fails on trunk,"Testcase: testKeyValLogFormat took 0.096 sec
Testcase: testAuditLoggerWithoutIP took 0.005 sec
Testcase: testAuditLoggerWithIP took 0.417 sec
        Caused an ERROR
java.io.IOException: Unknown protocol: org.apache.hadoop.ipc.TestRPC$TestProtocol
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:615)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

java.io.IOException: java.io.IOException: Unknown protocol: org.apache.hadoop.ipc.TestRPC$TestProtocol
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:615)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1517)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1513)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1152)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1511)

        at org.apache.hadoop.ipc.Client.call(Client.java:1085)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:244)
        at $Proxy6.ping(Unknown Source)
        at org.apache.hadoop.mapred.TestAuditLogger.testAuditLoggerWithIP(TestAuditLogger.java:150)
"
MAPREDUCE-3216,ant test TestNoDefaultsJobConf fails on trunk,"Testcase: testNoDefaults took 4.703 sec
        Caused an ERROR
Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
java.io.IOException: Cannot initialize Cluster. Please check your configuration for mapreduce.framework.name and the correspond server addresses.
        at org.apache.hadoop.mapreduce.Cluster.initialize(Cluster.java:118)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:81)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:74)
        at org.apache.hadoop.mapred.JobClient.init(JobClient.java:460)
        at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:439)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:809)
        at org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults(TestNoDefaultsJobConf.java:83)
"
MAPREDUCE-3215,org.apache.hadoop.mapreduce.TestNoJobSetupCleanup failing on trunk,"Testcase: testNoJobSetupCleanup took 13.271 sec
        FAILED
Number of part-files is 0 and not 1
junit.framework.AssertionFailedError: Number of part-files is 0 and not 1
        at org.apache.hadoop.mapreduce.TestNoJobSetupCleanup.submitAndValidateJob(TestNoJobSetupCleanup.java:60)
        at org.apache.hadoop.mapreduce.TestNoJobSetupCleanup.testNoJobSetupCleanup(TestNoJobSetupCleanup.java:70)
"
MAPREDUCE-3214,ant mapreduce tests failing,Umbrella jira for various test failures
MAPREDUCE-3212,Message displays while executing yarn command should be proper,"execute yarn command without any arguments. It displays
{noformat}Usage: hadoop [--config confdir] COMMAND {noformat}.
Rather the message should be
{noformat}Usage: yarn [--config confdir] COMMAND{noformat}
"
MAPREDUCE-3211,"Fetch failures if used ephemeral port for property ""mapreduce.shuffle.port"". ","To reproduce the bug. 

Use the following property in mapred-site.xml

<configuration>
    <property>
      <name> mapreduce.framework.name</name>
      <value>yarn</value>
    </property>
    <property>
      <name> mapreduce.shuffle.port</name>
      <value>0</value>
    </property>
</configuration>

and following in yarn-site.xml


  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce.shuffle</value>
    <description>shuffle service that needs to be set for Map Reduce to run </description>
  </property>

 <property>
<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>

Then try to start the yarn daemons.

And submit the job. (which would eventually fail).

Also observe NM logs. It says shuffle handler service started at port 0; :P"
MAPREDUCE-3209,Jenkins reports 160 FindBugs warnings,"See
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1055//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-common.html
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1055//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-app.html
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/1055//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-core.html"
MAPREDUCE-3208,NPE while flushing TaskLogAppender,"NPE will be throwed out while calling flush() of TaskLogAppender,if the QuietWriter isn't initialized in advance."
MAPREDUCE-3207,TestMRCLI failing on trunk  ,"Failing tests:
  7: Archive: Deleting a file in archive
  8: Archive: Renaming a file in archive
"
MAPREDUCE-3205,"MR2 memory limits should be pmem, not vmem","Currently, the memory resources requested for a container limit the amount of virtual memory used by the container. On my test clusters, at least, Java processes take up nearly twice as much vmem as pmem - a Java process running with -Xmx500m uses 935m of vmem and only about 560m of pmem.

This will force admins to either under-utilize available physical memory, or oversubscribe it by configuring the available resources on a TT to be larger than the true amount of physical RAM.

Instead, I would propose that the resource limit apply to pmem, and allow the admin to configure a ""vmem overcommit ratio"" which sets the vmem limit as a function of pmem limit."
MAPREDUCE-3204,mvn site:site fails on MapReduce,This problem does not happen on 0.23. See details in the next comment.
MAPREDUCE-3203,Fix some javac warnings in MRAppMaster.,MAPREDUCE-2762 accidentally introduced a couple of javac warning. This jira is to fix some of them in MRAppMaster. We have plenty more to fix but I dont intend to fix them all here. This is just so that the hudson bot does not -1 other patches with javac warnings.
MAPREDUCE-3201,"Even though jobs are getting failed on particular NM, it is not getting blacklisted","{code:xml}
The yarnchild process on a particular NM are getting killed continuosly. 
Still the NM is not getting blacklisted
{code}"
MAPREDUCE-3200,Job got failed with FileNotFoundException during ResourceLocalization,"The exception trace is as follows
{code:xml}
2011-10-18 15:37:11,315 WARN org.apache.hadoop.yarn.server.resourcemanager.RMAuditLogger: USER=root	OPERATION=Application Finished - Failed	TARGET=RMAppManager	RESULT=FAILURE	DESCRIPTION=App failed with state: FAILED	PERMISSIONS=Application application_1318930754911_0002 failed 1 times due to AM Container for appattempt_1318930754911_0002_000001 exited with  exitCode: -1000 due to: java.io.FileNotFoundException: file:/tmp/nm-local-dir/usercache/root/appcache/application_1318930754911_0003/container_1318930754911_0002_01_000001.tokens
	at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:189)
	at org.apache.hadoop.fs.DelegateToFileSystem.open(DelegateToFileSystem.java:150)
	at org.apache.hadoop.fs.AbstractFileSystem.open(AbstractFileSystem.java:595)
	at org.apache.hadoop.fs.FilterFs.open(FilterFs.java:197)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:759)
	at org.apache.hadoop.fs.FileContext$6.next(FileContext.java:756)
	at org.apache.hadoop.fs.FileContext$FSLinkResolver.resolve(FileContext.java:2321)
	at org.apache.hadoop.fs.FileContext.open(FileContext.java:756)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.runLocalization(ContainerLocalizer.java:133)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.startLocalizer(DefaultContainerExecutor.java:86)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerRunner.run(ResourceLocalizationService.java:855)

{code}"
MAPREDUCE-3199,TestJobMonitorAndPrint is broken on trunk,I bisected this down to MAPREDUCE-3003 changes. The parent project for client-core changed to hadoop-project which doesn't have the log4j configuration unlike the previous parent hadoop-mapreduce-client.
MAPREDUCE-3198,Change mode for hadoop-mapreduce-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/resources/mock-container-executor to 755 ,The file is checked in with 644 permissions. TestLinuxContainerExecutorWithMocks changes the file mode to add executable permission if needed resulting in a modified file for 'git/svn status' when tests are run. 
MAPREDUCE-3197,TestMRClientService failing on building clean checkout of branch 0.23,"A clean checkout of the branch 0.23 source tree does not pass TestMRClientService#test(), which fails with the error message ""Num diagnostics is not correct expected <2> but was:<1> upon running ""mvn clean install assembly:assembly"" inside MR directory.

"
MAPREDUCE-3196,TestLinuxContainerExecutorWithMocks fails on Mac OSX,TestLinuxContainerExecutorWithMocks uses /bin/true which isn't present. 
MAPREDUCE-3194,"""mapred mradmin"" command is broken in mrv2","$mapred  mradmin  
Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/mapred/tools/MRAdmin
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.tools.MRAdmin
        at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:248)
Could not find the main class: org.apache.hadoop.mapred.tools.MRAdmin.  Program will exit."
MAPREDUCE-3193,FileInputFormat doesn't read files recursively in the input path dir,"java.io.FileNotFoundException is thrown,if input file is more than one folder level deep and the job is getting failed.
Example:Input file is /r1/r2/input.txt
"
MAPREDUCE-3192,Fix Javadoc warning in JobClient.java and Cluster.java,Javadoc warnings in JobClient.java and Cluster.java need to be fixed.
MAPREDUCE-3191,docs for map output compression incorrectly reference SequenceFile,"The documentation currently says that map output compression uses SequenceFile compression. This hasn't been true in several years, since we use IFile for intermediate data now."
MAPREDUCE-3190,bin/yarn should barf early if HADOOP_COMMON_HOME or HADOOP_HDFS_HOME are not set,"Currently, if these env vars are not set when you run bin/yarn, it will crash with various ClassNotFoundExceptions, having added {{/share/hadoop/hdfs}} to the classpath. Rather, we should check for these env vars in the wrapper script and display a reasonable error message."
MAPREDUCE-3189,Add link decoration back to MR2's CSS,"I found the MRv2 web UI very difficult to use because it's not clear which items are links and which aren't. I'd like to change the CSS so that links are underlined, making it easier to see them (since they're also not in any different color)"
MAPREDUCE-3188,Lots of errors in logs when daemon startup fails,"Since the MR2 daemons are made up of lots of component services, if one of those components fails to start, it will cause the others to shut down as well, even if they haven't fully finished starting up. Currently, this causes the error output to have a bunch of NullPointerExceptions, IllegalStateExceptions, etc, which mask the actual root cause error at the top."
MAPREDUCE-3187,Add names for various unnamed threads in MR2,"Simple patch to add thread names for all the places we use Executors, etc."
MAPREDUCE-3186,User jobs are getting hanged if the Resource manager process goes down and comes up while job is getting executed.,"If the resource manager is restarted while the job execution is in progress, the job is getting hanged.
UI shows the job as running.
In the RM log, it is throwing an error ""ERROR org.apache.hadoop.yarn.server.resourcemanager.ApplicationMasterService: AppAttemptId doesnt exist in cache appattempt_1318579738195_0004_000001""
In the console MRAppMaster and Runjar processes are not getting killed"
MAPREDUCE-3185,RM Web UI does not sort the columns in some cases.,"While running lots of jobs on a MRv2 cluster the RM web UI shows this error on loading the RM web UI:

""DataTables warning (table id = 'apps'): Added data (size 8) does not match known number of columns (9)""

After ignoring the error, the column sorting on Web UI stops working."
MAPREDUCE-3184,Improve handling of fetch failures when a tasktracker is not responding on HTTP,"On a 100 node cluster, we had an issue where one of the TaskTrackers was hit by MAPREDUCE-2386 and stopped responding to fetches. The behavior observed was the following:
- every reducer would try to fetch the same map task, and fail after ~13 minutes.
- At that point, all reducers would report this failed fetch to the JT for the same task, and the task would be re-run.
- Meanwhile, the reducers would move on to the next map task that ran on the TT, and hang for another 13 minutes.
The job essentially made no progress for hours, as each map task that ran on the bad node was serially marked failed.

To combat this issue, we should introduce a second type of failed fetch notification, used when the TT does not respond at all (ie SocketTimeoutException, etc). These fetch failure notifications should count against the TT at large, rather than a single task. If more than half of the reducers report such an issue for a given TT, then all of the tasks from that TT should be re-run."
MAPREDUCE-3183,hadoop-assemblies/src/main/resources/assemblies/hadoop-mapreduce-dist.xml missing license header,Re-assigning as this is part of the mavenization related changes and requires a delayed merge to the 23 branch. 
MAPREDUCE-3181,Terasort fails with Kerberos exception on secure cluster,"We are seeing the following Kerberos exception upon trying to run terasort on secure single and multi-node clusters using the latest build from branch 0.23.

java.io.IOException: Can't get JobTracker Kerberos principal for use as renewer
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:106)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:90)
        at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:83)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:205)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:269)
        at org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(TeraInputFormat.java:318)
        at org.apache.hadoop.examples.terasort.TeraInputFormat.writePartitionFile(TeraInputFormat.java:169)
        at org.apache.hadoop.examples.terasort.TeraSort.run(TeraSort.java:306)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.examples.terasort.TeraSort.main(TeraSort.java:325)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)

Adding debug output shows that the job configuration is not loading up yarn-site.xml causing the above failure to happen.
"
MAPREDUCE-3180,TaskTracker.java.orig accidentally checked in to 0.20-security-205,"The file src/mapred/org/apache/hadoop/mapred/TaskTracker.java.orig was accidentally checked in as part of r1179465.  It is only in 0.20-security-205, not 0.20-security.  If there is a 0.20.205.1, remove it then."
MAPREDUCE-3179,Incorrect exit code for hadoop-mapreduce-test tests when exception thrown,"Exit code for test jar is 0 despite exception thrown

hadoop jar hadoop-mapreduce-test-0.23.0-SNAPSHOT.jar loadgen -Dmapreduce.job.acl-view -m 18 -r 0 -outKey org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text -indir nonexistentdir

Loadgen output snippet
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://machine.name.example.com:9000/user/exampleuser/nonexistentdir
        at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:234)
        at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:254)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeOldSplits(JobSubmitter.java:470)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:462)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:358)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1159)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1156)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1156)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:539)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:778)
        at org.apache.hadoop.mapred.GenericMRLoadGenerator.run(GenericMRLoadGenerator.java:200)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.mapred.GenericMRLoadGenerator.main(GenericMRLoadGenerator.java:214)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
        at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
-bash-3.2$ echo $?
0

This differs from example jar which correctly returns the correct exit code

hadoop jar hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount nonexistentdir /outputdir

wordcount output snippet
org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://machine.name.example.com:9000/user/exampleuser/nonexistentdir
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:243)
        at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:269)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:443)
        at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:460)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:358)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1159)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1156)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1156)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1176)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
-bash-3.2$ echo $?
255

"
MAPREDUCE-3178,Capacity Schedular shows incorrect cluster information in the RM logs,"When we start the NM, after stopping it (in a quick session) CS shows incorrect information about clusterResource in the logs.

I have encountered this issue in a pseudo cluster mode and steps to reproduce are

1) start the YARN cluster
2) stop a NM and start the NM again (in a quick session)

There should be a NM running in the cluster however as I observed RM detects NM as dead, after default time since its actual unavailability(In this case NM has been stopped).
 
If you start your NM before this time (default time), ResourceTracker throws IOEx, however, CS adds the NM's capacity to the clusterResource. 

After elapsed time (default time) when RM detects NM as dead, RM removes the NM and hence capacity of the cluster will be subtracted by the amount NM capacity.

Eventually there is no NM running in the cluster, but capacity of the cluster is NM's capacity (by default)"
MAPREDUCE-3177,mapreduce tar layout does not conform new layout,"The tar generated by MR does not follow the layout of common & hdfs, instead, it uses a arbitrary layout which is also different from the old legacy layout (there is a modules/ directory with all the MR jars)"
MAPREDUCE-3176,ant mapreduce tests are timing out,Secondary YARN builds started taking inordinately long and lots of tests started failing. Usually the secondary build would take ~ 2 hours. But recently even after 7 hours it wasn't done. 
MAPREDUCE-3175,Yarn httpservers not created with access Control lists,"RM, NM, job history, and application master httpservers are not created with access Control lists. I believe this means that anyone can access any of the standard servlets that check to see if the user has administrator access - like /jmx, /stacks, etc and ops has no way to restrict access to these things."
MAPREDUCE-3173,MRV2 UI doesn't work properly without internet,"When we try access the MRV2 UI, it is always giving the below message in the UI even if the java script enabled in the browser.
{code:xml}
This page works best with javascript enabled. 
{code}

It is trying to download these below css/js files from internet and finally ending up with the above message. For loading the page also it is taking long time.

{code:title=JQueryUI.java|borderStyle=solid}
  html.
      link(join(""https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.9/themes/"",
                getTheme(), ""/jquery-ui.css"")).
      link(""/static/dt-1.7.5/css/jui-dt.css"").
      script(""https://ajax.googleapis.com/ajax/libs/jquery/1.4.4/jquery.min.js"").
      script(""https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.9/jquery-ui.min.js"").
{code} "
MAPREDUCE-3171,normalize nodemanager native code compilation with common/hdfs native,"Use same build pattern as used by common/hdfs native:

* rename src/c to src/native
* run autoreconf, configure and make under target not to pollute the src tree
* use maven-make-plugin in an identical way as in common/hdfs native"
MAPREDUCE-3170,Trunk nightly commit builds are failing.,Looks like the trunk commit builds are failing after MAPREDUCE-3148 and MAPREDUCE-3126  were committed. I suspect its MAPREDUCE-3148.
MAPREDUCE-3169,Create a new MiniMRCluster equivalent which only provides client APIs cross MR1 and MR2,"Many dependent projects like HBase, Hive, Pig, etc, depend on MiniMRCluster for writing tests. Many users do as well. MiniMRCluster, however, exposes MR implementation details like the existence of TaskTrackers, JobTrackers, etc, since it was used by MR1 for testing the server implementations as well.

This JIRA is to create a new interface which could be implemented either by MR1 or MR2 that exposes only the client-side portions of the MR framework. Ideally it would be ""recompile-compatible"" with MiniMRCluster for most applications, and the MR1 implementation could be backported to 20x branch. Thus, dependent projects like HBase could migrate to this implementation and test against both MR1 and MR2. We can also use this to port over the current functional tests that use only the client-side features of MiniMRCluster."
MAPREDUCE-3168,[Gridmix] TestCompressionEmulationUtils fails after MR-3158,TestCompressionEmulationUtils fails after MAPREDUCE-3158 as it uses local job-runner to run jobs.
MAPREDUCE-3167,container-executor is not being packaged with the assembly target.,Looks like MAPREDUCE-2988 broke this. This is a temporary fix until we get a full fledged maven dist tar working. Trivial fix.
MAPREDUCE-3166,Make Rumen use job history api instead of relying on current history file name format,"Rumen should not depend on the regular expression of job history file name format and should use the newly added api like isValidJobHistoryFileName(), getJobIDFromHistoryFilePath()."
MAPREDUCE-3165,Ensure logging option is set on child command line,Currently the logging config is set in env in MapReduceChildJVM - we need to set it on command line.
MAPREDUCE-3163,JobClient spews errors when killing MR2 job,"When I used the ""hadoop job"" command line to kill a running MR2 job, I got a bunch of error spew on the console, despite the kill actually taking effect."
MAPREDUCE-3162,Separate application-init and container-init event types in NM's ApplicationImpl FSM,"Currently, the ApplicationImpl receives an INIT_APPLICATION event on every container initialization. Only on the first one does it really mean to init the application, whereas all subsequent events are for specific containers. This JIRA is to separate the events into INIT_APPLICATION, sent once and only once per application, and INIT_CONTAINER, which is sent for every container. The first container sends INIT_APPLICATION followed by INIT_CONTAINER."
MAPREDUCE-3161,Improve javadoc and fix some typos in MR2 code,"Just some simple cleanup, documentation, typos in variable names, etc. The only code change is to refactor ResourceLocalizationService so each event type is handled in its own method instead of a giant switch statement (just using eclipse's Extract Method - no semantic change)"
MAPREDUCE-3160,Merge -r 1177530:1177531 from trunk to branch-0.23 to fix MAPREDUCE-2996 broke ant test compilation,"I git bisected and the problem starts from adb810babaf25b9f9dae75b43d4beac782deaa01 . ant
{noformat}
[jsp-compile] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
    [javac] /home/raviprak/Code/hadoop/hadoop-all/hadoop-mapreduce-project/build.xml:398: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 2 source files to /home/raviprak/Code/hadoop/hadoop-all/hadoop-mapreduce-project/build/classes
    [javac] /home/raviprak/Code/hadoop/hadoop-all/hadoop-mapreduce-project/src/java/org/apache/hadoop/mapred/JobInProgress.java:697: cannot find symbol
    [javac] symbol  : constructor JobInitedEvent(org.apache.hadoop.mapred.JobID,long,int,int,java.lang.String,boolean)
    [javac] location: class org.apache.hadoop.mapreduce.jobhistory.JobInitedEvent
    [javac]     JobInitedEvent jie = new JobInitedEvent(
    [javac]                          ^
    [javac] Note: /home/raviprak/Code/hadoop/hadoop-all/hadoop-mapreduce-project/src/java/org/apache/hadoop/mapred/JobInProgress.java uses or overrides a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error
{noformat}
"
MAPREDUCE-3159,DefaultContainerExecutor removes appcache dir on every localization,The DefaultContainerExecutor currently has code that removes the application dir from appcache/ in the local directories on every task localization. This causes any concurrent executing tasks from the same job to fail.
MAPREDUCE-3158,Fix trunk build failures,"https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/1060/

"
MAPREDUCE-3157,Rumen TraceBuilder is skipping analyzing 0.20 history files,Rumen TraceBuilder is assuming the Pre21 history file name format to be JTIdentifier_jobId_<something>. But it can be jobId_<something> also as it is now in latest 0.20.x version. This also needs to be understood by TraceBuilder.
MAPREDUCE-3156,Allow TestMRCLI to be run against a cluster,Mapreduce part of HDFS-1762
MAPREDUCE-3154,"Validate the Jobs Output Specification as the first statement in JobSubmitter.submitJobInternal(Job, Cluster) method","Presently the output specification is validated after getting new JobId from ClientRMService, Copying the job jar, Configuration file, archives etc.

Instead of that move following Job Output specification validation call to the begining of JobSubmitter.submitJobInternal(Job, Cluster) method.

{code}
checkSpecs(job);
{code}

This will avoid unnecessary work in case of invalid output specs.

"
MAPREDUCE-3153,TestFileOutputCommitter.testFailAbort() is failing on trunk on Jenkins,This mostly is caused by MAPREDUCE-2702.
MAPREDUCE-3151,Contrib tests failing,"Jenkins builds fail:
https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-22-branch/80/console
"
MAPREDUCE-3149,add a test to verify that buildDTAuthority works for cases with no authority.,Add a test to verify that buildDTAuthority works for cases with no Authority.
MAPREDUCE-3148,Port MAPREDUCE-2702 to old mapred api,Port MAPREDUCE-2702 to old mapred api
MAPREDUCE-3147,Handle leaf queues with the same name properly,"If there are two leaf queues with the same name, there is ambiguity while submitting jobs, displaying queue info. When such ambiguity exists, the system should ask for clarification / show disambiguated information."
MAPREDUCE-3146,Add a MR specific command line to dump logs for a given TaskAttemptID,
MAPREDUCE-3145,Fix NM UI to serve logs from DFS once application finishes,
MAPREDUCE-3144,Augment JobHistory to include information needed for serving aggregated logs.,
MAPREDUCE-3143,Complete aggregation of user-logs spit out by containers onto DFS,"Already implemented the feature for handling user-logs spit out by containers in NodeManager. But the feature is currently disabled due to user-interface issues.

This is the umbrella ticket for tracking the pending bugs w.r.t putting container-logs on DFS."
MAPREDUCE-3142,smart-apply-patch.sh fails with errors,"smart-apply-patch.sh fails with the following error
{noformat}
./dev-support/smart-apply-patch.sh: line 84: syntax error in conditional expression: unexpected token `('
PATCH APPLICATION FAILED
{noformat}"
MAPREDUCE-3141,"Yarn+MR secure mode is broken, uncovered after MAPREDUCE-3056",
MAPREDUCE-3140,Invalid JobHistory URL for failed applications,"After completion of the applications execution (application has failed though), to verify the job history, I clicked on the JobHistory hyper-link displayed as part of the application details.In this case, it is displaying [http://n/A]."
MAPREDUCE-3139,SlivePartitioner generates negative partitions,"{{SlivePartitioner.getPartition()}} returns negative partition numbers on some occasions, which is illegal."
MAPREDUCE-3138,Allow for applications to deal with MAPREDUCE-954,MAPREDUCE-954 changed the context-objs api to interfaces. This breaks Pig. We need a bridge for them to move to 0.23.
MAPREDUCE-3137,Fix broken merge of MR-2719 to 0.23 branch for the distributed shell test case ,
MAPREDUCE-3136,Add docs for setting up real-world MRv2 clusters,Add docs for setting up real-world MRv2 clusters - MR portion of http://hadoop.apache.org/common/docs/stable/cluster_setup.html
MAPREDUCE-3135,Unit test org.apache.hadoop.mapred.TestJobHistoryServer fails intermittently,Every once in a while org.apache.hadoop.mapred.TestJobHistoryServer fails due to a timeout.
MAPREDUCE-3134,Add documentation for CapacityScheduler,Add documentation for CapacityScheduler in MRv2 similar to http://hadoop.apache.org/common/docs/stable/capacity_scheduler.html.
MAPREDUCE-3133,Running a set of methods in a Single Test Class,"Instead of running every test method in a class, limit to specific testing methods as describe in the link below.

http://maven.apache.org/plugins/maven-surefire-plugin/examples/single-test.html

Upgrade to the latest version of maven-surefire-plugin that has this feature."
MAPREDUCE-3127,Unable to restrict users based on resourcemanager.admin.acls value set,"Setting the following property in yarn-site.xml with user ids to restrict ability to run
'rmadmin -refreshQueues is not honoured

<property>
<name>yarn.server.resourcemanager.admin.acls</name>
<value>hadoop1</value>
<description></description>
<final></final>
</property>

Should it be the same for rmadmin -refreshNodes?"
MAPREDUCE-3126,mr job stuck because reducers using all slots and mapper isn't scheduled,"The command in MAPREDUCE-3124 run and this job got hung with 1 Map task waiting for resources and 7 Reducers running (2 waiting).  The mapper got scheduler, then AM scheduled the reducers, the map task failed and tried to start a new attempt but reducers were using all the slots.   

I will try to add some more info from the logs."
MAPREDUCE-3125,app master web UI shows reduce task progress 100% even though reducers not complete and state running/scheduled,ran same command as MAPREDUCE-3124. The app master web ui was displaying the reduce task progress as 100% even though the states were still running/scheduled.  Each of those reduce tasks had attempts that failed or killed and another one unassigned. Attaching screenshots.
MAPREDUCE-3124,mapper failed with failed to load native libs,"hadoop jar hadoop-mapreduce-examples-*.jar sort -Dmapreduce.job.acl-view
-job=* -Dmapreduce.map.output.compress=true 
-Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec 
-Dmapreduce.output.fileoutputformat.compress=true  -Dmapreduce.output.fileoutputformat.compression.type=NONE -Dmap
reduce.output.fileoutputformat.compression.codec=org.apache.hadoop.io.compress.GzipCodec  -outKey
org.apache.hadoop.io.Text -outValue org.apache.hadoop.io.Text  Compression/textinput Compression/textoutput-1317315994

This will fail with native libs not found error unless -Dmapred.child.java.opts='-Djava.library.path=${HADOOP_COMMON_HOME}/lib/native/Linux-i386-32' is added.


The error in container log:


2011-09-29 17:06:56,787 DEBUG org.apache.hadoop.util.NativeCodeLoader: Trying to load the custom-built native-hadoop
library...2011-09-29 17:06:56,787 DEBUG org.apache.hadoop.util.NativeCodeLoader: Failed to load native-hadoop with
error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path2011-09-29 17:06:56,787 DEBUG
org.apache.hadoop.util.NativeCodeLoader:
java.library.path=/share/gridjdk-1.6.0_21/jre/lib/i386/server:/share/gridjdk-1.6.0_21/jre/lib/i386:/share/gridjdk-1.6.0_21/jre/../lib/i386:/tmp/mapred-local/usercache/hadoopqa/appcache/application_1317314754104_0012/container_1317314754104_0012_01_000002:/current/lib:/usr/java/packages/lib/i386:/lib:/usr/lib2011-09-29
17:06:56,787 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform...
using builtin-java classes where applicable


Also note that the error that shows up at the application master for this is terrible:

Container killed by the ApplicationMaster. Container killed on request. Exit code is 137 Too Many fetch failures.Failing the attempt 
"
MAPREDUCE-3123,Symbolic links with special chars causing container/task.sh to fail,"the following job throws an exception when you have the special characters in it.

hadoop jar hadoop-streaming.jar -Dmapreduce.job.acl-view-job=* -Dmapreduce.job.queuename=queue1 -files file:///homes/user/hadoop/Streaming/data/streaming-980//InputDir#testlink!@$&*()-_+= -input Streaming/streaming-980/input.txt  -mapper 'xargs cat' -reducer cat -output Streaming/streaming-980/Output -jobconf mapred.job.name=streamingTest-980 -jobconf mapreduce.job.acl-view-job=*

Exception:
2011-09-27 20:58:48,903 INFO org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: launchContainer:
[container-executor, hadoopuser, 1, application_1317077272567_0239,
container_1317077272567 0239_01_000001,
tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001,
tmp/mapred-local/nmPrivate/application_1317077272567_0239/container_1317077272567_0239_01 000001/task.sh,
tmp/mapred-local/nmPrivate/container_1317077272567_0239_01_000001/container_1317077272567_0239_01_000001.tokens]1109221111-tests.jar:hadoop-mapreduce-p2011-09-27
20:58:48,944 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exit code from container is : 2    
                                                                                                           2011-09-27
20:58:48,946 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exception from container-launch :  
                                                                                                          
org.apache.hadoop.util.Shell$ExitCodeException:
/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:
line 26: syntax error near unexpected token `-_+='       
/tmp/mapred-local/usercache/hadoopuser/appcache/application_1317077272567_0239/container_1317077272567_0239_01_000001/task.sh:
line 26: `ln -sf /tmp/mapred-local/usercache/hadoopqa/filecache/-1888139433818483070/InputDir test
ink!@$&*()-_+='kson-jaxrs-1.7.1.jar:/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.7.3/jackson-mapper-asl-1.7.3.jar:.m2/repository/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar:

     at org.apache.hadoop.util.Shell.runCommand(Shell.java:261)                                                        
                                                                                                                       
   at org.apache.hadoop.util.Shell.run(Shell.java:188)                                                                 
                                                                                                                       
 at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:381)                                          
                                                                                                                      
at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.launchContainer(LinuxContainerExecutor.java:174)   
                                                                                                                     
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:197)  
                                                                                                                     
at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:62)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.ContainerExecutor:
2011-09-27 20:58:48,951 INFO org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container: Processing
container_1317077272567_0239_01_000001 of type UPDATE_DIAGNOSTICS_MSG
2011-09-27 20:58:48,951 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch:
Container exited with a non-zero exit code 2


"
MAPREDUCE-3121,DFIP aka 'NodeManager should handle Disk-Failures In Place',"This is akin to MAPREDUCE-2413 but for YARN's NodeManager. We want to minimize the impact of transient/permanent disk failures on containers. With larger number of disks per node, the ability to continue to run containers on other disks is crucial."
MAPREDUCE-3120,"JobHistory is not providing correct count failed,killed task","Please refer the attachment JobFail.PNG.
Here the Job (WordCount) Failed as all Map Attempts were killed(intensionally) but, still the Table in UI shows 0 Killed Attempts and no reason for Failure is also available."
MAPREDUCE-3118,Backport Gridmix and Rumen features from trunk to Hadoop 0.20 security branch,Backporting all the features and bugfixes that went into gridmix and rumen of trunk to hadoop 0.20 security branch. This will enable using all these gridmix features and run gridmix/rumen on the history logs of 0.20 security branch.
MAPREDUCE-3117,Uber jobs are hanging,"Ran a simple wordcount with uber jobs enabled and job hangs

hadoop jar hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount -Dmapreduce.job.ubertask.enable=true <path to small file> <output dir>

container syslog is filled with repeating
2011-09-28 16:55:04,157 INFO org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from attempt_1317246458306_0002_r_000000_0. fromEventID 0 maxEvents 10000
2011-09-28 16:55:04,157 DEBUG org.apache.hadoop.mapreduce.task.reduce.EventFetcher: Got 0 map completion events from 0
2011-09-28 16:55:04,157 DEBUG org.apache.hadoop.mapreduce.task.reduce.EventFetcher: GetMapEventsThread about to sleep for 1000
"
MAPREDUCE-3116,RM and NM fail to start (webapps/cluster is missing),"When I try to start the RM, I get:

2011-09-28 10:03:42,848 FATAL resourcemanager.ResourceManager (ResourceManager.java:main(514)) - Error starting ResourceManager
org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:152)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.startWepApp(ResourceManager.java:396)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.start(ResourceManager.java:411)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:512)
Caused by: java.io.FileNotFoundException: webapps/cluster not found in CLASSPATH
	at org.apache.hadoop.http.HttpServer.getWebAppsPath(HttpServer.java:484)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:184)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:139)
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:144)
	... 3 more

When I try to start the NM, I get:

2011-09-28 09:40:52,330 ERROR webapp.WebServer (WebServer.java:start(65)) - NMWebapps failed to start.
org.apache.hadoop.yarn.webapp.WebAppException: Error starting http server
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:152)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer.start(WebServer.java:59)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)
Caused by: java.io.FileNotFoundException: webapps/node not found in CLASSPATH
	at org.apache.hadoop.http.HttpServer.getWebAppsPath(HttpServer.java:507)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:207)
	at org.apache.hadoop.http.HttpServer.<init>(HttpServer.java:162)
	at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:144)
	... 4 more

I poked around a bit. When I jar -tvf my hadoop-yarn-common-0.24.0-SNAPSHOT.jar file, I see that it has:

     0 Mon Sep 19 09:41:18 PDT 2011 webapps/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/js/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/css/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/static/jt/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/test/
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/yarn/
   612 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/back_disabled.jpg
   260 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/sort_desc.png
   263 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/sort_asc.png
   807 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/back_enabled.jpg
   894 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/favicon.ico
   251 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/sort_desc_disabled.png
   252 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/sort_asc_disabled.png
 27490 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/Sorting icons.psd
   635 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/forward_disabled.jpg
   282 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/sort_both.png
   852 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/images/forward_enabled.jpg
 18043 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/js/jquery.dataTables.min.js.gz
  1276 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/css/demo_page.css
  9689 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/css/demo_table.css
  6211 Mon Sep 19 09:41:18 PDT 2011 webapps/static/dt-1.7.5/css/jui-dt.css
  4191 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_trontastic.png
  3259 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_humanity.png
  3260 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_start_menu.png
  8581 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_sunny.png
  2961 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_hot_sneaks.png
  3417 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_smoothness.png
  3309 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_black_matte.png
  3697 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_excite_bike.png
  8530 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_cupertino.png
  9041 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_eggplant.png
  5153 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_ui_light.png
  7533 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_blitzer.png
  9124 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_le_frog.png
  3166 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_dot_luv.png
  7103 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_overcast.png
 11553 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_pepper_grinder.png
  5367 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_swanky_purse.png
  6432 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_flick.png
 10481 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_dark_hive.png
  8760 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_ui_dark.png
  3370 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_windoze.png
  8417 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_south_street.png
  8620 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_mint_choco.png
  3623 Mon Sep 19 09:41:18 PDT 2011 webapps/static/theme/theme_90_black_tie.png
  1118 Mon Sep 19 09:41:18 PDT 2011 webapps/static/yarn.css
 23946 Mon Sep 19 09:41:18 PDT 2011 webapps/static/hadoop-st.png
  8821 Mon Sep 19 09:41:18 PDT 2011 webapps/static/themeswitcher.js.gz
  3494 Mon Sep 19 09:41:18 PDT 2011 webapps/static/busy.gif
 37540 Mon Sep 19 09:41:18 PDT 2011 webapps/static/jt/jquery.jstree.js.gz
  1628 Mon Sep 19 09:41:18 PDT 2011 webapps/static/yarn.dt.plugins.js
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/test/.keep
     0 Mon Sep 19 09:41:18 PDT 2011 webapps/yarn/.keep

Clearly, this is missing the cluster/.keep path, which appears to be required by RM (as it specifies ""cluster"" as the webapp name when it starts).

I think that we need to get ""cluster"" and whatever NM's webapp name is back into the webapps directory in the jar."
MAPREDUCE-3114,Invalid ApplicationMaster URL in Applications Page,"When the Application is in Accepted state and user tries to click the ApplicationMaster URL in Applications Page, it ends up in Invalid HTTP URL. 
The screenshot attached with this Issue makes it more clear.

The HTTP url formed is: http://n/A"
MAPREDUCE-3113,the scripts yarn-daemon.sh and yarn are not working properly,"When we execute them on any path but $YARN_HOME with bash -x option,it is giving the error as follows:
(Of course we should set the path variable of that scritps into the .bashrc or profile in advance)
{code}
/usr/share/hadoop/hadoop-mapreduce-0.24.0-SNAPSHOT/bin/yarn: line 55: /usr/share/hadoop/yarn-config.sh:  No such file or directory
{code} "
MAPREDUCE-3112,Calling hadoop cli inside mapreduce job leads to errors,"When running a streaming job with mapper

bin/hadoop --config /etc/hadoop/ jar contrib/streaming/hadoop-streaming-0.20.205.0.jar -mapper ""hadoop --config /etc/hadoop/ dfs -help"" -reducer NONE -input ""/tmp/input.txt"" -output NONE

Task log shows:

{noformat}
Exception in thread ""main"" java.lang.ExceptionInInitializerError
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:57)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.fs.FsShell.main(FsShell.java:1895)
Caused by: org.apache.commons.logging.LogConfigurationException: User-specified log class 'org.apache.commons.logging.impl.Log4JLogger' cannot be found or is not useable.
	at org.apache.commons.logging.impl.LogFactoryImpl.discoverLogImplementation(LogFactoryImpl.java:874)
	at org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:604)
	at org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:336)
	at org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:310)
	at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:685)
	at org.apache.hadoop.conf.Configuration.<clinit>(Configuration.java:142)
	... 3 more
java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 1
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:311)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:545)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:132)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:36)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:261)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.Child.main(Child.java:255)
{noformat}

Upon inspection, there are two problems in the inherited from environment which prevent the logger initialization to work properly.  In hadoop-env.sh, the HADOOP_OPTS is inherited from the parent process.  This configuration was requested by user to have a way to override HADOOP environment in the configuration template:

{noformat}
export HADOOP_OPTS=""-Djava.net.preferIPv4Stack=true $HADOOP_OPTS""
{noformat}

-Dhadoop.log.dir=$HADOOP_LOG_DIR/task_tracker_user is injected into HADOOP_OPTS in the tasktracker environment.  Hence, the running task would inherit the wrong logging directory, which the end user might not have sufficient access to write.  Second, $HADOOP_ROOT_LOGGER is override to: -Dhadoop.root.logger=INFO,TLA by the task controller, therefore, the bin/hadoop script will attempt to use hadoop.root.logger=INFO,TLA, but fail to initialize.  "
MAPREDUCE-3111,Fix log serving in NodeManager,"Just noticed that the current log serving is using the raw writer (instead of Hamlet) to serve logs without escaping html.

It's actually easier/cleaner to use Hamlet to serve logs:
{code}
pre._(buffer);
{code}

which takes care of content escaping automatically.

I will make raw writer access package private for framework use only."
MAPREDUCE-3110,TestRPC.testUnknownCall() is failing,"{code:xml}
Failed tests: 
  testUnknownCall(org.apache.hadoop.yarn.TestRPC): null expected:<...icationId called on []org.apache.hadoop.ya...> but was:<...icationId called on [interface ]org.apache.hadoop.ya...>

Tests run: 65, Failures: 1, Errors: 0, Skipped: 0

{code}"
MAPREDUCE-3109,NPE exception in the TestClass org.apache.hadoop.yarn.server.resourcemanager.Application,"Method *List<Container> org.apache.hadoop.yarn.server.resourcemanager.Application.getResources() throws IOException* throws NPE. 

This is causing TestCases to fail like:
*void org.apache.hadoop.yarn.server.resourcemanager.TestResourceManager.testContainerStatusesWillBeStoredInResourceManager() throws Exception* with following trace:
{noformat}
java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.resourcemanager.Application.getResources(Application.java:283)
	at org.apache.hadoop.yarn.server.resourcemanager.Application.schedule(Application.java:311)
	at org.apache.hadoop.yarn.server.resourcemanager.TestResourceManager.testContainerStatusesWillBeStoredInResourceManager(TestResourceManager.java:196)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:46)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)


{noformat}


Devraj,

Can you please take a look into it."
MAPREDUCE-3107,DFSIO tests are failing intermittently,"Intermittently DFSIO tests are failing either in ""read"" or ""write"" operations.

$HADOOP_COMMON_HOME/bin/hadoop --config $HADOOP_CONF_DIR jar $HADOOP_MAPRED_HOME/hadoop-mapreduce-test-*.jar TestDFSIO  -read -nrFiles 36 -fileSize 320


11/09/27 03:21:03 INFO fs.TestDFSIO: TestDFSIO.0.0.6
11/09/27 03:21:03 INFO fs.TestDFSIO: nrFiles = 36
11/09/27 03:21:03 INFO fs.TestDFSIO: fileSize (MB) = 320.0
11/09/27 03:21:03 INFO fs.TestDFSIO: bufferSize = 1000000
11/09/27 03:21:03 INFO fs.TestDFSIO: baseDir = /benchmarks/TestDFSIO
11/09/27 03:21:03 INFO fs.TestDFSIO: creating control file: 335544320 bytes, 36 files
11/09/27 03:21:05 INFO fs.TestDFSIO: created control files for: 36 files
..
..
..
..
..
11/09/27 03:24:04 INFO mapreduce.Job:  map 88% reduce 25%
11/09/27 03:24:05 INFO mapreduce.Job:  map 90% reduce 25%
11/09/27 03:24:06 INFO mapreduce.Job:  map 92% reduce 25%
11/09/27 03:24:09 INFO mapreduce.Job:  map 93% reduce 25%
11/09/27 03:24:10 INFO mapreduce.Job:  map 93% reduce 26%
11/09/27 03:24:42 INFO mapreduce.Job:  map 94% reduce 26%
11/09/27 03:24:43 INFO mapreduce.Job:  map 94% reduce 27%
11/09/27 03:24:56 INFO mapreduce.Job:  map 95% reduce 27%
11/09/27 03:24:58 INFO mapreduce.Job:  map 95% reduce 28%
11/09/27 03:25:13 INFO mapreduce.Job:  map 96% reduce 28%
11/09/27 03:25:15 INFO mapreduce.Job:  map 97% reduce 28%
11/09/27 03:25:16 INFO mapreduce.Job:  map 97% reduce 30%
11/09/27 03:25:16 INFO mapreduce.Job:  map 98% reduce 30%
11/09/27 03:25:16 INFO mapreduce.Job: Job job_1317092846056_0012 failed with state FAILED
11/09/27 03:25:16 INFO mapreduce.Job: Counters: 44
	File System Counters
		FILE: BYTES_READ=20931
		FILE: BYTES_WRITTEN=2192966
		FILE: READ_OPS=0
		FILE: LARGE_READ_OPS=0
		FILE: WRITE_OPS=0
		HDFS: BYTES_READ=10454250228
		HDFS: BYTES_WRITTEN=0
		HDFS: READ_OPS=172
		HDFS: LARGE_READ_OPS=0
		HDFS: WRITE_OPS=0
	org.apache.hadoop.mapreduce.JobCounter
		NUM_FAILED_MAPS=6
		TOTAL_LAUNCHED_MAPS=44
		TOTAL_LAUNCHED_REDUCES=1
		DATA_LOCAL_MAPS=10
		RACK_LOCAL_MAPS=34
		SLOTS_MILLIS_MAPS=2340307
	org.apache.hadoop.mapreduce.TaskCounter
		MAP_INPUT_RECORDS=36
		MAP_OUTPUT_RECORDS=140
		MAP_OUTPUT_BYTES=2103
		MAP_OUTPUT_MATERIALIZED_BYTES=2579
		SPLIT_RAW_BYTES=5210
		COMBINE_INPUT_RECORDS=0
		COMBINE_OUTPUT_RECORDS=0
		REDUCE_INPUT_GROUPS=0
		REDUCE_SHUFFLE_BYTES=3054
		REDUCE_INPUT_RECORDS=0
		REDUCE_OUTPUT_RECORDS=0
		SPILLED_RECORDS=140
		SHUFFLED_MAPS=33
		FAILED_SHUFFLE=0
		MERGED_MAP_OUTPUTS=0
		GC_TIME_MILLIS=59933
		CPU_MILLISECONDS=159470
		PHYSICAL_MEMORY_BYTES=11310596096
		VIRTUAL_MEMORY_BYTES=31425290240
		COMMITTED_HEAP_BYTES=12728664064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter
		BYTES_READ=4058
	org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter
		BYTES_WRITTEN=0
java.io.IOException: Job failed!
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:781)
	at org.apache.hadoop.fs.TestDFSIO.runIOTest(TestDFSIO.java:340)
	at org.apache.hadoop.fs.TestDFSIO.readTest(TestDFSIO.java:418)
	at org.apache.hadoop.fs.TestDFSIO.run(TestDFSIO.java:522)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
	at org.apache.hadoop.fs.TestDFSIO.main(TestDFSIO.java:445)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)"
MAPREDUCE-3106,"Replacing Mapper with MultithreadedMapper causes the job to crash with ""Type mismatch in key from map"" ","I have a hadoop job, which works perfectly fine when done with a class implementing Mapper. When I do replace Mapper with MultithreadMapper, the job crashes with following message:

java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.IntWritable, recieved org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:862)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:549)
	at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
	at org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$SubMapRecordWriter.write(MultithreadedMapper.java:211)
	at org.apache.hadoop.mapreduce.TaskInputOutputContext.write(TaskInputOutputContext.java:80)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)
	at org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper$MapRunner.run(MultithreadedMapper.java:264)

Here are the relevant source codes:

public class MapReduceMain {

	/**
	 * @param args
	 */
	public static void main(String[] args) {
		try {
			if (args.length != 2) {
				System.err.println(""Usage: MapReduceMain <input path> <output path>"");
				System.exit(123);
			}
			Job job = new Job();
			job.setJarByClass(MapReduceMain.class);
			job.setInputFormatClass(TextInputFormat.class);
			FileSystem fs = FileSystem.get(URI.create(args[0]), job.getConfiguration());
			FileStatus[] files = fs.listStatus(new Path(args[0]));
			for(FileStatus sfs:files){
				FileInputFormat.addInputPath(job, sfs.getPath());
			}
			FileOutputFormat.setOutputPath(job, new Path(args[1]));
			
			job.setMapperClass(MyMultithreadMapper.class);
			job.setReducerClass(MyReducer.class);
			MultithreadedMapper.setNumberOfThreads(job, MyMultithreadMapper.nThreads);

			job.setOutputKeyClass(IntWritable.class); 
			job.setOutputValueClass(MyPage.class);
			
			job.setOutputFormatClass(SequenceFileOutputFormat.class);
			
			System.exit(job.waitForCompletion(true) ? 0 : 1);
		} catch (Exception e) {
			e.printStackTrace();
		}

	}


public class MyMultithreadMapper extends MultithreadedMapper<LongWritable, Text, IntWritable, MyPage> {

	ConcurrentLinkedQueue<MyScraper>	scrapers	= new ConcurrentLinkedQueue<MyScraper>();

	public static final int				nThreads	= 5;

	public VrboMultithreadMapper() {
		for (int i = 0; i < nThreads; i++) {
			scrapers.add(new MyScraper());
		}
	}

	public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		MyScraper scraper = scrapers.poll();

		MyPage result = null;
		for (int i = 0; i < 10; i++) {
			try {
				result = scraper.scrapPage(value.toString(), true);
				break;
			} catch (Exception e) {
				e.printStackTrace();
			}
		}

		if (result == null) {
			result = new MyPage();
			result.setUrl(key.toString());
		}

		context.write(new IntWritable(result.getUrl().hashCode()), result);

		scrapers.add(scraper);
	}
}


and here's the code for the working mapper class, just to be sure:

public class MyMapper extends Mapper<LongWritable, Text, IntWritable,MyPage> {
	MyScraper scr = new MyScraper();
	
	public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
		MyPage result =null;
		for(int i=0;i<10;i++){
			try{
				result = scr.scrapPage(value.toString(), true);
				break;
			}catch(Exception e){
				e.printStackTrace();
			}
		}
		
		if(result==null){
			result = new MyPage();
			result.setUrl(key.toString());
		}
		
		context.write(new IntWritable(result.getUrl().hashCode()),result);
	}
}


This appears to be a hadoop bug"
MAPREDUCE-3105,NM<->RM shared secrets should be rolled every so often. ,
MAPREDUCE-3104,"Implement Application ACLs, Queue ACLs and their interaction",
MAPREDUCE-3103,Implement Job ACLs for MRAppMaster,
MAPREDUCE-3102,NodeManager should fail fast with wrong configuration or permissions for LinuxContainerExecutor,
MAPREDUCE-3101,[Umbrella] Security issues in YARN,Most of the chassis for security in YARN is set up and is working. There are known bugs and security holes though. This JIRA is an umbrella ticket for tracking those.
MAPREDUCE-3100,distcp with an hftp destination url fails if the destination directory does not exist,"bash-3.2$ bin/hadoop --config HADOOP_CONF_DIR distcp -i hftp://NN_HOST:50070/input_path  hftp://NN_HOST:50070/output_path
11/09/27 04:36:01 INFO tools.DistCp: srcPaths=[hftp://hftp://NN_HOST:50070/input_path]
11/09/27 04:36:01 INFO tools.DistCp: destPath=hftp://hftp://NN_HOST:50070/output_path
11/09/27 04:36:02 INFO tools.DistCp: hftp://hftp://NN_HOST:50070/output_path does not exist.
With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.IOException: Not supported
        at org.apache.hadoop.hdfs.HftpFileSystem.mkdirs(HftpFileSystem.java:558)
        at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1066)
        at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1170)
        at org.apache.hadoop.tools.DistCp.copy(DistCp.java:666)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:881)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:908)


The same command works if instead of hftp default filesystem (hdfs) is used. It creates the dir if it does not exist. We should do the same for hftp. I also suspect that we have this issue with webhdfs."
MAPREDUCE-3099,Add docs for setting up a single node MRv2 cluster.,
MAPREDUCE-3098,Report Application status as well as ApplicationMaster status in GetApplicationReportResponse ,"Currently, an application report received by the client from the RM/ASM for a given application returns the status of the application master. It does not return the status of the application i.e. whether that particular job succeeded or failed. 

The AM status would be one of FINISHED (SUCCEEDED should be renamed to FINISHED as AM state does not indicate overall success/failure), FAILED or KILLED. 
The final state sent by the AM to the RM in the FinishApplicationMasterRequest should be exposed to the client as ApplicationState. 
"
MAPREDUCE-3096,Add a good way to control the number of map/reduce tasks per node,"Currently, controlling the number of map/reduce tasks is a hell.

I've tried for it many times, and it doesn't work right. Also, I am not the only one person, who seems to have this problem.

There must be a better way to do it.

Here's my proposal:

add following functions to Job:
setNumberOfMappersPerNode(int);
setNumberOfReducersPerNode(int);
setMaxMemoryPerMapper(int);
setMaxMemoryPerReducer(int);"
MAPREDUCE-3095,fairscheduler ivy including wrong version for hdfs,fairscheduler ivy.xml includes the common version for hdfs dependency. This could break builds that have different common and hdfs version numbers. The reason we dont see it on the jenkins build is because we use the same version number for common and hdfs.
MAPREDUCE-3094,org.apache.hadoop.streaming.TestUlimit.testCommandLine fails intermittantly in 20.205.0,"11/09/24 00:22:10 INFO mapred.TaskInProgress: Error from attempt_20110924002157563_0001_m_000000_0: java.lang.RuntimeException: PipeMapRed.waitOutputThreads(): subprocess failed with code 134
	at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:311)
	at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:545)
	at org.apache.hadoop.streaming.PipeMapper.close(PipeMapper.java:132)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:57)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:36)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
	at org.apache.hadoop.mapred.Child$4.run(Child.java:261)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
	at org.apache.hadoop.mapred.Child.main(Child.java:255)"
MAPREDUCE-3092,Remove JOB_ID_COMPARATOR usage in JobHistory.java,"As part of the defect MAPREDUCE-2965, JobId.compareTo() has been implemented. Usage of JOB_ID_COMPARATOR in JobHistory.java can be removed because comparison is handling by JobId itself. 
 

"
MAPREDUCE-3090,"Change MR AM to use ApplicationAttemptId rather than <applicationId, startCount> everywhere","Change MR AM to use ApplicationAttemptId rather than <applicationId, startCount> everywhere, particularly after MAPREDUCE-3055"
MAPREDUCE-3088,Clover 2.4.3 breaks build for 0.22 branch,Due to known bug in Clover 2.4.3 build for 0.22 branch is broken.
MAPREDUCE-3087,CLASSPATH not the same after MAPREDUCE-2880,"After MAPREDUCE-2880, my classpath was missing key jar files. "
MAPREDUCE-3085,Fix / remove failing tests from MrV1,"30 failures. Most related to 
{code}
Error Message

Invalid ""mapreduce.jobtracker.address"" configuration value for JobTracker: ""local""

Stacktrace

java.io.IOException: Invalid ""mapreduce.jobtracker.address"" configuration value for JobTracker: ""local""
	at org.apache.hadoop.mapred.JobTrackerClientProtocolProvider.create(JobTrackerClientProtocolProvider.java:47)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:74)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:459)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:438)
	at org.apache.hadoop.mapred.TestComparators.configure(TestComparators.java:332)
	at org.apache.hadoop.mapred.TestComparators.testDefaultMRComparator(TestComparators.java:341)
{code}
https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/963/#showFailuresLink

Tests like TestTaskTrackerBlackListing, which aren't relevant can probably be removed."
MAPREDUCE-3084,race when KILL_CONTAINER is received for a LOCALIZED container,"Depending on when ContainersLaunch starts a container, {{KILL_CONTAINER}} when container state is {{LOCALIZED}} ({{LAUNCH_CONTAINER}} event already sent) can end up generating a {{CONTAINER_LAUNCHED}} event - which isn't handled by ContainerState: {{KILLING}}. Also, the launched container won't be killed since {{CLEANUP_CONTAINER}} would have already been processed."
MAPREDUCE-3082,archive command take wrong path for input file with current directory,"$hadoop dfs -copyFromLocal /etc/passwd .
$hadoop dfs -lsr .
-rw-------   3 hadoopqa hdfs       6883 2011-09-23 22:37 /user/hadoopqa/passwd
$hadoop archive -archiveName test1.har -p .  passwd .
11/09/23 22:39:22 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 4 for hadoopqa
11/09/23 22:39:22 INFO security.TokenCache: Got dt for
hdfs://<NN host>/user/hadoopqa/.staging/job_201109232234_0004;uri=<NN IP>:8020;t.service=<NN IP>:8020
11/09/23 22:39:22 INFO mapred.JobClient: Running job: job_201109232234_0004
11/09/23 22:39:23 INFO mapred.JobClient:  map 0% reduce 0%
11/09/23 22:39:34 INFO mapred.JobClient: Task Id : attempt_201109232234_0004_m_000000_0, Status : FAILED
java.io.FileNotFoundException: File does not exist: hdfs://<NN host>/user/hadoopqa/hadoopqa/passwd
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:525)
        at org.apache.hadoop.tools.HadoopArchives$HArchivesMapper.map(HadoopArchives.java:697)
        at org.apache.hadoop.tools.HadoopArchives$HArchivesMapper.map(HadoopArchives.java:587)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:436)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:372)
        at org.apache.hadoop.mapred.Child$4.run(Child.java:261)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
        at org.apache.hadoop.mapred.Child.main(Child.java:255)

So Archiving is failing as it was finding input file at /user/hadoopqa/hadoopqa/passwd , whereas it should look for /user/hadoopqa/passwd"
MAPREDUCE-3081,Change the name format for hadoop core and vaidya jar to be hadoop-{core/vaidya}-{version}.jar in vaidya.sh,Vaidya script is broken due to change in the naming convention for hadoop core jar and vaidya jar. 
MAPREDUCE-3079,usercache/<user>/appcache/<appid> directory not removed when using DefaultContainerExecutor,"Running with the DefaultContainerExecutor it appears that the usercache/<user>/appcache/<appid> directory itself is not removed when the app finishes.  All the directories under it are properly removed though.

The nodemanager log file indicates that it tries to delete it:
11/09/23 15:17:56 INFO nodemanager.DefaultContainerExecutor: Deleting absolute path : /home/hadoop/mapred/tmp/mapred-local/usercache/tgraves/appcache/application_1316722920862_0003

This doesn't appear to happen with the LinuxContainerExecutor."
MAPREDUCE-3078,Application's progress isn't updated from AM to RM.,"It helps to be able to monitor the application-progress from the RM UI itself.

Bits of it is already there, even the AM-RM API (in AllocateRequest). We just need to make sure the progress is produced and consumed properly."
MAPREDUCE-3076,TestSleepJob fails ,"TestSleepJob fails, it was intended to be used in other tests for MAPREDUCE-2981."
MAPREDUCE-3073,Build failure for MRv1 caused due to changes to MRConstants.,"When runnning ant -Dresolvers=internal binary, the build seems to be failing with:

  [javac] public class JobTracker implements MRConstants,
InterTrackerProtocol,
   [javac]                                    ^
   [javac] 
/home/y/var/builds/thread2/workspace/Cloud-Yarn-0.23-Secondary/hadoop-mapred
uce-project/src/java/org/apache/hadoop/mapred/TaskTracker.java:131:
interface expected here
   [javac]     implements MRConstants, TaskUmbilicalProtocol, Runnable,
TTConfig {
   [javac]                ^
   [javac] 
/home/y/var/builds/thread2/workspace/Cloud-Yarn-0.23-Secondary/hadoop-mapred
uce-project/src/java/org/apache/hadoop/mapred/TaskTracker.java:552: cannot
find symbol
   [javac] symbol  : variable WORKDIR
   [javac] location: class org.apache.hadoop.mapred.MRConstants
   [javac]     return getLocalJobDir(user, jobid) + Path.SEPARATOR +
MRConstants.WORKDIR;
   [javac]        
^
"
MAPREDUCE-3072,NodeManager doesn't recognize kill -9 of AM container,"If I kill -9 my application master's pid, the NM continues reporting that the container is running. I assume it should probably instead report back to the RM that the AM has died. Instead, it continues sending this status:


2011-09-22 09:33:13,352 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:getNodeStatus(222)) - Sending out status for container: container_id {, app_attempt_id {, application_id {, id: 1, cluster_timestamp: 1316707951832, }, attemptId: 1, }, id: 1, }, state: C_RUNNING, diagnostics: ""\n"", exit_status: -1000, 

2011-09-22 09:33:13,682 INFO  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(402)) - Memory usage of ProcessTree 27263 for container-id container_1316707951832_0001_01_000001 : Virtual 0 bytes, limit : 2147483648 bytes; Physical 0 bytes, limit -1 bytes

This status keeps being sent forever."
MAPREDUCE-3071,app master configuration web UI link under the Job menu opens up application menu,"If you go to the app master web UI for a particular job. The job menu on the left side displays links for overview, counters, configuration, etc..

If you click on the configuration one, it closes the job menu and opens the application menu on that left side. It shouldn't do this. It should leave the job menu open.
"
MAPREDUCE-3070,NM not able to register with RM after NM restart,"After stopping NM gracefully then starting NM, NM registration fails with RM with Duplicate registration from the node! error.


{noformat} 
2011-09-23 01:50:46,705 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager
org.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)
Caused by: org.apache.avro.AvroRuntimeException: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	... 2 more
Caused by: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: Duplicate registration from the node!
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:142)
	at $Proxy13.registerNodeManager(Unknown Source)
	at org.apache.hadoop.yarn.server.api.impl.pb.client.ResourceTrackerPBClientImpl.registerNodeManager(ResourceTrackerPBClientImpl.java:59)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:175)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)
	... 3 more
{noformat} 
"
MAPREDUCE-3068,Should set MALLOC_ARENA_MAX for all YARN daemons and AMs/Containers,"This is same as HADOOP-7154 but for yarn. RM, NM, AM and containers should all have this."
MAPREDUCE-3067,Container exit status not set properly to launched process's exit code on successful completion of process,"When testing the distributed shell sample app master, the container exit status was being returned incorrectly. 

11/09/21 11:32:58 INFO DistributedShell.ApplicationMaster: Got container status for containerID= container_1316629955324_0001_01_000002, state=COMPLETE, exitStatus=-1000, diagnostics="
MAPREDUCE-3066,YARN NM fails to start,"Please check conf.get() calls. Every time I svn up, I get one of these.


2011-09-21 15:36:33,534 INFO  service.AbstractService (AbstractService.java:stop(71)) - Service:org.apache.hadoop.yarn.server.nodemanager.DeletionService is stopped.
2011-09-21 15:36:33,534 FATAL nodemanager.NodeManager (NodeManager.java:main(204)) - Error starting NodeManager
org.apache.hadoop.yarn.YarnException: Failed to Start org.apache.hadoop.yarn.server.nodemanager.NodeManager
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:78)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.start(NodeManager.java:153)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:202)
Caused by: org.apache.avro.AvroRuntimeException: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:141)
	at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
	... 2 more
Caused by: java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.resource-tracker.address
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getRMClient(NodeStatusUpdaterImpl.java:154)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.registerWithRM(NodeStatusUpdaterImpl.java:164)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.start(NodeStatusUpdaterImpl.java:137)
	... 3 more
2011-09-21 15:36:33,535 INFO  service.CompositeService (CompositeService.java:stop(97)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl
java.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED
	at org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)
	at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)
	at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.stop(NodeStatusUpdaterImpl.java:149)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:95)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:85)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)
2011-09-21 15:36:33,535 INFO  nodemanager.NodeManager (StringUtils.java:run(605)) - SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NodeManager at criccomi-ld/127.0.0.1
************************************************************/
2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 45454
2011-09-21 15:36:33,536 INFO  logaggregation.LogAggregationService (LogAggregationService.java:stop(116)) - org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService waiting for pending aggregation during exit
2011-09-21 15:36:33,536 INFO  ipc.Server (Server.java:stop(1708)) - Stopping server on 4344
2011-09-21 15:36:33,536 INFO  service.CompositeService (CompositeService.java:run(120)) - Error stopping org.apache.hadoop.yarn.server.nodemanager.NodeManager
java.lang.IllegalStateException: For this operation, current State must be STARTED instead of INITED
	at org.apache.hadoop.yarn.service.AbstractService.ensureCurrentState(AbstractService.java:101)
	at org.apache.hadoop.yarn.service.AbstractService.stop(AbstractService.java:69)
	at org.apache.hadoop.yarn.service.CompositeService.stop(CompositeService.java:87)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.stop(NodeManager.java:158)
	at org.apache.hadoop.yarn.service.CompositeService$CompositeServiceShutdownHook.run(CompositeService.java:118)
"
MAPREDUCE-3065,ApplicationMaster killed by NodeManager due to excessive virtual memory consumption,"> Hey Vinod,
> 
> OK, so I have a little more clarity into this.
> 
> When I bump my resource request for my AM to 4096, it runs. The important line in the NM logs is:
> 
> 2011-09-21 13:43:44,366 INFO  monitor.ContainersMonitorImpl (ContainersMonitorImpl.java:run(402)) - Memory usage of ProcessTree 25656 for container-id container_1316637655278_0001_01_000001 : Virtual 2260938752 bytes, limit : 4294967296 bytes; Physical 120860672 bytes, limit -1 bytes
> 
> The thing to note is the virtual memory, which is off the charts, even though my physical memory is almost nothing (12 megs). I'm still poking around the code, but I am noticing that there are two checks in the NM, one for virtual mem, and one for physical mem. The virtual memory check appears to be toggle-able, but is presumably defaulted to on.
> 
> At this point I'm trying to figure out exactly what the VMEM check is for, why YARN thinks my app is taking 2 gigs, and how to fix this.
> 
> Cheers,
> Chris
> ________________________________________
> From: Chris Riccomini [criccomini@linkedin.com]
> Sent: Wednesday, September 21, 2011 1:42 PM
> To: mapreduce-dev@hadoop.apache.org
> Subject: Re: ApplicationMaster Memory Usage
> 
> For the record, I bumped to 4096 for memory resource request, and it works.
> :(
> 
> 
> On 9/21/11 1:32 PM, ""Chris Riccomini"" <criccomini@linkedin.com> wrote:
> 
>> Hey Vinod,
>> 
>> So, I ran my application master directly from the CLI. I commented out the
>> YARN-specific code. It runs fine without leaking memory.
>> 
>> I then ran it from YARN, with all YARN-specific code commented it. It again
>> ran fine.
>> 
>> I then uncommented JUST my registerWithResourceManager call. It then fails
>> with OOM after a few seconds. I call registerWithResourceManager, and then go
>> into a while(true) { println(""yeh"") sleep(1000) }. Doing this prints:
>> 
>> yeh
>> yeh
>> yeh
>> yeh
>> yeh
>> 
>> At which point, it dies, and, in the NodeManager,I see:
>> 
>> 2011-09-21 13:24:51,036 WARN  monitor.ContainersMonitorImpl
>> (ContainersMonitorImpl.java:isProcessTreeOverLimit(289)) - Process tree for
>> container: container_1316626117280_0005_01_000001 has processes older than 1
>> iteration running over the configured limit. Limit=2147483648, current usage =
>> 2192773120
>> 2011-09-21 13:24:51,037 WARN  monitor.ContainersMonitorImpl
>> (ContainersMonitorImpl.java:run(453)) - Container
>> [pid=23852,containerID=container_1316626117280_0005_01_000001] is running
>> beyond memory-limits. Current usage : 2192773120bytes. Limit :
>> 2147483648bytes. Killing container.
>> Dump of the process-tree for container_1316626117280_0005_01_000001 :
>> |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS)
>> VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
>> |- 23852 20570 23852 23852 (bash) 0 0 108638208 303 /bin/bash -c java -Xmx512M
>> -cp './package/*' kafka.yarn.ApplicationMaster
>> /home/criccomi/git/kafka-yarn/dist/kafka-streamer.tgz 5 1 1316626117280
>> com.linkedin.TODO 1
>> 1>/tmp/logs/application_1316626117280_0005/container_1316626117280_0005_01_000
>> 001/stdout
>> 2>/tmp/logs/application_1316626117280_0005/container_1316626117280_0005_01_000
>> 001/stderr
>> |- 23855 23852 23852 23852 (java) 81 4 2084134912 14772 java -Xmx512M -cp
>> ./package/* kafka.yarn.ApplicationMaster
>> /home/criccomi/git/kafka-yarn/dist/kafka-streamer.tgz 5 1 1316626117280
>> com.linkedin.TODO 1
>> 2011-09-21 13:24:51,037 INFO  monitor.ContainersMonitorImpl
>> (ContainersMonitorImpl.java:run(463)) - Removed ProcessTree with root 23852
>> 
>> Either something is leaking in YARN, or my registerWithResourceManager code
>> (see below) is doing something funky.
>> 
>> I'm trying to avoid going through all the pain of attaching a remote debugger.
>> Presumably things aren't leaking in YARN, which means it's likely that I'm
>> doing something wrong in my registration code.
>> 
>> Incidentally, my NodeManager is running with 1000 megs. My application master
>> memory is set to 2048, and my -Xmx setting is 512M
>> 
>> Cheers,
>> Chris
>> ________________________________________
>> From: Vinod Kumar Vavilapalli [vinodkv@hortonworks.com]
>> Sent: Wednesday, September 21, 2011 11:52 AM
>> To: mapreduce-dev@hadoop.apache.org
>> Subject: Re: ApplicationMaster Memory Usage
>> 
>> Actually MAPREDUCE-2998 is only related to MRV2, so that isn't related.
>> 
>> Somehow, your JVM itself is taking so much of virtual memory. Are you
>> loading some native libs?
>> 
>> And how many containers have already been allocated by the time the AM
>> crashes. May be you are accumulating some per-container data. You can try
>> dumping heap vai hprof.
>> 
>> +Vinod
>> 
>> 
>> On Wed, Sep 21, 2011 at 11:21 PM, Chris Riccomini
>> <criccomini@linkedin.com>wrote:
>> 
>>> Hey Vinod,
>>> 
>>> I svn up'd, and rebuilt. My application's task (container) now runs!
>>> 
>>> Unfortunately, my application master eventually gets killed by the
>>> NodeManager anyway, and I'm still not clear as to why. The AM is just
>>> running a loop, asking for a container, and executing a command in the
>>> container. It keeps doing this over and over again. After a few iterations,
>>> it gets killed with something like:
>>> 
>>> 2011-09-21 10:42:40,869 INFO  monitor.ContainersMonitorImpl
>>> (ContainersMonitorImpl.java:run(402)) - Memory usage of ProcessTree 21666
>>> for container-id container_1316626117280_0002_01_000001 : Virtual 2260938752
>>> bytes, limit : 2147483648 bytes; Physical 77398016 bytes, limit -1 bytes
>>> 2011-09-21 10:42:40,869 WARN  monitor.ContainersMonitorImpl
>>> (ContainersMonitorImpl.java:isProcessTreeOverLimit(289)) - Process tree for
>>> container: container_1316626117280_0002_01_000001 has processes older than 1
>>> iteration running over the configured limit. Limit=2147483648, current usage
>>> = 2260938752
>>> 2011-09-21 10:42:40,870 WARN  monitor.ContainersMonitorImpl
>>> (ContainersMonitorImpl.java:run(453)) - Container
>>> [pid=21666,containerID=container_1316626117280_0002_01_000001] is running
>>> beyond memory-limits. Current usage : 2260938752bytes. Limit :
>>> 2147483648bytes. Killing container.
>>> Dump of the process-tree for container_1316626117280_0002_01_000001 :
>>>        |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS)
>>> SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
>>>        |- 21669 21666 21666 21666 (java) 105 4 2152300544 18593 java
>>> -Xmx512M -cp ./package/* kafka.yarn.ApplicationMaster
>>> /home/criccomi/git/kafka-yarn/dist/kafka-streamer.tgz 2 1 1316626117280
>>> com.linkedin.TODO 1
>>>       |- 21666 20570 21666 21666 (bash) 0 0 108638208 303 /bin/bash -c
>>> java -Xmx512M -cp './package/*' kafka.yarn.ApplicationMaster
>>> /home/criccomi/git/kafka-yarn/dist/kafka-streamer.tgz 2 1 1316626117280
>>> com.linkedin.TODO 1
>>> 1>/tmp/logs/application_1316626117280_0002/container_1316626117280_0002_01_00
>>> 0001/stdout
>>> 2>/tmp/logs/application_1316626117280_0002/container_1316626117280_0002_01_00
>>> 0001/stderr
>>> 
>>> 2011-09-21 10:42:40,870 INFO  monitor.ContainersMonitorImpl
>>> (ContainersMonitorImpl.java:run(463)) - Removed ProcessTree with root 21666
>>> 
>>> I don't think that my AM is leaking memory. Full code paste after the break
>>> 
>>> 1. Do I need to release a container in my AM even if the AM receives it as
>>> a finished container in the resource request response?
>>> 2. Do I need to free any other resources after a resource request (e.g.
>>> ResourceRequest, AllocateRequest, etc)?
>>> 
>>> Cheers,
>>> Chris
>>> 
>>> 
>>> def main(args: Array[String]) {
>>>   // YARN will always give our ApplicationMaster
>>>   // the first four parameters as: <package> <app id> <attempt id>
>>> <timestamp>
>>>   val packagePath = args(0)
>>>   val appId = args(1).toInt
>>>   val attemptId = args(2).toInt
>>>   val timestamp = args(3).toLong
>>> 
>>>   // these are our application master's parameters
>>>   val streamerClass = args(4)
>>>   val tasks = args(5).toInt
>>> 
>>>   // TODO log params here
>>> 
>>>   // start the application master helper
>>>   val conf = new Configuration
>>>   val applicationMasterHelper = new ApplicationMasterHelper(appId,
>>> attemptId, timestamp, conf)
>>>     .registerWithResourceManager
>>> 
>>>   // start and manage the slaves
>>>   val noReleases = List[ContainerId]()
>>>   var runningContainers = 0
>>> 
>>>   // keep going forever
>>>   while (true) {
>>>     val nonRunningTasks = tasks - runningContainers
>>>     val response =
>>> applicationMasterHelper.sendResourceRequest(nonRunningTasks, noReleases)
>>> 
>>>     response.getAllocatedContainers.foreach(container => {
>>>       new ContainerExecutor(packagePath, container)
>>>         .addCommand(""java -Xmx256M -cp './package/*'
>>> kafka.yarn.StreamingTask "" + streamerClass + "" ""
>>>           + ""1>"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + ""/stdout ""
>>>           + ""2>"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR +
>>> ""/stderr"").execute(conf)
>>>     })
>>> 
>>>     runningContainers += response.getAllocatedContainers.length
>>>     runningContainers -= response.getCompletedContainersStatuses.length
>>> 
>>>     Thread.sleep(1000)
>>>   }
>>> 
>>>   applicationMasterHelper.unregisterWithResourceManager(""SUCCESS"")
>>> }
>>> 
>>> 
>>> class ApplicationMasterHelper(iAppId: Int, iAppAttemptId: Int, lTimestamp:
>>> Long, conf: Configuration) {
>>> val rpc = YarnRPC.create(conf)
>>> val appId = Records.newRecord(classOf[ApplicationId])
>>> val appAttemptId = Records.newRecord(classOf[ApplicationAttemptId])
>>> val rmAddress =
>>> NetUtils.createSocketAddr(conf.get(YarnConfiguration.RM_SCHEDULER_ADDRESS,
>>> YarnConfiguration.DEFAULT_RM_SCHEDULER_ADDRESS))
>>> val resourceManager = rpc.getProxy(classOf[AMRMProtocol], rmAddress,
>>> conf).asInstanceOf[AMRMProtocol]
>>> var requestId = 0
>>> 
>>> appId.setClusterTimestamp(lTimestamp)
>>> appId.setId(iAppId)
>>> appAttemptId.setApplicationId(appId)
>>> appAttemptId.setAttemptId(iAppAttemptId)
>>> 
>>> def registerWithResourceManager(): ApplicationMasterHelper = {
>>>   val req = Records.newRecord(classOf[RegisterApplicationMasterRequest])
>>>   req.setApplicationAttemptId(appAttemptId)
>>>   // TODO not sure why these are blank- This is how spark does it
>>>   req.setHost("""")
>>>   req.setRpcPort(1)
>>>   req.setTrackingUrl("""")
>>>   resourceManager.registerApplicationMaster(req)
>>>   this
>>> }
>>> 
>>> def unregisterWithResourceManager(state: String): ApplicationMasterHelper
>>> = {
>>>   val finReq = Records.newRecord(classOf[FinishApplicationMasterRequest])
>>>   finReq.setAppAttemptId(appAttemptId)
>>>   finReq.setFinalState(state)
>>>   resourceManager.finishApplicationMaster(finReq)
>>>   this
>>> }
>>> 
>>> def sendResourceRequest(containers: Int, release: List[ContainerId]):
>>> AMResponse = {
>>>   // TODO will need to make this more flexible for hostname requests, etc
>>>   val request = Records.newRecord(classOf[ResourceRequest])
>>>   val pri = Records.newRecord(classOf[Priority])
>>>   val capability = Records.newRecord(classOf[Resource])
>>>   val req = Records.newRecord(classOf[AllocateRequest])
>>>   request.setHostName(""*"")
>>>   request.setNumContainers(containers)
>>>   pri.setPriority(1)
>>>   request.setPriority(pri)
>>>   capability.setMemory(128)
>>>   request.setCapability(capability)
>>>   req.setResponseId(requestId)
>>>   req.setApplicationAttemptId(appAttemptId)
>>>   req.addAllAsks(Lists.newArrayList(request))
>>>   req.addAllReleases(release)
>>>   requestId += 1
>>>   // TODO we might want to return a list of container executors here
>>> instead of AMResponses
>>>   resourceManager.allocate(req).getAMResponse
>>> }
>>> }
>>> 
>>> 
>>> ________________________________________
>>> From: Vinod Kumar Vavilapalli [vinodkv@hortonworks.com]
>>> Sent: Wednesday, September 21, 2011 10:08 AM
>>> To: mapreduce-dev@hadoop.apache.org
>>> Subject: Re: ApplicationMaster Memory Usage
>>> 
>>> Yes, the process-dump clearly tells that this is MAPREDUCE-2998.
>>> 
>>> +Vinod
>>> (With a smirk to see his container-memory-monitoring code in action)
>>> 
>>> 
>>> On Wed, Sep 21, 2011 at 10:26 PM, Arun C Murthy <acm@hortonworks.com>
>>> wrote:
>>> 
>>>> I'll bet you are hitting MR-2998.
>>>> 
>>>> From the changelog:
>>>> 
>>>>   MAPREDUCE-2998. Fixed a bug in TaskAttemptImpl which caused it to fork
>>>> bin/mapred too many times. Contributed by Vinod K V.
>>>> 
>>>> Arun
>>>> 
>>>> On Sep 21, 2011, at 9:52 AM, Chris Riccomini wrote:
>>>> 
>>>>> Hey Guys,
>>>>> 
>>>>> My ApplicationMaster is being killed by the NodeManager because of
>>> memory
>>>> consumption, and I don't understand why. I'm using -Xmx512M, and setting
>>> my
>>>> resource request to 2048.
>>>>> 
>>>>> 
>>>>>   .addCommand(""java -Xmx512M -cp './package/*'
>>>> kafka.yarn.ApplicationMaster "" ...
>>>>> 
>>>>>   ...
>>>>> 
>>>>>   private var memory = 2048
>>>>> 
>>>>>   resource.setMemory(memory)
>>>>>   containerCtx.setResource(resource)
>>>>>   containerCtx.setCommands(cmds.toList)
>>>>>   containerCtx.setLocalResources(Collections.singletonMap(""package"",
>>>> packageResource))
>>>>>   appCtx.setApplicationId(appId)
>>>>>   appCtx.setUser(user.getShortUserName)
>>>>>   appCtx.setAMContainerSpec(containerCtx)
>>>>>   request.setApplicationSubmissionContext(appCtx)
>>>>>   applicationsManager.submitApplication(request)
>>>>> 
>>>>> When this runs, I see (in my NodeManager's logs):
>>>>> 
>>>>> 
>>>>> 2011-09-21 09:35:19,112 INFO  monitor.ContainersMonitorImpl
>>>> (ContainersMonitorImpl.java:run(402)) - Memory usage of ProcessTree 28134
>>>> for container-id container_1316559026783_0003_01_000001 : Virtual
>>> 2260938752
>>>> bytes, limit : 2147483648 bytes; Physical 71540736 bytes, limit -1 bytes
>>>>> 2011-09-21 09:35:19,112 WARN  monitor.ContainersMonitorImpl
>>>> (ContainersMonitorImpl.java:isProcessTreeOverLimit(289)) - Process tree
>>> for
>>>> container: container_1316559026783_0003_01_000001 has processes older
>>> than 1
>>>> iteration running over the configured limit. Limit=2147483648, current
>>> usage
>>>> = 2260938752
>>>>> 2011-09-21 09:35:19,113 WARN  monitor.ContainersMonitorImpl
>>>> (ContainersMonitorImpl.java:run(453)) - Container
>>>> [pid=28134,containerID=container_1316559026783_0003_01_000001] is running
>>>> beyond memory-limits. Current usage : 2260938752bytes. Limit :
>>>> 2147483648bytes. Killing container.
>>>>> Dump of the process-tree for container_1316559026783_0003_01_000001 :
>>>>>      |- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS)
>>>> SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
>>>>>      |- 28134 25886 28134 28134 (bash) 0 0 108638208 303 /bin/bash -c
>>>> java -Xmx512M -cp './package/*' kafka.yarn.ApplicationMaster 3 1
>>>> 1316559026783 com.linkedin.TODO 1
>>>> 
>>> 1>/tmp/logs/application_1316559026783_0003/container_1316559026783_0003_01_00
>>> 0001/stdout
>>>> 
>>> 2>/tmp/logs/application_1316559026783_0003/container_1316559026783_0003_01_00
>>> 0001/stderr
>>>>>      |- 28137 28134 28134 28134 (java) 92 3 2152300544 17163 java
>>>> -Xmx512M -cp ./package/* kafka.yarn.ApplicationMaster 3 1 1316559026783
>>>> com.linkedin.TODO 1
>>>>> 
>>>>> 2011-09-21 09:35:19,113 INFO  monitor.ContainersMonitorImpl
>>>> (ContainersMonitorImpl.java:run(463)) - Removed ProcessTree with root
>>> 28134
>>>>> 
>>>>> It appears that YARN is honoring my 2048 command, yet my process is
>>>> somehow taking 2260938752 bytes. I don't think that I'm using nearly that
>>>> much in permgen, and my heap is limited to 512. I don't have any JNI
>>> stuff
>>>> running (that I know of), so it's unclear to me what's going on here. The
>>>> only thing that I can think of is that Java's Runtime exec is forking,
>>> and
>>>> copying its entire JVM memory footprint for the fork.
>>>>> 
>>>>> Has anyone seen this? Am I doing something dumb?
>>>>> 
>>>>> Thanks!
>>>>> Chris
>>>> 
>>>> 
>>> 
> 
"
MAPREDUCE-3064,"27 unit test failures with  Invalid ""mapreduce.jobtracker.address"" configuration value for JobTracker: ""local""","unit test failure here: https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/946/

	Test Result (27 failures / +27)

    org.apache.hadoop.mapred.TestCollect.testCollect
    org.apache.hadoop.mapred.TestComparators.testDefaultMRComparator
    org.apache.hadoop.mapred.TestComparators.testUserMRComparator
    org.apache.hadoop.mapred.TestComparators.testUserValueGroupingComparator
    org.apache.hadoop.mapred.TestComparators.testAllUserComparators
    org.apache.hadoop.mapred.TestFileOutputFormat.testCustomFile
    org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob
    org.apache.hadoop.mapred.TestJavaSerialization.testWriteToSequencefile
    org.apache.hadoop.mapred.TestMapOutputType.testKeyMismatch
    org.apache.hadoop.mapred.TestMapOutputType.testValueMismatch
    org.apache.hadoop.mapred.TestMapOutputType.testNoMismatch
    org.apache.hadoop.mapred.TestMapRed.testMapred
    org.apache.hadoop.mapred.TestMapRed.testNullKeys
    org.apache.hadoop.mapred.TestMapRed.testCompression
    org.apache.hadoop.mapred.TestMapRed.testSmallInput
    org.apache.hadoop.mapred.TestMapRed.testBiggerInput
    org.apache.hadoop.mapreduce.TestMapCollection.testValLastByte
    org.apache.hadoop.mapreduce.TestMapCollection.testLargeRecords
    org.apache.hadoop.mapreduce.TestMapCollection.testSpillPer2B
    org.apache.hadoop.mapreduce.TestMapCollection.testZeroVal
    org.apache.hadoop.mapreduce.TestMapCollection.testSingleRecord
    org.apache.hadoop.mapreduce.TestMapCollection.testLowSpill
    org.apache.hadoop.mapreduce.TestMapCollection.testSplitMetaSpill
    org.apache.hadoop.mapreduce.TestMapCollection.testPostSpillMeta
    org.apache.hadoop.mapreduce.TestMapCollection.testLargeRecConcurrent
    org.apache.hadoop.mapreduce.TestMapCollection.testRandom
    org.apache.hadoop.mapreduce.TestMapCollection.testRandomCompress


All of them have similar stack traces of:

java.io.IOException: Invalid ""mapreduce.jobtracker.address"" configuration value for JobTracker: ""local""
	at org.apache.hadoop.mapred.JobTrackerClientProtocolProvider.create(JobTrackerClientProtocolProvider.java:47)
	at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:74)
	at org.apache.hadoop.mapred.JobClient.init(JobClient.java:459)
	at org.apache.hadoop.mapred.JobClient.<init>(JobClient.java:438)
	at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:777)
	at org.apache.hadoop.mapred.TestCollect.testCollect(TestCollect.java:133)"
MAPREDUCE-3063,Mapreduce trunk Commit builds are failing,"Mapreduce trunk commit builds are failing due to test failures. 
See https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/946/testReport/ for more details."
MAPREDUCE-3062,YARN NM/RM fail to start,"2011-09-21 10:21:41,932 FATAL resourcemanager.ResourceManager (ResourceManager.java:main(502)) - Error starting ResourceManager
java.lang.RuntimeException: Not a host:port pair: yarn.resourcemanager.admin.address
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.yarn.server.resourcemanager.AdminService.init(AdminService.java:88)
	at org.apache.hadoop.yarn.service.CompositeService.init(CompositeService.java:58)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.init(ResourceManager.java:191)
	at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.main(ResourceManager.java:497)

Another copy and paste issue. Similar to https://issues.apache.org/jira/browse/MAPREDUCE-3042."
MAPREDUCE-3059,QueueMetrics do not have metrics for aggregate containers-allocated and aggregate containers-released,"QueueMetrics for ResourceManager do not have any metrics for aggregate containers-allocated and containers-released.

We need the aggregates of containers-allocated and containers-released to figure out the rate at which RM is dishing out containers. NodeManager do have containers-launched and container-released metrics, but this is not across all nodes; so to get the cluster level aggregate, we need to preprocess NM metrics from all nodes - which is troublesome.

Currently, we do have AllocatedContainers and PendingContainers which reflect the running containers given out to AMs, and containers waiting for allocation respectively."
MAPREDUCE-3058,Sometimes task keeps on running while its Syslog says that it is shutdown,"While running GridMixV3, one of the jobs got stuck for 15 hrs. After clicking on the Job-page, found one of its reduces to be stuck. Looking at syslog of the stuck reducer, found this:
Task-logs' head:

{code}
2011-09-19 17:57:22,002 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2011-09-19 17:57:22,002 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system started
{code}

Task-logs' tail:
{code}
2011-09-19 18:06:49,818 INFO org.apache.hadoop.hdfs.DFSClient: Exception in createBlockOutputStream java.io.IOException: Bad connect ack with firstBadLink as <DATANODE1>
2011-09-19 18:06:49,818 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for block BP-1405370709-<NAMENODE>-1316452621953:blk_-7004355226367468317_79871 in pipeline  <DATANODE2>,  <DATANODE1>: bad datanode  <DATANODE1>
2011-09-19 18:06:49,818 DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtocol: lastAckedSeqno = 26870
2011-09-19 18:06:49,820 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf sending #454
2011-09-19 18:06:49,826 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <<NAMENODE> from gridperf got value #454
2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.ipc.RPC: Call: getAdditionalDatanode 8
2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.hdfs.DFSClient: Connecting to datanode <DATANODE2>
2011-09-19 18:06:49,827 DEBUG org.apache.hadoop.hdfs.DFSClient: Send buf size 131071
2011-09-19 18:06:49,833 WARN org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
java.io.EOFException: Premature EOF: no length prefix available
        at org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:158)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:860)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:838)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:929)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:740)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:415)
2011-09-19 18:06:49,837 WARN org.apache.hadoop.mapred.YarnChild: Exception running child : java.io.EOFException: Premature EOF: no length prefix available
        at org.apache.hadoop.hdfs.protocol.HdfsProtoUtil.vintPrefixed(HdfsProtoUtil.java:158)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.transfer(DFSOutputStream.java:860)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.addDatanode2ExistingPipeline(DFSOutputStream.java:838)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:929)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:740)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:415)

2011-09-19 18:06:49,837 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 sending #455
2011-09-19 18:06:49,839 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 got value #455
2011-09-19 18:06:49,840 DEBUG org.apache.hadoop.ipc.RPC: Call: statusUpdate 3
2011-09-19 18:06:49,840 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task
2011-09-19 18:06:49,840 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf sending #456
2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <NAMENODE> from gridperf got value #456
2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.RPC: Call: delete 18
2011-09-19 18:06:49,858 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 sending #457
2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.ipc.Client: IPC Client (26613121) connection to <APPMASTER> from job_1316452677984_0862 got value #457
2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.ipc.RPC: Call: reportDiagnosticInfo 1
2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: refCount=1
2011-09-19 18:06:49,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping ReduceTask metrics system...
2011-09-19 18:06:49,859 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping metrics source UgiMetrics
2011-09-19 18:06:49,859 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: class org.apache.hadoop.metrics2.lib.MetricsSourceBuilder$1
2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=UgiMetrics
2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping metrics source JvmMetrics
2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl: class org.apache.hadoop.metrics2.source.JvmMetrics
2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=JvmMetrics
2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=MetricsSystem,sub=Stats
2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system stopped.
2011-09-19 18:06:49,860 DEBUG org.apache.hadoop.metrics2.util.MBeans: Unregistering Hadoop:service=ReduceTask,name=MetricsSystem,sub=Control
2011-09-19 18:06:49,860 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: ReduceTask metrics system shutdown complete.
{code}

Which means that tasks is supposed to have stopped within 20 secs, whereas the process itself is stuck for more than 15 hours. From AM log, also found that this task was sending its update regularly. ps -ef | grep java was also showing that process is still alive.
"
MAPREDUCE-3057,Job History Server goes of OutOfMemory with 1200 Jobs and Heap Size set to 10 GB,"History server was started with -Xmx10000m
Ran GridMix V3 with 1200 Jobs trace in STRESS mode on 350 nodes with each node 4 NMS.
All jobs finished as reported by RM Web UI and HADOOP_MAPRED_HOME/bin/mapred job -list all
But found that GridMix job client was stuck while trying connect to HistoryServer
Then tried to do HADOOP_MAPRED_HOME/bin/mapred job -status jobid
JobClient also got stuck while looking for token to connect to History server
Then looked at History Server logs and found History is trowing ""java.lang.OutOfMemoryError: GC overhead limit exceeded"" error.

With 10GB of Heap space and 1200 Jobs, History Server should not go out of memory .
No matter what are the type of jobs.



"
MAPREDUCE-3056,Jobs are failing when those are submitted by other users,"MR cluster is started by the user 'root'. If any other users other than 'root' submit a job, it is failing always.

Find the conatiner logs in the comments section."
MAPREDUCE-3055,"Simplify parameter passing to Application Master from Client. SImplify approach to pass info such  appId, ClusterTimestamp and failcount required by App Master.","The Application master needs the application attempt id to register with the Applications Manager. To create an appAttemptId object, the appId object(needs cluster timestamp and app id) and failCount are needed.

Currently, all clients need to pass in the appId, cluster timestamp and fail count to the app master for the required objects to be constructed. 

We could look at simplifying this by providing either placeholders that would have values replaced by the app master launcher or setting it  into the environment ( although that requires a set of whitelisted env vars that can only be set by the yarn framework ). "
MAPREDUCE-3054,Unable to kill submitted jobs,"Found by Philip Su

The ""mapred job -kill"" command
appears to succeed, but listing the jobs again shows that the job supposedly killed is still there. 

{code}
mapred job -list
Total jobs:2
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1316203984216_0002  PREP    1316204924937   hadoopqa        default NORMAL
job_1316203984216_0001  PREP    1316204031206   hadoopqa        default NORMAL

mapred job -kill job_1316203984216_0002
Killed job job_1316203984216_0002

mapred job -list
Total jobs:2
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1316203984216_0002  PREP    1316204924937   hadoopqa        default NORMAL
job_1316203984216_0001  PREP    1316204031206   hadoopqa        default NORMAL
{code}"
MAPREDUCE-3053,YARN Protobuf RPC Failures in RM,"When I try to register my ApplicationMaster with YARN's RM, it fails.

In my ApplicationMaster's logs:

Exception in thread ""main"" java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.yarn.api.impl.pb.client.AMRMProtocolPBClientImpl.registerApplicationMaster(AMRMProtocolPBClientImpl.java:108)
	at kafka.yarn.util.ApplicationMasterHelper.registerWithResourceManager(YarnHelper.scala:48)
	at kafka.yarn.ApplicationMaster$.main(ApplicationMaster.scala:32)
	at kafka.yarn.ApplicationMaster.main(ApplicationMaster.scala)
Caused by: com.google.protobuf.ServiceException: java.lang.NullPointerException: java.lang.NullPointerException
	at org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)

	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:130)
	at $Proxy6.registerApplicationMaster(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.AMRMProtocolPBClientImpl.registerApplicationMaster(AMRMProtocolPBClientImpl.java:101)
	... 3 more
Caused by: java.lang.NullPointerException: java.lang.NullPointerException
	at org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)

	at org.apache.hadoop.ipc.Client.call(Client.java:1084)
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:127)
	... 5 more


In the ResourceManager's logs:

2011-09-20 15:11:20,973 INFO  ipc.Server (Server.java:run(1497)) - IPC Server handler 2 on 8040, call: org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$ProtoSpecificRequestWritable@455dd32a from 127.0.0.1:33793, error: 
java.lang.NullPointerException
	at org.apache.hadoop.yarn.proto.ClientRMProtocol$ClientRMProtocolService$2.getRequestPrototype(ClientRMProtocol.java:186)
	at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:323)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)

My registration code:

    val appId = args(0).toInt
    val attemptId = args(1).toInt
    val timestamp = args(2).toLong

    // these are our application master's parameters
    val streamerClass = args(3)
    val tasks = args(4).toInt

    // TODO log params here

    // start the application master helper
    val conf = new Configuration
    val applicationMasterHelper = new ApplicationMasterHelper(appId, attemptId, timestamp, conf)
      .registerWithResourceManager

  .....

  val rpc = YarnRPC.create(conf)
  val appId = Records.newRecord(classOf[ApplicationId])
  val appAttemptId = Records.newRecord(classOf[ApplicationAttemptId])
  val rmAddress = NetUtils.createSocketAddr(conf.get(YarnConfiguration.RM_ADDRESS, YarnConfiguration.DEFAULT_RM_ADDRESS))
  val resourceManager = rpc.getProxy(classOf[AMRMProtocol], rmAddress, conf).asInstanceOf[AMRMProtocol]
  var requestId = 0

  appId.setClusterTimestamp(lTimestamp)
  appId.setId(iAppId)
  appAttemptId.setApplicationId(appId)
  appAttemptId.setAttemptId(iAppAttemptId)

  def registerWithResourceManager(): ApplicationMasterHelper = {
    val req = Records.newRecord(classOf[RegisterApplicationMasterRequest])
    req.setApplicationAttemptId(appAttemptId)
    // TODO not sure why these are blank- This is how spark does it
    req.setHost("""")
    req.setRpcPort(1)
    req.setTrackingUrl("""")
    resourceManager.registerApplicationMaster(req)
    this
  }

My params are receiving the proper app/attempt/cluster timestamps:

app - 1
attempt - 1
timestamp - 1316556657998
"
MAPREDUCE-3052,"Maintain consistency in naming appIDs, jobIDs and attemptIDs","Currently, the appIDs, jobIDs and attempt/container ids are not consistently named in the logs, console and
UI.

Some recent jiras have fixed the inconsistencies with the appID.

For jobID
On the RM UI: job_1308259676864_5_5 
JHS UI: job_1308259676864_5_5 
Console/logs: job_1308259676864_0005
mapred-local dirs are named as: No jobID

I am planning on changing the jobID to match job_1308259676864_0005 in the RM UI and the JHS UI.


For attemptID
On the RM UI: attempt_1308259676864_5_5_m_24_0
JHS attempt_1308259676864_5_5_m_24_0
Console/logs: attempt_1308259676864_0005_m_000024_0
mapred-local dirs are named as: container_1308259676864_0005_000024

I'm not sure the best way to handle the attempt and container IDs, but I'm making them more consistent.  (If any of you have preferences, let me know)"
MAPREDUCE-3051,HADOOP_CONF_DIR exported twice in the classpath,"HADOOP_CONF_DIR is exported twice in the classpath during RM, NM and container startup time. Not an issue so far but seems redundant. "
MAPREDUCE-3050,YarnScheduler needs to expose Resource Usage Information,"Before the recent refactor The nodes had information in them about how much resources they were using.  This information is not hidden inside SchedulerNode.  Similarly resource usage information about an application, or in aggregate is only available through the Scheduler and there is not interface to pull it out.

We need to expose APIs to get Resource and Container information from the scheduler, in aggregate across the entire cluster, per application, per node, and ideally also per queue if applicable (although there are no JIRAs I am aware of that need this right now)."
MAPREDUCE-3048,"Fix test-patch to run tests via ""mvn clean install test""","Some tests like the ones failing at MAPREDUCE-3040 depend on the generated jars. TestMRJobs for e.g. won't run if we simply run ""mvn clean test"".

I propose that we change test-patch to run tests using ""mvn clean install test""."
MAPREDUCE-3045,Elapsed time filter on jobhistory server displays incorrect table entries,"The elapsed time filter on the jobhistory server filters incorrect information. 
For e.g. on a cluster where the elapsed time of all the tasks is either 7 or 8sec, the filter displays non null table entries for 1sec or 3sec"
MAPREDUCE-3044,Pipes jobs stuck without making progress,A simple example pipes job gets stuck without making any progress. The AM is launched but the maps do not make any progress.
MAPREDUCE-3043,Missing containers info on the nodes page,The containers info on the nodes page on the RM seems to be missing. This was useful in understanding the usage on each of the nodemanagers.
MAPREDUCE-3042,YARN RM fails to start,"When I build and run YARN's RM, I get an invalid host:port exception.

Looks like there's a typo in the ResourceTrackerService."
MAPREDUCE-3041,Enhance YARN Client-RM protocol to provide access to information such as cluster's Min/Max Resource capabilities similar to that of AM-RM protocol,"To request a container to launch an application master, the client needs to know the min/max resource capabilities so as to be able to make a proper resource request when submitting a new application.
"
MAPREDUCE-3040,"TestMRJobs, TestMRJobsWithHistoryService, TestMROldApiJobs fail","Running org.apache.hadoop.mapreduce.v2.TestMRJobs
Tests run: 4, Failures: 0, Errors: 4, Skipped: 0, Time elapsed: 6.229 sec <<< FAILURE!
Running org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService
Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 5.887 sec <<< FAILURE!
Running org.apache.hadoop.mapreduce.v2.TestMROldApiJobs
Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 6.067 sec <<< FAILURE!

All of them have the exception:


java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.util.MRApps.parseDistributedCacheArtifacts(MRApps.java:300)
        at org.apache.hadoop.mapreduce.v2.util.MRApps.setupDistributedCache(MRApps.java:277)
        at org.apache.hadoop.mapred.YARNRunner.createApplicationSubmissionContext(YARNRunner.java:349)
        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:227)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:376)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1161)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1158)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1158)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1178)
        at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(TestMRJobs.java:147)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)"
MAPREDUCE-3039,Make mapreduce use same version of avro as HBase,"HBase depends on avro 1.5.3 whereas hadoop-common depends on 1.3.2.
When building HBase on top of hadoop, this should be consistent.
Moreover, this should be consistent between common, hdfs, and mapreduce.

Contribs seem to have declared a dependency on avro but are not in fact depending on it."
MAPREDUCE-3038,job history server not starting because conf() missing HsController,"Exception starting history server.


Sep 19, 2011 6:51:53 PM com.google.inject.MessageProcessor visit
INFO: An exception was caught and reported. Message: org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController                                                                                 org.apache.hadoop.yarn.webapp.WebAppException: conf() not found in class org.apache.hadoop.mapreduce.v2.hs.webapp.HsController
    at org.apache.hadoop.yarn.webapp.Router.addController(Router.java:107)
    at org.apache.hadoop.yarn.webapp.Router.add(Router.java:83)
    at org.apache.hadoop.yarn.webapp.WebApp.route(WebApp.java:140)
    at org.apache.hadoop.yarn.webapp.WebApp.route(WebApp.java:146)
    at org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebApp.setup(HsWebApp.java:42)
    at org.apache.hadoop.yarn.webapp.WebApp.configureServlets(WebApp.java:121)
    at com.google.inject.servlet.ServletModule.configure(ServletModule.java:45)
    at com.google.inject.AbstractModule.configure(AbstractModule.java:59)
    at com.google.inject.spi.Elements$RecordingBinder.install(Elements.java:223)
    at com.google.inject.spi.Elements.getElements(Elements.java:101)
    at com.google.inject.InjectorShell$Builder.build(InjectorShell.java:135)
    at com.google.inject.InjectorBuilder.build(InjectorBuilder.java:102)
    at com.google.inject.Guice.createInjector(Guice.java:92)
    at com.google.inject.Guice.createInjector(Guice.java:69)
    at com.google.inject.Guice.createInjector(Guice.java:59)
    at org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:166)
    at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.initializeWebApp(HistoryClientService.java:138)
    at org.apache.hadoop.mapreduce.v2.hs.HistoryClientService.start(HistoryClientService.java:109)
    at org.apache.hadoop.yarn.service.CompositeService.start(CompositeService.java:68)
    at org.apache.hadoop.mapreduce.v2.hs.JobHistoryServer.main(JobHistoryServer.java:83)"
MAPREDUCE-3037,Add a consistent method for getting the job configuration's XML within the AppMaster and the JobHistory,"We should add consistent functionality for accessing/downloading the actual XML for the jobfile configuration from the Web UI (for both the AppMaster UI and the JobHistory UI).  Currently, you can get an HTML table with the configuration through /yarn/conf (a ""Configuration"" link on the left side of the UI).  It would be good to add a link there that allows the user to actually download the XML.  We could either have a conf-xml servlet or even better we could do something more REST-like by allowing requests to contain the desired format (XML, HTML, JSON, etc?)."
MAPREDUCE-3036,Some of the Resource Manager memory metrics go negative.,"ReservedGB seems to always be decremented when a container is released, even though the container never reserved any memory.
AvailableGB also seems to be able to go negative in a few situations."
MAPREDUCE-3035,MR V2 jobhistory does not contain rack information,"When topology.node.switch.mapping.impl is set to enable rack-locality resolution via the topology script, from the RM web-UI, we can see the rack information for each node. Running a job also reveals the information about rack-local map tasks launched at end of job completion on the client side.

But the hostname field for attempts in the JobHistory does not contain this rack information.

In case of hadoop-0.20 securiy or MRV1, hostname field of job history does contain rackid/hostname whereas in MRV2, hostname field only contains the hostIP. Thus this is a regression."
MAPREDUCE-3034,NM should act on a REBOOT command from RM,"RM sends a reboot command to NM in some cases, like when it gets lost and rejoins back. In such a case, NM should act on the command and reboot/reinitalize itself.

This is akin to TT reinitialize on order from JT. We will need to shutdown all the services properly and reinitialize - this should automatically take care of killing of containers, cleaning up local temporary files etc."
MAPREDUCE-3033,JobClient requires mapreduce.jobtracker.address config even when mapreduce.framework.name is set to yarn,"If mapreduce.jobtracker.address is not set in mapred-site.xml and mapreduce.framework.name is set yarn, job submission fails :

Tried to submit sleep job with maps 1 task. Job submission failed with following exception -:
{code}
11/09/19 13:19:20 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/19 13:19:20 INFO mapred.ResourceMgrDelegate: Connecting to ResourceManager at <RMHost>:8040
11/09/19 13:19:20 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.api.ClientRMProtocol
11/09/19 13:19:20 INFO mapred.ResourceMgrDelegate: Connected to ResourceManager at <RMHost>:8040
11/09/19 13:19:21 INFO mapred.ResourceMgrDelegate: DEBUG --- getStagingAreaDir: dir=/user/<username>/.staging
11/09/19 13:19:21 INFO mapreduce.JobSubmitter: Cleaning up the staging area /user/<username>/.staging/job_1316435926198_0004
java.lang.RuntimeException: Not a host:port pair: local
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:148)
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:132)
	at org.apache.hadoop.mapred.Master.getMasterAddress(Master.java:42)
	at org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:47)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:104)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:90)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:83)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:346)
	at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1072)
	at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1069)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1069)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
	at org.apache.hadoop.mapreduce.SleepJob.run(SleepJob.java:262)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.mapreduce.SleepJob.main(SleepJob.java:194)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
{code}"
MAPREDUCE-3032,JobHistory doesn't have error information from failed tasks,
MAPREDUCE-3031,Job Client goes into infinite loop when we kill AM,"Started a cluster. Submitted a sleep job with around 10000 maps and 1000 reduces.
Killed AM with kill -9 by which time already 7000 thousands maps got completed.

On the RM webUI, Application is stuck in Application.RUNNING state. And JobClient goes into an infinite loop as RM keeps telling the client that the application is running."
MAPREDUCE-3030,RM is not processing heartbeat and continuously giving the message 'Node not found rebooting',"{code:title=Node Manager Logs|borderStyle=solid}
2011-09-19 13:39:29,816 INFO  webapp.WebApps (WebApps.java:start(162)) - Registered webapp guice modules
2011-09-19 13:39:29,817 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer is started.
2011-09-19 13:39:29,818 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:Dispatcher is started.
2011-09-19 13:39:29,819 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:start(133)) - Configured ContainerManager Address is 10.18.52.124:45454
2011-09-19 13:39:29,819 INFO  ipc.YarnRPC (YarnRPC.java:create(47)) - Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
2011-09-19 13:39:29,822 INFO  ipc.HadoopYarnRPC (HadoopYarnProtoRPC.java:getProxy(49)) - Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.yarn.server.api.ResourceTracker
2011-09-19 13:39:29,862 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(165)) - Connected to ResourceManager at 0.0.0.0:8025
2011-09-19 13:39:30,369 INFO  nodemanager.NodeStatusUpdaterImpl (NodeStatusUpdaterImpl.java:registerWithRM(189)) - Registered with ResourceManager as 10.18.52.124:45454 with total resource of memory: 8192, 
2011-09-19 13:39:30,369 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl is started.
2011-09-19 13:39:30,371 INFO  service.AbstractService (AbstractService.java:start(61)) - Service:org.apache.hadoop.yarn.server.nodemanager.NodeManager is started.
{code}



{code:title=Resource Manager Logs|borderStyle=solid}
2011-09-19 14:01:03,238 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:04,240 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:05,242 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:06,244 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:07,246 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
Call: protocol=org.apache.hadoop.yarn.proto.ResourceTracker$ResourceTrackerService$BlockingInterface, method=nodeHeartbeat
2011-09-19 14:01:08,247 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:nodeHeartbeat(201)) - Node not found rebooting 10.18.52.124:45454
{code}

Node Manager is registered with Resource manager and the for every heartbeat, it is printing the above message."
MAPREDUCE-3028,Support job end notification in .next /0.23,"Oozie primarily depends on  the job end notification to determine when the job finishes. In the current version,  job end notification is implemented in job tracker. Since job tracker will be removed in the upcoming hadoop release (.next), we wander where this support will move. I think this best effort notification could be implemented in the new Application Manager as one of the last step of job completion.

Whatever implementation will it be, Oozie badly needs this feature to be continued in next releases as well.

 

"
MAPREDUCE-3027,MR-279: Completed container exit state needs to be enhanced to differentiate between container aborts/failures and actual application process exit codes,"Currently, a completed container's exit status is set to -100 to denote the container being killed by the framework either as a result of the application releasing the container or a node failure. An application process may also return an exit code of -100 creating an ambiguity. 

 "
MAPREDUCE-3026,"When user adds hierarchical queues to the cluster, mapred queue -list returns NULL Pointer Exception","When User adds the hierarchical queues, and try to see them from the command line using 
mapred queue -list 
It returns Null Pointer Exception."
MAPREDUCE-3025,Contribs not building,"Contribs are not getting built.
Snippet from Jenkins:

compile:
[subant] No sub-builds to iterate on
"
MAPREDUCE-3024,Make all poms to have hadoop-project POM as common parent,in order to effectively use the Maven 'versions' plugin to update version numbers all POMs should have the hadoop-project POM as their common parent.
MAPREDUCE-3023,Queue state is not being translated properly (is always assumed to be running),"During translation of QueueInfo, 

bq. TypeConverter.java:435 : queueInfo.toString(), QueueState.RUNNING,
ought to be 
bq. queueInfo.toString(), QueueState.getState(queueInfo.getQueueState().toString().toLowerCase()),"
MAPREDUCE-3022,Some Web UI links to other components don't specify path,"Some of the links to other components in the web ui just specify host:port and don't add on the path.  For instance in the RM UI - the nodes page.  Each node is just listed as IP:port.  The actual path to those pages are IP:port/yarn/*.  I think the links should be what that components webapp is registered at.  

There may be other places too so we should search for them."
MAPREDUCE-3021,"all yarn webapps use same base name of ""yarn/""","All of the yarn webapps (resource manager, node manager, app master, job history) use the same base url of /yarn/.  This doesn't lend itself very well to filters be able to differentiate them to say allow some to be not authenticated and other to be authenticated.  Perhaps we should rename them based on component.

There are also things in the code that hardcode paths to ""/yarn"" that should be fixed up.

"
MAPREDUCE-3020,Node link in reduce task attempt page is not working [Job History Page],"RM UI -> Applications -> Application(Job History) -> Reduce Tasks -> Task ID -> Node link is not working
hostname for ReduceAttemptFinishedEvent is coming wrong when loading from history file.
"
MAPREDUCE-3019,"Can't find the symbol ""YARN_MR_PREFIX"" in MRConstants.java ","Fail to compile AMConstants.java because there is no static variable YARN_MR_PREFIX in the interface MRConstants.java.
It seems this bug is caused by incomplete integration of MAPREDUCE-2864. "
MAPREDUCE-3018,Streaming jobs with -file option fail to run.,"Streaming jobs fail to run with the -file option.
hadoop jar streaming.jar -input input.txt -output Out -mapper ""mapper.sh"" -reducer NONE -file path_to_mapper.sh

fails to run."
MAPREDUCE-3017,The Web UI shows FINISHED for killed/successful/failed jobs.,The RM web ui shows FINISHED status for all the jobs even if they failed/killed or were successful. This should be fixed. Only the jobs where the AM crashes are marked as Failed.  
MAPREDUCE-3016,Add TT local dir failure info to the JT web UI,Like HDFS-556 but for the JT. The machine list page should report local directory failures per TT.
MAPREDUCE-3015,Add local dir failure info to metrics and the web UI,Like HDFS-811/HDFS-1850 but for the TT.
MAPREDUCE-3014,Rename and invert logic of '-cbuild' profile to 'native' and off by default,This would align MR modules with common & hdfs modules.
MAPREDUCE-3013,Remove YarnConfiguration.YARN_SECURITY_INFO,We don't need this anymore since RPC client uses SecurityUtil to pick it up via going through the providers for SecurityInfo interface. 
MAPREDUCE-3012,Change org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapred.MapFileOutputFormat to use new api for hadoop 0.20,"This bug has been fixed for hadoop 0.21 api, but it still is open for hadoop 0.20. As 0.21 is hardly used anywhere, and 0.20 is the main version on all the clusters, I feel that the issue has to be reopened.
https://issues.apache.org/jira/browse/MAPREDUCE-375
"
MAPREDUCE-3011,TT should remove bad local dirs from conf to prevent constant disk checking,Per HADOOP-7551 the TT does not remove bad mapred.local.dirs from the conf so after a single disk failure *every* call to get a local path for reading or writing results in a disk check of *all* configured local dirs. After detecting that a local dir is bad we should remove it from the conf so that we don't repeatedly perform this expensive operation.
MAPREDUCE-3010,ant mvn-install doesn't work on hadoop-mapreduce-project,"Even though ant jar works, ant mvn-install fails in the compile-fault-inject step"
MAPREDUCE-3009,RM UI -> Applications -> Application(Job History) -> Map Tasks -> Task ID -> Node link is not working,"RM UI -> Applications -> Application(Job History) -> Map Tasks -> Task ID -> Node link is not working. The URL contains extra '/' which is causing the problem. Please find in the attached screen shots.
"
MAPREDUCE-3008,[Gridmix] Improve cumulative CPU usage emulation for short running tasks,"CPU emulation in Gridmix fails to meet the expected target if the map has no data to sort/spill/merge. There are 2 major reasons for this:
1. The map task end immediately ends soon after the map task. The map progress is 67% while the map phase ends. 
2. Currently, the sort (comparator) doesnt emulate CPU. If the map is short lived, the CPU emulation thread (spawned from the map task in cleanup) doesn't get a chance to emulate."
MAPREDUCE-3007,JobClient cannot talk to JobHistory server in secure mode,"In secure mode, Jobclient cannot connect to HistoryServer. Thanks to [~karams] for finding this out.

{code}
11/09/14 09:57:51 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server
11/09/14 09:57:51 INFO security.ApplicationTokenSelector: Looking for a token with service <history-server>:10020
11/09/14 09:57:51 INFO security.ApplicationTokenSelector: Token kind is YARN_APPLICATION_TOKEN and the token's service name is <Am-ip>:46257
11/09/14 09:57:51 INFO security.UserGroupInformation: Initiating logout for <user-principal>
11/09/14 09:57:51 INFO security.UserGroupInformation: Initiating re-login for <user-principal>
11/09/14 09:57:55 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:57:56 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:00 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:05 WARN security.UserGroupInformation: Not attempting to re-login since the last re-login was attempted less than 600 seconds before.
11/09/14 09:58:05 WARN ipc.Client: Couldn't setup connection for <user-principal> to null
11/09/14 09:58:05 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1315993268700_0001  Will retry..
{code}

Am surprised no one working with YARN+MR ever ran into this!"
MAPREDUCE-3006,MapReduce AM exits prematurely before completely writing and closing the JobHistory file,"[~Karams] was executing a sleep job with 100,000 tasks on a 350 node cluster to test MR AM's scalability and ran into this. The job ran successfully but the history was not available.

I debugged around and figured that the job is finishing prematurely before the JobHistory is written. In most of the cases, we don't see this bug as we have a 5 seconds sleep in AM towards the end."
MAPREDUCE-3005,MR app hangs because of a NPE in ResourceManager,"The app hangs and it turns out to be a NPE in ResourceManager. This happened two of five times on [~karams]'s sort runs on a big cluster.
{code}
2011-09-12 15:02:33,715 ERROR org.apache.hadoop.yarn.server.resourcemanager.ResourceManager: Error in handling event type NODE_UPDATE to the scheduler
java.lang.NullPointerException
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocateNodeLocal(AppSchedulingInfo.java:244)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.AppSchedulingInfo.allocate(AppSchedulingInfo.java:206)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApp.allocate(SchedulerApp.java:230)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainer(LeafQueue.java:1120)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignNodeLocalContainers(LeafQueue.java:961)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainersOnNode(LeafQueue.java:933)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.assignContainers(LeafQueue.java:725)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainersToChildQueues(ParentQueue.java:577)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.assignContainers(ParentQueue.java:509)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.nodeUpdate(CapacityScheduler.java:579)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:620)
        at org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(CapacityScheduler.java:75)
        at org.apache.hadoop.yarn.server.resourcemanager.ResourceManager$SchedulerEventDispatcher$EventProcessor.run(ResourceManager.java:266)
        at java.lang.Thread.run(Thread.java:619)
{code}"
MAPREDUCE-3004,sort example fails in shuffle/reduce stage as it assumes a local job by default ,"Log trace when running sort on a single node setup:

11/09/13 17:01:06 INFO mapreduce.Job:  map 100% reduce 0%
11/09/13 17:01:10 INFO mapreduce.Job: Task Id : attempt_1315949787252_0009_r_000000_0, Status : FAILED
java.lang.UnsupportedOperationException: Incompatible with LocalRunner
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFile(YarnOutputFiles.java:200)
	at org.apache.hadoop.mapred.ReduceTask.getMapFiles(ReduceTask.java:183)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:365)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)
"
MAPREDUCE-3003,Publish MR JARs to Maven snapshot repository,"Currently this is failing since no distribution management section is defined in the POM.

https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-Common-trunk-Commit/883/consoleFull"
MAPREDUCE-3001,Map Reduce JobHistory and AppMaster UI should have ability to display task specific counters.,Map Reduce JobHistory and AppMaster UI should have ability to display task specific counters.  I think the best way to do this is to include in the Nav Block a task specific section with task links when a task is selected.  Counters is already set up to deal with a task passed in.
MAPREDUCE-3000,Move /mapred to /user/mapred for Hadoop 0.20.205,/mapred directory should be default to /user/mapred.  Owen request this to be changed for RPM deployment in 0.20.204.  This is a regression in 0.20.205 that /user/mapred is configured back to /mapred.
MAPREDUCE-2999,hadoop.http.filter.initializers not working properly on yarn UI,"Currently httpserver only has *.html"", ""*.jsp as user facing urls when you add a filter. For the new web framework in yarn, the pages no longer have the *.html or *.jsp and thus they are not properly being filtered."
MAPREDUCE-2998,Failing to contact Am/History for jobs: java.io.EOFException in DataInputStream,"I am getting an exception frequently when running my jobs on a single-node cluster.  It happens with basically any job I run: sometimes the job will work, but most of the time I get this exception (in this case, I was running a simple wordcount from the examples jar - where I got the exception 4 times in a row, and then the job worked the fifth time I submitted it). 
Sometimes restarting the namenode, resourcemanager, and historyserver helps - but not always.  Several other developers have seen this problem.


11/09/12 17:17:50 INFO mapred.YARNRunner: AppMaster capability = memory: 2048, 
11/09/12 17:17:51 INFO mapred.YARNRunner: Command to launch container for ApplicationMaster is : $JAVA_HOME/bin/java -Dhadoop.root.logger=DEBUG,console -Xmx1536m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1315847180566 6 <FAILCOUNT> 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr 
11/09/12 17:17:51 INFO mapred.ResourceMgrDelegate: Submitted application application_1315847180566_6 to ResourceManager
11/09/12 17:17:51 INFO mapred.ClientCache: Connecting to HistoryServer at: 0.0.0.0:10020
11/09/12 17:17:51 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/12 17:17:51 INFO mapred.ClientCache: Connected to HistoryServer at: 0.0.0.0:10020
11/09/12 17:17:51 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol
11/09/12 17:17:51 INFO mapreduce.Job: Running job: job_1315847180566_0006
11/09/12 17:17:52 INFO mapreduce.Job:  map 0% reduce 0%
11/09/12 17:18:00 INFO mapred.ClientServiceDelegate: Tracking Url of JOB is <IP-ADDRESS>:55361
11/09/12 17:18:00 INFO mapred.ClientServiceDelegate: Connecting to <IP-ADDRESS>:43465
11/09/12 17:18:00 INFO ipc.YarnRPC: Creating YarnRPC for org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
11/09/12 17:18:00 INFO ipc.HadoopYarnRPC: Creating a HadoopYarnProtoRpc proxy for protocol interface org.apache.hadoop.mapreduce.v2.api.MRClientProtocol
11/09/12 17:18:01 INFO mapred.ClientServiceDelegate: Failed to contact AM/History for job job_1315847180566_0006  Will retry..
java.lang.reflect.UndeclaredThrowableException
    at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:179)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:237)
    at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:276)
    at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:547)
    at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:540)
    at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1144)
    at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1092)
    at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
    at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
    at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    at java.lang.reflect.Method.invoke(Method.java:597)
    at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
Caused by: com.google.protobuf.ServiceException: java.io.IOException: Call to /<IP-ADDRESS>:43465 failed on local exception: java.io.EOFException
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:139)
    at $Proxy8.getTaskAttemptCompletionEvents(Unknown Source)
    at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:172)
    ... 23 more
Caused by: java.io.IOException: Call to /<IP-ADDRESS>:43465 failed on local exception: java.io.EOFException
    at org.apache.hadoop.ipc.Client.wrapException(Client.java:1119)
    at org.apache.hadoop.ipc.Client.call(Client.java:1087)
    at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:136)
    ... 25 more
Caused by: java.io.EOFException
    at java.io.DataInputStream.readInt(DataInputStream.java:375)
    at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:816)
    at org.apache.hadoop.ipc.Client$Connection.run(Client.java:754)
11/09/12 17:18:01 INFO mapreduce.Job: Job job_1315847180566_0006 failed with state FAILED
11/09/12 17:18:01 INFO mapreduce.Job: Counters: 0 

"
MAPREDUCE-2997,MR task fails before launch itself with an NPE in ContainerLauncher,"Exception found on the AM web UI while the application is running:
{code}
Container launch failed for container_1315908079531_0002_01_000387 : java.lang.NullPointerException
  at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl.getCMProxy(ContainerLauncherImpl.java:162)
  at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:204)
  at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
  at java.lang.Thread.run(Thread.java:619) 
{code}"
MAPREDUCE-2996,Log uberized information into JobHistory and use the same via CompletedJob,We always print the uberized info on the UI to be false irrespective of whether it is uberized or not.
MAPREDUCE-2995,MR AM crashes when a container-launch hangs on a faulty NM,"AM tries to launch containers on a faulty node which blocks several/all of the {{StartContainer}} requests. Eventually, RM expires the container-allocations, informs the AM about container-expiry. But AM crashes with an INTERNAL_ERROR as the event is unexpected.
{code}
11/09/12 14:11:38 ERROR impl.TaskAttemptImpl: Can't handle this event at current state
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: TA_CONTAINER_COMPLETED at ASSIGNED
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:297)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:39)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:439)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:903)
        at org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl.handle(TaskAttemptImpl.java:127)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:543)
        at org.apache.hadoop.mapreduce.v2.app.MRAppMaster$TaskAttemptEventDispatcher.handle(MRAppMaster.java:536)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:113)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
{code}

Found this on a big cluster where [~karams] was trying to get sort running."
MAPREDUCE-2994,Parse Error is coming for App ID when we click application link on the RM UI,"{code:xml}
Caused by: org.apache.hadoop.yarn.YarnException: Error parsing app ID: application_1315895242400_1
	at org.apache.hadoop.yarn.util.Apps.throwParseException(Apps.java:60)
	at org.apache.hadoop.yarn.util.Apps.toAppID(Apps.java:43)
	at org.apache.hadoop.yarn.util.Apps.toAppID(Apps.java:38)
	at org.apache.hadoop.yarn.server.resourcemanager.webapp.RmController.app(RmController.java:74)
	... 30 more
{code}"
MAPREDUCE-2993,Hamlet HTML elements are not closed properly. Every element should have proper end tag.,"Execute org.apache.hadoop.yarn.server.resourcemanager.webapp.TestRMWebApp.testNodesPage()

Verify the output on the console.

{code:xml} 
 <table id=""layout"" class=""ui-widget-content"">
    <thead>
      <tr>
        <td colspan=""2"">
          <div id=""header"" class=""ui-widget"">
            <div id=""user"">
              Logged in as: null
            </div>
            <div id=""logo"">
              <img src=""/static/hadoop-st.png"">
            </div>
            <h1>
              Nodes of the cluster
            </h1>
          </div>
    <tfoot>
      <tr>
        <td colspan=""2"">
          <div id=""footer"" class=""ui-widget"">
            <a href=""http://hadoop.apache.org/"">About Apache Hadoop</a>
          </div>
    <tbody>
      <tr>
        <td id=""navcell"">
          <div id=""nav"">
            <h3>
              Cluster
            </h3>
            <ul>
              <li>
                <a href=""/null/cluster"">About</a>
              <li>
                <a href=""/null/nodes"">Nodes</a>
              <li>
                <a href=""/null/apps"">Applications</a>
              <li>
                <a href=""/null/scheduler"">Scheduler</a>
            </ul>
            <h3>
              Tools
            </h3>
            <ul>
              <li>
                <a href=""/conf"">Configuration</a>
              <li>
                <a href=""/logs"">Local logs</a>
              <li>
                <a href=""/stacks"">Server stacks</a>
              <li>
                <a href=""/metrics"">Server metrics</a>
            </ul>
          </div>
          <div id=""themeswitcher"">
          </div>
        <td class=""content"">
          <table id=""nodes"">
            <thead>
              <tr>
                <th class=""rack"">
                  Rack
                <th class=""nodeaddress"">
                  Node Address
                <th class=""nodehttpaddress"">
                  Node HTTP Address
                <th class=""healthStatus"">
                  Health-status
                <th class=""lastHealthUpdate"">
                  Last health-update
                <th class=""healthReport"">
                  Health-report
                <th class=""containers"">
                  Containers
            <tbody>
              <tr>
                <td>
                  rack0
                <td>
                  host0:123
                <td>
                  <a href=""http://localhost:0"">localhost:0</a>
                <td>
                  Unhealthy
                <td>
                  N/A
                <td>
                  null
              <tr>
                <td>
                  rack0
                <td>
                  host1:123
                <td>
                  <a href=""http://localhost:0"">localhost:0</a>
                <td>
                  Unhealthy
                <td>
                  N/A
                <td>
                  null
            </tbody>
          </table>
    </tbody>
  </table>
</html>
{code} 

Many html elements does not have end tag.

"
MAPREDUCE-2991,queueinfo.jsp fails to show queue status if any Capacity scheduler queue name has dash/hiphen in it.,"If any queue name has a dash/hiphen in it, the queueinfo.jsp doesn't show any queue information.  This is happening because the queue name is used to create javascript variables and javascript doesn't allow dash in variable names."
MAPREDUCE-2990,Health Report on Resource Manager UI is null if the NM's are all healthy.,"The web UI on the RM for the link Nodes shows that Health-report as null when the NM is healthy. 

This is a simple fix where in we can check for null in NodesPage.java and put something meaningful instead of null.
NodesPage.java:
{code}

render(..)

td((health.getHealthReport() == null) ?""REPORT HEALTHY"": health.getHealthReport());

{code}
Or something like that.

 "
MAPREDUCE-2989,JobHistory should link to task logs,The log link on the task attempt page is currently broken - since it relies on a ContainerId. We should either pass the containerId via a history event - or some kind of field with information about the log location.
MAPREDUCE-2988,Reenable TestLinuxContainerExecutor reflecting the current NM code. ,"TestLinuxContainerExecutor is currently disabled completely.
"
MAPREDUCE-2987,RM UI display logged in user as null,"All the pages of the UI, currently show ""Logged in as: null"" instead of the correct username"
MAPREDUCE-2986,Multiple node managers support for the MiniYARNCluster,"The current MiniYARNCluster can only support 1 node manager, which is not enough for the full test purposes.

Would like to have a simulator that can support multiple node managers as the real scenario. This might be beneficial for hadoop users, testers and developers.
"
MAPREDUCE-2985,findbugs error in ResourceLocalizationService.handle(LocalizationEvent),"hudson mapreduce is reporting a findbugs error:
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/707//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-yarn-server-nodemanager.html

WMI 	Method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent) makes inefficient use of keySet iterator instead of entrySet iterator
	

Bug type WMI_WRONG_MAP_ITERATOR (click for details)
In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService
In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)
At ResourceLocalizationService.java:[line 295]
Another occurrence at ResourceLocalizationService.java:[line 318]

"
MAPREDUCE-2984,Throwing NullPointerException when we open the container page,"{code:xml}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.yarn.api.records.ContainerId.compareTo(ContainerId.java:97)
	at org.apache.hadoop.yarn.api.records.ContainerId.compareTo(ContainerId.java:23)
	at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:819)
	at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1640)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerPage$ContainerBlock.render(ContainerPage.java:70)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
	at org.apache.hadoop.yarn.webapp.View.render(View.java:210)
{code}

{code:xml}
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.yarn.server.nodemanager.webapp.ContainerPage$ContainerBlock.render(ContainerPage.java:71)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.render(HtmlBlock.java:64)
	at org.apache.hadoop.yarn.webapp.view.HtmlBlock.renderPartial(HtmlBlock.java:74)
	at org.apache.hadoop.yarn.webapp.View.render(View.java:210)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage$Page.subView(HtmlPage.java:47)
	at org.apache.hadoop.yarn.webapp.hamlet.HamletImpl$EImp._v(HamletImpl.java:117)
	at org.apache.hadoop.yarn.webapp.hamlet.Hamlet$TD._(Hamlet.java:843)
	at org.apache.hadoop.yarn.webapp.view.TwoColumnLayout.render(TwoColumnLayout.java:54)
	at org.apache.hadoop.yarn.webapp.view.HtmlPage.render(HtmlPage.java:80)
	at org.apache.hadoop.yarn.webapp.Controller.render(Controller.java:210)
	at org.apache.hadoop.yarn.server.nodemanager.webapp.NMController.container(NMController.java:62)
	... 30 more
{code}
"
MAPREDUCE-2983,All tasks are failing due to invalid shuffle port number,"{code:xml}
2011-09-12 18:43:10,361 INFO  mapreduce.Job (Job.java:printTaskEvents(1227)) - Task Id : attempt_1315831998314_0007_r_000000_0, Status : FAILED
Container launch failed for container_1315831998314_0007_01_000003 : java.lang.IllegalStateException: Invalid shuffle port number -1 returned for attempt_1315831998314_0007_r_000000_0
        at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:226)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)

{code}"
MAPREDUCE-2982,App/Tasks progress is showing as 0% in UI even if successfully completed,Application/Tasks progress is showing as 0% in UI even if successfully completed as shown in the attached screen shots.
MAPREDUCE-2981,Backport trunk fairscheduler to 0.20-security branch,"A lot of improvements have been made to the fair scheduler in 0.21, 0.22 and trunk, but have not been ported back to the new 0.20.20X releases that are currently considered the stable branch of Hadoop."
MAPREDUCE-2979,Remove ClientProtocolProvider configuration under mapreduce-client-core,"ClientProtocolProvider configuration exists under the job-client and core modules. It's really only required in job-client. The version in core points to JobTrackerClientProtocolProvider which causes

java.util.ServiceConfigurationError: org.apache.hadoop.mapreduce.protocol.ClientProtocolProvider: Provider org.apache.hadoop.mapred.JobTrackerClientProtocolProvider not found
        at java.util.ServiceLoader.fail(ServiceLoader.java:214)
        at java.util.ServiceLoader.access$400(ServiceLoader.java:164)
        at java.util.ServiceLoader$LazyIterator.next(ServiceLoader.java:350)
        at java.util.ServiceLoader$1.next(ServiceLoader.java:421)
        at org.apache.hadoop.mapreduce.Cluster.<init>(Cluster.java:73)
        at org.apache.hadoop.mapreduce.Job.<init>(Job.java:133)
        at org.apache.hadoop.mapreduce.Job.<init>(Job.java:138)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:75)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)"
MAPREDUCE-2978,hudson findbugs not reporting properly,"It seems that hudson is not properly reporting findbug failures introduced by jiras. 

Here is an example where hudson gave the jira a +1 for findbugs but it really introduced a bug:
https://issues.apache.org/jira/browse/MAPREDUCE-2937

The actual findbugs report - you'll see there is 1:
https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/662//artifact/trunk/hadoop-mapreduce-project/patchprocess/newPatchFindbugsWarningshadoop-mapreduce-client-jobclient.html

Note that I had to enter in the extra path of hadoop-mapreduce-project to see the html file so perhaps the path it is using to do the diff is wrong."
MAPREDUCE-2977,ResourceManager needs to renew and cancel tokens associated with a job,The JobTracker currently manages tokens for the applications and the resource manager needs the same functionality.
MAPREDUCE-2975,ResourceManager Delegate is not getting initialized with yarn-site.xml as default configuration.,MAPREDUCE-2937 accidentally changes ResourceMgrDelegate so that it does not pick up yarn-site.xml as a default resource. Will upload patch.
MAPREDUCE-2972,Running commands from the hadoop-mapreduce-test-*.jar fails with  ClassNotFoundException: junit.framework.TestCase,"Running any of the 'hadoop jar hadoop-mapreduce-test-*.jar' commands gives the following exception:

java.lang.NoClassDefFoundError: junit/framework/TestCase
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:621)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:124)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:260)
	at java.net.URLClassLoader.access$000(URLClassLoader.java:56)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:195)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:300)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
	at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
	at org.apache.hadoop.test.MapredTestDriver.<init>(MapredTestDriver.java:59)
	at org.apache.hadoop.test.MapredTestDriver.<init>(MapredTestDriver.java:53)
	at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
Caused by: java.lang.ClassNotFoundException: junit.framework.TestCase
	at java.net.URLClassLoader$1.run(URLClassLoader.java:200)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:188)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:307)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:252)
	at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:320)
	... 21 more


This happens even when just running 'hadoop jar $TEST_JAR' where it should just print the available commands.
Copying the junit-*.jar from $HADOOP_MAPRED_HOME/lib/ to $HADOOP_COMMON_HOME/share/hadoop/common/lib/ seems to fix the problem."
MAPREDUCE-2971,ant build mapreduce fails  protected access  jc.displayJobList(jobs);,"Running the ant target in the hadoop-mapreduce-project directory fails with:

[jsp-compile] log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
    [javac] /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/build.xml:398: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 50 source files to /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/build/classes
    [javac] /home/tgraves/branch23/branch-0.23/hadoop-mapreduce-project/src/java/org/apache/hadoop/mapred/JobQueueClient.java:189: displayJobList(org.apache.hadoop.mapreduce.JobStatus[]) has protected access in org.apache.hadoop.mapreduce.tools.CLI
    [javac]       jc.displayJobList(jobs);
    [javac]         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error"
MAPREDUCE-2970,"Null Pointer Exception while submitting a Job, If mapreduce.framework.name property is not set.","If mapreduce.framework.name property is not set in mapred-site.xml, Null pointer Exception is thrown.

java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.Cluster$1.run(Cluster.java:133)
	at org.apache.hadoop.mapreduce.Cluster$1.run(Cluster.java:1)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.mapreduce.Cluster.getFileSystem(Cluster.java:131)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1067)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
	at org.apache.hadoop.examples.WordCount.main(WordCount.java:84)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:189)"
MAPREDUCE-2969,Make the NodeManager delete unused distributed-cache entires by LRU policy,This is the same as MAPREDUCE-2494 and MAPREDUCE-2572 but for YARN/MRV2.
MAPREDUCE-2968,ContainerID record should get rid of ApplicationId field ,"It already has ApplicationAttemptId field which in turn refers to ApplicationId.

I've known this for some time, but didn't do this as it will touch a lot of code even if the patch is mostly going to be mechanical/dumb. But we should get this in sooner than later."
MAPREDUCE-2966,Add ShutDown hooks for MRV2 processes,"NodeManager registers a shudown hook in case of JVM exit.
Similar way, all other processes RM, HistoryServer, MRAppMaster should also handle the shutdown gracefully in case of JVM exit."
MAPREDUCE-2965,"Streamline hashCode(), equals(), compareTo() and toString() for all IDs","MAPREDUCE-2954 moved these methods to the record interfaces from the PB impls for ContainerId, ApplicationId and ApplicationAttemptId. This is good as they don't need to be tied to the implementation.

We should do the same for all IDs. In fact some of these are missing for IDs like MR AM JobId, TaskId etc."
MAPREDUCE-2964,mapreduce trunk build fails with compile-mapred-test ant target,"{noformat}
compile-mapred-test:
    [mkdir] Created dir: /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build/test/mapred/classes
....
  [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestCombineOutputCollector.java:128: warning: [unchecked] unchecked conversion
    [javac] found   : org.apache.hadoop.mapred.IFile.Writer
    [javac] required: org.apache.hadoop.mapred.IFile.Writer<java.lang.String,java.lang.Integer>
    [javac]     Writer<String, Integer> mockWriter = mock(Writer.class);
    [javac]                                              ^
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/mapred/TestJvmManager.java:63: unreported exception java.io.IOException; must be caught or declared to be thrown
    [javac]     FileUtil.fullyDelete(TEST_DIR);
    [javac]                         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 1 error
    [javac] 2 warnings

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:538: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:615: Compile failed; see the compiler error output for details.

{noformat}"
MAPREDUCE-2963,TestMRJobs hangs waiting to connect to history server.,TestMRJobs is hanging waiting to connect to history server. I will post the logs next.
MAPREDUCE-2961,Increase the default threadpool size for container launching in the application master.,"Currently the default threadpool size is 10 for launching containers in ContainerLauncherImpl. We should increase that to 100 for a reasonable default, so that container launching is not backed up by a small thread pool size."
MAPREDUCE-2958,mapred-default.xml not merged from mr279,"I have been running wordcount out of the 23 examples jar.  It says it succeeds but doesn't actually output a file.

hadoop jar examples/hadoop-mapreduce-0.23.0-SNAPSHOT/hadoop-mapreduce-examples-0.23.0-SNAPSHOT.jar wordcount input output2

input file is really basic:
fdksajl
dlkfsajlfljda;j
kldfsjallj
test
one
two
test"
MAPREDUCE-2957,The TT should not re-init if it has no good local dirs,The TT will currently try to re-init itself on disk failure even if it has no good local dirs. It should shutdown instead.
MAPREDUCE-2956,CompositeService should try to stop all services even if one fails,Right now if one of the services fails to stop in the CompositeServices it just quits.  It should continue and try to stop all the services so it shuts down as clean as possible.
MAPREDUCE-2954,Deadlock in NM with threads racing for ApplicationAttemptId,"Found this:
{code}
Java stack information for the threads listed above:
===================================================
""Thread-45"":
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.getApplicationId(ApplicationAttemptIdPBImpl.java:101)
        - waiting to lock <0xb6a43ba0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:144)
        - locked <0xb6a443a0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:31)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:215)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:34)
        at java.util.concurrent.ConcurrentSkipListMap.doGet(ConcurrentSkipListMap.java:797)
        at java.util.concurrent.ConcurrentSkipListMap.get(ConcurrentSkipListMap.java:1640)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:360)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher.handle(ContainerManagerImpl.java:355)
        at org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(AsyncDispatcher.java:113)
        at org.apache.hadoop.yarn.event.AsyncDispatcher$1.run(AsyncDispatcher.java:75)
        at java.lang.Thread.run(Thread.java:619)
""Thread-30"":
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.getApplicationId(ApplicationAttemptIdPBImpl.java:101)
        - waiting to lock <0xb6a443a0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:144)
        - locked <0xb6a43ba0> (a org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl)
        at org.apache.hadoop.yarn.api.records.impl.pb.ApplicationAttemptIdPBImpl.compareTo(ApplicationAttemptIdPBImpl.java:31)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:215)
        at org.apache.hadoop.yarn.api.records.impl.pb.ContainerIdPBImpl.compareTo(ContainerIdPBImpl.java:34)
        at java.util.concurrent.ConcurrentSkipListMap.doRemove(ConcurrentSkipListMap.java:1078)
        at java.util.concurrent.ConcurrentSkipListMap.remove(ConcurrentSkipListMap.java:1673)
        at java.util.concurrent.ConcurrentSkipListMap$Iter.remove(ConcurrentSkipListMap.java:2256)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.getNodeStatus(NodeStatusUpdaterImpl.java:223)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl.access$300(NodeStatusUpdaterImpl.java:62)
        at org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl$1.run(NodeStatusUpdaterImpl.java:262)
Found 1 deadlock.
{code}"
MAPREDUCE-2953,"JobClient fails due to a race in RM, removes staged files and in turn crashes MR AM","[~Karams] ran into this multiple times. MR JobClient crashes immediately.

{code}
11/09/08 10:52:35 INFO mapreduce.JobSubmitter: number of splits:2094
11/09/08 10:52:36 INFO mapred.YARNRunner: AppMaster capability = memory: 2048,
11/09/08 10:52:36 INFO mapred.YARNRunner: Command to launch container for ApplicationMaster is : $JAVA_HOME/bin/java -Dhadoop.root.logger=INFO,console -Xmx1536m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1315478927026 1 <FAILCOUNT> 1><LOG_DIR>/stdout 2><LOG_DIR>/stderr
11/09/08 10:52:36 INFO mapred.ResourceMgrDelegate: Submitted application application_1315478927026_1 to ResourceManager
11/09/08 10:52:36 INFO mapreduce.JobSubmitter: Cleaning up the staging area /user/gridperf/.staging/job_1315478927026_0001
RemoteTrace:
 at Local Trace:
        org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: failed to run job
        at org.apache.hadoop.yarn.factories.impl.pb.YarnRemoteExceptionFactoryPBImpl.createYarnRemoteException(YarnRemoteExceptionFactoryPBImpl.java:39)
        at org.apache.hadoop.yarn.ipc.RPCUtil.getRemoteException(RPCUtil.java:47)
        at org.apache.hadoop.mapred.YARNRunner.submitJob(YARNRunner.java:250)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:377)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1072)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1069)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1069)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1089)
        at org.apache.hadoop.examples.RandomWriter.run(RandomWriter.java:283)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.examples.RandomWriter.main(RandomWriter.java:294)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:68)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:189)
}
{code}

The client crashes due to a race in RM.

Because the client fails, it immediately removes the staged files which in turn makes the MR AM itself to crash due to failed localization on the NM."
MAPREDUCE-2952,Application failure diagnostics are not consumed in a couple of cases,"When Container crashes, the reason for failures isn't propagated because of a bug in _RMAppAttemptImpl.AMContainerCrashedTransition_ which simply discards the diagnostics of the container. Also RMAppAttemptImpl.diagnostics is never consumed."
MAPREDUCE-2951,Problem while building hadoop trunk on Windows 7,"Hi All,
I am facing problem with generating tar files for all hadoop modbles.
The generated tar files are not correct. 
For example, for hadoop-common-0.24.0-SNAPSHOT.tar.gz file/bin folder is missing all sh files.

Because of this i am not able to launch hdfs or mapreduce.

To generate the tar file i used following command

*mvn package -Pdist -Dtar -DskipTests -P-cbuild -Dcommons.daemon.os.name=linux -Dcommons.daemon.os.arch=i686 -X*

I am not maven expert but following is the part of the debug information generated by above command talks about excluding *.sh file from assembly.

[DEBUG]   (s) siteDirectory = D:\iSAP\Hadoop\SVN\trunk\hadoop-common-project\hadoop-common\target\site
[DEBUG]   (f) skipAssembly = false
[DEBUG]   (s) tarLongFileMode = warn
[DEBUG]   (s) tempRoot = D:\iSAP\Hadoop\SVN\trunk\hadoop-common-project\hadoop-common\target\archive-tmp
[DEBUG]   (s) workDirectory = D:\iSAP\Hadoop\SVN\trunk\hadoop-common-project\hadoop-common\target\assembly\work
[DEBUG] -- end configuration --
[DEBUG] Before assembly is interpolated:

<?xml version=""1.0"" encoding=""UTF-8""?><assembly>
  <id>hadoop-distro</id>
  <formats>
    <format>dir</format>
  </formats>
  <includeBaseDirectory>false</includeBaseDirectory>
  <fileSets>
    <fileSet>
      <directory>${basedir}/src/main/bin</directory>
      <outputDirectory>/bin</outputDirectory>
      <excludes>
        <exclude>*.sh</exclude>
      </excludes>
      <fileMode>0755</fileMode>
    </fileSet>


Anyone has any idea about this?


Thanks & Regards,
Abhijit
"
MAPREDUCE-2950,[Gridmix] TestUserResolve fails in trunk,TestUserResolve fails in trunk.
MAPREDUCE-2949,NodeManager in a inconsistent state if a service startup fails.,"When a service startup fails at the Nodemanager, the Nodemanager JVM doesnot exit as the following threads are still running.

Daemon Thread [Timer for 'NodeManager' metrics system] (Running)	
Thread [pool-1-thread-1] (Running)	
Thread [Thread-11] (Running)	
Thread [DestroyJavaVM] (Running).

As a result, the NodeManager keeps running even though no services are started."
MAPREDUCE-2948,"Hadoop streaming test failure, post MR-2767","After removing LinuxTaskController in MAPREDUCE-2767, one of the tests in contrib/streaming: TestStreamingAsDifferentUser.java is failing since it imports import org.apache.hadoop.mapred.ClusterWithLinuxTaskController. Patch forthcoming."
MAPREDUCE-2947,Sort fails on YARN+MR with lots of task failures,"[~karams](the great man the world hardly knows about) found lots of failing tasks while running sort on a 350 node cluster. The failed tasks eventually failed the job and this happening consistently on the big cluster.
{quote}
Container launch failed for container_1315410418107_0002_01_002511 : RemoteTrace: java.lang.IllegalArgumentException at java.nio.Buffer.position(Buffer.java:218) at java.nio.HeapByteBuffer.get(HeapByteBuffer.java:129) at java.nio.ByteBuffer.get(ByteBuffer.java:675) at com.google.protobuf.ByteString.copyFrom(ByteString.java:108) at com.google.protobuf.ByteString.copyFrom(ByteString.java:117) at org.apache.hadoop.yarn.util.ProtoUtils.convertToProtoFormat(ProtoUtils.java:97) at org.apache.hadoop.yarn.api.records.ProtoBase.convertToProtoFormat(ProtoBase.java:59) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.access$100(StartContainerResponsePBImpl.java:35) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl$1$1.next(StartContainerResponsePBImpl.java:134) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl$1$1.next(StartContainerResponsePBImpl.java:122) at com.google.protobuf.AbstractMessageLite$Builder.addAll(AbstractMessageLite.java:319) at org.apache.hadoop.yarn.proto.YarnServiceProtos$StartContainerResponseProto$Builder.addAllServiceResponse(YarnServiceProtos.java:12620) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.addServiceResponseToProto(StartContainerResponsePBImpl.java:144) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.mergeLocalToBuilder(StartContainerResponsePBImpl.java:60) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.mergeLocalToProto(StartContainerResponsePBImpl.java:68) at org.apache.hadoop.yarn.api.protocolrecords.impl.pb.StartContainerResponsePBImpl.getProto(StartContainerResponsePBImpl.java:52) at org.apache.hadoop.yarn.api.impl.pb.service.ContainerManagerPBServiceImpl.startContainer(ContainerManagerPBServiceImpl.java:69) at org.apache.hadoop.yarn.proto.ContainerManager$ContainerManagerService$2.callBlockingMethod(ContainerManager.java:83) at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Server.call(ProtoOverHadoopRpcEngine.java:337) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1496) at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1492) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1490) at LocalTrace: org.apache.hadoop.yarn.exceptions.impl.pb.YarnRemoteExceptionPBImpl: at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:151) at $Proxy20.startContainer(Unknown Source) at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagerPBClientImpl.startContainer(ContainerManagerPBClientImpl.java:81) at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:215) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619) 
{quote}"
MAPREDUCE-2946,TaskTrackers fail at startup,"Upgrading from 0.20.204.0 to 0.20.205.0-SNAPSHOT, the TaskTrackers refused to start because the cleanup failed. I was able to start the task trackers by deleting the mapred localdirs across the cluster.

I was running with the linux task controller and security turned on."
MAPREDUCE-2945,Hbase Batch Import Insertion Method,"Ubuntu
Hadoop & Hbase From CDH3

I am trying to write Hbase Batch Import Insertion Method, I am new in Hbase & Hadoop.
Can any one tell me example, Or can give info link.


"
MAPREDUCE-2944,Improve checking of input for Api displayTasks() ,"The JobClient.displayTasks() will do nothing and won't throw any exception either, 
while user call it with invalid type/state of task.
To be more friendly,it's better to remain user to check his parameters with an exception. "
MAPREDUCE-2942,TestNMAuditLogger.testNMAuditLoggerWithIP failing,"This is failing right after the MAPREDUCE-2655 commit, but Jenkins did report a success when that patch was submitted.

{code}
Standard Output

2011-09-07 07:12:52,785 INFO  ipc.Server (Server.java:run(349)) - Starting Socket Reader #1 for port 33000
2011-09-07 07:12:52,787 INFO  ipc.Server (WritableRpcEngine.java:registerProtocolAndImpl(399)) - ProtocolImpl=org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger$MyTestRPCServer protocolClass=org.apache.hadoop.yarn.server.nodemanager.TestNMAuditLogger$MyTestRPCServer version=1
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(642)) - IPC Server Responder: starting
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(473)) - IPC Server listener on 33000: starting
2011-09-07 07:12:52,788 INFO  ipc.Server (Server.java:run(1459)) - IPC Server handler 0 on 33000: starting
2011-09-07 07:12:52,798 INFO  ipc.Server (Server.java:run(1497)) - IPC Server handler 0 on 33000, call: ping(), rpc version=2, client version=1, methodsFingerPrint=-1968962669 from 67.195.138.31:33806, error: 
java.io.IOException: java.io.IOException: Unknown protocol: org.apache.hadoop.ipc.TestRPC$TestProtocol
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:622)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1489)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1485)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1135)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1483)
{code}"
MAPREDUCE-2941,In secure mode RM WebUI shows wrong user for application,In secure mode RM WebUI shows wrong user for application (mapred) although the RM logs show the right user (me).
MAPREDUCE-2940,Build fails with ant 1.7.0 but works with 1.8.0,"contrib builds fail when using Ant 1.7.

build.xml calls build.xml in contrib, which calls block-forensics build, which in turn uses build-contrib.
The inheritAll=true overrides the basedir in ant 1.7.0 but not in 1.8.0.
"
MAPREDUCE-2939,Ant setup on hadoop7 jenkins host,"From the build error it looks like
a) ant is not set up on the machine
b) $ANT_HOME point to the wrong spot

"
MAPREDUCE-2938,Missing log stmt for app submission fail CS,Missing log stmt for app submission fail CS
MAPREDUCE-2937,Errors in Application failures are not shown in the client trace.,"The client side does not show enough information on why the job failed. Here is step to reproduce it:

1) set the scheduler to be capacity scheduler with queues a, b
2) submit a job to a queue that is not a,b

The job just fails without saying why it failed. We should have enough trace log at the client side to let the user know why it failed."
MAPREDUCE-2936,Contrib Raid compilation broken after HDFS-1620,"After working around MAPREDUCE-2935 by removing TestServiceLevelAuthorization and runing the following:
At the trunk level: mvn clean install package -Dtar -Pdist -Dmaven.test.skip.exec=true
In hadoop-mapreduce-project: ant compile-contrib -Dresolvers=internal

yields 14 errors."
MAPREDUCE-2934,MR portion of HADOOP-7607 - Simplify the RPC proxy cleanup process,"Once HADOOP-7607 goes in, {{ProtoOverHadoopRpcEngine.stopProxy}} will need to be removed or at least have its {{@Override}} annotation removed."
MAPREDUCE-2933,Change allocate call to return ContainerStatus for completed containers rather than Container ,"Change allocate call to return ContainerStatus for completed containers rather than Container, we should do this all the way from the NodeManager too."
MAPREDUCE-2932,Missing instrumentation plugin class shouldn't crash the TT startup per design,"Per the implementation of the TaskTracker instrumentation plugin implementation (from 2008), a ClassNotFoundException during loading up of an configured TaskTracker instrumentation class shouldn't have hampered TT start up at all.

But, there is one class-fetching call outside try/catch, which makes TT fall down with a RuntimeException if there's a class not found. Would be good to include this line into the try/catch itself.

Strace would appear as:

{code}
2011-08-25 11:45:38,470 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: org.apache.hadoop.mapred.CustomInstPlugin 
at org.apache.hadoop.conf.Configuration.getClass(Configuration.java) 
at org.apache.hadoop.mapred.TaskTracker.getInstrumentationClass(TaskTracker.java) 
at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java) 
{code}"
MAPREDUCE-2931,CLONE - LocalJobRunner should support parallel mapper execution,"The LocalJobRunner currently supports only a single execution thread. Given the prevalence of multi-core CPUs, it makes sense to allow users to run multiple tasks in parallel for improved performance on small (local-only) jobs.

It is necessary to patch back MAPREDUCE-1367 into Hadoop 0.20.X version. Also, MapReduce-434 should be submitted together."
MAPREDUCE-2930,Generate state graph from the State Machine Definition,It would be nice to automatically generate the state machine visualization from the state machine declaration using graphviz or some such. Some state graphs already attached to MAPREDUCE-279.
MAPREDUCE-2928,MR-2413 improvements,Tracks improvements to MR-2413. See [this comment|https://issues.apache.org/jira/browse/MAPREDUCE-2413?focusedCommentId=13095073&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13095073].
MAPREDUCE-2927,CompletedJob.isUber throws a Yarn exception which makes the JobHistory UI unusable.,CompletedJob.isUber on the MR-279 branch returns jobInfo.getIsUber() but got turned into an exception when MR-279 was merged to trunk. SVN Revision 1159166.
MAPREDUCE-2926,500 Error in ResourceManager UI,"When accessing the resource manager UI the following is returned
{noformat}
Problem accessing /. Reason:

    org.codehaus.jackson.type.JavaType.<init>(Ljava/lang/Class;)V

Caused by:

java.lang.NoSuchMethodError: org.codehaus.jackson.type.JavaType.<init>(Ljava/lang/Class;)V
	at org.codehaus.jackson.map.type.TypeBase.<init>(TypeBase.java:15)
	at org.codehaus.jackson.map.type.SimpleType.<init>(SimpleType.java:45)
	at org.codehaus.jackson.map.type.SimpleType.<init>(SimpleType.java:40)
	at org.codehaus.jackson.map.type.TypeBindings.<clinit>(TypeBindings.java:20)
	at org.codehaus.jackson.map.type.TypeFactory._fromType(TypeFactory.java:530)
	at org.codehaus.jackson.map.type.TypeFactory.type(TypeFactory.java:63)
	at org.codehaus.jackson.map.ObjectMapper.<clinit>(ObjectMapper.java:179)
	at org.apache.hadoop.yarn.webapp.Controller.<clinit>(Controller.java:43)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
	at com.google.inject.DefaultConstructionProxyFactory$2.newInstance(DefaultConstructionProxyFactory.java:81)
	at com.google.inject.ConstructorInjector.construct(ConstructorInjector.java:85)
	at com.google.inject.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:111)
	at com.google.inject.InjectorImpl$4$1.call(InjectorImpl.java:758)
	at com.google.inject.InjectorImpl.callInContext(InjectorImpl.java:804)
	at com.google.inject.InjectorImpl$4.get(InjectorImpl.java:754)
	at com.google.inject.InjectorImpl.getInstance(InjectorImpl.java:793)
	at org.apache.hadoop.yarn.webapp.Dispatcher.service(Dispatcher.java:136)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at com.google.inject.servlet.ServletDefinition.doService(ServletDefinition.java:216)
	at com.google.inject.servlet.ServletDefinition.service(ServletDefinition.java:141)
	at com.google.inject.servlet.ManagedServletPipeline.service(ManagedServletPipeline.java:93)
	at com.google.inject.servlet.FilterChainInvocation.doFilter(FilterChainInvocation.java:63)
	at com.google.inject.servlet.ManagedFilterPipeline.dispatch(ManagedFilterPipeline.java:122)
	at com.google.inject.servlet.GuiceFilter.doFilter(GuiceFilter.java:110)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.apache.hadoop.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:892)
	at org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1212)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:399)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:182)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:450)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:326)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:542)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:928)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:549)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:212)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:404)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:410)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)

Powered by Jetty://

{noformat}"
MAPREDUCE-2925,job -status <JOB_ID> is giving continuously info message for completed jobs on the console,"This below message is coming continuously on the console.

{code:xml}
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Failed to contact AM for job job_1314955256658_0009  Will retry..
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server null
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Failed to contact AM for job job_1314955256658_0009  Will retry..
11/09/02 16:00:00 INFO mapred.ClientServiceDelegate: Application state is completed. Redirecting to job history server null
{code}
"
MAPREDUCE-2924,TaskTracker number of failed disks to tolerate should be configurable,"Like HDFS-1161 but for the TT. The user should be able to configure how many valid disks are needed for operation. Currently the TT will start and accept tasks even if eg only 1 of its 12 disks is working, which leads to poor performance of jobs with tasks that use this machine."
MAPREDUCE-2923,Add a new record to JobHistory to record start time of each instance of AM,Add a new record to JobHistory to record start time of each instance of AM
MAPREDUCE-2922,create-c++-task-controller-configure called during ant build create-c++-configure and fails ,"if you call ant create-c++-configure it tries to run create-c++-task-controller-configure, which fails with error about >>>     [exec] Makefile.am: C objects in subdir but `AM_PROG_CC_C_O'.  We don't need to build the task-controller anymore in mrv2 so simply remove it from build.xml 


cmdline used to build:
ant -Dresolvers=internal -Dcompile.c++=true -Dcompile.native=true             create-c++-configure binary  "
MAPREDUCE-2921,TaskTracker won't start with failed local directory,Chmod'ing one of the mapred local directories so it's not executable will cause the TT to fail to start. Doing this after the TT has started will result in a TT that is up but can not execute tasks. 
MAPREDUCE-2920,Local log dir links in the JT web UI are broken  ,"The task log servlet can no longer access user logs because MAPREDUCE-2415 introduce symlinks to the logs and jetty is not configured by default to follow  symlinks (for security reasons).
"
MAPREDUCE-2919,The JT web UI should show job start times ,"It would be helpful if the list of jobs in the main JT web UI (running, completed, failed..) had a column with the start time. Clicking into each job detail can get tedious."
MAPREDUCE-2917,Corner case in container reservations,"Saw a corner case in container reservations where the node on which the AM is running was reserved, and hence never fulfilled leaving the application hanging."
MAPREDUCE-2916,Ivy build for MRv1 fails with bad organization for common daemon.,This jira is to ignore ivy resolve errors because of bad poms in common daemons.
MAPREDUCE-2915,LinuxTaskController does not work when JniBasedUnixGroupsNetgroupMapping or JniBasedUnixGroupsMapping is enabled,"When a job is submitted, LinuxTaskController launches the native task-controller binary for job initialization. The native program does a series of prep work and call execv() to run JobLocalizer.  It was observed that JobLocalizer does fails to run when JniBasedUnixGroupsNetgroupMapping or JniBasedUnixGroupsMapping is enabled, resulting in 100% job failures.

JobLocalizer normally does not need the native library (libhadoop) for its functioning, but enabling a JNI user-to-group mapping function cause it to load the library. However, JobLocalizer cannot locate the library since ""java.library.path"" is not set.

The proposed solution is to pass the java.library.path property through task-controller. LinuxTaskController already does it when launching the task log truncater."
MAPREDUCE-2913,TestMRJobs.testFailingMapper does not assert the correct thing.,"{code}
    Assert.assertEquals(TaskCompletionEvent.Status.FAILED, 
        events[0].getStatus().FAILED);
    Assert.assertEquals(TaskCompletionEvent.Status.FAILED, 
        events[1].getStatus().FAILED);
{code}

when optimized would be

{code}
    Assert.assertEquals(TaskCompletionEvent.Status.FAILED, 
        TaskCompletionEvent.Status.FAILED);
    Assert.assertEquals(TaskCompletionEvent.Status.FAILED, 
        TaskCompletionEvent.Status.FAILED);
{code}

obviously these assertions will never fail.  If we remove the {code}.FAILED{code} the asserts no longer pass. This could be because MRApp mocks out the task launcher and never actually launches anything."
MAPREDUCE-2912,Trunk build failing due to testcase failures from many builds,"run-test-mapred:

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/hadoop-mapreduce-project/build.xml:848: Tests failed!

Total time: 115 minutes 23 seconds
Build step 'Execute shell' marked build as failure"
MAPREDUCE-2911,Hamster: Hadoop And Mpi on the same cluSTER,"MPI is commonly used for many machine-learning applications. OpenMPI (http://www.open-mpi.org/) is a popular BSD-licensed version of MPI. In the past, running MPI application on a Hadoop cluster was achieved using Hadoop Streaming (http://videolectures.net/nipsworkshops2010_ye_gbd/), but it was kludgy. After the resource-manager separation from JobTracker in Hadoop, we have all the tools needed to make MPI a first-class citizen on a Hadoop cluster. I am currently working on the patch to make MPI an application-master. Initial version of this patch will be available soon (hopefully before September 10.) This jira will track the development of Hamster: The application master for MPI."
MAPREDUCE-2909,Docs for remaining records in yarn-api,"MAPREDUCE-2891 , MAPREDUCE-2897 & MAPREDUCE-2898 added javadocs for core protocols (i.e. AMRMProtocol, ClientRMProtocol & ContainerManager). Most 'records' also have javadocs - this jira is to track the remaining ones."
MAPREDUCE-2908,Fix findbugs warnings in Map Reduce.,In the current trunk/0.23 codebase there are 5 findbugs warnings which cause the precommit CI builds to -1 the patches.
MAPREDUCE-2907,ResourceManager logs filled with [INFO] debug messages from org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue,I see a lot of info messages (probably used for debugging during development)
MAPREDUCE-2906,FindBugs OutOfMemoryError,"When running the findbugs target from Jenkins, I get an OutOfMemory error.
The ""effort"" in FindBugs is set to Max which ends up using a lot of memory to go through all the classes. The jvmargs passed to FindBugs is hardcoded to 512 MB max.

We can leave the default to 512M, as long as we pass this as an ant parameter which can be overwritten in individual cases through -D, or in the build.properties file (either basedir, or user's home directory).
"
MAPREDUCE-2905,CapBasedLoadManager incorrectly allows assignment when assignMultiple is true (was: assignmultiple per job),"We encountered a situation where in the same cluster, large jobs benefit from mapred.fairscheduler.assignmultiple, but small jobs with small numbers of mappers do not: the mappers all clump to fully occupy just a few nodes, which causes those nodes to saturate and bottleneck. The desired behavior is to spread the job across more nodes so that a relatively small job doesn't saturate any node in the cluster.

Testing has shown that setting mapred.fairscheduler.assignmultiple to false gives the desired behavior for small jobs, but is unnecessary for large jobs. However, since this is a cluster-wide setting, we can't properly tune.

It'd be nice if jobs can set a param similar to mapred.fairscheduler.assignmultiple on submission to better control the task distribution of a particular job."
MAPREDUCE-2904,HDFS jars added incorrectly to yarn classpath,
MAPREDUCE-2903,Map Tasks graph is throwing XML Parse error when Job is executed with 0 maps,"{code:xml}
XML Parsing Error: no element found
Location: http://10.18.52.170:50030/taskgraph?type=map&jobid=job_201108291536_0001
Line Number 1, Column 1:
^
{code}
"
MAPREDUCE-2900,"Replace ContainerId, Resource in ContainerLaunchContext with Container","Replace ContainerId, Resource in ContainerLaunchContext with Container"
MAPREDUCE-2899,Replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext,We can replace major parts of ApplicationSubmissionContext with a ContainerLaunchContext.
MAPREDUCE-2898,Docs for core protocols in yarn-api - ContainerManager,Track docs for ContainerManager and related apis/records.  
MAPREDUCE-2897,Docs for core protocols in yarn-api - ClientRMProtocol,Track docs for ClientRMProtocol and related apis/records.
MAPREDUCE-2896,Remove all apis other than getters and setters in all org/apache/hadoop/yarn/api/records/*,"Remove all apis other than getters and setters in all org/apache/hadoop/yarn/api/records/*.

We initially added some list manipulation methods etc. which are ungainly and need to go."
MAPREDUCE-2895,Merge AllocateResponse and AMResponse,"We need to merge AllocateResponse and AMResponse, having them separate serves no purpose."
MAPREDUCE-2894,Improvements to YARN apis,Ticket to track improvements to YARN apis.
MAPREDUCE-2893,Removing duplicate service provider in hadoop-mapreduce-client-jobclient,"There is duplicate provider class name in the configuration file of ClientProtocolProvider under hadoop-mapreduce-client-jobclient. Although it will be ignored.
"
MAPREDUCE-2892,Improvements to AM apis,"Some api changes before we declare yarn apis as stable:

# FinishApplicationMasterRequest doesn't need to send out 'tracking url'.
# FinishApplicationMasterRequest shouldn't use 'string' as final state - it's got to be an enum and we need to use that enum appropriately in the RM's state-machines."
MAPREDUCE-2891,Docs for core protocols in yarn-api - AMRMProtocol,We need to add docs for AMRMProtocol
MAPREDUCE-2890,Documentation for MRv2,Let's use this jira to track docs for all of MRv2.
MAPREDUCE-2889,Add docs for writing new application frameworks,"We need to add docs for writing new application frameworks, including examples, javadocs and sample apps."
MAPREDUCE-2888,saveVersion.sh doesn't work when svn copy is staged,"The build fails with an error on the sed command, since saveVersion.sh doesn't correctly grab the URL."
MAPREDUCE-2887,MR changes to match HADOOP-7524 (multiple RPC protocols),
MAPREDUCE-2886,Fix Javadoc warnings in MapReduce.,"On the current trunk and 0.23, there are 73 javadoc warnings which is causing the buildbot to -1 every patch in MR. We need to fix this to stabilize the CI precommit builds."
MAPREDUCE-2885,mapred-config.sh doesn't look for $HADOOP_COMMON_HOME/libexec/hadoop-config.sh,mapred-config.sh doesn't look for $HADOOP_COMMON_HOME/libexec/hadoop-config.sh and thus fails to find it and errors out.
MAPREDUCE-2884,tmpjars not working when default filesystem mismatches between client and server,"One of the HBase tests is failing which tries to add a local file to the distributed cache using the ""tmpjars"" configuration variable. The first half of the distributedcache setup decides not to copy it to the JT, because the JT is apparently using the same filesystem, but the second half of distributedcache setup tries to check timestamps on a different filesystem where the file does not exist."
MAPREDUCE-2883,MR FI tests failing to build,running ant mvn-install in hadoop-mapreduce-project on branch-0.23 fails in the fault injection compilation
MAPREDUCE-2882,TestLineRecordReader depends on ant jars,This test is currently importing an ant utility class to read a file - this dependency doesn't work in mavenized land.
MAPREDUCE-2881,"mapreduce ant compilation fails ""java.lang.IllegalStateException: impossible to get artifacts""","[ivy:resolve] 	found com.cenqua.clover#clover;3.0.2 in fs
[ivy:resolve] 
[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: ERRORS
[ivy:resolve] 	impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16
[ivy:resolve] 
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/build.xml:451: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/contrib/build.xml:30: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/hadoop-mapreduce-project/src/contrib/build-contrib.xml:511: impossible to resolve dependencies:
	java.lang.IllegalStateException: impossible to get artifacts when data has not been loaded. IvyNode = log4j#log4j;1.2.16
"
MAPREDUCE-2880,Fix classpath construction for MRv2,MRConstants.java refers a hard-coded version of MR AM jar. The build config works around with a symlink. The deployment currently needs symlink workaround as well. We need to fix this so that we can actually launch arbitrary versions of AMs.
MAPREDUCE-2879,Change mrv2 version to be 0.23.0-SNAPSHOT,"Currently yarn.version and hadoop-mapreduce.version are set to be 1.0, clearly it's 0.23.0. :)

Also, we should stop using ${yarn.version} and ${hadoop-mapreduce.version} in all the poms, maven doesn't like the version substitutions - it complains bitterly! :)"
MAPREDUCE-2878,Fix the INSTALL file,"The URL in INSTALL should be changed accordingly, after the layout of directories  has been changed.
And meanwhile,the HDFS should no longer be compiled with ant but maven."
MAPREDUCE-2877,Add missing Apache license header in some files in MR and also add the rat plugin to the poms.,"Some of the files in MR have a missing Apache header files. We also need to add the apache-rat plugin to be able to run rat automatically via the top level pom. 
"
MAPREDUCE-2876,ContainerAllocationExpirer appears to use the incorrect configs,"ContainerAllocationExpirer sets the expiration interval to be RMConfig.CONTAINER_LIVELINESS_MONITORING_INTERVAL but uses AMLIVELINESS_MONITORING_INTERVAL as the interval.  This is very different from what AMLivelinessMonitor does.

There should be two configs RMConfig.CONTAINER_LIVELINESS_MONITORING_INTERVAL for the monitoring interval and RMConfig.CONTAINER_EXPIRY_INTERVAL for the expiry.
"
MAPREDUCE-2875,NM does not communicate Container crash to RM,"Faulty container crash detection code path in NodeManager.

Steps:
Run a job. 
Kill the AM container in NM.

NM logs has:
org.apache.hadoop.yarn.state.InvalidStateTransitonException: Invalid event: CONTAINER_KILLED_ON_REQUEST at RUNNING
        at org.apache.hadoop.yarn.state.StateMachineFactory.doTransition(StateMachineFactory.java:297)
        at org.apache.hadoop.yarn.state.StateMachineFactory.access$300(StateMachineFactory.java:39)
        at org.apache.hadoop.yarn.state.StateMachineFactory$InternalStateMachine.doTransition(StateMachineFactory.java:439)
        at org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.handle(ContainerImpl.java:685)

"
MAPREDUCE-2874,ApplicationId printed in 2 different formats and has 2 different toString routines that are used,"Looks like the ApplicationId is now printed in 2 different formats.  ApplicationIdPBImpl.java has a toString routine that prints it in the format: return ""application_"" + this.getClusterTimestamp() + ""_"" + this.getId();

While the webapps use ./hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/util/Apps.java toString that prints it like:     
return _join(""app"", id.getClusterTimestamp(), id.getId());  "
MAPREDUCE-2872,Optimize TaskTracker memory usage,"We observe high memory usage of framework level components on slave node, mainly TaskTracker & Child, especially for large clusters. To be clear at first, large jobs with 10000-100000 map and >10000 reduce tasks are very common in our offline cluster, and will very likely continue to grow. This is reasonable because the number of map & reduce slots are in the same range, and it's impractical for users to reduce their job's task number without execution time penalty. 

High memory consumption will:
* Limit the memory used by up level application; 
* Reduce page cache space, which plays a  important role in spill, merge, shuffle and even HDFS performance; 
* Increase the probability of slave node OOM, which may affect storage layer(HDFS) too. 

A stable TT with predictable memory behavior is desired, this also applies to Child JVM.

This issue focuses on TaskTracker memory optimization, on our cluster, TaskTracker use 600M+ memory & 300%+(3core+) CPU at peak, and 300M+ memory & much less CPU in average, so we need to set -Xmx to 1000M for TT to prevent OOM, then the TT memory is in 200M-1200M range, and 800M in average. 

Here are some ideas:  

Jetty http connection use a lot memory when these are many requests in queue, we need to limit the length of the queue, combine multiple requests into one request, or use netty just like MR2

TaskCompletionEvents use a lot memory too if a job have large number of map task, this won't be a problem in MR2, but can be optimized, A typical TaskCompletionEvent object use 296 bytes memory, a job with 100000 map will use about 30M memory, problem will appear if there are some big RunningJob in a TaskTracker. There are more memory efficient implementations for TaskCompletionEvent.

IndexCache: memory of indexcache varies directly as reduce number, on large cluster 10MB of indexcache is not enough, 
we set it to 100MB, again use primitive long[] instead of IndexRecord[] can save 50% of memory.

Although some of the above won't be a problem in MR-v2, since MR-v1 is still widely used, I think optimizations are needed.



"
MAPREDUCE-2871,Docs updates for MR2,Jira for docs changes needed to reflect MR2 (Eg the cluster setup page). If there's a lot of them this can be an umbrella jira.
MAPREDUCE-2869,DelegationTokenRenewal should handle abstract delegation tokens,{{DelegationTokenRenewal}} only handles tokens of type {{DelegationTokenIdentifiers}}.  This precludes renewal of job manager tokens (which will be fixed on another jira).  It should accept {{AbstractDelegationTokenIdentifiers}}.
MAPREDUCE-2868,ant build broken in hadoop-mapreduce dir,"The ant build target doesn't work in the hadoop-mapreduce directory since the mavenization of hdfs changes were checked in.

Error it gives is:
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]           ::          UNRESOLVED DEPENDENCIES         ::
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]           :: org.apache.avro#avro-ipc;working@host: not found
[ivy:resolve]           :: org.apache.hadoop#hadoop-alfredo;working@host: not found
[ivy:resolve]           :: commons-daemon#commons-daemon;working@host: not found
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::

Steps I followed:
check out trunk
build common/hdfs: mvn clean install -Pbintar -DskipTests
build yarn/mapred: 
mvn clean install assembly:assembly -DskipTests
ant veryclean tar -Dresolvers=internal  ----> this fails
"
MAPREDUCE-2867,Remove Unused TestApplicaitonCleanup in resourcemanager/applicationsmanager.,TestApplicationCleanup in resourcemanager/applicationsmanager doesnt do anything. There is already a test in resourcemanager/TestApplicationCleanup which tests all the cleanup code for container and applications. We should remove the unused one in the trunk.
MAPREDUCE-2866,"""Ignoring 'duplicate' heartbeat from tracker_x:localhost/127.0.0.1:35419'; resending the previous 'lost' response"" message is coming continuously for some time",
MAPREDUCE-2864,Renaming of configuration property names in yarn,"Now that YARN has been put in to trunk we should do something similar to MAPREDUCE-849.  We should go back and look at all of the configurations that have been added in and rename them as needed to be consistent and subdivided by component.

# We should use all lowercase in the config names. e.g., we should use appsmanager instead of appsManager etc.
# history server config names should be prefixed with mapreduce instead of yarn."
MAPREDUCE-2863,Support web-services for RM & NM,It will be very useful for RM and NM to support web-services to export json/xml.
MAPREDUCE-2861,Modify version_control.html to reflect new path to mapreduce trunk,We need to modify http://hadoop.apache.org/mapreduce/version_control.html to reflect the change of mapreduce trunk to trunk/hadoop-mapreduce.
MAPREDUCE-2860,Fix log4j logging in the maven test cases.,At present the logging in the new test cases is broken because surefire isnt able to find the log4j properties file. 
MAPREDUCE-2859,mapreduce trunk is broken with eclipse plugin contrib,"ant compile with eclipse home fails mapreduce trunk builds.

$ANT_HOME/bin/ant -Dversion=${VERSION} -Declipse.home=$ECLIPSE_HOME compile

compile:
     [echo] contrib: eclipse-plugin 
    [javac] Compiling 45 source files to /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/contrib/eclipse-plugin/classes
    [javac] /home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopServer.java:39: cannot find symbol
    [javac] symbol  : class JobClient
    [javac] location: package org.apache.hadoop.mapred
    [javac] import org.apache.hadoop.mapred.JobClient;
    [javac]                                ^


-----




 [javac]     JobConf conf = new JobConf(location.getConfiguration());
    [javac]                        ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 49 errors

BUILD FAILED
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build.xml:451: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/contrib/build.xml:30: The following error occurred while executing this line:
/home/jenkins/jenkins-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/contrib/eclipse-plugin/build.xml:62: Compile failed; see the compiler error output for details.
"
MAPREDUCE-2858,MRv2 WebApp Security,"In MRv2, while the system servers (ResourceManager (RM), NodeManager (NM) and NameNode (NN)) run as ""trusted""
system users, the application masters (AM) run as users who submit the application. While this offers great flexibility
to run multiple version of mapreduce frameworks (including their UI) on the same Hadoop cluster, it has significant
implication for the security of webapps (Please do not discuss company specific vulnerabilities here).

Requirements:

# Secure authentication for AM (for app/job level ACLs).
# Webapp security should be optional via site configuration.
# Support existing pluggable single sign on mechanisms.
# Should not require per app/user configuration for deployment.
# Should not require special site-wide DNS configuration for deployment.

This the top jira for webapp security. A design doc/notes of threat-modeling and counter measures will be posted on the wiki."
MAPREDUCE-2856,wire hadoop-mapreduce build to trunk build in Maven POM,"hadoop-mapreduce is not wired to the trunk build.

The trunk/pom.xml must be updated to contain.

{code}
<module>hadoop-mapreduce</module>
{code}
"
MAPREDUCE-2855,ResourceBundle lookup during counter name resolution takes a lot of time,"Loading a job status page in trunk takes a lot of time, and it seems like most of the time is spent resolving counter names. Looking through the JDK source, ResourceBundle.getBundle(String) ends up calling getClassContext() which is not very efficient. I think if we pass our own classloader manually it will be faster. In Counters.incrAllCounters, we may also be able to avoid setting the counter name if one is already set."
MAPREDUCE-2854,update INSTALL with config necessary run mapred on yarn,"The following config is needed to run mapreduce on yarn framework.  Document it in the INSTALL doc.

<property>
<name> mapreduce.framework.name</name>
<value>yarn</value>
</property>


The INSTALL doc also still references the old 22 mapred examples jar."
MAPREDUCE-2852,Jira for YDH bug 2854624 ,"The DefaultTaskController and LinuxTaskController reference Yahoo! internal bug 2854624:

{code}
FileSystem rawFs = FileSystem.getLocal(getConf()).getRaw();
long logSize = 0; //TODO: Ref BUG:2854624
{code}

This jira tracks this TODO. If someone w/ access to Yahoo's bugzilla could update this jira with what the bug is that would be great."
MAPREDUCE-2850,Add test for TaskTracker disk failure handling (MR-2413),MR-2413 doesn't have any test coverage that eg tests that the TT can survive disk failure.
MAPREDUCE-2849,Add javadoc and site documentation for MRv2,Need API and site documentation for MRv2. The initial patch will use maven's default [apt format|https://maven.apache.org/doxia/references/apt-format.html] for site documentation.
MAPREDUCE-2848,Upgrade avro to 1.5.2,Upgrade avro to the current version requires some code changes in mapreduce due to avro package split. The mapreduce part of the change will be part of the atomic commit of HADOOP-7264 after MAPREDUCE-279 is merged to trunk. The jira is for mapreduce change log.
MAPREDUCE-2847,A tiny improvement for the LOG format,"A space character is missing in the file 
""src/java/org/apache/hadoop/mapred/TaskInProgress.java(840):LOG.debug(""TaskInProgress adding"" + status.getNextRecordRange())""."
MAPREDUCE-2846,a small % of all tasks fail with DefaultTaskController,"After upgrading our test 0.20.203 grid to 0.20.204-rc2, we ran terasort to verify operation.  While the job completed successfully, approx 10% of the tasks failed with task runner execution errors and the inability to create symlinks for attempt logs."
MAPREDUCE-2844,[MR-279] Incorrect node ID info ,The node ID info for the nodemanager entires on the RM UI incorrectly displays the value of $yarn.server.nodemanager.address instead of the ID.
MAPREDUCE-2843,[MR-279] Node entries on the RM UI are not sortable,The nodemanager entries on the RM UI is not sortable unlike the other web pages. 
MAPREDUCE-2842,Maven build issues in MR2 ,"* mapreduce has not been rebased on top of trunk

* mapreduce dir/module should be named hadoop-mapreduce (following convention of common, hdfs)

* there is lot of stuff under mapreduce that seems stale (bin/, conf, ivy/, lib/ src/)

* yarn* dirs/modules should be named hadoop-yarn* (following convention of other Hadoop artifacts)

* yarn/bin/ scripts should be under yarn/src/main/bin

* yarn/conf/ scripts should be under yarn/src/main/conf

* JAR POM files do not use hadoop-project POM as parent

* some POM files have version parameterized and this will break things for people consuming JARs from Maven repos

* mapreduce is not using assembly from hadoop-assemblies (the changes introduced by HDFS-2096 make the assembly/packaging reusable across different components)
"
MAPREDUCE-2841,Task level native optimization,"I'm recently working on native optimization for MapTask based on JNI. 

The basic idea is that, add a NativeMapOutputCollector to handle k/v pairs emitted by mapper, therefore sort, spill, IFile serialization can all be done in native code, preliminary test(on Xeon E5410, jdk6u24) showed promising results:

1. Sort is about 3x-10x as fast as java(only binary string compare is supported)

2. IFile serialization speed is about 3x of java, about 500MB/s, if hardware CRC32C is used, things can get much faster(1G/

3. Merge code is not completed yet, so the test use enough io.sort.mb to prevent mid-spill

This leads to a total speed up of 2x~3x for the whole MapTask, if IdentityMapper(mapper does nothing) is used

There are limitations of course, currently only Text and BytesWritable is supported, and I have not think through many things right now, such as how to support map side combine. I had some discussion with somebody familiar with hive, it seems that these limitations won't be much problem for Hive to benefit from those optimizations, at least. Advices or discussions about improving compatibility are most welcome:) 

Currently NativeMapOutputCollector has a static method called canEnable(), which checks if key/value type, comparator type, combiner are all compatible, then MapTask can choose to enable NativeMapOutputCollector.

This is only a preliminary test, more work need to be done. I expect better final results, and I believe similar optimization can be adopt to reduce task and shuffle too. 




"
MAPREDUCE-2840,mr279 TestUberAM.testSleepJob test fails,"Currently the TestUberAM.testSleepJob  is failing on the mr279 branch. 

snippet of failure:
junit.framework.AssertionFailedError: null
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at junit.framework.Assert.assertTrue(Assert.java:27)
	at org.apache.hadoop.mapreduce.v2.TestMRJobs.testSleepJob(TestMRJobs.java:150)
	at org.apache.hadoop.mapreduce.v2.TestUberAM.testSleepJob(TestUberAM.java:58)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)"
MAPREDUCE-2839,MR Jobs fail on a secure cluster with viewfs,TokenCache needs to use the new FileSystem.getDelegationTokens api for it to work with viewfs.
MAPREDUCE-2838,to fix mapreduce builds to use the new hadoop common test jars,"maprecude builds are still resolving the old hadoop-common-test jars.. Instead ivy classifiers should be used to resolve the new hadoop-common test jars ; as maven publishes test jars with classifier tests and not as a separate artifact.

[ivy:resolve] 	[SUCCESSFUL ] org.apache.hadoop#hadoop-common;0.23.0-SNAPSHOT!hadoop-common.jar (1979ms)
[ivy:resolve] downloading https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-common-test/0.23.0-SNAPSHOT/hadoop-common-test-0.23.0-20110727.191243-218.jar ...
[ivy:resolve] ........................................................................................................................ (885kB)"
MAPREDUCE-2837,MR-279: Bug fixes ported from y-merge,Similar to MAPREDUCE-2679.
MAPREDUCE-2836,Provide option to fail jobs when submitted to non-existent pools.,"In some environments, it might be desirable to explicitly specify the fair scheduler pools and to explicitly fail jobs that are not submitted to any of the pools. 

Current behavior of the fair scheduler is to submit jobs to a default pool if a pool name isn't specified or to create a pool with the new name if the pool name doesn't already exist. There should be a configuration option for the fair scheduler that causes it to noisily fail the job if it's submitted to a pool that isn't pre-specified or if the specified pool doesn't exist."
MAPREDUCE-2835,Make per-job counter limits configurable,"The per-job counter limits introduced in MAPREDUCE-1943 are fixed, except for the total number allowed per job (mapreduce.job.counters.limit). It would be useful to make them all configurable."
MAPREDUCE-2833,Job Tracker needs to collect more job/task execution stats and save them to DFS file,"
In order to facilitate offline analysis on the dynamic behaviors and performance characterics of map/reduce jobs, 
we need the job tracker to collect some data about jobs and save them to DFS files. Some data are  in time series form, 
and some are not.
Below is a preliminary list of desired data. Some of them are already available in the current job trackers. Some are new.

For each map/reduce job, we need the following non time series data:
   1. jobid, jobname,  number of mappers, number of reducers, start time, end time, end of mapper phase
   2. Average (median, min, max) of successful mapper execution time, input/output records/bytes
   3. Average (median, min, max) of uncessful mapper execution time, input/output records/bytes
   4.Total mapper retries,  max, average number of re-tries per mapper
   5. The reasons for mapper task fails.

   6. Average (median, min, max) of successful reducer execution time, input/output reocrds/bytes
           Execution time is the difference between the sort end time and the task end time
   7. Average (median, min, max) of successful copy time (from the mapper phase end time  to the sort start time).
   8. Average (median, min, max) of successful sorting time for successful reducers

   9. Average (median, min, max) of unsuccessful reducer execution time (from the end of mapper phase or the start of the task, 
       whichever later, to the end of task)
   10. Total reducer retries,  max, average number of per reducer retries
   11. The reasons for reducer task fails (user code error, lost tracker, failed to write to DFS, etc.)

For each map/reduce job, we collect the following  time series data (with one minute interval):

    1. Numbers of pending mappers, reducers
    2. Number of running mappers, reducers

For the job tracker, we need the following data:

    1. Number of trackers 
    2. Start time 
    3. End time 
    4. The list of map reduce jobs (their ids, starttime/endtime)
    
The following time series data (with one minute interval):
    1. The number of running jobs
    2. The numbers of running mappers/reducers
    3. The number pending mappers/reducers 


The data collection should be optional. That is, a job tracker can turn off such data collection, and 
in that case, it should not pay the cost.

The job tracker should organize the in memory version of the collected data in such a way that:
1. it does not consume excessive amount of memory
2. the data may be suitable for presenting through the Web status pages.

The data saved on DFS files should be in hadoop record format.


"
MAPREDUCE-2829,TestMiniMRMapRedDebugScript times out,"I am running TestMiniMRMapRedDebugScript from trunc.
This is what I see in the stdout:
{code}
2007-11-22 02:21:23,494 WARN  conf.Configuration (Configuration.java:loadResource(808)) - 
hadoop/build/test/mapred/local/1_0/taskTracker/jobcache/job_200711220217_0001/task_200711220217_0001_m_000000_0/job.xml:a attempt to override final parameter: hadoop.tmp.dir;  Ignoring.
2007-11-22 02:21:28,940 INFO  jvm.JvmMetrics (JvmMetrics.java:init(56)) - Initializing JVM Metrics with processName=MAP, sessionId=
2007-11-22 02:22:09,504 INFO  mapred.MapTask (MapTask.java:run(127)) - numReduceTasks: 0
2007-11-22 02:22:42,434 WARN  mapred.TaskTracker (TaskTracker.java:main(1982)) - Error running child
java.io.IOException
	at org.apache.hadoop.mapred.TestMiniMRMapRedDebugScript$MapClass.map(TestMiniMRMapRedDebugScript.java:41)
	at org.apache.hadoop.mapred.TestMiniMRMapRedDebugScript$MapClass.map(TestMiniMRMapRedDebugScript.java:35)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:192)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1977)
{code}

Stderr and debugout both say: Bailing out.
BTW on Windows everything works just fine."
MAPREDUCE-2827,Test code can create Integer.MIN_INT when trying to create a random non-negative integer,"Sadly, Math.abs returns Integer.MIN_VALUE when passed Integer.MIN_VALUE  Thus the code in 
org.apache.hadoop.mapred.TestMapRed appears to need to consider this case.  Patch below.

Index: .
===================================================================
--- .	(revision 8259)
+++ .	(working copy)
@@ -97,7 +97,9 @@
       int randomCount = key.get();
 
       for (int i = 0; i < randomCount; i++) {
-        out.collect(new IntWritable(Math.abs(r.nextInt())), new IntWritable(randomVal));
+    	int collectKey = Math.abs(r.nextInt());
+    	if (collectKey == Integer.MIN_VALUE) collectKey = Integer.MAX_VALUE;
+        out.collect(new IntWritable(collectKey), new IntWritable(randomVal));
       }
     }
     public void close() {
"
MAPREDUCE-2826,Change the job state observer classes to interfaces,"Schedulers will most often want to be the observers of the job state events in a single class. Therefore, I think they should  be interfaces which can have multiple inheritance."
MAPREDUCE-2825,Factor out commonly used code in mapred testcases,The commonly used code in the testcases are made _static_ like {{TestRackAwareTaskPlacement.configureJobConf()}}. It would be nice to factor out these apis and either add it to a class like {{StringUtils}} or into a separate dir like {{utils}}.
MAPREDUCE-2824,MiniMRCluster should have an idempotent shutdown,"It looks on a quick skim-through that the org.apache.hadoop.mapred.MiniMRCluster class has nothing to stop a caller calling shutdown() more than once, with possible adverse consequences. This will normally only show up if a test fails at precisely the wrong place."
MAPREDUCE-2823,map-reduce doctor (Mr Doctor),"Problem Description: 

 Users typically submit jobs with sub-optimal parameters resulting in under-utilization, black-listed task-trackers, time-outs, re-tries etc.

 Issue can be mitigated by submitting job with custom Hadoop parameters."
MAPREDUCE-2822,TaskTracker.offerService could handle IO and Remote Exceptions better,"The core offerService() loop has a try/catch wrapper that catches and processes exceptions. Most cause offerService() to return, which then triggers a sleep and restart in the main loop. But some exceptions are just logged and ignored, which may be inappropriate
"
MAPREDUCE-2821,[MR-279] Missing fields in job summary logs ,"The following fields are missing in the job summary logs in mrv2:
- numSlotsPerMap
- numSlotsPerReduce
- clusterCapacity (Earlier known as clusterMapCapacity and clusterReduceCapacity in 0.20.x)

The first two fields are important to know if the job was a High RAM job or not and the last field is important to know the total available resource in the cluster during job execution.
"
MAPREDUCE-2820,Task tracker should not ask for tasks if its temp disk space is almost full,"
I observed a case where a task tracker still asked for task even though the available disk space on the machine is less than 1%.
Consequently, it had hard time to finish the tasks.
"
MAPREDUCE-2819,"extend JobClient.runJob(JobConf) with the ability to take a timeout, so fail better during test runs","Tests that submit jobs via JobClient hang until they are killed if something goes wrong in the back end -JobClient does not impose limits on how long runs should take, but JUnit does. If we had an overload of runJob() that took a timeout, JobClient could kill a job that was taking too long, extracting the stack trace and better diagnostics to the test reports. "
MAPREDUCE-2818,Rest API for retrieving job / task statistics ,"a rest api that returns a simple JSON containing information about a given job such as:  min/max/avg times per task, failed tasks, etc. This would be useful in order to allow external restart or modification of parameters of a run.
"
MAPREDUCE-2817,MiniRMCluster hardcodes 'mapred.local.dir' configuration to 'build/test/mapred/local',"The {{mapred.local.dir}} configuration property for the {{MiniMRCluster}} is forced to {{build/test/mapred/local}}

This is inconvenient in different situations. For example:

* When running multiple tests using {{MiniMRCluster}} is not possible to see the end state of the dir for a particular test
* When using {{MiniMRCluster}} in another build system (i.e. Maven) that uses a different output directory (target instead build)
"
MAPREDUCE-2815,JavaDoc does not generate correctly for MultithreadedMapRunner,"The following code in MultithreadedMapRunner.java does not get published to the HTML docs correctly.

This is what actually appears in the HTML docs:
""It can be used instead of the default implementation, ""

This is what *should* appear:
/**
 * Multithreaded implementation for @link org.apache.hadoop.mapred.MapRunnable.
 * <p>
 * It can be used instead of the default implementation,
 * @link org.apache.hadoop.mapred.MapRunner, when the Map operation is not CPU
 * bound in order to improve throughput.
 * <p>
 * Map implementations using this MapRunnable must be thread-safe.
 * <p>
 * The Map-Reduce job has to be configured to use this MapRunnable class (using
 * the JobConf.setMapRunnerClass method) and
 * the number of thread the thread-pool can use with the
 * <code>mapred.map.multithreadedrunner.threads</code> property, its default
 * value is 10 threads.
 * <p>
 */"
MAPREDUCE-2809,Refactor JobRecoveryManager into a new class file.,"RecoveryManager in itself subsumes a lot of code, and should be moved out of JobTracker.java. "
MAPREDUCE-2808,pull MAPREDUCE-2797 into mr279 branch,The ant tar command fails in the mapreduce directory on the mr279 branch.  The issue was a change in hdfs and was fixed on trunk with jira MAPREDUCE-2797.  Pull that change into mr279.
MAPREDUCE-2807,MR-279: AM restart does not work after RM refactor,"When the AM crashes, RM is not able to launch a new App attempt."
MAPREDUCE-2806,[Gridmix] Load job fails with timeout errors when resource emulation is turned on,"When the Load job's tasks are emulating cpu/memory, the task-tracker kills the emulating task due to lack of status updates. Load job has its own status reporter which dies too soon."
MAPREDUCE-2805,Update RAID for HDFS-2241,"{noformat}
src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/datanode/RaidBlockSender.java:44: interface expected here
    [javac] public class RaidBlockSender implements java.io.Closeable, FSConstants {
    [javac]                                                            ^
{noformat}"
MAPREDUCE-2804,"""Creation of symlink to attempt log dir failed."" message is not useful","In attempting to qualify the 204 RC2 release, my tasktracker logs are filled with the above message.  I'd love to do something about it, but since it doesn't tell me what exactly it is trying to symlink I cannot unless I dig into the source code.
"
MAPREDUCE-2802,[MR-279] Jobhistory filenames should have jobID to help in better parsing ,"For jobID such as job_1312933838300_0007, jobhistory file names are named as job%5F1312933838300%5F0007_<submit_time>_ramya_<jobname>_<finish_time>_1_1_SUCCEEDED.jhist It would be easier for parsing if the jobIDs were a part of the filenames.
"
MAPREDUCE-2801,Include the native libs in java.library.path ,"For the child tasks in mrv2, java.library.path is set to just $PWD and the native libs are not included. Whereas in 0.20.x, java.library.path for child tasks was set to <path to native libs>:$PWD
"
MAPREDUCE-2800,"clockSplits, cpuUsages, vMemKbytes, physMemKbytes is set to -1 in jhist files","clockSplits, cpuUsages, vMemKbytes, physMemKbytes  is set to -1 for all the map tasks for the last 4 progress interval in the jobhistory files.
"
MAPREDUCE-2799,[MR-279] NPE is throwing on job -status <Invalid Job ID/Job Id doesn't exist>,"
{code:xml} 
Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.mapred.ClientServiceDelegate.refreshProxy(ClientServiceDelegate.java:113)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getProxy(ClientServiceDelegate.java:101)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getRefreshedProxy(ClientServiceDelegate.java:94)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:384)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:515)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:154)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:223)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1074)
{code} "
MAPREDUCE-2797,Some java files cannot be compiled,"Due to the changes in HDFS-2239, the following files cannot be compiled (Thanks Amar for pointing them out.)
1. src/test/mapred/org/apache/hadoop/mapreduce/security/TestTokenCache.java
2. src/test/mapred/org/apache/hadoop/mapreduce/security/TestBinaryTokenFile.java
3. src/test/mapred/org/apache/hadoop/mapreduce/security/TestTokenCacheOldApi.java
4. src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyRaid.java"
MAPREDUCE-2796,[MR-279] Start time for all the apps is set to 0,"The start time for all the apps in the output of ""job -list"" is set to 0"
MAPREDUCE-2795,[MR-279] AppsKilled is never incremented,AppsKilled metrics is never incremented even though there are killed jobs in the system.
MAPREDUCE-2794,[MR-279] Incorrect metrics value for AvailableGB per queue per user,"AvailableGB per queue is not the same as AvailableGB per queue per user when the user limit is set to 100%.
i.e. if the total available GB of the cluster is 60, and queue ""default"" has 92% capacity with 100% as the user limit, AvailableGB per queue default = 55 (i.e. 0.92*60) whereas AvailableGB per queue for user ramya is 56 (however it should be 55 = 0.92*60*1) 

Also, unlike the AvailableGB/queue, AvailableGB/queue/user is not decremented when user ramya is running apps on the ""default"" queue."
MAPREDUCE-2793,"[MR-279] Maintain consistency in naming appIDs, jobIDs and attemptIDs ","appIDs, jobIDs and attempt/container ids are not consistently named in the logs, console and UI. For consistency purpose, they all have to follow a common naming convention.

Currently, 
For appID
=========
On the RM UI: app_1308259676864_5 
On the JHS UI: No appID 
Console/logs: No appID
mapred-local dirs are named as: application_1308259676864_0005

For jobID
=========
On the RM UI: job_1308259676864_5_5 
JHS UI: job_1308259676864_5_5 
Console/logs: job_1308259676864_0005
mapred-local dirs are named as: No jobID


For attemptID
============
On the RM UI: attempt_1308259676864_5_5_m_24_0
JHS attempt_1308259676864_5_5_m_24_0
Console/logs: attempt_1308259676864_0005_m_000024_0
mapred-local dirs are named as: container_1308259676864_0005_000024

"
MAPREDUCE-2792,[MR-279] Replace IP addresses with hostnames,"Currently, all the logs, UI, CLI have IP addresses of the NM/RM, which are difficult to manage. It will be useful to have hostnames like in 0.20.x for easier debugging and maintenance purpose. "
MAPREDUCE-2791,[MR-279] Missing/incorrect info on job -status CLI ,"There are a couple of details missing/incorrect on the job -status command line output for completed jobs:

1. Incorrect job file
2. map() completion is always 0
3. reduce() completion is always set to 0
4. history URL is empty
5. Missing launched map tasks
6. Missing launched reduce tasks 



"
MAPREDUCE-2790,[MR-279] Add additional field for storing the AM/job history info on CLI,"bin/mapred job [-list [all]] displays the AM or job history location in the ""SchedulingInfo"" field. An additional column has to be added to display the AM/job history information. Currently, the output reads:

{noformat}
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
jobID  FAILED       0           ramya           default NORMAL      AM information/job history location

{noformat}"
MAPREDUCE-2789,[MR:279] Update the scheduling info on CLI,"The scheduling information such as number of containers running, memory usage and reservations per job is not available on bin/mapred job -list CLI."
MAPREDUCE-2788,Normalize requests in FifoScheduler.allocate to prevent NPEs later,The assignContainer() method in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue can cause the scheduler to crash if the ResourseRequest capability memory == 0 (divide by zero).
MAPREDUCE-2787,MR-279: Performance improvement in running Uber MapTasks,The runUberMapTasks() in org.apache.hadoop.mapred.UberTask obtains the local fileSystem and local job configuration for every task attempt.  This will have a negative performance impact.
MAPREDUCE-2786,TestDFSIO should also test compression reading/writing from command-line.,"I thought it might be beneficial to simply alter the code of TestDFSIO to accept any compression codec class and allow testing for compression by a command line argument instead of having to change the config file everytime. Something like ""-compression"" would do."
MAPREDUCE-2785,MiniMR cluster thread crashes if no hadoop log dir set,"I'm marking this as minor as it is most obvious in the MiniMRCluster, but the root cause is in the JT. 

If you instantiate an MiniMR Cluster without setting {{hadoop.job.history.location}} in the configuration and the system property {{hadoop.log.dir}} unset, then the JobHistory throws an NPE. In production, that would be picked up as a failure to start the JT. In the MiniMRCluster, all it does is crash the JT thread -which isn't noticed by the MiniMR cluster. You see the logged error, but the tests will just timeout waiting for things to come up

2011/08/08 17:46:26:427 CEST [ERROR][Thread-44] org.apache.hadoop.mapred.MiniMRCluster - Job tracker crashed <java.lang.NullPointerException>         java.lang.NullPointerException
 	at java.io.File.<init>(File.java:222)
 	at org.apache.hadoop.mapred.JobHistory.initLogDir(JobHistory.java:531)
 	at org.apache.hadoop.mapred.JobHistory.init(JobHistory.java:499)
 	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:2316)
 	at org.apache.hadoop.mapred.JobTracker$2.run(JobTracker.java:2313)
 	at java.security.AccessController.doPrivileged(Native Method)
 	at javax.security.auth.Subject.doAs(Subject.java:396)
 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
 	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2313)
 	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2171)
 	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:300)
 	at org.apache.hadoop.mapred.MiniMRCluster$JobTrackerRunner$1.run(MiniMRCluster.java:114)
 	at org.apache.hadoop.mapred.MiniMRCluster$JobTrackerRunner$1.run(MiniMRCluster.java:112)
 	at java.security.AccessController.doPrivileged(Native Method)
 	at javax.security.auth.Subject.doAs(Subject.java:396)
 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
 	at org.apache.hadoop.mapred.MiniMRCluster$JobTrackerRunner.run(MiniMRCluster.java:112)
 	at java.lang.Thread.run(Thread.java:662)
"
MAPREDUCE-2784,[Gridmix] TestGridmixSummary fails with NPE when run in DEBUG mode.,TestGridmixSummary fails with NPE when run in debug mode. JobFactory tries to access the _createReaderThread()_ API of JobStoryProducer which returns null in TestGridmixSummary's FakeJobStoryProducer.
MAPREDUCE-2783,mr279 job history handling after killing application,"The job history/application tracking url handling during kill is not consistent. Currently if you kill a job that was running the tracking url points to job history, but job history server doesn't have the job.  "
MAPREDUCE-2782,MR-279: Unit (mockito) tests for CS,Add (true) unit tests for CapacityScheduler
MAPREDUCE-2781,mr279 RM application finishtime not set,The RM Application finishTime isn't being set.  Looks like it got lost in the RM refactor.
MAPREDUCE-2780,Standardize the value of token service,"The token's service field must (currently) be set to ""ip:port"".  All the producers of a token are independently building the service string.  This should be done via a common method to reduce the chance of error, and to facilitate the field value being easily changed in the (near) future."
MAPREDUCE-2779,JobSplitWriter.java can't handle large job.split file,"We use cascading MultiInputFormat. MultiInputFormat sometimes generates big job.split used internally by hadoop, sometimes it can go beyond 2GB.

In JobSplitWriter.java, the function that generates such file uses 32bit signed integer to compute offset into job.split.


writeNewSplits
...
        int prevCount = out.size();
...
        int currCount = out.size();

writeOldSplits
...
      long offset = out.size();
...
      int currLen = out.size();
"
MAPREDUCE-2777,Backport MAPREDUCE-220 to Hadoop 20 security branch,
MAPREDUCE-2776,MR 279: Fix some of the yarn findbug warnings,Fix / ignore some of the findbug warnings in the yarn module.
MAPREDUCE-2775,[MR-279] Decommissioned node does not shutdown,A Nodemanager which is decommissioned by an admin via refreshnodes does not automatically shutdown. 
MAPREDUCE-2774,[MR-279] Add a startup msg while starting RM/NM,"Add a startup msg while starting NM/RM indicating the version, build details etc. This will help in easier parsing of logs and debugging."
MAPREDUCE-2773,[MR-279] server.api.records.NodeHealthStatus renamed but not updated in client NodeHealthStatus.java,"On the mr279 branch, you can't successfully run the ant target from the mapreduce directory since the checkin of the RM refactor.  

The issue is the NodeHealthStatus rename from org.apache.hadoop.yarn.server.api.records.NodeHealthStatus to org.apache.hadoop.yarn.api.records.NodeHealthStatus but the client mapreduce/src/java/org/apache/hadoop/mapred/NodeHealthStatus.java wasn't updated with the change"
MAPREDUCE-2772,MR-279: mrv2 no longer compiles against trunk after common mavenization.,mrv2 no longer compiles against trunk after common mavenization
MAPREDUCE-2770,Improve hadoop.job.history.location doc in mapred-default.xml,The documentation for hadoop.job.history.location in mapred-default.xml should indicate that this parameter can be a URI and any file system that Hadoop supports (eg hdfs and file).
MAPREDUCE-2769,TT should give more info for failed file operations,The TT should give more info when it fail a NativeIO file operation (eg the file name).
MAPREDUCE-2768,[MR-279] NMs not being blacklisted as determined by health scripts,"The NMs are not being blacklisted via the node health script. Below is the configuration used:

yarn.server.nodemanager.healthchecker.script.path=<path to node health script which blacklists a NM>
yarn.server.nodemanager.healthchecker.interval=10
yarn.server.nodemanager.healthchecker.script.timeout=12

The node continues to be healthy forever. "
MAPREDUCE-2767,Remove Linux task-controller from 0.22 branch,"There's a potential security hole in the task-controller as it stands. Based on the discussion on general@, removing task-controller from the 0.22 branch will pave way for 0.22.0 release. (This was done for the 0.21.0 release as well: see MAPREDUCE-2014.) We can roll a 0.22.1 release with the task-controller when it is fixed."
MAPREDUCE-2766,[MR-279] Set correct permissions for files in dist cache,"Currently, the files in both public and private dist cache are having 777 permission. Also, the group ownership of files on private cache have to be set to $TT_SPECIAL_GROUP

"
MAPREDUCE-2765,DistCp Rewrite,"This is a slightly modified version of the DistCp rewrite that Yahoo uses in production today. The rewrite was ground-up, with specific focus on:
1. improved startup time (postponing as much work as possible to the MR job)
2. support for multiple copy-strategies
3. new features (e.g. -atomic, -async, -bandwidth.)
4. improved programmatic use
Some effort has gone into refactoring what used to be achieved by a single large (1.7 KLOC) source file, into a design that (hopefully) reads better too.

The proposed DistCpV2 preserves command-line-compatibility with the old version, and should be a drop-in replacement.

New to v2:

1. Copy-strategies and the DynamicInputFormat:
	A copy-strategy determines the policy by which source-file-paths are distributed between map-tasks. (These boil down to the choice of the input-format.) 
	If no strategy is explicitly specified on the command-line, the policy chosen is ""uniform size"", where v2 behaves identically to old-DistCp. (The number of bytes transferred by each map-task is roughly equal, at a per-file granularity.) 
	Alternatively, v2 ships with a ""dynamic"" copy-strategy (in the DynamicInputFormat). This policy acknowledges that 
		(a)  dividing files based only on file-size might not be an even distribution (E.g. if some datanodes are slower than others, or if some files are skipped.)
		(b) a ""static"" association of a source-path to a map increases the likelihood of long-tails during copy.
	The ""dynamic"" strategy divides the list-of-source-paths into a number (> nMaps) of smaller parts. When each map completes its current list of paths, it picks up a new list to process, if available. So if a map-task is stuck on a slow (and not necessarily large) file, other maps can pick up the slack. The thinner the file-list is sliced, the greater the parallelism (and the lower the chances of long-tails). Within reason, of course: the number of these short-lived list-files is capped at an overridable maximum.
	Internal benchmarks against source/target clusters with some slow(ish) datanodes have indicated significant performance gains when using the dynamic-strategy. Gains are most pronounced when nFiles greatly exceeds nMaps.
	Please note that the DynamicInputFormat might prove useful outside of DistCp. It is hence available as a mapred/lib, unfettered to DistCpV2. Also note that the copy-strategies have no bearing on the CopyMapper.map() implementation.
	
2. Improved startup-time and programmatic use:
	When the old-DistCp runs with -update, and creates the list-of-source-paths, it attempts to filter out files that might be skipped (by comparing file-sizes, checksums, etc.) This significantly increases the startup time (or the time spent in serial processing till the MR job is launched), blocking the calling-thread. This becomes pronounced as nFiles increases. (Internal benchmarks have seen situations where more time is spent setting up the job than on the actual transfer.)
	DistCpV2 postpones as much work as possible to the MR job. The file-listing isn't filtered until the map-task runs (at which time, identical files are skipped). DistCpV2 can now be run ""asynchronously"". The program quits at job-launch, logging the job-id for tracking. Programmatically, the DistCp.execute() returns a Job instance for progress-tracking.
	
3. New features:
	(a)   -async: As described in #2.
	(b)   -atomic: Data is copied to a (user-specifiable) tmp-location, and then moved atomically to destination.
	(c)   -bandwidth: Enforces a limit on the bandwidth consumed per map.
	(d)   -strategy: As above.    
	
A more comprehensive description the newer features, how the dynamic-strategy works, etc. is available in src/site/xdoc/, and in the pdf that's generated therefrom, during the build.

High on the list of things to do is support to parallelize copies on a per-block level. (i.e. Incorporation of HDFS-222.)

I look forward to comments, suggestions and discussion that will hopefully ensue. I have this running against Hadoop 0.20.203.0. I also have a port to 0.23.0 (complete with unit-tests).

P.S.
A tip of the hat to Srikanth (Sundarrajan) and Venkatesh (Seetharamaiah), for ideas, code, reviews and guidance. Although much of the code is mine, the idea to use the DFS to implement ""dynamic"" input-splits wasn't.
	
"
MAPREDUCE-2764,Fix renewal of dfs delegation tokens,"The JT may have issues renewing hftp tokens which disrupt long distcp jobs.  The problem is the JT's delegation token renewal code is built on brittle assumptions.  The token's service field contains only the ""ip:port"" pair.  The renewal process assumes that the scheme must be hdfs.  If that fails due to a {{VersionMismatchException}}, it tries https based on another assumption that it must be hftp if it's not hdfs.  A number of other exceptions, most commonly {{IOExceptions}}, can be generated which fouls up the renewal since it won't fallback to https."
MAPREDUCE-2763,IllegalArgumentException while using the dist cache,"IllegalArgumentException is seen while using distributed cache to cache some files and custom jars in classpath.

A simple way to reproduce this error is by using a streaming job:
hadoop jar hadoop-streaming.jar -libjars file://<path to custom jar> -input <path to input file> -output out -mapper ""cat"" -reducer NONE -cacheFile  hdfs://<path to some file>#linkname

This is a regression introduced and the same command works fine on 0.20.x"
MAPREDUCE-2762,[MR-279] - Cleanup staging dir after job completion,"The files created under the staging dir have to be deleted after job completion. Currently, all job.* files remain forever in the ${yarn.apps.stagingDir}"
MAPREDUCE-2760,mapreduce.jobtracker.split.metainfo.maxsize typoed in mapred-default.xml,"The configuration mapreduce.jobtracker.split.metainfo.maxsize is incorrectly included in mapred-default.xml as mapreduce.*job*.split.metainfo.maxsize. It seems that {{jobtracker}} is correct, since this is a JT-wide property rather than a job property."
MAPREDUCE-2759,TaskTrackerAction should follow Open Closed Principle,"In the class TaskTrackerAction  there are fixed actions or directions specified from the Job Tracker to the Task Tracker.So if in the future if some more actions are specified from the Job Tracker to Task Tracker,Current implementation is breaking Open Closed Principle(Open for extension,closed for modification).As the number of actions increases in the future, the code need to be modified to incorporate the actions."
MAPREDUCE-2757,"[MR-279] Redundant ""file:"" directory created in appcache ","A redundant directory called ""file:"" is being created under ${yarn.server.nodemanager.local-dir}/usercache/${username}/appcache/appID which further has a directory structure ${yarn.server.nodemanager.local-dir}/usercache/${username}/(appcache|filecache)/appID/filecache which is empty. 
"
MAPREDUCE-2756,JobControl can drop jobs if an error occurs,"If you run a pig job with UDFs that has not been recompiled for MRV2.  There are situations where pig will fail with an error message stating that Hadoop failed and did not give a reason.  There is even the possibility of deadlock if an Error is thrown and the JobControl thread dies.
"
MAPREDUCE-2755,MR-279: AM writes logs to stderr,"Currently the AM logs are written to $YARN_LOG_DIR/appID/containerID/stderr. In order to maintain consistency with other container logs, it probably should be moved to syslog."
MAPREDUCE-2754,MR-279: AM logs are incorrectly going to stderr and error messages going incorrectly to stdout,"The log messages for AM container are going into stderr instead of syslog. Also, stderr and stdout roles are reversed."
MAPREDUCE-2753,Generated POMs hardcode dependency on hadoop-common version 0.22.0-SNAPSHOT,"The generated poms inject the version of mapred itself, but hardcode the version of hadoop-common they depend on.
When trying to build downstream projects (HBase), then they will require hadoop-common-0.22.0-SNAPSHOT.jar instead of the version they compiled against.

When trying to do an offline build this will fail to resolve as another hadoop-common has been installed in the local maven repo.
Even during online build, it should compile against the hadoop-common that hdfs compiled against.

When versions mismatch one cannot do a coherent build. That is particularly problematic when making simultaneous change in hadoop-common and hadoop-mapreduce and you want to try this locally before committing each."
MAPREDUCE-2752,Build does not pass along properties to contrib builds,"Subant call to compile contribs do not pass along parameters from parent build.
Properties such as hadoop-common.version, asfrepo, offline, etc. are not passed along.
Result is that build not connected to Internet fails, hdfs proxy refuses to build against own recently built common but rather downloads 0.22-SNAPSHOT from apache again."
MAPREDUCE-2751,[MR-279] Lot of local files left on NM after the app finish.,"This ticket is about app-only files which should be cleaned after app-finish.

I see these undeleted after app-finish:
/tmp/nm-local-dir/0/nmPrivate/application_1305091029545_0001/*
/tmp/nm-local-dir/0/nmPrivate/container_1305019205843_0001_000002/*
/tmp/nm-local-dir/0/usercache/nobody/appcache/application_1305091029545_0001/*

We should check for other left-over files too, if any."
MAPREDUCE-2750,[MR-279] NodeManager should start its servers on ephemeral ports ,"There is absolutely no need for NM to start ContainerManager on a standard port, it should bind to an ephemeral port. Binding on ephemeral ports will help us start multiple NMs on a single node without any issues.

The same holds for the ResourceLocalizationService's server port and NM Http server's port. "
MAPREDUCE-2749,[MR-279] NM registers with RM even before it starts various servers,"In case NM eventually fails to start the ContainerManager server because of say a port clash, RM will have to wait for expiry to detect the NM crash.

It is desirable to make NM register with RM only after it can start all of its components successfully."
MAPREDUCE-2748,[MR-279] NM should pass a whitelisted environmental variables to the container ,"This is similar to [MAPREDUCE-103] . We should pass a whitelisted set of environment variables from NM env to the container. By default, we should pass HADOOP_* variables. This can be a simple configuration key that NodeManager reads.

Today, we already either pass the following correctly or assume that it works but doesn't
 - YARN_HOME: ContainerLaunch#writeLaunchEnv
 - HADOOP_CLIENT_OPTS: MapReduceChildJVM#setVMEnv
 - JAVA_HOME: TaskAttemptImpl#createContainerLaunchContext - Works by shell-expansion.
 - LD_LIBRARY_PATH: Assumed to work via shell-expansion but doesn't."
MAPREDUCE-2747,[MR-279] [Security] Cleanup LinuxContainerExecutor binary sources,"There are a lot of references to the old task-controller nomenclature still, job/task refs instead of app/container.

Also the configuration file is named as taskcontroller.cfg and the configured variables are also from the mapred world (mrv1). These SHOULD  be fixed before we make a release. Marking this as blocker."
MAPREDUCE-2746,[MR-279] [Security] Yarn servers can't communicate with each other with hadoop.security.authorization set to true,"Because of this problem, till now, we've been testing YARN+MR with {{hadoop.security.authorization}} set to false. We need to register yarn communication protocols in the implementation of the authorization related PolicyProvider (MapReducePolicyProvider.java).

[~devaraj] also found this issue independently."
MAPREDUCE-2742,[MR-279] [Security] All tokens in YARN + MR should have an expiry interval ,"Right now none of the tokens and secret-keys have an expiry interval. This needs to be fixed.

This ticket should also handle how to renew the tickets when necessary."
MAPREDUCE-2741,Make ant build system work with hadoop-common JAR generated by Maven,"Some tweaks must be done in MAPRED & its contribs ivy configuration to work with HADOOP-6671.

This wil be a temporary fix until MAPRED is mavenized."
MAPREDUCE-2740,MultipleOutputs in new API creates needless TaskAttemptContexts,"MultipleOutputs.write creates a new TaskAttemptContext, which we've seen to take a significant amount of CPU. The TaskAttemptContext constructor creates a JobConf, gets current UGI, etc. I don't see any reason it needs to do this, instead of just creating a single TaskAttemptContext when the InputFormat is created (or lazily but cached as a member)"
MAPREDUCE-2739,MR-279: Update installation docs (remove YarnClientFactory),"Need to remove reference to the YarnClinetFactory in the INSTALL instructions: https://svn.apache.org/repos/asf/hadoop/common/branches/MR-279/mapreduce/INSTALL

The YarnClientFactory class removed (MAPRECUCE-2400 patch). "
MAPREDUCE-2738,Missing cluster level stats on the RM UI,"Cluster usage information such as the following are currently not available in the RM UI. 

- Total number of apps submitted so far
- Total number of containers running/total memory usage 
- Total capacity of the cluster (in terms of memory)
- Reserved memory
- Total number of NMs - sorting based on Node IDs is an option but when there are lost NMs or restarted NMs, the node ids does not correspond to the actual value
- Blacklisted NMs - sorting based on health-status and counting manually is not very straight forward
- Excluded NMs
- Handle to the jobhistory server
"
MAPREDUCE-2737,Update the progress of jobs on client side,The progress of the jobs are not being correctly updated on the client side. The map progress halts at 66% and both map/reduce progress % does not display 100 when the job completes.
MAPREDUCE-2736,Remove unused contrib components dependent on MR1,"As discussed on mapreduce-dev@ and general@, let's remove or disable MR1.

1. http://mail-archives.apache.org/mod_mbox/hadoop-mapreduce-dev/201107.mbox/%3CCAPn_vTsdiiqfCB2G0HfsOr3W_4PKoocPcTf2VB93Y3MZrzRczQ@mail.gmail.com%3E

2. http://mail-archives.apache.org/mod_mbox/hadoop-general/201107.mbox/%3CCAPn_vTsjcErtt35RSkCykY2m+qbk3w-ZEMQKpd+wNRaYo7tc5A@mail.gmail.com%3E"
MAPREDUCE-2735,MR279: finished applications should be added to an application summary log,When an application finishes it should be added to an application summary log for historical purposes.  jira MAPREDUCE-2649 is going to start purging applications from RM when certain limits are hit which makes this more critical. We also need to save the information early enough after the app finishes so we don't lose the info if the RM does get restarted.
MAPREDUCE-2734,DistCp with FairScheduler assign all map tasks in one TT,"1 Using FairScheduler.
2 distcp a directory contains 5 files.

The DistCp job will launch 5 map tasks, and FairScheduler assign them to one TaskTracker.
It should be assigned different, like the original JobQueueScheduler.
"
MAPREDUCE-2733,Gridmix v3 cpu emulation system tests.,"1. Enable CPU emulation with default resource usage interval and run Gridmix v3 with a trace file that contains the CPU resource usage details.
2. Enable CPU emulation with custom resource usage interval and run Gridmix v3 with a trace file that contains the CPU resource usage details. 
3. Disable CPU emulation and run Gridmix v3 with a trace file that contains the CPU resource usage details. 
4. Enable CPU emulation with default resource usage interval and run Gridmix v3 with a trace file that doesn't contains the CPU resource usage details."
MAPREDUCE-2732,Some tests using FSNamesystem.LOG cannot be compiled,
MAPREDUCE-2730,mr279: Application EXPIRED_PENDING to FAILED state transition incomplete,"in mrv2 if the application fails, it currently does not set the finishTime so it shows up as being 0."
MAPREDUCE-2729,"Reducers are always counted having ""pending tasks"" even if they can't be scheduled yet because not enough of their mappers have completed","In capacity scheduler, number of users in a queue needing slots are calculated based on whether users' jobs have any pending tasks.
This works fine for map tasks. However, for reduce tasks, jobs do not need reduce slots until the minimum number of map tasks have been completed.

Here, we add checking whether reduce is ready to schedule (i.e. if a job has completed enough map tasks) when we increment number of users in a queue needing reduce slots.
"
MAPREDUCE-2728,Update Mapreduce dependency of Java for deb package,"Java dependency for Debian package is specified as open JDK, but it should depends on Sun version of Java.  This dependency can be implicitly defined by hadoop-common dependency.  Hence, there is no need to explicitly defined in hadoop-mapreduce."
MAPREDUCE-2727,MR-279: SleepJob throws divide by zero exception when count = 0,"When the count is 0 for mappers or reducers, a divide-by-zero exception is thrown.  There are existing checks to error out when count < 0, which obviously doesn't handle the 0 case.  This is causing the MRReliabilityTest to fail."
MAPREDUCE-2726,MR-279: Add the jobFile to the web UI,"MAPREDUCE:2716 adds the jobfile information to the ApplicationReport.  With that information available, we should add the jobfile to the web UI as well."
MAPREDUCE-2724,Reducer fetcher synchronize problem,"I've recently using hadoop(version 0.21.0) for some data processing, but sometimes reducer crashed. Always the log is like bellow, which tells when multi fetchers recieved mapoutput simultaneously, the merge part may fail due to some disadvantages. To verify this assumption, I then set the number of fetchers to 1 (mapreduce.reduce.shuffle.parallelcopies), after which the problem dispeared and the job works well.
2011-07-20 18:56:34,999 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_201107140944_0086_r_000000_0: Got 2 new map-outputs
2011-07-20 18:56:35,000 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging dc-0005:50060 with 1 to fetcher#1
2011-07-20 18:56:35,000 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to dc-0005:50060 to fetcher#1
2011-07-20 18:56:35,000 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: Assiging dc-0002:50060 with 1 to fetcher#3
2011-07-20 18:56:35,000 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: assigned 1 of 1 to dc-0002:50060 to fetcher#3
2011-07-20 18:56:35,006 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=50060/mapOutput?job=job_201107140944_0086&reduce=0&map=attempt_201107140944_0086_m_000498_0 sent hash and receievd reply
2011-07-20 18:56:35,016 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: for url=50060/mapOutput?job=job_201107140944_0086&reduce=0&map=attempt_201107140944_0086_m_000491_0 sent hash and receievd reply
2011-07-20 18:56:35,056 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#3 about to shuffle output of map attempt_201107140944_0086_m_000498_0 decomp: 12647556 len: 12647560 to MEMORY
2011-07-20 18:56:35,070 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: fetcher#1 about to shuffle output of map attempt_201107140944_0086_m_000491_0 decomp: 30172760 len: 30172764 to MEMORY
2011-07-20 18:56:35,553 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 12647556 bytes from map-output for attempt_201107140944_0086_m_000498_0
2011-07-20 18:56:35,553 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -> map-output of size: 12647556, inMemoryMapOutputs.size() -> 25
2011-07-20 18:56:35,553 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManager: Starting inMemoryMerger's merge since usedMemory=479526428 > mergeThreshold=440963456
2011-07-20 18:56:35,553 INFO org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 25 segments, while ignoring 0 segments
2011-07-20 18:56:35,554 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: dc-0002:50060 freed by fetcher#3 in 554s
2011-07-20 18:56:35,556 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManager: Initiating in-memory merge with 25 segments...
2011-07-20 18:56:35,557 INFO org.apache.hadoop.mapred.Merger: Merging 25 sorted segments
2011-07-20 18:56:35,557 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 25 segments left of total size: 449352783 bytes
2011-07-20 18:56:35,696 INFO org.apache.hadoop.mapreduce.task.reduce.Fetcher: Read 30172760 bytes from map-output for attempt_201107140944_0086_m_000491_0
2011-07-20 18:56:35,696 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManager: closeInMemoryFile -> map-output of size: 30172760, inMemoryMapOutputs.size() -> 1
2011-07-20 18:56:35,696 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManager: Starting inMemoryMerger's merge since usedMemory=479526428 > mergeThreshold=440963456
2011-07-20 18:56:35,696 INFO org.apache.hadoop.mapreduce.task.reduce.MergeThread: InMemoryMerger - Thread to merge in-memory shuffled map-outputs: Starting merge with 1 segments, while ignoring 0 segments
2011-07-20 18:56:35,696 INFO org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler: dc-0005:50060 freed by fetcher#1 in 696s
2011-07-20 18:56:41,540 WARN org.apache.hadoop.mapred.Child: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in InMemoryMerger - Thread to merge in-memory shuffled map-outputs
at org.apache.hadoop.mapreduce.task.reduce.Shuffle.run(Shuffle.java:124)
at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:362)
at org.apache.hadoop.mapred.Child$4.run(Child.java:217)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:742)
at org.apache.hadoop.mapred.Child.main(Child.java:211)
Caused by: java.lang.RuntimeException: java.io.EOFException
at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:132)
at org.apache.hadoop.mapred.Merger$MergeQueue.lessThan(Merger.java:530)
at org.apache.hadoop.util.PriorityQueue.downHeap(PriorityQueue.java:141)
at org.apache.hadoop.util.PriorityQueue.adjustTop(PriorityQueue.java:108)
at org.apache.hadoop.mapred.Merger$MergeQueue.adjustPriorityQueue(Merger.java:478)
at org.apache.hadoop.mapred.Merger$MergeQueue.next(Merger.java:493)
at org.apache.hadoop.mapred.Merger.writeFile(Merger.java:199)
at org.apache.hadoop.mapreduce.task.reduce.MergeManager$InMemoryMerger.merge(MergeManager.java:443)
at org.apache.hadoop.mapreduce.task.reduce.MergeThread.run(MergeThread.java:89)
Caused by: java.io.EOFException
at java.io.DataInputStream.readFully(DataInputStream.java:180)
at java.io.DataInputStream.readFully(DataInputStream.java:152)
at com.iflytek.hadoop.streaming.io.BaseKey32.readFields(BaseKey32.java:24)
at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:129)
... 8 more

2011-07-20 18:56:41,552 INFO org.apache.hadoop.mapred.Task: Runnning cleanup for the task"
MAPREDUCE-2722,Gridmix simulated job's map's hdfsBytesRead counter is wrong when compressed input is used,"When compressed input was used by original job's map task, then the simulated job's map task's hdfsBytesRead counter is wrong if compression emulation is enabled. This issue is because hdfsBytesRead of map task of original job is considered as uncompressed map input size by Gridmix."
MAPREDUCE-2721,TaskTracker is calling the close () method twice unnecessarily ,"When there is a version mismatch between the JobTracker and TaskTracker, TaskTracker is calling the close () method twice. Once in the finally block of run () method and also in the shutdown () method call. "
MAPREDUCE-2719,MR-279: Write a shell command application,"With nextgen hadoop (mrv2), it is simple to write non-MR applications. Write an AplicationMaster (also corresponding simple client), to submit and run a shell command application in the cluster."
MAPREDUCE-2718,Job fails if AppMaster is killed,"Started a cluster. Sumitted a sleep job with around 10000 maps and 1000 reduces.
when 5000 maps got completed, It killed AppMaster.
RM web UI Application as failed.
And jobclient after retry for 50 times -:
{
java.lang.reflect.UndeclaredThrowableException
        at
org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:161)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getTaskCompletionEvents(ClientServiceDelegate.java:254)
        at org.apache.hadoop.mapred.YARNRunner.getTaskCompletionEvents(YARNRunner.java:520)
        at org.apache.hadoop.mapreduce.Job.getTaskCompletionEvents(Job.java:540)
        at org.apache.hadoop.mapreduce.Job.monitorAndPrintJob(Job.java:1130)
        at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1084)
        at org.apache.hadoop.mapreduce.SleepJob.run(SleepJob.java:259)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.mapreduce.SleepJob.main(SleepJob.java:191)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
        at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:192)
Caused by: com.google.protobuf.ServiceException: java.net.ConnectException: Call to /98.137.103.174:42557 failed on
connection exception: java.net.ConnectException: Connection refused
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:96)
        at $Proxy11.getTaskAttemptCompletionEvents(Unknown Source)
        at
org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBClientImpl.java:154)
        ... 21 more
Caused by: java.net.ConnectException: Call to /... failed on connection exception:
java.net.ConnectException: Connection refused
        at org.apache.hadoop.ipc.Client.wrapException(Client.java:1087)
        at org.apache.hadoop.ipc.Client.call(Client.java:1063)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:250)
        at org.apache.hadoop.yarn.ipc.$Proxy10.call(Unknown Source)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$Invoker.invoke(ProtoOverHadoopRpcEngine.java:94)
        ... 23 more
Caused by: java.net.ConnectException: Connection refused
        at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
        at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
        at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
        at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:375)
        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:448)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:536)
        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:211)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1196)
        at org.apache.hadoop.ipc.Client.call(Client.java:1040)
}"
MAPREDUCE-2717,Client should be able to know why an AM crashed.,"Today if an AM crashes, we have to dig through logs - very cumbersome. It is good to have client print some reason for
AM crash. Various possible reasons for AM crash:
 (1) AM container failed during localization itself.
 (2) AM container launched but failed before properly starting, for e.g. due to classpath issues
 (3) AM failed after starting properly.
 (4) an AM is expired and killed by the RM

Potential fixes:
 - For (1) and (2) the client should obtain the container-status, container diagnostics and exit code.
 - For (3), the AM should set some kind of reason for failure during its heartbeat to RM and the client should obtain
the same from RM.

		"
MAPREDUCE-2716,MR279: MRReliabilityTest job fails because of missing job-file.,"The ApplicationReport should have the jobFile (e.g. hdfs://localhost:9000/tmp/hadoop-<USER>/mapred/staging/<USER>/.staging/job_201107121640_0001/job.xml)


Without it, jobs such as MRReliabilityTest fail with the following error (caused by the fact that jobFile is hardcoded to """" in TypeConverter.java):
e.g. java.lang.IllegalArgumentException: Can not create a Path from an empty string
        at org.apache.hadoop.fs.Path.checkPathArg(Path.java:88)
        at org.apache.hadoop.fs.Path.<init>(Path.java:96)
        at org.apache.hadoop.mapred.JobConf.<init>(JobConf.java:445)
        at org.apache.hadoop.mapreduce.Cluster.getJobs(Cluster.java:104)
        at org.apache.hadoop.mapreduce.Cluster.getAllJobs(Cluster.java:218)
        at org.apache.hadoop.mapred.JobClient.getAllJobs(JobClient.java:757)
        at org.apache.hadoop.mapred.JobClient.jobsToComplete(JobClient.java:741)
        at org.apache.hadoop.mapred.ReliabilityTest.runTest(ReliabilityTest.java:219)
        at org.apache.hadoop.mapred.ReliabilityTest.runSleepJobTest(ReliabilityTest.java:133)
        at org.apache.hadoop.mapred.ReliabilityTest.run(ReliabilityTest.java:116)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.mapred.ReliabilityTest.main(ReliabilityTest.java:504)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:72)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:144)
        at org.apache.hadoop.test.MapredTestDriver.run(MapredTestDriver.java:111)
        at org.apache.hadoop.test.MapredTestDriver.main(MapredTestDriver.java:118)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:192)"
MAPREDUCE-2715,submitAndMonitorJob() doesn't play nice with MultipleOutputFile,"part of submitAndMonitorJob() balks if the output directory currently exists but is non-empty:

  ""Error launching job , Output path already exists : ""

this logic actually conflicts with the ideas behind MultipleOutputFile, where the output file path is calculated later on.

it would be really nice to remove the restriction for non-empty output directories in submitAndMonitorJob() so that MultipleOutputFile becomes more useful - as it stands now, I can't, for example, specify a base output path then use MutlipleOutputFile to partition by date on a daily basis.

thanks."
MAPREDUCE-2714,"When a job is retired by the same user's another job, its jobconf file is not deleted from the log directory of the JobTracker ","After MAPREDUCE-130, the job's conf copy will be deleted from the log directory of the JobTracker when the job is retired. However, it just works if the job is retired by _RetireJobs_ thread of JobTracker. If a job is retired by the same user's another job, its conf copy will not be deleted. This kind of retire happens in _JobTracker::finalizeJob(job)_, when JobTracker maintains more than _MAX_COMPLETE_USER_JOBS_IN_MEMORY_ jobs information in memory for a given user."
MAPREDUCE-2713,Recovery of ResourceManager,ResourceManager needs to recover from crashes to the state where it left off. All running applications should be able to join back the restarted RM. All running containers should not be affected and continue to run.
MAPREDUCE-2711,TestBlockPlacementPolicyRaid cannot be compiled,{{TestBlockPlacementPolicyRaid}} access internal {{FSNamesystem}} directly.  It cannot be compiled after HDFS-2147.
MAPREDUCE-2710,Update DFSClient.stringifyToken(..) in JobSubmitter.printTokens(..) for HDFS-2161,{{DFSClient.stringifyToken(..)}} was removed by HDFS-2161.  {{JobSubmitter.printTokens(..)}} won't be compiled.
MAPREDUCE-2709,Test case to ensure ReflectionUtils.setConf configures the target object only once,
MAPREDUCE-2708,[MR-279] Design and implement MR Application Master recovery,Design recovery of MR AM from crashes/node failures. The running job should recover from the state it left off.
MAPREDUCE-2707,ProtoOverHadoopRpcEngine without using TunnelProtocol over WritableRpc,"ProtoOverHadoopRpcEngine is introduced in MR-279, which uses TunnelProtocol over WritableRpcEngine. This jira removes the tunnel protocol and lets ProtoOverHadoopRpcEngine directly interact with ipc.Client and ipc.Server."
MAPREDUCE-2706,MR-279: Submit jobs beyond the max jobs per queue limit no longer gets logged,"Submitting jobs over the queue limits used to print log messages such as these:
hadoop-mapred-jobtracker-HOSTNAME.log. ... INFO
org.apache.hadoop.mapred.CapacityTaskScheduler: default has 10 active tasks for user MYUSER, cannot initialize
job_XXX with 10 tasks since it will exceed limit of 15 active tasks per user for this queue
and
hadoop-mapred-jobtracker-HOSTNAME.log ... INFO org.apache.hadoop.mapred.CapacityTaskScheduler: default already has 2 running jobs and 0 initializing jobs; cannot initialize job_XXX since it will exceeed limit of 2 initialized jobs for this queue

These log messages are useful - especially for QA and testing.  "
MAPREDUCE-2705,tasks localized and launched serially by TaskLauncher - causing other tasks to be delayed,"The current TaskLauncher serially launches new tasks one at a time. During the launch it does the localization and then starts the map/reduce task.  This can cause any other tasks to be blocked waiting for the current task to be localized and started. In some instances we have seen a task that has a large file to localize (1.2MB) block another task for about 40 minutes. This particular task being blocked was a cleanup task which caused the job to be delayed finishing for the 40 minutes.
"
MAPREDUCE-2704,CombineFileInputFormat only works when paths are on the default filesystem,"CombineFileInputFormat constructs new Path objects by converting an existing path to a URI, and then only pulling out the ""path"" part of it. This drops the scheme and host, which makes CombineFileInputFormat fail if the paths are on a filesystem other than the default one."
MAPREDUCE-2703,Add a doc note about changes to io.sort.mb and io.sort.factor config params for SequenceFile sorting in DistCp,"Carrying over work from MAPREDUCE-2622 and HADOOP-6801 that impacts how sequencefiles will utilize the now deprecated io.sort.mb and io.sort.factor configs (new configs are made available for it to use, see HADOOP-6801). Since DistCp is the remaining lone framework user of SequenceFile.Sorter, it will require additions to docs about new properties to control."
MAPREDUCE-2702,[MR-279] OutputCommitter changes for MR Application Master recovery,"In MR AM recovers from a crash, it only reruns the non completed tasks. The completed tasks (along with their output, if any) needs to be recovered from the previous life. This would require some changes in OutputCommitter."
MAPREDUCE-2701,MR-279: app/Job.java needs UGI for the user that launched it,"./mr-client/hadoop-mapreduce-client-app/src/main/java/org/apache/hadoop/mapreduce/v2/app/job/Job.java is missing some data that is needed by the Job History GUI.  It needs the UGI for the user that launched it.
"
MAPREDUCE-2699,AM crashing because of invalid TA_CONTAINER_COMPLETED event,AM crashing because of invalid TA_CONTAINER_COMPLETED event
MAPREDUCE-2698,Expired NM's containers aren't being communicated to AM,Expired NM's containers aren't being communicated to AM - so the AM needs to rely on timeouts. We need to fix this.
MAPREDUCE-2697,Enhance CS to cap concurrently running jobs,Enhance CS to cap concurrently running jobs ala 0.20.203
MAPREDUCE-2696,Container logs aren't getting cleaned up when LogAggregation is disabled,Container logs aren't getting cleaned up when log-aggregation is disabled.
MAPREDUCE-2695,Unhealthy nodes (health-script) are still being assigned containers,Unhealthy nodes (health-script) are still being assigned containers
MAPREDUCE-2693,NPE in AM causes it to lose containers which are never returned back to RM,"The following exception in AM of an application at the top of queue causes this. Once this happens, AM keeps obtaining
containers from RM and simply loses them. Eventually on a cluster with multiple jobs, no more scheduling happens
because of these lost containers.

It happens when there are blacklisted nodes at the app level in AM. A bug in AM
(RMContainerRequestor.containerFailedOnHost(hostName)) is causing this - nodes are simply getting removed from the
request-table. We should make sure RM also knows about this update.

========================================================================
11/06/17 06:11:18 INFO rm.RMContainerAllocator: Assigned based on host match 98.138.163.34
11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=4978 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=4977 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: BEFORE decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=1540 #asks=5
11/06/17 06:11:18 INFO rm.RMContainerRequestor: AFTER decResourceRequest: applicationId=30 priority=20
resourceName=... numContainers=1539 #asks=6
11/06/17 06:11:18 ERROR rm.RMContainerAllocator: ERROR IN CONTACTING RM. 
java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decResourceRequest(RMContainerRequestor.java:246)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor.decContainerReq(RMContainerRequestor.java:198)
        at
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.assign(RMContainerAllocator.java:523)
        at
org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator$ScheduledRequests.access$200(RMContainerAllocator.java:433)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.heartbeat(RMContainerAllocator.java:151)
        at org.apache.hadoop.mapreduce.v2.app.rm.RMCommunicator$1.run(RMCommunicator.java:220)
        at java.lang.Thread.run(Thread.java:619)"
MAPREDUCE-2692,Ensure AM Restart and Recovery-on-restart is complete,Need to get AM restart and the subsequent recover after restart to work
MAPREDUCE-2691,Finish up the cleanup of distributed cache file resources and related tests.,Implement cleanup of distributed cache file resources
MAPREDUCE-2690,Construct the web page for default scheduler,"Currently, the web page for default scheduler reads as ""Under construction"". This is a long known issue, but could not find a tracking ticket. Hence opening one."
MAPREDUCE-2689,InvalidStateTransisiton when AM is not assigned to a job,"In cases where an AM is not being assigned to a job, RELEASED at COMPLETED invalid event is observed. This is easily reproducible in cases such as MAPREDUCE-2687."
MAPREDUCE-2688,rpm should only require the same major version as common and hdfs,The rpm should only require the same version of common and hdfs be installed.
MAPREDUCE-2687,Non superusers unable to launch apps in both secure and non-secure cluster,"Apps of non superuser fail to succeed in both secure and non-secure environment. Only the superuser(i.e. one who started/owns the mrv2 cluster) is able to launch apps successfully. However, when a normal user submits a job, the job fails."
MAPREDUCE-2686,NPE while requesting info for a non-existing job,"While performing job related operations such as job -kill, -status, -events etc for an unknown job, the following NPE is seen:

Exception in thread ""main"" java.lang.NullPointerException
        at org.apache.hadoop.mapred.ClientServiceDelegate.refreshProxy(ClientServiceDelegate.java:112)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getProxy(ClientServiceDelegate.java:100)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getRefreshedProxy(ClientServiceDelegate.java:93)
        at org.apache.hadoop.mapred.ClientServiceDelegate.getJobStatus(ClientServiceDelegate.java:383)
        at org.apache.hadoop.mapred.YARNRunner.getJobStatus(YARNRunner.java:515)
        at org.apache.hadoop.mapreduce.Cluster.getJob(Cluster.java:154)
        at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:254)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
        at org.apache.hadoop.mapred.JobClient.main(JobClient.java:1074)
"
MAPREDUCE-2685,Hadoop-Mapreduce-trunk build is failing,"Hadoop-Mapreduce-trunk has been failing for long time. 

https://builds.apache.org/job/Hadoop-Mapreduce-trunk/737/

org.apache.hadoop.cli.TestMRCLI.testAll is failing since Build #697
{code:xml}
2011-07-14 13:20:44,103 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(178)) -                  Comparator: [TokenComparator]
2011-07-14 13:20:44,104 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(180)) -          Comparision result:   [fail]
2011-07-14 13:20:44,104 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(182)) -             Expected output:   [Usage: java FsShell [-mv <src> ... <dst>]]
2011-07-14 13:20:44,104 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(184)) -               Actual output:   [mv: Wrong FS: har:/dest/dir0.har/dir0/file0, expected: hdfs://localhost:55672
Usage: hadoop fs [generic options] -mv <src> ... <dst>
]
{code}

org.apache.hadoop.fs.TestFileSystem.testCommandFormat is failing since Build #702

{code:xml}
org.apache.hadoop.fs.shell.CommandFormat$TooManyArgumentsException: Too many arguments: expected 2 but got 3
	at org.apache.hadoop.fs.shell.CommandFormat.parse(CommandFormat.java:113)
	at org.apache.hadoop.fs.shell.CommandFormat.parse(CommandFormat.java:77)
	at org.apache.hadoop.fs.TestFileSystem.__CLR3_0_2b0mwvrw7b(TestFileSystem.java:97)
	at org.apache.hadoop.fs.TestFileSystem.testCommandFormat(TestFileSystem.java:92)

{code}
org.apache.hadoop.mapred.TestNodeRefresh.testBlacklistedNodeDecommissioning
"
MAPREDUCE-2684,Job Tracker can starve reduces with very large input.,"If mapreduce.reduce.input.limit is mis-configured or if a cluster is just running low on disk space in general then reduces with large a input may never get scheduled causing the Job to never fail and never succeed, just starve until the job is killed.

The JobInProgess tries to guess at the size of the input to all reducers in a job.  If the size is over mapreduce.reduce.input.limit then the job is killed.  If it is not then findNewReduceTask() checks to see if the estimated size is too big to fit on the node currently looking for work.  If it is not then it will let some other task have a chance at the slot.

The idea is to keep track of how often it happens that a Reduce Slot is rejected because of the lack of space vs how often it succeeds and then guess if the reduce tasks will ever be scheduled.

So I would like some feedback on this.

1) How should we guess.  Someone who found the bug here suggested P1 + (P2 * S), where S is the number of successful assignments.  Possibly P1 = 20 and P2 = 2.0.  I am not really sure.
2) What should we do when we guess that it will never get a slot?  Should we fail the job or do we say, even though it might fail, well lets just schedule the it and see if it really will fail."
MAPREDUCE-2682,Add a -classpath option to bin/mapred,"We should have a bin/mapred classpath switch, MR-279 uses this in the branch."
MAPREDUCE-2680,Enhance job-client cli to show queue information for running jobs,"It'd be very useful to display queue-information for running jobs alongwith jobid, user, start-time etc."
MAPREDUCE-2679,MR-279: Merge MR-279 related minor patches into trunk,Jira to track very minor and misc. changes to trunk for MR-279
MAPREDUCE-2678,MR-279: minimum-user-limit-percent no longer honored,"MR-279: In the capacity-scheduler.xml configuration, the 'minimum-user-limit-percent' property is no longer honored. "
MAPREDUCE-2677,MR-279: 404 error while accessing pages from history server,"Accessing the following pages from the history server, causes 404 HTTP error
1. Cluster-> About 
2. Cluster -> Applications
3. Cluster -> Scheduler
4. Application -> About"
MAPREDUCE-2676,MR-279: JobHistory Job page needs reformatted,"The Job page, The Maps page and the Reduces page for the job history server needs to be reformatted.

The Job Overview needs to add in the User, a link to the Job Conf, and the Job ACLs
It also needs Submitted at, launched at, and finished at, depending on how they relates to Started and Elapsed.

In the attempts table we need to remove the new and the running columns
In the tasks table we need to remove progress, pending, and running columns and add in a failed count column
We also need to investigate what it would take to add in setup and cleanup statistics.  Perhaps these should be more generally Application Master statistics and links.

The Maps page and Reduces page should have the progress column removed."
MAPREDUCE-2675,MR-279: JobHistory Server main page needs to be reformatted,"The main page of the Job History Server is based off of the Application Master code.  It needs to be reformatted to be more useful and better match what was there before.

- The Active Jobs title needs to be replaced with something more appropriate (i.e. Retired Jobs)
- The table of jobs should have the following columns in it
  - Submit time, Job Id, Job Name, User and just because I think it would be useful state, maps completed, maps failed, reduces completed, reduces failed
- The table needs more advanced filtering, something like http://datatables.net/release-datatables/examples/api/multi_filter.html This is to match the previous search functionality."
MAPREDUCE-2673,MR-279: JobHistory Server should not refresh,"The Job History Server UI is based off of the Application Master UI, which refreshes the page for jobs regularly.  The page should not refresh at all for the JobHistroy, because the job has finished and is not changing."
MAPREDUCE-2672,MR-279: JobHistory Server needs Analysis this job,"The JobHistory Server needs to implement the Analysis this job functionality from the previous server.

This should include the following info
Hadoop Job ID 
User : 
JobName : 
JobConf : 
Submitted At : 
Launched At :  (including duration)
Finished At :  (including duration)
Status :

Time taken by best performing Map task <TASK_LINK>:
Average time taken by Map tasks:
Worse performing map tasks: (including task links and duration)
The last Map task <TASK_LINK> finished at (relative to the Job launch time):  (including duration)

Time taken by best performing shuffle <TASK_LINK>:
Average time taken by shuffle:
Worse performing Shuffles: (including task links and duration)
The last Shuffle <TASK_LINK> finished at (relative to the Job launch time):  (including duration)

Time taken by best performing Reduce task <TASK_LINK>:
Average time taken by Reduce tasks:
Worse performing reduce tasks: (including task links and duration)
The last Reduce task <TASK_LINK> finished at (relative to the Job launch time):  (including duration)
"
MAPREDUCE-2671,"MR-279: Package examples, tools, test jars with the build","Jars such as examples, tools, test, streaming, gridmix has to be packaged as a part of the MR-279 builds https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-MR-279-Build/

"
MAPREDUCE-2670,Fixing spelling mistake in FairSchedulerServlet.java,"""Admininstration"" is misspelled."
MAPREDUCE-2669,Some new examples and test cases for them.,"Looking to add some more examples such as Mean, Median, and Standard Deviation to the examples.
I have some generic JUnit testcases as well."
MAPREDUCE-2668,MR-279: APPLICATION_STOP is never sent to AuxServices,APPLICATION_STOP is never sent to the AuxServices only APPLICATION_INIT.  This means that all map intermediate data will never be deleted.
MAPREDUCE-2667,MR279: mapred job -kill leaves application in RUNNING state,"the mapred job -kill command doesn't seem to fully clean up the application.

If you kill a job and run mapred job -list again it still shows up as running:

mapred job -kill job_1310072430717_0003
Killed job job_1310072430717_0003

 mapred job -list
Total jobs:1
JobId   State   StartTime       UserName        Queue   Priority        SchedulingInfo
job_1310072430717_0003  RUNNING 0       tgraves default NORMAL  98.139.92.22:19888/yarn/job/job_1310072430717_3_3

Running kill again will error out.

It also still shows up in the RM Applications UI as running with a note of: Kill Job received from client
job_1310072430717_0003 Job received Kill while in RUNNING state."
MAPREDUCE-2666,MR-279: Need to retrieve shuffle port number on ApplicationMaster restart,MAPREDUCE-2652 allows ShuffleHandler to return the port it is operating on.  In the case of an ApplicationMaster crash where it needs to be restarted that information is lost.  We either need to re-query it from each of the NodeManagers or to persist it to the JobHistory logs and retrieve it again.  The job history logs is probably the simpler solution.
MAPREDUCE-2665,MR-279: Add hostname:port to NM and RM info/about page,Adding host port information to the RM NM info/about pages
MAPREDUCE-2664,MR 279: Implement JobCounters for MRv2 + Fix for Map Data Locality,MRv2 is currently not setting any Job Counters.
MAPREDUCE-2663,MR-279: Refactoring StateMachineFactory inner classes,"The code for ApplicableSingleTransition and ApplicableMultipleTransition inner classes is almost identical. For maintainability, it is better to refactor them into a single inner class."
MAPREDUCE-2661,MR-279: Accessing MapTaskImpl from TaskImpl,We are directly accessing MapTaskImpl in TaskImpl.InitialScheduleTransition.transition(..). It'll be better to reorganize the code so each subclass can provide its own behavior instead of explicitly checking for the subclass type. 
MAPREDUCE-2660,MR-279: org.apache.hadoop.mapred.CombineFileInputFormat.getSplits() throws ArrayStoreException,"In branch MR-279, org.apache.hadoop.mapred.getSplits() throws RuntimeException:ArrayStoreException 

The following code in trunk:
{noformat}
  public InputSplit[] getSplits(JobConf job, int numSplits) 
    throws IOException {
    List<org.apache.hadoop.mapreduce.InputSplit> newStyleSplits =
      super.getSplits(new Job(job));
    InputSplit[] ret = new InputSplit[newStyleSplits.size()];
    for(int pos = 0; pos < newStyleSplits.size(); ++pos) {
      org.apache.hadoop.mapreduce.lib.input.CombineFileSplit newStyleSplit = 
        (org.apache.hadoop.mapreduce.lib.input.CombineFileSplit) newStyleSplits.get(pos);
      ret[pos] = new CombineFileSplit(job, newStyleSplit.getPaths(),
        newStyleSplit.getStartOffsets(), newStyleSplit.getLengths(),
        newStyleSplit.getLocations());
    }
    return ret;
  }
{noformat}

got changed to

{noformat}
  public InputSplit[] getSplits(JobConf job, int numSplits) 
    throws IOException {
    return super.getSplits(new Job(job)).toArray(new InputSplit[0]);
  }
{noformat}

Code in trunk works fine. We should change the code in MR-279 to the same in trunk."
MAPREDUCE-2658,Problem running full map & reduce jobs on mrv2,"Following the installation instructions at: https://svn.apache.org/repos/asf/hadoop/common/branches/MR-279/mapreduce/INSTALL
the randomwriter example runs successfully. However, other full map & reduce jobs (e.g. wordcount) fail with the error:

java.lang.UnsupportedOperationException: Incompatible with LocalRunner
	at org.apache.hadoop.mapred.YarnOutputFiles.getInputFile(YarnOutputFiles.java:200)
	at org.apache.hadoop.mapred.ReduceTask.getMapFiles(ReduceTask.java:223)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:412)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:148)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:143)

The ReduceTask evaluates the isLocal flag based on the property ""mapreduce.jobtracker.address"", the default value for this property in mapred-default.xml is 'local' and this is the cause of the problem.

Setting ""mapreduce.jobtracker.address"" in the mapred-site.xml to something other than ""local"" seems to solve the problem. "
MAPREDUCE-2656,"Map Reduce Tasks are continously failing, when one among the several harddisks available on the TaskTracker fails.","1. Pull out one hard disk from Task tracker node (out of 10 disks pull one). Now it is noted that some jobs are failing. 
However process is continued. 
2. Wait for sometime (15 mins) and pull out one disk from another Task tracker. 
3. More number of jobs failed now and it can be seen from UI. Process is getting paused.

The exception can be seen in the job tracker UI for a failed job.
{code:xml} 
Error initializing attempt_201010221528_10174_m_000011_0:
java.io.IOException: Expecting a line not the end of stream
 at org.apache.hadoop.fs.DF.parseExecResult(DF.java:110)
 at org.apache.hadoop.util.Shell.runCommand(Shell.java:182)
 at org.apache.hadoop.util.Shell.run(Shell.java:137)
 at org.apache.hadoop.fs.DF.getAvailable(DF.java:74)
 at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:385)
 at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:134)
 at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:113)
 at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:835)
 at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1790)
 at org.apache.hadoop.mapred.TaskTracker.access$1200(TaskTracker.java:104)
 at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1753)

Error initializing attempt_201010221528_10174_m_000011_1:
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for taskTracker/jobcache/job_201010221528_10174/work
 at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:454)
 at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:134)
 at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:113)
 at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:835)
 at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1790)
 at org.apache.hadoop.mapred.TaskTracker.access$1200(TaskTracker.java:104)
 at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1753)

{code} 


Task Tracker log can be seen here :
{code:xml} 
2010-10-25 16:36:24,215 ERROR mapred.TaskTracker (TaskTracker.java:offerService(1211)) - Caught exception: java.io.IOException: Expecting a line not the end of stream
        at org.apache.hadoop.fs.DF.parseExecResult(DF.java:110)
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:182)
        at org.apache.hadoop.util.Shell.run(Shell.java:137)
        at org.apache.hadoop.fs.DF.getAvailable(DF.java:74)
        at org.apache.hadoop.mapred.TaskTracker.getFreeSpace(TaskTracker.java:1586)
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:1274)
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1106)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1848)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3022)

2010-10-25 16:36:24,216 INFO  mapred.TaskTracker (TaskTracker.java:run(1856)) - Lost connection to JobTracker [/192.168.97.1:9001].  Retrying...
java.lang.Exception: java.io.IOException: Expecting a line not the end of stream
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1212)
        at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:1848)
        at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:3022)
Caused by: java.io.IOException: Expecting a line not the end of stream
        at org.apache.hadoop.fs.DF.parseExecResult(DF.java:110)
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:182)
        at org.apache.hadoop.util.Shell.run(Shell.java:137)
        at org.apache.hadoop.fs.DF.getAvailable(DF.java:74)
        at org.apache.hadoop.mapred.TaskTracker.getFreeSpace(TaskTracker.java:1586)
        at org.apache.hadoop.mapred.TaskTracker.transmitHeartBeat(TaskTracker.java:1274)
        at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:1106)
        ... 2 more
2010-10-25 16:36:29,550 INFO  mapred.TaskTracker (TaskTracker.java:transmitHeartBeat(1256)) - Resending 'status' to '192.168.97.1' with reponseId '18361
2010-10-25 16:36:29,550 WARN  mapred.TaskTracker (TaskTracker.java:checkLocalDirs(2982)) - Task Tracker local can not create directory: /hdfsdata/0/mapred/local
2010-10-25 16:36:32,656 WARN  mapred.TaskTracker (TaskTracker.java:checkLocalDirs(2982)) - Task Tracker local can not create directory: /hdfsdata/0/mapred/local
{code} 


This seems to be fixed in the trunk."
MAPREDUCE-2655,MR279: Audit logs for YARN ,"We need audit logs for YARN components:

ResourceManager:
 - All the refresh* protocol access points - refreshQueues, refreshNodes, refreshProxyUsers,
refreshUserToGroupMappings.
 - All app-submissions, app-kills to RM.
 - Illegal and successful(?) AM registrations.
 - Illegal container allocations/deallocations from AMs
 - Successful container allocations/deallocations from AMs too?

NodeManager:
 - Illegal container launches from AMs
 - Successful container launches from AMs too?

Not sure if we need audit logs from MR AMs."
MAPREDUCE-2652,MR-279: Cannot run multiple NMs on a single node ,"Currently in MR-279 the Auxiliary services, like ShuffleHandler, have no way to communicate information back to the applications.  Because of this the Map Reduce Application Master has hardcoded in a port of 8080 for shuffle.  This prevents the configuration ""mapreduce.shuffle.port"" form ever being set to anything but 8080.  The code should be updated to allow this information to be returned to the application master.  Also the data needs to be persisted to the task log so that on restart the data is not lost."
MAPREDUCE-2651,Race condition in Linux Task Controller for job log directory creation,There is a rare race condition in linux task controller when concurrent task processes tries to create job log directory at the same time. 
MAPREDUCE-2650,back-port MAPREDUCE-2238 to 0.20-security,"Dev had seen the attempt directory permission getting set to 000 or 111 in the CI builds and tests run on dev desktops with 0.20-security.
MAPREDUCE-2238 reported and fixed the issue for 0.22.0, back-port to 0.20-security is needed.
"
MAPREDUCE-2649,MR279: Fate of finished Applications on RM,"Today RM keeps the references of finished application for ever. Though this is not sustainable long term, it keeps
the user experience saner. Users can revisit RM UI and check the status of their apps.

We need to think of purging old references yet keeping the UX sane."
MAPREDUCE-2648,High Availability for JobTracker,"In Hadoop cluster, JobTracker is responsible for managing the life cycle of MapReduce jobs. If JobTracker fails, then MapReduce service will not be available until JobTracker is restarted. We propose an automatic failover solution for JobTracker to address such single point of failure. It is based on Leader Election Framework suggested in ZOOKEEPER-1080

Please refer to attached document."
MAPREDUCE-2647,Memory sharing across all the Tasks in the Task Tracker to improve the job performance,"	If all the tasks (maps/reduces) are using (working with) the same additional data to execute the map/reduce task, each task should load the data into memory individually and read the data. It is the additional effort for all the tasks to do the same job. Instead of loading the data by each task, data can be loaded into main memory and it can be used to execute all the tasks.


h5.Proposed Solution:
1. Provide a mechanism to load the data into shared memory and to read that data from main memory.
2. We can provide a java API, which internally uses the native implementation to read the data from the memory. All the maps/reducers can this API for reading the data from the main memory. 


h5.Example: 
	Suppose in a map task, ip address is a key and it needs to get location of the ip address from a local file. In this case each map task should load the file into main memory and read from it and close it. It takes some time to open, read from the file and process every time. Instead of this, we can load the file in the task tracker memory and each task can read from the memory directly.
"
MAPREDUCE-2646,MR-279: AM with same sized maps and reduces hangs in presence of failing maps,Currently AM can assign a container given by RM to any map or reduce. However RM allocates for a particular priority. This leads to AM and RM data structures going out of sync.
MAPREDUCE-2645,Updates to MRv2 INSTALL documentation,"There are a few issues w/the current INSTALL document for MRv2 that I came across when I attempted to get it running:

1) Correct the mvn arg for skipping tests,
2) Add a step to start the yarn historyserver,
3) Add instructions to explicitly build the examples jar file and specify the mapreduce.clientfactory.class.name parameter correctly for MRv2."
MAPREDUCE-2644,NodeManager fails to create containers when NM_LOG_DIR is not explicitly set in the Configuration,"If the yarn configuration does not explicitly specify a value for the yarn.server.nodemanager.log.dir property, container allocation will fail on the NodeManager w/an NPE when the LocalDirAllocator goes to create the temp directory. In most of the code, we handle this by defaulting to /tmp/logs, but we cannot do this in the LocalDirAllocator context, so we need to set the default value explicitly in the Configuration.

Marking this as major b/c it's annoying to bump into it when you're getting your first MRv2 cluster up and running. :)"
MAPREDUCE-2642,Fix two bugs in v2.app.speculate.DataStatistics,"Fixes two bugs in DataStatistics: a divide by zero in the variance calculation when count == 0, and a synchronization issue in how the updateStatistics method was implemented."
MAPREDUCE-2641,Fix the ExponentiallySmoothedTaskRuntimeEstimator and its unit test,Fixed the ExponentiallySmoothedTaskRuntimeEstimator so that it can run and pass the test defined for it in TestRuntimeEstimators.
MAPREDUCE-2640,"The maxRunningTasks property of the LimitTasksPerJob scheduler is ambiguous in its description, and must be updated","The property's entry in mapred-default.xml is like so:

{code}
<property>
  <name>mapreduce.jobtracker.taskscheduler.maxrunningtasks.perjob</name>
  <value></value>
  <description>The maximum number of running tasks for a job before
  it gets preempted. No limits if undefined.
  </description>
</property>
{code}

There is no mention that this is a property exclusive to the LimitTasksPerJob scheduler alone. The doc ought to be updated to note that unless there's a plan of reusing such a property (I do not see fair or capacity schedulers utilizing this, and they use their own configs)."
MAPREDUCE-2635,Jobs hang indefinitely on failure.,"Running the following example hangs the child job indefinitely.

public class HaltCluster
{

  public static void main(String[] args) throws IOException
  {
    JobConf jobConf = new JobConf();
    prepareConf(jobConf);
    if (args != null && args.length > 0)
    {
      jobConf.set(""callonceagain"", args[0]);
      jobConf.setMaxMapAttempts(1);
      jobConf.setJobName(""ParentJob"");

    }
    JobClient.runJob(jobConf);

  }

  public static void prepareConf(JobConf jobConf)
  {
    jobConf.setJarByClass(HaltCluster.class);
    jobConf.set(""mapred.job.tracker"", ""<<jobtracker>>"");
    jobConf.set(""fs.default.name"", ""<<hdfs>>"");
    MultipleInputs.addInputPath(jobConf, new Path(""/ignore"" + System.currentTimeMillis()), MyInputFormat.class);
    jobConf.setJobName(""ChildJob"");
    jobConf.setMapperClass(MyMapper.class);
    jobConf.setOutputFormat(NullOutputFormat.class);
    jobConf.setNumReduceTasks(0);
  }

}

public class MyMapper implements Mapper<IntWritable, Text, NullWritable, NullWritable>
{
  JobConf myConf = null;

  @Override
  public void map(IntWritable arg0, Text arg1, OutputCollector<NullWritable, NullWritable> arg2, Reporter arg3) throws IOException
  {
    if (myConf != null && ""true"".equals(myConf.get(""callonceagain"")))
    {
      startBackGroundReporting(arg3);
      HaltCluster.main(new String[] {});
    }

    throw new RuntimeException(""Throwing exception"");
  }

  private void startBackGroundReporting(final Reporter arg3)
  {
    Thread t = new Thread()
    {
      @Override
      public void run()
      {
        while (true)
        {
          arg3.setStatus(""Reporting to be alive at "" + System.currentTimeMillis());
        }
      }
    };
    t.setDaemon(true);
    t.start();
  }

  @Override
  public void configure(JobConf arg0)
  {
    myConf = arg0;

  }

  @Override
  public void close() throws IOException
  {
    // TODO Auto-generated method stub

  }

}

run using the following command

java -cp <<classpath>> HaltCluster true

But if only one job is triggered as java -cp <<classpath>> HaltCluster
it fails to max number of attempts and quits as expected.


Also, when the jobs hang, running the child job once again, makes it come out of deadlock and completes the three jobs.

"
MAPREDUCE-2633,MR-279: Add a getCounter(Enum) method to the Counters interface,"I'm fixing a few TODOs I came across in TaskAttemptImpl.java related to the fact that the MRv2 Counters interface don't expose a getCounter(Enum) method for accessing a Counter using the enum's class as the group name and the enum's value as the name of the counter.

Will add the patch momentarily."
MAPREDUCE-2632,Avoid calling the partitioner when the numReduceTasks is 1.,We can avoid the call to the partitioner when the number of reducers is 1.This will avoid the unnecessary computations by the partitioner.
MAPREDUCE-2631,Potential resource leaks in BinaryProtocol$TeeOutputStream.java,"{code:title=BinaryProtocol$TeeOutputStream.java|borderStyle=solid}

public void close() throws IOException {
      flush();
      file.close();
      out.close();
    }
{code} 

In the above code, if the file.close() throws any exception out will not be closed.
 
"
MAPREDUCE-2630,MR-279: refreshQueues leads to NPEs when used w/FifoScheduler,"The RM's admin service exposes a method refreshQueues that is used to update the queue configuration when used with the CapacityScheduler, but if it is used with the FifoScheduler, it will set the containerTokenSecretManager/clusterTracker fields on the FifoScheduler to null, which eventually leads to NPE. Since the FifoScheduler only has one queue that cannot be refreshed, the correct behavior is for the refreshQueues call to be a no-op.

I will attach a patch that fixes this by splitting the ResourceScheduler's reinitialize method into separate initialize/updateQueues methods."
MAPREDUCE-2629,Class loading quirk prevents inner class method compilation,"While profiling jobs like terasort and gridmix, I noticed that a
method ""org.apache.hadoop.mapreduce.task.ReduceContextImpl.access
$000"" is near the top. It turns out that this is because the
ReduceContextImpl class has a member backupStore which is accessed
from an inner class ReduceContextImpl$ValueIterator. Due to the way
synthetic accessor methods work, every access of backupStore results
in a call to access$000 to the outer class. For some portion of the
run, backupStore is null and the BackupStore class has never been
loaded by the reducer.

Due to the way the Hotspot JVM inliner works, by default it will not
inline a short method where the class of of the return value object
is unloaded - if you use a debug JVM with -XX:+PrintCompilation you
will see a failure reason message like ""unloaded signature classes.""
This causes every call to ReduceContextImpl.access$000 to be executed
in the interpreter for the handful of bytecodes to return the null
backupStore.
"
MAPREDUCE-2628,MR-279: Add compiled on date to NM and RM info/about page,"Compiled on dates were present on the JobTracker UI. Bring compiled on dates to resource manager and node
manager UI. 

NM and RM retrieves build version for hadoop and yarn version via the getBuildVersion util api. This function used to
contain the compiled on date, but since has been removed since that function is used to determine hadoop compatible
versions, but was too restrictive with build date being present. Instead, a getDate call should be used to retrieve the
compiled on date."
MAPREDUCE-2627,guava-r09 JAR file needs to be added to mapreduce.,"Need to add the guava-r09.jar file into the ""mapreduce/build/ivy/lib/Hadoop/common"" directory; missing from build."
MAPREDUCE-2625,MR-279: Add Node Manager Version to NM info page,Hadoop and YARN versions are missing from the NM info page
MAPREDUCE-2624,Update RAID for HDFS-2107,HDFS-2107 is going to move BlockPlacementPolicy to another package.
MAPREDUCE-2623,Update ClusterMapReduceTestCase to use MiniDFSCluster.Builder,"Looking at test class ClusterMapReduceTestCase it issues a warning that the dfsCluster = new MiniDFSCluster(conf, 2, reformatDFS, null); line of code is deprecated and MiniDFSCluster.Builder should be used instead. It notes that the current API will be phased out in version 24. I propose to update the test class to the most up to date code as it's referenced several places on the internet as an example of how to write a Hadoop Unit Test."
MAPREDUCE-2622,"Remove the last remaining reference to ""io.sort.mb""","TestLocalRunner still carries ""io.sort.mb"", which must be updated to ""mapreduce.task.io.sort.mb"" (MRJobConfig.IO_SORT_MB)."
MAPREDUCE-2621,"TestCapacityScheduler fails with ""Queue ""q1"" does not exist""","{quote}
Error Message

Queue ""q1"" does not exist

Stacktrace

java.io.IOException: Queue ""q1"" does not exist
	at org.apache.hadoop.mapred.JobInProgress.<init>(JobInProgress.java:354)
	at org.apache.hadoop.mapred.TestCapacityScheduler$FakeJobInProgress.<init>(TestCapacityScheduler.java:172)
	at org.apache.hadoop.mapred.TestCapacityScheduler.submitJob(TestCapacityScheduler.java:794)
	at org.apache.hadoop.mapred.TestCapacityScheduler.submitJob(TestCapacityScheduler.java:818)
	at org.apache.hadoop.mapred.TestCapacityScheduler.submitJobAndInit(TestCapacityScheduler.java:825)
	at org.apache.hadoop.mapred.TestCapacityScheduler.testMultiTaskAssignmentInMultipleQueues(TestCapacityScheduler.java:1109)
{quote}

When queue name is invalid, an exception is thrown now. 

"
MAPREDUCE-2620,Update RAID for HDFS-2087,DataTransferProtocol was changed by HDFS-2087.  Need to update RAID.
MAPREDUCE-2619,Broken eclipse environment for mapreduce,"The build.xml ant eclipse target creates a broken eclipse environment for mapreduce.

Excluding testjar/ClassWithNoPackage.java and {contrib.dir}/gridmix/src/test seems to solve this issue."
MAPREDUCE-2618,"MR-279: 0 map, 0 reduce job fails with Null Pointer Exception","A 0 map, 0 reduce job fails with an NPE. This case works fine on hadoop-0.20.x. The job should succeed and run setup/cleanup code - with no tasks.  Below is the stacktrace:

11/06/05 19:35:37 WARN mapred.ClientServiceDelegate:
 StackTrace: java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl.getTaskAttemptCompletionEvents(JobImpl.java:498)
        at
org.apache.hadoop.mapreduce.v2.app.client.MRClientService$MRClientProtocolHandler.getTaskAttemptCompletionEvents(MRClientService.java:290)
        at
org.apache.hadoop.mapreduce.v2.api.impl.pb.service.MRClientProtocolPBServiceImpl.getTaskAttemptCompletionEvents(MRClientProtocolPBServiceImpl.java:139)
        at
org.apache.hadoop.yarn.proto.MRClientProtocol$MRClientProtocolService$2.callBlockingMethod(MRClientProtocol.java:195)
        at org.apache.hadoop.yarn.ipc.ProtoOverHadoopRpcEngine$TunnelResponder.call(ProtoOverHadoopRpcEngine.java:168)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:420)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1406)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1402)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1094)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1400)"
MAPREDUCE-2615,MR 279: KillJob should go through AM whenever possible,KillJob currently goes directly to the RM - which effectively causes the AM and tasks to be killed via a signal. History information is not recorded in this case.
MAPREDUCE-2611,"MR 279: Metrics, finishTimes, etc in JobHistory",
MAPREDUCE-2610,Inconsistent API JobClient.getQueueAclsForCurrentUser,"Client needs access to the current user's queue name.
Public method JobClient.getQueueAclsForCurrentUser() returns QueueAclsInfo[].
The QueueAclsInfo class has default access. A public method should not return a package-private class.

The QueueAclsInfo class, its two constructors, getQueueName, and getOperations methods should be public."
MAPREDUCE-2608,Mavenize mapreduce contribs,Same as HADOOP-6671 for mapreduce contribs
MAPREDUCE-2607,Mavenization of hadoop-mapreduce,Same as HADOOP-6671 for mapreduce
MAPREDUCE-2606,Remove IsolationRunner,"IsolationRunner it seems it has been broken for a while, it gives a NPE when trying to use it.

In addition, it supports only Map tasks; to use it the user must ssh to the node where the task failed; and unless the job has been configured to keep local files, the job must be run again.

Because of this, IMO, the current implementation of IsolationRunner is not of much use.

Any objection to remove it from trunk and if people have the need for such functionality to open another JIRA to build this functionality supported by the JobTracker (ie via the UI console)?"
MAPREDUCE-2605,Hadoop Streaming (StreamJob) does not delete temporary job/package jar,"The streaming job driver (org.apache.hadoop.streaming.StreamJob) does not delete the temporary JAR file it generates after a job completes.  Without the fix, /var/tmp fills up  with streaming job jars until they get wiped.

The jar name is stored in the class variable 'jar_'.  The JAR is generated in 'packageJobJar()' and the name stored in jar_.

Fix:  run()/submitAndMonitorJob() should clean up the jar_ file when done.  Or the JAR could be generatd as a tempfile and cleaned up automatically.

"
MAPREDUCE-2603,Gridmix system tests are failing due to high ram emulation enable by default for normal mr jobs in the trace which exceeds the solt capacity.,"In Gridmix high ram emulation enable by default.Because of this feature, some of the gridmix system tests are hanging for some time and then failing after timeout. Actually the failure case was occurring whenever reserved slot capacity exceeds the cluster slot capacity.So for fixing the issue by disabling the high ram emulation in the tests which are using the normal mr jobs in the traces."
MAPREDUCE-2602,Allow setting of end-of-record delimiter for TextInputFormat (for the old API),"Since there are users who are still using the old MR API, it will be useful to modify the org.apache.hadoop.mapred.LineRecordReader and org.apache.hadoop.mapred.TextInputFormat to be able to use custom (user-specified) end-of-record delimiters. This will make use of the LineReader improvement introduced in HADOOP-7096 that enables the LineReader to break lines at user-specified delimiters. 

Note: MAPREDUCE-2254 already added this improvement to the new API (but not the old API)."
MAPREDUCE-2598,"MR 279: miscellaneous UI, NPE fixes for JobHistory, UI",
MAPREDUCE-2596,Gridmix should notify job failures,Gridmix doesn't warn the user if any of the jobs in the mix fail... it probably should printout a summary of the jobs and other statistics at the end too.
MAPREDUCE-2595,MR279: update yarn INSTALL doc,yarn install doc needs to be updated after unsplit: http://svn.apache.org/repos/asf/hadoop/common/branches/MR-279/mapreduce/INSTALL
MAPREDUCE-2592,TT should fail task immediately if userlog dir cannot be created,"Currently, TaskRunner will log the message ""mkdirs failed. Ignoring"" if it fails to mkdir the userlog directory for a task. Then, it goes on to spawn taskjvm.sh which tries to redirect output into the userlogs dir, thus failing with exit code 1. This leads to error messages that are very hard to diagnose (""task failed with exit status 1"") in cases where the userlog directory has either become inaccessible or has reached the maximum number of dirents (32000 in ext3)"
MAPREDUCE-2590,How to access Job Configuration file in Partitioner,"I need to access Job Configuration file in partitioner to fetch some information. Generally we can access job configuration file easily in map or reduce side by this code 

Configuration config = context.getConfiguration();
But this same code cannot be used in partitioner. To solve this issue I followed the patch https://issues.apache.org/jira/browse/MAPREDUCE-2474 but it is a doc so I downloaded the latest trunk code and generate the jar but I did not get any extra feature from that to call the job configuration file So any one knows the code to call Job Configuration file in partitioner."
MAPREDUCE-2589,TaskTracker not purging userlog directories,"UserLogCleaner is not robust. Leftover userlogs after a restart sometimes have to be manually
cleaned. Things can accumulate over a period of time."
MAPREDUCE-2588,Raid is not compile after DataTransferProtocol refactoring,Raid is directly using {{DataTransferProtocol}}.  It cannot be compiled after HDFS-2066.
MAPREDUCE-2587,MR279: Fix RM version in the cluster->about page ,The Resource Manager version in the Cluster->About page always shows 1.0-SNAPSHOT. 
MAPREDUCE-2586,mapreduce/contrib/raid not compile due to hdfs changes.,
MAPREDUCE-2585,Add dumpConfiguration option in hadoop help message,Execution of bin/hadoop should show the -dumpConfiguration option introduced in MAPREDUCE-768
MAPREDUCE-2584,"Check for serializers early, and give out more information regarding missing serializers","As discussed on HADOOP-7328, MapReduce can handle serializers in a much better way in case of bad configuration, improper imports (Some odd Text class instead of the Writable Text set as key), etc..

This issue covers the MapReduce parts of the improvements (made to IFile, MapOutputBuffer, etc. and possible early-check of serializer availability pre-submit) that provide more information than just an NPE as is the current case."
MAPREDUCE-2582,MR 279: Cleanup JobHistory event generation,Generate JobHistoryEvents for the correct transitions. Fix missing / incorrect values being set.
MAPREDUCE-2581,Spelling errors in log messages (MapTask),"Spelling errors in log messages (MapTask) - e.g. search for ""recieve"" (should be ""receive"").  A decent IDE should detect these errors as well."
MAPREDUCE-2580,MR 279: RM UI should redirect finished jobs to History UI,"The RM UI currently has a link to the AM UI. After an application finishes (AM not available), the RM UI should link to the history UI."
MAPREDUCE-2579,The parity path is not initial correctly in BlockPlacementPolicyRaid,"BlockPlacementPolicyRaid.initialize() initialize the parity paths.
It uses Path.makeQualified() that requires to contact namenode but namenode is not up yet."
MAPREDUCE-2578,Fix eclipse project to work out of the box,"Currently ""ant eclipse"" generates an eclipse project that doesn't actually work properly. A few issues:
- the ""testjar"" dir inside src/test/mapred has a java class in no package, which confuses Eclipse since it's in testjar/
- the gridmix tests have test/org and test/system/org, which makes eclipse thing the system tests belong in a package ""system.org.apache.hadoop...""
- the webapps are in build/ directly, but putting build/ on the classpath breaks things since we then have two copies of every class, etc
- some parts of the code depend on hadoop.log.dir being defined, which isn't true when running junit inside a stock Eclipse setup"
MAPREDUCE-2577,RAID FS (DistributedRaidFileSystem) skip() implementation needs to be improved,"MAPREDUCE-2248 implemented skip() so that it skips one byte at a time, which is bad. It should skip a larger number of bytes at a time to improve performance."
MAPREDUCE-2576,Typo in comment in SimulatorLaunchTaskAction.java,"This JIRA is to track a fix to a super-trivial issue of a typo of ""or"" misspelled as ""xor "" in Line 24 of SimulatorLaunchTaskAction.java"
MAPREDUCE-2575,TestMiniMRDFSCaching fails if test.build.dir is set to something other than build/test,TestMiniMRDFSCaching fails if test.build.dir is set to something other than build/test
MAPREDUCE-2573,New findbugs warning after MAPREDUCE-2494,"MAPREDUCE-2494 introduced the following findbugs warning in trunk:
TrackerDistributedCacheManager.java:739, SIC_INNER_SHOULD_BE_STATIC, Priority: Low
Should org.apache.hadoop.mapreduce.filecache.TrackerDistributedCacheManager$CacheDir be a _static_ inner class?

This class is an inner class, but does not use its embedded reference to the object which created it.  This reference makes the instances of the class larger, and may keep the reference to the creator object alive longer than necessary.  If possible, the class should be made static."
MAPREDUCE-2572,Throttle the deletion of data from the distributed cache,"When deleting entries from the distributed cache we do so in a background thread.  Once the size limit of the distributed cache is reached all unused entries are deleted.  MAPREDUCE-2494 changes this so that entries are deleted in LRU order until the usage falls below a given threshold.  In either of these cases we are periodically flooding a disk with delete requests which can slow down all IO operations to a drive.  It would be better to be able to throttle this deletion so that it is spread out over a longer period of time.  This jira is to add in this throttling.

On investigating it seems much simpler to backport MPAREDUCE-2494 to 20S before implementing this change rather then try to implement it without LRU deletion, because LRU goes a long way towards reducing the load on the disk anyways."
MAPREDUCE-2571,CombineFileInputFormat.getSplits throws a java.lang.ArrayStoreException,"The getSplits methods of 
  org.apache.hadoop.mapred.lib.CombineFileInputFormat 
not work.

...mapred.lib.CombineFileInputFormat(0.20-style) is a proxy for ...mapreduce.lib.input.CombineFileInputFormat(0.21-style)

The 0.21-style getSplits returns ArrayList<...mapreduce.lib.input.CombineFileSplit>
and the 0.20-style delegation calls toArray(...mapred.InputSplit[])

The ...mapreduce.lib.input.CombineFileSplit is based on ...mapreduce.InputSplit
and ...mapred.InputSplit is a interface, not a super-class of ...mapreduce.InputSplit

"
MAPREDUCE-2570,Bug in RAID FS (DistributedRaidFileSystem) unraid path,"The ""un-raid"" path in DistributedRaidFileSystem goes through RaidNode.unRaidCorruptBlock(), which has a bug when the parity file is inside a HAR. The temporary file that contains the recovered block contents is created in the filesystem that hosts the parity file. In case the parity file is inside a HAR, its filesystem is HarFileSystem, which is read-only. In this case the temporary file creation will fail. The fix is a one-line change to use the underlying filesystem of the HAR."
MAPREDUCE-2569,MR-279: Restarting resource manager with root capacity not equal to 100 percent should result in error,root.capacity is set to 90% without failure
MAPREDUCE-2566,MR 279: YarnConfiguration should reloadConfiguration if instantiated with a non YarnConfiguration object,YarnConfiguration(conf) uses the ctor Configuration(conf) which is effectively a clone. If the configuration object is created before YarnConfiguration has been loaded - yarn-site.xml will not be available to the configuration.
MAPREDUCE-2564,NullPointerException in WritableComparator,"java.lang.NullPointerException
        at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:96)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.compare(MapTask.java:1110)
        at org.apache.hadoop.util.QuickSort.sortInternal(QuickSort.java:70)
        at org.apache.hadoop.util.QuickSort.sort(QuickSort.java:59)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1398)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1297)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:698)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:765)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:369)
        at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:210)

It is easy to see why this is happening.  The WritableComparator is created in JobConf line 776:
{code:title=JobConf.java}
   return WritableComparator.get(getMapOutputKeyClass().asSubclass(WritableComparable.class));
}
{code}
which calls
{code:title=WritableComparator.java|borderStyle=solid}
protected WritableComparator(Class<? extends WritableComparable> keyClass) {
    this(keyClass, false);
  }

  protected WritableComparator(Class<? extends WritableComparable> keyClass,
      boolean createInstances) {
    this.keyClass = keyClass;
    if (createInstances) {
      key1 = newKey();
      key2 = newKey();
      buffer = new DataInputBuffer();
    } else {
      key1 = key2 = null;
      buffer = null;
    }
  }
{code}

key1, key2, and buffer end up being null. When compare() is called the NPE is thrown because buffer is null

{code:title=WritableComparator.java|borderStyle=solid}
 public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) {
    try {
      buffer.reset(b1, s1, l1);                   // parse key1
      key1.readFields(buffer);
      
      buffer.reset(b2, s2, l2);                   // parse key2
      key2.readFields(buffer);
      
    } catch (IOException e) {
      throw new RuntimeException(e);
    }
    
    return compare(key1, key2);                   // compare them
  }
{code}"
MAPREDUCE-2563,Gridmix high ram jobs emulation system tests.,"1. Run the Gridmix with a high ram jobs trace and  verify each Gridmix job whether it honors the high ram or not. In
the trace the jobs should use the high ram for both maps and reduces.

2. Run the Gridmix with a high ram jobs trace and  verify each Gridmix job whether it honors the high ram or not. In
the trace the jobs should use the high ram only for maps.

3. Run the Gridmix with a high ram jobs trace and verify each Gridmix job whether it honors the high ram or not. In the
trace the jobs should use the high ram only for reducers.

4. Run the Gridmix with a high ram jobs trace by disabling the emulation of high ram  and verify each Gridmix job
whether it honors the high ram or not. In disable mode it should should not honor the high ram and run it as a normal
job.
"
MAPREDUCE-2562,NullPointerException in Jobtracker when it is started without Name Node,"It is throwing NullPointerException in job tracker logs when job tracker is started without NameNode.

{code:title=Bar.java|borderStyle=solid}
2011-06-03 01:50:04,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 7 time(s).
2011-06-03 01:50:05,307 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 8 time(s).
2011-06-03 01:50:06,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /10.18.52.225:9000. Already tried 9 time(s).
2011-06-03 01:50:21,243 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1635)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:287)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:279)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:274)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4312)
{code} "
MAPREDUCE-2561,Typo in a comment in TaskInProgress.java,"This JIRA is to track a fix to a super-trivial issue of a typo of ""receive"" misspelled as ""recieve"" in Line 563 of TaskInProgress.java.

"
MAPREDUCE-2559,ant binary fails due to missing c++ lib dir,"Post MAPRED-2521 ant binary fails without ""-Dcompile.c++=true -Dcompile.native=true"". The bin-package is trying to copy from the c++ lib dir which doesn't exist yet. The binary target should check for the existence of this dir or would also be reasonable to depend on the compile-c++ (since this is the binary target).
"
MAPREDUCE-2558,Add queue-level metrics 0.20-security branch,We would like to record and present the jobtracker metrics on a per-queue basis.
MAPREDUCE-2557,Counters don't reset state when readFields() called,"When calling readFields() on a Counters object, the internal state is not completely reset. The IdentityHashMap<Enum<?>, Counter> cache retains all previous mappings, even after the actual CounterGroups are changed. Using the same Counters pointer over and over again results in the cache always keeping the mapping for the first call to getCounter(Enum<?>). I've add a clear() call to the cache when readFields() is called and added a unit test to verify that it works."
MAPREDUCE-2556,MR 279: NodeStatus.getNodeHealthStatus().setBlah broken,
MAPREDUCE-2555,JvmInvalidate errors in the gridmix TT logs,"Observing a  lot of jvmValidate exceptions in TT logs for grid mix run



************************
2011-04-28 02:00:37,578 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 46121, call
statusUpdate(attempt_201104270735_5993_m_003305_0, org.apache.hadoop.mapred.MapTaskStatus@1840a9c,
org.apache.hadoop.mapred.JvmContext@1d4ab6b) from 127.0.0.1:50864: error: java.io.IOException: JvmValidate Failed.
Ignoring request from task: attempt_201104270735_5993_m_003305_0, with JvmId:
jvm_201104270735_5993_m_103399012gsbl20430: java.io.IOException: JvmValidate Failed. Ignoring request from task:
attempt_201104270735_5993_m_003305_0, with JvmId: jvm_201104270735_5993_m_103399012gsbl20430: --
      at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1386)
      at java.security.AccessController.doPrivileged(Native Method)
      at javax.security.auth.Subject.doAs(Subject.java:396)
      at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1059)
      at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1384)


*********************

"
MAPREDUCE-2554,Gridmix distributed cache emulation system tests.,"1.Verify the emulation of HDFS and Local FS distributed cache files against the given input trace file.
2.Verify the Gridmix emulation of HDFS distributed cache files of different visibilities.
3.Verify the Gridmix emulation of HDFS distributed cache file which uses different jobs that are submitted with different users.
4.Verify the emulation of local FS distributed cache files.
5.Verify the Gridmix emulation of HDFS private distributed cache file.
6.Verify the Gridmix emulation of HDFS public distributed cache file.
7.Verify the Gridmix emulation of Multiple HDFS private distributed cache files.
8.Verify the Gridmix emulation of Multiple HDFS public distributed cache files."
MAPREDUCE-2553,missing space in the error message of distcp command,"Error message of distcp command missing space, here's an example output:
$ hadoop distcp /user/test/input /user/test/ouput file:/root/temp
...
Copy failed: java.io.IOException: Failed to createfile:/root/temp
...

Generated from this line of source.

src/tools/org/apache/hadoop/tools/DistCp.java: throw new IOException(""Failed to create"" + args.dst);

""Failed to create"" should end with a ' '."
MAPREDUCE-2552,MR 279: NPE when requesting attemptids for completed jobs ,"While constructing a CompletedJob instance on the JobHistory server - successfuleAttempt is not populated. Causes an NPE when listing completed attempts for a job via the CLI.

CLI: hadoop job -list-attempt-ids <job_id> MAP completed"
MAPREDUCE-2551,MR 279: Implement JobSummaryLog,"Implement JobSummary log for MR.Next
"
MAPREDUCE-2550,bin/mapred no longer works from a source checkout,Developer may want to run hadoop without extracting tarball.  It would be nice if existing method to run mapred scripts from source code is preserved for developers.
MAPREDUCE-2549,"Potential resource leaks in HadoopServer.java, RunOnHadoopWizard.java and Environment.java",
MAPREDUCE-2548,Log improvements in DBOutputFormat.java and CounterGroup.java,"1. Instead of the printing the stack trace on the console, It can be logged. 


{code:title=DBOutputFormat.java|borderStyle=solid}
    
public void write(K key, V value) throws IOException {
      try {
        key.write(statement);
        statement.addBatch();
      } catch (SQLException e) {
        e.printStackTrace();
      }
    }
{code}


2. Missing resource information can be logged. 

{code:title=CounterGroup .java|borderStyle=solid}

protected CounterGroup(String name) {
    this.name = name;
    try {
      bundle = getResourceBundle(name);
    }
    catch (MissingResourceException neverMind) {
    }
    displayName = localize(""CounterGroupName"", name);
  }


  private String localize(String key, String defaultValue) {
    String result = defaultValue;
    if (bundle != null) {
      try {
        result = bundle.getString(key);
      }
      catch (MissingResourceException mre) {
      }
    }
    return result;
  }
{code}
    


"
MAPREDUCE-2547,TestDFSIO fails on a physical cluster,An attempt to run TestDSFIO on cluster fails because TestDFSIO tries to run MR job with local runner. If JT is explicitly specified via {{-jt}} cmd. arg. then everything is working as expected.
MAPREDUCE-2544,Gridmix compression emulation system tests.,"Develop system tests for the following cases.

1. Enable a compression emulation and generated the data using gridmix and verify whether compressed input generated or not.
2. Verify a Gridmix jobs map input, map output and reduce output compression ratios against the default compression ratios.
3. Verify a Gridmix jobs map input, map output and reduce output compression ratios against user specified compression ratios.
4. Verify a Gridmix jobs map input, map output compression ratios with file output compression format is false in original trace against default compression ratios.
5. Verify a Gridmix jobs map input, map output compression ratios with file output compression format is false in original trace against user specified compression ratios.
6. Verify a Gridmix jobs reduce output with file output compression format is true in original trace against the default compression ratios.
7. Verify a Gridmix jobs reduce output with file output compression format is true in original trace against the user specified compression ratios."
MAPREDUCE-2543,[Gridmix] Add support for HighRam jobs,Gridmix currently ignores high ram job configuration of the original job. It would be nice if Gridmix configures the simulated job's high ram parameters such that the simulated job has same effect on the job scheduler & task-tracker as the original job.
MAPREDUCE-2541,"Race Condition in IndexCache(readIndexFileToCache,removeMap) causes value of totalMemoryUsed corrupt, which may cause TaskTracker continue throw Exception","The race condition goes like this:
Thread1: readIndexFileToCache()  totalMemoryUsed.addAndGet(newInd.getSize())
Thread2: removeMap() totalMemoryUsed.addAndGet(-info.getSize());
When SpillRecord is being read from fileSystem, client kills the job, info.getSize() equals 0, so in fact totalMemoryUsed is not reduced, but after thread1 finished reading SpillRecord, it adds the real index size to totalMemoryUsed, which makes the value of totalMemoryUsed wrong(larger).
When this value(totalMemoryUsed) exceeds totalMemoryAllowed (this usually happens when a vary large job with vary large reduce number is killed by the user, probably because the user sets a wrong reduce number by mistake), and actually indexCache has not cache anything, freeIndexInformation() will throw exception constantly.

A quick fix for this issue is to make removeMap() do nothing, let freeIndexInformation() do this job only.
"
MAPREDUCE-2539,NPE when calling JobClient.getMapTaskReports for retired job,"When calling JobClient.getMapTaskReports for a retired job this results in a NPE.  In the 0.20.* version an empty TaskReport array was returned instead.

Caused by: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobClient.getMapTaskReports(JobClient.java:588)
        at org.apache.pig.tools.pigstats.JobStats.addMapReduceStatistics(JobStats.java:388)
......"
MAPREDUCE-2537,MR-279: The RM writes its log to yarn-mapred-resourcemanager-<RM_Host>.out,
MAPREDUCE-2536,TestMRCLI broke due to change in usage output,"One of the tests broke because it checks the FsShell mv usage line that is emitted after an error.  The usage was updated to from ""-mv <src> <dst>"" to ""-mv <src> ... <dst>"", so the ""..."" broke the test."
MAPREDUCE-2535,JobClient creates a RunningJob with null status and profile,"Exception occurred because the job was retired and is removed from RetireJobCcahe and CompletedJobStatusStore. But, the
JobClient creates a RunningJob with null status and profile, if getJob(JobID) is called again.
So, Even-though not null check is there in the following user code, it did not help.
466             runningJob = jobClient.getJob(mapRedJobID);
467             if(runningJob != null) {

JobClient.getJob() should return null if status is null.


In trunk this is fixed by validating that the job status is not null every time it is updated, and also verifying that that the profile data is not null when created."
MAPREDUCE-2534,MR-279: Fix CI breaking hard coded version in jobclient pom,
MAPREDUCE-2533,MR-279: Metrics for reserved resource in ResourceManager,Add metrics for reserved resources.
MAPREDUCE-2532,MR-279: Metrics for NodeManager,Metrics for node manager. Requires a recent (last night) update of hadoop common in the yahoo-merge branch. 
MAPREDUCE-2531,org.apache.hadoop.mapred.jobcontrol.getAssignedJobID throw class cast exception ,"When using a combination of the mapred and mapreduce APIs (PIG) it is possible to have the following exception

Caused by: java.lang.ClassCastException: org.apache.hadoop.mapreduce.JobID cannot be cast to
org.apache.hadoop.mapred.JobID
        at org.apache.hadoop.mapred.jobcontrol.Job.getAssignedJobID(Job.java:71)
        at org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:239)
        at org.apache.pig.PigServer.launchPlan(PigServer.java:1325)
        ... 29 more

This is because the JobID is just downcast.  It should be calling JobID.downgrade"
MAPREDUCE-2530, TaskTracker jetty stuck in a tight loop,"We are seeing some TaskTracker jetty servers stuck in a tight loop. This appears to be related to Jetty bug 937 (http://jira.codehaus.org/browse/JETTY-937). 

stack trace for this thread 15993(0x3e79) showing a loop in jetty.


""21006965@qtp-11400638-0 - Acceptor0 SelectChannelConnector@0.0.0.0:50060"" prio=10 tid=0x08e6d400 nid=0x3e79
runnable [0xaddfb000]
   java.lang.Thread.State: RUNNABLE
        at java.lang.Throwable.fillInStackTrace(Native Method)
        - locked <0xdf2708e8> (a java.io.IOException)
        at java.lang.Throwable.<init>(Throwable.java:196)
        at java.lang.Exception.<init>(Exception.java:41)
        at java.io.IOException.<init>(IOException.java:41)
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:210)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)
        - locked <0xb6524f58> (a sun.nio.ch.Util$1)
        - locked <0xb6524f68> (a java.util.Collections$UnmodifiableSet)
        - locked <0xb6400930> (a sun.nio.ch.EPollSelectorImpl)
        at sun.nio.ch.SelectorImpl.selectNow(SelectorImpl.java:88)
        at org.mortbay.io.nio.SelectorManager$SelectSet.doSelect(SelectorManager.java:652)
        at org.mortbay.io.nio.SelectorManager.doSelect(SelectorManager.java:192)
        at org.mortbay.jetty.nio.SelectChannelConnector.accept(SelectChannelConnector.java:124)
        at org.mortbay.jetty.AbstractConnector$Acceptor.run(AbstractConnector.java:708)
        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:582)"
MAPREDUCE-2529,Recognize Jetty bug 1342 and handle it,"We are seeing many instances of the Jetty-1342 (http://jira.codehaus.org/browse/JETTY-1342). The bug doesn't cause Jetty to stop responding altogether, some fetches go through but a lot of them throw exceptions and eventually fail. The only way we have found to get the TT out of this state is to restart the TT.  This jira is to catch this particular exception (or perhaps a configurable regex) and handle it in an automated way to either blacklist or shutdown the TT after seeing it a configurable number of them.
"
MAPREDUCE-2527,MR-279: Metrics for MRAppMaster,
MAPREDUCE-2525,"State of the checkboxes are not matching with Select All / Deselect All button, after refreshing jobtracker.jsp","These are the steps to reproduce,

# Select all the running jobs.
# Refresh the jobtracker.jsp page.
# After refreshing, *Deselect All* button becomes *Select All*, however all the selected check boxes remain in the select state only."
MAPREDUCE-2524,Backport trunk heuristics for failing maps when we get fetch failures retrieving map output during shuffle,"The heuristics for failing maps when we get map output fetch failures during the shuffle is pretty conservative in 20. Backport the heuristics from trunk which are more aggressive, simpler, and configurable.

"
MAPREDUCE-2523,TestTaskContext should cleanup its temporary files/folders on completion,"TestTaskContext creates ""in"" and ""out"" folders in the current working directory. Ideally these files should go under ""test.build.data"" or ""/tmp"". Also the testcase should delete these files on completion. "
MAPREDUCE-2522,MR 279: Security for JobHistory service,
MAPREDUCE-2521,Mapreduce RPM integration project,This jira is corresponding to HADOOP-6255 and associated directory layout change. The patch for creating Mapreduce rpm packaging should be posted here for patch test build to verify against mapreduce svn trunk.
MAPREDUCE-2520,InputSampler.RandomSampler only accepts Text keys,"I want to do a total sort on some data whose key type is Writable but not Text.  I wrote an InputSampler.RandomSampler object following the example in the ""Total Sort"" section of Hadoop: The Definitive Guide.  When I call InputSampler.writePartitionFile() I get a runtime class cast exception because my key type cannot be cast to Text.  Specifically the issue seems to be the following section of InputSampler.getSample():

    K key = reader.getCurrentKey();
    ....
    Text keyCopy = WritableUtils.<Text>clone((Text)key, job.getConfiguration());

You can only use a RandomSampler on data with Text keys despite the fact that InputSampler takes <Key, Value> generic parameters.

InputSampler.getSample() should be changed to cast the key to type K instead of type Text."
MAPREDUCE-2519,Progress reported by a reduce task executed via LocalJobRunner is incorrect,"ReduceTask splits its progress reporting into 3 phases
1. Copy
2. Shuffule
3. Reduce

When the reduce task is run using a LocalJobRunner, the copy phase is ignored (skipped) but the progress is not updated. This results in a mismatch in the Reduce task's progress."
MAPREDUCE-2518,missing t flag in distcp help message '-p[rbugp]',"'t: modification and access times' flag is defined but
missing in distcp help message '-p[rbugp]'. should be
changed to -p[rbugpt].
"
MAPREDUCE-2517,Porting Gridmix v3 system tests into trunk branch.,Porting of girdmix v3 system tests into trunk branch.
MAPREDUCE-2516,option to control sensitive web actions,"as per HADOOP-7302, webinterface.private.actions should not be in trunk. But it should be here, and should have a clearer name."
MAPREDUCE-2515,MapReduce references obsolete options,"Option topology.node.switch.mapping.impl has been renamed to net.topology.node.switch.mapping.impl; JT still uses old name. Likewise, JT uses old names for several other since-renamed options.
"
MAPREDUCE-2514,ReinitTrackerAction class name misspelled RenitTrackerAction in task tracker log,
MAPREDUCE-2513,Improvements in Job Tracker UI for monitoring and managing the map reduce jobs,"It will be helpful to the user/administrator if we provide following features in the Job Tracker UI 

1. User wants to get the list of jobs submitted with given state
2. User wants to kill a scheduled/running job through UI
3. User wants to change the priority of a job 
4. User wants to get the scheduling information of jobs
5. User wants to delete the logs of Jobs and tasks
6. Only authorized users to be able to perform the above operations through task management UI
7. Pagination support for the jobs listing


"
MAPREDUCE-2512,wait(5000) and notify() mechanism can be implemented instead of sleep(5000) in reduce task when there are no copies in progress and no new copies to schedule,"{code:title=ReduceTask.java|borderStyle=solid} 
       try { 
            if (numInFlight == 0 && numScheduled == 0) { 
              // we should indicate progress as we don't want TT to think 
              // we're stuck and kill us 
              reporter.progress(); 
              Thread.sleep(5000); 
            } 
          } catch (InterruptedException e) { } // IGNORE 
{code} 

Here if we have no copies in flight and we can't schedule anything new, it is going to wait for 5000 millis. Instead of waiting for 5000 millis, this thread can wait with timeout and GetMapEventsThread can notify it if gets new map completion events earlier than 5000 millis time. 
 
"
MAPREDUCE-2511,Progress reported by map tasks of a map-only job is incorrect,"For a map task of a map-reduce job, the progress bar is (logically) split into 2 distinct phases
1. Map Phase
2. Sort Phase

The map phase manages 66% of the overall tasks progress while the sort phase governs the rest i.e 33%. 

For a map task of a map-only job, there is no sort phase. Hence the entire map phase should govern 100% of the task's progress. Currently, the progress bar is split divided into 66%-33% irrespective of whether the job has reducers or not (i.e whether there is a sort phase or not)."
MAPREDUCE-2510,TaskTracker throw OutOfMemoryError after upgrade to jetty6,"Our product cluster's TaskTracker sometimes throw OutOfMemoryError after upgrade to jetty6. The exception in TT's log is as follows:
2011-05-17 19:16:40,756 ERROR org.mortbay.log: Error for /mapOutput

java.lang.OutOfMemoryError: Java heap space

        at java.io.BufferedInputStream.<init>(BufferedInputStream.java:178)

        at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:44)

        at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:176)

        at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:359)

        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:3040)

        at javax.servlet.http.HttpServlet.service(HttpServlet.java:707)

        at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)

        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)

        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)

        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)

        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)

        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)

        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)

        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)

        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)

        at org.mortbay.jetty.Server.handle(Server.java:324)

        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)

        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)

        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)

        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)

        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)

        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)

        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)

Exceptions in .out file:
java.lang.OutOfMemoryError: Java heap space

Exception in thread ""process reaper"" java.lang.OutOfMemoryError: Java heap space

Exception in thread ""pool-1-thread-1"" java.lang.OutOfMemoryError: Java heap space

java.lang.OutOfMemoryError: Java heap space

java.lang.reflect.InvocationTargetException

Exception in thread ""IPC Server handler 6 on 50050""     at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)

        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)

        at java.lang.reflect.Method.invoke(Method.java:597)

        at org.mortbay.log.Slf4jLog.warn(Slf4jLog.java:126)

        at org.mortbay.log.Log.warn(Log.java:181)

        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:449)

        at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)

        at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)

        at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)

        at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)

        at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)

        at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)

        at org.mortbay.jetty.Server.handle(Server.java:324)

        at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)

        at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)

        at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)

        at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)

        at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)

        at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)

        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)


"
MAPREDUCE-2509,MR-279: Fix NPE in UI for pending attempts,The task attempts page gets a 500 (and NPE in the AM logs) if the attempt is pending (not running yet).
MAPREDUCE-2508,vaidya script uses the wrong path for vaidya jar due to jar renaming,This clearly wasn't tested in 203.
MAPREDUCE-2507,vaidya script uses the wrong path for hadoop-core due to jar renaming,Another fallout of the incompatible jar renaming.  I sure hope Maven was worth it.
MAPREDUCE-2505,Explain how to use ACLs in the fair scheduler,"The fair scheduler already works with the ACL system introduced through the mapred.queue.* parameters, but the documentation doesn't explain how to use this. We should add a paragraph or two about it."
MAPREDUCE-2504,MR 279: race in JobHistoryEventHandler stop ,"The condition to stop the eventHandling thread currently requires it to be 'stopped' AND interrupted. If an interrupt arrives after a take, but before handleEvent is called - the interrupt status ends up being handled by hadoop.util.Shell.runCommand() - which ignores it (and in the process resets the flag).
The eventHandling thread subsequently hangs on eventQueue.take()
This currently randomly fails unit tests - and can hang MR AMs."
MAPREDUCE-2502,JobSubmitter should use mapreduce.job.maps,JobSubmitter should use {{mapreduce.job.maps}} instead of the deprecated {{mapred.map.tasks}}.
MAPREDUCE-2501,MR-279: Attach sources in builds,"Attach sources to builds for various reasons, one of which is better debuggability on clusters."
MAPREDUCE-2500,MR 279: PB factories are not thread safe,
MAPREDUCE-2499,MR part of HADOOP-7291,The hudson-test-patch target needs to be updated to not pass python.home since this argument is no longer needed.
MAPREDUCE-2498,TestRaidShellFsck failing on trunk,"TestRaidShellFsck.testFileBlockAndParityBlockMissingHar2 has been failing the last several builds:

Error Message: parity file not HARed after 40s

java.io.IOException: parity file not HARed after 40s
       at org.apache.hadoop.raid.TestRaidShellFsck.raidTestFiles(TestRaidShellFsck.java:281)
       at org.apache.hadoop.raid.TestRaidShellFsck.setUp(TestRaidShellFsck.java:181)
       at org.apache.hadoop.raid.TestRaidShellFsck.testFileBlockAndParityBlockMissingHar2(TestRaidShellFsck.java:666)
"
MAPREDUCE-2497,missing spaces in error messages,"Error message(s) are missing spaces.  Here's an example output:
  11/05/15 09:44:10 WARN mapred.JobClient: Error reading task outputhttp://
Generated from this line of source.

./src/mapred/org/apache/hadoop/mapred/JobClient.java:      LOG.warn(""Error reading task output"" + ioe.getMessage()); 

The 1st arg to LOG.warn should end with a ' '.

There may be other instances of this problem in the source base."
MAPREDUCE-2496,ivy: test conf should not extend common conf,Similar improvement as HADOOP-7289.
MAPREDUCE-2495,The distributed cache cleanup thread has no monitoring to check to see if it has died for some reason,"The cleanup thread in the distributed cache handles IOExceptions and the like correctly, but just to be a bit more defensive it would be good to monitor the thread, and check that it is still alive regularly, so that the distributed cache does not fill up the entire disk on the node. "
MAPREDUCE-2494,Make the distributed cache delete entires using LRU priority,"Currently the distributed cache will wait until a cache directory is above a preconfigured threshold.  At which point it will delete all entries that are not currently being used.  It seems like we would get far fewer cache misses if we kept some of them around, even when they are not being used.  We should add in a configurable percentage for a goal of how much of the cache should remain clear when not in use, and select objects to delete based off of how recently they were used, and possibly also how large they are/how difficult is it to download them again."
MAPREDUCE-2492,[MAPREDUCE] The new MapReduce API should make available task's progress to the task,There is no way to get the task's current progress in the new MapReduce API. It would be nice to make it available so that the task (map/reduce) can use it. 
MAPREDUCE-2490,Log blacklist debug count,Gain some insight into blacklist increments/decrements by enhancing the debug logging
MAPREDUCE-2489,Jobsplits with random hostnames can make the queue unusable,"We saw an issue where a custom InputSplit was returning invalid hostnames for the splits that were then causing the JobTracker to attempt to excessively resolve host names.  This caused a major slowdown for the JobTracker.  We should prevent invalid InputSplit hostnames from affecting everyone else.

I propose we implement some verification for the hostnames to try to ensure that we only do DNS lookups on valid hostnames (and fail otherwise).  We could also fail the job after a certain number of failures in the resolve."
MAPREDUCE-2487,ChainReducer uses MAPPER_BY_VALUE instead of REDUCER_BY_VALUE,"On line 293 of o.a.h.mapred.lib.Chain in setReducer(...):

reducerConf.setBoolean(MAPPER_BY_VALUE, byValue);

this should be REDUCER_BY_VALUE.

http://grepcode.com/file/repository.cloudera.com/content/repositories/releases/com.cloudera.hadoop/hadoop-core/0.20.2-737/org/apache/hadoop/mapred/lib/Chain.java#293"
MAPREDUCE-2486,0.22 - snapshot incorrect dependency published in .pom files,"The pom at https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-mapred/0.22.0-SNAPSHOT/ publishes a dependency on hadoop-common version ""0.22.0-dev-SNAPSHOT"" while hadoop-common only publishes ""0.22.0-SNAPSHOT"" (no -dev)."
MAPREDUCE-2485,reinitialize CLASSPATH variable when executing Mapper/Reducer code,"We're using pipes, and using libhdfs inside our mapper and reducer code.  We've determined that we need to execute a putenv call in order for libhdfs to actually have access to the CLASSPATH.  Ideally, it should just use the CLASSPATH we set when the job was executed.

For some more context, see these threads:
https://groups.google.com/a/cloudera.org/group/cdh-user/browse_thread/thread/ae9808d80fb132fb?tvc=2
http://comments.gmane.org/gmane.comp.jakarta.lucene.hadoop.user/25830

"
MAPREDUCE-2484,divideAndCeil should not use LOG.info or have a more meaningful message,"divideAndCeil has 

{code}
        LOG.info(""divideAndCeil called with a="" + a + "" b="" + b);
{code}

which should either be a debug message or something more meaningful if it really needs to be LOG.info."
MAPREDUCE-2483,Clean up duplication of dependent jar files,"For trunk, the build and deployment tree look like this:

hadoop-common-0.2x.y
hadoop-hdfs-0.2x.y
hadoop-mapred-0.2x.y

Technically, mapred's the third party dependent jar files should be fetch from hadoop-common and hadoop-hdfs.  However, it is currently fetching from hadoop-mapred/lib only.  It would be nice to eliminate the need to repeat duplicated jar files at build time.

There are two options to manage this dependency list, continue to enhance ant build structure to fetch and filter jar file dependencies using ivy.  On the other hand, it would be a good opportunity to convert the build structure to maven, and use maven to manage the provided jar files."
MAPREDUCE-2482,Enable RAID contrib in trunk,The RAID contrib project can be re-enabled since federation related changes are now in.
MAPREDUCE-2480,MR-279: mr app should not depend on hard-coded version of shuffle,"The following commit introduced a dependency of shuffle with hard-coded version for mr app:
{noformat}
commit 6f69742140516be7493c9a9177b81d0516cc9539
Author: Vinod Kumar Vavilapalli <vinodkv@apache.org>
Date:   Wed May 4 06:53:52 2011 +0000

    Adding user log handling for YARN. Making NM put the user-logs on DFS and providing log-dump tools. Contributed by Vinod Kumar Vavilapalli.
{noformat}"
MAPREDUCE-2479,Backport MAPREDUCE-1568 to hadoop security branch,
MAPREDUCE-2478,MR 279: Improve history server,"Index based jobId search in the history server.
Faster jobList loading."
MAPREDUCE-2476,Set mapreduce scheduler to capacity scheduler for RPM/Debian packages by default,Hadoop RPM/Debian package is default to use the default scheduler.  It would be nice to setup the packages to use capacity scheduler instead.
MAPREDUCE-2475,Disable IPV6 for junit tests,"IPV6 addresses not handles currently in the common library methods. IPV6 can return address as ""0:0:0:0:0:0:port"". Some utility methods such as NetUtils#createSocketAddress(), NetUtils#normalizeHostName(), NetUtils#getHostNameOfIp() to name a few, do not handle IPV6 address and expect address to be of format host:port.

Until IPV6 is formally supported, I propose disabling IPV6 for junit tests to avoid problems seen in HDFS-1891.
"
MAPREDUCE-2474,Add docs to the new API Partitioner on how to access Job Configuration data,"The new Partitioner interface does not extend Configurable classes as the old one and thus need to carry a tip on how to implement a custom partitioner that needs to feed off the Job Configuration data to work.

Attaching a patch that adds in the javadoc fix."
MAPREDUCE-2473,MR portion of HADOOP-7214 - Hadoop /usr/bin/groups equivalent,
MAPREDUCE-2472,Extra whitespace in mapred.child.java.opts breaks JVM initialization,"When creating taskjvm.sh, we split mapred.child.java.opts on "" "" and then create a quoted argument for each of those results. So, if you have an extra space anywhere in this configuration, you get an argument '' in the child command line, which the JVM interprets as an empty class name. This results in a ClassNotFoundException and the task cannot run."
MAPREDUCE-2470,Receiving NPE occasionally on RunningJob.getCounters() call,"This is running in a Java daemon that is used as an interface (Thrift) to get information and data from MR Jobs. Using JobClient.getJob(JobID) I successfully get a RunningJob object (I'm checking for NULL), and then rarely I get an NPE when I do RunningJob.getCounters(). This seems to occur after the daemon has been up and running for a while, and in the event of an Exception, I close the JobClient, set it to NULL, and a new one should then be created on the next request for data. Yet, I still seem to be unable to fetch the Counters. Below is the stack trace.


java.lang.NullPointerException
            at org.apache.hadoop.mapred.Counters.downgrade(Counters.java:77)
            at org.apache.hadoop.mapred.JobClient$NetworkedJob.getCounters(JobClient.java:381)
            at com.telescope.HadoopThrift.service.ServiceImpl.getReportResults(ServiceImpl.java:350)
            at com.telescope.HadoopThrift.gen.HadoopThrift$Processor$getReportResults.process(HadoopThrift.java:545)
            at com.telescope.HadoopThrift.gen.HadoopThrift$Processor.process(HadoopThrift.java:421)
            at org.apache.thrift.server.TNonblockingServer$FrameBuffer.invoke(TNonblockingServer.java:697)
            at org.apache.thrift.server.THsHaServer$Invocation.run(THsHaServer.java:317)
            at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
            at java.lang.Thread.run(Thread.java:619)
"
MAPREDUCE-2469,Task counters should also report the total heap usage of the task,"Currently, the task counters report VSS and RSS usage of the task. The task counter should also report the total heap usage of the task also. The task might be configured with a max heap size of M but the task's total heap usage might only be H, where H < M. In such a case, knowing only M doesn't provide a complete picture of the task's memory usage.  "
MAPREDUCE-2468,MR-279: Metrics for shuffle,Metrics for MR shuffle service.
MAPREDUCE-2467,HDFS-1052 changes break the raid contrib module in MapReduce,Raid contrib module requires changes to work with the federation changes made in HDFS-1052.
MAPREDUCE-2466,TestFileInputFormat.testLocality failing after federation merge,"This test is failing, I believe due to federation merge. It's only finding one location for the test file instead of the expected two."
MAPREDUCE-2465,HDFS raid not compiling after federation merge,"The RAID contrib is no longer compiling now that federation has been merged, due to some API changes in LocatedBlock and FSDataset."
MAPREDUCE-2464,NullPointerException is coming in the job tracker when job tracker resends the previous heartbeat response.,"Over the network, the heartbeat response sent by Job Tracker to Task Tracker might get lost. When Task Tracker sends the old heart beat again to Job Tracker then Job Tracker finds and ignores it saying duplicate and resends the old heartbeat response which it is maintaining in a map. If the response contains LaunchTaskAction for MapTask, then the NullPointerException is throwing.

{code:xml} 
2011-05-02 16:01:53,148 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9001 caught: java.lang.NullPointerException
	at org.apache.hadoop.mapred.MapTask.write(MapTask.java:140)
	at org.apache.hadoop.mapred.LaunchTaskAction.write(LaunchTaskAction.java:48)
	at org.apache.hadoop.mapred.HeartbeatResponse.write(HeartbeatResponse.java:91)
	at org.apache.hadoop.io.ObjectWritable.writeObject(ObjectWritable.java:163)
	at org.apache.hadoop.io.ObjectWritable.write(ObjectWritable.java:74)
	at org.apache.hadoop.ipc.Server.setupResponse(Server.java:1561)
	at org.apache.hadoop.ipc.Server.access$2800(Server.java:96)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1433)
{code} "
MAPREDUCE-2463,Job History files are not moving to done folder when job history location is hdfs location,"If ""mapreduce.jobtracker.jobhistory.location"" is configured as HDFS location then either during initialization of Job Tracker (while moving old job history files) or after completion of the job, history files are not moving to done and giving following exception.

{code:xml} 
2011-04-29 15:27:27,813 ERROR org.apache.hadoop.mapreduce.jobhistory.JobHistory: Unable to move history file to DONE folder.
java.lang.IllegalArgumentException: Wrong FS: hdfs://10.18.52.146:9000/history/job_201104291518_0001_root, expected: file:///
	at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:402)
	at org.apache.hadoop.fs.RawLocalFileSystem.pathToFile(RawLocalFileSystem.java:58)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:419)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:294)
	at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:215)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1516)
	at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1492)
	at org.apache.hadoop.fs.FileSystem.moveFromLocalFile(FileSystem.java:1482)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.moveToDoneNow(JobHistory.java:348)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.access$200(JobHistory.java:61)
	at org.apache.hadoop.mapreduce.jobhistory.JobHistory$1.run(JobHistory.java:439)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)

{code} 
"
MAPREDUCE-2462,"MR 279: Write job conf along with JobHistory, other minor improvements","Write the job xml along with the job history file. Split some common functionality into a helper class, etc."
MAPREDUCE-2461,Hudson jobs failing because mapred staging directory is full,"All of the tests that submit MR jobs are failing on the h7 build machine. This is because the staging directory is entirely full:

hudson@h7:/tmp/mr/mr$ ls -l /tmp/hadoop-hudson/mapred/staging/ | wc -l
31999

This makes me think that there's some bug where we're leaking things in the staging directory. I will manually clean this for now, but we should investigate."
MAPREDUCE-2460,TestFairSchedulerSystem failing on Hudson,Seems to have been failing for a while. For example: https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/655/testReport/junit/org.apache.hadoop.mapred/TestFairSchedulerSystem/testFairSchedulerSystem/
MAPREDUCE-2459,Cache HAR filesystem metadata,"Each HAR file system has two index files that contains information on how files are stored in the part files. During the block location calculation, these indexes are reread for every file in the archive. Caching the indexes and the status of the part files will greatly reduce the number of name node operations during the job setup time."
MAPREDUCE-2458,MR-279: Rename sanitized pom.xml in build directory to work around IDE bug,The sanitized pom.xml in target directory apparently triggered a bug in NetBeans (http://netbeans.org/bugzilla/show_bug.cgi?id=198162) causing it to fail to recognize the generated sources. The work-around is to rename the generated pom.xml to saner-pom.xml
MAPREDUCE-2457,job submission should inject group.name (on the JT side),"Until Hadoop 0.20, the JobClient was injecting the property 'group.name' on the JobConf submitted to the JobTracker.

Since Hadoop 0.21, due to security related changes, this is not done anymore.

This breaks backwards compatibility for jobs/components that expect the 'group.name' to be automatically set at submission time.

An example of a component being affected by this change is the FairScheduler where it is common to use the group.name as pool name. Different from other properties, a special characteristic of the group.name is that its value cannot be tampered by a user.

For security reasons this should not be done (as it was done before) in the JobClient side. Instead, it should be done in the JobTracker when the JobConf is received.
"
MAPREDUCE-2456,"Show the reducer taskid and map/reduce tasktrackers for ""Failed fetch notification #_ for task attempt..."" log messages","This jira is to provide more useful log information for debugging the ""Too many fetch-failures"" error.

Looking at the JobTracker node, we see messages like this:
""2010-12-14 00:00:06,911 INFO org.apache.hadoop.mapred.JobInProgress: Failed fetch notification #8 for task
attempt_201011300729_189729_m_007458_0"".

I would be useful to see which reducer is reporting the error here.

So, I propose we add the following to these log messages:
  1. reduce task ID
  2. TaskTracker nodenames for both the mapper and the reducer
"
MAPREDUCE-2455,Remove deprecated JobTracker.State in favour of JobTrackerStatus,"MAPREDUCE-2337 deprecated getJobTrackerState() on ClusterStatus, this issue is to remove the getter (in favour of getJobTrackerStatus(), which will remain) so there is no longer a direct dependency of the public API on JobTracker. This is for MAPREDUCE-1638."
MAPREDUCE-2454,Allow external sorter plugin for MR,Define interfaces and some abstract classes in the Hadoop framework to facilitate external sorter plugins both on the Map and Reduce sides.
MAPREDUCE-2452,Delegation token cancellation shouldn't hold global JobTracker lock,"Currently, when the JobTracker cancels a job's delegation token (at the end of the job), it holds the global lock. This is not desired."
MAPREDUCE-2451,Log the reason string of healthcheck script,The information on why a specific TaskTracker got blacklisted is not stored anywhere. The jobtracker web ui will show the detailed reason string until the TT gets unblacklisted.  After that it is lost.
MAPREDUCE-2450,Calls from running tasks to TaskTracker methods sometimes fail and incur a 60s timeout,"I'm seeing some map tasks in my jobs take 1 minute to commit after they finish the map computation. On the map side, the output looks like this:

<code>
2009-03-02 21:30:54,384 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=MAP, sessionId= - already initialized
2009-03-02 21:30:54,437 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 800
2009-03-02 21:30:54,437 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 300
2009-03-02 21:30:55,493 INFO org.apache.hadoop.mapred.MapTask: data buffer = 239075328/298844160
2009-03-02 21:30:55,494 INFO org.apache.hadoop.mapred.MapTask: record buffer = 786432/983040
2009-03-02 21:31:00,381 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2009-03-02 21:31:07,892 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2009-03-02 21:31:07,951 INFO org.apache.hadoop.mapred.TaskRunner: Task:attempt_200903022127_0001_m_003163_0 is done. And is in the process of commiting
2009-03-02 21:32:07,949 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.io.IOException: Call to /127.0.0.1:50311 failed on local exception: java.nio.channels.ClosedChannelException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:733)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at org.apache.hadoop.mapred.$Proxy0.ping(Unknown Source)
	at org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:525)
	at java.lang.Thread.run(Thread.java:619)
Caused by: java.nio.channels.ClosedChannelException
	at java.nio.channels.spi.AbstractSelectableChannel.register(AbstractSelectableChannel.java:167)
	at java.nio.channels.SelectableChannel.register(SelectableChannel.java:254)
	at org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:331)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:155)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:128)
	at java.io.FilterInputStream.read(FilterInputStream.java:116)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:276)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:237)
	at java.io.DataInputStream.readInt(DataInputStream.java:370)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)

2009-03-02 21:32:07,953 INFO org.apache.hadoop.mapred.TaskRunner: Task 'attempt_200903022127_0001_m_003163_0' done.
</code>

In the TaskTracker log, it looks like this:

<code>
2009-03-02 21:31:08,110 WARN org.apache.hadoop.ipc.Server: IPC Server Responder, call ping(attempt_200903022127_0001_m_003163_0) from 127.0.0.1:56884: output error
2009-03-02 21:31:08,111 INFO org.apache.hadoop.ipc.Server: IPC Server handler 10 on 50311 caught: java.nio.channels.ClosedChannelException
    at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:126)
    at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:324)    at org.apache.hadoop.ipc.Server.channelWrite(Server.java:1195)
    at org.apache.hadoop.ipc.Server.access$1900(Server.java:77)
    at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:613)
    at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:677)
    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:981)
</code>

Note that the task actually seemed to commit - it didn't get speculatively executed or anything. However, the job wasn't able to continue until this one task was done. Both parties seem to think the channel was closed. How does the channel get closed externally? If closing it from outside is unavoidable, maybe the right thing to do is to set a much lower timeout, because 1 minute delay can be pretty significant for a small job."
MAPREDUCE-2449,"Allow for command line arguments when performing ""Run on Hadoop"" action.","It is currently not possible to specify command line arguments when creating a run configuration for ""Run on Hadoop."" This patch adds a text box to the RunOnHadoopWizard dialog for providing command line arguments. The arguments are then stored as part of the run configuration. Additionally (as a result), this patch prevents the creation of duplicate run configuration creation by seeing if the original configuration has been changed first."
MAPREDUCE-2448,NoSuchMethodError: org.apache.hadoop.hdfs.TestDatanodeBlockScanner.corruptReplica(..),"{noformat}
java.lang.NoSuchMethodError: org.apache.hadoop.hdfs.TestDatanodeBlockScanner.corruptReplica(Ljava/lang/String;I)Z
	at org.apache.hadoop.raid.TestBlockFixer.corruptBlock(TestBlockFixer.java:643)
	at org.apache.hadoop.raid.TestBlockFixer.implBlockFix(TestBlockFixer.java:189)
	at org.apache.hadoop.raid.TestBlockFixer.testBlockFixLocal(TestBlockFixer.java:139)
{noformat}"
MAPREDUCE-2447,Set JvmContext sooner for a task - MR2429,"TaskTracker.validateJVM() is throwing NPE when setupWorkDir() throws IOException. This is because
taskFinal.setJvmContext() is not executed yet"
MAPREDUCE-2446,HCE 2.0,"Enhancing MapReduce by Task-level Optimization. Except for yielding speedups of up to 130% on original Streaming Program, Hce 2.0 provides some more flexible programming interfaces including c++, java, python, etc."
MAPREDUCE-2445,TestMiniMRWithDFSWithDistinctUsers is very broken,"This test has a number of issues:
- it side steps the normal job submission API for no apparent reason, manually writing splits file and uploading submission files. (but forgets to upload the job jar, so the jobs all fail)
- it doesn't call waitForCompletion, or check job status (so it doesn't notice that the jobs all fail)
- it doesn't verify in any way that the job output is owned by the user who supposedly ran the job
- it shuts down DFS before MR

These all conspire to make it pass, but it isn't actually testing anything."
MAPREDUCE-2444,error connect tasktracker for jobtracker,"In TaskTracker.java on create connection to JobTracker we check compare build version

if(!VersionInfo.getBuildVersion().equals(jobTrackerBV)) 

but

public static String getBuildVersion(){
    return VersionInfo.getVersion() +
    "" from "" + VersionInfo.getRevision() +
    "" by "" + VersionInfo.getUser() +
    "" source checksum "" + VersionInfo.getSrcChecksum();
}

in result identical version/revision/srcChecksum but compiled different users incompatible
"
MAPREDUCE-2443,Fix FI build - broken after MR-2429,"src/test/system/aop/org/apache/hadoop/mapred/TaskAspect.aj:72 [warning] advice defined in org.apache.hadoop.mapred.TaskAspect has not been applied [Xlint:adviceDidNotMatch]

After the fix in MR-2429, the call to ping in TaskAspect needs to be fixed."
MAPREDUCE-2442,Add a JSP page for RaidNode,
MAPREDUCE-2441,regression: maximum limit of -1 + user-lmit math appears to be off,The math around the slot usage when maximum-capacity=-1 appears to be faulty.  See comments.
MAPREDUCE-2440,MR-279: Name clashes in TypeConverter,"public static TaskTrackerInfo[] fromYarn(List<NodeManagerInfo> nodes) has the same erasure as
public static JobStatus[] fromYarn(List<Application> applications)

Not detected by the current JDK 6 but still wrong according to the JLS 8.4.2.

See also: http://bugs.sun.com/view_bug.do?bug_id=6182950

The patch renames the former signature to fromYarnNodes and the later fromYarnApps."
MAPREDUCE-2439,MR-279: Fix YarnRemoteException to give more details.,Fix YarnRemoteException to add more details.
MAPREDUCE-2438,MR-279: WebApp for Job History,Add webapp for job history server in MR-279 branch.
MAPREDUCE-2437,SLive should process only part* files while generating the report.,SliveTest when producing the final report scans all files in the reduce output directory. The directory now may contain {{_SUCCESS}} and {{_logs}} entries. SliveTest should process only files starting with {{part*}}.
MAPREDUCE-2436,RAID block fixer should prioritize block fix operations,"The RAID block fixer submits mapreduce jobs to fix corrupt files. This is OK for XOR RAID, but with Reed-Solomon RAID, there can be large number of corrupt files when even a single datanode goes dead. With Reed-SOlomon RAID, it is better to categorize corrupt files based on urgency. Files with only one corrupt block can be treated as lower priority than those with more number of corrupt blocks."
MAPREDUCE-2434,MR-279: ResourceManager metrics,"Hierarchical scheduler metrics, per queue, per user (default off)"
MAPREDUCE-2433,MR-279: YARNApplicationConstants hard code app master jar version,"YARNApplicationConstants hard code version string in HADOOP_MAPREDUCE_CLIENT_APP_JAR_NAME and consequently YARN_MAPREDUCE_APP_JAR_PATH

This is a blocker."
MAPREDUCE-2432,MR-279: Install sanitized poms for downstream sanity,"Due to [MNG-4223|http://jira.codehaus.org/browse/MNG-4223], the installed POMs of MR-279 is downstream hostile. E.g., it's impossible to use versions of hadoop-mapreduce-client-core.version in ivy other than 1.0-SNAPSHOT without changing the multiple POMs, rendering the version properties (hadoop-mapreduce.version and yarn.version) practically useless.

This patch will install POMs with version (only) properties expanded. This patch also use inheritance and dependencyManagement to make POMs DRYer. It could use further cleanup to reduce ""unnecessary"" dependencies in some modules, but it's a working start.

To see the patch work, apply the patch and do a mvn clean install -P-cbuild -DskipTests to make sure sane POMs are installed and then working on individual test issues."
MAPREDUCE-2430,Remove mrunit contrib,"As per vote on general@ (http://mail-archives.apache.org/mod_mbox/hadoop-general/201102.mbox/%3C77405974-6771-4604-926B-976240743F3C@mac.com%3E) mrunit contrib can now be removed from contrib since it's code has been moved to the incubator: 
  svn remove mapreduce/trunk/src/contrib/mrunit
A link to the incubator project should be added to our website ""related projects"" section.
"
MAPREDUCE-2429,Check jvmid during task status report,Currently TT doens't check to ensure jvmid is relevant during communication with the Child via TaskUmbilicalProtocol.
MAPREDUCE-2428,start-mapred.sh script fails if HADOOP_HOME is not set,MapReduce portion of HADOOP-6953
MAPREDUCE-2427,JT should ensure history directory is a directory,If the JT history directory doesn't exist or isn't a directory retired job files are renamed to a file called 'history' and eventually start overwriting each other. The JT should ensure 'history' exists and is a directory before performing the move.
MAPREDUCE-2426,Make TestFairSchedulerSystem fail with more verbose output,"The TestFairSchedulerSystem test failed here: https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/644/testReport/junit/org.apache.hadoop.mapred/TestFairSchedulerSystem/testFairSchedulerSystem/

with a failed assertion {{assertTrue(contents.contains(""</svg>""));}}. We should make the assertion failure include the value of {{contents}}
"
MAPREDUCE-2425,Distributed simulator for stressing JobTracker and NameNode,"Hadoop need a tool for stressing JobTracker and NameNode. Mumak introduced a simulated JobTracker, whose behavior doesn't exactly like that of the real JobTracker. Even more, mumak can't simulate a large cluster with quite a lot of jobs run on it. On the other hand, Gridmix v3 need hundreds of physical nodes to replay job stories. 

You can think this tool a complementation of mumak and gridmix v3. We successfully used this tool to simulate a 12000 nodes cluster through 4 real machines. 
I've talk to Hong Tang and Scott Chen offline, they suggested me contributing this tool to the hadoop community."
MAPREDUCE-2424,MR-279: counters/UI/etc. for uber-AppMaster (in-cluster LocalJobRunner for MRv2),"Polish uber-AM (MAPREDUCE-2405).  Specifically:
* uber-specific counters (""command-line UI"")
* GUI indicators
** RM all-containers level
** multi-job app level [if exists]
** single-job level
* fix uber-decision (""is this a small job?""):
** memory criterion
** input-bytes criterion
* disable speculation
* isUber() method (somewhere) for unit tests to use
* delete (most of) old UberTask code (MAPREDUCE-1220; came in with initial MR-279 branch)
* implement non-RPC, local version of umbilical
* AM restart (default 4 tries) on another node on any task-attempt failure
* uber-specific metrics?
* rename configurables? (still ""ubertask""-based)
"
MAPREDUCE-2423,Monitoring the job tracker ui of hadoop using other open source monitoring tools like Nagios,I just wish if there is a way I can write monitors to check my hadoop job tracker UI using my existing Nagios infrastructure. As this would help me in keeping everything centrally located and hence under manageable limits.
MAPREDUCE-2422,Removed unused internal methods from DistributedCache,"DistributedCache has a number of deprecated methods that are no longer used ever since TrackerDistributedCacheManager was introduced in MAPREDUCE-476. Removing these methods (which are not user-facing) will make it possible to complete MAPREDUCE-1638 by keeping DistributedCache in the API tree, and TrackerDistributedCacheManager, TaskDistributedCacheManager in the implementation tree."
MAPREDUCE-2420,JobTracker should be able to renew delegation token over HTTP,"in case JobTracker has to talk to a NameNode running a different version (RPC version mismatch), Jobtracker should be able to fall back to HTTP renewal.

Example of the case - running distcp between different versions using hfpt."
MAPREDUCE-2418,Errors not shown in the JobHistory servlet (specifically Counter Limit Exceeded),"Job error details are not displayed in the JobHistory servlet. e.g. Errors like 'Counter limit exceeded for a job'. 
jobdetails.jsp has 'Failure Info', but this is missing in jobdetailshistory.jsp"
MAPREDUCE-2417,"In Gridmix, in RoundRobinUserResolver mode, the testing/proxy users are not associated with unique users in a trace","As per the Gridmix documentation, the testing users should associate with unique user in the trace. However, currently the gridmix impersonate the users based on job irrespective of user."
MAPREDUCE-2416,"In Gridmix, in RoundRobinUserResolver, the list of groups for a user obtained from users-list-file is incorrect","RoundRobinUserResolver.parseUserList() has a bug in obtaining list of groups for each user --- in the sense that the list is not cleared before obtaining groups list for the next user. So if the first line has some groups, then from 2nd
line onwards, the validation of ""whether the users(in the next lines) are also having group names in those lines"" is useless as the list is already nonempty.

For example, users-list-file content as shown below also is valid as per parseUserList():
------------------
user1,group1
user2,
user3,
user4,
------------------"
MAPREDUCE-2415,Distribute TaskTracker userlogs onto multiple disks,"Currently, userlogs directory in TaskTracker is placed under hadoop.log.dir like <hadoop.log.dir>/userlogs. I am proposing to spread these userlogs onto multiple configured mapred.local.dirs to strengthen TaskTracker reliability w.r.t disk failures.  "
MAPREDUCE-2414,MR-279: Use generic interfaces for protocols,Use generic interfaces for protocols for MAPREDUCE-279.
MAPREDUCE-2413,TaskTracker should handle disk failures at both startup and runtime,"At present, TaskTracker doesn't handle disk failures properly both at startup and runtime.

(1) Currently TaskTracker doesn't come up if any of the mapred-local-dirs is on a bad disk. TaskTracker should ignore that particular mapred-local-dir and start up and use only the remaining good mapred-local-dirs.
(2) If a disk goes bad while TaskTracker is running, currently TaskTracker doesn't do anything special. This results in either
   (a) TaskTracker continues to ""try to use that bad disk"" and this results in lots of task failures and possibly job failures(because of multiple TTs having bad disks) and eventually these TTs getting graylisted for all jobs. And this needs manual restart of TT with modified configuration of mapred-local-dirs avoiding the bad disk. OR
   (b) Health check script identifying the disk as bad and the TT gets blacklisted. And this also needs manual restart of TT with modified configuration of mapred-local-dirs avoiding the bad disk.

This JIRA is to make TaskTracker more fault-tolerant to disk failures solving (1) and (2). i.e. TT should start even if at least one of the mapred-local-dirs is on a good disk and TT should adjust its in-memory list of mapred-local-dirs and avoid using bad mapred-local-dirs.
"
MAPREDUCE-2412,"When you submit a job on a non-existent queue, you get an opaque NPE",
MAPREDUCE-2411,When you submit a job to a queue with no ACLs you get an inscrutible NPE,"With this patch we'll check for that, and print a message in the logs.  Then at submission time you find out about it."
MAPREDUCE-2410,document multiple keys per reducer oddity in hadoop streaming FAQ,"Hi,
for a newcomer to hadoop streaming, it comes as a surprise that the reducer receives arbitrary keys, unlike the ""real"" hadoop where a reducer works on a single key.
An explanation for this is @ http://mail-archives.apache.org/mod_mbox/hadoop-common-user/201103.mbox/browser

I suggest to add this to the FAQ of hadoop streaming"
MAPREDUCE-2409,Distributed Cache does not differentiate between file /archive for files with the same path,"If a 'global' file is specified as a 'file' by one job - subsequent jobs cannot override this source file to be an 'archive' (until the TT cleans up it's cache or a TT restart).
The other way around as well -> 'archive' to 'file'

In case of an accidental submission using the wrong type - some of the tasks for the second job will end up seeing the source file as an archive, others as a file."
MAPREDUCE-2408,Make Gridmix emulate usage of data compression,Currently Gridmix emulates disk IO load only. This JIRA is to make Gridmix emulate load due to data compression as defined by the job-trace.
MAPREDUCE-2407,Make Gridmix emulate usage of Distributed Cache files,Currently Gridmix emulates disk IO load only. This JIRA is to make Gridmix emulate Distributed Cache load as defined by the job-trace.
MAPREDUCE-2405,MR-279: Implement uber-AppMaster (in-cluster LocalJobRunner for MRv2),"""Port"" MAPREDUCE-1220 to MRv2.  This is an optimization for small jobs wherein all tasks run on the same node in the same JVM/container."
MAPREDUCE-2403,MR-279: Improve job history event handling in AM to log to HDFS,Improve the job history event handling in the application master to log to HDFS in the staging directory for the job and also move it to the required location for the job history server to use.
MAPREDUCE-2400,Remove Cluster's dependency on JobTracker,Introduce a factory using ServiceLoader to remove the direct dependency.
MAPREDUCE-2399,The embedded web framework for MAPREDUCE-279,Discuss the web framework which is a part of MAPREDUCE-279.
MAPREDUCE-2398,MRBench: setting the baseDir parameter has no effect,"The optional {{-baseDir}} parameter lets user specify the base DFS path for output/input of MRBench.

However, the two private variables {{INPUT_DIR}} and {{OUTPUT_DIR}} (MRBench.java) are not updated in the case that the default value of  {{-baseDir}} is actually overwritten by the user. Hence any input and output is always written to the default locations ({{/benchmarks/MRBench/...}}), even though the user-supplied location for {{-baseDir}} is created (and eventually deleted again) on HDFS.

The bug affects at least Hadoop 0.20.2 and the current trunk (r1082703) as of March 21, 2011."
MAPREDUCE-2397,"Allow user to sort jobs in different sections (Completed, Failed, etc.) by the various columns available",It would be nice (IMHO) to be able to sort the tables on the jobtracker.jsp page by any column (jobID would be most logical at first) so that one could eliminate scrolling all of the time.  Perhaps also have the page save the user's sorting preferences per table too.
MAPREDUCE-2395,TestBlockFixer timing out on trunk,"In recent Hudson builds, TestBlockFixer has been timing out. Not clear how long it has been broken since MAPREDUCE-2394 was hiding the RAID tests from Hudson's test result parsing."
MAPREDUCE-2394,JUnit output format doesn't propagate into some contrib builds,"Some of the contribs seem to have an issue where the test.junit.output.format property isn't propagating down into their builds. So, Hudson is unable to parse the test output, and we see failed builds with no actual parsed test results showing what failed.

This is at least true for {{contrib/raid}} but maybe others as well."
MAPREDUCE-2393,No total min share limitation of all pools,"hi, there is no limitation about min share of all pools with cluster total shares. User can define arbitrary amount of min share for each pool. It has such description in <fair scheduler design document>, but no regular code. 
It may critical for slot distribution. One pool can hold all cluster slots to meet it's min share that greater than cluster total slots very much.
If that case has happened, we should scaled down proportionally.
"
MAPREDUCE-2392,TaskTracker shutdown in the tests sometimes take 60s,"There are a lot of the following in the test logs:

{noformat}
2011-03-16 13:47:02,267 INFO  mapred.TaskTracker (TaskTracker.java:shutdown(1275)) - Shutting down StatusHttpServer
2011-03-16 13:48:02,349 ERROR mapred.TaskTracker (TaskTracker.java:offerService(1609)) - Caught exception: java.io.IOException: Call to localhost/127.0.0.1:57512 failed on local exception: java.nio.channels.ClosedByInterruptException
{noformat}

Note there is over one minute between the first line and the second."
MAPREDUCE-2390,JobTracker and TaskTrackers fail with a misleading error if one of the mapreduce.cluster.dir has unusable permissions / is unavailable.,"To reproduce, have a mapred.local.dir property set to a few directories. Before starting up the JT, set one of these directories' permission as 'd---------', and then start the JT/TT. The JT, although it tries to ignore this directory, fails with an odd and misleading message claiming that its configured address in use.

Fixing the permission clears this issue!

This was also reported in the mailing lists by Ted Yu, quite a few months ago. But I had forgotten about filing a bug for it here. Still seems to happen. A log is attached below.

{code}
2011-03-17 00:40:32,321 WARN org.apache.hadoop.mapred.JobTracker: Error starting tracker: java.io.IOException: Cannot create toBeDeleted in /home/hack/.tmplocalz/2
        at org.apache.hadoop.util.MRAsyncDiskService.<init>(MRAsyncDiskService.java:86)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2189)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2022)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:276)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:268)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4712)

2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2011-03-17 00:40:33,322 INFO org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager: Updating the current master key for generating delegation tokens
2011-03-17 00:40:33,322 INFO org.apache.hadoop.mapred.JobTracker: Scheduler configured with (memSizeForMapSlotOnJT, memSizeForReduceSlotOnJT, limitMaxMemForMapTasks, limitMaxMemForReduceTasks) (-1, -1, -1, -1)
2011-03-17 00:40:33,322 INFO org.apache.hadoop.util.HostsFileReader: Refreshing hosts (include/exclude) list
2011-03-17 00:40:33,350 INFO org.apache.hadoop.mapred.JobTracker: Starting jobtracker with owner as hack
2011-03-17 00:40:33,351 FATAL org.apache.hadoop.mapred.JobTracker: java.net.BindException: Problem binding to localhost/127.0.0.1:8021 : Address already in use
        at org.apache.hadoop.ipc.Server.bind(Server.java:227)
        at org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:314)
        at org.apache.hadoop.ipc.Server.<init>(Server.java:1411)
        at org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:510)
        at org.apache.hadoop.ipc.RPC.getServer(RPC.java:471)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2112)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:2022)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:276)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:268)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4712)
Caused by: java.net.BindException: Address already in use
        at sun.nio.ch.Net.bind(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:126)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:59)
        at org.apache.hadoop.ipc.Server.bind(Server.java:225)
        ... 9 more

2011-03-17 00:40:33,352 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at QDuo/127.0.0.1
************************************************************/
{code}

The list conversation in context, at {{search-hadoop.com}}:
http://search-hadoop.com/m/FzN7iqreL/problem+starting+cdh3b2+jobtracker&subj=problem+starting+cdh3b2+jobtracker

I'll try to investigate and post the exact problem / solution soon."
MAPREDUCE-2387,Potential Resource leak in IOUtils.java,"

{code:title=IOUtils.java|borderStyle=solid}


    try {
      copyBytes(in, out, buffSize);
    } finally {
      if(close) {
        out.close();
        in.close();
      }
    }
 
{code} 

In the above code if any exception throws from the out.close() statement, in.close() statement will not execute and the input stream will not be closed.
"
MAPREDUCE-2384,The job submitter should make sure to validate jobs before creation of necessary files,"In 0.20.x/1.x, 0.21, 0.22 the MapReduce job submitter writes some job-necessary files to the JT FS before checking for output specs or other job validation items. This appears unnecessary to do.

This has since been silently fixed in the rewrite of the MRApp (called MRv2) in the MAPREDUCE-279 dump thats now replaced the older MR (or, MRv1 now). However, we can still do with a test case to prevent regressing again.

Original description below:

{quote}
When I read the source code of MapReduce in Hadoop 0.21.0, sometimes it made me confused about error response. For example:
        1. JobSubmitter checking output for each job. MapReduce makes rule to limit that each job output must be not exist to avoid fault overwrite. In my opinion, MR should verify output at the point of client submitting. Actually, it copies related files to specified target and then, doing the verifying. 
        2. JobTracker.   Job has been submitted to JobTracker. In first step, JT create JIT object that is very ""huge"" . Next step, JT start to verify job queue authority and memory requirements.
 
        In normal case, verifying client input then response immediately if any cases in fault. Regular logic can be performed if all the inputs have passed.  
        It seems like that those code does not make sense for understanding. Is only my personal opinion? Wish someone help me to explain the details. Thanks!
{quote}"
MAPREDUCE-2383,Improve documentation of DistributedCache methods,Users find the various methods in DistributedCache confusing - it's not clearly documented what the difference is between addArchiveToClassPath vs addFileToClassPath. We should improve the docs to clarify this and perhaps add an example that uses the DistributedCache.
MAPREDUCE-2382,Key/Value ordering within a single key/value set when multiple values exist for a key,">>The context of this issue is entirely within one key/value(s) pair/set, NOT between key/value sets as they are funneled to a reducer  by mappers.<<

When mapper writes multiple values for a key, the underlying collection class maps each of the values to the key, but not always in chronological order. If chronological order were guaranteed each of the values mapped to the key, each of the values could be understood as specific and different parameters between the mapper and the reducer.

I've done little tricks like having the mapper flag one a the values by making it a  negative number, which the reducer recognizes and can write it to hbase as a unique column value.This is a kluge workaround which it would be nice to not have to do.

Used to formulate this suggestion:
TableMapper<ImmutableBytesWritable,IntWritable>
TableReducer<ImmutableBytesWritable,IntWritable, ImmutableBytesWritable>

"
MAPREDUCE-2381,JobTracker instrumentation not consistent about error handling,"In the current code, if the class specified by the JobTracker instrumentation config property is not there, the JobTracker fails to start with a ClassNotFound.  If it's there, but it can't load for whatever reason, the JobTracker continues with the default.  Having two different error-handling routes is a bit confusing; I propose to move one line so that it's consistent.  (On the TaskTracker instrumentation side, if any of the multiple instrumentations aren't available, the default is used.)

The attached patch merely moves a line inside of the try block that's already there. "
MAPREDUCE-2379,Distributed cache sizing configurations are missing from mapred-default.xml,"* MAPREDUCE-1538 added {{mapreduce.tasktracker.cache.local.numberdirectories}} which is not documented in mapred-default.xml
* When MAPREDUCE-711 moved DistributedCache into the mapred project, the {{local.cache.size}} parameter was left in core-default.xml instead of moved to mapred-default.xml. It has since been renamed to {{mapreduce.tasktracker.cache.local.size}}"
MAPREDUCE-2378,Reduce fails when running on 1 small file. ,"If i run the wordcount example on 1 small (less than 2MB) file i get the following error:

log4j:ERROR Failed to flush writer,
java.io.InterruptedIOException
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:260)
        at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)
        at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:272)
        at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:276)
        at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:122)
        at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:212)
        at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:58)
        at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:316)
        at org.apache.log4j.WriterAppender.append(WriterAppender.java:160)
        at org.apache.hadoop.mapred.TaskLogAppender.append(TaskLogAppender.java:58)
        at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
        at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)
        at org.apache.log4j.Category.callAppenders(Category.java:206)
        at org.apache.log4j.Category.forcedLog(Category.java:391)
        at org.apache.log4j.Category.log(Category.java:856)
        at org.apache.commons.logging.impl.Log4JLogger.info(Log4JLogger.java:199)
        at org.apache.hadoop.mapreduce.task.reduce.ShuffleScheduler.freeHost(ShuffleScheduler.java:345)
        at org.apache.hadoop.mapreduce.task.reduce.Fetcher.run(Fetcher.java:152)


If i run the wordcount test with 2 files, it works fine. 

I have actually repeated this with my own code. I am working on something that requires me to map/reduce a small file and I had to work around the problem by splitting the file into 2 1MB pieces for my job to run. 

All our jobs that run on 1 single larger file (over 1GB) work flawlessly. I am not exactly sure the threshold, From the testing i have done it seems to be any file smaller than the default HDFS block size (64MB) Sometimes it seems random in the 5-64MB range. But its 100% for the 5MB and smaller files. 


"
MAPREDUCE-2377,task-controller fails to parse configuration if it doesn't end in \n,"If the task-controller.cfg file doesn't end in a newline, it fails to parse properly."
MAPREDUCE-2375,Improve exception thrown by SpillRecord for bad spill index,"In trying to debug some issues on a cluster that was seeing shuffle fetch failures, I found the IOException thrown by the SpillRecord constructor to be insufficient. An improved exception would have more details about the file path, offset, etc."
MAPREDUCE-2374,"""Text File Busy"" errors launching MR tasks","Some very small percentage of tasks fail with a ""Text file busy"" error.

The following was the original diagnosis:
{quote}
Our use of PrintWriter in TaskController.writeCommand is unsafe, since that class swallows all IO exceptions. We're not currently checking for errors, which I'm seeing result in occasional task failures with the message ""Text file busy"" - assumedly because the close() call is failing silently for some reason.
{quote}
.. but turned out to be another issue as well (see below)"
MAPREDUCE-2372,TaskLogAppender mechanism shouldn't be set in log4j.properties,"The TaskLogAppender log4j appender relies on using log4j.properties to pass in some Java system properties into properties of the logger. This is problematic since we've often found that users have customized log4j.properties and don't upgrade it when they upgrade the version of Hadoop.

Since this is really an internal mechanism of how the task runner passes task info to the TLA, we shouldn't rely on these settings in log4j.properties at all. Rather, we should just get the system properties directly from System.getProperty."
MAPREDUCE-2371,TaskLogsTruncater does not need to check log ownership when running as Child,"Before MAPREDUCE-2178, it used to be that the TaskLogsTruncater had to use the SecureIO API to open the task logs before truncation, to avoid an attack where the user would symlink in something that the TT had access to but not the user. After MAPREDUCE-2178, this truncation is done as the user rather than as the TT, so we don't need to perform this check.

Not performing the check avoids a fork() call which we've found to be troublesome since it doubles vmem consumption and thus requires that users bump mapred.child.ulimit to >2x the expected child heap size."
MAPREDUCE-2370,JobConf.findContainingJar incorrectly transforms paths containing '+' character,"Due to the usage of URLDecoder in JobConf#findContainingJar, the path will be incorrectly modified if it contains the '\+' character.  URLDecoder is intended for HTML form data (application/x-www-form-urlencoded), so all '\+' will be converted to ' '.

This is easy to reproduce - install hadoop at a path which contains a '\+' character and try to run a distcp job.  Mapreduce will fail to locate hadoop-tools.jar.  I have only investigated this error on 0.20.3-rc2.

Below is the exception which indicate the failure (correct path is {{/home/user/build/hadoop-core-0.20.3\+8/hadoop-tools-0.20.3\+8.jar}}):

{code}
Copy failed: java.io.FileNotFoundException: File /home/user/build/hadoop-core-0.20.3 8/hadoop-tools-0.20.3 8.jar does not exist.
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:361)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:245)
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:192)
        at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1189)
        at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1165)
        at org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:1137)
        at org.apache.hadoop.mapred.JobClient.configureCommandLineOptions(JobClient.java:657)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:761)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:730)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1249)
        at org.apache.hadoop.tools.DistCp.copy(DistCp.java:651)
        at org.apache.hadoop.tools.DistCp.run(DistCp.java:857)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.tools.DistCp.main(DistCp.java:884)
{code}"
MAPREDUCE-2369,Using TableMapper Iterable IntWritables not passed to the reducer in order put by mapper,"For mapper class:
      class Mapper1 extends TableMapper<ImmutableBytesWritable,IntWritable>
With reducer class:
     class Reducer1 extends TableReducer<ImmutableBytesWritable,IntWritable, ImmutableBytesWritable>

Iterable<IntWritable> values are usually received by the reducer in the
order the values are written to the context by the mapper. However in my
testing about 5% of cases, the same order is not maintained, and the ability
of the reducer to categorize a value by order lost.
Chronological order guaranteed would serve as a facility for identification by the reducer.

 

 "
MAPREDUCE-2368,RAID DFS regression,"The patch for MAPREDUCE-2248 did not handle zero-length files correctly, which leads to ArrayIndexOutOfBoundsException when opening a zero-length file. That case needs special handling."
MAPREDUCE-2367,Allow using a file to exclude certain tests from build,"It would be nice to be able to exclude certain tests when running builds. For example, when a test is ""known flaky"", you may want to exclude it from the main Hudson job, but not actually disable it in the codebase (so that it still runs as part of another Hudson job, for example)."
MAPREDUCE-2366,TaskTracker can't retrieve stdout and stderr from web UI,"Problem where the task browser UI can't retrieve the stdxxx printouts of streaming jobs that abend in the unix code, in the common case where the containing job doesn't reuse JVM's."
MAPREDUCE-2365,Add counters for FileInputFormat (BYTES_READ) and FileOutputFormat (BYTES_WRITTEN),"MAP_INPUT_BYTES and MAP_OUTPUT_BYTES will be computed using the difference between FileSystem
counters before and after each next(K,V) and collect/write op.

In case compression is being used, these counters will represent the compressed data sizes. The uncompressed size will
not be available.

This is not a direct back-port of 5710. (Counters will be computed in MapTask instead of in individual RecordReaders).

0.20.100 ->
   New API -> MAP_INPUT_BYTES will be computed using this method
   Old API -> MAP_INPUT_BYTES will remain unchanged.

0.23 ->
   New API -> MAP_INPUT_BYTES will be computed using this method
   Old API -> MAP_INPUT_BYTES likely to use this method
"
MAPREDUCE-2364,Shouldn't hold lock on rjob while localizing resources.,There is a deadlock while localizing resources on the TaskTracker.
MAPREDUCE-2363,Bad error messages for queues without acls,"When a queue is built without any access rights, the error message is very bad."
MAPREDUCE-2362,Unit test failures: TestBadRecords and TestTaskTrackerMemoryManager,Fix unit-test failures: TestBadRecords (NPE due to rearranged MapTask code) and TestTaskTrackerMemoryManager (need hostname in output-string pattern).
MAPREDUCE-2360,Pig fails when using non-default FileSystem,"The job client strips the file system from the user's job jar, which causes breakage when it isn't the default file system."
MAPREDUCE-2359,Distributed cache doesn't use non-default FileSystems correctly,"We are passing fs.deafult.name as viewfs:/// in core site.xml on oozie server.
We have default name node in configuration also viewfs:///

We are using hdfs://path in our path for application.
Its giving following error:

IllegalArgumentException: Wrong FS:
hdfs://nn/user/strat_ci/oozie-oozi/0000002-110217014830452-oozie-oozi-W/hadoop1--map-reduce/map-reduce-launcher.jar,
expected: viewfs:/"
MAPREDUCE-2358,MapReduce assumes HDFS as the default filesystem,Mapred assumes hdfs as the default fs even when defined otherwise.
MAPREDUCE-2357,"When extending inputsplit (non-FileSplit), all exceptions are ignored","if you're using a custom RecordReader/InputFormat setup and using an
InputSplit that does NOT extend FileSplit, then any exceptions you throw in your RecordReader.nextKeyValue() function
are silently ignored."
MAPREDUCE-2356,A task succeeded even though there were errors on all attempts.,"From Luke Lu:

Here is a summary of why the failed map task was considered ""successful"" (Thanks to Mahadev, Arun and Devaraj
for insightful discussions).

1. The map task was hanging BEFORE being initialized (probably in localization, but it doesn't matter in this case).
Its state is UNASSIGNED.

2. The jt decided to kill it due to timeout and scheduled a cleanup task on the same node.

3. The cleanup task has the same attempt id (by design.) but runs in a different JVM. Its initial state is
FAILED_UNCLEAN.

4. The JVM of the original attempt is getting killed, while proceeding to setupWorkDir and throwed an
IllegalStateException while FileSystem.getLocal, which causes taskFinal.taskCleanup being called in Child, and
triggered the NPE due to the task is not yet initialized (committer is null). Before the NPE, however it sent a
statusUpdate to TT, and in tip.reportProgress, changed the task state (currently FAILED_UNCLEAN) to UNASSIGNED.

5. The cleanup attempt succeeded and report done to TT. In tip.reportDone, the isCleanup() check returned false due to
the UNASSIGNED state and set the task state as SUCCEEDED.
"
MAPREDUCE-2355,Add an out of band heartbeat damper,We should have a configurable knob to throttle how many out of band heartbeats are sent.
MAPREDUCE-2353,Make the MR changes to reflect the API changes in SecureIO library,"Make the MR changes to reflect the API changes in SecureIO library. Specifically, the 'group' argument is never used in the SecureIO library, and hence the API changes."
MAPREDUCE-2352,RAID blockfixer can use a heuristic to find unfixable files ,"It is possible to have corrupt files that were never RAIDed. In such a case, there is no use in trying to submit a block fixer job for that file. The RAID code has the function filterUnfixableSourceFiles() that checks for the presence of parity files for each source file. This is too expensive, since a lot of the parity files can be HARed. Instead, we can use a heuristic where we just check for the presence of the parent directory in the parity space. If the parent directory is absent, the parity file cannot be present, and the source file would be unfixable. "
MAPREDUCE-2351,mapred.job.tracker.history.completed.location should support an arbitrary filesystem URI,"Currently, mapred.job.tracker.history.completed.location is resolved relative to the default filesystem. If not set it defaults to history/done in the local log directory. There is no way to set it to another local filesystem location (with a file:// URI) or an arbitrary Hadoop filesystem."
MAPREDUCE-2350,"LocalJobRunner uses ""mapred.output.committer.class"" configuration property to retrieve the OutputCommitter (regardless of whether the old API is used or the new API)","LocalJobRunner uses the ""mapred.output.committer.class"" configuration property to retrieve the output committer for the job, which can be different from the Output Committer returned from OutputFormat.getOutputCommitter(TaskAttemptContext context). So, two different output committers can be used in the same job.

See line 324 in org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter outputCommitter = job.getOutputCommitter();

Need to modify this behavior to check if the new or the old API is used, and then return the correct output committer. "
MAPREDUCE-2349,speed up list[located]status calls from input formats,"when a job has many input paths - listStatus - or the improved listLocatedStatus - calls (invoked from the getSplits() method) can take a long time. Most of the time is spent waiting for the previous call to complete and then dispatching the next call. 

This can be greatly speeded up by dispatching multiple calls at once (via executors). If the same filesystem client is used - then the calls are much better pipelined (since calls are serialized) and don't impose extra burden on the namenode while at the same time greatly reducing the latency to the client. In a simple test on non-peak hours, this resulted in the getSplits() time reducing from about 3s to about 0.5s."
MAPREDUCE-2348,TestSimulator* failed on trunk,"All Failed Tests
{code}
org.apache.hadoop.mapred.TestSimulatorJobTracker.testTrackerInteraction 
org.apache.hadoop.mapred.TestSimulatorDeterministicReplay.testMain 
org.apache.hadoop.mapred.TestSimulatorEndToEnd.testMain 
org.apache.hadoop.mapred.TestSimulatorSerialJobSubmission.testMain 
org.apache.hadoop.mapred.TestSimulatorStressJobSubmission.testMain 
{code}"
MAPREDUCE-2347,RAID blockfixer should check file blocks after the file is fixed,"After a file is fixed by the block fixer, all its blocks should be checked for the presence of replicas. If any block still is missing valid replicas, it should be fixed again"
MAPREDUCE-2346,JobClient's isSuccessful and isComplete API's can throw NPE in some cases,"Description:

* Submit a job to the job tracker and let the job complete its execution through one of the job client's submitJob APIs. 
* Jobclient returns a handle to the job, in the form of a RunningJob object. Client can use this object to check whether job is sucessful or whether job is completed.
* Reduce the following property *mapred.jobtracker.retirejob.interval*.By default this value is 1 day. I reduced it to 5 min.
* Set the property *mapred.job.tracker.persist.jobstatus.active* to {color:blue}*false*{color}.
* Call either isComplete or isSuccessful APIs, after *mapred.jobtracker.retirejob.interval* time period, previously mentioned APIs throw NPE.

Below I am attaching stack trace
{code:xml} 

java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobClient$NetworkedJob.isSuccessful(JobClient.java:330)
	at com.huawei.isap.hdp.mapreduce.test.TestJobClient.testjobClientForNULL(TestJobClient.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:164)
	at junit.framework.TestCase.runBare(TestCase.java:130)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:120)
	at junit.framework.TestSuite.runTest(TestSuite.java:230)
	at junit.framework.TestSuite.run(TestSuite.java:225)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
{code} 
"
MAPREDUCE-2345,Optimize jobtracker's  memory usage  ,"Too many tasks will eat up a considerable amount of JobTracker's heap space. According to our observation, 50GB heap size can support to 5,000,000 tasks, so we should optimize jobtracker's memory usage for more jobs and tasks. Yourkit java profile show that counters, duplicate strings, task waste too much memory. Our optimization around these three points reduced jobtracker's memory to 1/3. "
MAPREDUCE-2344,Exclude second Ant JAR from classpath in MR builds,Counterpart of HDFS-798
MAPREDUCE-2342,mrunit shall pass Configuration in constructors,"MrUnit shall pass Configuration in constructors rather then create a new one.

For example MockOutputCollector does not get user provided ""io.serializations"". So one can't test with custom serializers (like AvroWrapper)."
MAPREDUCE-2337,Remove dependence of public MapReduce API on classes in server package,"Cluster#getJobTrackerState() returns a org.apache.hadoop.mapreduce.server.jobtracker.State enum, which makes the API in o.a.h.mapreduce have a dependency on the server package. It would be better to make the public API self-contained by using an equivalent enum in the Cluster class."
MAPREDUCE-2336,Tool-related packages should be in the Tool javadoc group,Some of the tool packages are mistakenly in the general group.
MAPREDUCE-2334,Update BlockPlacementPolicyRaid,Update {{BlockPlacementPolicyRaid}} for the recent changes of {{BlockPlacementPolicy}}.
MAPREDUCE-2333,RAID jobs should delete temporary files in the event of filesystem failures,"If the creation of a parity file or parity file HAR fails due to a filesystem level error, RAID should delete the temporary files. Specifically, datanode death during parity file creation would cause FSDataOutputStream.close() to throw an IOException. The RAID code should delete such a file."
MAPREDUCE-2331,Add coverage of task graph servlet to fair scheduler system test,"Would be useful to hit the TaskGraph servlet in the fair scheduler system test. This way, when run under JCarder, it will check for any lock inversions in this code."
MAPREDUCE-2330,Forward port MapReduce server MXBeans,"Some JMX classes e.g., JobTrackerMXBean and TaskTrackerMXBean in 0.20.100~ needs to be forward ported to 0.23 in some fashion, depending on how MapReduce 2.0 emerges.

Note, similar item for HDFS, HDFS-1318 is already in 0.22."
MAPREDUCE-2329,RAID BlockFixer should exclude temporary files,RAID BlockFixer should exclude files matching the pattern ^/tmp/.*
MAPREDUCE-2327,MapTask doesn't need to put username information in SpillRecord,"This is an amendment to MAPREDUCE-2096 that's found in Yahoo's 0.20.100 branch.

This bug causes task failures in the following case:
- Cluster is not set up with LinuxTaskController (ie not secured cluster)
- Job submitter is not the same as the user running the TT
- Map output is more than one spill's worth

The issue is that UserGroupInformation's view of the current user is the job submitter, but on disk the spill files will be owned by the TT user. SecureIO will then fail when constructing the spill record."
MAPREDUCE-2326,Port gridmix changes from hadoop-0.20.100 to trunk,We have some changes to gridmix in hadoop-0.20.100. Uber jira to track merges to trunk.
MAPREDUCE-2324,Job should fail if a reduce task can't be scheduled anywhere,"If there's a reduce task that needs more disk space than is available on any mapred.local.dir in the cluster, that task will stay pending forever. For example, we produced this in a QA cluster by accidentally running terasort with one reducer - since no mapred.local.dir had 1T free, the job remained in pending state for several days. The reason for the ""stuck"" task wasn't clear from a user perspective until we looked at the JT logs.

Probably better to just fail the job if a reduce task goes through all TTs and finds that there isn't enough space."
MAPREDUCE-2323,Add metrics to the fair scheduler,"It would be useful to be able to monitor various metrics in the fair scheduler, like demand, fair share, min share, and running task count."
MAPREDUCE-2320,RAID DistBlockFixer should limit pending jobs instead of pending files,"DistBlockFixer limits the number of files being fixed simultaneously to avoid an unlimited backlog. This limits the number of parallel jobs though, and if one job has a long running task, it prevents newer jobs being started. Instead, it should have a limit on running jobs. That way, one long running task will not block other jobs."
MAPREDUCE-2317,HadoopArchives throwing NullPointerException while creating hadoop archives (.har files),"While we are trying to run hadoop archive tool in widows using this way, it is giving the below exception.

java org.apache.hadoop.tools.HadoopArchives -archiveName temp.har D:/test/in E:/temp

{code:xml} 

java.lang.NullPointerException
	at org.apache.hadoop.tools.HadoopArchives.writeTopLevelDirs(HadoopArchives.java:320)
	at org.apache.hadoop.tools.HadoopArchives.archive(HadoopArchives.java:386)
	at org.apache.hadoop.tools.HadoopArchives.run(HadoopArchives.java:725)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.tools.HadoopArchives.main(HadoopArchives.java:739)

{code} 

I see the code flow to handle this feature in windows also, 

{code:title=Path.java|borderStyle=solid}

/** Returns the parent of a path or null if at root. */
  public Path getParent() {
    String path = uri.getPath();
    int lastSlash = path.lastIndexOf('/');
    int start = hasWindowsDrive(path, true) ? 3 : 0;
    if ((path.length() == start) ||               // empty path
        (lastSlash == start && path.length() == start+1)) { // at root
      return null;
    }
    String parent;
    if (lastSlash==-1) {
      parent = CUR_DIR;
    } else {
      int end = hasWindowsDrive(path, true) ? 3 : 0;
      parent = path.substring(0, lastSlash==end?end+1:lastSlash);
    }
    return new Path(uri.getScheme(), uri.getAuthority(), parent);
  }

{code} "
MAPREDUCE-2316,Update docs for CapacityScheduler,Need to update CS docs 
MAPREDUCE-2315,javadoc is failing in nightly,"Last nightly build failed to publish javadoc because the javadoc build failed:

javadoc:
    [mkdir] Created dir: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-22-branch/trunk/build/docs/api
  [javadoc] Generating Javadoc
  [javadoc] Javadoc execution
  [javadoc] 1 error
  [javadoc] javadoc: error - Cannot find doclet class org.apache.hadoop.classification.tools.ExcludePrivateAnnotationsStandardDoclet"
MAPREDUCE-2314,configure files that are generated as part of the released tarball need to have executable bit set,"Currently the configure files that are packaged in a tarball are -rw-rw-r--
"
MAPREDUCE-2311,TestFairScheduler failing on trunk,"Most of the test cases in this test are failing on trunk, unclear how long since the contrib tests weren't running while the core tests were failed."
MAPREDUCE-2310,"If we stop Job Tracker, Task Tracker is also getting stopped.","If we execute stop-jobtracker.sh for stopping Job Tracker, Task Tracker is also stopping.

This is not applicable for the latest (trunk) code because stop-jobtracker.sh file is not coming.
"
MAPREDUCE-2309,"While querying the Job Statics from the command-line, if we give wrong status name then there is no warning or response.","If we try to get the jobs information by giving the wrong status name from the command line interface, it is not giving any warning or response.
"
MAPREDUCE-2307,"Exception thrown in Jobtracker logs, when the Scheduler configured is FairScheduler.","If we try to start the job tracker with fair scheduler using the default configuration, It is giving the below exception.


{code:xml} 
2010-07-03 10:18:27,142 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9001: starting
2010-07-03 10:18:27,143 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2010-07-03 10:18:27,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9001: starting
2010-07-03 10:18:28,037 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/linux172.site
2010-07-03 10:18:28,090 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/linux177.site
2010-07-03 10:18:40,074 ERROR org.apache.hadoop.mapred.PoolManager: Failed to reload allocations file - will use existing allocations.
java.lang.NullPointerException
at java.io.File.<init>(File.java:222)
at org.apache.hadoop.mapred.PoolManager.reloadAllocsIfNecessary(PoolManager.java:127)
at org.apache.hadoop.mapred.FairScheduler.assignTasks(FairScheduler.java:234)
at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2785)
at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
at java.lang.reflect.Method.invoke(Method.java:597)
at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:513)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:984)
at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:980)
at java.security.AccessController.doPrivileged(Native Method)
at javax.security.auth.Subject.doAs(Subject.java:396)
at org.apache.hadoop.ipc.Server$Handler.run(Server.java:978)
{code} "
MAPREDUCE-2306,It is better to give Job start time instead of JobTracker start time in the JobTracker UI->Home.,"In the log details, for each job it is giving JobTracker start time and also In the JobTracker UI->Home it is giving Start time of JobTracker. It is better to give JobId start time instead of JobTracker start time in Job Tracker UI home.
"
MAPREDUCE-2304,TestMRCLI fails when hostname has a hyphen (-),"TestMRCLI fails with below

Comparator: [RegexpComparator]
Comparision result:   [fail]
Expected output: [mv: Wrong FS: har:/dest/dir0.har/dir0/file0, expected: hdfs://\w+[.a-z]*:[0-9]+]
Actual output:   [mv: Wrong FS: har:/dest/dir0.har/dir0/file0, expected: hdfs://lab-something.host.com:34039
"
MAPREDUCE-2303,RAID BlockFixer should choose targets better,"The RAID BlockFixer chooses the destination of the generated block at random. It avoids nodes that have a corrupt replica of the block, but does not do anything beyond that. It needs to avoid data nodes that have a replica of any source or parity block in the block's stripe."
MAPREDUCE-2302,Add static factory methods in GaloisField,GaloisField is immutable and should be kept reuse after creation to avoid redundant calculation of the multiplication and division tables.
MAPREDUCE-2300,TestUmbilicalProtocolWithJobToken failing,"Testcase: testJobTokenRpc took 0.678 sec
        Caused an ERROR
null
java.lang.NullPointerException
        at org.apache.hadoop.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:241)
        at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:422)
        at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:368)
        at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:333)
        at org.apache.hadoop.ipc.RPC.getProtocolProxy(RPC.java:461)
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:442)
        at org.apache.hadoop.mapreduce.security.TestUmbilicalProtocolWithJobToken$1.run(TestUmbilicalProtocolWithJobToken.java:102)
"
MAPREDUCE-2298,FairScheduler status page allows users to set pool and priority,"The FairScheduler status page should allow users to view status without enabling admin functions like set pool and set priority.

One proposal is to disable all admin commands from the FairScheduler status page to make it read only. We would have to provide an alternate administration interface, for example via shell (MAPREDUCE-2292).
"
MAPREDUCE-2297,All map reduce tasks are failing if we give invalid path jar file for Job,"This can be reproduced by giving the invalid jar file for the Job or it can be reproduced from hive.


In hive-default.xml

<property>
<name>hive.aux.jars.path</name>
<value></value>
<description>Provided for adding auxillaryjarsPath</description>
</property>

If we configure an invalid path for jar file, It is making all map reduce tasks to fail even those jobs are not depending on this jar file and it is giving the below exception.
{code:xml} 
hive> select * from a join b on(a.b=b.c);
Total MapReduce jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
set mapred.reduce.tasks=<number>
java.io.FileNotFoundException: File does not exist: /user/root/grade.jar
at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:495)
at org.apache.hadoop.filecache.DistributedCache.getTimestamp(DistributedCache.java:509)
at org.apache.hadoop.mapred.JobClient.configureCommandLineOptions(JobClient.java:651)
at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:783)
at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:752)
at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:698)
at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:107)
at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:64)

{code} "
MAPREDUCE-2296,Fix references to misspelled message name getProtocolSigature,"HADOOP-7129 fixed the typo, need to update usages in MR."
MAPREDUCE-2294,Mumak won't compile in MR trunk,"HADOOP-6904 added a required getProtocolSignature() method for protocols, but the mock JT in Mumak doesn't implement this. So, MR trunk is currently failing."
MAPREDUCE-2290,TestTaskCommit missing getProtocolSignature override,"Fixes an MR compilation error, HADOOP-6904 added a new implementation of getProtocolSignature but TestTaskCommit doesn't override it."
MAPREDUCE-2289,Permissions race can make getStagingDir fail on local filesystem,"I've observed the following race condition in TestFairSchedulerSystem which uses a MiniMRCluster on top of RawLocalFileSystem:
- two threads call getStagingDir at the same time
- Thread A checks fs.exists(stagingArea) and sees false
-- Calls mkdirs(stagingArea, JOB_DIR_PERMISSIONS)
--- mkdirs calls the Java mkdir API which makes the file with umask-based permissions
- Thread B runs, checks fs.exists(stagingArea) and sees true
-- checks permissions, sees the default permissions, and throws IOE
- Thread A resumes and sets correct permissions"
MAPREDUCE-2288,JT Availability,"This is an umbrella jira, like HDFS-1064, for discussing and providing references to jobtracker availability jiras (eg from JT restart on a host or to cross host fail-over)."
MAPREDUCE-2287,add Kerberos HTTP SPNEGO authentication support to Hadoop JT/NN/DN/TT web-consoles,This JIRA is for the MAPRED portion of HADOOP-7119
MAPREDUCE-2286,ASF mapreduce,"This sub-net ensures versions in description, however projects or manufacturing will have to be in working conditioning in the time of unknown versions."
MAPREDUCE-2285,MiniMRCluster does not start after ant test-patch,"Any test using MiniMRCluster hangs in the MiniMRCluster constructor after running ant test-patch. Steps to reproduce:
 1. ant -Dpatch.file=<dummy patch to CHANGES.txt>  -Dforrest.home=<path to forrest> -Dfindbugs.home=<path to findbugs> -Dscratch.dir=/tmp/testpatch  -Djava5.home=<path to java5> test-patch
 2. Run any test that creates MiniMRCluster, say ant test -Dtestcase=TestFileArgs (contrib/streaming)

Expected result: Test should succeed
Actual result: Test hangs  in MiniMRCluster.<init>. This does not happen if we run ant clean after ant test-patch

Test output:
{code}
    [junit] 11/01/27 12:11:43 INFO ipc.Server: IPC Server handler 3 on 58675: starting
    [junit] 11/01/27 12:11:43 INFO mapred.TaskTracker: TaskTracker up at: localhost.localdomain/127.0.0.1:58675
    [junit] 11/01/27 12:11:43 INFO mapred.TaskTracker: Starting tracker tracker_host0.foo.com:localhost.localdomain/127.0.0.1:58675
    [junit] 11/01/27 12:11:44 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 0 time(s).
    [junit] 11/01/27 12:11:45 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 1 time(s).
    [junit] 11/01/27 12:11:46 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 2 time(s).
    [junit] 11/01/27 12:11:47 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 3 time(s).
    [junit] 11/01/27 12:11:48 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 4 time(s).
    [junit] 11/01/27 12:11:49 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 5 time(s).
    [junit] 11/01/27 12:11:50 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 6 time(s).
    [junit] 11/01/27 12:11:51 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 7 time(s).
    [junit] 11/01/27 12:11:52 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 8 time(s).
    [junit] 11/01/27 12:11:53 INFO ipc.Client: Retrying connect to server: localhost/127.0.0.1:0. Already tried 9 time(s).
    [junit] 11/01/27 12:11:53 INFO ipc.RPC: Server at localhost/127.0.0.1:0 not available yet, Zzzzz...
{code}

Stack trace: 

{code}
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:611)
        at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:429)
        - locked <0x00007f3b8dc08700> (a org.apache.hadoop.ipc.Client$Connection)
        at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:504)
        - locked <0x00007f3b8dc08700> (a org.apache.hadoop.ipc.Client$Connection)
        at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:206)
        at org.apache.hadoop.ipc.Client.getConnection(Client.java:1164)
        at org.apache.hadoop.ipc.Client.call(Client.java:1008)
        at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:198)
        at org.apache.hadoop.mapred.$Proxy11.getProtocolVersion(Unknown Source)
        at org.apache.hadoop.ipc.WritableRpcEngine.getProxy(WritableRpcEngine.java:235)
        at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:275)
        at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:206)
        at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:185)
        at org.apache.hadoop.ipc.RPC.waitForProxy(RPC.java:169)
        at org.apache.hadoop.mapred.TaskTracker$2.run(TaskTracker.java:699)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1142)
        at org.apache.hadoop.mapred.TaskTracker.initialize(TaskTracker.java:695)
        - locked <0x00007f3b8ccc3870> (a org.apache.hadoop.mapred.TaskTracker)
        at org.apache.hadoop.mapred.TaskTracker.<init>(TaskTracker.java:1391)
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner.createTaskTracker(MiniMRCluster.java:219)
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner$1.run(MiniMRCluster.java:203)
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner$1.run(MiniMRCluster.java:201)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1142)
        at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner.<init>(MiniMRCluster.java:201)
        at org.apache.hadoop.mapred.MiniMRCluster.startTaskTracker(MiniMRCluster.java:716)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:541)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:482)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:474)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:466)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:458)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:448)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:438)
        at org.apache.hadoop.mapred.MiniMRCluster.<init>(MiniMRCluster.java:429)
        at org.apache.hadoop.streaming.TestFileArgs.<init>(TestFileArgs.java:59)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:202)
        at org.junit.runners.BlockJUnit4ClassRunner$1.runReflectiveCall(BlockJUnit4ClassRunner.java:251)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:248)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
        at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
        at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
        at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
        at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:422)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:931)
        at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:785)

{code}"
MAPREDUCE-2284,TestLocalRunner.testMultiMaps times out,This test has timed out in a number of Hudson builds.
MAPREDUCE-2283,TestBlockFixer hangs initializing MiniMRCluster,TestBlockFixer (a raid contrib test) is hanging the precommit testing on Hudson
MAPREDUCE-2282,MapReduce tests don't compile following HDFS-1561,"TestMRServerPorts depends on TestHDFSServerPorts which was changed by HDFS-1561, resulting in a compilation failure."
MAPREDUCE-2281,"Fix javac, javadoc, findbugs warnings",Split from HADOOP-6642
MAPREDUCE-2280,The mapreducer wizard of eclipse-plugin should generate sample code using new API,"The mapreducer wizard of eclipse-plugin, NewDriverWizard, NewMapperWizard and NewReducerWizard components generate sample code with deprecated API, better to using new mapreducer API to generate sample code."
MAPREDUCE-2279,Improper byte -> int conversion in DistributedRaidFileSystem,"When return a byte value from DistributedRaidFileSystem.read(), we should do 0xff & byteVal. Otherwise the returned int value will be incorrectly negative.
This is a regression from MAPREDUCE-2248"
MAPREDUCE-2278,DistributedCache shouldn't hold a ref to JobConf,"The reference is unnecessary, leads to a memory leak."
MAPREDUCE-2277,TestCapacitySchedulerWithJobTracker fails sometimes,"Sometimes the testJobTrackerIntegration test fails on my Hudson. It seems the issue is that it doesn't ever wait for the first job to complete before checking its success status. Since the two jobs are in different queues, the first job may complete after the second job."
MAPREDUCE-2276,Fix build failure introduced by HDFS-1547,MiniDFSCluster#startDataNodes() method signature changes introduced by HDFS-1547 breaks the mapreduce build
MAPREDUCE-2275,RaidNode should monitor and fix blocks that violate RAID block placement ,"When files are RAIDed, it is important to keep blocks in each RAID stripe and the corresponding parity blocks on as many different machines as possible. This ensures minimal probability of data loss when data nodes go dead.

BlockPlacementPolicyRaid ensures that parity blocks are not located on the same machines as the source blocks. But source blocks placement is not controlled directly in this manner. Instead, source blocks are allowed to be created using the default policy. After a source file is RAIDed, its replication is increased, and then decreased. BlockPlacementPolicyRaid then tries to keep the source blocks well-located when excess blocks are deleted. This is not guaranteed to ensure the correct block placement for RAID.

Also, if blocks are moved around by the balancer, the block placement could be violated.

We need periodic monitoring of block placement of RAIDed files and the corresponding parity blocks."
MAPREDUCE-2274,Generalize block fixer scheduler options,"The Raid block fixer currently allows the specification of the fair scheduler pool name. This is not generic since it assumes usage of the fair scheduler. Also this does not allow multiple options to be set, just the pool name. This is similar to MAPREDUCE-1818"
MAPREDUCE-2273,TaskLogServlet does not set content type,"TaskLogServlet has never set the content type, even though it can serve plain text or HTML, but since HADOOP-7093 the problem has been highlighted since it serves HTML as ""text/plain"" (before it was serving plain text as ""text/html"")."
MAPREDUCE-2272,Job ACL file should not be executable,"For some reason the job ACL file is localized with permissions 700. This doesn't make sense, since it's not executable. It should be 600."
MAPREDUCE-2271,TestSetupTaskScheduling failing in trunk,This test case is failing in trunk after the commit of MAPREDUCE-2207
MAPREDUCE-2268,"With JVM reuse, JvmManager doesn't delete last workdir properly","In JvmManager, when a Jvm exits, it tries to delete the workdir for {{initalContext.task}} which is null, hence throwing NPE. Currently this NPE is swallowed into the abyss.

We should catch exceptions out of the JvmRunner thread, add a test case that verifies this functionality, and fix this code to properly grab the last task."
MAPREDUCE-2267,Parallelize reading of blocks within a stripe,"RAID code has several instances where several blocks of data have to be read to perform an operation. For example, computing a parity block requires reading the blocks of the source file. Similarly, generating a fixed block requires reading a parity block and the good blocks from the source file. These read operations proceed sequentially currently. RAID code should use a thread pool to increase the parallelism and thus reduce latency."
MAPREDUCE-2266,JvmManager sleeps between SIGTERM and SIGKILL while holding many TT locks,"Between sending a task SIGTERM and SIGKILL, the JvmManager will sleep for sleepTimeBeforeSigKill millis. But in many call heirarchies this is done while holding important locks like the TT lock and the JvmManagerForType lock. With the default 5 second sleep, this prevents other tasks from getting scheduled and reduces scheduling throughput."
MAPREDUCE-2265,task-controller and jsvc should install into sbin/<platform>/ directory,"Currently the task-controller and jsvc ""live"" in the bin/ directory regardless of build platform. This is incorrect since these components are native compiled code and thus are built for a particular architecture. So, when we ship a build of 22, we will want to ship both 32-bit and 64-bit artifacts so users can use these components without rebuilding on their own.

Additionally, it doesn't make sense for them to be in bin/ since they're not user-facing in any way (i.e a user would never directly invoke them). So I would propose putting them in an sbin directory.

The final proposed path is $HADOOP_HOME/sbin/<platform>/{jsvc,task-controller}

Note this is not an incompatible change since these components were not present in any prior apache release."
MAPREDUCE-2264,Job status exceeds 100% in some cases ,"I'm looking now at my jobtracker's list of running reduce tasks. One of them is 120.05% complete, the other is 107.28% complete.

I understand that these numbers are estimates, but there is no case in which an estimate of 100% for a non-complete task is better than an estimate of 99.99%, nor is there any case in which an estimate greater than 100% is valid.

I suggest that whatever logic is computing these set 99.99% as a hard maximum."
MAPREDUCE-2263,MapReduce side of HADOOP-6904,Make changes in Map/Reduce to incorporate HADOOP-6904.
MAPREDUCE-2262,Capacity Scheduler unit tests fail with class not found,"Currently the ivy.xml file for the capacity scheduler doesn't include the commons-cli, leading to class not found exceptions."
MAPREDUCE-2261,Fair Multiple Task Assignment Scheduler (Assigning multiple tasks per heart beat),"      Functionality wise the Fair Multiple Task Assignment Scheduler behaves the same way except the assignment of Tasks. Instead of assigning a single Task per heartbeat, it checks for all the jobs if any local or non-local Task that can be launched.

Fair Multiple Task Assignment Scheduler has the advantage of assigning multiple jobs per heart beat interval depending upon the slots available on the Task Tracker, by configuring the number of parallel tasks to be executed in a Task Tracker at any point of time. The advantages are as follows:

a) Parallel Execution allows tasks be to submitted and processed in parallel independent of the status of other tasks.
b) More number of tasks is assigned in a heartbeat interval and consequently multitasking capability increases.
c) With multi task assignment, Task Tracker efficiency is increased.
"
MAPREDUCE-2260,Remove auto-generated native build files,The repo currently includes the automake and autoconf generated files for the native build. Per discussion on HADOOP-6421 let's remove them and use the host's automake and autoconf. We should also do this for libhdfs and fuse-dfs. 
MAPREDUCE-2259,Hadoop Streaming JAR location might be updated,"examples in docs/streaming.html:
$HADOOP_HOME/hadoop-streaming.jar
might be updated to
$HADOOP_HOME/contrib/streaming/hadoop-$HADOOP-VERSION-streaming.jar
for someone could not find the streaming archive."
MAPREDUCE-2258,IFile reader closes stream and compressor in wrong order,"In IFile.Reader.close(), we return the decompressor to the pool and then call close() on the input stream. This is backwards and causes a rare race in the case of LzopCodec, since LzopInputStream makes a few calls on the decompressor object inside close(). If another thread pulls the decompressor out of the pool and starts to use it in the meantime, the first thread's close() will cause the second thread to potentially miss pieces of data."
MAPREDUCE-2256,FairScheduler fairshare preemption from multiple pools may preempt all tasks from one pool causing that pool to go below fairshare.,"Scenarios:
You have a cluster with 600 map slots and 3 pools.  Fairshare for each pool is 200 to start with.  Fairsharepreemption timeout is 5 mins.
1)  Pool1 schedules 300 map tasks first
2)  Pool2 then schedules another 300 map tasks
3)  Pool3 demands 300 map tasks but doesn't get any slot as all slots are taken.
4)  After 5 mins pool3 should preempt 200 map-slots.  Instead of peempting 100 slots each from pool1 and pool2, the bug would cause it to preempt all 200 slots from pool2 (last started) causing it to go below fairshare.  This is happening because the preemptTask method is not reducing the tasks left from a pool while preempting the tasks.  

The above scenario could be an extreme case but some amount of excess preemption would happen because of this bug.

The patch I created was for 0.22.0 but the code fix should work on 0.21  as well as looks like it has the same bug."
MAPREDUCE-2255,correct example code in /api/org/apache/hadoop/util/Tool.html,"a trivial mistake(?) in example code. But I wondered where Sort() was come from for a few days.

<  int res = ToolRunner.run(new Configuration(), new Sort(), args);
---
>  int res = ToolRunner.run(new Configuration(), new MyApp(), args);

"
MAPREDUCE-2254,Allow setting of end-of-record delimiter for TextInputFormat,"It will be useful to allow setting the end-of-record delimiter for TextInputFormat. The current implementation hardcodes '\n', '\r' or '\r\n' as the only possible record delimiters. This is a problem if users have embedded newlines in their data fields (which is pretty common). This is also a problem for other tools using this TextInputFormat (See for example: https://issues.apache.org/jira/browse/PIG-836 and https://issues.cloudera.org/browse/SQOOP-136).

I have wrote a patch to address this issue. This patch allows users to specify any custom end-of-record delimiter using a new added configuration property. For backward compatibility, if this new configuration property is absent, then the same exact previous delimiters are used (i.e., '\n', '\r' or '\r\n')."
MAPREDUCE-2253,Servlets should specify content type,"HADOOP-7093 will change the default content-type to text/plain. So TaskLogServlet, which outputs HTML, needs to change to specify this content type. I believe the other HTML servlets already correctly specify a content type. The MapOutputServlet appears to specify no content type and work fine without one, but to be ""correct"" we may as well specify application/octet-stream"
MAPREDUCE-2252,XSS injection in JobHistoryParser,"A malicious user can copy a job history file to another location to which both the user and the JT have access to, and then modify the ""taskid"" field of a ""TaskStarted"" event in the JSON to include a script tag. This will be printed unescaped in the 500 error that is produced."
MAPREDUCE-2251,Remove mapreduce.job.userhistorylocation config,"Best I can tell, this config parameter is no longer used as of MAPREDUCE-157 but still exists in the code and in mapred-default.xml. We should remove it to avoid user confusion."
MAPREDUCE-2250,Fix logging in raid code.,There are quite a few error messages being logged with a log level of info. That should be fixed to help debugging.
MAPREDUCE-2249,Better to check the reflexive property of the object while overriding equals method of it,"It is better to check the reflexive property of the object while overriding equals method of it.
 
It improves the performance when a heavy object is compared to itself.
"
MAPREDUCE-2248,DistributedRaidFileSystem should unraid only the corrupt block,DistributedRaidFileSystem unraids the entire file if it hits a corrupt block. It is better to unraid just the corrupt block and use the rest of the file as normal. This becomes really important when we have tera-byte sized files.
MAPREDUCE-2247,Use readlink to get absolute paths in the scripts,MR side of HADOOP-7089.
MAPREDUCE-2246,Timeout for fixing a file,"If the DistBlockFixer takes a long time to to fix a file, it would be better to ""timeout"" and try again in a new MR job."
MAPREDUCE-2245,Failure metrics for block fixer,Publish file fixing failure metrics for the block fixer.
MAPREDUCE-2243,Close all the file streams propely in a finally block to avoid their leakage.,"In the following classes streams should be closed in finally block to avoid their leakage in the exceptional cases.

CompletedJobStatusStore.java
------------------------------------------
       dataOut.writeInt(events.length);
        for (TaskCompletionEvent event : events) {
          event.write(dataOut);
        }
       dataOut.close() ;

EventWriter.java
----------------------
   encoder.flush();
   out.close();

MapTask.java
-------------------
    splitMetaInfo.write(out);
     out.close();

TaskLog
------------
 1) str = fis.readLine();
      fis.close();

2) dos.writeBytes(Long.toString(new File(logLocation, LogName.SYSLOG
      .toString()).length() - prevLogLength) + ""\n"");
    dos.close();

TotalOrderPartitioner.java
-----------------------------------
 while (reader.next(key, value)) {
	      parts.add(key);
	      key = ReflectionUtils.newInstance(keyClass, conf);
	    }
reader.close();


"
MAPREDUCE-2241,ClusterWithLinuxTaskController should accept relative path on the command line,"Currently if you pass a relative path for the -Dtaskcontroller-path option when running these tests, it fails in a fairly unintuitive way. We should absolutize it inside the tests to make it easier for people to run them."
MAPREDUCE-2240,DistBlockFixer could sleep indefinitely,"DistributedBlockFixer computes its sleep interval based on the amount of time spent in fixing jobs. This computation has a bug which can result in the sleep interval becoming negative, which would make the distributed block fixer sleep indefinitely"
MAPREDUCE-2239,BlockPlacementPolicyRaid should call getBlockLocations only when necessary,"Currently BlockPlacementPolicyRaid calls getBlockLocations for every chooseTarget().
This puts pressure on NameNode. We should avoid calling if this file is not raided or a parity file."
MAPREDUCE-2238,Undeletable build directories ,"The MR hudson job is failing, looks like it's due to a test chmod'ing a build directory so the checkout can't clean the build dir.

https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/549/console

Building remotely on hadoop7
hudson.util.IOException2: remote file operation failed: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk at hudson.remoting.Channel@2545938c:hadoop7
	at hudson.FilePath.act(FilePath.java:749)
	at hudson.FilePath.act(FilePath.java:735)
	at hudson.scm.SubversionSCM.checkout(SubversionSCM.java:589)
	at hudson.scm.SubversionSCM.checkout(SubversionSCM.java:537)
	at hudson.model.AbstractProject.checkout(AbstractProject.java:1116)
	at hudson.model.AbstractBuild$AbstractRunner.checkout(AbstractBuild.java:479)
	at hudson.model.AbstractBuild$AbstractRunner.run(AbstractBuild.java:411)
	at hudson.model.Run.run(Run.java:1324)
	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:46)
	at hudson.model.ResourceController.execute(ResourceController.java:88)
	at hudson.model.Executor.run(Executor.java:139)
Caused by: java.io.IOException: Unable to delete /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/logs/userlogs/job_20101230131139886_0001/attempt_20101230131139886_0001_m_000000_0"
MAPREDUCE-2237,Lost heartbeat response containing MapTask throws NPE when it is resent,"When the JT sends a heartbeat response, it records it in trackerToHeartbeatResponseMap. But after MapTask writes its input split, it sets that split to null (assumedly to save memory?). So, if the heartbeat response is lost, and the JT needs to resend it, it will throw NPE since the split information has been lost."
MAPREDUCE-2236,No task may execute due to an Integer overflow possibility,"If the attempts is configured to use Integer.MAX_VALUE, an overflow occurs inside TaskInProgress, and thereby no task is attempted by the cluster and the map tasks stay in pending state forever.

For example, here's a job driver that causes this:
{code}
import java.io.IOException;

import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.TextInputFormat;
import org.apache.hadoop.mapred.lib.IdentityMapper;
import org.apache.hadoop.mapred.lib.NullOutputFormat;


@SuppressWarnings(""deprecation"")
public class IntegerOverflow {

	/**
	 * @param args
	 * @throws IOException 
	 */
	@SuppressWarnings(""deprecation"")
	public static void main(String[] args) throws IOException {
		JobConf conf = new JobConf();
		
		Path inputPath = new Path(""ignore"");
		FileSystem fs = FileSystem.get(conf);
		if (!fs.exists(inputPath)) {
			FSDataOutputStream out = fs.create(inputPath);
			out.writeChars(""Test"");
			out.close();
		}
		
		conf.setInputFormat(TextInputFormat.class);
		conf.setOutputFormat(NullOutputFormat.class);
		FileInputFormat.addInputPath(conf, inputPath);
		
		conf.setMapperClass(IdentityMapper.class);
		conf.setNumMapTasks(1);
		// Problem inducing line follows.
		conf.setMaxMapAttempts(Integer.MAX_VALUE);
		
		// No reducer in this test, although setMaxReduceAttempts leads to the same problem.
		conf.setNumReduceTasks(0);
		
		JobClient.runJob(conf);
	}

}
{code}

The above code will not let any map task run. Additionally, a log would be created inside JobTracker logs with the following information that clearly shows the overflow:
{code}
2010-12-30 00:59:07,836 WARN org.apache.hadoop.mapred.TaskInProgress: Exceeded limit of -2147483648 (plus 0 killed) attempts for the tip 'task_201012300058_0001_m_000000'
{code}

The issue lies inside the TaskInProgress class (/o/a/h/mapred/TaskInProgress.java), at line 1018 (trunk), part of the getTaskToRun(String taskTracker) method.
{code}
  public Task getTaskToRun(String taskTracker) throws IOException {   
    // Create the 'taskid'; do not count the 'killed' tasks against the job!
    TaskAttemptID taskid = null;
    /* ============ THIS LINE v ====================================== */
    if (nextTaskId < (MAX_TASK_EXECS + maxTaskAttempts + numKilledTasks)) {
    /* ============ THIS LINE ^====================================== */
      // Make sure that the attempts are unqiue across restarts
      int attemptId = job.getNumRestarts() * NUM_ATTEMPTS_PER_RESTART + nextTaskId;
      taskid = new TaskAttemptID( id, attemptId);
      ++nextTaskId;
    } else {
      LOG.warn(""Exceeded limit of "" + (MAX_TASK_EXECS + maxTaskAttempts) +
              "" (plus "" + numKilledTasks + "" killed)""  + 
              "" attempts for the tip '"" + getTIPId() + ""'"");
      return null;
    }
{code}

Since all three variables being added are integer in type, one of them being Integer.MAX_VALUE makes the condition fail with an overflow, thereby logging and returning a null as the result is negative.

One solution would be to make one of these variables into a long, so the addition does not overflow?"
MAPREDUCE-2235,"JobTracker ""over-synchronization"" makes it hang up in certain cases ","There is a genaral problem in JobTracker.java code: it's using ""this"" synchronization everywhere so only one method could be executed at one moment. When the job submit rate is low (lower then one job in several seconds) tracker's working without a problem. When the job rate is high the following problem occurs:

Inside submitJob() JT copies job jar + xml to local filesystem. After that it's doing ""chmod"" on those files. Hadoop does chmod  by spawning child process. When JT heap is big (like several gigabytes) spawning child process takes a lot of time (because java calls fork()) — in our case it's about 1-2 seconds. So job tracker can't handle high frequency job submits.

Except of that, as heartbeat() method is also synchronized JT stops to process heart-beat as ""this"" monitor is being held by submit job. That makes JT thins that a lot of TaskTrackers are down.

Following solution could help:

""chmod"" is being called from submitJob() method under following line:

JobInProgress job = new JobInProgress(jobId, this, this.conf);

This block could be taken away from synchronized code:

public JobStatus submitJob(JobID jobId) throws IOException {
    synchronized (this) {
        .... the rest
    }

    //here we're leaving this line outside syncronized code as it doesn't relate
    //on state of JobTracker. Also this line

    JobInProgress job = new JobInProgress(jobId, this, this.conf);

    synchronized (this) {
         .... the rest
    }"
MAPREDUCE-2234,"If Localizer can't create task log directory, it should fail on the spot","Currently, it simply emits a warning. Then, when the taskjvm.sh tries to pipe its output into this directory, it fails with a strange error code like ""exit code: 1"" which is not intuitive to ops. Instead it should simply throw an exception at initialization time rather than attempting to run the task."
MAPREDUCE-2233,LinuxTaskController throws NPE when task fails to start,"When the LinuxTaskController is incorrectly configured (eg wrong permissions or path) an NPE is thrown when it tries to kill the failed tasks, since there is no known pid."
MAPREDUCE-2232,Add missing methods to TestMapredGroupMappingServiceRefresh,"HADOOP-6864 added new methods to the GroupMappingServiceProvider interface, so MR trunk no longer compiles."
MAPREDUCE-2230,Fault-injection tests are executed multiple times if invoked with run-test-hdfs-fault-inject target,When invoked with {{run-test-hdfs-fault-inject target}} fault injection tests are getting executed 4 times.
MAPREDUCE-2229,Initialize reader in Sort example,"As described in paragraph ""Total Sort"" in HTDG book, page 223, I tried to create a Hadoop job to sort globally some input, using InputSampler with TotalOrderPartitioner.

Please run the mapreduce Sort example with the following arguments to reproduce the exception.
{noformat}
org.apache.hadoop.examples.Sort
	-r 2
	-outKey org.apache.hadoop.io.Text
	-outValue org.apache.hadoop.io.Text
	-inFormat org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat
	-outFormat org.apache.hadoop.mapreduce.lib.output.TextOutputFormat
	-totalOrder 0.1 10000 10
	test/sortInput
	test/sortOutput
{noformat}

The issue is already described there:
- http://mail-archives.apache.org/mod_mbox/hadoop-mapreduce-user/201011.mbox/%3CDB1B07B75C01FB40B814678DEE6E0085175C86CDFF@bdc.taomee-ex.com%3E
- http://www.mail-archive.com/mapreduce-user@hadoop.apache.org/msg01372.html

This is a somewhat related comment:
http://www.mail-archive.com/common-user@hadoop.apache.org/msg03947.html

We need to initialize the reader to avoid the NPE occuring when generating the partition file:
{noformat}
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:149)
	at org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.nextKeyValue(KeyValueLineRecordReader.java:91)
	at org.apache.hadoop.mapreduce.lib.partition.InputSampler$RandomSampler.getSample(InputSampler.java:220)
	at org.apache.hadoop.mapreduce.lib.partition.InputSampler.writePartitionFile(InputSampler.java:315)
	at org.apache.hadoop.examples.Sort.run(Sort.java:166)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.examples.Sort.main(Sort.java:192)
{noformat} 

Right now, this initialization only happens in runNewMapper in org.apache.hadoop.mapred.MapTask, but the sampling is performed before the job started. TeraInputFormat class for the TeraSort has its own writePartitionFile method. This is the javadoc comment of createRecordReader method in InputFormat class:
{noformat}
   * Create a record reader for a given split. The framework will call
   * {@link RecordReader#initialize(InputSplit, TaskAttemptContext)} before
   * the split is used.
{noformat}
"
MAPREDUCE-2228,Remove java5 dependencies from build,As the first short-term step let's remove JDK5 dependency from build(s)
MAPREDUCE-2227,update the pom template's dependency list,update the pom template's in the ivy folder to point to latest set of dependencies.
MAPREDUCE-2225,MultipleOutputs should not require the use of 'Writable',"MultipleOutputs right now requires for Key/Value classes to utilize the Writable and WritableComparable interfaces, and fails if the associated key/value classes aren't doing so.

With support for alternates like Avro serialization, using Writables isn't necessary and thus the MO class must not strictly check for them.

And since comparators may be given separately, key class doesn't need to be checked for implementing a comparable (although it is good design if the key class does implement Comparable at least).

Am not sure if this brings about an incompatible change (does Java have BIC? No idea)."
MAPREDUCE-2224,Synchronization bugs in JvmManager,JvmManager.JvmManagerForType has several HashMap members that are inconsistently synchronized. I've seen sporadic NPEs in the 0.20 version of this code which has similar bugs.
MAPREDUCE-2223,TestMRCLI might fail on Ubuntu with default /etc/hosts,"Depending on the order of entries in /etc/hosts, TestCLI can fail. This is because it sets fs.default.name to ""localhost"", and then the bound IPC socket on the NN side reports its hostname as ""foobar-host"" if the entry for 127.0.0.1 lists ""foobar-host"" before ""localhost"". This seems to be the default in some versions of Ubuntu."
MAPREDUCE-2222,Ivy resolve force mode should be turned off by default,cf. HADOOP-7068
MAPREDUCE-2220,Fix new API FileOutputFormat-related typos in mapred-default.xml,"there're two typos:
 * mapreduce.output.fileoutputformat.compression.type instead of mapreduce.output.fileoutputformat.compress.type
 * mapreduce.output.fileoutputformat.compression.codec instead of mapreduce.output.fileoutputformat.compress.codec

in mapred-default. Trivial patch to fix."
MAPREDUCE-2219,JT should not try to remove mapred.system.dir during startup,"During startup, the JT tries to clean up mapred.system.dir by recursively removing it and then recreating it. This requires that mapred.system.dir is inside a directory owned by the mapred user. For example, if set to /system/mapred then /system must be owned by the mapred account. This isn't documented properly and also seems unnecessary. Instead we can remove the *contents* of mapred.system.dir instead of the directory itself."
MAPREDUCE-2217,The expire launching task should cover the UNASSIGNED task,"The ExpireLaunchingTask thread kills the task that are scheduled but not responded.
Currently if a task is scheduled on tasktracker and for some reason tasktracker cannot put it to RUNNING.
The task will just hang in the UNASSIGNED status and JobTracker will keep waiting for it.

JobTracker.ExpireLaunchingTask should be able to kill this task."
MAPREDUCE-2215,A more elegant FileSystem#listCorruptFileBlocks API (RAID changes),Map/reduce changes related to HADOOP-7060 and HDFS-1533.
MAPREDUCE-2212,MapTask and ReduceTask should only compress/decompress the final map output file,"Currently if we set mapred.map.output.compression.codec
1. MapTask will compress every spill, decompress every spill, merge and compress the final map output file
2. ReduceTask will decompress, merge and compress every map output file. And repeat the compression/decompression every pass.

This causes all the data being compressed/decompressed many times.
The reason we need mapred.map.output.compression.codec is for network traffic.
We should not compress/decompress the data again and again during merge sort.

We should only compress the final map output file that will be transmitted over the network."
MAPREDUCE-2210,Preemption does not obey job priority,"Preemption, as it currently works, kills running tasks that are ""unfair"" in terms of the amount of task attention used by one job compared to another.

The bug is that pre-emption occurs such that HIGH priority jobs have their tasks killed when the cluster is filled with lower-priority jobs. Pre-emption should only be allowed to kill tasks for jobs with equal or lower priority."
MAPREDUCE-2207,Task-cleanup task should not be scheduled on the node that the task just failed,"Currently the task-cleanup task always go to the same node that the task just failed.
There is a higher chance that it hits a bad node. This should be changed."
MAPREDUCE-2206,The task-cleanup tasks should be optional,"For job does not use OutputCommitter.abort(), this should be able to turn off.
This improves the latency of the job because failed tasks are often the bottleneck of the jobs."
MAPREDUCE-2205,FairScheduler should not re-schedule jobs that have just been preempted,"We have hit a problem with the preemption implementation in the FairScheduler where the following happens:

# job X runs short of fair share or min share and requests/causes N tasks to be preempted
# when slots are then scheduled - tasks from some other job are actually scheduled
# after preemption_interval has passed, job X finds it's still underscheduled and requests preemption. goto 1.

This has caused widespread preemption of tasks and the cluster going from high utilization to low utilization in a few minutes.

After doing some analysis of the logs - one of the biggest contributing factors seems to be the scheduling of jobs when a heartbeat with multiple slots is advertised. currently it goes over all the jobs/pools (in sorted) order until all the slots are exhausted. this leads to lower priority jobs also getting scheduled (that may have just been preempted)."
MAPREDUCE-2204,Implement gridmix system tests with different time intervals of  high ram job traces.,"Implement gridmix system tests with different time intervals of High Ram map reduce jobs with below scenarios.

1) Generate input data based on cluster size and create the synthetic jobs by using the 2 min MR High RAM jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = SleepJob
GRIDMIX_USER_RESOLVER = SubmitterUserResolver
GRIDMIX_SUBMISSION_POLICY = SERIAL
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false
Input Size = 200 MB * No. of nodes in cluster.
TRACE_FILE = 5 min folded trace.
GRIDMIX_SLEEP_MAP_MAX_TIME=5 sec.                                                                 
GRIDMIX_SLEEP_REDUCE_MAX_TIME=5 sec.
Verify JobStatus for each job and summary (QueueName, UserName, StatTime, FinishTime, MAPS, REDUCERS and COUNTERS etc) after completion of execution.

2) Generate input data based on cluster size and create the synthetic jobs by using the 3 min MR High RAM jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = RoundRobinUserResolver
GRIDMIX_SUBMISSION_POLICY = STRESS
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false
BYTES_PER_FILE = 200 MB
Input Size = 400 MB * No. of nodes in cluster.
TRACE_FILE = 3 min folded trace.
Verify JobStatus for each job and summary (QueueName, UserName, StatTime, FinishTime, MAPS, REDUCERS and COUNTERS etc) after completion of execution.


3) Generate input data based on cluster size and create the synthetic jobs by using the 5 min MR High RAM jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = EchoUserResolver
GRIDMIX_SUBMISSION_POLICY = Replay
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false
Input Size = 300 MB * No. of nodes in cluster.
TRACE_FILE = 5 min folded trace.
Verify JobStatus for each job and summary (QueueName, UserName, StatTime, FinishTime, MAPS, REDUCERS and COUNTERS etc) after completion of execution."
MAPREDUCE-2203,Wong javadoc for TaskRunner's appendJobJarClasspaths method,"""{@link Configuration.getJar()})"" should be ""{@link JobConf.getJar()})"""
MAPREDUCE-2202,Generalize CLITest structure and interfaces to facilitate upstream adoption (e.g. for web or system testing),Counterpart of HADOOP-7014 and HDFS-1486
MAPREDUCE-2200,TestUmbilicalProtocolWithJobToken is failing without Krb evironment: needs to be conditional,TestUmbilicalProtocolWithJobToken requires Krb environment to be set. For testing some 'pseudo' environment is needed (similar to HDFS-1284). 
MAPREDUCE-2199,build is broken 0.22 branch creation,hdfs and common dep versions weren't updated properly.
MAPREDUCE-2198,Allow FairScheduler to control the number of slots on each TaskTracker,"We can set the number of slots on the TaskTracker to be high and let FairScheduler handles the slots.
This approach allows us to change the number of slots on each node dynamically.
The administrator can change the number of slots with a CLI tool.

One use case of this is for upgrading the MapReduce.
Instead of restarting the cluster, we can run the new MapReduce on the same cluster.
And use the CLI tool to gradually migrate the slots.
This way we don't lost the progress fo the jobs that's already executed."
MAPREDUCE-2195,New property for local conf directory in system-test-mapreduce.xml file.,As its counter-part HDFS-1167: new parameter needs to be added to the system-test configuration file to serve 'cluster restart with new  configuration' feature
MAPREDUCE-2194,Local mode seems to be broken in Cloudera's 737 release,"

We have upgraded our dev environment from Cloudera's 0.20.2-228-cloudera to 0.20.2-737-cloudera

Version 228 worked great for us. In version 737 we are getting the following exception:

(LocalJobRunner.java:295) - job_local_0005
java.lang.ClassCastException: org.apache.hadoop.mapreduce.lib.input.FileSplit cannot be cast to org.apache.hadoop.mapred.InputSplit
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:357)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:317)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:212)

We have tried to set job.getConfiguration().setBoolean(""mapred.reducer.new-api"", true) but that did not resolve the issue.

"
MAPREDUCE-2193,13 Findbugs warnings on trunk and branch-0.22,There are 13 findbugs warnings on trunk.  See attached html file.  These must be fixed or filtered out to get back to 0 warnings.  The OK_FINDBUGS_WARNINGS property in src/test/test-patch.properties should also be set to 0 in the patch that fixes this issue.
MAPREDUCE-2192,Implement gridmix system tests with different time intervals for MR streaming job traces.,"Develop gridmix system tests for below scenarios by using different time intervals of  MR streaming jobs.

1. Generate input data based on cluster size and create the synthetic jobs by using the 2 min folded MR streaming jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = LOADJOB
GRIDMIX_USER_RESOLVER = SubmitterUserResolver
GRIDMIX_SUBMISSION_POLICY = STRESS
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = True
Input Size = 250 MB * No. of nodes in cluster.
MINIMUM_FILE_SIZE=150MB
TRACE_FILE = 2 min folded trace.
Verify JobStatus for each job, input split size for each job and summary (QueueName, UserName, StatTime, FinishTime, maps, reducers and counters etc) after completion of execution.

2.  Generate input data based on cluster size and create the synthetic jobs by using the 3 min folded MR streaming jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = RoundRobinUserResolver
GRIDMIX_BYTES_PER_FILE = 150 MB
GRIDMIX_SUBMISSION_POLICY = REPLAY
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = True
Input Size = 200 MB * No. of nodes in cluster.
PROXY_USERS = proxy users file path
TRACE_FILE = 3 min folded trace.
Verify JobStatus for each job, input split size for each job and summary (QueueName, UserName, StatTime, FinishTime, maps, reducers and counters etc) after completion of execution.

3. Generate input data based on cluster size and create the synthetic jobs by using the 5 min MR streaming jobs trace and submit the jobs with below arguments.
GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = SubmitterUserResolver
GRIDMIX_SUBMISSION_POLICY = SERIAL
GRIDMIX_JOB_SUBMISSION_QUEUE_IN_TRACE = false
GRIDMIX_KEY_FRC = 0.5f
Input Size = 200MB * No. of nodes in cluster.
TRACE_FILE = 5 min folded trace.
Verify JobStatus for each job and summary (QueueName, UserName, StatTime, FinishTime, MAPS, REDUCERS and COUNTERS etc) after completion of execution."
MAPREDUCE-2191,Findbugs reports 13 warnings on trunk,"Findbugs reports 13 warnings on trunk:

Warning Type	Number
Bad practice Warnings	1
Correctness Warnings	5
Multithreaded correctness Warnings	6
Performance Warnings	1
Total	13
"
MAPREDUCE-2189,RAID Parallel traversal needs to synchronize stats,The implementation of multi-threaded directory traversal does not update stats in a thread-safe manner
MAPREDUCE-2188,The new API MultithreadedMapper doesn't call the initialize method of the RecordReader,"The wrapping RecordReader in the Multithreaded Mapper is never initialized. With HADOOP-6685, this becomes a problem because the ReflectionUtils.copy requires a non-null configuration."
MAPREDUCE-2187,map tasks timeout during sorting,"During the execution of a large job, the map tasks timeout:

{code}
INFO mapred.JobClient: Task Id : attempt_201010290414_60974_m_000057_1, Status : FAILED
Task attempt_201010290414_60974_m_000057_1 failed to report status for 609 seconds. Killing!
{code}

The bug is in the fact that the mapper has already finished, and, according to the logs, the timeout occurs during the merge sort phase.
The intermediate data generated by the map task is quite large. So I think this is the problem.

The logs show that the merge-sort was running for 10 minutes when the task was killed.
I think the mapred.Merger should call Reporter.progress() somewhere."
MAPREDUCE-2186,DistributedRaidFileSystem should implement getFileBlockLocations(),"If a RAIDed file has missing blocks, DistributedRaidFileSystem.getFileBlockLocations() would return no block locations. This could lead a client to believe that the file is not readable. But if parity data is available, the file actually is readable.

It would be better to implement getFileBlockLocations() and return the location of the parity blocks that would be needed to reconstruct the missing block."
MAPREDUCE-2185,Infinite loop at creating splits using CombineFileInputFormat,"This is caused by a missing block in HDFS. So the block's locations are empty. The following code adds the block to blockToNodes map but not to rackToBlocks map. Later on when generating splits, only blocks in rackToBlocks are removed from blockToNodes map. So blockToNodes map can never become empty therefore causing infinite loop

{code}
          // add this block to the block --> node locations map
          blockToNodes.put(oneblock, oneblock.hosts);

          // add this block to the rack --> block map
          for (int j = 0; j < oneblock.racks.length; j++) {
             ..
          }
{code}"
MAPREDUCE-2184,Port DistRaid.java to new mapreduce API,"DistRaid.java was implemented with the older mapred API, this task is for porting it to the new API"
MAPREDUCE-2183,Adding new target to build.xml to run test-core without compiling,"While testing Apache Harmony Select (lightweight version of Harmony) with Hadoop mapreduce we had to first build with Harmony and then test using Harmony Select using the test-core target. This was done in an effort to investigate any issues with Harmony Select in running common. However, the test-core target also compiles the classes which we are unable to do with Harmony Select. A new target is proposed that only runs the tests without compiling them."
MAPREDUCE-2180,Add coverage of fair scheduler servlet to system test,"MAPREDUCE-2051 added a system test for the fair scheduler which starts a minicluster and runs a couple jobs with preemption on. I recently found a deadlock in a previous version of the scheduler that was due to lock inversion between the scheduler servlet and some JT internals. I'd like to modify the existing system test to also hit the /scheduler servlet, allowing jcarder to detect such lock inversions in the future."
MAPREDUCE-2179,RaidBlockSender.java compilation fails,"

https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk/490/consoleFull


Mapreduce trunk compilation is broken with 

compile:
     [echo] contrib: raid
    [javac] Compiling 27 source files to /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/contrib/raid/classes
    [javac] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/datanode/RaidBlockSender.java:71: cannot find symbol
    [javac] symbol  : class BlockTransferThrottler
    [javac] location: class org.apache.hadoop.hdfs.server.datanode.RaidBlockSender
    [javac]   private BlockTransferThrottler throttler;
    [javac]           ^
    [javac] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/contrib/raid/src/java/org/apache/hadoop/hdfs/server/datanode/RaidBlockSender.java:377: cannot find symbol
    [javac] symbol  : class BlockTransferThrottler
    [javac] location: class org.apache.hadoop.hdfs.server.datanode.RaidBlockSender
    [javac]                  BlockTransferThrottler throttler) throws IOException {
    [javac]                  ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 2 errors"
MAPREDUCE-2178,Race condition in LinuxTaskController permissions handling,"The linux-task-controller executable currently traverses a directory heirarchy and calls chown/chmod on the files inside. There is a race condition here which can be exploited by an attacker, causing the task-controller to improprly chown an arbitrary target file (via a symlink) to the user running a MR job. This can be exploited to escalate to root.

[this issue was raised and discussed on the security@ list over the last couple of months]"
MAPREDUCE-2176,ant test-patch failing on a clean checkout,"ant test-patch fails for a dummy patch on CHANGES.txt:

{code}
     [exec] 
     [exec] -1 overall.  
     [exec] 
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec] 
     [exec]     -1 tests included.  The patch doesn't appear to include any new or modified tests.
     [exec]                         Please justify why no new tests are needed for this patch.
     [exec]                         Also please list what manual steps were performed to verify this patch.
     [exec] 
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec] 
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec] 
     [exec]     -1 findbugs.  The patch appears to introduce 13 new Findbugs warnings.
     [exec] 
     [exec]     -1 release audit.  The applied patch generated 3 release audit warnings (more than the trunk's current 1 warnings).
     [exec] 
     [exec]     +1 system test framework.  The patch passed system test framework compile.
     [exec] 
     [exec] 
     [exec] 
     [exec] 
     [exec] ======================================================================
     [exec] ======================================================================
     [exec]     Finished build.
     [exec] ======================================================================
     [exec] ======================================================================
     [exec] 
     [exec] 

BUILD FAILED
/data/users/rvadali/apache/hadoop-mapred-trunk/build.xml:1740: exec returned: 3

Total time: 13 minutes 14 seconds
Test results are in /tmp/rvadali.hadoopQA
[rvadali@dev502 hadoop-mapred-trunk]$ svn st 
?      build-fi
?      SecurityAuth.audit
?      lib/jdiff/hadoop-mapred_0.22.0-SNAPSHOT.xml
M      CHANGES.txt
X      src/test/bin


{code}"
MAPREDUCE-2175,speculation framework does not update job progress rate with time causing false speculation,"When considering task speculation - the job's overall progress rate for the given task type and the individual task's progress rate are compared. When doing so - the task's current progress rate is considered. However the job's overall progress rate is only only updated when a task's progress report is received.

This causes weirdness if a particular task does not report for a while. The job's progress rate is not updated - but the task's progress rate decays. For single task jobs - it causes speculation almost inevitably. 

We need to update the job's overall progress rate as the task's progress rate changes."
MAPREDUCE-2174,Introduce timeout in bin/slaves.sh,"If connection to one slave has problem, slaves.sh appears to hang.
We can incorporate timeout mechanism by using the script from Dmitry V Golovashkin"
MAPREDUCE-2173,Race condition in TestBlockFixer causes intermittent failure,TestBlockFixer sometimes fails in reportCorruptBlocks because a corrupt block is deleted before in.readFully is called. This causes a BlockMissingException instead of the expected ChecksumException.
MAPREDUCE-2172,test-patch.properties contains incorrect/version-dependent values of OK_FINDBUGS_WARNINGS and OK_RELEASEAUDIT_WARNINGS,"Running ant test-patch with an empty patch yields 25 findbugs warning and 3 release audit warnings (rather than the 0 findbugs warnings and 1 release audit warning specified in test-patch.properties):

{code}
[exec] -1 overall.  
[exec] 
[exec]     +1 @author.  The patch does not contain any @author tags.
[exec] 
[exec]     -1 tests included.  The patch doesn't appear to include any new or modified tests.
[exec]                         Please justify why no new tests are needed for this patch.
[exec]                         Also please list what manual steps were performed to verify this patch.
[exec] 
[exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
[exec] 
[exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
[exec] 
[exec]     -1 findbugs.  The patch appears to introduce 25 new Findbugs warnings.
[exec] 
[exec]     -1 release audit.  The applied patch generated 3 release audit warnings (more than the trunk's current 1 warnings).
[exec] 
[exec]     +1 system test framework.  The patch passed system test framework compile.
{code}"
MAPREDUCE-2169,Integrated Reed-Solomon code with RaidNode,Scott Chen recently checked in an implementation of  the Reed Solomon code. This task will track the integration of the code with RaidNode.
MAPREDUCE-2167,Faster directory traversal for raid node,"The RaidNode currently iterates over the directory structure to figure out which files to RAID. With millions of files, this can take a long time - especially if some files are already RAIDed and the RaidNode needs to look at parity files / parity file HARs to determine if the file needs to be RAIDed.

The directory traversal is encapsulated inside the class DirectoryTraversal, which examines one file at a time, using the caller's thread.

My proposal is to make this multi-threaded as follows:
 * use a pool of threads inside DirectoryTraversal
 * The caller's thread is used to retrieve directories, and each new directory is assigned to a thread in the pool. The worker thread examines all the files the directory.
 * If there sub-directories, those are added back as workitems to the pool.

Comments?"
MAPREDUCE-2166,"""map.input.file"" is not set","Hadoop does not set the ""map.input.file"" variable. I tried the fallowing and all I get is ""null"".

public class Map extends Mapper<Object, Text, LongWritable, Text> {

   public void map(Object key, Text value, Context context)
           throws IOException, InterruptedException {
       Configuration conf = context.getConfiguration();
       System.out.println(conf.get(""map.input.file""));
   }

   protected void setup(Context context) throws IOException,
           InterruptedException {
       Configuration conf = context.getConfiguration();
       System.out.println(conf.get(""map.input.file""));
   }
}
"
MAPREDUCE-2165,Add support for skipping records in streaming for new api.,
MAPREDUCE-2164,MapredTestDriver.java compilation fails on trunk,"compile-mapred-test:
    [mkdir] Created dir: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build/test/mapred/classes
    [mkdir] Created dir: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build/test/mapred/testjar
    [mkdir] Created dir: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build/test/mapred/testshell 
    [javac] Compiling 319 source files to /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build/test/mapred/classes
    [javac] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java:21: cannot find symbol
    [javac] symbol  : class TestSequenceFile
    [javac] location: package org.apache.hadoop.io
    [javac] import org.apache.hadoop.io.TestSequenceFile; 
    [javac]                            ^
    [javac] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java:59: cannot find symbol
    [javac] symbol  : class TestSequenceFile
    [javac] location: class org.apache.hadoop.test.MapredTestDriver
    [javac]       pgd.addClass(""testsequencefile"", TestSequenceFile.class, 
    [javac]                                        ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 errors"
MAPREDUCE-2159,Provide metrics for RaidNode,"It will be useful to have the following metrics for RAID:
 - files raided
 - files too new to be raided
 - files too small to be raided
 - number of blocks fixed using raid."
MAPREDUCE-2156,Raid-aware FSCK,"Currently, FSCK reports files as corrupt even if they can be fixed using parity blocks. We need a tool that only reports files that are irreparably corrupt (i.e., files for which too many data or parity blocks belonging to the same stripe have been lost or corrupted)."
MAPREDUCE-2155,RaidNode should optionally dispatch map reduce jobs to fix corrupt blocks (instead of fixing locally),"Recomputing blocks based on parity information is expensive. Rather than doing this locally at the RaidNode, we should run map reduce jobs. This will allow us to quickly fix a large number of corrupt or missing blocks."
MAPREDUCE-2153,Bring in more job configuration properties in to the trace file,"To emulate distributed cache usage in gridmix jobs, there are 9 configuration properties needed to be available in trace file: 
(1) mapreduce.job.cache.files
(2) mapreduce.job.cache.files.visibilities
(3) mapreduce.job.cache.files.filesizes
(4) mapreduce.job.cache.files.timestamps

(5) mapreduce.job.cache.archives
(6) mapreduce.job.cache.archives.visibilities
(7) mapreduce.job.cache.archives.filesizes
(8) mapreduce.job.cache.archives.timestamps

(9) mapreduce.job.cache.symlink.create

To emulate data compression in gridmix jobs, trace file should contain the following configuration properties:
(1) mapreduce.map.output.compress
(2) mapreduce.map.output.compress.codec
(3) mapreduce.output.fileoutputformat.compress
(4) mapreduce.output.fileoutputformat.compress.codec
(5) mapreduce.output.fileoutputformat.compress.type

Ideally, gridmix should set many job specific configuration properties like io.sort.mb, io.sort.factor, etc when running simulated jobs to get the same effect of original/real job in terms of spilled records, number of merges, etc.

TraceBuilder should bring in all these properties into the generated trace file."
MAPREDUCE-2151,[rumen] Add a map of jobconf key-value pairs in LoggedJob,It'd be useful to retain application level configuration settings in LoggedJob.
MAPREDUCE-2150,RaidNode should periodically fix corrupt blocks,"(Recreating HDFS-1171 since RAID is in mapreduce)

RaidNode currently does not fix missing blocks. The missing blocks have to be fixed using RaidShell.
This task proposes that recovery be more automated:
1. RaidNode periodically fetches a list of corrupt files from the NameNode
2. If the corrupt files can be fixed using RAID, it should generate the block.
3. Choose a datanode and send the block contents along with checksum to the datanode.
"
MAPREDUCE-2149,Distcp : setup with update is too slow when latency is high,"
If you run distcp with '-update' option, for _each of the files_ present on source cluster setup invokes a separate RPC to destination cluster to fetch file info. 
Usually this overhead is not very noticeable when both cluster are geographically close to each other. But if the latency is large, setup could take couple of orders of magnitude longer.

E.g. : source has 10k directories, each with about 10 files, round trip latency between source and destination is 75 ms (typical for coast-to-coast clusters). 
If we run distcp on source cluster, set up would take about _2.5 hours_ irrespective of whether destination has these files or not. '-lsr' on the same dest dir from source cluster would take up to 12 min (depending on how many directories already exist on dest). 

  * A fairly simple fix to how setup() iterates should bring the set up time to same as '-lsr'. I will have a patch for this.. (though 12 min is too large).
  * A more scalable option is to differ update check to mappers.

"
MAPREDUCE-2147,JobInProgress has some redundant lines in its ctor,"In the ctor of JobInProgress class that's used by the JT, lines that create the various lists of TIPs are repeated for no purpose. Might've been due to an overlook I think.

Attaching a patch that removes these unnecessary repeats of re-init."
MAPREDUCE-2146,Raid should not affect access time of a source file,"After a file is read for creating a raid parity file, the access time should be set back to the value before the read. The read by RAID code is not an application read and should not affect the access time."
MAPREDUCE-2145,upgrade clover on the builds servers to v 3.0.2,"upgrade clover on the builds servers to v 3.0.2, as the mr builds requires the latest version of clover for better coverage reporting..."
MAPREDUCE-2143,HarFileSystem is not able to handle spaces in its path,"If the Path to the HAR contains spaces, Path.getFileSystem() fails. The problem is in HarFileSystem.initialize(), which uses URI.toString() to get a string for getting to the .har suffix. URI.toString() returns a percent-encoded string when the path contains spaces. When this string is subsequently used to get the _index file, we get a FileNotFoundException. The fix is to use URI.getPath().
"
MAPREDUCE-2142,Refactor RaidNode to remove dependence on map reduce,"I am refactoring the RaidNode code as follows: The base class RaidNode will contain the common functionality needed for raiding files. The derived class LocalRaidNode contains an implementation of RaidNode that performs raiding locally. The derived class DistRaidNode performs raiding using map reduce jobs. This way, only DistRaidNode has a dependency on map reduce code and RaidNode and LocalRaidNode can be moved to HDFS."
MAPREDUCE-2141,"Add an ""extra data"" field to Task for use by Mesos","In order to support running Hadoop on the Mesos cluster manager (http://mesos.berkeley.edu/), I'd like to add an extra String field to the Task class to allow extra data (a Mesos task ID) to be associated with each task. This should have no impact on normal operation other than making the serialized form of Task a few bytes longer. In the Mesos support patch for Hadoop, this field is set by a pluggable Hadoop scheduler implementation to allow code on the TaskTracker side to see which Mesos task corresponds to each Hadoop task. "
MAPREDUCE-2140,Re-generate fair scheduler design doc PDF,"The Fair Scheduler contains a design document in src/contrib/fairscheduler/designdoc that is included both as a Latex file and as a PDF. However, the PDF that's currently there is not generated properly and has some question marks for section references. I'd like to regenerate it and commit the new one. There is no patch to attach because this just requires running pdflatex and committing a binary file."
MAPREDUCE-2138,"Gridmix tests with different time interval mr traces (1min, 3min and 5min).","1. Generate input data based on cluster size and create the synthetic jobs by using the 1 min folded MR trace and
submit the jobs with below arguments.

GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = SubmitterUserResolver
GRIDMIX_SUBMISSION_POLICY = STRESS
Input Size = 400 MB * No. of nodes in cluster.
TRACE_FILE = 1 min folded trace.
Verify each job status and summary(QueueName, UserName, StatTime, FinishTime, maps, reducers and counters etc) after
completion of execution.

2. Generate input data based on cluster size and create the synthetic jobs by using the 3 min folded MR trace and
submit the jobs with below arguments.

GRIDMIX_JOB_TYPE = LoadJob
GRIDMIX_USER_RESOLVER = RoundRobinUserResolver
GRIDMIX_SUBMISSION_POLICY = Replay
Input Size = 200 MB * No. of nodes in cluster.
TRACE_FILE = 3 min folded trace.
PROXY_USERS = proxy users file path.
Verify each job status, submitted user and summary(QueueName, UserName, StatTime, FinishTime, maps, reducers and
counters etc) after completion of execution.

3. Generate input data based on cluster size and create the synthetic jobs by using the 5 min folded MR trace and
submit the jobs with below arguments.

GRIDMIX_JOB_TYPE = SleepJob
GRIDMIX_USER_RESOLVER = EchoUserResolver
GRIDMIX_MIN_FILE = 100 MB
GRIDMIX_SUBMISSION_POLICY = Serial
Input Size = 300 MB * No. of nodes in cluster.
TRACE_FILE = 5 min folded trace.
Verify each job status, file size and summary(QueueName, UserName, StatTime, FinishTime, maps, reducers and counters
etc) after completion of execution.

"
MAPREDUCE-2137,Mapping between Gridmix jobs and the corresponding original MR jobs is needed,"Consider a trace file ""trace1"" obtained by running Rumen on a set of MR jobs' history logs. When gridmix runs simulated jobs from ""trace1"", it may skip some of the jobs from the trace file for some reason like out-of-order-jobs. Now use Rumen to generate trace2 from the history logs of gridmix's simulated jobs.
Now, to compare and analyze the gridmix's simulated jobs with original MR jobs, we need a mapping between them."
MAPREDUCE-2134,ant binary-system is broken in mapreduce project.,"Build failed due to unable to copy the commons instrumented jar. I could see the following error in the log.

binary-system:
     [copy] Copying 5 files to /home/vinay/mapreduce/build-fi/system/hadoop-mapred-0.22.0-SNAPSHOT

BUILD FAILED
/home/vinay/mapreduce/build.xml:1307: Warning: Could not find file /home/vinay/mapreduce/build-fi/ivy/lib/Hadoop/system/hadoop-common-instrumented-0.22.0-SNAPSHOT.jar to copy.


It's pointing to the wrong path to copy the file. Actually the correct path is,

/home/vinay/mapreduce/build-fi/system/ivy/Hadoop/system


"
MAPREDUCE-2132,Need a command line option in RaidShell to fix blocks using raid,"RaidShell currently has an option to recover a file and return the path to the recovered file. The administrator can then rename the recovered file to the damaged file.

The problem with this is that the file metadata is altered, specifically the modification time. Instead we need a way to just repair the damaged blocks and send the fixed blocks to a data node.

Once this is done, we can put automation around it."
MAPREDUCE-2130,Better distribution of files among DistRaid map tasks,Currently the map tasks get a random subset of the files to be raided. But a disproportionately large file could make a map task extremely slow. We need to give approximately the same amount of data to each map task.
MAPREDUCE-2129,Job may hang if mapreduce.job.committer.setup.cleanup.needed=false and mapreduce.map/reduce.failures.maxpercent>0,Job may hang at RUNNING state if mapreduce.job.committer.setup.cleanup.needed=false and mapreduce.map/reduce.failures.maxpercent>0. It happens when some tasks fail but havent reached failures.maxpercent.
MAPREDUCE-2128,Add alternative search-provider to site,"Use search-hadoop.com service to make available search in sources, MLs, wiki, etc.
This was initially proposed on user mailing list. The search service was already added in site's skin (common for all Hadoop related projects) before so this issue is about enabling it for MapReduce."
MAPREDUCE-2127,mapreduce trunk builds are failing on hudson,"https://hudson.apache.org/hudson/job/Hadoop-Mapreduce-trunk-Commit/507/console

[exec] checking for pthread.h... yes
     [exec] checking for pthread_create in -lpthread... yes
     [exec] checking for HMAC_Init in -lssl... no
     [exec] configure: error: Cannot find libssl.so
     [exec] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/src/c++/pipes/configure: line 4250: exit: please: numeric argument required
     [exec] /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/src/c++/pipes/configure: line 4250: exit: please: numeric argument required

BUILD FAILED
/grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build.xml:1647: exec returned: 255
"
MAPREDUCE-2126,JobQueueJobInProgressListener's javadoc is inconsistent with source code,"JobQueueJobInProgressListener.java has {@link #JobQueueJobInProgressListener(Collection)} in Javadoc. But it does not have the corresponding constructor. It has constructor JobQueueJobInProgressListener(Map<JobSchedulingInfo, JobInProgress> jobQueue). So {@link JobQueueJobInProgressListener(Collection)} should be {@link #JobQueueJobInProgressListener(Map)}."
MAPREDUCE-2123,Multiple threads per JVM,"I have a process that standardizes name and place strings, and requires access to java objects that require a lot of RAM (800MB).  Hadoop (via Amazon elastic mapreduce) was running out of memory, because it was firing up one JVM per task per slave.  Each JVM needed 1.5GB, and 6 of those blew out memory.

In this case, we don't need 6 different JVMs running--we only need one, but with multiple threads.  I tried using a MultithreadedMapper, but it doesn't have a thread-safe ""run()"" method: it makes 3 calls to the input source to read one ""line"", which doesn't work if multiple threads are doing that.  So I had to override the run() method.  I ended up having to do so much work to override the run() method that it was simpler to skip using the MultithreadedMapper at all.  Instead, I took my original mapper and just overrode the run() method there directly.  I fired up n threads, each of which called a method that had a synchronized(mutex) around the part of the process that made the three calls to an input source to get the next line to operate on.  Then, outside of the synchronized block, it called the map() method, which made use of the large, shared (singleton) standardization object.

All of this made me wonder why hadoop fires up multiple JVMs per slave in the first place--that is a lot of overhead to use per thread.   I've also been warned that doing continual reuse of JVMs instead of restarting one per task will use up more memory.  That seems like it should only be true if hadoop (or our mapper) is leaking memory.  If that's the case, let's get it fixed.

My guess is that since hadoop can run tasks in languages other than Java--and since other languages may have less overhead per process--that firing up a JVM per task (or per thread) simplifies hadoop.  But the multithreaded solution we did was very general-purpose.  It seems like it ought to be pretty much the default solution in java, and that a ""...map.threads"" property should be all that is required to fire up that many threads to help with each task, rather than have to jump through the hoops we had to.

Below is the implementation that seems to be working:

In the main class:
    Configuration config = getConf();
    config.set(""num_threads_per_jvm"", Integer.toString(numThreads));
    Job job = new Job(config, ""Standardize stuff"");

In the Mapper class:
  public void run(final Context context) throws IOException, InterruptedException {
    int numThreads = Integer.parseInt(context.getConfiguration().get(""num_threads_per_jvm"");
    setup(context); // setup and cleanup just once, rather than once per thread
    List<MapRunner> mapRunners = new ArrayList<MapRunner>();
    for (int i = 0; i < numThreads; i++) {
      MapRunner mapRunner = new MapRunner(context, i);
      mapRunners.add(mapRunner);
      mapRunner.start();
    }
     // Wait for all the threads to complete
    for (MapRunner mapRunner : mapRunners) {
      mapRunner.join();
    }
    cleanup(context);
  }

  private class MapRunner extends Thread {
    final Context context;

    private MapRunner(Context context) {
      this.context = context;
    }

    @Override
    public void run() {
      boolean gotValue = true;
      do {
        try {
          Text key = null;
          Text value = null;
          synchronized(contextMutex) {
            gotValue = context.nextKeyValue();
            if (gotValue) {
              key = context.getCurrentKey();
              value = context.getCurrentValue();
            }
          }
          if (gotValue) {
            map(key, value, context);
          }
        } catch (Exception e) {
          throw new RuntimeException(e);
        }
      } while (gotValue);
    }
  }"
MAPREDUCE-2121,TestControlledMapReduceJob times out on trunk.,"TestControlledMapReduceJob times out on trunk. Logs show the following ArrayIndexOutOfBoundsException:
{noformat} 
java.lang.ArrayIndexOutOfBoundsException: 0
    [junit]     at org.apache.hadoop.mapred.ControlledMapReduceJob.map(ControlledMapReduceJob.java:302)
    [junit]     at org.apache.hadoop.mapred.ControlledMapReduceJob.map(ControlledMapReduceJob.java:60)
    [junit]     at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:54)
    [junit]     at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:397)
    [junit]     at org.apache.hadoop.mapred.MapTask.run(MapTask.java:330)
    [junit]     at org.apache.hadoop.mapred.Child$4.run(Child.java:223)
    [junit]     at java.security.AccessController.doPrivileged(Native Method)
    [junit]     at javax.security.auth.Subject.doAs(Subject.java:396)
    [junit]     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1114)
    [junit]     at org.apache.hadoop.mapred.Child.main(Child.java:217)
{noformat}"
MAPREDUCE-2120,TestGridmixSubmission consumes a lot of time.,TestGridmixSubmission consumes a lot of time. It took 582 seconds on my machine. The test time should be improved.
MAPREDUCE-2119,many unit tests with SequenceFiles fail on trunk,"The following tests are failing in trunk :
* TestSequenceFile
* TestSequenceFileInputFormat
* TestSequenceFileAsTextInputFormat
* TestSequenceFileInputFilter
* TestMRSequenceFileAsTextInputFormat
* TestMRSequenceFileInputFilter
"
MAPREDUCE-2115,[GridMix] Add emulation plugin support in GridMix,"Currently, GridMix faithfully emulates I/O load. We are working towards adding CPU and Memory emulation to GridMix. These emulation points or load types can be better visualized as load/emulation plugins (_emulins_). GridMix, as a framework, should provide support for various such _emulins_. A GridMix user can now select a set of _emulins_ based on the load to be simulated. "
MAPREDUCE-2114,user finer grained locks in JT getCounters implementation,"We are bound on the JobTracker lock on our largest cluster. One pattern i have seen is the following:

- JT acquires JobTracker lock - but blocked on JIP lock:

java.lang.Thread.State: BLOCKED (on object monitor)
at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1028)
  waiting to lock <0x00002aae21092ff8> (a org.apache.hadoop.mapred.JobInProgress)
at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:4403)
at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3444)
  locked <0x00002aab6ebb6640> (a org.apache.hadoop.mapred.JobTracker)

- the JIP lock is typically held by a getcounters call:

  locked <0x00002aaaf88beff8> (a org.apache.hadoop.mapred.Counters$Group)
at org.apache.hadoop.mapred.Counters.incrAllCounters(Counters.java:445)
  locked <0x00002aaaf88bb948> (a org.apache.hadoop.mapred.Counters)
at org.apache.hadoop.mapred.JobInProgress.incrementTaskCounters(JobInProgress.java:1253)
at org.apache.hadoop.mapred.JobInProgress.getCounters(JobInProgress.java:1240)
  locked <0x00002aae21092ff8> (a org.apache.hadoop.mapred.JobInProgress)

the solution seems simple. in order to summarize the counters for all tasks - we need to only lock one task's counters at a time. we don't need to lock the entire job. "
MAPREDUCE-2113,SequenceFile tests assume createWriter w/ overwrite,"Many of the {{\*SequenceFile}} tests create writers in a loop. This fails after HADOOP-6856, which will not overwrite the destination by default."
MAPREDUCE-2111,make getPathInHar public in HarFileSystem,"This patch makes getPathInHar public in HarFileSystem allowing us to retrieve the local path name of a file stored within a HAR archive. This is useful for maintaining HAR archives within the context of RAID.

Index: src/tools/org/apache/hadoop/fs/HarFileSystem.java
===================================================================
--- src/tools/org/apache/hadoop/fs/HarFileSystem.java   (revision 1004421)
+++ src/tools/org/apache/hadoop/fs/HarFileSystem.java   (working copy)
@@ -278,7 +278,7 @@
    * @param path the fully qualified path in the har filesystem.
    * @return relative path in the filesystem.
    */
-  private Path getPathInHar(Path path) {
+  public Path getPathInHar(Path path) {
     Path harPath = new Path(path.toUri().getPath());
     if (archivePath.compareTo(harPath) == 0)
       return new Path(Path.SEPARATOR);"
MAPREDUCE-2110,add getArchiveIndex to HarFileSystem,"This patch adds a public getter for archiveIndex to HarFileSystem, allowing us to access the index file corresponding to a har file system (useful for raid).

Index: src/tools/org/apache/hadoop/fs/HarFileSystem.java
===================================================================
--- src/tools/org/apache/hadoop/fs/HarFileSystem.java   (revision 1004421)
+++ src/tools/org/apache/hadoop/fs/HarFileSystem.java   (working copy)
@@ -759,6 +759,13 @@
   }
   
   /**
+   * returns the archive index
+   */
+  public Path getArchiveIndex() {
+    return archiveIndex;
+  }
+
+  /**
    * return the top level archive path.
    */
   public Path getHomeDirectory() {"
MAPREDUCE-2109,Add support for reading multiple hadoop delegation token files,This is the MR part of HADOOP-6988.
MAPREDUCE-2108,Allow TaskScheduler manage number slots on TaskTrackers,"Currently the map slots and reduce slots are managed by TaskTracker configuration.
To change the task tracker slots, we need to restart the TaskTrackers.
Also, for a non-uniform cluster, we have to deploy different sets of configuration.

Now JobTracker holds the CPU and memory status of TaskTrackers (MAPREDUCE-1218).
So it makes sense to just let JobTracker.taskScheduler decided the number of slots on each node.
This way we can
1. Change the number of slots dynamically without restarting TaskTracker
2. Use different number of slots based on the resource of a TaskTracker

To achieve this, we need to change the logic that we use totalMapSlots and totalReduceSlots in JobTracker.
I think they are used in WebUI and speculativeCap.

We will need to make JobTracker calculate these numbers from TaskScheduler and TaskTrackerStatus.
TaskScheduler and TaskTracker can both hold their maximum slots. We pick the smaller one.

Thoughts?"
MAPREDUCE-2107,Emulate Memory Usage of Tasks in GridMix3,"MAPREDUCE-220 makes CPU/Memory usage of Tasks available in JobHistory files. Use this
to emulate the memory usage of Tasks (of course, once MAPREDUCE-2104 is done)."
MAPREDUCE-2106,Emulate CPU Usage of Tasks in GridMix3,"MAPREDUCE-220 makes CPU/Memory usage of Tasks available in JobHistory files. Use this
to emulate the CPU usage of Tasks (of course, once MAPREDUCE-2104 is done)."
MAPREDUCE-2105,Simulate Load Incrementally and Adaptively in GridMix3,"Tasks launched by GridMix3 should incrementally and adaptively simulate load (I/O, CPU, memory, etc.) rather than doing
everything upfront and then sleeping. This helps in evening out the load when fine-grained information from the original
Task is not available and greater accuracy when it is.

By ""incremental"" I mean having several iterations corresponding to appropriate phases/time-slices. By ""adaptive"" I mean
taking the existing load into account before inflicting additional load to meet a target load (we are unlikely to achieve
100% fidelity as we overshoot or undershoot with each iteration)."
MAPREDUCE-2104,Rumen TraceBuilder Does Not Emit CPU/Memory Usage Details in Traces,"Via MAPREDUCE-220, we now have CPU/Memory usage information in MapReduce JobHistory files. However, Rumen's TraceBuilder
does not emit this information in the JSON traces. Without this information, GridMix3 cannot emulate CPU/Memory usage correctly."
MAPREDUCE-2103,task-controller shouldn't require o-r permissions,"The task-controller currently checks that ""other"" users don't have read permissions. This is unnecessary - we just need to make it's not executable. The debian policy manual explains it well:

{quote}
Setuid and setgid executables should be mode 4755 or 2755 respectively, and owned by the appropriate user or group. They should not be made unreadable (modes like 4711 or 2711 or even 4111); doing so achieves no extra security, because anyone can find the binary in the freely available Debian package; it is merely inconvenient. For the same reason you should not restrict read or execute permissions on non-set-id executables.

Some setuid programs need to be restricted to particular sets of users, using file permissions. In this case they should be owned by the uid to which they are set-id, and by the group which should be allowed to execute them. They should have mode 4754; again there is no point in making them unreadable to those users who must not be allowed to execute them.
{quote}"
MAPREDUCE-2101,compile-mapred-test broken in trunk,"r1002905 seems to have caused it.

{code}
compile-mapred-test:
    [mkdir] Created dir: /data/users/rvadali/apache/hadoop-mapred-trunk-2/build/test/mapred/classes
    [mkdir] Created dir: /data/users/rvadali/apache/hadoop-mapred-trunk-2/build/test/mapred/testjar
    [mkdir] Created dir: /data/users/rvadali/apache/hadoop-mapred-trunk-2/build/test/mapred/testshell
    [javac] /data/users/rvadali/apache/hadoop-mapred-trunk-2/build.xml:587: warning: 'includeantruntime' was not set, defaulting to build.sysclasspath=last; set to false for repeatable builds
    [javac] Compiling 320 source files to /data/users/rvadali/apache/hadoop-mapred-trunk-2/build/test/mapred/classes
    [javac] /data/users/rvadali/apache/hadoop-mapred-trunk-2/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java:62: cannot find symbol
    [javac] symbol  : method getRpcServer(org.apache.hadoop.hdfs.server.namenode.NameNode)
    [javac] location: class org.apache.hadoop.hdfs.server.namenode.NameNodeAdapter
    [javac]       Set<Class<?>> protocolsWithAcls = NameNodeAdapter.getRpcServer(dfs.getNameNode())
    [javac]                                                        ^
    [javac] /data/users/rvadali/apache/hadoop-mapred-trunk-2/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java:79: cannot find symbol
    [javac] symbol  : method getRpcServer(org.apache.hadoop.hdfs.server.namenode.NameNode)
    [javac] location: class org.apache.hadoop.hdfs.server.namenode.NameNodeAdapter
    [javac]       protocolsWithAcls = NameNodeAdapter.getRpcServer(dfs.getNameNode())
    [javac]                                          ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 errors

BUILD FAILED
/data/users/rvadali/apache/hadoop-mapred-trunk-2/build.xml:518: The following error occurred while executing this line:
/data/users/rvadali/apache/hadoop-mapred-trunk-2/build.xml:587: Compile failed; see the compiler error output for details.


{code}"
MAPREDUCE-2099,RaidNode should recreate outdated parity HARs,"After parity files are archived into a parity HAR, a change in the source file does not cause the HAR to be recreated. Instead, individual parity files are created for the modified files but the HAR is not touched. This causes increased disk usage for parity data.

The parity HAR could be recreated if a certain percentage of files in the HAR are determined to be outdated.

"
MAPREDUCE-2098,Extra url encoding makes jobdetailshistory.jsp report FileNotFoundException,"In cdh3b2, when viewing :50030/jobdetailshistory.jsp?jobid=job_201009172356_0007&logFile=file%3A%2Fopt%2Fmsip%2Fclients%2FCIQ-Performance%2Fm2mDeployment%2Fhadoop%2Flogs%2Fhistory%2Fdone%2Fus01-ciqps1-name01.carrieriq.com_1284767796615_job_201009172356_0007_hadoop_flow-dca_evdo_m2m_trunk-4%252B%252523%252BpppEndFiltering-job%252B%252528d, we got:

java.io.FileNotFoundException: File file:/opt/msip/xxx/hadoop/logs/history/done/us01-ciqps1-name01.com_1284767796615_job_201009172356_0007_hadoop_flow-dca_evdo_m2m_trunk-4%2B%2523%2BpppEndFiltering-job%2B%2528d does not exist.
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:372)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:251)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.(ChecksumFileSystem.java:126)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:284)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:398)
	at org.apache.hadoop.mapred.JobHistory.parseHistoryFromFS(JobHistory.java:405)
	at org.apache.hadoop.mapred.DefaultJobHistoryParser.parseJobTasks(DefaultJobHistoryParser.java:50)
	at org.apache.hadoop.mapred.loadhistory_jsp._jspService(loadhistory_jsp.java:89)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.servlet.Dispatcher.include(Dispatcher.java:192)
	at org.apache.jasper.runtime.JspRuntimeLibrary.include(JspRuntimeLibrary.java:966)
	at org.apache.hadoop.mapred.jobdetailshistory_jsp._jspService(jobdetailshistory_jsp.java:57)
	at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:97)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:820)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:502)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:363)
	at org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:216)
	at org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:181)
	at org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:766)
	at org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:417)
	at org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:230)
	at org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:152)
	at org.mortbay.jetty.Server.handle(Server.java:324)
	at org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:534)
	at org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:864)
	at org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:533)
	at org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:207)
	at org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:403)
	at org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:409)
	at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:522)

But us01-ciqps1-name01.carrieriq.com_1284767796615_job_201009172356_0007_hadoop_flow-dca_evdo_m2m_trunk-4+%23+pppEndFiltering-job+%28d exists under hadoop/logs/history/done

The issue was due to double encoding.
In jobhistory.jsp, line 237:
      String encodedJobFileName =
          JobHistory.JobInfo.encodeJobHistoryFileName(jobFile.getName());

Then MAPREDUCE-1378 encodes the filename again.
"
MAPREDUCE-2096,Secure local filesystem IO from symlink vulnerabilities,"This JIRA is to contribute a patch developed on the private security@ mailing list.

The vulnerability is that MR daemons occasionally open files that are located in a path where the user has write access. A malicious user may place a symlink in place of the expected file in order to cause the daemon to instead read another file on the system -- one which the attacker may not naturally be able to access. This includes delegation tokens belong to other users, log files, keytabs, etc."
MAPREDUCE-2095,Gridmix unable to run for compressed traces(.gz format).,"I was trying to run gridmix with compressed trace file.However, it throws a JsonParseException and exit.

exception details:
==================
org.codehaus.jackson.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n,
\t) is allowed between tokens
 at [Source: org.apache.hadoop.fs.FSDataInputStream@17ba38f; line: 1, column: 2]
        at org.codehaus.jackson.impl.JsonParserBase._constructError(JsonParserBase.java:651)
        at org.codehaus.jackson.impl.JsonParserBase._reportError(JsonParserBase.java:635)
        at org.codehaus.jackson.impl.JsonParserBase._throwInvalidSpace(JsonParserBase.java:596)
        at org.codehaus.jackson.impl.Utf8StreamParser._skipWSOrEnd(Utf8StreamParser.java:981)
        at org.codehaus.jackson.impl.Utf8StreamParser.nextToken(Utf8StreamParser.java:77)
        at org.codehaus.jackson.map.ObjectMapper._initForReading(ObjectMapper.java:688)
        at org.codehaus.jackson.map.ObjectMapper._readValue(ObjectMapper.java:624)
        at org.codehaus.jackson.map.ObjectMapper.readValue(ObjectMapper.java:275)
        at org.apache.hadoop.tools.rumen.JsonObjectMapperParser.getNext(JsonObjectMapperParser.java:84)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:117)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:29)
        at org.apache.hadoop.mapred.gridmix.JobFactory.getNextJobFiltered(JobFactory.java:174)
        at org.apache.hadoop.mapred.gridmix.StressJobFactory$StressReaderThread.run(StressJobFactory.java:166)
10/09/23 09:43:17 ERROR gridmix.Gridmix: Error in trace
org.codehaus.jackson.JsonParseException: Illegal character ((CTRL-CHAR, code 31)): only regular white space (\r, \n,
\t) is allowed between tokens
 at [Source: org.apache.hadoop.fs.FSDataInputStream@17ba38f; line: 1, column: 2]
        at org.codehaus.jackson.impl.JsonParserBase._constructError(JsonParserBase.java:651)
        at org.codehaus.jackson.impl.JsonParserBase._reportError(JsonParserBase.java:635)
        at org.codehaus.jackson.impl.JsonParserBase._throwInvalidSpace(JsonParserBase.java:596)
        at org.codehaus.jackson.impl.Utf8StreamParser._skipWSOrEnd(Utf8StreamParser.java:981)
        at org.codehaus.jackson.impl.Utf8StreamParser.nextToken(Utf8StreamParser.java:77)
        at org.codehaus.jackson.map.ObjectMapper._initForReading(ObjectMapper.java:688)
        at org.codehaus.jackson.map.ObjectMapper._readValue(ObjectMapper.java:624)
        at org.codehaus.jackson.map.ObjectMapper.readValue(ObjectMapper.java:275)
        at org.apache.hadoop.tools.rumen.JsonObjectMapperParser.getNext(JsonObjectMapperParser.java:84)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:117)
        at org.apache.hadoop.tools.rumen.ZombieJobProducer.getNextJob(ZombieJobProducer.java:29)
        at org.apache.hadoop.mapred.gridmix.JobFactory.getNextJobFiltered(JobFactory.java:174)
        at org.apache.hadoop.mapred.gridmix.StressJobFactory$StressReaderThread.run(StressJobFactory.java:166)
10/09/23 09:43:17 INFO gridmix.Gridmix: Exiting...
"
MAPREDUCE-2094,"LineRecordReader should not seek into non-splittable, compressed streams.","When implementing a custom derivative of FileInputFormat we ran into the effect that a large Gzipped input file would be processed several times. 

A near 1GiB file would be processed around 36 times in its entirety. Thus producing garbage results and taking up a lot more CPU time than needed.

It took a while to figure out and what we found is that the default implementation of the isSplittable method in [org.apache.hadoop.mapreduce.lib.input.FileInputFormat | http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/java/org/apache/hadoop/mapreduce/lib/input/FileInputFormat.java?view=markup ] is simply ""return true;"". 

This is a very unsafe default and is in contradiction with the JavaDoc of the method which states: ""Is the given filename splitable? Usually, true, but if the file is stream compressed, it will not be. "" . The actual implementation effectively does ""Is the given filename splitable? Always true, even if the file is stream compressed using an unsplittable compression codec. ""

For our situation (where we always have Gzipped input) we took the easy way out and simply implemented an isSplittable in our class that does ""return false; ""

Now there are essentially 3 ways I can think of for fixing this (in order of what I would find preferable):
# Implement something that looks at the used compression of the file (i.e. do migrate the implementation from TextInputFormat to FileInputFormat). This would make the method do what the JavaDoc describes.
# ""Force"" developers to think about it and make this method abstract.
# Use a ""safe"" default (i.e. return false)"
MAPREDUCE-2093,Herriot JT and TT clients should vend statistics,Mapreduce counterpart of HDFS-1408
MAPREDUCE-2092,Trunk can't be compiled,"Compilation of the trunk is broken because of an attempt to call
{{ServiceAuthorizationManager.refresh}} from a static content. 
0.21 branch seems to be Ok."
MAPREDUCE-2091,Map/Reduce Build Failing due to missing Smoke Tests,"The Compilation (the ANT clean and tar directives) of the Map/Reduce  Project works fine, but the test-core directive fails because the smoke tests are missing. This is the tail of the build log:

    [junit] Running org.apache.hadoop.mapreduce.TestMapReduceLocal
    [junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 57.962 sec
    [junit] Running org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
    [junit] Tests run: 2, Failures: 0, Errors: 0, Time elapsed: 1.839 sec
    [junit] Running org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter
    [junit] Tests run: 3, Failures: 0, Errors: 0, Time elapsed: 0.866 sec

checkfailure:

run-smoke-test:
   [delete] Deleting directory /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/data
    [mkdir] Created dir: /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/data
   [delete] Deleting directory /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/logs
    [mkdir] Created dir: /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build/test/logs

BUILD FAILED
/home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build.xml:749: The following error occurred while executing this line:
/home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/build.xml:658: Excludesfile /home/hadoop/Hadoop-Versions/hadoop-0.21.0/mapreduce/src/test/smoke-tests not found.

The fastest way to reproduce this error is to run : ""ant run-test-mapred-excluding-commit-and-smoke""
"
MAPREDUCE-2090,Clover build doesn't generate per-test coverage,Because of the way the structure of Hadoop's builds is done Clover can't properly detect test classes among the sources. As the result clover reports are incomplete and do not provide viral per-test coverage info.
MAPREDUCE-2086,CHANGES.txt does not reflect the release of version 0.21.0.,"CHANGES.txt should show the release date for 0.21.0 and include section for for 0.21.1 - Unreleased. Latest changes, that did not make into 0.21.0, should be moved under 0.21.1 section."
MAPREDUCE-2084,Deprecated org.apache.hadoop.util package in MapReduce produces deprecations in Common classes in Eclipse,"As reported in [this thread|http://mail-archives.apache.org/mod_mbox/hadoop-mapreduce-user/201009.mbox/%3C4C9A0A08.3030901@web.de%3E] the classes in org.apache.hadoop.util from the Common JAR, like Tool, are marked as deprecated by Eclipse, even though they are not deprecated. The fix is to mark the individual classes in the MapReduce org.apache.hadoop.util class as deprecated, not the whole package."
MAPREDUCE-2083,Run partial reduce instead of combiner at reduce node to overlap shuffle delay with reduce,"Shuffle delays can be large for mapreductions with lots of intermediate data. Some of this shuffle delay can be overlapped with reduce if some of the reduce computation is started on partial intermediate data received by a reduce. Along these lines, the patch ??HADOOP-3226?? runs the combiner on the reduce side to prune the data that goes to reduce. However, ??HADOOP-3226?? does not achieve our goal of overlap with the shuffle because: 
(1) In its original use of reducing intermediate data volume, the combiner falls in the critical path at the map side. Therefore, the combiner is usually a simple function which is too  lightweight in its new use to achieve sufficient overlap with the shuffle. 
(2) Running the combiner  at the reduce side is helpful in overlapping with the shuffle only if  the combiner's functionality is a major portion of the reduce functionality --  otherwise running the combiner at the reduce side achieves only modest overlap with the shuffle. In many mapreductions, the combiner computation is often not part or only a small part of reduce computation. Addressing both these points, reduces that are complex often have heavier-weight computation than simple combining that can be overlapped with the shuffle. This heavy-weight computation is specified by a user-supplied ""partial reduce"" which performs the commutative/associative parts of reduce. The idea is to run partial reduce on subsets of intermediate data as they arrive at a reduce to  overlap with the shuffle, and then run the full-blown final reduce which re-reduces the partially-reduced data. Because the shuffle delay is large  for shuffle-heavy mapreductions, partial reduce that are heavier-weight than simple combiner can be hidden under the shuffle delay without extending the critical path of execution. 
Finally, to further ensure that the partial reduce does not extend the critical path, we need to include two easily-tunable thresholds: One to start partial reduce only after enough intermediate data has been received (e.g. use mapred.inmem.merge.threshold or a separately defined parameter) so that we do not incur the overhead of invoking partial reduce on small data. Another threshold to stop partial reduce after most of the intermediate data has been received so that running partial reduce on the small remainder data does not delay starting final reduce."
MAPREDUCE-2082,Race condition in writing the jobtoken password file when launching pipes jobs,"In Application.java, when jobtoken password file is written, there is a race condition because the file is written in job's work directory. The file should rather be written in the task's working directory."
MAPREDUCE-2081,[GridMix3] Implement functionality for get the list of job traces which has different intervals.,"Girdmix system tests should require different job traces with different time intervals for generate and submit the gridmix jobs. So, implement a functionaliy for getting the job traces and arrange them in hash table with time interval as key.Also getting the list of traces from resource location irrespective of time. The following methods needs to implement.

Method signature:
public static Map <String, String> getMRTraces(Configuration conf)  throws IOException; - it get the traces with time intervals from resources default location.

public static Map <String, String> getMRTraces(Configuration conf,Path path)  throws IOException; - it get the traces with time intervals from user specified resource location.


public static List<String> listMRTraces(Configuration conf) throws IOException  -it list all the traces from resource default location irrespective of time interval.

public static List<String> listMRTraces(Configuration conf, Path tracesPath) throws IOException - it list all the traces from user specified user location irrespective of  time interval.

public static List<String> listMRTracesByTime(Configuration conf, String timeInterval) throws IOException - it list all traces of a given time interval from default resource location.

public static List<String> listMRTracesByTime(Configuration conf, String timeInterval,Path path) throws IOException - it list all traces of a given time interval from a given resources location.
"
MAPREDUCE-2080,Reducer JVM process hangs,"We use cdh3b2

After reducer took more than 600 seconds to report to tasktracker, tasktracker tried to kill it.
However reducer JVM process hung.

Attaching stack trace of reducer."
MAPREDUCE-2078,TraceBuilder unable to generate the traces while giving the job history path by globing.,"I was trying to generate the traces for MR job histories by using TraceBuilder. However, it's unable to generate the traces while giving the job history path by globing. It throws a file not found exception even though the job history path is exists.

I have provide the job history path in the below way.

hdfs://<<clustername>>/dir1/dir2/dir3/*/*/*/*/*/*/

Exception:

java.io.FileNotFoundException: File does not exist:
hdfs://<<clustername>>/dir1/dir2/dir3/*/*/*/*/*/*
        at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:525)
        at org.apache.hadoop.tools.rumen.TraceBuilder$MyOptions.<init>(TraceBuilder.java:88)
        at org.apache.hadoop.tools.rumen.TraceBuilder.run(TraceBuilder.java:183)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.tools.rumen.TraceBuilder.main(TraceBuilder.java:121)

It's truncating the last  slash in the path.
"
MAPREDUCE-2077,Name clash in the deprecated o.a.h.util.MemoryCalculatorPlugin,"Name clash compile error in the deprecated org.apache.hadoop.util.MemoryCalculatorPlugin due to JLS3 8.4.8.3 (cf. http://bugs.sun.com/view_bug.do?bug_id=6182950)

The bug doesn't manifest in jdk 1.6 up to 20, but shows up in NetBeans 6.9+ due to its bundled (conforming) compiler. Fix is trivial: just remove the offending method in the deprecated subclass as its equivalent erasure is inherited from the parent class anyway."
MAPREDUCE-2076,Showing inputsplit filename/offset inside the webui or tasklog,"For debugging purposes, it would be nice to have inputsplit's  filename and offset for FileInputFormat and alike.
(in addition to input split's node list that is already shown)
"
MAPREDUCE-2075,Show why the job failed  (e.g. Job ___ failed because task ____ failed 4 times),"When our users have questions about their jobs' failure, they tend to copy&paste all the userlog exceptions they see on the webui/console.  However, most of them are not the one that caused the job to fail.   When we tell them 'This task failed 4 times"", sometimes that's enough information for them to solve the problem on their own.

It would be nice if jobclient or job status page shows the reason for the job being flagged as fail.
"
MAPREDUCE-2074,Task should fail when symlink creation fail,"If I pass an invalid symlink as   -Dmapred.cache.files=/user/knoguchi/onerecord.txt#abc/abc

Task only reports a WARN and goes on.

{noformat} 
2010-09-16 21:38:49,782 INFO org.apache.hadoop.mapred.TaskRunner: Creating symlink: /0/tmp/mapred-local/taskTracker/knoguchi/distcache/-5031501808205559510_-128488332_1354038698/abc-nn1.def.com/user/knoguchi/onerecord.txt <- /0/tmp/mapred-local/taskTracker/knoguchi/jobcache/job_201008310107_15105/attempt_201008310107_15105_m_000000_0/work/./abc/abc
2010-09-16 21:38:49,789 WARN org.apache.hadoop.mapred.TaskRunner: Failed to create symlink: /0/tmp/mapred-local/taskTracker/knoguchi/distcache/-5031501808205559510_-128488332_1354038698/abc-nn1.def.com/user/knoguchi/onerecord.txt <- /0/tmp/mapred-local/taskTracker/knoguchi/jobcache/job_201008310107_15105/attempt_201008310107_15105_m_000000_0/work/./abc/abc
{noformat} 

I believe we should fail the task at this point."
MAPREDUCE-2073,TestTrackerDistributedCacheManager should be up-front about requirements on build environment,"TestTrackerDistributedCacheManager will fail on a system where the build directory is in any path where an ancestor doesn't have a+x permissions. On one of our hudson boxes, for example, hudson's workspace had 700 permissions and caused this test to fail reliably, but not in an obvious manner. It would be helpful if the test failed with a more obvious error message during setUp() when the build environment is misconfigured."
MAPREDUCE-2072,Allow multiple instances of same local job to run simutaneously on the same machine,"On the same (build) machine, there may be multiple instances of same local job running - e.g. same unit test from snapshot build and release build.

For each build project on our build machine, there is environment variable with unique value defined. 

In JobClient.submitJobInternal(), there is following code:
    JobID jobId = jobSubmitClient.getNewJobId();
    Path submitJobDir = new Path(getSystemDir(), jobId.toString());

The above code doesn't handle the scenario described previously and often leads to the following failure:
Caused by: org.apache.hadoop.util.Shell$ExitCodeException: chmod: cannot access `/tmp/hadoop-build/mapred/system/job_local_0002': No such file or directory
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:195)
	at org.apache.hadoop.util.Shell.run(Shell.java:134)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:286)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:354)
	at org.apache.hadoop.util.Shell.execCommand(Shell.java:337)
	at org.apache.hadoop.fs.RawLocalFileSystem.execCommand(RawLocalFileSystem.java:492)
	at org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:484)
	at org.apache.hadoop.fs.FilterFileSystem.setPermission(FilterFileSystem.java:286)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:308)
	at org.apache.hadoop.mapred.JobClient.configureCommandLineOptions(JobClient.java:614)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:802)
	at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:771)
	at org.apache.hadoop.mapred.HadoopClient.runJob(HadoopClient.java:177)

One solution would be to incorporate the value of the underlying environment variable into either NewJobId or SystemDir so that there is no conflict.
"
MAPREDUCE-2069,Distcp setup is slow,"When starting a distcp the setup phase often takes a very long time. For example during the distcp I just ran the setup phase took 15 minutes and the actual copy 3 minutes. Could this be improved? Or at least a progress bar added so the user doesn't think it stalled.

I also often see exceptions like this in the setup, but the distcp finishes eventually.
java.io.EOFException
        at java.io.DataInputStream.readShort(DataInputStream.java:298)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.endBlock(DFSClient.java:1672)
        at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.close(DFSClient.java:1744)
        at org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:49)
        at org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:64)
        at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:774)
        at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.setup(CopyFiles.java:351)
        at org.apache.hadoop.util.CopyFiles.copy(CopyFiles.java:773)
        at org.apache.hadoop.util.CopyFiles.run(CopyFiles.java:854)
        at org.apache.hadoop.util.ToolBase.doMain(ToolBase.java:187)
        at org.apache.hadoop.util.CopyFiles.main(CopyFiles.java:864)"
MAPREDUCE-2068,TaskInProgress contains duplicate idWithinJob() / getIdWithinJob() accessors,"Both are public, both ""return partition;"", and neither is currently deprecated.

Main user seems to be JobInProgress, and it mostly uses the ""get"" flavor, but it also uses the other one in two places."
MAPREDUCE-2067,Distinct minicluster services (e.g. NN and JT) overwrite each other's service policies,MR portion of HADOOP-6951.
MAPREDUCE-2065,Tutorial includes overly specified compilation command,"The tutorial (mapred_tutorial.html) shows a command line to compile the wordcount program. It specifically mentions three Hadoop-supplied jar files in the classpath, but in my 0.20.2 installation (and I assume, later ones as well), only one is necessary, that being ""core"". In fact, the mentioned mapred and hdfs jars are not even present in my HADOOP_HOME directory."
MAPREDUCE-2064,Tutorial should mention SetMapOutputKeyClass,"The official tutorial (mapred_tutorial.html) (and all other tutorials I've seen on the web) show a program that has the same datatypes for the key/value pairs emitted by the mapper and by the reducer, and shows a configuration call to Job.setOutput{Key,Value}Class but doesn't say that it refers to both the mapper and the reducer. It sounds like it refers to the reducer output. This might be mentioned in the ""Job Configuration"" section. Here is a possible addition, after the ""The Job is used to specify ..."" paragraph.

The job also configures the types of its key/value pairs with setOutputKeyClass(type) andsetOutputValueClass(type), which appy to both the mapper and reducer classes. If the types output by the mapper and reducer are not the same, that should be followed with setMapOutputKeyClass(type) and setMapOutputValueClass(type).

(I'm assuming that at least a call to setOutput{Key,Value}Class is required.)"
MAPREDUCE-2062,speculative execution is too aggressive under certain conditions,"The function canBeSpeculated has subtle bugs that cause too much speculation in certain cases.

- it compares the current progress of the task with the last observed mean of all the tasks. if only one task is in question - then the progress rate decays as time progresses (in the absence of updates) and std-dev is zero. So a job with a single reducer or mapper is almost always speculated.
- is only a single task has reported progress - then the stddev is zero. so other tasks may be speculated aggressively.
- several tasks take a while to report progress initially. they seem to get speculated as soon as speculative-lag is over. the lag should be configurable at the minimum.
"
MAPREDUCE-2061,child environment substitution is broken,"TaskRunner.getVMEnvironment is still broken in a couple of ways even after HADOOP-5981:
* It does not recognize ${VAR} notation. This is necessary if we have both ""VAR"" and ""VAR_1"" existent, and it becomes ambiguous whether $VAR_1 means appending _1 following $VAR, or simply taking the value of $VAR_1
* It tries to do lazy-binding except for self-referencing like X=$X:Y. This would cause some unexpected behavior. For instance, if I specify ""A=$LD_LIBRARY_PATH:xxx"", A would be shown as "":xxx"", while if I specify ""LD_LIBRARY_PATH=$Z:xxx,Z=$LD_LIBRARY_PATH:yyy"", Z would be come the actual value of LD_LIBRARY_PATH + "":yyy"" (and LD_LIBRARY_PATH is not affected at all). I think we should support eager binding (and we can support lazy binding later through quoting or escaping).
"
MAPREDUCE-2060,IOException: Filesystem closed on submitJob,"I get the following strange error on the jobtracker when attempting to submit a job:

10/09/09 20:31:35 INFO ipc.Server: IPC Server handler 7 on 31000, call submitJob(job_201009092028_0001, hdfs://hns4.sea1.qc:21000/tmp/hadoop-mr20/mapred/staging/dadkins/.staging/job_201009092028_0001, org.apache.hadoop.security.Credentials@20c87621) from 10.128.130.145:49253: error: java.io.IOException: Filesystem closed
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:307)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:1212)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:494)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1491)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:395)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3078)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:3014)
	at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:2996)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.java:349)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1380)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1376)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1105)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1374)
"
MAPREDUCE-2059,RecoveryManager attempts to add jobtracker.info,"The jobtracker is treating the file 'jobtracker.info' in the system data directory as a job to be recovered, resulting in the following:

10/09/09 18:06:02 WARN mapred.JobTracker: Failed to add the job jobtracker.info
java.lang.IllegalArgumentException: JobId string : jobtracker.info is not properly formed
        at org.apache.hadoop.mapreduce.JobID.forName(JobID.java:158)
        at org.apache.hadoop.mapred.JobID.forName(JobID.java:84)
        at org.apache.hadoop.mapred.JobTracker$RecoveryManager.addJobForRecovery(JobTracker.java:1057)
        at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1565)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:275)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:267)
        at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:262)
        at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4256)
"
MAPREDUCE-2057,"Job Tracker appears to do host access-control (mapred.hosts, mapred.hosts.exclude) based on presented name from TaskTracker","As far as I can tell, where the NameNode, in validating the dfs.hosts and dfs.hosts.exclude files uses the source IP address for the RPC connection, the JobTracker appears to use the presented hostname (set via slave.host.name or the standard hostname-search semantics) from the TaskTracker. Obviously this is a security bug as in a production environment it could allow rogue machines to present the hostname of a real TaskTracker and take over that role, but it also turns up as a configuration bug because it means that you can set up a (multi-homed, natch) environment where the same set of files work for the NameNode, but don't for the JobTracker or vice versa - with the same binding hostname for fs.default.name and mapred.job.tracker."
MAPREDUCE-2056,run job options broken,"HADOOP-1622 was apparently broken in refactoring (I think in the refactoring that removed JobShell) a few releases ago. e.g., running

hadoop -libjars lib.jar main.jar Class 

now tries to run -libjars as a library.

It would be nice to fix this regression.
"
MAPREDUCE-2054,Hierarchical queue implementation broke dynamic queue addition in Dynamic Scheduler,Queue names were returned from the queue manager as an immutable set after the hierarchical queuname feature which breaks the dynamic priority scheduler
MAPREDUCE-2053,[Herriot] Test Gridmix file pool for different input file sizes based on pool minimum size.,"Scenario:
1. Generate 1.8G data with Gridmix data generator, such that the files can create under different folders inside the given input directory and also create the files directly in the given input directory with the following sizes {50 MB,100 MB,400 MB, 50 MB,300 MB,10 MB ,60 MB,40 MB,20 MB,10 MB,500 MB}.
2.Set the FilePool minimum size is 100 MB.
3. Verify the files count and sizes after excluding the files that are less than file pool minimum size.Also make sure, whether files are collected recursively from the different locations under input folder or not.
"
MAPREDUCE-2051,Contribute a fair scheduler preemption system test,"We've seen a number of bugs in the fair share scheduler not caught by its unit tests, which are heavily mock-based. This JIRA is to add an integration/system/stress test for the fairshare scheduler. This test can help identify races and deadlocks, and when run within the jcarder framework has identified several potential deadlocks for us that aren't turned up running small scale testing."
MAPREDUCE-2050,TestMRCLI fails on trunk,"TestMRCLI fails with following error:
{noformat}
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(150)) -                     Test ID: [1]
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(151)) -            Test Description: [refreshServiceAcl: refreshing security authorization policy for jobtracker]
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(152)) - 
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(156)) -               Test Commands: [-jt JOBTRACKER -refreshServiceAcl ]
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(160)) - 
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(167)) - 
2010-09-02 14:23:25,974 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(171)) -                  Comparator: [ExactComparator]
2010-09-02 14:23:25,975 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(173)) -          Comparision result:   [fail]
2010-09-02 14:23:25,975 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(175)) -             Expected output:   []
2010-09-02 14:23:25,975 INFO  cli.CLITestHelper (CLITestHelper.java:displayResults(177)) -               Actual output:   [refreshServiceAcl: Kerberos service principal name isn't configured properly (should have 3 parts): 
{noformat}"
MAPREDUCE-2049,JT and TT should prune invalid local dirs on startup,"MRAsyncDiskService fails when it's given local dirs it can't create or write. Per MAPREDUCE-1213 this conflicts with the previous behavior. The TTs will no longer start on hosts where the config has localdirs that can not be created (ie if some hosts don't have the same local mounts).  

The TT and JT should prune out invalid local dirs (ones that fail checkLocalDirs ie that it can not create) before giving them to MRAsyncDiskService and using them otherwise.

Also mapred-default.xml states that mapred.local.dir that do not exist are ignored, this should be updated as directories that don't exist are created (if possible), they're only ignored if they can not be created. 

"
MAPREDUCE-2047,reduce overhead of findSpeculativeTask,"We are bottlenecked (in the JT) on the jobtracker lock and calls to findSpeculativeTask frequently show up as one of the top routines (by time) called holding this lock.

this routine calls canBeSpeculated() and hasRunOnMachine() for each task in a candidate job. Both these routines are reasonably expensive when invoked repeatedly  for thousands of tasks. The top candidates for speculation from a job only need to be refreshed periodically (and not once every heartbeat) - and we can can avoid most of these invocations this way."
MAPREDUCE-2046,A CombineFileInputSplit cannot be less than a dfs block ,"I ran into this while testing some hive features.

Whether we use hiveinputformat or combinehiveinputformat, a split cannot be less than a dfs block size.
This is a problem if we want to increase the block size for older data to reduce memory consumption for the
name node.

It would be useful if the input split was independent of the dfs block size."
MAPREDUCE-2045,[Gridmix] Separate out the -generate option in Gridmix,"Currently, the data generating option (-generate) is embedded in the main GridMix command. This is very confusing and needs to separated out as a full-fledged option."
MAPREDUCE-2044,[Gridmix] Document the usage of '-' as the input-trace in GridMix,GridMix users can pipeline the input trace to GridMix using the '-' option. This needs a documentation.
MAPREDUCE-2042,InputFormat#getSplits() is called twice in local mode,"In local mode the InputFormat#getSplits() is called twice in local mode.
- 1st time: JobClient#writeOld/NewSplits() (then they write the splits to disk )
- 2nd time: LocalJobRunner#run() (instead of reading the split file )

That can become annoying in case the InputFormat access external resources or takes a little longer to create the splits.
"
MAPREDUCE-2040,Forrest Documentation for Dynamic Priority Scheduler,New Forrest documentation for dynamic priority scheduler
MAPREDUCE-2039,Improve speculative execution,"In speculation, the framework issues a second task attempt on a task where one attempt is already running.  This is useful if the running attempt is bogged down for reasons outside of the task's code, so a second attempt finishes ahead of the existing attempt, even though the first attempt has a head start.

Early versions of speculation had the weakness that an attempt that starts out well but breaks down near the end would never get speculated.  That got fixed in HADOOP:2141 , but in the fix the speculation wouldn't engage until the performance of the old attempt, _even counting the early portion where it progressed normally_ , was significantly worse than average.

I want to fix that by overweighting the more recent progress increments.  In particular, I would like to use exponential smoothing with a lambda of approximately 1/minute [which is the time scale of speculative execution] to measure progress per unit time.  This affects the speculation code in two places:

   * It affects the set of task attempts we consider to be underperforming
   * It affects our estimates of when we expect tasks to finish.  This could be hugely important; speculation's main benefit is that it gets a single outlier task finished earlier than otherwise possible, and we need to know which task is the outlier as accurately as possible.

I would like a rich suite of configuration variables, minimally including lambda and possibly weighting factors.  We might have two exponentially smoothed tracking variables of the progress rate, to diagnose attempts that are bogged down and getting worse vrs. bogging down but improving.


Perhaps we should be especially eager to speculate a second attempt.  If a task is deterministically failing after bogging down [think ""rare infinite loop bug""] we would rather take a couple of our attempts in parallel to discover the problem sooner.


As part of this patch we would like to add benchmarks that simulate rare tasks that behave poorly, so we can discover whether this change in the code is a good idea and what the proper configuration is.  Early versions of this will be driven by our assumptions.  Later versions will be driven by the fruits of MAPREDUCE:2037"
MAPREDUCE-2037,"Capturing interim progress times, CPU usage, and memory usage, when tasks reach certain progress thresholds","We would like to capture the following information at certain progress thresholds as a task runs:

   * Time taken so far
   * CPU load [either at the time the data are taken, or exponentially smoothed]
   * Memory load [also either at the time the data are taken, or exponentially smoothed]

This would be taken at intervals that depend on the task progress plateaus.  For example, reducers have three progress ranges -- [0-1/3], (1/3-2/3], and (2/3-3/3] -- where fundamentally different activities happen.  Mappers have different boundaries, I understand, that are not symmetrically placed.  Data capture boundaries should coincide with activity boundaries.  For the state information capture [CPU and memory] we should average over the covered interval.

This data would flow in with the heartbeats.  It would be placed in the job history as part of the task attempt completion event, so it could be processed by rumen or some similar tool and could drive a benchmark engine."
MAPREDUCE-2036,Enable Erasure Code in Tool similar to Hadoop Archive,"Features:
1) HAR-like Tool
2) RAID5/RAID6 & pluggable interface to implement additional coding
3) Enable to group blocks across files
4) Portable across cluster since all necessary metadata is embedded

While it was developed separately from HAR or RAID due to time constraints, it would make sense to integrate with either of them."
MAPREDUCE-2035,Enable -Wall and fix warnings in task-controller build,Enabling -Wall shows a bunch of warnings. We should enable them and then fix them.
MAPREDUCE-2034,TestSubmitJob triggers NPE instead of permissions error,"TestSubmitJob.testSecureJobExecution catches _any_ IOException and assumes a permissions error has been caught. In fact, it was passing an invalid path name to the NameNode and triggering an NPE, not a Permission denied error, in one case, but the test was not specific enough to detect this."
MAPREDUCE-2033,[Herriot] Gridmix generate data tests with various submission policies and different user resolvers.,"Tests for submitting and verifying the gridmix generate input data in different submission policies and various user resolver modes. It covers the following scenarios.

1. Generate the data in a STRESS submission policy with SubmitterUserResolver mode and verify whether the generated data matches with given size of input or not.
2. Generate the data in a REPLAY submission policy with RoundRobinUserResolver mode and verify whether the generated data matches with the given input size or not.
3. Generate the data in a SERIAL submission policy with EchoUserResolver mode and specify the no.of bytes per file. Verify whether each file size is matches with given per file size or not and also verify the overall size of generated data. "
MAPREDUCE-2032,TestJobOutputCommitter fails in ant test run,"TestJobOutputCommitter fails in a ""ant test"" run with following exception :
{noformat}
Output directory /home/amarsri/mapred/build/test/data/test-job-cleanup/output-2 already exists
org.apache.hadoop.fs.FileAlreadyExistsException: Output directory /home/amarsri/mapred/build/test/data/test-job-cleanup/output-2 already exists
        at org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:141)
        at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:391)
        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:350)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1037)
        at org.apache.hadoop.mapreduce.Job$2.run(Job.java:1034)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1093)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:1034)
        at org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter.testKilledJob(TestJobOutputCommitter.java:192)
        at org.apache.hadoop.mapreduce.lib.output.TestJobOutputCommitter.testDefaultCleanupAndAbort(TestJobOutputCommitter.java:232)
{noformat}
But it passes when it is run individually."
MAPREDUCE-2031,TestTaskLauncher and TestTaskTrackerLocalization fail with NPE in trunk.,"TestTaskLauncher and TestTaskTrackerLocalization fail in trunk after the commit of MAPREDUCE-1881 with NPE:
{noformat}
java.lang.NullPointerException
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.kill(TaskTracker.java:2978)
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.jobHasFinished(TaskTracker.java:2941)
        at org.apache.hadoop.mapred.TaskTracker.purgeJob(TaskTracker.java:1919)
        at org.apache.hadoop.mapred.TestTaskTrackerLocalization.verifyUserLogsRemoval(TestTaskTrackerLocalization.java:816)
        at org.apache.hadoop.mapred.TestTaskTrackerLocalization.testJobFilesRemoval(TestTaskTrackerLocalization.java:897)
{noformat}

{noformat}
java.lang.NullPointerException
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.kill(TaskTracker.java:2978)
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.jobHasFinished(TaskTracker.java:2941)
        at org.apache.hadoop.mapred.TaskTracker.purgeTask(TaskTracker.java:1981)
        at org.apache.hadoop.mapred.TaskTracker.processKillTaskAction(TaskTracker.java:420)
        at org.apache.hadoop.mapred.TestTaskLauncher.testExternalKillForLaunchTask(TestTaskLauncher.java:95)
{noformat}

NPE happens because taskTracker.myInstrumentation is not initialized."
MAPREDUCE-2030,Throwing IOException while submitting the gridmix jobs consecutively through ToolRunner.,"Gridmix throws an IOException while submitting the Gridmix jobs consecutively through ToolRunner. For first job its works fine and for next job onwards, it throws the below exception.

    [junit] java.io.IOException: Stream closed
    [junit]     at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:145)
    [junit]     at java.io.BufferedInputStream.read(BufferedInputStream.java:308)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.ensureLoaded(ByteSourceBootstrapper.java:338)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.detectEncoding(ByteSourceBootstrapper.java:116)
    [junit]     at org.codehaus.jackson.impl.ByteSourceBootstrapper.constructParser(ByteSourceBootstrapper.java:205)
    [junit]     at org.codehaus.jackson.JsonFactory._createJsonParser(JsonFactory.java:298)
    [junit]     at org.codehaus.jackson.JsonFactory.createJsonParser(JsonFactory.java:251)
    [junit]     at org.apache.hadoop.tools.rumen.JsonObjectMapperParser.<init>(JsonObjectMapperParser.java:72)
    [junit]     at org.apache.hadoop.tools.rumen.JobTraceReader.<init>(JobTraceReader.java:49)
    [junit]     at org.apache.hadoop.tools.rumen.ZombieJobProducer.<init>(ZombieJobProducer.java:94)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.createJobFactory(Gridmix.java:212)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.startThreads(Gridmix.java:181)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.start(Gridmix.java:291)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.runJob(Gridmix.java:273)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.access$000(Gridmix.java:55)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:227)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix$1.run(Gridmix.java:225)
    [junit]     at java.security.AccessController.doPrivileged(Native Method)
    [junit]     at javax.security.auth.Subject.doAs(Subject.java:396)
    [junit]     at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
    [junit]     at org.apache.hadoop.mapred.gridmix.Gridmix.run(Gridmix.java:225)
    [junit]     at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
    [junit]     at org.apache.hadoop.mapred.gridmix.TestGridMixDataGeneration.testGenerateDataWithREPLAYSubmission(TestGridMixDataGeneration.java:173)
    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    [junit]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    [junit]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
    [junit]     at java.lang.reflect.Method.invoke(Method.java:597)
    [junit]     at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
    [junit]     at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
    [junit]     at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
    [junit]     at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
    [junit]     at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit]     at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit]     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:73)
    [junit]     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:46)
    [junit]     at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:180)
    [junit]     at org.junit.runners.ParentRunner.access$000(ParentRunner.java:41)
    [junit]     at org.junit.runners.ParentRunner$1.evaluate(ParentRunner.java:173)
    [junit]     at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
    [junit]     at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
    [junit]     at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
    [junit]     at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
    [junit]     at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
    [junit] 10/08/25 07:05:13 ERROR gridmix.Gridmix: Startup failed
    [junit] java.io.IOException: java.io.IOException: Stream closed
"
MAPREDUCE-2029,DistributedRaidFileSystem not removed from cache on close(),"When DistributedRaidFileSystem.close() is called, it does not remove itself from the FileSystem cache, but it does close the underlying filesystem, e.g. DFS.

Because the DRFS with the closed DFS is still in the cache, calling FileSystem.get() returns a stale DRFS that throws 'filesystem closed' exceptions."
MAPREDUCE-2028,streaming should support MultiFileInputFormat,There should be a way to call MultiFileInputFormat from streaming without having to write Java code...
MAPREDUCE-2026,JobTracker.getJobCounters() should not hold JobTracker lock while calling JobInProgress.getCounters(),"JobTracker.getJobCounter() will lock JobTracker and call JobInProgress.getCounters().
JobInProgress.getCounters() can be very expensive because it aggregates all the task counters.
We found that from the JobTracker jstacks that this method is one of the bottleneck of the JobTracker performance.

JobInProgress.getCounters() should be able to be called out side the JobTracker lock because it already has JobInProgress lock.
For example, it is used by jobdetails.jsp without a JobTracker lock.
"
MAPREDUCE-2024,"5th JobTracker constructor (for simulator) uses outdated configs, duplicates code","The fifth JobTracker constructor (JobTracker(final JobConf conf, Clock clock, boolean ignoredForSimulation)) still uses the old ""mapred.*"" config settings and appears to duplicate much of the code in the fourth (main) ctor.  It should be modernized and, ideally, share as much code as possible with the main one in order to minimize simulation drift and the potential for config errors."
MAPREDUCE-2023,TestDFSIO read test may not read specified bytes.,TestDFSIO's read test may read less bytes than specified when reading large files.
MAPREDUCE-2022,trunk build broken,"Trunk compilation fails with following errors:
    [javac] /home/amarsri/workspace/trunk/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:267: getListing(java.lang.String,byte[],boolean) in org.apache.hadoop.hdfs.protocol.ClientProtocol cannot be applied to (java.lang.String,byte[])
    [javac]         client.getListing(
    [javac]               ^
    [javac] /home/amarsri/workspace/trunk/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:281: getListing(java.lang.String,byte[],boolean) in org.apache.hadoop.hdfs.protocol.ClientProtocol cannot be applied to (java.lang.String,byte[])
    [javac]         client.getListing(
    [javac]               ^

This is due to commit of HDFS-202"
MAPREDUCE-2021,CombineFileInputFormat returns duplicate  hostnames in split locations,"CombineFileInputFormat.getSplits creates splits with duplicate locations. It adds locations of the files in the split to an ArrayList; if all the files are on same location, the location is added again and again. Instead, it should add it to a Set instead of List to avoid duplicates."
MAPREDUCE-2019,Add  targets for gridmix unit and system tests in a gridmix build xml file.,Add the targets for both unit and system tests in gridmix build xml (src/contrib/gridmix/build.xml). The target name for system tests would be 'test-system' and same way the target name for unit tests would be 'test'.
MAPREDUCE-2018,TeraSort example fails in trunk,"Exceptions are thrown while computing splits near the end of file - typically when the number of bytes read is smaller than RECORD_LENGTH

10/08/17 22:44:17 WARN conf.Configuration: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
10/08/17 22:44:17 INFO input.FileInputFormat: Total input paths to process : 1
Spent 19ms computing base-splits.
Spent 2ms computing TeraScheduler splits.
Computing input splits took 22ms
Sampling 1 splits of 1
Got an exception while reading splits java.io.EOFException: read past eof
        at org.apache.hadoop.examples.terasort.TeraInputFormat$TeraRecordReader.nextKeyValue(TeraInputFormat.java:267)
        at org.apache.hadoop.examples.terasort.TeraInputFormat$1.run(TeraInputFormat.java:181)

TeraInoutFormat I believe assumes the file sizes are exact multiples of RECORD_LENGTH

"
MAPREDUCE-2017,Move jobs between queues post-job submit,It would be massively useful to be able to move a job between queues after it has already been submitted.
MAPREDUCE-2016,GridMix throws an ArithmeticException error when tasktracker count is zero while generating the data.,"GridMix throws an ArithmeticException error when tasktracker count is zero. In generating data, while calculating the bytes per task tracker in getSplit method, throws an exception if tasktracker count is zero. Actually bytes are calculating by dividing the number of task trackers in the cluster. So we need to build the better exception handling for these kinds of cases. Should add a condition (count should be >0) for tasktracker count before calculating the bytes per tasktracker. 

10/08/12 08:33:34 INFO gridmix.JobSubmitter:  Job org.apache.hadoop.mapreduce.Job@18a8ce2 submission failed 
java.lang.ArithmeticException: / by zero
        at org.apache.hadoop.mapred.gridmix.GenerateData$GenDataFormat.getSplits(GenerateData.java:161)
        at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:902)
        at org.apache.hadoop.mapred.JobClient.writeSplits(JobClient.java:919)
        at org.apache.hadoop.mapred.JobClient.access$5(JobClient.java:913)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:838)
        at org.apache.hadoop.mapred.JobClient$2.run(JobClient.java:1)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:792)
        at org.apache.hadoop.mapreduce.Job.submit(Job.java:465)
        at org.apache.hadoop.mapred.gridmix.GenerateData$1.run(GenerateData.java:116)
        at org.apache.hadoop.mapred.gridmix.GenerateData$1.run(GenerateData.java:101)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1021)
        at org.apache.hadoop.mapred.gridmix.GenerateData.call(GenerateData.java:101)
        at org.apache.hadoop.mapred.gridmix.GenerateData.call(GenerateData.java:57)
        at org.apache.hadoop.mapred.gridmix.JobSubmitter$SubmitTask.run(JobSubmitter.java:106)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:619)
"
MAPREDUCE-2015,GridMix always throws an FileAlreadyExistsException even ouput directory is not available in HDFS.,"Gridmix always throws an FileAlreadyExistsException even ouput directory is not available in HDFS. Actually I was launching the Gridmix in a command line for generating the data, before launching I just make sure the output directory is not available in the HDFS by deleting the folder if already exists.However, I could see output directory already exists exception every time. Please see the attached logs for more information."
MAPREDUCE-2014,Remove task-controller from 0.21 branch,
MAPREDUCE-2012,Some contrib tests fail in branch 0.21 and trunk,"After the commit of MAPREDUCE-1920, some contrib tests such as TestStreamingStatus, TestStreamingTaskLog and etc. are timing out."
MAPREDUCE-2011,Reduce number of getFileStatus call made from every task(TaskDistributedCache) setup,"On our cluster, we had jobs with 20 dist cache and very short-lived tasks resulting in 500 map tasks launched per second resulting in  10,000 getFileStatus calls to the namenode.  Namenode can handle this but asking to see if we can reduce this somehow.  
"
MAPREDUCE-2009,GridMix hangs forever if there is no tasktracker running in the cluster.,"Suppose if user submit a GridMix job in a cluster. However, there are no task trackers running in the cluster, in this case the GridMix is hanging forever at JobMonitor. Please make sure to exit the job with appropriate message after specified amount of time instead of waiting forever."
MAPREDUCE-2007,"Is it possible that use ArrayList or other type  instead Iterable  when use reduce(Object, Iterable, Context)?","1) Sometimes We only need get the elements count of the input values of Reducer task,

but we have to iterate all the input values to calculate it.

2) Sometimes We only need get a few elements (for example top n,last n ,or random ) from  the input values of Reducer task,

if it can use ArrayList or other type  instead Iterable  when use reduce(Object, Iterable, Context),it 's more conveniency."
MAPREDUCE-2006,Gridmix can emit better error messages instead of throwing Exceptions,"Gridmix throws Exceptions (including those that come from mapreduce jobs) when there are some issues like
(1) ioPath already exists and -generate option is given
(2) when -generate option is given, ioPath (a) doesn't exist (b) exists but with wrong permissions
(3) gridmix.output.directory path already exists
(4) gridmix.min.file.size is > the size specified as option to -generate
etc.

These can be validated early and provide proper error messages to the user of gridmix."
MAPREDUCE-2003,It should be able to specify different jvm settings for map and reduce child process (via mapred.child.map.java.opts and mapred.child.reduce.java.opts options) ,"Sometimes mapper child process requires different JVM settings than reducer. For example when mapper requires much more memory than reducer.
Now it's only possible to set options for both using mapred.child.java.opts.

Proposed solution: mapred.child.java.opts could be overwritten by mapred.child.map.java.opts or mapred.child.reduce.java.opts. Thus, we're adding more flexibility and compatibility with old configurations.

The same should be done for mapred.child.env."
MAPREDUCE-2000,Rumen is not able to extract counters for Job history logs from Hadoop 0.20,"Rumen tries to match the end of a value string through indexOf(""\""""). It does not take into account the case when an escaped '""' in the value string. This leads to the incorrect parsing the remaining key=value properties in the same line."
MAPREDUCE-1999,ClientProtocol incorrectly uses hdfs DelegationTokenSelector,ClientProtocol in MR incorrectly uses the DelegationTokenSelector in hdfs due to a wrong import. It should use the DelegationTokenSelector in mapreduce.
MAPREDUCE-1998,Size-based queuing for capacity scheduler,"On job submission, it would be useful if the capacity scheduler could pick a queue based on the # of maps and reduces.  This way one could have queues based on job-size without users having to pick the queue prior to submission.  "
MAPREDUCE-1996,API: Reducer.reduce() method detail misstatement,"method detail for Reducer.reduce() method has paragraph starting:

""Applications can use the Reporter  provided to report progress or just indicate that they are alive. In scenarios where the application takes an insignificant amount of time to process individual key/value pairs, this is crucial since the framework might assume that the task has timed-out and kill that task. ""

s/an insignificant amount of time/a significant amount of time/
"
MAPREDUCE-1995,FairScheduler can wait for JobInProgress lock while holding JobTracker lock,"Here is the related code path.
{code}
JobInProgress.getTaskInProgress() (Locks JobInProgress)
LocalityLevel.fromTask()
FairScheduler.updateLastMapLocalityLevel()
FairScheduler.assignTasks()
JobTracker.heartbeat() (Locks JobTracker)
{code}"
MAPREDUCE-1994,Linux task-controller determines its own path insecurely,"The task-controller uses argv[0] to determine its own path, and then calls stat() on that. Instead it should stat(""/proc/self/exe"") directly. This is important since argv[0] can be spoofed to point to another program and thus either fool the autodetection of HADOOP_HOME or evade various permissions checks."
MAPREDUCE-1993,TestTrackerDistributedCacheManagerWithLinuxTaskController fails on trunk,TestTrackerDistributedCacheManagerWithLinuxTaskController fails when run with the DefaultTaskController. 
MAPREDUCE-1992,NPE in JobTracker's constructor,"On my local machine, JobTracker is *not* coming up with current trunk. Logs show the following NPE:

2010-08-03 14:01:41,449 FATAL org.apache.hadoop.mapred.JobTracker: java.lang.NullPointerException
  at org.apache.hadoop.security.UserGroupInformation.isLoginKeytabBased(UserGroupInformation.java:703)
  at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:1383)
  at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:275)
  at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:267)
  at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:262)
  at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:4236)

2010-08-03 14:01:41,449 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG:"
MAPREDUCE-1991,taskcontroller allows stealing permissions on any local file,The linux task-controller setuid binary allows a malicious user to chmod any file on the system to 644 (and as a side effect appends some junk to the end)
MAPREDUCE-1989,Gridmix3 doesn't emit out proper mesage when user resolver is set and no user list is given,"Currently, Gridmix3 emits out the following mesage when user resolver is set and no user list is given.
""Resource null ignored"".
This is not clear/meaningful to user."
MAPREDUCE-1988,We would like more information to be available in job history index,"So far, people have requested:

   * completion state
   * start time
   * end time
   * job name

be available from an index record

Please make additional requests here."
MAPREDUCE-1986,History files fail to move to DONE folder when hadoop.job.history.location is configured to a HDFS path,"When hadoop.job.history.location is configured to a HDFS path and when the job retires, the history files are never moved to
mapred.job.tracker.history.completed.location and they remain forever in hadoop.job.history.location . The jobhistory is never viewable thereafter. 
"
MAPREDUCE-1985,java.lang.ArrayIndexOutOfBoundsException in analysejobhistory.jsp of jobs with 0 maps,"This is Yahoo bug #3460762 included in ydist, but couldn't find a public JIRA for it. Uploading patch from YDH in case anyone else has run into this on the 0.20 branch."
MAPREDUCE-1984,herriot TestCluster fails because exclusion is not there,"restart is part of the test case which causes ioexceptions, and this needs to be ignored. The test case should not be incorrectly failed. "
MAPREDUCE-1982,[Rumen] TraceBuilder's output shows jobname as NULL for jobhistory files with valid jobnames,"{{TraceBuilder}} fails to extract configuration properties (like job-name) from the job-conf if the job-conf has the properties stored using the deprecated keys.
"
MAPREDUCE-1981,Improve getSplits performance by using listLocatedStatus,"This jira will make FileInputFormat and CombinedFileInputForm to use the new API, thus reducing the number of RPCs to HDFS NameNode."
MAPREDUCE-1980,TaskAttemptUnsuccessfulCompletionEvent.java incorrectly logs MAP_ATTEMPT_KILLED as event type for reduce tasks,"TaskAttemptUnsuccessfulCompletionEvent is used to log unsuccessful map and reduce task attempts to JobHistory. Following is the implementation of getEventType() method of TaskAttemptUnsuccessfulCompletionEvent

/** Get the event type */
  public EventType getEventType() {
    return EventType.MAP_ATTEMPT_KILLED;
  }

"
MAPREDUCE-1979,"""Output directory already exists"" error in gridmix when gridmix.output.directory is not defined","""Output directory already exists"" error is seen in gridmix when gridmix.output.directory is not defined. When gridmix.output.directory is not defined, then gridmix uses inputDir/gridmix/ as output path for gridmix run. Because gridmix is creating outputPath(in this case, inputDir/gridmix/) at the begining, the output path to generate-data-mapreduce-job(i.e. inputDir) already exists and becomes error from mapreduce.

There is need for creation of this outputPath in any case(whether user specifies the path using gridmix.output.directory OR gridmix itself considering inputDir/gridmix/ ) even though the paths are automatically created for output paths of mapreduce jobs(like mkdir -p), because gridmix needs to set 777 permissions for this outputPath sothat different users can create different output directories of different mapreduce jobs within this gridmix run.

The other case in which this problem is seen is when gridmix.output.directory is defined as a relative path. This is because in this case also, gridmix tries to create relative path under ioPath/ and thus the same issue."
MAPREDUCE-1978,[Rumen] TraceBuilder should provide recursive input folder scanning,"Currently, {{TraceBuilder}} assumes that the input is either jobhistory files or a folders containing jobhistory files directly underneath the specified folder. There could be a use cases where the input folder could contain sub-folders containing jobhistory files. Rumen should support such input folders."
MAPREDUCE-1976,Inconsistency in logging hostnames to JobHistory,JobHistory line for successful task-attempts store tracker-name (i.e /rack/xyz.com:1234) for the _hostname_ field while unsuccessful task-attempts store only the hostname (i.e xyz.com).
MAPREDUCE-1975,gridmix shows unnecessary InterruptedException,"The following InterruptedException is seen when gridmix is run and it ran successfully:

10/06/24 20:43:03 INFO gridmix.ReplayJobFactory: START REPLAY @ 11331037109
10/06/24 20:43:03 ERROR gridmix.Statistics: Statistics interrupt while waiting for polling null
java.lang.InterruptedException
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec\
t.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:1899)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec\
t.await(AbstractQueuedSynchronizer.java:2066)
        at org.apache.hadoop.mapred.gridmix.Statistics$StatCollector.run(Statis\
tics.java:190)
10/06/24 20:43:03 INFO gridmix.Gridmix: Exiting..."
MAPREDUCE-1974,FairScheduler can preempt the same task many times,"In FairScheduler.preemptTasks(), tasks are collected from JobInProgress.runningMapCache.
But tasks repeat multiple times in  JobInProgress.runningMapCache (on rack, node and cluster).
This makes FairScheduler preempt the same task many times."
MAPREDUCE-1972,TestUserLogCleanup test cant clean up the toBeDeleted,"All the hudson patch test builds are failing as the Mapreduce-Patch-h4.grid.sp2.yahoo.net/trunk/build/test/logs/userlogs has a folder created by the following test which doesnt seem to have read permission. 

Running org.apache.hadoop.mapred.TestUserLogCleanup
     [exec]     [junit] 2010-07-14 22:24:54,027 INFO  mapred.UserLogCleaner (UserLogCleaner.java:markJobLogsForDeletion(174)) - Adding job_test_0001 for user-log deletion with retainTimeStamp:7200000
...........

     [exec]     [junit] 2010-07-14 22:24:54,373 WARN  util.MRAsyncDiskService (MRAsyncDiskService.java:run(214)) - Failure in deletion of toBeDeleted/2010-07-14_22-24-54.372_6 on /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h4.grid.sp2.yahoo.net/trunk/build/test/logs/userlogs with original name job_20100714203911410_0002
     [exec]     [junit] 2010-07-14 22:24:54,374 WARN  util.MRAsyncDiskService (MRAsyncDiskService.java:run(214)) - Failure in deletion of toBeDeleted/2010-07-14_22-24-54.373_7 on /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h4.grid.sp2.yahoo.net/trunk/build/test/logs/userlogs with original name job_test_0003
     [exec]     [junit] 2010-07-14 22:24:54,391 WARN  util.MRAsyncDiskService (MRAsyncDiskService.java:run(214)) - Failure in deletion of toBeDeleted/2010-07-14_22-24-54.372_6 on /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h4.grid.sp2.yahoo.net/trunk/build/test/logs/userlogs with original name /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h4.grid.sp2.yahoo.net/trunk/build/test/logs/userlogs/toBeDeleted/2010-07-14_22-24-54.372_6
     [exec]     [junit] 2010-07-14 22:24:54,405 INFO  mapred.UserLogCleaner (UserLogCleaner.java:markJobLogsForDeletion(174)) - Adding job_test_0001 for user-log deletion with retainTimeStamp:7200000
..............
     [exec]     [junit] 2010-07-14 22:24:54,441 WARN  util.MRAsyncDiskService (MRAsyncDiskService.java:run(214)) - Failure in deletion of toBeDeleted/2010-07-14_22-2
"
MAPREDUCE-1970,Reed-Solomon code implementation to be used in raid,A Reed-Solomon erasure code implementation.
MAPREDUCE-1969,Allow raid to use Reed-Solomon erasure codes,"Currently raid uses one parity block per stripe which corrects one missing block on one stripe.
Using Reed-Solomon code, we can add any number of parity blocks to tolerate more missing blocks.
This way we can get a good file corrupt probability even if we set the replication to 1.

Here are some simple comparisons:
1. No raid, replication = 3:
File corruption probability = O(p^3), Storage space = 3x

2. Single parity raid with stripe size = 10, replication = 2:
File corruption probability = O(p^4), Storage space = 2.2x 

3. Reed-Solomon raid with parity size = 4 and stripe size = 10, replication = 1:
File corruption probability = O(p^5), Storage space = 1.4x

where p is the missing block probability.
Reed-Solomon code can save lots of space without compromising the corruption probability.

To achieve this, we need some changes to raid:
1. Add a block placement policy that knows about raid logic and do not put blocks on the same stripe on the same node.
2. Add an automatic block fixing mechanism. The block fixing will replace the replication of under replicated blocks.
3. Allow raid to use general erasure code. It is now hard coded using Xor.
4. Add a Reed-Solomon code implementation

We are planing to use it on the older data only.
Because setting replication = 1 hurts the data locality.
"
MAPREDUCE-1968,Deprecate GridMix v1,"GridMix v2 in ""src/benchmarks/gridmix2"" obsoletes GridMix v1 in ""src/benchmarks/gridmix"".
The latter should be deprecated and then removed to reduce the clutter in the source-tree.

One way of doing this is shown by the ""hadoop"" script from 0.20.xx that has been deprecated
in favour of ""mapred"", for example."
MAPREDUCE-1965,Add info for job failure on jobtracker UI.,"MAPREDUCE-1521 added a filed to jobstatus to mark reason for failures of the job. This information needs to be displayed on the jobtracker UI.
"
MAPREDUCE-1964,Running hi Ram jobs when TTs are blacklisted,"More slots are getting reserved for HiRAM job tasks then required 

Blacklist more than 25% TTs across the job.  Run high ram job.  No java.lang.RuntimeException should be displayed. "
MAPREDUCE-1961,[gridmix3] ConcurrentModificationException when shutting down Gridmix,"We observed the following exception occasionally at the end of the Gridmix run:

{code}
Exception in thread ""StatsCollectorThread"" java.util.ConcurrentModificationException
          at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
          at java.util.AbstractList$Itr.next(AbstractList.java:343)
          at org.apache.hadoop.mapred.gridmix.Statistics$StatCollector.updateAndNotifyClusterStatsListeners(Statistics.java:220)
          at org.apache.hadoop.mapred.gridmix.Statistics$StatCollector.run(Statistics.java:205)
{code}"
MAPREDUCE-1960,Limit the size of jobconf.,"In some of our production cluster users have huge job.xml's that bring down the jobtracker. THis jira is to put limit on the size of the jobconf, so that we dont blow up the memory on jobtracker."
MAPREDUCE-1958,using delegation token over hftp for long running clients (part of hdfs 1296),
MAPREDUCE-1956,allow reducer to initialize lazily,"From http://www.scribd.com/doc/23046928/Hadoop-Performance-Tuning:
""In M/R job Reducers are initialized with Mappers at the job initialization, but the reduce method is called in reduce phase when all the maps had been finished. So in large jobs where Reducer loads data (>100 MB for business logic) in-memory on initialization, the performance can be increased by lazily initializing Reducers i.e. loading data in reduce method controlled by an initialize flag variable which assures that it is loaded only once. By lazily initializing Reducers which require memory (for business logic) on initialization, number of maps can be increased.""

Introducing a parameter for this purpose would allow more people to utilize the above pattern."
MAPREDUCE-1952,Add a separate ant 'test' target for MapReduce tools,There should be some easy way to run {{tools}} tests in one go. 
MAPREDUCE-1951,SecurityAuth.audit file created after every test run,"After every test run, a SecurityAuth.audit file gets created in the $HADOOP_HOME folder which is not cleaned up."
MAPREDUCE-1947,test-patch target for javadoc broken?,"Running ""ant javadoc"" in mapreduce trunk gives following warning:
{noformat}
  [javadoc] /home/amarsri/workspace/mapreduce/src/java/org/apache/hadoop/mapreduce/Counter.java:125: warning - @param argument ""the"" is not a parameter name.
{noformat}
But test-patch did not complain for the patch build which introduced the warning, and it did not complain for any further builds.
"
MAPREDUCE-1945,Support for using different Kerberos keys for Jobtracker and TaskTrackers,This is the MapRed part of HADOOP-6632.
MAPREDUCE-1943,"Implement limits on per-job JobConf, Counters, StatusReport, Split-Sizes","We have come across issues in production clusters wherein users abuse counters, statusreport messages and split sizes. One such case was when one of the users had 100 million counters. This leads to jobtracker going out of memory and being unresponsive. In this jira I am proposing to put sane limits on the status report length, the number of counters and the size of block locations returned by the input split. "
MAPREDUCE-1942, 'compile-fault-inject' should never be called directly.,Similar to HDFS-1299: prevent calls to helper targets.
MAPREDUCE-1941,Need a servlet in JobTracker to stream contents of the job history file,"There is no convenient mechanism to retrieve the contents of the job history file. Need a way to retrieve the job history file contents from Job Tracker. 

This can perhaps be implemented as a servlet on the Job tracker.

* Create a jsp/servlet that accepts job id as a request parameter
* Stream the contents of the history file corresponding to the job id, if user has permissions to view the job details."
MAPREDUCE-1939,split reduce compute phase into two threads one for reading and another for computing,"it is known that  reduce task is made up of three phases: shuffle , sort and reduce. During reduce phase, a reduce function will read a record from disk or memory first and process it to write to hdfs finally. To convert this serial progress to parallel progress , I split the reduce phase into two threads called producer and consumer individually. producer is used to read record from disk and consumer to process the records read by the first one. I use two buffer, if  producer is writing one buffer consumer will read from another buffer.  Theoretically  there will be a overlap between this two phases so we can reduce the whole reduce time.

I wonder why hadoop does not implement it originally? Is there some potential problems for such ideas ?

I have already implemmented a prototypy. The producer just reads bytes from the disk and leaves the work of transformation to real key and value objects to consumer. The results is not good only a improvement of 13%  for time. I think it has someting with the buffer size and the time spending on different threads.Maybe the tiem spend by consumer thread is too long and the producer has to wait until the next buffer is available."
MAPREDUCE-1938,Ability for having user's classes take precedence over the system classes for tasks' classpath,"It would be nice to have the ability in MapReduce to allow users to specify for their jobs alternate implementations of classes that are already defined in the MapReduce libraries. For example, an alternate implementation for CombineFileInputFormat. "
MAPREDUCE-1937,mvn-deployed snapshot is out of sync with trunk,"Trying to use the 0.22.0-SNAPSHOT artifacts from common, hdfs, and mapred retrieved from Apache maven in my project results in ""ClassNotFoundException: TokenStorage"". In common, ""TokenStorage"" was renamed to ""Credentials"". Building all three projects locally works -- suggesting that the publicly-published mapred jar is out-of-sync with trunk"
MAPREDUCE-1936,[gridmix3] Make Gridmix3 more customizable.,"I'd like to make gridmix3 more customizable. Specifically, the proposed customizations include:
- add (random) location information for each sleep map task.
- make the parameters used in stress submission load throttling configurable.
"
MAPREDUCE-1935,HFTP needs to be updated to use delegation tokens (from HDFS-1007),
MAPREDUCE-1932,record skipping doesn't work with the new map/reduce api,The new HADOOP-1230 map/reduce api doesn't support the record skipping features.
MAPREDUCE-1931,Gridmix forrest documentation ,Gridmix forrest documentation
MAPREDUCE-1930,Rumen expects history file names to be in old format,"Rumen expects history file names to be in old format. History file name format got changed in trunk, but Rumen is not modified to understand the new file name format. So TraceBulder is skipping processing of the new history file names. See the old patterns jobFileNameRegex and confFileNameRegex in TraceBuilder.java."
MAPREDUCE-1929,Allow artifacts to be published to the staging Apache Nexus Maven Repository,MapReduce companion issue to HADOOP-6847.
MAPREDUCE-1927,unit test for HADOOP-6835 (concatenated gzip support),More extensive test of concatenated gzip (and bzip2) decoding support for HADOOP-6835 (and HADOOP-4012 and HADOOP-6852).
MAPREDUCE-1926,MapReduce distribution is missing build-utils.xml,The tarball should be able to build itself.
MAPREDUCE-1925,TestRumenJobTraces fails in trunk,"TestRumenJobTraces failed with following error:
Error Message

the gold file contains more text at line 1 expected:<56> but was:<0>

Stacktrace

	at org.apache.hadoop.tools.rumen.TestRumenJobTraces.testHadoop20JHParser(TestRumenJobTraces.java:294)

Full log of the failure is available at http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/292/testReport/org.apache.hadoop.tools.rumen/TestRumenJobTraces/testHadoop20JHParser/"
MAPREDUCE-1924,Mappers running when reducers have finished,"Occasionally, I will run jobs for which some reducers are able to finish but there are still mappers running. I understand why sometimes mappers restart themselves even after the reduce phase has begun--too many fetch-failures, for example. But in today's case, ALL of the reducers have succeeded and are done, so these mappers really ARE unnecessary...so it is a bug that they are running.

Then, I killed one of them to see what was up--it just restarted itself. So, it is another bug that mappers don't know they're unnecessary when they're killed.

My guess is that if one of these jobs, which clearly finished at least once, were to die randomly a few times, it would take the whole job with it--even though the job has completed.

Whenever all reduce tasks are complete, Hadoop should kill ALL remaining map tasks and immediately move to finish the job.
"
MAPREDUCE-1920,Job.getCounters() returns null when using a cluster,"Calling Job.getCounters() after the job has completed (successfully) returns null.
"
MAPREDUCE-1918,Add documentation to Rumen,Add forrest documentation to Rumen tool.
MAPREDUCE-1916,Usage should be added to HadoopStreaming.java,"The command:
bin/hadoop jar streaming.jar
just prints :
No Arguments Given!

It should print the valid arguments also."
MAPREDUCE-1915,IndexCache - getIndexInformation - check reduce index Out Of Bounds,"When checking if the ""reduce"" index is out of bounds the check should be 

info.mapSpillRecord.size() <= reduce

instead of:

info.mapSpillRecord.size() < reduce

Not a big bug since an Out Of Bounds is thrown downstream anyway."
MAPREDUCE-1914,TrackerDistributedCacheManager never cleans its input directories,"When we localize a file into a node's cache, it's installed in a directory whose subroot is a random {{long}} .  These {{long}} s all sit in a single flat directory [per disk, per cluster node].  When the cached file is no longer needed, its reference count becomes zero in a tracking data structure.  The file then becomes eligible for deletion when the total amount of space occupied by cached files exceeds 10G [by default] or the total number of such files exceeds 10K.

However, when we delete a cached file, we don't delete the directory that contains it; this importantly includes the elements of the flat directory, which then accumulate until they reach a system limit, 32K in some cases, and then the node stops working.

We need to delete the flat directory when we delete the localized cache file it contains."
MAPREDUCE-1911,Fix errors in -info option in streaming,"Here are some of the findings by Karam while verifying -info option in streaming:
# We need to add ""Optional"" for -mapper, -reducer,-combiner and -file options.
# For -inputformat and -outputformat options, we should put ""Optional"" in the prefix for the sake on uniformity.
# We need to remove -cluster decription.
# -help option is not displayed in usage message.
# when displaying message for -info or -help options, we should not display ""Streaming Job Failed!""; also exit code should be 0 in case of -help/-info option.

"
MAPREDUCE-1910,Allow raid policy to specify a parent policy,We encountered the problem that there are lots of redundancy in our raid.xml file. Most of the policy shares the same properties. It will be nice if a policy can inherit from a previously defined policy and get the default properties from it. This way it is easier to maintain the raid policies.
MAPREDUCE-1908,DistributedRaidFileSystem does not handle ChecksumException correctly,"ChecksumException reports the offset of corruption within a block,
whereas DistributedRaidFileSystem.setAlternateLocations was expecting it
to report the offset of corruption within the file.

The best way of dealing with a missing block/corrupt block is to just
use the current seek offset in the file as the position of corruption.
"
MAPREDUCE-1907,nutch doesnt run under 0.20.2+228-1~karmic-cdh3b1 version of hadoop,"new versions of hadoop appear to put jars in a different format now, instead of file:/a/b/c/d/job.jar, its now jar:file:/a/b/c/d/job.jar!, which breaks nutch when its trying to load its plugins. Specifically, the stack trace looks like:

Caused by: java.lang.RuntimeException: x point org.apache.nutch.net.URLNormalizer not found.
at org.apache.nutch.net.URLNormalizers.<init>(URLNormalizers.java:124)
at org.apache.nutch.crawl.Injector$InjectMapper.configure(Injector.java:57)

A simple test class was written the used the URLFilters class, and the following stack trace resulted:

10/07/01 14:25:25 INFO mapred.JobClient: Task Id : attempt_201006171624_46525_m_000000_1, Status : FAILED
java.lang.RuntimeException: org.apache.nutch.net.URLFilter not found.
at org.apache.nutch.net.URLFilters.<init>(URLFilters.java:52)
at com.maxpoint.crawl.BidSampler$BIdSMapper.setup(BidSampler.java:42)
at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:142)
at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:621)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
at org.apache.hadoop.mapred.Child.main(Child.java:170)

Running this on an older version of hadoop works.
"
MAPREDUCE-1906,Lower default minimum heartbeat interval for tasktracker > Jobtracker,"I get a 0% to 15% performance increase for smaller clusters by making the heartbeat throttle stop penalizing clusters with less than 300 nodes.

Between 0.19 and 0.20, the default minimum heartbeat interval increased from 2s to 3s.   If a JobTracker is throttled at 100 heartbeats / sec for large clusters, why should a cluster with 10 nodes be throttled to 3.3 heartbeats per second?  "
MAPREDUCE-1905,Context.setStatus() and progress() api are ignored,"TaskAttemptContext.setStatus() and progress() were overriden in TaskInputOutputContext, inbranch 0.20, to call the underlying reporter apis. But the methods are no more over-riden in TaskInputOutputContextImpl after MAPREDUCE-954."
MAPREDUCE-1901,Jobs should not submit the same jar files over and over again,"Currently each Hadoop job uploads the required resources (jars/files/archives) to a new location in HDFS. Map-reduce nodes involved in executing this job would then download these resources into local disk.

In an environment where most of the users are using a standard set of jars and files (because they are using a framework like Hive/Pig) - the same jars keep getting uploaded and downloaded repeatedly. The overhead of this protocol (primarily in terms of end-user latency) is significant when:
- the jobs are small (and conversantly - large in number)
- Namenode is under load (meaning hdfs latencies are high and made worse, in part, by this protocol)

Hadoop should provide a way for jobs in a cooperative environment to not submit the same files over and again. Identifying and caching execution resources by a content signature (md5/sha) would be a good alternative to have available."
MAPREDUCE-1900,MapReduce daemons should close FileSystems that are not needed anymore,"Related to HADOOP-6843, this jira is to make MapReduce behave better with respect to closing FileSystems when they are not needed anymore."
MAPREDUCE-1899,[Herriot] Test jobsummary information for different jobs.,"Test the following scenarios.

1. Verify the job summary information for killed job.
2. Verify the job summary information for failed job.
3. Verify the job queue information in job summary after job has successfully completed.
4. Verify the job summary information for high ram jobs.
"
MAPREDUCE-1897,trunk build broken on compile-mapred-test,"...apparently.  Fresh checkout of trunk (all three hadoop-*), build.properties project.version fix, ant veryclean mvn-install of common, hdfs, and then mapreduce:

    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:52: cannot access org.apache.hadoop.test.system.DaemonProtocol
    [javac] class file for org.apache.hadoop.test.system.DaemonProtocol not found
    [javac]   static class FakeJobTracker extends JobTracker {
    [javac]          ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:60: non-static variable this cannot be referenced from a static context
    [javac]       this.trackers = tts;
    [javac]       ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:60: cannot find symbol
    [javac] symbol  : variable trackers
    [javac] location: class org.apache.hadoop.mapred.FakeObjectUtilities
    [javac]       this.trackers = tts;
    [javac]           ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:67: cannot find symbol
    [javac] symbol  : method taskTrackers()
    [javac] location: class org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker
    [javac]           taskTrackers().size() - getBlacklistedTrackerCount(),
    [javac]           ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:67: cannot find symbol
    [javac] symbol  : method getBlacklistedTrackerCount()
    [javac] location: class org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker
    [javac]           taskTrackers().size() - getBlacklistedTrackerCount(),
    [javac]                                   ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:68: cannot find symbol
    [javac] symbol  : method getBlacklistedTrackerCount()
    [javac] location: class org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker
    [javac]           getBlacklistedTrackerCount(), 0, 0, 0, totalSlots/2, totalSlots/2, 
    [javac]           ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:64: method does not override or implement a method from a supertype
    [javac]     @Override
    [javac]     ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:73: non-static variable this cannot be referenced from a static context
    [javac]       this.totalSlots = totalSlots;
    [javac]       ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/FakeObjectUtilities.java:73: cannot find symbol
    [javac] symbol  : variable totalSlots
    [javac] location: class org.apache.hadoop.mapred.FakeObjectUtilities
    [javac]       this.totalSlots = totalSlots;
    [javac]           ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgress.java:91: establishFirstContact(org.apache.hadoop.mapred.JobTracker,java.lang.String) in org.apache.hadoop.mapred.FakeObjectUtilities cannot be applied to (org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker,java.lang.String)
    [javac]           FakeObjectUtilities.establishFirstContact(jobTracker, s);
    [javac]                              ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgress.java:170: cannot find symbol
    [javac] symbol  : constructor MyFakeJobInProgress(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker)
    [javac] location: class org.apache.hadoop.mapred.TestJobInProgress.MyFakeJobInProgress
    [javac]     MyFakeJobInProgress job1 = new MyFakeJobInProgress(conf, jobTracker);
    [javac]                                ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgress.java:185: cannot find symbol
    [javac] symbol  : constructor MyFakeJobInProgress(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker)
    [javac] location: class org.apache.hadoop.mapred.TestJobInProgress.MyFakeJobInProgress
    [javac]     MyFakeJobInProgress job2 = new MyFakeJobInProgress(conf, jobTracker);
    [javac]                                ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgress.java:225: cannot find symbol
    [javac] symbol  : constructor MyFakeJobInProgress(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker)
    [javac] location: class org.apache.hadoop.mapred.TestJobInProgress.MyFakeJobInProgress
    [javac]     MyFakeJobInProgress jip = new MyFakeJobInProgress(conf, jobTracker);
    [javac]                               ^
    [javac] /home/roelofs/grid/trunk2/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgress.java:296: cannot find symbol
    [javac] symbol  : constructor MyFakeJobInProgress(org.apache.hadoop.mapred.JobConf,org.apache.hadoop.mapred.FakeObjectUtilities.FakeJobTracker)
    [javac] location: class org.apache.hadoop.mapred.TestJobInProgress.MyFakeJobInProgress
    [javac]     MyFakeJobInProgress jspy = spy(new MyFakeJobInProgress(conf, jobTracker));
    [javac]                                    ^
"
MAPREDUCE-1896,[Herriot] New property for multi user list.,Adding new property for multi user list.
MAPREDUCE-1894,DistributedRaidFileSystem.readFully() does not return,DistributedRaidFileSystem.readFully() has a while(true) loop with no return. The read(*) functions do not have this problem.
MAPREDUCE-1893,Multiple reducers for Slive,Slive currently uses single reducer. It could use multiple ones.
MAPREDUCE-1892,RaidNode can allow layered policies more efficiently,"The RaidNode policy file can have layered policies that can cover a file more than once. To avoid processing a file multiple times (for RAIDing), RaidNode maintains a list of processed files that is used to avoid duplicate processing attempts.

This is problematic in that a large number of processed files could cause the RaidNode to run out of memory.

This task proposes a better method of detecting processed files. The method is based on the observation that a more selective policy will have a better match with a file name than a less selective one. Specifically, the more selective policy will have a longer common prefix with the file name.

So to detect if a file has already been processed, the RaidNode only needs to maintain a list of processed policies and compare the lengths of the common prefixes. If the file has a longer common prefix with one of the processed policies than with the current policy, it can be assumed to be processed already."
MAPREDUCE-1888,Streaming overrides user given output key and value types.,"The following code in StreamJob.java overrides user given output key and value types.
{code}
    idResolver.resolve(conf.get(StreamJobConfig.MAP_OUTPUT,
        IdentifierResolver.TEXT_ID));
    conf.setClass(StreamJobConfig.MAP_OUTPUT_READER_CLASS,
      idResolver.getOutputReaderClass(), OutputReader.class);
    job.setMapOutputKeyClass(idResolver.getOutputKeyClass());
    job.setMapOutputValueClass(idResolver.getOutputValueClass());
    
    idResolver.resolve(conf.get(StreamJobConfig.REDUCE_OUTPUT,
        IdentifierResolver.TEXT_ID));
    conf.setClass(StreamJobConfig.REDUCE_OUTPUT_READER_CLASS,
      idResolver.getOutputReaderClass(), OutputReader.class);
    job.setOutputKeyClass(idResolver.getOutputKeyClass());
    job.setOutputValueClass(idResolver.getOutputValueClass());
{code}
"
MAPREDUCE-1887,MRAsyncDiskService does not properly absolutize volume root paths,"In MRAsyncDiskService, volume names are sometimes specified as relative paths, which are not converted to absolute paths. This can cause errors of the form ""cannot delete </full/path/to/foo> since it is outside of <relative/volume/root>"" even though the actual path is inside the root. "
MAPREDUCE-1885,Trunk compilation is broken because of FileSystem api change in HADOOP-6826,"Trunk compilation is broken because of FileSystem api change in HADOOP-6826.

Here are the error messages:

     [iajc] /home/gravi/workspace/gitMR/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/JobHistory.java:277 [error] The method create(Path, FsPermission, boolean, int, short, long, Progressable) in the type FileSystem is not applicable for the arguments (Path, FsPermission, EnumSet<CreateFlag>, int, short, long, null)
     [iajc] FSDataOutputStream out = logDirFs.create(logFile,
     [iajc]                                   ^
     [iajc] /home/gravi/workspace/gitMR/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/JobHistory.java:297 [error] The method create(Path, FsPermission, boolean, int, short, long, Progressable) in the type FileSystem is not applicable for the arguments (Path, FsPermission, EnumSet<CreateFlag>, int, short, long, null)
     [iajc] jobFileOut = logDirFs.create(logDirConfPath,
     [iajc]
     [iajc]
     [iajc] 2 errors
"
MAPREDUCE-1884,Remove/deprecate mapred.map.tasks tunable,"Considering it isn't used for much that I know, is there any reason to keep the mapred.map.tasks tunable hanging around?  If not, let's remove it from the documentation, xml files, etc.  All it does is generate user confusion when it doesn't work."
MAPREDUCE-1881,Improve TaskTrackerInstrumentation,"The TaskTrackerInstrumentation class provides a useful way to capture key events at the TaskTracker for use in various reporting tools, but it is currently rather limited, because only one TaskTrackerInstrumentation can be added to a given TaskTracker and this objects receives minimal information about tasks (only their IDs). I propose enhancing the functionality through two changes:

# Support a comma-separated list of TaskTrackerInstrumentation classes rather than just a single one in the JobConf, and report events to all of them.
# Make the reportTaskLaunch and reportTaskEnd methods in TaskTrackerInstrumentation receive a reference to a whole Task object rather than just its TaskAttemptID. It might also be useful to make the latter receive the task's final state, i.e. failed, killed, or successful.

I'm just posting this here to get a sense of whether this is a good idea. If people think it's okay, I will make a patch against trunk that implements these changes."
MAPREDUCE-1880,"""java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result."" while running ""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 4 30""","If I run ""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 4 30"", I get the following output:

Number of Maps  = 4
Samples per Map = 30
Wrote input for Map #0
Wrote input for Map #1
Wrote input for Map #2
Wrote input for Map #3
Starting Job
10/06/19 21:50:34 INFO mapred.FileInputFormat: Total input paths to process : 4
10/06/19 21:50:34 INFO mapred.JobClient: Running job: job_201006192101_0003
10/06/19 21:50:35 INFO mapred.JobClient:  map 0% reduce 0%
10/06/19 21:50:45 INFO mapred.JobClient:  map 50% reduce 0%
10/06/19 21:50:51 INFO mapred.JobClient:  map 100% reduce 0%
10/06/19 21:51:00 INFO mapred.JobClient:  map 100% reduce 100%
10/06/19 21:51:02 INFO mapred.JobClient: Job complete: job_201006192101_0003
10/06/19 21:51:02 INFO mapred.JobClient: Counters: 18
10/06/19 21:51:02 INFO mapred.JobClient:   Job Counters 
10/06/19 21:51:02 INFO mapred.JobClient:     Launched reduce tasks=1
10/06/19 21:51:02 INFO mapred.JobClient:     Launched map tasks=4
10/06/19 21:51:02 INFO mapred.JobClient:     Data-local map tasks=4
10/06/19 21:51:02 INFO mapred.JobClient:   FileSystemCounters
10/06/19 21:51:02 INFO mapred.JobClient:     FILE_BYTES_READ=94
10/06/19 21:51:02 INFO mapred.JobClient:     HDFS_BYTES_READ=472
10/06/19 21:51:02 INFO mapred.JobClient:     FILE_BYTES_WRITTEN=334
10/06/19 21:51:02 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=215
10/06/19 21:51:02 INFO mapred.JobClient:   Map-Reduce Framework
10/06/19 21:51:02 INFO mapred.JobClient:     Reduce input groups=8
10/06/19 21:51:02 INFO mapred.JobClient:     Combine output records=0
10/06/19 21:51:02 INFO mapred.JobClient:     Map input records=4
10/06/19 21:51:02 INFO mapred.JobClient:     Reduce shuffle bytes=112
10/06/19 21:51:02 INFO mapred.JobClient:     Reduce output records=0
10/06/19 21:51:02 INFO mapred.JobClient:     Spilled Records=16
10/06/19 21:51:02 INFO mapred.JobClient:     Map output bytes=72
10/06/19 21:51:02 INFO mapred.JobClient:     Map input bytes=96
10/06/19 21:51:02 INFO mapred.JobClient:     Combine input records=0
10/06/19 21:51:02 INFO mapred.JobClient:     Map output records=8
10/06/19 21:51:02 INFO mapred.JobClient:     Reduce input records=8
Job Finished in 28.593 seconds
java.lang.ArithmeticException: Non-terminating decimal expansion; no exact representable decimal result.
	at java.math.BigDecimal.divide(BigDecimal.java:1603)
	at org.apache.hadoop.examples.PiEstimator.estimate(PiEstimator.java:313)
	at org.apache.hadoop.examples.PiEstimator.run(PiEstimator.java:342)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.examples.PiEstimator.main(PiEstimator.java:351)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:68)
	at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:139)
	at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:64)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:156)


""hadoop jar hadoop-0.20.1+169.89-examples.jar pi 2 10"" finishes fine"
MAPREDUCE-1879,JobTracker web page showing &apos;,"{noformat}
On the secure JobTracker web page, I saw

    Active users:
    User &apos;tsz&apos;: 1985 (100.0% of used capacity)

According to W3C (http://www.w3.org/TR/xhtml1/#C_16),
&#39; should be used instead of &apos;
{noformat}"
MAPREDUCE-1878,Add MRUnit documentation,"A short user guide for MRUnit, written in asciidoc."
MAPREDUCE-1876,TaskAttemptStartedEvent.java incorrectly logs MAP_ATTEMPT_STARTED as event type for reduce tasks,"{{TaskAttemptStartedEvent}} is used to log the start time of both the map and reduce task attempts to {{JobHistory}}. Following is the implementation of _getEventType()_ method of {{TaskAttemptStartedEvent}}

{code}
/** Get the event type */
  public EventType getEventType() {
    return EventType.MAP_ATTEMPT_STARTED;
  }
{code}

"
MAPREDUCE-1875,Need sample map reduce program for arithmetic calculations from text files  and produce the results in hadoop 0.20.2,"Hi I am new to Hadoop Map-reduce programming. Can anyone provide me the sample map-reduce code for some basic arithmatic calculations. Like, read from the text /csv files and then do some addition/sub/multi/div opearations and produce the output.
Kindly anyone help me on this"
MAPREDUCE-1874,Enable column sorting for all JobTracker Administration UI tables ,"Add ability to sort columns in ascending or descending order for all JobTracker Admin tables 

""Scheduling Info""
""Running Jobs"" 
""Retired Jobs"" 
""Completed Jobs"""
MAPREDUCE-1872,Re-think (user|queue) limits on (tasks|jobs) in the CapacityScheduler,"We need to re-think our story to have lead to a better overall picture of having limits on {users, queues} w.r.t 
# Jobs - limits on submission, initialization
# Tasks - limits per-job, per-queue on total tasks, concurrent tasks etc.

"
MAPREDUCE-1871,"Create automated test scenario for ""Collect information about number of tasks succeeded / total per time unit for a tasktracker""","Create automated test scenario for ""Collect information about number of tasks succeeded / total per time unit for a tasktracker""

1) Verification of all the above mentioned fields with the specified TTs. Total no. of tasks and successful tasks should be equal to the corresponding no. of tasks specified in TTs logs

2)  Fail a task on tasktracker.  Node UI should update the status of tasks on that TT accordingly. 

3)  Kill a task on tasktracker.  Node UI should update the status of tasks on that TT accordingly

4) Positive Run simultaneous jobs and check if all the fields are populated with proper values of tasks.  Node UI should have correct valiues for all the fields mentioned above. 

5)  Check the fields across one hour window  Fields related to hour should be updated after every hour

6) Check the fields across one day window  fields related to hour should be updated after every day

7) Restart a TT and bring it back.  UI should retain the fields values.  

8) Positive Run a bunch of jobs with 0 maps and 0 reduces simultanously.
"
MAPREDUCE-1870,Harmonize MapReduce JAR library versions with Common and HDFS,MapReduce part of HADOOP-6800.
MAPREDUCE-1869,TaskTracker hangs due to Java's usage of fork() being MT-unsafe,"A TaskTracker process on our grid appears to be locked up and not sending heartbeats to the namenode.  Attaching jstack and pstack output.  Even tho the hangs appear to be in LocalDirAllocator, the local file system seems to be a-ok.  
"
MAPREDUCE-1868,Add read timeout on userlog pull,"Add read and connection timeout to prevent job client hangs

jobclient can block indefinitely during task log pull if read or connect fails 

        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1049)
        - locked <0xeed0f0f0> (a sun.net.www.protocol.http.HttpURLConnection)
        at org.apache.hadoop.mapred.JobClient.getTaskLogs(JobClient.java:1396)
"
MAPREDUCE-1867,Remove unused methods in org.apache.hadoop.streaming.StreamUtil,There are many unused methods in org.apache.hadoop.streaming.StreamUtil. They should be removed from the class for maintainability. 
MAPREDUCE-1866,Remove deprecated class org.apache.hadoop.streaming.UTF8ByteArrayUtils,"The class org.apache.hadoop.streaming.UTF8ByteArrayUtils is deprecated in favor of org.apache.hadoop.util.UTF8ByteArrayUtils in branch 0.19.
The same should be removed."
MAPREDUCE-1865,[Rumen] Rumen should also support jobhistory files generated using trunk,Rumen code in trunk parses and process only jobhistory files from pre-21 hadoop mapreduce clusters. It should also support jobhistory files generated using trunk.
MAPREDUCE-1864,PipeMapRed.java has uninitialized members log_ and LOGNAME ,"PipeMapRed.java has members log_ and LOGNAME, which are never initialized and they are used in code for logging in several places. 
They should be removed and PipeMapRed should use commons LogFactory and Log for logging. This would improve code maintainability.

Also, as per [comment | https://issues.apache.org/jira/browse/MAPREDUCE-1851?focusedCommentId=12878530&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12878530], stream.joblog_ configuration property can be removed.
"
MAPREDUCE-1863,[Rumen] Null failedMapAttemptCDFs in job traces generated by Rumen,All the traces generated by Rumen for jobs having failed task attempts has null value for failedMapAttemptCDFs.
MAPREDUCE-1862,Distributed Cache doesn't accept paths from non-default filesystems,"addFileToClassPath/addArchive... try to qualify supplied against default file system. this fails when the supplied path doesn't belong to default file system.

this happens during local mode execution. fs.default.name may be pointing to production hdfs. localjobrunner tries to add files in local filesystem (because, starting 0.21, it correctly uses a local system dir) to distributed cache. this bombs."
MAPREDUCE-1861,Raid should rearrange the replicas while raiding,"Raided file introduce extra dependencies on the blocks on the same stripe.
Therefore we need a new way to place the blocks.

It is desirable that raided file satisfies the following two conditions:
a. Replicas on the same stripe should be on different machines (or racks)
b. Replicas of the same block should be on different racks

MAPREDUCE-1831 will try to delete the replicas on the same stripe and the same machine (a).
But in the mean time, it will try to maintain the number of distinct racks of one block (b).
We cannot satisfy (a) and (b) at the same time with the current logic in BlockPlacementPolicyDefault.chooseTarget().

One choice we have is to change BlockPlacementPolicyDefault.chooseTarget().
However, this placement is in general good for all files including the unraided ones.
It is not clear to us that we can make this good for both raided and unraided files.

So we propose this idea that when raiding the file. We create one more off-rack replica (so the replication=4 now).
Than we delete two blocks using the policy in MAPREDUCE-1831 after that (replication=2 now).
This way we can rearrange the replicas to satisfy (a) and (b) at the same time.
"
MAPREDUCE-1860,LocalJobRunner should use local filesystem to qualify systemdir,"getSystemDir() in LocalJobRunner returns a path qualified using the default file system from the Configuration. Usually default filesystem is set to hdfs cluster. which means that when trying to use the local mode - the jobclient ends up using hdfs as system directory.

this seems like an error. localjobrunner should use local file system as it's default file system and that should be used to qualify the mapred system directory."
MAPREDUCE-1859,maxConcurrentMapTask & maxConcurrentReduceTask per job,"It would be valuable if one could specify the max number of map/reduce slots which should be used for a given job. An example would be an map-reduce job importing from a database where you don't want 50 map tasks querying one db at a time but also you don't want to shrink the overall map task count.
Also this is probably already possible through Fair/Capacity-Scheduler or an own Extension i think it would be a good addition for the default TaskScheduler since this seems to be more then a rare used feature.
This would have the benefit in situations where you don't have control/ownership over the cluster as well. 
And its more job-centric whereas the existing scheduler extensions seems to be more job-type-centric.

Implementing this feature should be relatively straightforward. Adding something like jobConf.setMaxConcurrentMapTask(int) and respecting this configuration in JobQueueTaskScheduler.

Not sure if this feature would be harmonical with the existing Fair/Capacity-Schedulers.


"
MAPREDUCE-1858,TestCopyFiles fails consistently on trunk,"
All the tests in TestCopyFiles fail. For e.g.

{code}
Testcase: testCopyFromLocalToLocal took 10.051 sec
        Caused an ERROR
File /home/vinodkv/Workspace/eclipse-workspace/apache-svn-mapreduce/trunk/build/test/data/destdat/one/one/9208695393420117603 does not exist.
java.io.FileNotFoundException: File /home/vinodkv/Workspace/eclipse-workspace/apache-svn-mapreduce/trunk/build/test/data/destdat/one/one/9208695393420117603 does not exist.
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:420)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:290)
        at org.apache.hadoop.tools.TestCopyFiles.checkFiles(TestCopyFiles.java:169)
        at org.apache.hadoop.tools.TestCopyFiles.checkFiles(TestCopyFiles.java:159)
        at org.apache.hadoop.tools.TestCopyFiles.testCopyFromLocalToLocal(TestCopyFiles.java:271)
{code}"
MAPREDUCE-1857,Remove unused streaming configuration from src,The configuration stream.numinputspecs is just set and not read anywhere. It can be removed.
MAPREDUCE-1856,Extract a subset of tests for smoke (DOA) validation,"Similar to that of HDFS-1199 for MapReduce.
Adds an ability to run up to 30 minutes of the tests to 'smoke' MapReduce build i.e. find possible issues faster than the full test cycle does)."
MAPREDUCE-1855,refreshSuperUserGroupsConfiguration for MR should use server side configuration for the refresh (for HADOOP-6815),
MAPREDUCE-1853,MultipleOutputs does not cache TaskAttemptContext,"In MultipleOutputs there is
{code}
 private TaskAttemptContext getContext(String nameOutput) throws IOException {
    // The following trick leverages the instantiation of a record writer via
    // the job thus supporting arbitrary output formats.
    Job job = new Job(context.getConfiguration());
    job.setOutputFormatClass(getNamedOutputFormatClass(context, nameOutput));
    job.setOutputKeyClass(getNamedOutputKeyClass(context, nameOutput));
    job.setOutputValueClass(getNamedOutputValueClass(context, nameOutput));
    TaskAttemptContext taskContext = 
      new TaskAttemptContextImpl(job.getConfiguration(), 
                                 context.getTaskAttemptID());
    return taskContext;
  }
{code}

so for every reduce call it creates a new Job instance ...which creates a new LocalJobRunner.
That does not sound like a good idea.

You end up with a flood of ""jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized""

This should probably also be added to 0.22."
MAPREDUCE-1852,build/test path is hardcoded in many testcases.,"build/test path is hardcoded in many testcases, instead it should be read from system property test.build.dir or any other other appropriate property."
MAPREDUCE-1851,Document configuration parameters in streaming,"There are several streaming options such as stream.map.output.field.separator, stream.num.map.output.key.fields, stream.map.input.field.separator,  stream.reduce.input.field.separator,  stream.map.input.ignoreKey, stream.non.zero.exit.is.failure etc which are spread everywhere. These should be documented at single place with description and default-value."
MAPREDUCE-1850,Include job submit host information (name and ip) in jobconf and jobdetails display,Enhancement to identify the source (submit host and ip) of a job request. 
MAPREDUCE-1849,Implement a FlumeJava-like library for operations over parallel collections using Hadoop MapReduce,The API used internally at Google is described in great detail at http://portal.acm.org/citation.cfm?id=1806596.1806638.
MAPREDUCE-1848,"Put number of speculative, data local, rack local tasks in JobTracker metrics",It will be nice that we can collect these information in JobTracker metrics
MAPREDUCE-1847,capacity scheduler job tasks summaries are wrong if nodes fail,The Job Scheduling Information the web UI is needs to be re-computed in case nodes fail.  Otherwise it will report tasks are running that are not.
MAPREDUCE-1846,Add option to run Slive tests in test jar driver. ,Currently there is no way to run Slive tests through test jar. It is required to add option to run slive tests from test jar driver.
MAPREDUCE-1845,FairScheduler.tasksToPeempt() can return negative number,"This method can return negative number. This will cause the preemption to under-preempt.
The bug was discovered by Joydeep."
MAPREDUCE-1844,Tests failing with java.lang.NoClassDefFoundError,"Tests are failing with java.lang.NoClassDefFoundError (see http://pastebin.com/Y3E8iDw0). Steps to reproduce on trunk
1) Delete ~/.ivy2
2) checkout trunk
3) ant -Dtestcase=TestMRCLI run-test-mapred
"
MAPREDUCE-1843,Allow for map and reduce specific DistributedCache artifacts,"In several cases, only the maps or the reduces need artifacts in the DistributedCache. We need to allow for the same."
MAPREDUCE-1841,o.a.h.mapreduce.FileOutputCommitter doens't check for existence of ${mapred.output.dir}/_temporary,"o.a.h.mapred.FileOutputCommitter.getWorkOutputPath checks for existence of ${mapred.output.dir}/_temporary to ensure tasks launched _after_ the job-cleanup task fail early (in a vast majority of cases). This check is missing in the mapreduce libraries.

Related note: FileOutputCommitter.setupTask seems a more appropriate place for the above check..."
MAPREDUCE-1840,[Gridmix] Exploit/Add security features in GridMix,"Use security information while replaying jobs in Gridmix. This includes
- Support for multiple users
- Submitting jobs as different users
- Allowing usage of secure cluster (hdfs + mapreduce)
- Support for multiple queues

Other features include : 
- Support for sleep job
- Support for load job 

+ testcases for verifying all of the above changes"
MAPREDUCE-1839,HadoopArchives should provide a way to configure replication,"When creating HAR archives, the part files use the default replication of the filesystem. This should be made configurable through either the configuration file or command line."
MAPREDUCE-1838,DistRaid map tasks have large variance in running times,"HDFS RAID uses map-reduce jobs to generate parity files for a set of source files. Each map task gets a subset of files to operate on. The current code assigns files by walking through the list of files given in the constructor of DistRaid

The problem is that the list of files given to the constructor has the order of (pretty much) the directory listing. When a large number of files is added, files in that order tend to have the same size. Thus a map task can end up with large files where as another can end up with small files, increasing the variance in run times.

We could do smarter assignment by using the file sizes."
MAPREDUCE-1837,Raid should store the metadata in HDFS,"Currently if you change the stripe length in the raid policy. The existing raided files cannot be recovered.
Also in the future if we want to upgrade to a better erasure code such as Reed-Solomon or LDPC and change the policy for that.
The same problem will happen. We can avoid this problem if we store the information in a metadata file.
"
MAPREDUCE-1836,Refresh for proxy superuser config (mr part for HDFS-1096),
MAPREDUCE-1835,TestDelegationTokenRenewal token fails sometimes in branch 0.21,"org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal fails sometimes in branch 0.21.

The test fails with following error:
Testcase: testDTRenewal took 15.606 sec
	FAILED
renew wasn't called as many times as expected expected:<5> but was:<4>
junit.framework.AssertionFailedError: renew wasn't called as many times as expected expected:<5> but was:<4>
	at org.apache.hadoop.mapreduce.security.token.TestDelegationTokenRenewal.testDTRenewal(TestDelegationTokenRenewal.java:303)

In run of 5, the test failed twice."
MAPREDUCE-1834,TestSimulatorDeterministicReplay timesout on trunk,"TestSimulatorDeterministicReplay timesout on trunk.
See hudson patch build http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/216/testReport/org.apache.hadoop.mapred/TestSimulatorDeterministicReplay/testMain/"
MAPREDUCE-1833,[gridmix3] limit the maximum task duration in sleep job.,"In production job history logs, sometimes a task takes very long time to finish. Replaying such trace in sleep-job mode in Gridmix3 would unnecessarily prolong the benchmark execution time. It would be desirable to allow users to limit the maximum task duration."
MAPREDUCE-1832,Support for file sizes less than 1MB in DFSIO benchmark.,Currently DFSIO benchmark allows to specify files sizes in 1MB increments. It would be useful to be able to specify smaller sizes.
MAPREDUCE-1831,BlockPlacement policy for RAID,"Raid introduce the new dependency between blocks within a file.
The blocks help decode each other. Therefore we should avoid put them on the same machine.

The proposed BlockPlacementPolicy does the following
1. When writing parity blocks, it avoid the parity blocks and source blocks sit together.
2. When reducing replication number, it deletes the blocks that sits with other dependent blocks.
3. It does not change the way we write normal files. It only has different behavior when processing raid files."
MAPREDUCE-1830,Ivy2.0 has bugs: let's upgrate to 2.1.0,Similar to HDFS-1177 Ivy needs to be upgraded up to 2.1
MAPREDUCE-1829,JobInProgress.findSpeculativeTask should use min() to find the candidate instead of sort(),"findSpeculativeTask needs only one candidate to speculate so it does not need to sort the whole list. It may looks OK but someone can still submit big jobs with small slow task thresholds. In this case, this sorting becomes expensive."
MAPREDUCE-1828,Job doesn't fail graciously when an invalid mapred.child.env value is specified,"When invalid input is given to -Dmapred.child.env=, ArrayIndexOutOfBoundsException is seen instead of giving a useful error message.

bin/hadoop jar hadoop-streaming.jar -Dmapred.child.env=""X:Y"" -input inp_empty -output out -mapper /bin/cat
-reducer /bin/cat

java.lang.Throwable: Child Error at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:242) Caused by:
java.lang.ArrayIndexOutOfBoundsException: 1 at
org.apache.hadoop.mapred.TaskRunner.getVMEnvironment(TaskRunner.java:571) at
org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:212)
"
MAPREDUCE-1825,jobqueue_details.jsp and FairSchedulerServelet should not call finishedMaps and finishedReduces when job is not initialized,"JobInProgress.finishedMaps() and finishedReduces() are synchronized. They are called from jobqueue_details.jsp and FairSchedulerServelet which iterates through all jobs. If any job is in initialization, these pages don't come up until the initialization finishes.

See [comment|https://issues.apache.org/jira/browse/MAPREDUCE-1354?focusedCommentId=12834139&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12834139] for more details"
MAPREDUCE-1824,JobTracker should reuse file system handle for delegation token renewal,"In trunk, the DelegationTokenRenewal obtains the file system handle by creating the uri out of service in the token, which is ip:port. The intention of this jira is to use host name of the namenode so that fils system handle in the cache on jobtracker could be re-used. This jira is created because such an optimization is there in 20 code and the patch attached is the direct port of the code in 20."
MAPREDUCE-1820,"InputSampler does not create a deep copy of the key object when creating a sample, which causes problems with some formats like SequenceFile<Text,Text>","I tried to use the InputSampler on a SequenceFile<Text,Text> and found that it comes up with duplicate keys in the sample.  The problem was tracked down to the fact that the Text object returned from the reader is essentially a wrapper pointing to a byte array, which changes as the sequence file reader progresses.  There was also a bug in that the reader should be initialized before the use.  The am attaching a patch that fixes both of the issues.  --Alex K"
MAPREDUCE-1819,RaidNode should be smarter in submitting Raid jobs,"The RaidNode currently computes parity files as follows:
1. Using RaidNode.selectFiles() to figure out what files to raid for a policy
2. Using #1 repeatedly for each configured policy to accumulate a list of files. 
3. Submitting a mapreduce job with the list of files from #2 using DistRaid.doDistRaid()

This task addresses the fact that #2 and #3 happen sequentially. The proposal is to submit a separate mapreduce job for the list of files for each policy and use another thread to track the progress of the submitted jobs. This will help reduce the time taken for files to be raided.
"
MAPREDUCE-1818,RaidNode should specify a pool name incase the cluster is using FairScheduler,contrib/fairscheduler (FairScheduler) supports scheduling based on pools. The RaidNode should specify a pool name based on configuration to make use of pools.
MAPREDUCE-1817,JT and TT should not have to match build versions,"TaskTracker#offerService checks for a match with the JT VersionInfo#getBuildVersion, and fails if they are the same version but happen to be built at a different time of day. It seems like the correct test is VersionInfo#getRevision.  fwiw the NN and DN do not have to match build versions. 
"
MAPREDUCE-1816,HAR files used for RAID parity need to have configurable partfile size,"RAID parity files are merged into HAR archives periodically. This is required to reduce the number of files that the NameNode has to track. The number of files present in a HAR archive depends on the size of HAR part files - higher the size, lower the number of files.
The size of HAR part files is configurable through the setting har.partfile.size, but that is a global setting. This task introduces a new setting specific to raid.har.partfile.size, that is used in-turn to set har.partfile.size"
MAPREDUCE-1815,Directory in logs/history causes ArrayIndexOutOfBoundsException,Creating a directory in the jobtracker history directory causes an ArrayIndexOutOfBounds exception.
MAPREDUCE-1813,NPE in PipeMapred.MRErrorThread,"Some reduce tasks fail with following NPE
java.lang.RuntimeException: java.lang.NullPointerException
        at org.apache.hadoop.streaming.PipeMapRed.waitOutputThreads(PipeMapRed.java:325)
        at org.apache.hadoop.streaming.PipeMapRed.mapRedFinished(PipeMapRed.java:540)
        at org.apache.hadoop.streaming.PipeReducer.close(PipeReducer.java:137)
        at org.apache.hadoop.mapred.ReduceTask.runOldReducer(ReduceTask.java:474)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:412)
        at org.apache.hadoop.mapred.Child.main(Child.java:159)
Caused by: java.lang.NullPointerException
       at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.setStatus(PipeMapRed.java:517)
        at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.run(PipeMapRed.java:449)
"
MAPREDUCE-1812,New properties for suspend and resume process.,Adding new properties in system-test-mr.xml file for suspend and resume process.
MAPREDUCE-1811,Job.monitorAndPrintJob() should print status of the job at completion,"Job.monitorAndPrintJob() just prints ""Job Complete"" at the end of the job. It should print the state whether the job SUCCEEDED/FAILED/KILLED."
MAPREDUCE-1810,0.21 build is broken,"/src/java/org/apache/hadoop/mapred/AdminOperationsProtocol.java:31: cannot find symbol
    [javac] symbol  : method value()
    [javac] location: @interface org.apache.hadoop.security.KerberosInfo
    [javac] @KerberosInfo(MRJobConfig.JOB_JOBTRACKER_ID)
"
MAPREDUCE-1809,Ant build changes for Streaming system tests in contrib projects.,Implementing new target( test-system) in build-contrib.xml file for executing the system test that are in contrib projects. Also adding 'subant'  target in aop.xml that calls the build-contrib.xml file for system tests.
MAPREDUCE-1807,TestQueueManager can take long enough to time out,"Sometimes TestQueueManager takes such a long time that the JUnit engine times out and declares it a failure.  We should fix this, possibly by splitting the file's 19 test cases into two or more manageable test sets."
MAPREDUCE-1806,CombineFileInputFormat does not work with paths not on default FS,"In generating the splits in CombineFileInputFormat, the scheme and authority are stripped out. This creates problems when trying to access the files while generating the splits, as without the har:/, the file won't be accessed through the HarFileSystem."
MAPREDUCE-1804,Stress-test tool for HDFS introduced in HDFS-708,This issue is to commit the SLive test developed in HDFS-708 to MR trunk.
MAPREDUCE-1803,0.21 nightly snapshot build has dependency on 0.22 snapshot,The POM generated in https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-mapred/0.21.0-SNAPSHOT/ has a reference to hadoop-core 0.22.0-SNAPSHOT 
MAPREDUCE-1802,allow outputcommitters to skip setup/cleanup,"Job setup and cleanup overheads in our (larger) clusters are very significant and add to latency for small jobs. It turns out that Hive does not require job setup and cleanup at all - since all management of output/temporary files and such is done by the hive client side. So it would be a big win for our environment (and Hive users in general) if we could skip job cleanup/setup altogether.

The proposal is to add new calls to OutputCommitter interface (along the lines of needsTaskCommit()) to optionally allow skipping of setup/cleanup and for the JT to take these into account while scheduling setup/cleanup. NullOutputFormat should not need setup/cleanup for example."
MAPREDUCE-1798,normalize property names for JT kerberos principal names in configuration (from HADOOP 6633),
MAPREDUCE-1797,The JobTracker lock can be a reader/writer lock,"The Jobtracker has a global lock and a per-job JobInProgress lock. The aim for the JobInprogress lock is to support the ability to lock a single job's metadata without  blocking out the entire JobTracker. However, many code paths acquire the JobTracker lock and then acquire the JobInProgress lock while keeping the JobTracker lock. This somewhat defeats the benefit of having a per-job lock."
MAPREDUCE-1796,job tracker history viewer shows all recent jobs as being run at job tracker (re)start time,"This has been the behavior of the History viewer for long that it
shows the timestamp when the JobTracker restarted rather than Job
start time."
MAPREDUCE-1795,"add error option if file-based record-readers fail to consume all input (e.g., concatenated gzip, bzip2)","When running MapReduce with concatenated gzip files as input, only the first part (""member"" in gzip spec parlance, http://www.ietf.org/rfc/rfc1952.txt) is read; the remainder is silently ignored.  As a first step toward fixing that, this issue will add a configurable option to throw an error in such cases.

MAPREDUCE-469 is the tracker for the more complete fix/feature, whenever that occurs."
MAPREDUCE-1794,Test the job status of lost task trackers before and after the timeout.,"This test covers the following scenarios.

1. Verify the job status whether it is succeeded or not when  the task tracker is lost and alive before the timeout.
2. Verify the job status and killed attempts of a task whether it is succeeded or not and killed attempts are matched or not  when the task trackers are lost and it timeout for all the four attempts of a task. "
MAPREDUCE-1792,add script that backups job statistics,"When cluster is terminated, job statistics from previous execution is lost.
A script should be created to backup job statistics so that analysis can be performed across cluster restart.

A utility to visualize job statistics is also desirable."
MAPREDUCE-1791,Remote cluster control functionality needs JavaDocs improvement,This is MR part of HADOOP-6752.
MAPREDUCE-1790,Automatic resolution of Lzo codecs is needed.,"The test cases are failing due to non-availablity of the jar  hadoop-gpl-compression-0.1.0-1005060043.jar, need changes to aop xml to fix this. "
MAPREDUCE-1789,MapReduce trunk fails to compile following HADOOP-6600,A few classes need updating following the change to KerberosInfo introduced in HADOOP-6600
MAPREDUCE-1788,o.a.h.mapreduce.Job shouldn't make a copy of the JobConf,Having o.a.h.mapreduce.Job make a copy of the passed in JobConf has several issues: any modifications done by various pieces such as InputSplit etc. are not reflected back and causes issues for frameworks built on top.
MAPREDUCE-1785,Add streaming config option for not emitting the key,PipeMapper currently does not emit the key when using TextInputFormat. If you switch to input formats (eg LzoTextInputFormat) the key will be emitted. We should add an option so users can explicitly make streaming not emit the key so they can change input formats without breaking or having to modify their existing programs.
MAPREDUCE-1784,IFile should check for null compressor,"IFile assumes that when it has a codec it can always get a compressor. This fails when mapred.compress.map.output is true but the native libraries are not installed, resulting in an NPE:

{code}
java.lang.NullPointerException
at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:102)
at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1198)
at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1091)
at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:359)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:307)
at org.apache.hadoop.mapred.Child.main(Child.java:170)
{code}

Let's make IFile handle this case by logging and using non-compressed streams.l"
MAPREDUCE-1783,Task Initialization should be delayed till when a job can be run,"The FairScheduler task scheduler uses PoolManager to impose limits on the number of jobs that can be running at a given time. However, jobs that are submitted are initiaiized immediately by EagerTaskInitializationListener by calling JobInProgress.initTasks. This causes the job split file to be read into memory. The split information is not needed until the number of running jobs is less than the maximum specified. If the amount of split information is large, this leads to unnecessary memory pressure on the Job Tracker.
To ease memory pressure, FairScheduler can use another implementation of JobInProgressListener that is aware of PoolManager limits and can delay task initialization until the number of running jobs is below the maximum."
MAPREDUCE-1781,"option ""-D mapred.tasktracker.map.tasks.maximum=1"" does not work when no of mappers is bigger than no of nodes - always spawns 2 mapers/node","Hello

I am a new user of Hadoop and I have some trouble using Hadoop Streaming and the ""-D mapred.tasktracker.map.tasks.maximum"" option. 

I'm experimenting with an unmanaged application (C++) which I want to run over several nodes in 2 scenarios
1) the number of maps (input splits) is equal to the number of nodes
2) the number of maps is a multiple of the number of nodes (5, 10, 20, ...

Initially, when running the tests in scenario 1 I would sometimes get 2 process/node on half the nodes. However I fixed this by adding the optin ""-D mapred.tasktracker.map.tasks.maximum=1"", so everything works fine.

In the case of scenario 2 (more maps than nodes) this directive no longer works, always obtaining 2 processes/node. I tested the even with putting maximum=5 and I still get 2 processes/node.

The entire command I use is:

/usr/bin/time --format=""-duration:\t%e |\t-MFaults:\t%F |\t-ContxtSwitch:\t%w"" \
 /opt/hadoop/bin/hadoop jar /opt/hadoop/contrib/streaming/hadoop-0.20.2-streaming.jar \
 -D mapred.tasktracker.map.tasks.maximum=1 \
 -D mapred.map.tasks=30 \
 -D mapred.reduce.tasks=0 \
 -D io.file.buffer.size=5242880 \
 -libjars ""/opt/hadoop/contrib/streaming/hadoop-7debug.jar"" \
 -input input/test \
 -output out1 \
 -mapper ""/opt/jobdata/script_1k"" \
 -inputformat ""me.MyInputFormat""

Why is this happening and how can I make it work properly (i.e. be able to limit exactly how many mappers I can have at 1 time per node)?

Thank you in advance"
MAPREDUCE-1780,AccessControlList.toString() is used for serialization of ACL in JobStatus.java,"HADOOP-6715 is created to fix AccessControlList.toString() for the case of WILDCARD. JobStatus.write() and readFields() assume that toString() returns the serialized String of AccessControlList object, which is not true. Once HADOOP-6715 gets fixed in COMMON, JobStatus.write() and JobStatus.readFields() should be fixed depending on the fix of HADOOP-6715."
MAPREDUCE-1779,Should we provide a way to know JobTracker's memory info from client?,"In HADOOP-4435, in branch 0.20, getClusterStatus() method returns JobTracker's used memory and total memory.
But these details are missed in new api (through MAPREDUCE-777).
If these details are needed only for web UI, I don't think they are needed for client.
So, should we provide a way to know JobTracker's memory info from client?
If yes, an api should be added in org.apache.hadoop.mapreduce.Cluster for the same."
MAPREDUCE-1778,CompletedJobStatusStore initialization should fail if {mapred.job.tracker.persist.jobstatus.dir} is unwritable,"If {mapred.job.tracker.persist.jobstatus.dir} points to an unwritable location or mkdir of {mapred.job.tracker.persist.jobstatus.dir} fails, then CompletedJobStatusStore silently ignores the failure and disables CompletedJobStatusStore. Ideally the JobTracker should bail out early indicating a misconfiguration."
MAPREDUCE-1777,"In streaming, jobs that used to work, crash in the map phase -- even if the mapper is /bin/cat","The exception is either ""out of memory"" of or ""broken pipe"" -- see both stack dumps bellow.

st Hadoop input: |null|
last tool output: |[B@20fa83|
Date: Sat Dec 15 21:02:18 UTC 2007
java.io.IOException: Broken pipe
        at java.io.FileOutputStream.writeBytes(Native Method)
        at java.io.FileOutputStream.write(FileOutputStream.java:260)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:124)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:96)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:192)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1760)


        at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:107)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:192)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1760)



-------------------------------------------------
java.io.IOException: MROutput/MRErrThread
failed:java.lang.OutOfMemoryError: Java heap space
        at java.util.Arrays.copyOf(Arrays.java:2786)
        at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)
        at java.io.DataOutputStream.write(DataOutputStream.java:90)
        at org.apache.hadoop.io.Text.write(Text.java:243)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect (MapTask.java:347)
        at org.apache.hadoop.streaming.PipeMapRed$MROutputThread.run (PipeMapRed.java:344)

        at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:76)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:192)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java: 
1760)
"
MAPREDUCE-1776,Hadoop should provide a simplified way of fetching user-logs,"Hi,

   Currently , in both streaming and normal mode hadoop mapred program, user can't download the 
logs programatically.

jobclient.output.filter=ALL, allows user to print output in the stdout/stderr


We need to have the ability to fetch the user logs from the framework.

in 0.18, under the hod , we used to store the logs in the hdfs.
For 0.20, as long as the jobhistory resides user can view the logs but then it's gone.

So in short , I am proposing that hadoop 
1) provide the options to the JobClient (i.e jobconf var jobclient.output.logs.location), so that it will download the output in the hdfs location instead of printing to stdout.

Thanks
Alok




Alok
"
MAPREDUCE-1774,Large-scale Automated Framework,This is MapReduce part of HADOOP-6332
MAPREDUCE-1773,streaming doesn't support jobclient.output.filter,"the streaming Jobclient implementation i.e contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java is significantly different than the core hadoop mapred/org/apache/hadoop/mapred/JobClient.java.

for example unlike StreamJob.java, JobClient.java it gets tasks log when jobclient.output.filter=ALL is specified .

With hod-logs going away in hadoop 0.20 (due to new scheduler) user has no good way of programmitically getting logs

We should have intermediate adaptor class to implement Tools for the purpose of submitting jobs via m/r, streaming, pipes so that we don't miss some core functionality.
 
GenericJobClient implements Tools and then StreamJob extends GenericJobClient, JobClient extends GenericJobClient

Alok"
MAPREDUCE-1772,Hadoop streaming doc should not use IdentityMapper as an example,"From the URL http://hadoop.apache.org/core/docs/current/streaming.html

This example doesn't work:
{quote}
You can supply a Java class as the mapper and/or the reducer. The above example is equivalent to:

$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \
    -reducer /bin/wc
{quote}

This will produce the following exception:
{quote}
java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, recieved org.apache.hadoop.io.LongWritable
{quote}
"
MAPREDUCE-1770,have option to limit stderr output from user scripts in hadoop streaming,"People often echo to stderr to debug their programs.  We have had cases where someone inadvertently dumped large amounts of data to stderr. this created large userlog directories and caused quite a few mapred slaves to become dysfunctional (logs partition was full).

Hence looking for a defensive measure against such errant scripts. We are currently putting in a limit on the number of bytes from the script's stderr that are forwarded to System.err.
"
MAPREDUCE-1769,"Streaming command should be able to take its output to a ""file"", rather then to stdout","In some cases, especially when a streaming command is a 3rd party or legacy application,
it is impossible of inconvenient to make it write its output to stdout
The command may require that the ouput file name is specified as a command line option, or the output file name is hard coded.

Related to https://issues.apache.org/jira/browse/HADOOP-2235"
MAPREDUCE-1767,Steaming infrastructures should provide statisics about job,"This should include
-- the commands (mapper and reducer commands) executed
-- time information (e.g. min, max, and avg start time, end time, elapsed time for tasks, total elapsed time )
-- sizes -- bytes and records, min, max, avg per task and total, input and output
-- information about input and output data sets (all output data sets, if there are several)
-- all user counters (when they are implemented for streaming)

the information should be stored in a file -- e.g. in the working directory from where the job was launched, with a name derived from the job name


"
MAPREDUCE-1766,Hadoop Streaming should not use TextInputFormat class as the default input format class.,"The TextInputFormat class does not work with IdentityMapper class.
"
MAPREDUCE-1765,Streaming doc - change StreamXmlRecord to StreamXmlRecordReader ,"Streaming doc - fix typo.

CHANGE:
hadoop jar hadoop-streaming.jar -inputreader ""StreamXmlRecord,begin=BEGIN_STRING,end=END_STRING"" ..... (rest of the command)

TO THIS:
hadoop jar hadoop-streaming.jar -inputreader ""StreamXmlRecordReader,begin=BEGIN_STRING,end=END_STRING"" ..... (rest of the command)

Note: No new test code; changes to documentation only.

See: Bugzilla Ticket 2520942 - XML Streaming "
MAPREDUCE-1763,JobHistory should enable history collection after a timeout or some other event,"If you search for disableHistory in JobHistory.java, one can discover that it is enabled only at the initialization time.  There are two instances where job history can be disabled:

* if it fails to initialize the the output directories
* If it fails to create a single job history file

There are a few problems with that.  One is that there is no way to revert the flag even if the original problem goes away.  Second, these cases should probably be handled separately.  The result of which is that once the job history file creation fails, the job history mechanism becomes disabled and there is no way to switch it back.

One simple solution is to have a timeout after which we can try to enable the job history collection.  Another is to have a more granular job history control per job.

Alex K
"
MAPREDUCE-1762,Add a setValue() method in Counter,"Counters are very useful because of the logging and transmitting are already there.
It is very convenient to transmit and store numbers. But currently Counter only has an increment() method.
It will be nice if there can be a setValue() method in this class that will allow us to transmit wider variety of information through it.

What do you think?"
MAPREDUCE-1761,FairScheduler should allow separate configuration of node and rack locality wait time,"It would be nice that we can separately assign rack locality wait time.
In our use case, we would set node locality wait to zero and wait only rack locality.

I propose that we add two parameters
mapred.fairscheduler.locality.delay.nodetorack
mapred.fairscheduler.locality.delay.racktoany
This allows specifying the wait time on each stage.

And we can use
mapred.fairscheduler.locality.delay
as the default value of the above fields so that this is backward compatible.

Thoughts?"
MAPREDUCE-1759,"Exception message for unauthorized user doing killJob, killTask, setJobPriority needs to be improved","The Exception message contains ADMINISTER_JOBS or MODIFY_JOB as the operation name when an unauthorized user tries to do killTask, killJob or setJobPriority operations. This needs to be changed so that user gets the correct operation instead of ADMINISTER_JOBS or MODIFY_JOB."
MAPREDUCE-1756,FairScheduler may assign tasks over the TaskTracker limit,"FairScheduler may assign tasks over the TaskTracker limit.
The over assigned task will wait on the TaskTracker in the state of UNASSIGNED causing a higher latency."
MAPREDUCE-1755,Zombie tasks kept alive by logging system,"I'm currently looking at a task that, as far as the task tracker is concerned, is dead.  Like long long long ago dead.  It was a failed task that ran out of heap.  Rather than just kill it, I thought I would see what it was doing, since it was clearly using system resources.  It would appear the system is trying to log but failing.  I'm guessing we're missing an error condition and not doing the appropriate thing. See the comments for more."
MAPREDUCE-1754,Replace mapred.persmissions.supergroup with an acl : mapreduce.cluster.administrators,"mapred.permissions.supergroup should be replaced with an acl so that it does not restrict the admins to a single group.
See more details on MAPREDUCE-1542."
MAPREDUCE-1752,Implement getFileBlockLocations in HarFilesystem,"To efficiently run map reduce on the data that has been HAR'ed it will be great to actually implement getFileBlockLocations for a given filename.
This way the JobTracker will have information about data locality and will schedule tasks appropriately.
I believe the overhead introduced by doing lookups in the index files can be smaller than that of copying data over the wire.
Will upload the patch shortly, but would love to get some feedback on this. And any ideas on how to test it are very welcome."
MAPREDUCE-1751,Change MapReduce to depend on Hadoop 'common' artifacts instead of 'core',This is the MapReduce part of HADOOP-6404.
MAPREDUCE-1749,Pull configuration strings out of JobContext,"The configuration strings should not have been included in JobContext, because they distract from the intended use of the interface."
MAPREDUCE-1748,Put back the documentation for the job-acls feature,"This is related to MAPREDUCE-1747 which removed the documentation of job-acls for 0.21 release. Once the branch is cut of 21, we should put back the documentation into the trunk/0.22."
MAPREDUCE-1747,Remove documentation for the 'unstable' job-acls feature,"As discussed [here|https://issues.apache.org/jira/browse/MAPREDUCE-1604?focusedCommentId=12862151&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12862151] and [here|https://issues.apache.org/jira/browse/MAPREDUCE-1604?focusedCommentId=12860916&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12860916] at MAPREDUCE-1604, the job-acls feature is currently unstable. Without MAPREDUCE-1664, job-acls are practically useless because of their problematic interactions with queue-acls. Removing them for 0.21 will both relieve ourselves of these problems as well as the burden to support the backwards compatibility of the configuration options as well as the going-to-be-changed semantics of the feature. This jira is about removing the documentation from 0.21 so that the completed feature can be added in 0.22 with ease."
MAPREDUCE-1744,DistributedCache creates its own FileSytem instance when adding a file/archive to the path,"According to the contract of {{UserGroupInformation.doAs()}} the only required operations within the {{doAs()}} block are the
creation of a {{JobClient}} or getting a {{FileSystem}} .

The {{DistributedCache.add(File/Archive)ToClasspath()}} methods create a {{FileSystem}} instance outside of the {{doAs()}} block,
this {{FileSystem}} instance is not in the scope of the proxy user but of the superuser and permissions may make the method
fail.

One option is to overload the methods above to receive a filesystem.

Another option is to do obtain the {{FileSystem}} within a {{doAs()}} block, for this it would be required to have the proxy
user set in the passed configuration.

The second option seems nicer, but I don't know if the proxy user is as a property in the jobconf."
MAPREDUCE-1742,Job.setNumReduceTasks doesn't work,"Calling Job.setNumReduceTasks(0) doesn't seem to work with the latest trunc, and the job still goes through a reduction phase.
Also, Job.setNumReduceTasks(1) doesn't seem to work either, and several reducers are spawned.

It seems that something about Job.setNumReduceTasks got broken recently."
MAPREDUCE-1741,Automate the test scenario of  job related files are moved from history directory to done directory,"Job related files are moved from history directory to done directory, when

1) Job succeeds
2) Job is killed
3) When 100 files are put in the done directory
4) When multiple jobs are completed at the same time, some successful, some failed.

Also, two files, conf.xml and job files should be present in the done directory."
MAPREDUCE-1740,NPE in getMatchingLevelForNodes when node locations are variable depth,"In getMatchingLevelForNodes, we assume that both nodes have the same ""depth"" (ie number of path components). If the user provides a topology script that assigns one node a path like /foo/bar/baz and another node a path like /foo/blah, this function will throw an NPE.

I'm not sure if there are other places where we assume that all node locations have a constant number of paths. If so we should check the output of the topology script aggressively to be sure this is the case. Otherwise I think we simply need to add && n2 != null to the while loop"
MAPREDUCE-1738,MapReduce portion of HADOOP-6728 (ovehaul metrics framework),
MAPREDUCE-1737,Refactoring of TestGridmixSubmission .,
MAPREDUCE-1735,Un-deprecate the old MapReduce API in the 0.21 branch,"This issue is to un-deprecate the ""old"" MapReduce API (in o.a.h.mapred) in the next 0.21 release, as discussed at http://www.mail-archive.com/mapreduce-dev@hadoop.apache.org/msg01833.html"
MAPREDUCE-1734,Un-deprecate the old MapReduce API in the 0.20 branch,"This issue is to un-deprecate the ""old"" MapReduce API (in o.a.h.mapred) in the next 0.20 release, as discussed at http://www.mail-archive.com/mapreduce-dev@hadoop.apache.org/msg01833.html"
MAPREDUCE-1733,Authentication between pipes processes and java counterparts.,The connection between a pipe process and its parent java process should be authenticated.
MAPREDUCE-1732,"""bin/hadoop jar hadoop-test.jar mrbench ...""  won't honor the -files option","When one of our users incanted 

{quote}
bin/hadoop jar hadoop-test.jar mrbench -baseDir /user/hdfs/mrbench -numRuns 3 -maps 28 -reduces 13 -inputLines 10000 -inputType ascending -files /grid/0/gs/hadoop/current/LOCAL-CHANGES.txt
{quote}

they got 

{quote}
MRBenchmark.0.0.2
Usage: mrbench [-baseDir <base DFS path for output/input, default is /benchmarks/MRBench>] [-jar <local path to job jar file containing Mapper and Reducer implementations, default is current jar file>] [-numRuns <number of times to run the job, default is 1>] [-maps <number of maps for each run, default is 2>] [-reduces <number of reduces for each run, default is 1>] [-inputLines <number of input lines to generate, default is 1>] [-inputType <type of input to generate, one of ascending (default), descending, random>] [-verbose]
{quote}

."
MAPREDUCE-1731,Process tree clean up suspended task tests.,"1 .Verify the process tree cleanup of suspended task and task should be terminated after timeout.
2. Verify the process tree cleanup of suspended task and resume the task before task timeout."
MAPREDUCE-1730,Automate test scenario for successful/killed jobs' memory is properly removed from jobtracker after these jobs retire.,"Automate using herriot framework,  test scenario for successful/killed jobs' memory is properly removed from jobtracker after these jobs retire.

This should test when successful and failed jobs are retired,  their jobInProgress object are removed properly.
"
MAPREDUCE-1729,"Distributed cache should provide an option to fail the job or not, if cache file gets modified on the fly.","Currently, distributed cache fails the job if the cache file gets modified on the fly. But there should be an option to fail a job or not.
See discussions in MAPREDUCE-1288.
"
MAPREDUCE-1728,Oracle timezone strings do not match Java,"OracleDBRecordReader sets the session timezone based on the toString representation of the current java.util.TimeZone. This is incorrect; Oracle manages a separate database of acceptable timezone strings, whose string representations are different than the timezone representations recognized by Java."
MAPREDUCE-1727,TestJobACLs fails after HADOOP-6686,"HADOOP-6686, an incompatbile change, removed exception class name in unwrapped exceptions thrown at the RPC client. TestJobACLs depended on this for verifying exceptions, and thus is broken now."
MAPREDUCE-1725,Fix MapReduce API incompatibilities between 0.20 and 0.21,A few API compatibilities have crept in since 0.20 (they are being tracked in MAPREDUCE-1623). These should be fixed before 0.21 is released.
MAPREDUCE-1724,JobTracker balks at empty String for locations,"If a split has locations which are """" (empty String), then the JobTracker will get upset during initialization:

2010-04-22 19:09:20,395 ERROR org.apache.hadoop.mapred.JobTracker: Job initialization failed:
java.lang.StringIndexOutOfBoundsException: String index out of range: 0
        at java.lang.String.charAt(String.java:687)
        at org.apache.hadoop.net.NetUtils.normalizeHostName(NetUtils.java:420)
        at org.apache.hadoop.net.NetUtils.normalizeHostNames(NetUtils.java:443)
        at org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:42)
        at org.apache.hadoop.mapred.JobTracker.resolveAndAddToTopology(JobTracker.java:2411)
        at org.apache.hadoop.mapred.JobInProgress.createCache(JobInProgress.java:360)
        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:462)
        at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:3183)
        at org.apache.hadoop.mapred.EagerTaskInitializationListener$InitJob.run(EagerTaskInitializationListener.java:79)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
        at java.lang.Thread.run(Thread.java:637)

Two key points:
 * This is different from Hadoop 0.18
 * CombineFileSplit has a constructor where String[] location is not specified, and hence the location array is populated with empty Strings."
MAPREDUCE-1723,Capacity Scheduler should allow configuration of Map & Reduce task slots independently per queue,The Capacity Scheduler allows configuration of percentage of task slots per queue. We have a scenario in which our biggest queue (50% quota) has Jobs with mainly Map tasks & we need to enforce strict capacity limits per queue due to SLA requirements. So other smaller queues which require Reduce tasks gets starved even though the Reduce slots are idle. The Grid can be more efficiently utilized if Capacity Scheduler allows configuration of Map & Reduce task slots capacity independently per queue.
MAPREDUCE-1722,contrib/index - Upgrade to new Hadoop and Lucene API,"contrib/index is still using the old hadoop API. In addition, lucene 3.x has also a new API. The contrib/index should be updated and based on these new APIs."
MAPREDUCE-1720, 'Killed' jobs and 'Failed' jobs should be displayed seperately in JobTracker UI,"The JobTracker UI shows both Failed/Killed Jobs as Failed. The Killed job status has been separated from Failed as part of HADOOP-3924, so the UI needs to be updated to reflect the same..
"
MAPREDUCE-1718,job conf key for the services name of DelegationToken for HFTP url is constructed incorrectly in HFTPFileSystem,"the key (build in TokenCache) is hdfs.service.host_HOSTNAME.PORT, but 
in HftpFileSystem it is sometimes built as hdfs.service.host_IP.PORT.

Fix. change it to always be IP."
MAPREDUCE-1717,Topology resolution should be asynchronous ,Currently we hold the JT lock while resolving topology of nodes. We need to make this asynchronous w.r.t. the JT lock.
MAPREDUCE-1716,Truncate logs of finished tasks to prevent node thrash due to excessive logging,
MAPREDUCE-1714,Delegation Token is scheduled for renewal when previous renewal faild with AccessControlException,In case of failed renewal (with AccessControlException) we should not schedule another renewal (because it till fail too).
MAPREDUCE-1713,Utilities for system tests specific.,"1.  A method for restarting  the daemon with new configuration.
      public static  void restartCluster(Hashtable<String,Long> props, String confFile) throws Exception;

2.  A method for resetting the daemon with default configuration.
      public void resetCluster() throws Exception;

3.  A method for waiting until daemon to stop.
      public  void waitForClusterToStop() throws Exception;

4.  A method for waiting until daemon to start.
      public  void waitForClusterToStart() throws Exception;

5.  A method for checking the job whether it has started or not.
      public boolean isJobStarted(JobID id) throws IOException;

6.  A method for checking the task whether it has started or not.
      public boolean isTaskStarted(TaskInfo taskInfo) throws IOException;"
MAPREDUCE-1712,HAR sequence files throw errors in MR jobs,"When a HAR is specified as the input for a map reduce job and the file format is sequence file, an error similar to the following is thrown (this one is from Hive).

{code}
java.lang.IllegalArgumentException: Offset 0 is outside of file (0..-1)
        at org.apache.hadoop.mapred.FileInputFormat.getBlockIndex(FileInputFormat.java:299)
        at org.apache.hadoop.mapred.FileInputFormat.getSplitHosts(FileInputFormat.java:455)
        at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:260)
        at org.apache.hadoop.hive.ql.io.HiveInputFormat.getSplits(HiveInputFormat.java:261)
        at org.apache.hadoop.mapred.JobClient.writeOldSplits(JobClient.java:827)
        at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:798)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:747)
        at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:663)
        at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:107)
        at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:55)
        at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:631)
        at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:504)
        at org.apache.hadoop.hive.ql.Driver.run(Driver.java:382)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:138)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:197)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:303)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:156)
{code}

This is caused by the dummy block location returned by HarFileSystem.getFileBlockLocations()."
MAPREDUCE-1711,Gridmix should provide an option to submit jobs to the same queues as specified in the trace.,Gridmix should provide an option to submit jobs to the same queues as specified in the trace.
MAPREDUCE-1710,Process tree clean up of exceeding memory limit tasks.,"1. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Let the job complete . Check if all the child processes are killed, the overall job should fail.

2. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Kill/fail the job while in progress. Check if all the child processes are killed."
MAPREDUCE-1709,mapred.cache.archives is not creating links for long path names,"I got the following complaint:

{quote}

We specified this {{JobConf}} parameter:

{{mapred.cache.archives=/tmp/mchiang/workflows/custommain/lib/tutorial-udf.jar\#udfjar}}

However, we do not see a link created here: {{$\{PWD\}/udfjar/tutorial-udf.jar}}

{quote}

I will look into this and publish detailed problem duplication instructions soon.

"
MAPREDUCE-1708,Add a test for connect and read time outs during shuffle.,Write a test which injects connect and read time outs during shuffle and validates the fetch failures for corresponding maps.
MAPREDUCE-1707,TaskRunner can get NPE in getting ugi from TaskTracker,"The following code in TaskRunner can get NPE in the scenario described below.
{code}
      UserGroupInformation ugi = 
        tracker.getRunningJob(t.getJobID()).getUGI();
{code}

The scenario:
Tracker got a LaunchTaskAction; Task is localized and TaskRunner is started.
Then Tracker got a KillJobAction; This would issue a kill for the task. But, kill will be a no-op because the task did not actually start; The job is removed from runningJobs. 
Then if TaskRunner calls tracker.getRunningJob(t.getJobID()), it will be null.

Instead of TaskRunner doing a back call to tasktracker to get the ugi, tracker.getRunningJob(t.getJobID()).getUGI(), ugi should be passed a parameter in the constructor of TaskRunner. 
"
MAPREDUCE-1706,Log RAID recoveries on HDFS,"It would be good to have a way to centralize all the recovery logs, since recovery can be executed by any hdfs client. The best place to store this information is HDFS itself."
MAPREDUCE-1705,Archiving and Purging of parity files should handle globbed policies,Archiving (har) and purging of parity files don't work in policies whose source is a globbed path.
MAPREDUCE-1704,Parity files that are outdated or nonexistent should be immediately disregarded,"In the current implementation, old or nonexistent parity files are not immediately disregarded. Absence will trigger exceptions, but old files could lead to bad recoveries and maybe data corruption. This should be fixed."
MAPREDUCE-1703,TaskRunner would crash in finally block if taskDistributedCacheManager is null,"If TaskRunner throws an Exception before initializing taskDistributedCacheManager, it would crash in finally block at taskDistributedCacheManager.release(). TaskRunner would crash without doing tip.reportTaskFinished() thus not failing the task. Task will be marked FAILED after ""mapred.task.timeout"" because there is no report from  the task.

We should add a not null check for taskDistributedCacheManager in finally block.
"
MAPREDUCE-1702,CPU/Memory emulation for GridMix3,"Currently GridMix3 can successfully recreate I/O workload of jobs from job traces. The goal of this feature is to emulate CPU and memory usage of jobs as well. For this we need to record cpu/memory usage of tasks on the cluster, save them to JobHistory so that they can be read by Rumen, and replay the cpu and memory usage in gridmix3 jobs."
MAPREDUCE-1701,AccessControlException while renewing a delegation token in not correctly handled in the JobTracker,The timer task for renewing delegation token gets scheduled even when an AccessControlException is obtained. 
MAPREDUCE-1700,User supplied dependencies may conflict with MapReduce system JARs,"If user code has a dependency on a version of a JAR that is different to the one that happens to be used by Hadoop, then it may not work correctly. This happened with user code using a different version of Avro, as reported [here|https://issues.apache.org/jira/browse/AVRO-493?page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel&focusedCommentId=12852081#action_12852081].

The problem is analogous to the one that application servers have with WAR loading. Using a specialized classloader in the Child JVM is probably the way to solve this."
MAPREDUCE-1699,JobHistory shouldn't be disabled for any reason,Recently we have had issues with JobTracker silently disabling job-history and starting to keep all completed jobs in memory. This leads to OOM on the JobTracker. We should never do this.
MAPREDUCE-1697,Document the behavior of -file option in streaming and deprecate it in favour of generic -files option.,"The behavior of -file option in streaming is not documented anywhere.
The behavior of -file is the following :
1) All the files passed through  -file option are packaged into job.jar.
2) If -file option is used for .class or .jar files, they are unjarred on tasktracker and placed in ${mapred.local.dir}/taskTracker/jobcache/job_ID/jars/classes or /lib, respectively. Symlinks to the directories classes and lib are created from the cwd of the task, . The names of symlinks are ""classes"", ""lib"". So file names of .class or .jar files do not appear in cwd of the task. 
Paths to these files are automatically added to classpath. The tricky part is that hadoop framework can pick .class or .jar using classpath, but actual mapper script cannot. If you'd like to access these .class or .jar inside script, please do something like ""java -cp lib/*;classes/* <ClassName>"". 
3) If -file option is used for files other than .class or .jar (e.g, .txt or .pl), these files are unjarred into ${mapred.local.dir}/taskTracker/jobcache/job_ID/jars/. Symlinks to these files are created from the cwd of the task. Names of these symlinks are actually file names. 

"
MAPREDUCE-1695,capacity scheduler is not included in findbugs/javadoc targets,Capacity Scheduler is not included in findbugs/javadoc targets.
MAPREDUCE-1694,streaming documentation appears to be wrong on overriding settings w/-D,"Throughout http://hadoop.apache.org/common/docs/current/streaming.html , there are many examples that do ""hadoop jar streaming blah -Dsomething=something"".  None of these examples appear to work anymore.  Moving the ""-Dsomething=something"" to be after ""hadoop jar streaming"" works."
MAPREDUCE-1693,Process tree clean up of either a failed task or killed task tests.,"The following scenarios covered in the test.

1. Run a job which spawns subshells in the tasks. Kill one of the task. All the child process of the killed task must be killed.
2. Run a job which spawns subshells in tasks. Fail one of the task. All the child process of the killed task must be killed along with the task after its failure.
3. Check process tree cleanup on paritcular task-tracker when we use -kill-task and -fail-task with both map and reduce.

4. Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Let the job complete . Check if all the child processes are killed, the overall job should fail.

l)Submit a job which would spawn child processes and each of the child processes exceeds the memory limits. Kill/fail the job while in progress. Check if all the child processes are killed.
"
MAPREDUCE-1692,Remove TestStreamedMerge from the streaming tests,"Currently the {{TestStreamedMerge}} is never run as a part of the streaming test suite, the code paths which were exercised by the test was removed in HADOOP-1315, so it is better to remove the testcase from the code base."
MAPREDUCE-1690,Using BuddySystem to reduce the ReduceTask's mem usage in the step of shuffle,"       When the reduce task launched, it will start several MapOutputCopier threads to download the output from finished map, every thread is a MapOutputCopier thread running instance. Every time the thread trying to copy map output from remote from local, the MapOutputCopier thread will desides to shuffle the map output data in memory or to disk, this depends on the map output data size and the configuration of the ShuffleRamManager which loaded from the client hadoop-site.xml or JobConf, no matter what, if the reduce task decides to shuffle the map output data in memory , the MapOutputCopier will connect to the remote map host , read the map output in the socket, and then  copy map-output into an in-memory buffer, and every time, the in-memory buffer is from ""byte[] shuffleData = new byte[mapOutputLength];"", here is where the problem begin. In our cluster, there are some special jobs which will process a huge number of original data, say 110TB,  so the reduce tasks will shuffle a lot of data, some shuffled to disk and some shuffle in memory, even though, their will be a lot of data shuffled in memory, and every time the MapOutputCopier threads will ""new"" some memory from the reduce heap, for a long-running-huge-data job, this will easily feed the Reduce Task's heap size to the full,  make the reduce task to OOM and then exhausted the memory of the TaskTracker machine.
       Here is our solution: Change the code logic when MapOutputCopier threads shuffle map-output in memory, using a BuddySystem similar to the Linux Kernel  BuddySystem which used to allocate and deallocate memory page. When the reduce task launched , initialize some memory to this BuddySystem, say 128MB, everytime the reduce want to shuffle map-output in memory ,just require memory buffer from the buddySystem, if the buddySystem has enough memory , use it, and if not , let  the MapOutputCopier threads to wait() just like what they do right now in the current hadoop shuffle code logic. This will reduce the Reduce Task's memory usage and reduce the TaskTracker memory shortage a lot. In our cluster, this buddySystem makes the situation of ""lost a batch of tasktrackers because of memory over used when the huge jobs running  ""  disappeared. And therefore makes the cluster more stable."
MAPREDUCE-1689,Write MR wire protocols in Avro IDL,"As part of the the move to AVRO and wire compatibility, write all Map-Reduce protocols in AVRO IDL. This is analogous to HDFS-1069."
MAPREDUCE-1688,A failing retry'able notification in JobEndNotifier can affect notifications of other jobs.,"The JobTracker puts all the notification commands into a delay-queue.  It has a single thread that loops through this queue and sends out the notifications.  When it hits failures with any notification which is configured to be retired via {{job.end.retry.attempts}} and {{job.end.retry.interval}}, the notification is queued back again. A single notification with sufficiently large number of configured retries and which consistently fails will affect other notifications in the queue."
MAPREDUCE-1687,Stress submission policy does not always stress the cluster.,"Currently, the rough idea of stress submission policy is to continue submitting jobs until the pending map tasks reach 2x of the cluster capacity. This proves to be inadequate and we saw a large job could monopolize the whole cluster."
MAPREDUCE-1686,ClassNotFoundException for custom format classes provided in libjars,"The StreamUtil::goodClassOrNull method assumes user-provided classes have package names and if not, they are part of the Hadoop Streaming package. For example, using custom InputFormat or OutputFormat classes without package names will fail with a ClassNotFound exception which is not indicative given the classes are provided in the libjars option. Admittedly, most Java packages should have a package name so this should rarely come up.

Possible resolution options:

1) modify the error message to include the actual classname that was attempted in the goodClassOrNull method
2) call the Configuration::getClassByName method first and if class not found check for default package name and try the call again
{code}
    public static Class goodClassOrNull(Configuration conf, String className, String defaultPackage) {
        Class clazz = null;
        try {
            clazz = conf.getClassByName(className);
        } catch (ClassNotFoundException cnf) {
        }
        if (clazz == null) {
            if (className.indexOf('.') == -1 && defaultPackage != null) {
                className = defaultPackage + ""."" + className;
                try {
                    clazz = conf.getClassByName(className);
                } catch (ClassNotFoundException cnf) {
                }
            }
        }
        return clazz;
    }
{code}"
MAPREDUCE-1685,Debug statements affecting performance of JobTracker.heartbeat,"Several debug statements that come in the critical section in JobTracker.heartbeat() are not protected by a LOG.isDebugEnabled() and so incur non-trivial costs, in the order of 15% of the total heartbeat processing time."
MAPREDUCE-1684,ClusterStatus can be cached in CapacityTaskScheduler.assignTasks(),"Currently,  CapacityTaskScheduler.assignTasks() calls getClusterStatus() thrice: once in assignTasks(), once in MapTaskScheduler and once in ReduceTaskScheduler. It can be cached in assignTasks() and re-used.
"
MAPREDUCE-1683,Remove JNI calls from ClusterStatus cstr,"The {{ClusterStatus}} constructor makes two JNI calls to the {{Runtime}} to fetch memory information. {{ClusterStatus}} instances are often created inside the {{JobTracker}} to obtain other, unrelated metrics (sometimes from schedulers' inner loops). Given that this information is related to the {{JobTracker}} process and not the cluster, the metrics are also available via {{JvmMetrics}}, and the jsps can gather this information for themselves: these fields can be removed from {{ClusterStatus}}"
MAPREDUCE-1682,Tasks should not be scheduled after tip is killed/failed.,"We have seen the following scenario in our cluster:
A job got marked failed, because four attempts of a TIP failed. This would kill all the map and reduce tips. Then a job-cleanup attempt is launched.
The job-cleanup attempt failed because it could not report status for 10 minutes. There are 3 such job-cleanup attempts leading the job to get killed after 1/2 hour.
While waiting for the job cleanup to finish, JobTracker scheduled many tasks of the job on TaskTrackers and sent a KillTaskAction in the next heartbeat. 

This is just wasting lots of resources, we should avoid scheduling tasks of a tip once the tip is killed/failed.

"
MAPREDUCE-1681,MapReduce API compatibility,This is an umbrella issue to document and test MapReduce API compatibility across releases.
MAPREDUCE-1680,Add a metrics to track the number of heartbeats processed,It would be nice to add a metrics that tracks the number of heartbeats processed by JT.
MAPREDUCE-1679,capacity scheduler's user-limit documentation is not helpful,"The example given for the user limit tunable doesn't actually show how that value comes into play.  With 4 users, the Max() is 25 for both the user limit and the capacity limit (from my reading of the source).  Either pushing the example to 5 users or raising the user limit to something higher than 25 would help a great deal.  Also, presenting this info in tabular format showing how the max() value is in play would also be great."
MAPREDUCE-1678,Change org.apache.hadoop.mapreduce.Cluster methods to allow for extending,"Change methods in org.apache.hadoop.mapreduce.Cluster from private to protected to allow extension of cluster.
If the method createRPCProxy is changed from private to protected, then alternate cluster implementations could be written that return other ClientProtocol's. 
For example, changing the protocol some custom implementation called SimpleClient
 
ie:
public class SimpleCluster extends Cluster {
  @Override
  protected ClientProtocol createRPCProxy(InetSocketAddress addr, Configuration conf) throws IOException {
    return new SimpleClient(conf);
  } 
}


"
MAPREDUCE-1675,SleepJob hacks GridmixKey to pass along the sleep duration from map tasks to reduce tasks.,SleepJob hacks GridmixKey to pass along the sleep duration from map tasks to reduce tasks. We need to come up with cleaner solution
MAPREDUCE-1674,Some new features for CapacityTaskScheduler,Some new features for CapacityTaskScheduler developed at Baidu.
MAPREDUCE-1673,Start and Stop scripts for the RaidNode,We should have scripts that start and stop the RaidNode automatically. Something like start-raidnode.sh and stop-raidnode.sh
MAPREDUCE-1670,RAID should avoid policies that scan their own destination path,"Raid currently allows policies that include the destination directory into the source directory and vice-versa.
Both situations can create cycles and should be avoided."
MAPREDUCE-1668,RaidNode should only Har a directory if all its parity files have been created,"In the current code, it can happen that a directory will be Archived (Har'ed) before all its parity files have been generated since parity file generation is not atomic. We should verify if all the parity files are present before Archiving a directory."
MAPREDUCE-1666,job output chroot support,"It would be useful to be able to submit the same job and have it chroot the output to a different base directory before execution.  This would allow for input to be the same, but output different for the same job over multiple runs (potentially by different users)."
MAPREDUCE-1665,kill and modify should not be the same acl,"The permission to kill a job/task should be split out from modification.  There are definitely instances where someone who can kill a job should not be able to modify it.  [Third person job monitoring, for example, such as we have here at LinkedIn.]  "
MAPREDUCE-1664,Job Acls affect Queue Acls,"MAPREDUCE-1307 introduced job ACLs for securing job level operations. So in current trunk, queue ACLs and job ACLs are checked(with AND for both acls) for allowing job level operations. So for doing operations like killJob, killTask and setJobPriority user should be part of both mapred.queue.{queuename}.acl-administer-jobs and in mapreduce.job.acl-modify-job. This needs to change so that users who are part of mapred.queue.{queuename}.acl-administer-jobs will be able to do killJob,killTask,setJobPriority and users part of mapreduce.job.acl-modify-job will be able to do killJob,killTask,setJobPriority."
MAPREDUCE-1663,mapred.local.dir for IsolationRunner is not set properly,"MAPREDUCE-842 enforces that mapred.local.dir for Task to be attemptDirs in all local dirs. The conf is not set to attemptDirs for IsolationRunner. 
So, the map output files are created directly under Cluster's local dir. The same can be seen in TestIsolationRunner. Test does not fail because it is not validated.

"
MAPREDUCE-1662,TaskRunner.prepare() and close() can be removed,"TaskRunner.prepare() and close() methods call only mapOutputFile.removeAll(). The removeAll() call is a always a no-op in prepare(), because the directory is always empty during start up of the task. The removeAll() call in close() is useless, because it is followed by a attempt directory cleanup. Since the map output files are in attempt directory,  the call to close() is useless.
After MAPREDUCE-842, these calls are under TaskTracker space, passing the wrong conf. Now, the calls do not make sense at all.
I think we can remove the methods."
MAPREDUCE-1661,The input directory in test TestTaskOwner.java is not cleaned up,"The test should delete the directories in hdfs that it creates as a good practice, it should leave around any vestige directories, since it can cause undesired side effects. "
MAPREDUCE-1659,RaidNode should write temp files on /tmp and add random numbers to their names to avoid conflicts,"The RaidNode methods to raid files and recover them should write recovery and tmp files on /tmp instead of /raid.

Besides that, filenames should have a random number appended to them to avoid conflicts. This makes the code safer and avoids errors when multiple recoveries run in parallel."
MAPREDUCE-1658,[Rumen] Extract some job configurations.,"Enhance Rumen to extract the following configuration parameters from JobConf that may be relevant to job execution:
- mapred.map.tasks.speculative.execution, mapred.reduce.tasks.speculative.execution
- mapred.reduce.slowstart.completed.maps
- io.sort.factor, io.sort.mb, io.sort.record.percent, io.sort.spill.percent
- mapreduce.reduce.shuffle.connect.timeout, mapreduce.reduce.shuffle.read.timeout
- mapred.job.shuffle.merge.percent, mapred.job.shuffle.input.buffer.percent
- mapred.inmem.merge.threshold"
MAPREDUCE-1657,"After task logs directory is deleted, tasklog servlet displays wrong error message about job ACLs","When task log gets deleted if from Web UI we click view task log, web page displays wrong error message -:
[
HTTP ERROR: 401

User user1 failed to view tasklogs of job job_201003241521_0001!

user1 is not authorized for performing the operation VIEW_JOB on job_201003241521_0001. VIEW_JOB Access control list
configured for this job : 

RequestURI=/tasklog
]
Even if user is having view job acls set / or user is owner of job.
"
MAPREDUCE-1656,JobStory should provide queue info.,Add a method in JobStory to get the queue to which a job is submitted.
MAPREDUCE-1655,Automate the local file permission checking when a job is running. ,This test case will automate the file permission under mapred.local.dir when a job runs. 
MAPREDUCE-1653,Add apache header to UserNamePermission.java,Add the missing header to the file. 
MAPREDUCE-1652,Tasks need to emit a better error message when job-acls.xml file cannot be created,"If task cannot create job-acls.xml in userlogs/$jobid/task-attempt-dir(because of disc being full, OR disc has gone bad, etc), then task should emit a better error message instead of failing with FileNotFoundException in writeJobACLs().

The stack trace shown currently is:

java.lang.Throwable: Child Error
        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:242)
Caused by: java.io.FileNotFoundException:
$mapred-local-dir/userlogs/job_201003240402_0402/attempt_201003240402_0402_m_002091_0/job-acl.xml (No such
file or directory)
        at java.io.FileOutputStream.open(Native Method)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:131)
        at org.apache.hadoop.mapred.TaskRunner.writeJobACLs(TaskRunner.java:303)
        at org.apache.hadoop.mapred.TaskRunner.prepareLogFiles(TaskRunner.java:286)
        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:205)
"
MAPREDUCE-1650,Exclude Private elements from generated MapReduce Javadoc,Exclude elements annotated with InterfaceAudience.Private or InterfaceAudience.LimitedPrivate from Javadoc and JDiff.
MAPREDUCE-1649,Compressed files with TextInputFormat does not work with CombineFileInputFormat,"{{CombineFileInputFormat}} creates splits based on blocks, regardless whether the underlying {{FileInputFormat}} is splittable or not..

This means that we can have 2 or more splits for a compressed text file with {{TextInputFormat}}. For each of these splits, {{TextInputFormat.getRecordReader}} will return a {{RecordReader}} for the whole compressed file, thus causing duplicate input data."
MAPREDUCE-1648,Use rolling to limit tasklogs,"There are at least two types of task-logs: syslog and stdlog

Task-Jvm outputs syslog by log4j with TaskLogAppender, TaskLogAppender looks just like ""tail -c"", it stores last N byte/line logs in memory(via queue), and do real output only if all logs is commit and Appender is going to close.

The common problem of TaskLogAppender and 'tail -c'  is keep everything in memory and user can't see any log output while task is in progress.

So I'm going to try RollingFileAppender  instead of  TaskLogAppender, use MaxFileSize&MaxBackupIndex to limit log file size.

RollingFileAppender is also suitable for stdout/stderr, just redirect stdout/stderr to log4j via LoggingOutputStream, no client code have to be changed, and RollingFileAppender seems better than 'tail -c' too.

"
MAPREDUCE-1647,JvmEnv miss logSize argument,"class JvmEnv missed logSize argument in its constructor, thus task-jvms seems will never limit their stdout/stderr outputs into specified size.

{code:title=JvmManager.java|borderStyle=solid}
    public JvmEnv(List<String> setup, Vector<String> vargs, File stdout,
        File stderr, long logSize, File workDir, Map<String,String> env,
        JobConf conf) {
      this.setup = setup;
      this.vargs = vargs;
      this.stdout = stdout;
      this.stderr = stderr;
      this.workDir = workDir;
      this.env = env;
      this.conf = conf;
    }

{code}"
MAPREDUCE-1645,Task cleanup attempt details should also be logged to JobHistory,"Currently, Task cleanup attempt details are not logged to JobHistory. JobHistory should log at least where the task cleanup attempt ran."
MAPREDUCE-1644,Remove Sqoop from Apache Hadoop (moving to github),Sqoop is moving to github! All code for sqoop is already live at http://github.com/cloudera/sqoop - this issue removes the duplicate code from the Apache Hadoop repository before the 0.21 release.
MAPREDUCE-1642,Many hudson test failures because of ZipException,"Nowadays, many hudson patch builds fail because of ZipException.

One such failure @http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/67/testReport/org.apache.hadoop.streaming/TestStreamingBadRecords/testNarrowDown/"
MAPREDUCE-1641,Job submission should fail if same uri is added for mapred.cache.files and mapred.cache.archives,"The behavior of mapred.cache.files and mapred.cache.archives is different during localization in the following way:

If a jar file is added to mapred.cache.files,  it will be localized under TaskTracker under a unique path. 
If a jar file is added to mapred.cache.archives, it will be localized under a unique path in a directory named the jar file name, and will be unarchived under the same directory.

If same jar file is passed for both the configurations, the behavior undefined. Thus the job submission should fail.
Currently, since distributed cache processes files before archives, the jar file will be just localized and not unarchived."
MAPREDUCE-1640,Node health feature fails to blacklist a node if the health check script times out in some cases,"Node health check feature fails to blacklist a TT if health check script times out. Below are the values that were set:
 - mapred.healthChecker.interval=60000
 - mapred.healthChecker.script.timeout=6000

And the script was:
{code}
#!/bin/bash
echo ""start""
sleep 100000
echo ""end""
{code}"
MAPREDUCE-1638,Remove MapReduce server depedencies on client code,I think it makes sense to separate the MapReduce source into client and server parts.
MAPREDUCE-1637,Create a test for API compatibility between releases,We should have an automated test (or a set of tests) for checking that programs written against an old version of the API still run with a newer version. 
MAPREDUCE-1636,Missing counters on taskdetails.jsp,A tip counter is actually the counter of its best performing attempt. This is correctly displayed on jobtasks.jsp but is missing on the taskdetails.jsp.
MAPREDUCE-1635,ResourceEstimator does not work after MAPREDUCE-842,"MAPREDUCE-842 changed Child's mapred.local.dir to have attemptDir as the base local directory. Also assumption is that
org.apache.hadoop.mapred.MapOutputFile always gets Child's mapred.local.dir. 
But, MapOuptutFile.getOutputFile() is called from TaskTracker's conf, which does not find the output file. Thus TaskTracker.tryToGetOutputSize() always returns -1.
"
MAPREDUCE-1634,add input and output formats for Avro value wrappers,HADOOP-6660 proposes adding an AvroValue wrapper for Avro data.  We should add InputFormat and OutputFormat implementations for Avro data files that use this.
MAPREDUCE-1633,Queue ACLs documentation must talk about wildcards,Currently the Forrest documentation about queue ACLs is not talking about wildcards - the value that states that all users are allowed for an operation in a queue. This should be documented.
MAPREDUCE-1632,TestHadoopArchives fails on trunk,"Here is the test report:
org.apache.hadoop.tools.TestHadoopArchives.testPathWithSpaces  (from TestHadoopArchives)
Failing for the past 7 builds (Since Failed#48 )
Took 25 sec.

Error Message:

expected:<[/a, /b, /c, /c_c, /sub_1, /sub_1/file, /sub_1/file_x_y_z, /sub_1/x, /sub_1/y, /sub_1/z, /sub_2]> but was:<[]>

Stacktrace:

junit.framework.AssertionFailedError: expected:<[/a, /b, /c, /c_c, /sub_1, /sub_1/file, /sub_1/file_x_y_z, /sub_1/x, /sub_1/y, /sub_1/z, /sub_2]> but was:<[]>
	at org.apache.hadoop.tools.TestHadoopArchives.testPathWithSpaces(TestHadoopArchives.java:158)

Full log for the Failure is @ http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h4.grid.sp2.yahoo.net/54/testReport/org.apache.hadoop.tools/TestHadoopArchives/testPathWithSpaces/ "
MAPREDUCE-1631,hadoop-mapreduce-trunk build has broken because fo build issue.,"
http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/269/console

ERROR: Publisher hudson.tasks.JavadocArchiver aborted due to exception
java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
at java.io.FileOutputStream.write(FileOutputStream.java:260)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:109)
	at java.io.ObjectOutputStream$BlockDataOutputStream.drain(ObjectOutputStream.java:1838)
	at java.io.ObjectOutputStream$BlockDataOutputStream.writeByte(ObjectOutputStream.java:1876)
	at java.io.ObjectOutputStream.writeFatalException(ObjectOutputStream.java:1537)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:329)
	at hudson.remoting.Channel.send(Channel.java:417)
	at hudson.remoting.Request.call(Request.java:105)
	at hudson.remoting.Channel.call(Channel.java:551)
	at hudson.EnvVars.getRemote(EnvVars.java:196)
	at hudson.model.Computer.getEnvironment(Computer.java:728)
	at hudson.model.Run.getEnvironment(Run.java:1601)
	at hudson.model.AbstractBuild.getEnvironment(AbstractBuild.java:663)
	at hudson.tasks.JavadocArchiver.perform(JavadocArchiver.java:92)
	at hudson.tasks.BuildStepMonitor$1.perform(BuildStepMonitor.java:19)
	at hudson.model.AbstractBuild$AbstractRunner.perform(AbstractBuild.java:582)
	at hudson.model.AbstractBuild$AbstractRunner.performAllBuildStep(AbstractBuild.java:563)
	at hudson.model.AbstractBuild$AbstractRunner.performAllBuildStep(AbstractBuild.java:550)
	at hudson.model.Build$RunnerImpl.post2(Build.java:152)
	at hudson.model.AbstractBuild$AbstractRunner.post(AbstractBuild.java:528)
	at hudson.model.Run.run(Run.java:1221)
	at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:46)
	at hudson.model.ResourceController.execute(ResourceController.java:88)
	at hudson.model.Executor.run(Executor.java:122)

"
MAPREDUCE-1630,Starting JobTracker with a wrong keytab should throw error right away,"If the JobTracker is started with a wrong key tab file, it should die immediately throwing the right error to the user. Right now, the JobTracker keeps trying to login with the available credentials and hence the process does not die immediately. So, to the user it appears like the JobTracker process is running successfully. This is misleading."
MAPREDUCE-1629,"Get rid of fakeBlockLocations() on HarFileSystem, since it's not used","On HarFileSystem.java, I think function fakeBlockLocations() was left behind when Mahadev fixed HADOOP-6467."
MAPREDUCE-1628,HarFileSystem shows incorrect replication numbers and permissions,"In the har dir, the replication # of part-0 is 3.
{noformat}
-bash-3.1$ hadoop fs -ls  ${DIR}.har
Found 3 items
-rw-------   5 tsz users       1141 2010-02-10 18:34 /user/tsz/t20.har/_index
-rw-------   5 tsz users         24 2010-02-10 18:34 /user/tsz/t20.har/_masterindex
-rw-------   3 tsz users      15052 2010-02-10 18:34 /user/tsz/t20.har/part-0
{noformat}
but the replication # of the individual har:// files is shown as 5.
{noformat}
-bash-3.1$ hadoop fs -lsr  ${HAR_FULL}/
drw-------   - tsz users          0 2010-02-10 18:34 /user/tsz/t20.har/t20
-rw-------   5 tsz users        723 2010-02-10 18:34 /user/tsz/t20.har/t20/text-00000000
-rw-------   5 tsz users        779 2010-02-10 18:34 /user/tsz/t20.har/t20/text-00000001
-rw-------   5 tsz users        818 2010-02-10 18:34 /user/tsz/t20.har/t20/text-00000002
...
{noformat}
The permission also has similar problem.  Clearly, the permission of t20.har/t20 shown above is incorrect."
MAPREDUCE-1627,HadoopArchives should not uses DistCp method,"{code}
//line 502.
  final String randomId = DistCp.getRandomId();
{code}
If HadoopArchives does not use the DistCp method, it could be packaged as a standalone tool."
MAPREDUCE-1626,Publish Javadoc for all contrib packages with user-facing APIs,"Some packages don't appear in the Javadoc. E.g. MRUnit, Vertica."
MAPREDUCE-1625,Improve grouping of packages in Javadoc,"There are a couple of problems with the current Javadoc:
* The main MapReduce package documentation on the index page appears under ""Other Packages"" below the fold.
* Some contrib classes and packages are interspersed in the main MapReduce documentation, which is very confusing for users.
"
MAPREDUCE-1624,Document the job credentials and associated details to do with delegation tokens (on the client side),Document the job credentials and associated details to do with delegation tokens (on the client side)
MAPREDUCE-1623,Apply audience and stability annotations to classes in mapred package,"There are lots of implementation classes in org.apache.hadoop.mapred which makes it difficult to see the user-level MapReduce API classes in the Javadoc. (See http://hadoop.apache.org/common/docs/r0.20.2/api/org/apache/hadoop/mapred/package-summary.html for example.) By marking these implementation classes with the InterfaceAudience.Private annotation we can exclude them from user Javadoc (using HADOOP-6658).

Later work will move the implementation classes into o.a.h.mapreduce.server and related packages (see MAPREDUCE-561), but applying the annotations is a good first step. "
MAPREDUCE-1622,Include slf4j dependencies in binary tarball,"After MAPREDUCE-1556 and HADOOP-6486, starting \*Trackers from a binary tarball produces the following warning:
{noformat}
SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
2010-03-18 01:11:32.988::INFO:  Logging to STDERR via org.mortbay.log.StdErrLog
2010-03-18 01:11:33.056::INFO:  jetty-6.1.14
{noformat}"
MAPREDUCE-1621,Streaming's TextOutputReader.getLastOutput throws NPE if it has never read any output,"If TextOutputReader.readKeyValue() has never successfully read a line, then its bytes member will be left null. Thus when logging a task failure, PipeMapRed.getContext() can trigger an NPE when it calls outReader_.getLastOutput()."
MAPREDUCE-1619,Eclipse .classpath file should be generated from Ivy files to avoid duplicating dependencies,"Using Ant-Eclipse (http://sourceforge.net/projects/ant-eclipse/) it's possible to generate Eclipse files from Ivy files, this avoids unnecessary duplication of dependencies information.

See: HADOOP-6407"
MAPREDUCE-1618,JobStatus.getJobAcls() and setJobAcls should have javadoc,org.apache.hadoop.mapreduce.JobStatus.getJobAcls() and setJobAcls are added in MAPREDUCE-1307. They should have javadoc.
MAPREDUCE-1617,TestBadRecords failed once in our test runs,"org.apache.hadoop.mapred.TestBadRecords.testBadMapRed failed with the following
exception:
java.io.IOException: Job failed!
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1142)
        at org.apache.hadoop.mapred.TestBadRecords.runMapReduce(TestBadRecords.java:94)
        at org.apache.hadoop.mapred.TestBadRecords.testBadMapRed(TestBadRecords.java:211)
"
MAPREDUCE-1615,ant test on trunk does not compile.,"ant test on trunk fails to compile with the following error:

{noformat}
    [javac] Compiling 264 source files to /home/mahadev/workspace/hadoop-commit-trunk/mapreduce/build/test/mapred/classes
    [javac] /mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:266: \
            getListing(java.lang.String,byte[]) in org.apache.hadoop.hdfs.protocol.ClientProtocol \
            cannot be applied to (java.lang.String)
    [javac]         client.getListing(path.toString());
    [javac]               ^
    [javac] /mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java:279: \
            getListing(java.lang.String,byte[]) in org.apache.hadoop.hdfs.protocol.ClientProtocol \
            cannot be applied to (java.lang.String)
    [javac]         client.getListing(jobSubmitDirpath.toString());
    [javac]               ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 errors

BUILD FAILED
{noformat}"
MAPREDUCE-1614,TestDFSIO should allow to configure output directory,"TestDFSIO has a hardcoded location for its files to be written and read to or from. This location is /benchmarks. However, it might pose a problem if HDFS '/' doesn't allow anyone to write into it. It'd be convenient to have a command line option to specify an alternative location on demand."
MAPREDUCE-1613,Install/deploy source jars to Maven repo,Publishing source jars to the Maven repo enables most IDEs to easily show Hadoop code to developers.
MAPREDUCE-1612,job conf file is not accessible from job history web page,Clicking on conf file link from job history web page is causing an NPE if history file(and the job conf file) are stored on DFS. This NPE is from jobconf_history.jsp because jobConf built from path on DFS is not having any properties.
MAPREDUCE-1611,Refresh nodes and refresh queues doesnt work with service authorization enabled,"If service-level authorization enabled (i.e _hadoop.security.authorization_ set to *true*) for MapReduce then refreshing the node and queue fails with the following message
{noformat}
Protocol interface org.apache.hadoop.mapred.AdminOperationsProtocol is not known.
{noformat}"
MAPREDUCE-1610,Forrest documentation should be updated to reflect the changes in MAPREDUCE-856,The directory structure under mapred-local-dir is changed in MAPREDUCE-856. This needs changes to the forrest documentation.
MAPREDUCE-1609,TaskTracker.localizeJob should not set permissions on job log directory recursively,"Currently TaskTracker.localizeJob sets permissions (570 with LinuxTaskController) on job log directory recursively. When the tracker restarts/reinits, if there are new tasks for the job, localizeJob would find attempt log directories for the earlier tasks. If the job has many tasks, it would spend significant time in chmod'ing.

Also, if a cleanup attempt is launched after the restart/reinit, we would hit MAPREDUCE-1607.

This problem is missed by the patch for MAPREDUCE-927. The above problem never existed before MAPREDUCE:927."
MAPREDUCE-1607,Task controller may not set permissions for a task cleanup attempt's log directory,"Task controller uses the INITIALIZE_TASK command to initialize task attempt and task log directories. For cleanup tasks, task attempt directories are named as task-attempt-id.cleanup. But log directories do not have the .cleanup suffix. The task controller is not aware of this distinction and tries to set permissions for log directories named task-attempt-id.cleanup. This is a NO-OP. Typically the task cleanup runs on the same node that ran the original task attempt as well. So, the task log directories are already properly initialized. However, the task cleanup can run on a node that has not run the original task attempt. In that case, the initialization would not happen and this could result in the cleanup task failing."
MAPREDUCE-1606,TestJobACLs may timeout as there are no slots for launching JOB_CLEANUP task,"TestJobACLs may timeout as there are no slots for launching JOB_CLEANUP task. Because MiniMRCluster with 0 TaskTrackers is started in the test. In trunk, we can set the config property mapreduce.job.committer.setup.cleanup.needed to false sothat we don't get into this issue."
MAPREDUCE-1604,Job acls should be documented in forrest.,Job acls introduced in MAPREDUCE-1307 should be documented in forrest.
MAPREDUCE-1603,Add a plugin class for the TaskTracker to determine available slots,"Currently the #of available map and reduce slots is determined by the configuration. MAPREDUCE-922 has proposed working things out automatically, but that is going to depend a lot on the specific tasks -hard to get right for everyone.

There is a Hadoop cluster near me that would like to use CPU time from other machines in the room, machines which cannot offer storage, but which will have spare CPU time when they aren't running code scheduled with a grid scheduler. The nodes could run a TT which would report a dynamic number of slots, the number depending upon the current grid workload. 

I propose we add a plugin point here, so that different people can develop plugin classes that determine the amount of available slots based on workload, RAM, CPU, power budget, thermal parameters, etc. Lots of space for customisation and improvement. And by having it as a plugin: people get to integrate with whatever datacentre schedulers they have without Hadoop itself needing to be altered: the base implementation would be as today: subtract the number of active map and reduce slots from the configured values, push that out. "
MAPREDUCE-1602,"When the src does not exist, archive shows IndexOutOfBoundsException","{noformat}
-bash-3.1$ $H archive -archiveName foo.har -p / src-not-exists dst
IndexOutOfBoundsException in archives
Index: 0, Size: 0
{noformat}"
MAPREDUCE-1601,CombineFileInputFormat and Job classes,"org.apache.hadoop.mapred.lib.CombineFileInputFormat can not be used with org.apache.hadoop.mapreduce.Job
because Job.setInputFormat requires subclass of  org.apache.hadoop.mapreduce.InputFormat and CombineFileInputFormat
extends org.apache.hadoop.mapred.FileInputFormat.

Also CombineFileInputFormat uses deprecated classes. "
MAPREDUCE-1600,o.a.h.mapreduce.FileOutputCommitter should qualify the output path,"Same as HADOOP-4746, but for the new api."
MAPREDUCE-1599,MRBench reuses jobConf and credentials there in.,"MRBench reuses the jobconf and therefore credentials are re-used, but JobTracker cancels the delegation tokens therefore the test fails sometimes. 
The fix is to pass the mapreduce.job.complete.cancel.delegation.tokens=false in the jobconf so that JobTracker does not cancel the tokens."
MAPREDUCE-1597,combinefileinputformat does not work with non-splittable files,"CombineFileInputFormat.getSplits() does not take into account whether a file is splittable.
This can lead to a problem for compressed text files - for example, getSplits() may return more
than 1 split depending on the size of the compressed file, all the splits recordreader will read the
complete file.

I ran into this problem while using Hive on hadoop 20.
"
MAPREDUCE-1596,MapReduce trunk snapshot is not being published to maven,"The hadoop-core and hadoop-hdfs artifacts are pushed to maven on a regular basis (daily?), but hadoop-mapreduce has not been updated since 2/18/10. Is there something automatic in Hudson that is configured for these core and hdfs, but not mapred?

Downstream projects that try to build against Hadoop's trunk (via Ivy or Maven) cannot compile due to API inconsistency here.

"
MAPREDUCE-1595,LinuxTaskController is too strict on the initial ownership of files/dir.,"Linux task controller is too strict now w.r.t the initial ownership of the files/dir that it tries to make as secure as possible. Currently, it expects, for e.g, the mapred-local/tasktracker/user-dir to be both user-owned and group-owned by TT. This leads to unrecoverable failures in some corner cases.

It can instead allow the files/dirs to be owned either by TT *or* by the jobOwner."
MAPREDUCE-1594,Support for Sleep Jobs in gridmix,Support for Sleep jobs in gridmix
MAPREDUCE-1593,[Rumen] Improvements to random seed generation ,"RandomSeedGenerator introduced in MAPREDUCE-1306 could be more efficient by reusing the MD5 object across calls. Wrapping the MD5 in a ThreadLocal makes the call thread safe as well. Neither of these is an issue with the current client, the mumak simulator, but the changes are small and make the code more useful in the future. Thanks to Chris Douglas for the suggestion."
MAPREDUCE-1592,Generate Eclipse's .classpath file from Ivy config,MapReduce companion issue for HADOOP-6407.
MAPREDUCE-1590,Move HarFileSystem from Hadoop Common to Mapreduce tools.,"Keeping HarFileSystem in Hadoop Common has been a mistake since we sometimes cannot make changes to archives without breaking build across  common and mapreduce. Also, it would be good to package archives as a seperate jar which can be used as a user jar."
MAPREDUCE-1588,Fail early if the configured values for total number of tasks is greater than 'mapreduce.jobtracker.maxtasks.perjob',"If a job is configured with *high* value for num-map and num-reduce tasks, then the JobTracker should fail early i.e during job submission."
MAPREDUCE-1587,NPE in JobClient querying an (empty) queue,"Getting a stack trace on a VM-hosted cluster with an empty queue. Thought maybe it was the -verbose option, but no, remove that and I still see it.
{code}
java org.apache.hadoop.mapred.JobQueueClient -list -showjobs -verbose
  [sshexec] 10/03/10 13:56:21 INFO security.Groups: Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping; cacheTimeout=300000
  [sshexec] 10/03/10 13:56:21 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
  [sshexec] Exception in thread ""main"" 
  [sshexec] java.lang.NullPointerException
  [sshexec] 	at org.apache.hadoop.mapred.JobClient.getJobQueueInfoArray(JobClient.java:921)
  [sshexec] 	at org.apache.hadoop.mapred.JobClient.getRootQueues(JobClient.java:937)
  [sshexec] 	at org.apache.hadoop.mapred.JobQueueClient.displayQueueList(JobQueueClient.java:142)
  [sshexec] 	at org.apache.hadoop.mapred.JobQueueClient.run(JobQueueClient.java:96)
  [sshexec] 	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
  [sshexec] 	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
  [sshexec] 	at org.apache.hadoop.mapred.JobQueueClient.main(JobQueueClient.java:232)


{code}"
MAPREDUCE-1585,Create Hadoop Archives version 2 with filenames URL-encoded,"Hadoop Archives version 1 don't cope with files that have spaces on their names.

One proposal is to URLEncode filenames inside the index file (version 2, refers to HADOOP-6591).

This task is to allow the creation of version 2 files that have file names encoded appropriately. It currently depends on HADOOP-6591"
MAPREDUCE-1579,archive: check and possibly replace the space charater in paths,"Since the space character is used as a separator in the index files, it won't work if there are spaces in the path (see also HADOOP-6591).  The archive tools should 
# detect if there are spaces in the paths and 
# provide an option to replace it with some other characters."
MAPREDUCE-1578,HadoopArchives.java should not use HarFileSystem.VERSION,"If we upgrade the protocol on HarFileSystem, HadoopArchives might generate an old archive and assign the new version number to it.

This should be fixed"
MAPREDUCE-1577,FileInputFormat in the new mapreduce package to support multi-level/recursive directory listing ,See MAPREDUCE-1501 for details.
MAPREDUCE-1576,Counters like number of records written in map are not available in hadoop local execution engine,Counters like number of records written in map are not available in hadoop local execution engine - currently for the number of records the value reported is 0.
MAPREDUCE-1573,TestStreamingAsDifferentUser fails if run as tt_user,"TestStreamingAsDifferentUser fails if run as tt_user. MAPREDUCE-890 didn't make the necessary changes needed for the newly added testcase in TestStreamignAsDifferentUser.

{code}
Testcase: testStreamingWithDistCache took 21.228 sec
  FAILED
Path /tmp/hadoop-gravi/mapred/local/0_0/taskTracker/gravi/distcache has the permissions drwxrws--- instead of the expected dr-xrws---
junit.framework.AssertionFailedError: Path /tmp/hadoop-gravi/mapred/local/0_0/taskTracker/gravi/distcache has the permissions drwxrws--- instead of the expected dr-xrws---   at org.apache.hadoop.mapred.TestTaskTrackerLocalization.checkFilePermissions(TestTaskTrackerLocalization.java:292)
  at org.apache.hadoop.mapred.ClusterWithLinuxTaskController.checkPermissionsOnDir(ClusterWithLinuxTaskController.java:440)
  at org.apache.hadoop.mapred.ClusterWithLinuxTaskController.checkPermissionsOnPrivateDistCache(ClusterWithLinuxTaskController.java:354)
  at org.apache.hadoop.streaming.TestStreamingAsDifferentUser$2.run(TestStreamingAsDifferentUser.java:157)
  at org.apache.hadoop.streaming.TestStreamingAsDifferentUser$2.run(TestStreamingAsDifferentUser.java:120)
  at java.security.AccessController.doPrivileged(Native Method)
  at javax.security.auth.Subject.doAs(Subject.java:396)
  at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:706)
  at org.apache.hadoop.streaming.TestStreamingAsDifferentUser.testStreamingWithDistCache(TestStreamingAsDifferentUser.java:120)
{code}"
MAPREDUCE-1572,MapReduceDriver combiner functionality,the MapReduceDriver for the new API should be updated to allow the configuration of a Combiner
MAPREDUCE-1571,OutOfMemoryError during shuffle,"A OutOfMemoryError can occur when determining if the shuffle can be accomplished in memory

2010-03-06 07:54:49,621 INFO org.apache.hadoop.mapred.ReduceTask:
Shuffling 4191933 bytes (435311 raw bytes) into RAM from
attempt_201003060739_0002_m_000061_0
2010-03-06 07:54:50,222 INFO org.apache.hadoop.mapred.ReduceTask: Task
attempt_201003060739_0002_r_000000_0: Failed fetch #1 from
attempt_201003060739_0002_m_000202_0
2010-03-06 07:54:50,223 WARN org.apache.hadoop.mapred.ReduceTask:
attempt_201003060739_0002_r_000000_0 adding host
hd37.dfs.returnpath.net to penalty box, next contact in 4 seconds
2010-03-06 07:54:50,223 INFO org.apache.hadoop.mapred.ReduceTask:
attempt_201003060739_0002_r_000000_0: Got 1 map-outputs from previous
failures
2010-03-06 07:54:50,223 FATAL org.apache.hadoop.mapred.TaskRunner:
attempt_201003060739_0002_r_000000_0 : Map output copy failure :
java.lang.OutOfMemoryError: Java heap space
       at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.shuffleInMemory(ReduceTask.java:1508)
       at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1408)
       at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1261)
       at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:1195)


Ted Yu identified the following potential solution:

I think there is mismatch (in ReduceTask.java) between:
     this.numCopiers = conf.getInt(""mapred.reduce.parallel.copies"", 5);
and:
       maxSingleShuffleLimit = (long)(maxSize *
MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION);
where MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION is 0.25f

because
     copiers = new ArrayList<MapOutputCopier>(numCopiers);
so the total memory allocated for in-mem shuffle is 1.25 * maxSize

A JIRA should be filed to correlate the constant 5 above and
MAX_SINGLE_SHUFFLE_SEGMENT_FRACTION."
MAPREDUCE-1570,Shuffle stage - Key and Group Comparators,Shuffle method in org.apache.hadoop.mrunit.MapReduceDriverBase doesn't currently allow the use of custom GroupingComparator and SortComparator.
MAPREDUCE-1569,Mock Contexts & Configurations,"Currently the library creates a new Configuration object in the MockMapContext and MocKReduceContext constructors, rather than allowing the developer to configure and pass their own"
MAPREDUCE-1568,TrackerDistributedCacheManager should clean up cache in a background thread,"Right now the TrackerDistributedCacheManager do the clean up with the following code path:
{code}
TaskRunner.run() -> 
TrackerDistributedCacheManager.setup() ->
TrackerDistributedCacheManager.getLocalCache() -> 
TrackerDistributedCacheManager.deleteCache()
{code}
The deletion of the cache files can take a long time and it should not be done by a task. We suggest that there should be a separate thread checking and clean up the cache files."
MAPREDUCE-1566,Need to add a mechanism to import tokens and secrets into a submitted job.,We need to include tokens and secrets into a submitted job. I propose adding a configuration attribute that when pointed at a token storage file will include the tokens and secrets from that token storage file.
MAPREDUCE-1562,TestBadRecords fails sometimes,TestBadRecords.testMapRed fails sometimes. One instance of this was seen by Hudson while testing MAPREDUCE-890: http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h3.grid.sp2.yahoo.net/342/testReport/.
MAPREDUCE-1561,"mapreduce patch tests hung with ""java.lang.OutOfMemoryError: Java heap space""","http://hudson.zones.apache.org/hudson/view/Mapreduce/job/Mapreduce-Patch-h9.grid.sp2.yahoo.net/4/console

Error form the console:

 [exec]     [junit] 10/03/05 04:08:29 INFO datanode.DataNode: PacketResponder 2 for block blk_-3280111748864197295_19758 terminating
     [exec]     [junit] 10/03/05 04:08:29 INFO hdfs.StateChange: BLOCK* NameSystem.addStoredBlock: blockMap updated: 127.0.0.1:46067 is added to blk_-3280111748864197295_19758{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:46067|RBW], ReplicaUnderConstruction[127.0.0.1:37626|RBW], ReplicaUnderConstruction[127.0.0.1:48886|RBW]]} size 0
     [exec]     [junit] 10/03/05 04:08:29 INFO hdfs.StateChange: DIR* NameSystem.completeFile: file /tmp/hadoop-hudson/mapred/system/job_20100304162726530_3751/job-info is closed by DFSClient_79157028
     [exec]     [junit] 10/03/05 04:08:29 INFO mapred.JobTracker: Job job_20100304162726530_3751 added successfully for user 'hudson' to queue 'default'
     [exec]     [junit] 10/03/05 04:08:29 INFO mapred.JobTracker: Initializing job_20100304162726530_3751
     [exec]     [junit] 10/03/05 04:08:29 INFO mapred.JobInProgress: Initializing job_20100304162726530_3751
     [exec]     [junit] 10/03/05 04:08:29 INFO mapreduce.Job: Running job: job_20100304162726530_3751
     [exec]     [junit] 10/03/05 04:08:29 INFO jobhistory.JobHistory: SetupWriter, creating file file:/grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h9.grid.sp2.yahoo.net/trunk/build/contrib/raid/test/logs/history/job_20100304162726530_3751_hudson
     [exec]     [junit] 10/03/05 04:08:29 ERROR mapred.JobTracker: Job initialization failed:
     [exec]     [junit] org.apache.avro.AvroRuntimeException: java.lang.NoSuchFieldException: _SCHEMA
     [exec]     [junit] 	at org.apache.avro.specific.SpecificData.createSchema(SpecificData.java:50)
     [exec]     [junit] 	at org.apache.avro.reflect.ReflectData.getSchema(ReflectData.java:210)
     [exec]     [junit] 	at org.apache.avro.specific.SpecificDatumWriter.<init>(SpecificDatumWriter.java:28)
     [exec]     [junit] 	at org.apache.hadoop.mapreduce.jobhistory.EventWriter.<init>(EventWriter.java:47)
     [exec]     [junit] 	at org.apache.hadoop.mapreduce.jobhistory.JobHistory.setupEventWriter(JobHistory.java:252)
     [exec]     [junit] 	at org.apache.hadoop.mapred.JobInProgress.logSubmissionToJobHistory(JobInProgress.java:710)
     [exec]     [junit] 	at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:619)
     [exec]     [junit] 	at org.apache.hadoop.mapred.JobTracker.initJob(JobTracker.java:3256)
     [exec]     [junit] 	at org.apache.hadoop.mapred.EagerTaskInitializationListener$InitJob.run(EagerTaskInitializationListener.java:79)
     [exec]     [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
     [exec]     [junit] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
     [exec]     [junit] 	at java.lang.Thread.run(Thread.java:619)
     [exec]     [junit] Caused by: java.lang.NoSuchFieldException: _SCHEMA
     [exec]     [junit] 	at java.lang.Class.getDeclaredField(Class.java:1882)
     [exec]     [junit] 	at org.apache.avro.specific.SpecificData.createSchema(SpecificData.java:48)
     [exec]     [junit] 	... 11 more
     [exec]     [junit] 
     [exec]     [junit] Exception in thread ""pool-1-thread-3"" java.lang.OutOfMemoryError: Java heap space
     [exec]     [junit] 	at java.util.Arrays.copyOf(Arrays.java:2786)
     [exec]     [junit] 	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:94)
     [exec]     [junit] 	at java.io.PrintStream.write(PrintStream.java:430)
     [exec]     [junit] 	at org.apache.tools.ant.util.TeeOutputStream.write(TeeOutputStream.java:81)
     [exec]     [junit] 	at java.io.PrintStream.write(PrintStream.java:430)
     [exec]     [junit] 	at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:202)
     [exec]     [junit] 	at sun.nio.cs.StreamEncoder.implFlushBuffer(StreamEncoder.java:272)
     [exec]     [junit] 	at sun.nio.cs.StreamEncoder.implFlush(StreamEncoder.java:276)
     [exec]     [junit] 	at sun.nio.cs.StreamEncoder.flush(StreamEncoder.java:122)
     [exec]     [junit] 	at java.io.OutputStreamWriter.flush(OutputStreamWriter.java:212)
     [exec]     [junit] 	at org.apache.log4j.helpers.QuietWriter.flush(QuietWriter.java:58)
     [exec]     [junit] 	at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:316)
     [exec]     [junit] 	at org.apache.log4j.WriterAppender.append(WriterAppender.java:160)
     [exec]     [junit] 	at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251)
     [exec]     [junit] 	at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66)10/03/05 04:08:36 INFO raid.RaidNode: Triggering Policy Filter RaidTest1 hdfs://localhost:44624/user/test/raidtest
     [exec]     [junit] 10/03/05 04:08:39 INFO raid.RaidNode: Trigger thread continuing to run...
     [exec]     [junit] Exception in thread ""org.apache.hadoop.raid.RaidNode$TriggerMonitor@5ebac9"" 10/03/05 04:08:44 INFO security.Groups: Returning cached groups for 'hudso10/03/05 04:08:47 INFO ipc.Server: IPC Server handler 8 on 44624, call getException in thread ""IPC Server handler 8 on 44624"" java.lang.OutOfMemoryError: Java heap space10/03/05 04:08:53 INFO mapreduce.Job:  map 0% reduce 0%

"
MAPREDUCE-1560,Better diagnostic message for tasks killed for going over vmem limit,"Currently the user has no indication of his tasks getting killed due to vmem limit, the only way to know is by looking at TT logs. We should get the TT to insert a diagnostic string for the task to indicate this."
MAPREDUCE-1559,The DelegationTokenRenewal timer task should use the jobtracker's credentials to create the filesystem,"The submitJob RPC finally creates a timer task for renewing the delegation tokens of the submitting user. This timer task inherits the context of the RPC handler that runs in the context of the job submitting user, and when it tries to create a filesystem, the RPC client tries to use the user's credentials. This should instead use the JobTracker's credentials."
MAPREDUCE-1558,specify correct server principal for RefreshAuthorizationPolicyProtocol and RefreshUserToGroupMappingsProtocol protocols in MRAdmin (for HADOOP-6612),
MAPREDUCE-1557,MapReduce teragen  example should print correct error message for invalid inputs. Currently throws ArrayIndexOutOfBoundsException .,"MapReduce teragen  example should print correct error message for invalid inputs. 
Currently for invalid  CLI arguments stack trace is thrown with  ArrayIndexOutOfBoundsException. "
MAPREDUCE-1556,upgrade to Avro 1.3.0,"Avro 1.3.0 has now been released.  HADOOP-6486 and HDFS-892 require it, and the version of Avro used by MapReduce should be synchronized with these projects."
MAPREDUCE-1554,"If user name contains '_', then searching of jobs based on user name on job history web UI doesn't work","If user name contains underscore as part of it, then searching of jobs based on user name on job history web UI doesn't work. This is because in code, everywhere {code}split(""_""){code} is done on history file name to get user name. And other parts of history file name also should *not* be obtained by using split(""_"")."
MAPREDUCE-1553,mapred.userlog.retain.hours is improperly renamed in MAPREDUCE-849,"mapred.userlog.retain.hours is renamed as mapred.task.userlog.retain.hours in JobContext. But, in mapred-default, it is mapreduce.task.userlog.retain.hours.

"
MAPREDUCE-1552,TaskTracker should report which fs during error,"We run with ZFS with fs quotas for the mapred spill space to prevent it over-running the HDFS space.  During merge, we some times end up running out of space.  It would be useful if the stack trace (see below) included which file system the errors actually came from."
MAPREDUCE-1551,TestMiniMRLocalFS fails,"{{TestMiniMRLocalFS}} fails consistently on trunk:
{noformat}
Testcase: testWithLocal took 38.957 sec
        Caused an ERROR
File QuasiMonteCarlo_TMP_3_141592654/out/reduce-out does not exist.
java.io.FileNotFoundException: File QuasiMonteCarlo_TMP_3_141592654/out/reduce-out does not exist.
        at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:420)
        at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:246)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1466)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1447)
        at org.apache.hadoop.examples.QuasiMonteCarlo.estimatePi(QuasiMonteCarlo.java:313)
        at org.apache.hadoop.mapred.TestMiniMRWithDFS.runPI(TestMiniMRWithDFS.java:235)
        at org.apache.hadoop.mapred.TestMiniMRLocalFS.testWithLocal(TestMiniMRLocalFS.java:68)
{noformat}"
MAPREDUCE-1550,UGI.doAs should not be used for getting the history file of jobs,When the jobtracker tries to open a job history file it does a doAs to get the filesystem for the user (that had submitted the job). This should not be done since the job history files are owned by the jobtracker.
MAPREDUCE-1549,TestTrackerDistributedCacheManager failed on some machines,TestTrackerDistributedCacheManager.testPublicPrivateCache fails on some machines.
MAPREDUCE-1548,Hadoop archives should be able to preserve times and other properties from original files,"Files inside hadoop archives don't keep their original:

- modification time
- access time
- permission
- owner
- group

all such properties are currently taken from the file storing the archive index, and not the stored files. This doesn't look very correct.

There should be possible to preserve the original properties of the stored files."
MAPREDUCE-1547,Build Hadoop-Mapreduce-trunk and Mapreduce-trunk-Commit  fails,"http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/243/console



Build Hadoop-Mapreduce-trunk fails with this message

BUILD FAILED
/grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build.xml:1382: Execute failed: java.io.IOException: Cannot run program ""autoreconf"" (in directory ""/grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/src/c++/utils""): java.io.IOException: error=2, No such file or directory

http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/251/console

Build Mapreduce-trunk-Commit fails with this message:

/bin/bash /tmp/hudson2120484997034746272.sh
bash: /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/nightly/commitBuild.sh: No such file or directory

"
MAPREDUCE-1546,Jobtracker JSP pages should automatically redirect to the corresponding history page if not in memory,"MAPREDUCE-1185 redirects jobdetails.jsp to it's corresponding history page.

For convenience, we should also redirect the following JSP pages to the corresponding history pages:
jobconf.jsp
jobtasks.jsp
taskdetails.jsp
taskstats.jsp
"
MAPREDUCE-1545,Add 'first-task-launched' to job-summary,It would be useful to track 'first-task-launched' time to job-summary for better reporting.
MAPREDUCE-1544,Miscellaneous improvements to HTML markup for web UIs,"The Web UIs have various bits of bad markup (eg missing <head> sections, some pages missing CSS links, inconsistent td vs th for table headings). We should fix this up."
MAPREDUCE-1543,Log messages of JobACLsManager should use security logging of HADOOP-6586,{{JobACLsManager}} added in MAPREDUCE-1307 logs the successes and failures w.r.t job-level authorization in the corresponding Daemons' logs. The log messages should instead use security logging of HADOOP-6586.
MAPREDUCE-1542,Deprecate mapred.permissions.supergroup in favor of hadoop.cluster.administrators,"HADOOP-6568 added the configuration {{hadoop.cluster.administrators}} through which admins can configure who the superusers/supergroups for the cluster are. MAPREDUCE itself already has {{mapred.permissions.supergroup}} (which is just a single group). As agreed upon at HADOOP-6568, this should be deprecated in favor of {{hadoop.cluster.administrators}}."
MAPREDUCE-1541,JobHistory page should list job start time rather than job-tracker start time,
MAPREDUCE-1540,Sometimes JobTracker holds stale refrence of JobInProgress even after Job gets retired,"Ran random writer, sort and sort validate job. Checked the jmap -histo:live and verified that there is no reference of JobInProgress after Jobs are retired 
Now submitter around 77  sleeps of around 10000 maps. then after 1 hr killed all the job when jobs got retired. again checked jmap -histo:live  for JobInProgress for JT process found 2 references were there.
Found this while doing sanity testing of 1316"
MAPREDUCE-1539,authorization checks for inter-server protocol (based on HADOOP-6600),authorization checks for inter-server protocol (based on HADOOP-6600)
MAPREDUCE-1538,TrackerDistributedCacheManager can fail because the number of subdirectories reaches system limit,"TrackerDistributedCacheManager deletes the cached files when the size goes up to a configured number.
But there is no such limit for the number of subdirectories. Therefore the number of subdirectories may grow large and exceed system limit.
This will make TT cannot create directory when getLocalCache and fails the tasks."
MAPREDUCE-1537,TestDelegationTokenRenewal fails,"TestDelegationTokenRenewal does not compile in trunk.
The reason is that DelegationTokenSecretManager in hdfs requires namesystem in constructor."
MAPREDUCE-1536,DataDrivenDBInputFormat does not split date columns correctly.,"The DateSplitter does not properly split a range of (min, max) dates."
MAPREDUCE-1535,Replace usage of FileStatus#isDir(),HADOOP-6585 will deprecate FileStatus#isDir(). This jira is for replacing all uses of isDir() in MR with checks of isDirectory() or isFile() as needed.
MAPREDUCE-1534,MAP_INPUT_BYTES couner is not recorded with new M/R API ,I ran a WordCount example from hadoop 0.20.0 distribution and it does not record the MAP_INPUT_BYTES counter. Looks like it may be a problem with new mapreduce (Job) API.  
MAPREDUCE-1533,Reduce or remove usage of String.format() usage in CapacityTaskScheduler.updateQSIObjects and Counters.makeEscapedString(),"When short jobs are executed in hadoop with OutOfBandHeardBeat=true, JT executes heartBeat() method heavily. This internally makes a call to CapacityTaskScheduler.updateQSIObjects(). 

CapacityTaskScheduler.updateQSIObjects(), internally calls String.format() for setting the job scheduling information. Based on the datastructure size of ""jobQueuesManager"" and ""queueInfoMap"", the number of times String.format() gets executed becomes very high. String.format() internally does pattern matching which turns to be out very heavy (This was revealed while profiling JT. Almost 57% of time was spent in CapacityScheduler.assignTasks(), out of which String.format() took 46%.

Would it be possible to do String.format() only at the time of invoking JobInProgress.getSchedulingInfo?. This might reduce the pressure on JT while processing heartbeats. "
MAPREDUCE-1532,Delegation token is obtained as the superuser,"When the UserGroupInformation.doAs is invoked for proxy users, the delegation token is incorrectly obtained as the real user."
MAPREDUCE-1531,Log truncation via MAPREDUCE-1100 is broken,MAPREDUCE-1100 has a bug where the index isn't updated correctly.
MAPREDUCE-1529,TokenCache - needs api to clear the cache.,"It may cause some tests to fail (ones that run multiple jobs from the same process).
For example TestQueueManager
"
MAPREDUCE-1528,TokenStorage should not be static,"Currently, TokenStorage is a singleton. This doesn't work for some use cases, such as Oozie. I think that each Job should have a TokenStorage that is associated it."
MAPREDUCE-1527,QueueManager should issue warning if mapred-queues.xml is skipped.,"MAPREDUCE-861 added support for hierarchical queues and used a new file mapred-queues.xml to configure queues. But the QueueManager will silently skip the file if property ""mapred.queue.names"" is defined in Configuration. This tripped us when we are testing MAPREDUCE-1235 and copied configuration files from a Hadoop 0.20 cluster.

I suggest QueueManager issue a friendly warning if both of the following are true: (1) ""mapred.queue.names"" exists in Configuration; (2) ""mapred-queues.xml"" is found in the classpath."
MAPREDUCE-1526,"Cache the job related information while submitting the job , this would avoid many RPC calls to JobTracker.",
MAPREDUCE-1525,mapreduce- trunk-commit fails because of not able to delete ivy file,"mapreduce- trunk-commit fails because of not able to delete ivy file

http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk-Commit/250/consoleFull

pasting the part of log which shows the exact error:

BUILD FAILED
/grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk-Commit/trunk/build.xml:1171: Unable to delete file /homes/hudson/.ivy2/cache/org.apache.hadoop/hadoop-hdfs/jars/.nfs000000000540c1c300000029


"
MAPREDUCE-1524,Support for CLOB and BLOB values larger than can fit in memory,"The patch in MAPREDUCE-1446 provides support for ""inline"" CLOB and BLOB values which can be fully materialized. Values which are too big for RAM should be written to separate files in HDFS and referenced in an indirect fashion; access should be provided through a stream."
MAPREDUCE-1523,Sometimes rumen trace generator fails to extract the job finish time.,We saw sometimes (not very often) that rumen may fail to extract the job finish time from Hadoop 0.20 history log.
MAPREDUCE-1522,FileInputFormat may change the file system of an input path,"org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(Job job, Path path) uses the default FileSystem but not the FileSystem specified in the path.
{code}
//org.apache.hadoop.mapreduce.lib.input.FileInputFormat
  public static void addInputPath(Job job, 
                                  Path path) throws IOException {
    Configuration conf = job.getConfiguration();
    FileSystem fs = FileSystem.get(conf);
    path = path.makeQualified(fs); // the original FileSystem is lost.
    ...
  }
{code}
There is a similar problem in FileInputFormat.setInputPaths(..)."
MAPREDUCE-1521,Protection against incorrectly configured reduces,"We've seen a fair number of instances where naive users process huge data-sets (>10TB) with badly mis-configured #reduces e.g. 1 reduce.

This is a significant problem on large clusters since it takes each attempt of the reduce a long time to shuffle and then run into problems such as local disk-space etc. Then it takes 4 such attempts.

Proposal: Come up with heuristics/configs to fail such jobs early. 

Thoughts?"
MAPREDUCE-1520,TestMiniMRLocalFS fails on trunk,TestMiniMRLocalFS fails on trunk. I checked with both trunk revs - pre and post MAPREDUCE-1430 commit and it failed in both the cases.
MAPREDUCE-1519,RaidNode fails to create new parity file if an older version already exists,"When RaidNode tries to recreate a parity file for a source file that has been modified (recreated) recently, it crashes.

"
MAPREDUCE-1518,"On contrib/raid, the RaidNode currently runs the deletion check for parity files on directories too. It would be better if it didn't.",
MAPREDUCE-1517,streaming should support running on background,"StreamJob submit the job and use a while loop monitor the progress.
I prefer it running on background.

Just add ""&"" at the end of command is a alternative solution, but it keeps a java process on client machine.
When submit hundreds jobs at the same time, the client machine is overloaded.

Adding a -background option to StreamJob, tell it only submit and don't monitor the progress.
"
MAPREDUCE-1516,JobTracker should issue a delegation token only for kerberos authenticated client,Delegation tokens should be issued only if the client is kerberos authenticated.
MAPREDUCE-1515,need to pass down java5 and forrest home variables,"Currently, the build script doesn't pass down the variables for java5 and forrest, so the build breaks unless they are on the command line."
MAPREDUCE-1514,"Add documentation on permissions, limitations, error handling for archives.",add documentaion on permissions aspect of archives and other limitations that it might have. Also add documentation on error handling (with respect to quota's/otherwise) to the forrest docs.
MAPREDUCE-1512,RAID could use HarFileSystem directly instead of FileSystem.get,"Makes the code run slightly faster and avoids possible problems in matching the right filesystem like the stale cache reported in HADOOP-6097.

This is a minor improvement for trunk, but it is really helpful for people running RAID on earlier releases susceptible to HADOOP-6097, since RAID would crash on them."
MAPREDUCE-1510,RAID should regenerate parity files if they get deleted,"Currently, if a source file has a replication factor lower or equal to that expected by RAID, the file is skipped and no parity file is generated. I don't think this is a good behavior since parity files can get wrongly deleted, leaving the source file with a low replication factor. In that case, raid should be able to recreate the parity file.
"
MAPREDUCE-1509,Partition size of Hadoop Archives should be configurable,"The size of partitions on Hadoop Archives is fixed to 2G:

  static final long partSize = 2 * 1024 * 1024 * 1024l;

We should make it a configurable parameter so that users can define it at the command line

$ hadoop archive -partsize 4 ....


"
MAPREDUCE-1508,NPE in TestMultipleLevelCaching on error cleanup path,TestMultipleLevelCaching dereferences objects in a finally block which may not have been initialized.
MAPREDUCE-1507,The old MapReduce API is only partially deprecated,"Not all of the old API is currently marked as deprecated. E.g. org.apache.hadoop.mapred.OutputFormat is deprecated, but org.apache.hadoop.mapred.FileOutputFormat isn't."
MAPREDUCE-1506,Assertion failure in TestTaskTrackerMemoryManager,"With asserts enabled, TestTaskTrackerMemoryManager sometimes fails. From what I've inspected, it's because some tasks are marked as FAILED/TIPFAILED while others are marked SUCCEEDED.

This can be reproduced by applying MAPREDUCE-1092 and then running {{ant clean test -Dtestcase=TestTaskTrackerMemoryManager}}"
MAPREDUCE-1505,Cluster class should create the rpc client only when needed,"It will be good to have the org.apache.hadoop.mapreduce.Cluster create the rpc client object only when needed (when a call to the jobtracker is actually required). org.apache.hadoop.mapreduce.Job constructs the Cluster object internally and in many cases the application that created the Job object really wants to look at the configuration only. It'd help to not have these connections to the jobtracker especially when Job is used in the tasks (for e.g., Pig calls mapreduce.FileInputFormat.setInputPath in the tasks and that requires a Job object to be passed).

In Hadoop 20, the Job object internally creates the JobClient object, and the same argument applies there too.
"
MAPREDUCE-1504,SequenceFile.Reader constructor leaking resources,"When {{SequenceFile.Reader}} constructor throws an {{IOException}} (because the file does not conform to {{SequenceFile}} format), we will have such a problem.
The caller won't have a pointer to the reader because of the {{IOException}} thrown.

We should call {{in.close()}} inside the constructor to make sure that we don't leak resources (file descriptor and connection to the data node, etc).
"
MAPREDUCE-1503,Push HADOOP-6551 into MapReduce,We need to throw readable exceptions instead of returning false.
MAPREDUCE-1502,Sqoop should run mysqldump in a mapper as opposed to a user-side process,"Sqoop currently runs mysqldump (""direct import mode"") in the local user process with a single thread. Better system performance and reliability could be achieved by running this in a parallel set of mapper tasks."
MAPREDUCE-1501,FileInputFormat to support multi-level/recursive directory listing,"As we have seen multiple times in the mailing list, users want to have the capability of getting all files out of a multi-level directory structure.

4/1/2008: http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200804.mbox/%3Ce75c02ef0804011433x144813e6x2450da7883de3aca@mail.gmail.com%3E

2/3/2009: http://mail-archives.apache.org/mod_mbox/hadoop-core-user/200902.mbox/%3C7F80089C-3E7F-4330-90BA-6F1C5B0B0F3F@nist.gov%3E

6/2/2009: http://mail-archives.apache.org/mod_mbox/hadoop-common-user/200906.mbox/%3C4A258A16.8050300@darose.net%3E


One solution that our users had is to write a new FileInputFormat, but that means all existing FileInputFormat subclasses need to be changed in order to support this feature.

We can easily provide a JobConf option (which defaults to false) to {{FileInputFormat.listStatus(...)}} to recursively go into directory structure.
"
MAPREDUCE-1499,JobTracker.finalizeJob inverts lock order and causes potential deadlock,"This issue was brought up by Matei in MAPREDUCE-1436 as a fairsched bug, but it turns out it's a JT bug even with the fifo scheduler in unpatched 0.20.2. JobTracker.finalizeJob locks JT.jobs, JT.taskScheduler, etc, having gotten the JIP log before the JT lock."
MAPREDUCE-1497,Suppress warning on inconsistent TaskTracker.indexCache synchronization,"Findbugs warns that TaskTracker.indexCache is incorrectly synchronized. 
It is not accessed synchronously from MapOutputServlet.doGet, TaskCleanupThread and  TaskTracker.killOverflowingTasks() method. Other callers access it synchronously."
MAPREDUCE-1495,Reduce locking contention on JobTracker.getTaskCompletionEvents(),"While profiling JT for slow performance with small-jobs, it was observed that JobTracker.getTaskCompletionEvents() is attributing to 40% of lock contention on JT.

This JIRA ticket is created to explore the possibilities of reducing the sychronized code block in this method. "
MAPREDUCE-1494,TestJobDirCleanup verifies wrong jobcache directory,TestJobDirCleanup verifies tasktracker/jobcache directory to be empty. But localization happens in tasktracker/user/jobcache after MAPREDUCE-856.
MAPREDUCE-1493,Authorization for job-history pages,"MAPREDUCE-1455 introduces authorization for most of the Map/Reduce jsp pages and servlets, but left history pages. This JIRA will make sure that authorization checks are made while accessing job-history pages also."
MAPREDUCE-1492,Delete or recreate obsolete har files used on hdfs raid,The current code for har on raid doesn't delete or recreate har directories when they become obsolete. We should fix that.
MAPREDUCE-1491,Use HAR filesystem to merge parity files ,"The HDFS raid implementation (HDFS-503) creates a parity file for every file that is RAIDed. This puts additional burden on the memory requirements of the namenode. It will be  nice if the parity files are combined together using the HadoopArchive (har) format.


This was (HDFS-684) before, but raid migrated to MAPREDUCE."
MAPREDUCE-1490,Raid client throws NullPointerException during initialization,"During instantiation and initialization, the DistributedRaidFileSystem class throws a NullPointerException."
MAPREDUCE-1489,DataDrivenDBInputFormat should not query the database when generating only one split,"DataDrivenDBInputFormat runs a query to establish bounding values for each split it generates; but if it's going to generate only one split (mapreduce.job.maps == 1), then there's no reason to do this. This will remove overhead associated with a single-threaded import of a non-indexed table since it avoids a full table scan."
MAPREDUCE-1485,CapacityScheduler should have prevent a single job taking over large parts of a cluster,"The proposal is to have a per-queue limit on the number of concurrent tasks a job can run on a cluster. 

We've seen cases where a single, large, job took over a majority of the cluster - worse, it meant that any bug in it caused issues for both the NameNode _and_ the JobTracker."
MAPREDUCE-1483,CompletedJobStore should be authorized using job-acls,MAPREDUCE-1307 adds job-acls. CompletedJobStore serves job-status off DFS after jobs are long gone and needs to have job-acls also serialized so as to facilitate authorization of job related requests.
MAPREDUCE-1482,Better handling of task diagnostic information stored in the TaskInProgress,Task diagnostic information can be very large at times eating up Jobtracker's memory. There should be some way to avoid storing large error strings in JobTracker.
MAPREDUCE-1480,CombineFileRecordReader does not properly initialize child RecordReader,CombineFileRecordReader instantiates child RecordReader instances but never calls their initialize() method to give them the proper TaskAttemptContext.
MAPREDUCE-1476,committer.needsTaskCommit should not be called for a task cleanup attempt,"Currently, Task.done() calls committer.needsTaskCommit() to know whether it needs a commit or not. This need not be called for task cleanup attempt as no commit is required for a cleanup attempt. 
Due to MAPREDUCE-1409, we saw a case where cleanup attempt went into COMMIT_PENDING state."
MAPREDUCE-1474,forrest docs for archives is out of date.,The docs for archives are out of date. The new docs that were checked into hadoop common were lost because of the project split.
MAPREDUCE-1473,Sqoop should allow users to control export parallelism,"Sqoop uses MapReduce jobs to export files back to a table in the database. The degree of parallelism is controlled by the number of splits; i.e., the number of input files used. The bottleneck in the system, though, is likely to be the database itself.

Users should have the ability to tune the number of parallel exporters being used to a degree appropriate to their database deployment."
MAPREDUCE-1472,JobTracker.submitJob holds a lock on the JobTracker while copying job-conf from HDFS,"This could have very bad impact on responsiveness of the cluster.

JobTracker.submitJob also forks a DU and writes to it's local-disk."
MAPREDUCE-1471,FileOutputCommitter does not safely clean up it's temporary files,"When the FileOutputCommitter cleans up during it's cleanupJob method, it potentially deletes the temporary files of other concurrent jobs.

Since all the temporary files for all concurrent jobs are written to working_path/_temporary/ any concurrent tasks that have the same working_path will remove all currently executing jobs when it removes working_path/_temporary during job cleanup.

If the file name output is guaranteed by the client application to be unique, the temporary files/directories should also be guaranteed to be unique to avoid this problem. Suggest modifying cleanupJob to only remove files that it created itself."
MAPREDUCE-1470,Move Delegation token into Common so that we can use it for MapReduce also,We need to update one reference for map/reduce when we move the hdfs delegation tokens.
MAPREDUCE-1469,Sqoop should disable speculative execution in export,Concurrent writers of the same output shard may cause the database to try to insert duplicate primary keys concurrently. Not a good situation. Speculative execution should be forced off for this operation.
MAPREDUCE-1467,Add a --verbose flag to Sqoop,Need a {{--verbose}} flag that sets the log4j level to DEBUG.
MAPREDUCE-1466,FileInputFormat should save #input-files in JobConf,"We already track the amount of data consumed by MR applications (MAP_INPUT_BYTES), alongwith, it would be useful to #input-files from the client-side for analysis. Along the lines of MAPREDUCE-1403, it would be easy to stick in the JobConf during job-submission."
MAPREDUCE-1465,archive partSize should be configurable,"The archive part size is current set to 2GB.  For archiving 10^5 small files, it took 52 minutes since there is only 1 mapper.

{noformat}
-bash-3.1$ time $H archive ${Q} -archiveName ${DIR}.3.har -p ${PARENT} ${DIR} ${PARENT}
10/02/06 01:55:14 INFO mapred.JobClient: Running job: job_201002042035_5737
...
10/02/06 02:47:18 INFO mapred.JobClient:  map 100% reduce 100%
10/02/06 02:47:19 INFO mapred.JobClient: Job complete: job_201002042035_5737
...
10/02/06 02:47:19 INFO mapred.JobClient:     Reduce input records=100002

real    52m27.188s
user    0m29.314s
sys     0m1.276s
{noformat}
"
MAPREDUCE-1464,In JobTokenIdentifier change method getUsername to getUser which returns UGI,The TokenIdentifier interface has changed in HADOOP-6510. This jira tracks corresponding change in MR. The only change is that in JobTokenIdentifier getUsername method will be changed to getUser that will return ugi.
MAPREDUCE-1461,Feature to instruct rumen-folder utility to skip jobs worth of specific duration,"JSON outputs of rumen on production logs can be huge in the order of multiple GB. Rumen's folder utility helps in getting a smaller snapshot of this JSON data.
It would be helpful to have an option in rumen-folder, wherein user can specify a duration from which rumen-folder should start processing data.

Related JIRA link: https://issues.apache.org/jira/browse/MAPREDUCE-1295"
MAPREDUCE-1460,Oracle support in DataDrivenDBInputFormat,DataDrivenDBInputFormat does not work with Oracle due to various SQL syntax issues.
MAPREDUCE-1459,There are javadoc warnings in Trunk,"There are two javadoc warnings in Trunk.

They're trivial and I will fix them quickly."
MAPREDUCE-1457,"For secure job execution, couple of more UserGroupInformation.doAs needs to be added","During our testing in a kerberos environment, we had to add UserGroupInformation.doAs blocks in certain places."
MAPREDUCE-1455,Authorization for servlets,"This jira is about building the authorization for servlets (on top of MAPREDUCE-1307). That is, the JobTracker/TaskTracker runs authorization checks on web requests based on the configured job permissions. For e.g., if the job permission is 600, then no one except the authenticated user can look at the job details via the browser. The authenticated user in the servlet can be obtained using the HttpServletRequest method."
MAPREDUCE-1454,The servlets should quote server generated strings sent in the response,This is related to HADOOP-6151 but for output. We need to go through all the servlets/jsps and pass all the response strings that could be based on the incoming request or user's data through a filter (implemented in HADOOP-6151).
MAPREDUCE-1452,Add a low-level MapReduce API,"Add an API to MapReduce that operates at the raw bytes level. The existing (object-based) MapReduce APIs would be implemented on top of the raw API, and in future it will be easier to add new APIs (like MAPREDUCE-1183) and higher-level abstractions on MapReduce. "
MAPREDUCE-1450,task logs should specify user vs. system death,"When looking at task attempt logs, it should specify whether the task was killed by Hadoop or by the user."
MAPREDUCE-1449,Sqoop Documentation about --split-by column has to be unique key seems to be wrong,"http://archive.cloudera.com/docs/sqoo... 

The document above shows that "" To guarantee correctness of your input, you must select an ordering column for which each row has a unique value. If duplicate values appear in the ordering column, the results of the import are undefined, and Sqoop will not be able to detect the error."" 

I read the source code for sqoop, it seems that the column to split by doesn't have to be a unique key. Plus, when the primary key is a composite key, the sqoop code only takes the first column of the composite key which in most cases is not unique key anyways. 

I also checked the output when non-unique key is used to split, there is nothing wrong with the result. 

I am wondering if the document is wrong, or there is some hidden trickiness that I am not aware of. 

I am using sqoop 20.1."
MAPREDUCE-1448,[Mumak] mumak.sh does not honor --config option.,"When --config is specified, mumak.sh should put the customized conf directory in the classpath."
MAPREDUCE-1447,job level hook in OutputCommitter is not working in local mode,"OutputCommitter is not totally working in local mode. Only task level hooks are called, which are setupTask, needsTaskCommit, commitTask, abortTask. Job level hooks are not working, which are: setupJob, cleanupJob."
MAPREDUCE-1446,Sqoop should support CLOB and BLOB datatypes,Sqoop should allow import of CLOB and BLOB based data.
MAPREDUCE-1445,Refactor Sqoop tests to support better ConnManager testing,"Sqoop's test suite is heavily biased toward testing with the HSQLDB embedded database. This issue proposes to refactor some tests into abstract classes which can be used as a basis for testing a variety of connection manager implementations, ensuring better cross-database compatibility coverage."
MAPREDUCE-1444,Sqoop ConnManager instances can leak Statement objects,"The ConnManager API returns ResultSets to users but does not provide a mechanism to clean up the underlying Statement that generated the ResultSet. Problematically, closing the Statement will invalidate the ResultSet, so these must be cleaned up in LIFO order, putting the onus on the receiver of the ResultSet."
MAPREDUCE-1443,DBInputFormat can leak connections,"The DBInputFormat creates a Connection to use when enumerating splits, but never closes it. This can leak connections to the database which are not cleaned up for a long time."
MAPREDUCE-1442,StackOverflowError when JobHistory parses a really long line,"JobHistory.parseLine() fails with StackOverflowError on a really big COUNTER value, triggered via the web interface. See attached file."
MAPREDUCE-1441,Configuration of directory lists should trim whitespace,"HADOOP-2366 added a getTrimmedStringCollection method to Configuration. MapReduce should use this for all the cases where it configures a list of directories. This solves issues that come up when people set mapred.local.dir to ""/data/1, /data/2, /data/3"" (note the spaces). This is a very common mistake that we should guard against."
MAPREDUCE-1440,MapReduce should use the short form of the user names,"To minimize disruption on MapReduce, we should use the local names (ie. ""omalley"") rather than the long names (ie. ""omalley@APACHE.ORG"" as the basis for the username in MapReduce."
MAPREDUCE-1439,Learning Scheduler,"I would like to contribute the scheduler I have written to the MapReduce project. Presently the scheduler source code is available on http://code.google.com/p/learnsched/. It has been tested to work with Hadoop 0.20, although the code available at the URL had been modified to build with trunk and needs testing. Currently the scheduler is in experimental stages, and any feedback for improvement will be extremely useful."
MAPREDUCE-1438,Include one minute load average information in TaskTrackerStatus.ResourceStatus,"Load averages are useful indicators of overall system CPU and I/O activity. Including load average information in ResourceStatus could be useful to schedulers in balancing load across TaskTrackers. Since JDK 1.6, one minute. load information can be obtained using the OperatingSystemMXBean.getSystemLoadAverage() method."
MAPREDUCE-1437,org.apache.hadoop.examples.terasort.TestTeraSort.testTeraSort is failing in trunk,"Trunk is failing because of this error

http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/223/testReport/org.apache.hadoop.examples.terasort/TestTeraSort/testTeraSort/

Error Message

port out of range:-1

Stacktrace

java.lang.IllegalArgumentException: port out of range:-1
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:377)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.activate(NameNode.java:317)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:308)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:421)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:410)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1261)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:127)
	at org.apache.hadoop.mapred.HadoopTestCase.setUp(HadoopTestCase.java:148)

Attaching full output as attachment."
MAPREDUCE-1436,Deadlock in preemption code in fair scheduler,"In testing the fair scheduler with preemption, I found a deadlock between updatePreemptionVariables and some code in the JobTracker. This was found while testing a backport of the fair scheduler to Hadoop 0.20, but it looks like it could also happen in trunk and 0.21. Details are in a comment below."
MAPREDUCE-1435,symlinks in cwd of the task are not handled properly after MAPREDUCE-896,"With JVM reuse, TaskRunner.setupWorkDir() lists the contents of workDir and does a fs.delete on each path listed. If the listed file is a symlink to directory, it will delete the contents of those linked directories. This would delete files from distributed cache and jars directory,if mapred.create.symlink is true.
Changing ownership/permissions of symlinks through ENABLE_TASK_FOR_CLEANUP would change ownership/permissions of underlying files.

This is observed by Karam while running streaming jobs with DistributedCache and jvm reuse."
MAPREDUCE-1433,Create a Delegation token for MapReduce,"Occasionally, MapReduce jobs need to launch other MapReduce jobs. With security enabled, the task needs to authenticate to the JobTracker as the user with a token."
MAPREDUCE-1432,Add the hooks in JobTracker and TaskTracker to load tokens from the token cache into the user's UGI,Related to HADOOP-6520. Here it is about putting hooks in the JobTracker/TaskTracker for loading tokens in the user's UGI. This is required when job files are copied from the HDFS on behalf of the user.
MAPREDUCE-1430,JobTracker should be able to renew delegation tokens for the jobs,JobTracker should automatically renew delegation tokens for the jobs it is currently running.
MAPREDUCE-1429,New ant target to run all and only the linux task-controller related tests,"The LinuxTaskController tests cannot be run automatically by Hudson and so we've missed several bugs in the past because of not running some of these tests explicitly ourselves. It's a real pain to run them manually one by one, we should have an ant target to run them all in one swoop."
MAPREDUCE-1428,Make block size and the size of archive created files configurable.,"Currently the block size used by archives is the default block size of the hdfs filesystem. We need to make it configurable so that the block size can be higher for the part files that archives create.
Also, we need to make the size of part files in archives configurable again to make it bigger in size and create less number of such files.
"
MAPREDUCE-1425,archive throws OutOfMemoryError,"{noformat}
-bash-3.1$ hadoop  archive -archiveName t4.har -p . t4 .
Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space
        at java.util.regex.Pattern.compile(Pattern.java:1432)
        at java.util.regex.Pattern.<init>(Pattern.java:1133)
        at java.util.regex.Pattern.compile(Pattern.java:847)
        at java.lang.String.replace(String.java:2208)
        at org.apache.hadoop.fs.Path.normalizePath(Path.java:146)
        at org.apache.hadoop.fs.Path.initialize(Path.java:137)
        at org.apache.hadoop.fs.Path.<init>(Path.java:126)
        at org.apache.hadoop.fs.Path.makeQualified(Path.java:296)
        at org.apache.hadoop.hdfs.DistributedFileSystem.makeQualified(DistributedFileSystem.java:244)
        at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:256)
        at org.apache.hadoop.tools.HadoopArchives.archive(HadoopArchives.java:393)
        at org.apache.hadoop.tools.HadoopArchives.run(HadoopArchives.java:736)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.tools.HadoopArchives.main(HadoopArchives.java:751)
{noformat}"
MAPREDUCE-1423,Improve performance of CombineFileInputFormat when multiple pools are configured,"I have a map-reduce job that is using CombineFileInputFormat. It has configured 10000 pools and 30000 files. The time to create the splits takes more than an hour. The reaosn being that CombineFileInputFormat.getSplits() converts the same path from String to Path object multiple times, one for each instance of a pool. Similarly, it calls Path.toUri(0 multiple times. This code can be optimized."
MAPREDUCE-1422,Changing permissions of files/dirs under job-work-dir may be needed sothat cleaning up of job-dir in all mapred-local-directories succeeds always,"After MAPREDUCE-896, if LinuxTaskController is set in config, task-controller binary is launched for changing permissions of taskAttemptDir and taskWorkDir before cleaning up of these directories sothat cleanup will be succeeded even if user had created files/dirs under taskAttemptDir or taskWorkDir with non-writable permissions. Users can't create files/dirs under job-dir directly as we set 2570 for job-dir. But as job-work-dir has 2770 permissions and user can create files/dirs under job-work-dir with non-writable permissions, Changing permissions of files/dirs under job-work-dir may be needed sothat cleaning up of job-dir in all mapred-local-directories succeeds always."
MAPREDUCE-1421,LinuxTaskController tests failing on trunk after the commit of MAPREDUCE-1385,"The following tests fail, in particular:
 - TestDebugScriptWithLinuxTaskController
 - TestJobExecutionAsDifferentUser
 - TestPipesAsDifferentUser
 - TestKillSubProcessesWithLinuxTaskController"
MAPREDUCE-1420,TestTTResourceReporting failing in trunk,"TestTTResourceReporting failing in trunk. 

The most specific issue from the logs seems to be : Error executing shell command org.apache.hadoop.util.Shell$ExitCodeException: kill: No such process 

Link :
http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/217/

Attaching output in a  file.

"
MAPREDUCE-1419,Enhance tasktracker's localization tests after MAPREDUCE-181,"The following tests are missing:
 - Verifying the secure permissions and ownership of the localized token-file
 - Making the tests future proof against missing of permissions/ownership checks of newly added files/directories.
 - JobContext.JOB_TOKEN_FILE property setting in the localized job-configuration.
 - Failure of localization if the token-file is not present in the JT file-system"
MAPREDUCE-1417,Forrest documentation should be updated to reflect the changes in MAPREDUCE-744,MAPREDUCE-744 introduced private/public visibility of DistributedCache files on the TaskTracker. Forrest documentation is stale and only refers to private visible files.
MAPREDUCE-1416,New JIRA components for Map/Reduce project,"We need more JIRA components for the Map/Reduce project for better tracking. Some missing ones: DistributedCache, TaskController, contrib/vaidya, contrib/mruit, contrib/dynamic-scheduler, contrib/data_join."
MAPREDUCE-1414, TestRecoveryManager can spin waiting for a job to be half done,"This is something I've seen: the TestRecoveryManager spinning forever waiting for a job to get half done. The test runner will eventually kill it, but that loses any log and chance of finding the problem.

Solution: have a timeout on how long you wait for the job"
MAPREDUCE-1413,Improve logging of progress/errors in the job and task trackers,"I have code that improves the logging of the trackers as they start stop and fail, through
# More logging of events
# including exception strings and stacks when things go wrong
People's whose JTs and TTs aren't behaving may appreciate this"
MAPREDUCE-1412,TestTaskTrackerBlacklisting fails sometimes,"{{TestTaskTrackerBlacklisting}} fails occasionally. The granularity of the timer is responsible; the unit test adds a day to the expiration interval to verify that the tracker is removed from the blacklist, but the tracker is not removed if the interval exactly matches 1 day."
MAPREDUCE-1409,FileOutputCommitter.abortTask should not catch IOException,"FileOutputCommitter.abortTask currently catches IOException. It should be thrown out, thus making the task failed."
MAPREDUCE-1408,Allow customization of job submission policies,"Currently, gridmix3 replay job submission faithfully. For evaluation purposes, it would be great if we can support other job submission policies such as sequential job submission, or stress job submission."
MAPREDUCE-1407,"Invalid example in the documentation of org.apache.hadoop.mapreduce.{Mapper,Reducer}",Both examples are using context.collect instead of context.write
MAPREDUCE-1406,JobContext.MAP_COMBINE_MIN_SPILLS is misspelled,{{JobContext.MAP_COMBINE_MIN_SPILLS}} is misspelled as {{JobContext.MAP_COMBINE_MIN_SPISS}}
MAPREDUCE-1405,unchecked cast warnings in trunk,"{noformat}
compile-mapred-classes:
[jsp-compile] 10/01/24 15:16:55 WARN compiler.TldLocationsCache: Internal Error: File /WEB-INF/web.xml not found
    [javac] Compiling 494 source files to /.../mapred/build/classes
    [javac] /.../mapred/src/java/org/apache/hadoop/mapred/Child.java:159: warning: [unchecked] unchecked cast
    [javac] found   : org.apache.hadoop.security.token.Token<capture#981 of ? extends org.apache.hadoop.security.token.TokenIdentifier>
    [javac] required: org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier>
    [javac]         Token<JobTokenIdentifier> jt = (Token<JobTokenIdentifier>)ts.getJobToken();
    [javac]                                                                                 ^
    [javac] /.../mapred/src/java/org/apache/hadoop/mapred/TaskTracker.java:922: warning: [unchecked] unchecked cast
    [javac] found   : org.apache.hadoop.security.token.Token<capture#810 of ? extends org.apache.hadoop.security.token.TokenIdentifier>
    [javac] required: org.apache.hadoop.security.token.Token<org.apache.hadoop.mapreduce.security.token.JobTokenIdentifier>
    [javac]         Token<JobTokenIdentifier> jt = (Token<JobTokenIdentifier>)ts.getJobToken();
{noformat}"
MAPREDUCE-1404,Cluster-Setup and Single-Node-Setup Docs ,"(Updated Summary and Description)

The cluster_setup.xml file is in 2 places: common-trunk and mapreduce-trunk. 

The single_node_setup.xml file is in 1 place: common-trunk.

Issues:

(1) Remove duplication - cluster_setup.xml should only be in 1 trunk (no duplication of files)

(2) Both files stay together - cluster_setup.xml and single_node_setup.xml should be together in the same location (trunk)

(3) Which trunk - originally, both files were  assigned to the common-trunk during the doc split that occured the summer of 2009. 

Solutions:

(1) have both files live in common-trunk  ... OR ...

(2) have both files live in mapreduce-trunk

This ticket affects trunk and branch-0.21

"
MAPREDUCE-1403,Save file-sizes of each of the artifacts in DistributedCache in the JobConf,It would be a useful metric to collect... potentially GridMix could use it to emulate jobs which use the DistributedCache.
MAPREDUCE-1402,Remove src/benchmarks,src/benchmarks has not attracted many contributions. The versions of gridmix currently there are deprecated in in favor of the version in contrib (MAPREDUCE-776) and will be redundant after MAPREDUCE-1401.
MAPREDUCE-1401,[Gridmix] Add a load generating factory,"To replace previous Gridmix benchmarks (HADOOP-2369 , HADOOP-3770), it must be possible to put a sustained, saturating load on a cluster. While tools for manipulating traces (MAPREDUCE-1295) allow one to produce lighter or heavier load than observed, a client monitoring and responding to observed load would let one write easier-to-interpret, end-to-end benchmarks."
MAPREDUCE-1400,sed in build.xml fails,MAPRED version of HADOOP-6505
MAPREDUCE-1399,The archive command shows a null error message,"{noformat}
bash-3.1$ hadoop archive -archiveName foo.har -p . foo .
Exception in archives
null
{noformat}"
MAPREDUCE-1398,TaskLauncher remains stuck on tasks waiting for free nodes even if task is killed.,"Tasks could be assigned to trackers for slots that are running other tasks in a commit pending state. This is an optimization done to pipeline task assignment and launch. When the task reaches the tracker, it waits until sufficient slots become free for it. This wait is done in the TaskLauncher thread. Now, while waiting, if the task is killed externally (maybe because the job finishes, etc), the TaskLauncher is not notified of this. So, it continues to wait for the killed task to get sufficient slots. If slots do not become free for a long time, this would result in considerable delay in waking up the TaskLauncher thread. If the waiting task happens to be a high RAM task, then it is also wasteful, because by waking up, it can make way for normal tasks that can run on the available number of slots."
MAPREDUCE-1397,NullPointerException observed during task failures,"In an environment where many jobs are killed simultaneously, NPEs are observed in the TT/JT logs when a task fails. The situation is aggravated when the taskcontroller.cfg is not configured properly. Below is the exception obtained:

{noformat}
INFO org.apache.hadoop.mapred.TaskInProgress: Error from <attempt_ID>:
java.lang.Throwable: Child Error
        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:529)
Caused by: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.getDetails(JvmManager.java:329)
        at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.reapJvm(JvmManager.java:315)
        at org.apache.hadoop.mapred.JvmManager$JvmManagerForType.access$000(JvmManager.java:146)
        at org.apache.hadoop.mapred.JvmManager.launchJvm(JvmManager.java:109)
        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:502)

 {noformat}"
MAPREDUCE-1396,Display more details about memory usage on jobtracker web UI,"HDFS-850 is introducing changes to the NameNode web UI to display additional details of memory information. I think it will be good to have similar information for the jobtracker as well, particularly for heavily used clusters that run the risk of the masters running out of memory."
MAPREDUCE-1395,Sqoop does not check return value of Job.waitForCompletion(),"Old code depended on JobClient.runJob() throwing IOException on failure. Job.waitForCompletion can fail in that manner, or it can fail by returning false. Sqoop needs to check for this condition."
MAPREDUCE-1394,Sqoop generates incorrect URIs in paths sent to Hive,"Hive used to require a ':8020' in HDFS URIs used with LOAD DATA statements, even though the normalized form of such a URI does not contain an explicit port number (since 8020 is the default port). Sqoop matched this by hacking the URI strings it forwarded to Hive.

Hive fixed this bug a while ago -- Sqoop should catch up."
MAPREDUCE-1393,Update http://hadoop.apache.org/mapreduce/credits.html with current list of committers,The website appears out of date; http://people.apache.org/~jim/committers.html lists folks as committers to projects who do not appear on http://hadoop.apache.org/mapreduce/credits.html.
MAPREDUCE-1392,TestReduceFetch failure,TestReduceFetch is failing on one of our QA machines
MAPREDUCE-1391,mapred.jobtracker.restart.recover should be true by default,"I haven't played with it much (about to), but is there a reason why jt recover is false by default?  "
MAPREDUCE-1390,"Default value of ""/tmp/hadoop/mapred/system"" for JTConfig.JT_SYSTEM_DIR prevents multiple users from running tests and starting mapred cluster/JobTracker","This was done by MAPREDUCE-181.

Same is the case with ""/tmp/hadoop/mapred/staging"" in LocalJobRunner.

The default values should instead point to /tmp/hadoop-$user/."
MAPREDUCE-1388,Move RAID from HDFS to MR,Here's the MR side change of HDFS-902. The HDFS RAID code has a MR dependency so let's move it to the mapred repo. 
MAPREDUCE-1386,'ant javadoc' fails,"_ant javadoc_ fails with the warning :
trunk/src/contrib/mumak/src/java/org/apache/hadoop/mapred/SimulatorJobTracker.java:44: warning - Tag @link: reference not found: JobSubmissionProtocol

Looks like MAPREDUCE-777 renamed JobSubmissionProtocol.java to ClientProtocol.java but didnt delete the orignal JobSubmissionProtocol.java file (i.e svn del). MAPREDUCE-847 deleted (svn del) JobSubmissionProtocol.java resulting into stale javadoc links."
MAPREDUCE-1385,Make changes to MapReduce for the new UserGroupInformation APIs (HADOOP-6299),This is about moving the MapReduce code to use the new UserGroupInformation API as described in HADOOP-6299.
MAPREDUCE-1383,Allow storage and caching of delegation token.,Client needs to obtain delegation tokens from all the NameNodes it is going to work with and pass it to the application.
MAPREDUCE-1382,MRAsyncDiscService should tolerate missing local.dir,"Currently when some of the local.dir do not exist, MRAsyncDiscService will fail. It should only fail when all directories don't work."
MAPREDUCE-1379,Limit both numMapTasks and numReduceTasks,"In some environment, the number of concurrent running process is very sensitive.

  mapreduce.tasktracker.map.tasks.maximum
and
  mapreduce.tasktracker.reduce.tasks.maximum
limit tasks running on each tasktracker separately.

This patch limits them together, using mapreduce.tasktracker.total.tasks.maximum"
MAPREDUCE-1378,Args in job details links on jobhistory.jsp are not URL encoded,"The logFile argument in the job links on the JT jobhistory.jsp page is not properly URL encoded leading to links that result in 500 errors. I found the issue while working with the Cloudera distro which contained a plus ('+') in the path which is interpreted as a space character (%20) by Firefox. Here is the (trimmed) URL. Note the hadoop-0.20.1+152 directory which should be hadoop-0.20.1%2B152. I have created a patch against current ASF svn trunk but it is untested (although the jsp compiles to a class file ok).

A job link from http://host:50030/jobhistory.jsp:
http://host:50030/jobdetailshistory.jsp?jobid=job_201001141235_0001&logFile=file:/Users/esammer/hadoop-0.20.1+152/logs/history/done/..."
MAPREDUCE-1376,Support for varied user submission in Gridmix,Gridmix currently submits all synthetic jobs as the client user. It should be possible to map users in the trace to a set of users appropriate for the target cluster.
MAPREDUCE-1375,TestFileArgs fails intermittently,"TestFileArgs failed once for me with the following error
{code}
expected:<[job.jar
sidefile
tmp
]> but was:<[]>
sidefile
tmp
]> but was:<[]>
        at org.apache.hadoop.streaming.TestStreaming.checkOutput(TestStreaming.java:107)
        at org.apache.hadoop.streaming.TestStreaming.testCommandLine(TestStreaming.java:123)
{code}"
MAPREDUCE-1374,Reduce memory footprint of FileSplit,"We can have many FileInput objects in the memory, depending on the number of mappers.

It will save tons of memory on JobTracker and JobClient if we intern those Strings for host names.

{code}
FileInputFormat.java:

      for (NodeInfo host: hostList) {
        // Strip out the port number from the host name
-        retVal[index++] = host.node.getName().split("":"")[0];
+        retVal[index++] = host.node.getName().split("":"")[0].intern();
        if (index == replicationFactor) {
          done = true;
          break;
        }
      }
{code}

More on String.intern(): http://www.javaworld.com/javaworld/javaqa/2003-12/01-qa-1212-intern.html


It will also save a lot of memory by changing the class of {{file}} from {{Path}} to {{String}}. {{Path}} contains a {{java.net.URI}} which internally contains ~10 String fields. This will also be a huge saving.

{code}
  private Path file;
{code}

"
MAPREDUCE-1372,ConcurrentModificationException in JobInProgress,"We have seen the following  ConcurrentModificationException in one of our clusters
{noformat}
java.io.IOException: java.util.ConcurrentModificationException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
        at java.util.HashMap$KeyIterator.next(HashMap.java:828)
        at org.apache.hadoop.mapred.JobInProgress.findNewMapTask(JobInProgress.java:2018)
        at org.apache.hadoop.mapred.JobInProgress.obtainNewMapTask(JobInProgress.java:1077)
        at org.apache.hadoop.mapred.CapacityTaskScheduler$MapSchedulingMgr.obtainNewTask(CapacityTaskScheduler.java:796)
        at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.getTaskFromQueue(CapacityTaskScheduler.java:589)
        at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.assignTasks(CapacityTaskScheduler.java:677)
        at org.apache.hadoop.mapred.CapacityTaskScheduler$TaskSchedulingMgr.access$500(CapacityTaskScheduler.java:348)
        at org.apache.hadoop.mapred.CapacityTaskScheduler.addMapTask(CapacityTaskScheduler.java:1397)
        at org.apache.hadoop.mapred.CapacityTaskScheduler.assignTasks(CapacityTaskScheduler.java:1349)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2976)
        at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
{noformat}
"
MAPREDUCE-1370,TestCombineFileInputFormat.testSplitPlacement fails in trunk,"http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/202/


org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testSplitPlacement (from TestCombineFileInputFormat) 

Failing for the past 1 build (Since #202 ) 
Took 18 sec.
add description

Error Message
port out of range:-1
Stacktrace
java.lang.IllegalArgumentException: port out of range:-1
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:377)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.activate(NameNode.java:317)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:308)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:416)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:410)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1230)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:290)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:153)
	at org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat.testSplitPlacement(TestCombineFileInputFormat.java:95)


raw output format:

[junit] Running org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat
    [junit] 2010-01-11 15:05:29,813 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(166)) - defaultReplication = 1
    [junit] 2010-01-11 15:05:29,816 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(167)) - maxReplication = 512
    [junit] 2010-01-11 15:05:29,817 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(168)) - minReplication = 1
    [junit] 2010-01-11 15:05:29,817 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(169)) - maxReplicationStreams = 2
    [junit] 2010-01-11 15:05:29,818 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(170)) - shouldCheckForEnoughRacks = false
    [junit] 2010-01-11 15:05:29,826 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(389)) - fsOwner=hudson,hudson
    [junit] 2010-01-11 15:05:29,827 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(395)) - supergroup=supergroup
    [junit] 2010-01-11 15:05:29,827 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(396)) - isPermissionEnabled=true
    [junit] 2010-01-11 15:05:29,831 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(434)) - isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
    [junit] 2010-01-11 15:05:29,864 INFO  common.Storage (FSImage.java:saveFSImage(1218)) - Image file of size 96 saved in 0 seconds.
    [junit] 2010-01-11 15:05:29,890 INFO  common.Storage (FSImage.java:format(1289)) - Storage directory /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/data/dfs/name1 has been successfully formatted.
    [junit] 2010-01-11 15:05:29,891 INFO  common.Storage (FSImage.java:saveFSImage(1218)) - Image file of size 96 saved in 0 seconds.
    [junit] 2010-01-11 15:05:29,905 INFO  common.Storage (FSImage.java:format(1289)) - Storage directory /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/data/dfs/name2 has been successfully formatted.
    [junit] 2010-01-11 15:05:29,933 INFO  metrics.RpcMetrics (RpcMetrics.java:<init>(58)) - Initializing RPC Metrics with hostName=NameNode, port=50403
    [junit] 2010-01-11 15:05:29,983 INFO  jvm.JvmMetrics (JvmMetrics.java:init(71)) - Initializing JVM Metrics with processName=NameNode, sessionId=null
    [junit] 2010-01-11 15:05:29,984 INFO  metrics.NameNodeMetrics (NameNodeMetrics.java:<init>(103)) - Initializing NameNodeMeterics using context object:org.apache.hadoop.metrics.spi.NullContext
    [junit] 2010-01-11 15:05:29,985 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(166)) - defaultReplication = 1
    [junit] 2010-01-11 15:05:29,986 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(167)) - maxReplication = 512
    [junit] 2010-01-11 15:05:29,986 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(168)) - minReplication = 1
    [junit] 2010-01-11 15:05:29,987 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(169)) - maxReplicationStreams = 2
    [junit] 2010-01-11 15:05:29,988 INFO  namenode.FSNamesystem (BlockManager.java:setConfigurationParameters(170)) - shouldCheckForEnoughRacks = false
    [junit] 2010-01-11 15:05:29,994 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(389)) - fsOwner=hudson,hudson
    [junit] 2010-01-11 15:05:29,994 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(395)) - supergroup=supergroup
    [junit] 2010-01-11 15:05:29,995 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(396)) - isPermissionEnabled=true
    [junit] 2010-01-11 15:05:29,996 INFO  namenode.FSNamesystem (FSNamesystem.java:setConfigurationParameters(434)) - isAccessTokenEnabled=false accessKeyUpdateInterval=0 min(s), accessTokenLifetime=0 min(s)
    [junit] 2010-01-11 15:05:29,999 INFO  metrics.FSNamesystemMetrics (FSNamesystemMetrics.java:<init>(78)) - Initializing FSNamesystemMetrics using context object:org.apache.hadoop.metrics.spi.NullContext
    [junit] 2010-01-11 15:05:30,001 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(3986)) - Registered FSNamesystemStatusMBean
    [junit] 2010-01-11 15:05:30,007 INFO  common.Storage (FSImage.java:loadFSImage(1050)) - Number of files = 1
    [junit] 2010-01-11 15:05:30,008 INFO  common.Storage (FSImage.java:loadFilesUnderConstruction(1393)) - Number of files under construction = 0
    [junit] 2010-01-11 15:05:30,009 INFO  common.Storage (FSImage.java:loadFSImage(987)) - Image file of size 96 loaded in 0 seconds.
    [junit] 2010-01-11 15:05:30,010 INFO  common.Storage (FSEditLog.java:loadFSEdits(374)) - Edits file /grid/0/hudson/hudson-slave/workspace/Hadoop-Mapreduce-trunk/trunk/build/test/data/dfs/name1/current/edits of size 4 edits # 0 loaded in 0 seconds.
    [junit] 2010-01-11 15:05:30,013 INFO  namenode.FSNamesystem (FSNamesystem.java:initialize(265)) - Finished loading FSImage in 28 msecs
    [junit] 2010-01-11 15:05:30,016 INFO  util.HostsFileReader (HostsFileReader.java:refresh(81)) - Refreshing hosts (include/exclude) list
    [junit] 2010-01-11 15:05:30,017 INFO  namenode.FSNamesystem (FSNamesystem.java:getCompleteBlocksTotal(3744)) - Number of blocks under construction: 0
    [junit] 2010-01-11 15:05:30,017 INFO  namenode.FSNamesystem (BlockManager.java:processMisReplicatedBlocks(1233)) - Total number of blocks = 0
    [junit] 2010-01-11 15:05:30,018 INFO  namenode.FSNamesystem (BlockManager.java:processMisReplicatedBlocks(1234)) - Number of invalid blocks = 0
    [junit] 2010-01-11 15:05:30,018 INFO  namenode.FSNamesystem (BlockManager.java:processMisReplicatedBlocks(1235)) - Number of under-replicated blocks = 0
    [junit] 2010-01-11 15:05:30,019 INFO  namenode.FSNamesystem (BlockManager.java:processMisReplicatedBlocks(1236)) - Number of  over-replicated blocks = 0
    [junit] 2010-01-11 15:05:30,019 INFO  hdfs.StateChange (FSNamesystem.java:leave(3438)) - STATE* Leaving safe mode after 0 secs.
    [junit] 2010-01-11 15:05:30,020 INFO  hdfs.StateChange (FSNamesystem.java:leave(3447)) - STATE* Network topology has 0 racks and 0 datanodes
    [junit] 2010-01-11 15:05:30,021 INFO  hdfs.StateChange (FSNamesystem.java:leave(3450)) - STATE* UnderReplicatedBlocks has 0 blocks
    [junit] SLF4J: Class path contains multiple SLF4J bindings.
    [junit] SLF4J: Found binding in [jar:file:/homes/hudson/.ivy2/cache/org.slf4j/slf4j-simple/jars/slf4j-simple-1.5.8.jar!/org/slf4j/impl/StaticLoggerBinder.class]
    [junit] SLF4J: Found binding in [jar:file:/homes/hudson/.ivy2/cache/org.slf4j/slf4j-log4j12/jars/slf4j-log4j12-1.4.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
    [junit] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
    [junit] 1 [main] INFO org.mortbay.log - Logging to org.slf4j.impl.SimpleLogger(org.mortbay.log) via org.mortbay.log.Slf4jLog
    [junit] 2010-01-11 15:05:30,190 INFO  http.HttpServer (HttpServer.java:addGlobalFilter(302)) - Added global filtersafety (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
    [junit] 2010-01-11 15:05:30,199 INFO  http.HttpServer (HttpServer.java:start(442)) - Port returned by webServer.getConnectors()[0].getLocalPort() before open() is -1. Opening the listener on 0
    [junit] 2010-01-11 15:05:30,200 INFO  http.HttpServer (HttpServer.java:start(447)) - listener.getLocalPort() returned 57237 webServer.getConnectors()[0].getLocalPort() returned 57237
    [junit] 2010-01-11 15:05:30,200 INFO  http.HttpServer (HttpServer.java:start(480)) - Jetty bound to port 57237
    [junit] 77 [main] INFO org.mortbay.log - jetty-6.1.14
    [junit] 17760 [main] INFO org.mortbay.log - Started SelectChannelConnector@localhost:57237
    [junit] Tests run: 1, Failures: 0, Errors: 1, Time elapsed: 18.611 sec
    [junit] Test org.apache.hadoop.mapreduce.lib.input.TestCombineFileInputFormat FAILED
"
MAPREDUCE-1369,JUnit tests should never depend on anything in conf,The recent change to mapred-queues.xml that causes many mapreduce tests to break unless you delete conf/mapred-queues.xml out of your build tree is bad. We need to make sure that nothing in conf is used in the unit tests. One potential solution is to copy the templates into build/test/conf and use that instead.
MAPREDUCE-1368,Vertica adapter doesn't use explicity transactions or report progress,"The vertica adapter doesn't use explicit transactions, so speculative tasks can result in duplicate loads.  The JDBC driver supports it so the fix is pretty minor. Also the JDBC driver commits synchronously and the adapter needs to report progress even if it takes longer than the timeout."
MAPREDUCE-1367,LocalJobRunner should support parallel mapper execution,"The LocalJobRunner currently supports only a single execution thread. Given the prevalence of multi-core CPUs, it makes sense to allow users to run multiple tasks in parallel for improved performance on small (local-only) jobs."
MAPREDUCE-1366,Tests should not timeout if TaskTracker/JobTracker crashes in MiniMRCluster,"Currently tests timeout if there is any problem bringing up JobTracker or TaskTracker in MiniMRCluster. Instead tests should fail saying JT/TT crashed.
See test timeout on MAPREDUCE-1365"
MAPREDUCE-1365,TestTaskTrackerBlacklisting.AtestTrackerBlacklistingForJobFailures is mistyped.,The name of TestTaskTrackerBlacklisting.testTrackerBlacklistingForJobFailures got changed to TestTaskTrackerBlacklisting.AtestTrackerBlacklistingForJobFailures unintentionally in MAPREDUCE-686.
MAPREDUCE-1364,Hudson build of mapreduce - 0.21.0 to be green ,"Make hudson build of mapreduce-0.21.0 green. 
http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-21-Build/ 

The last successful one was on Dec 11 , and the latest one seems to fail with some classpath issue on hadoop-core ( complains about missing o.a.h.Configuration etc. ). 

Having the build to be green would be useful to understand the sanity of the latest snapshot of branch-0.21 and understand the release schedule for the same. 

Thanks for helping. "
MAPREDUCE-1361,"In the pools with minimum slots, new job will always receive slots even if the minimum slots limit has been fulfilled","In 0.20, the fair scheduler compares all the jobs based on their running tasks, minimum slots and deficit. If the number of running tasks is less than the number of minimum slots, it will be scheduled first.

Consider a pool with minimum slot of 1000 but already have 5000 running tasks.
If we launch another job on this pool, this new job will receive minimum slots based on its weight. This new job may have higher weight if NewJobWeightBooster is used.
So this new job will still get extra slots even if the pool's running tasks are way more than the minimum slots.

The latest version does not have this problem because it first compares pool then compares jobs in the pool."
MAPREDUCE-1359,TypedBytes TestIO doesn't mkdir its test dir first,TestIO fails when run alone since it doesn't mkdir its test directory in the setUp function. This JIRA should fix it and update the tests to use junit 4 style.
MAPREDUCE-1358,Utils.OutputLogFilter incorrectly filters for _logs,"OutputLogFilter checks if the path contains _logs. This would incorrectly filter out all contents of a directory called server_logs, for example. Instead it should check for a path component exactly equal to _logs"
MAPREDUCE-1357,contrib/index - As part of the hudson build ,"As of now - it seems like contrib/index test cases do not come under the hudson build (contrib/index not being actively maintained ? ) test suite. 

Given that it is in the tree - might be useful to bring that in the first place. 

At its current state - most probably it might fail and may need to apply - MAPREDUCE-1328 and MAPREDUCE-1334 . 

But as the first step - we may need to bring in contrib/index ( If it is dormant - try to understand a bit of background ). 
"
MAPREDUCE-1356,Allow user-specified hive table name in sqoop,The table name used in a hive-destination import is currently pegged to the input table name. This should be user-configurable.
MAPREDUCE-1355,"contrib/index - fails to build with error  - "" Overriding index.ivy.settings' is not allowed when using override='notallowed' "" ","Checked out the trunk of mapreduce - tried to build contrib/index 

$ cd contrib/index

$ ant clean compile test 

Failed with the error - 
mapreduce/src/contrib/build-contrib.xml:311: Overriding a previous definition of ivy:settings with the id 'index.ivy.settings' is not allowed when using override='notallowed' , (when in fact the override has been specified to be 'false' ). 

Bumping the ivy.version to 2.1.0 seems to be fix the issue.  Marking this as critical since it is not possible to build in the first place. 

"
MAPREDUCE-1354,Incremental enhancements to the JobTracker for better scalability,It'd be nice to have the JobTracker object not be locked while accessing the HDFS for reading the jobconf file and while writing the jobinfo file in the submitJob method. We should see if we can avoid taking the lock altogether.
MAPREDUCE-1352,0.21.0 - snapshot incorrect dependency published in .pom files ,"The snapshot available here at -
https://repository.apache.org/content/repositories/snapshots/org/apache/hadoop/hadoop-mapred/0.21.0-SNAPSHOT/ , has an incorrect dependency specified for hadoop-core ( in the .pom file ). 

The source code ( in branch-0.21 )  refers to hadoop-core-0.21 in ivy/libaries.properties but pom.xml published in the repository refers to 0.22 . Please fix the same by republishing a .pom again. 


"
MAPREDUCE-1350,Streaming should allow TextInputFormat keys to be passed through,"Streaming's PipeMapper automatically ignores the key (LongWritable file offset) coming from TextInputFormat. This is usually what the user wants, but occasionally the file offsets are useful - for example, after grepping a large file for a particular pattern, you may want to look at the offset in the file where the pattern matched. There should be a boolean configuration variable which overrides ignoreKey in PipeMapper.java:86"
MAPREDUCE-1349,Create jira component - contrib/index ,Can we have a component - contrib/index for issues related to contrib/index  (in jira ) 
MAPREDUCE-1348,Package org.apache.hadoop.blockforensics does not match directory name,"BlockSearch is in the package org.apache.hadoop.blockforensics, but in the source directory org/apache/hadoop/block_forensics. While javac doesn't seem to mind about this mismatch, Eclipse treats it as an error."
MAPREDUCE-1345,JobTracker is slowed down because it forks subprocesses to do a df command,The JobTracker periodically does a df on the local directories. It forks a shell a shell to run a df command. The creation of the separate process is very slow because the process address space is copied by the OS on every subprocess creation. This becomes worse when the JT is configured to use a large heap space. 
MAPREDUCE-1342,Potential JT deadlock in faulty TT tracking,"JT$FaultyTrackersInfo.incrementFaults first locks potentiallyFaultyTrackers, and then calls blackListTracker, which calls removeHostCapacity, which locks JT.taskTrackers
On the other hand, JT.blacklistedTaskTrackers() locks taskTrackers, then calls faultyTrackers.isBlacklisted() which goes on to lock potentiallyFaultyTrackers.

I haven't produced such a deadlock, but the lock ordering here is inverted and therefore could deadlock.

Not sure if this goes back to 0.21 or just in trunk."
MAPREDUCE-1341,Sqoop should have an option to create hive tables and skip the table import step,"In case the client only needs to create tables in hive, it would be helpful if Sqoop had an optional parameter:

--hive-create-only

which would omit the time consuming table import step, generate hive create table statements and run them.

If this feature seems useful, I can generate the patch. I have modified the Sqoop code and built it on my development machine, and it seems to be working well."
MAPREDUCE-1340,Sqoop should close database connection in case of accidental interruption of command execution,"If a sqoop command is running and suddenly interrupted or killed, all database connections should be automatically closed.

Currently the code catches java.lang.InterruptedException, but it doesn't release and close the database connections in the catch block.

In case this issue is found to be a problem, I suppose it may require some code refactoring in the following classes:

org.apache.hadoop.sqoop.mapred.ImportJob
org.apache.hadoop.sqoop.manager.SqlManager (and all its subclasses)
org.apache.hadoop.sqoop.mapreduce.DataDrivenImportJob

"
MAPREDUCE-1339,Sqoop full table import job times out when using the split-by attribute,"Problem
------------
When running sqoop command for full table import with split-by attribute specified, as follows:

sqoop --connect CONNECT_STRING --username USER_NAME --password PASSWORD --table TABLE_NAME --fields-terminated-by \\0x01 --as-textfile  --warehouse-dir OUTPUT_DIR split-by RECORD_ID

Sqoop is going to transform the split-by attribute to ORDER BY clause and run the following query in SQL (say, Oracle):

SELECT * FROM TABLE_NAME ORDER BY RECORD_ID

If the table has, for example, 20 million records, the ORDER BY part will increase the query running significantly, eventually causing time out, and resulting in no output written to Hadoop file system.

Proposed solution
-------------------------
Not to append the ORDER_BY clause to SQL query if no where clause is specified.

Can there be any issues with this solution?"
MAPREDUCE-1338,need security keys storage solution,"set, get, store, load security keys

key alias - byte[]
key value - byte[]

store/load from DataInput/Output stream
"
MAPREDUCE-1337,Generify StreamJob for better readability,Generify some of the members of StreamJob for better readability. 
MAPREDUCE-1335,Add SASL DIGEST-MD5 authentication to TaskUmbilicalProtocol,Use job token as the credential for Task to local TaskTracker authentication over RPC.  
MAPREDUCE-1334,contrib/index - test - TestIndexUpdater fails due to an additional presence of file _SUCCESS in hdfs ,"$ cd src/contrib/index
$ ant clean test 

This fails the test TestIndexUpdater due to a mismatch in the - doneFileNames - data structure, when it is being run with different parameters. 

(ArrayIndexOutOfBoundsException raised when inserting elements in doneFileNames, array ). 

Debugging further - there seems to be an additional file called as - hdfs://localhost:36021/myoutput/_SUCCESS , taken into consideration in addition to those that begins with done* .  The presence of the extra file causes the error. 

Attaching a patch that would circumvent this by increasing the array length of shards by 1 . 

But longer term the test fixtures need to be probably revisited to see if the presence of _SUCCESS as a file is a good thing to begin with before we even get to this test case. 

Any comments / suggestions on the same welcome. 

"
MAPREDUCE-1333,Parallel running tasks on one single node may slow down the performance,"When I analysis running tasks performance, I found that parallel running tasks on one single node will not be better performance than the serialized ones.
We can set mapred.tasktracker.{map|reduce}.tasks.maximum = 1 individually, but there will be parallel map AND reduce tasks.

And I wonder it's true in the real commercial clusters?"
MAPREDUCE-1332,Ant tasks for job submission,"Ant tasks to make it easy to work with hadoop filesystem and submit jobs. 

<submit> : uploads JAR, submits job as user, with various settings

filesystem operations: mkdir, copyin, copyout, delete
 -We could maybe use Ant1.7 ""resources"" here, and so use hdfs as a source or dest in Ant's own tasks

# security. Need to specify user; pick up user.name from JVM as default?
# cluster binding: namenode/job tracker (hostname,port) or url are all that is needed?
#job conf: how to configure the job that is submitted? support a list of <property name=""name"" value=""something""> children
# testing. AntUnit to generate <junitreport> compatible XML files
# Documentation. With an example using Ivy to fetch the JARs for the tasks and hadoop client.
# Polling: ant task to block for a job finished? "
MAPREDUCE-1331,TestMiniMRWithDFS.testWithDFSWithDefaultPort inadvertently mistyped,"One of the patches, possibly MAPREDUCE-181, inadvertently mistyped TestMiniMRWithDFS.testWithDFSWithDefaultPort to tesWithDFSWithDefaultPort. As a result it wouldn't run as a JUnit test."
MAPREDUCE-1328,contrib/index  - modify build / ivy files as appropriate ,"The build / ivy.xml files in its current state does not seem to launch successfully due to missing dependencies. 

Added dependency on : hadoop-core-test / hadoop-hdfs-test . 

Also the junit classpath is set to include the files retrieved by ivy , specific to the index project. "
MAPREDUCE-1327,Oracle database import via sqoop fails when a table contains the column types such as TIMESTAMP(6) WITH LOCAL TIME ZONE and TIMESTAMP(6) WITH TIME ZONE,"When Oracle table contains the columns ""TIMESTAMP(6) WITH LOCAL TIME ZONE"" and ""TIMESTAMP(6) WITH TIME ZONE"", Sqoop fails to map values for those columns to valid Java data types, resulting in the following exception:

ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.NullPointerException
java.lang.NullPointerException
        at org.apache.hadoop.sqoop.orm.ClassWriter.generateFields(ClassWriter.java:253)
        at org.apache.hadoop.sqoop.orm.ClassWriter.generateClassForColumns(ClassWriter.java:701)
        at org.apache.hadoop.sqoop.orm.ClassWriter.generate(ClassWriter.java:597)
        at org.apache.hadoop.sqoop.Sqoop.generateORM(Sqoop.java:75)
        at org.apache.hadoop.sqoop.Sqoop.importTable(Sqoop.java:87)
        at org.apache.hadoop.sqoop.Sqoop.run(Sqoop.java:175)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.sqoop.Sqoop.main(Sqoop.java:201)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)


I have modified the code for Hadoop and Sqoop so this bug is fixed on my machine. Please let me know if you would like me to generate the patch and upload it to this ticket."
MAPREDUCE-1326,fi tests don't use fi-site.xml ,When fault injection framework was ported to the Mapreduce fi-site.xml is missed from the testing process. E.g. when the tests run they won't use FI configuration.
MAPREDUCE-1325,Fix IsolationRunner to run with reduces too,"HADOOP-4041 fixed various problems with IsolationRunner, but to keep the patch simple it completely broke it for reduces and postponed the effort for another issue. We should fix IsolationRunner to work with reduces here."
MAPREDUCE-1322,TestStreamingAsDifferentUser fails on trunk,"TestStreamingAsDifferentUser fails on trunk with following exception :

Can not create a Path from a null string
java.lang.IllegalArgumentException: Can not create a Path from a null string
	at org.apache.hadoop.fs.Path.checkPathArg(Path.java:78)
	at org.apache.hadoop.fs.Path.<init>(Path.java:90)
	at org.apache.hadoop.mapred.ClusterWithLinuxTaskController.createHomeAndStagingDirectory(ClusterWithLinuxTaskController.java:158)
	at org.apache.hadoop.mapred.ClusterWithLinuxTaskController.startCluster(ClusterWithLinuxTaskController.java:147)
	at org.apache.hadoop.streaming.TestStreamingAsDifferentUser.testStreaming(TestStreamingAsDifferentUser.java:49)

The corresponding line for the exception :
{code}
    Path stagingArea = new Path(conf.get(JTConfig.JT_STAGING_AREA_ROOT));
{code}

"
MAPREDUCE-1321,Spurios logs with org.apache.hadoop.util.DiskChecker$DiskErrorException in TaskTracker,TaskTracker logs have spurious org.apache.hadoop.util.DiskChecker$DiskErrorException. These logs are for job setup/cleanup tasks and for map tasks of jobs with no reduces. 
MAPREDUCE-1317,Reducing memory consumption of rumen objects,We have encountered OutOfMemoryErrors in mumak and gridmix when dealing with very large jobs. The purpose of this jira is to optimze memory consumption of rumen produced job objects.
MAPREDUCE-1316,JobTracker holds stale references to retired jobs via unreported tasks ,JobTracker fails to remove _unreported_ tasks' mapping from _taskToTIPMap_ if the job finishes and retires. _Unreported tasks_ refers to tasks that were scheduled but the tasktracker did not report back with the task status. In such cases a stale reference is held to TaskInProgress (and thus JobInProgress) long after the job is gone leading to memory leak.
MAPREDUCE-1315,taskdetails.jsp and jobfailures.jsp should have consistent convention for machine names in case of lost task tracker,"Machine names displayed in taskdetails.jsp and jobfailures,jsp show inconsistency in convention in case of lost TT i.e in case of lost TT the machine name is displayed as ""tracker_<hostname>:localhost/127.0.0.1:<port>"" (not a hyperlink) whereas for other TTs the name displayed is <hostname> (hyperlink). Ideally the machine names should follow a single convention."
MAPREDUCE-1314,Some logs have wrong configuration names.,"After MAPREDUCE-849, some of the logs have wrong configuration names.
For example :
09/12/16 20:30:58 INFO mapred.MapTask: mapreduce.task.mapreduce.task.io.sort.mb = 10"
MAPREDUCE-1313,NPE in FieldFormatter if escape character is set and field is null,Performing an import with the {{\-\-escaped-by}} character set on a table with a null field will cause a NullPointerException in FieldFormatter
MAPREDUCE-1312,TestStreamingKeyValue fails on hudson patch builds,"TestStreamingKeyValue fails on hudson patch builds with FileNotFoundException.
The failure log from one of the builds is @ 
http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h3.grid.sp2.yahoo.net/203/testReport/org.apache.hadoop.streaming/TestStreamingKeyValue/testCommandLine/"
MAPREDUCE-1311,TestStreamingExitStatus fails on hudson patch builds,"TestStreamingExitStatus fails on hudson patch builds. The logs have the following error :
{noformat}
09/12/16 20:30:58 INFO fs.FSInputChecker: Found checksum error: b[0, 6]=68656c6c6f0a
org.apache.hadoop.fs.ChecksumException: Checksum error: file:/grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/build/contrib/streaming/test/data/input.txt at 0
	at org.apache.hadoop.fs.FSInputChecker.verifySum(FSInputChecker.java:278)
	at org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:242)
	at org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:190)
	at org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:158)
	at java.io.DataInputStream.read(DataInputStream.java:83)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:134)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:180)
	at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:45)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.moveToNext(MapTask.java:206)
	at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:191)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
	at org.apache.hadoop.streaming.PipeMapRunner.run(PipeMapRunner.java:36)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:376)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:325)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:257)
09/12/16 20:30:58 INFO streaming.PipeMapRed: MRErrorThread done
{noformat}

The same passes on my local machine."
MAPREDUCE-1310,CREATE TABLE statements for Hive do not correctly specify delimiters,Imports to HDFS via Sqoop that also inject metadata into Hive do not correctly specify delimiters; using Hive to access the data results in rows being parsed as NULL characters. See http://getsatisfaction.com/cloudera/topics/sqoop_hive_import_giving_null_query_values for an example bug report
MAPREDUCE-1309,"I want to change the rumen job trace generator to use a more modular internal structure, to allow for more input log formats ","There are two orthogonal questions to answer when processing a job tracker log: how will the logs and the xml configuration files be packaged, and in which release of hadoop map/reduce were the logs generated?  The existing rumen only has a couple of answers to this question.  The new engine will handle three answers to the version question: 0.18, 0.20 and current, and two answers to the packaging question: separate files with names derived from the job ID, and concatenated files with a header between sections [used for easier file interchange]."
MAPREDUCE-1308,reduce tasks stall and are eventually killed,"We recently migrated our 0.19.2 cluster from Gentoo Linux to Fedora Linux.  Everything was running smoothly before, but now about 5%-10% of our jobs have at least one reduce task that stalls out and is eventually killed with the message:

      Task attempt_200912102211_1648_r_000009_0 failed to report status for 6003 seconds. Killing!

The task is then re-launched and completes successfully, usually in a couple of minutes.

This is problematic because our scheduled Hadoop jobs now take an extra hour-and-a-half to run (6000 seconds).

There are no indications in the logs that anything is amiss.  The task starts, a small amount of the copy/shuffle runs, and then nothing is else is heard from the task until it is killed.  I will attach the relevant parts of the TaskTracker logs in the comments.
"
MAPREDUCE-1307,Introduce the concept of Job Permissions,"It would be good to define the notion of job permissions analogous to file permissions. Then the JobTracker can restrict who can ""read"" (e.g. look at the job page) or ""modify"" (e.g. kill) jobs."
MAPREDUCE-1306,[MUMAK] Randomize the arrival of heartbeat responses,"We propose to make the following changes to mumak, MAPREDUCE-728
- make the timing of heartbeat responses more realistic by adding an option to randomly perturb them
- randomize the startup time of task trackers in a fixed interval 
- remove 2 magic constants from SimulatorEngine and make sure that the first job is submitted only after the entire cluster is up and running
"
MAPREDUCE-1305,Running distcp with -delete incurs avoidable penalties,"*First problem*

In org.apache.hadoop.tools.DistCp#deleteNonexisting we serialize FileStatus objects when the path is all we need.

The performance problem comes from org.apache.hadoop.fs.RawLocalFileSystem.RawLocalFileStatus#write which tries to retrieve file permissions by issuing a ""ls -ld <path>"" which is painfully slow.

Changed that to just serialize Path and not FileStatus.

*Second problem*

To delete the files we invoke the ""hadoop"" command line tool with option ""-rmr <path>"". Again, for each file.

Changed that to dstfs.delete(path, true)"
MAPREDUCE-1304,Add counters for task time spent in GC,"It's easy to grab the number of millis spent in GC (see JvmMetrics for example). Exposing these as task counters would be handy - occasionally I've seen user jobs where long GC pauses cause big ""unexplainable"" performance problems, and a large counter would make it obvious to the user what's going on."
MAPREDUCE-1302,TrackerDistributedCacheManager can delete file asynchronously,"With the help of AsyncDiskService from MAPREDUCE-1213, we should be able to delete files from distributed cache asynchronously.

That will help make task initialization faster, because task initialization calls the code that localizes files into the cache and may delete some other files.
The deletion can slow down the task initialization speed.
"
MAPREDUCE-1301,TestDebugScriptWithLinuxTaskController fails ,"After MAPREDUCE:879,  TestDebugScriptWithLinuxTaskController fails with following exception :

java.lang.NullPointerException
	at org.apache.hadoop.mapred.TestTaskTrackerLocalization.getFilePermissionAttrs(TestTaskTrackerLocalization.java:274)
	at org.apache.hadoop.mapred.TestTaskTrackerLocalization.checkFilePermissions(TestTaskTrackerLocalization.java:294)
	at org.apache.hadoop.mapred.TestDebugScript.verifyDebugScriptOutput(TestDebugScript.java:162)
	at org.apache.hadoop.mapred.TestDebugScriptWithLinuxTaskController.testDebugScriptExecutionAsDifferentUser(TestDebugScriptWithLinuxTaskController.java:50)
"
MAPREDUCE-1299,Hudson uses an old version of eclipse to test patches,"As diagnosed [here|https://issues.apache.org/jira/browse/MAPREDUCE-1262?focusedCommentId=12787032&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12787032], Hudson may be using an old version of eclipse."
MAPREDUCE-1298,better access/organization of userlogs,"Right now, it is quite a chore to browse to all userlogs generated during a given map or reduce phase.

It is quite easy to browse to a job and look at either the map or reduce tasks, like so:
/jobtasks.jsp?jobid=job_<myid>&type=map&pagenum=1
/jobtasks.jsp?jobid=job_<myid>&type=reduce&pagenum=1

However, it is not easy to look at the stderr output across all the attempts. Currently, the best technique I know of is to browse into each task:
/taskdetails.jsp?jobid=job_<myid>&tipid=task_<taskid>

And from there, jump to the slave node's task log for that taskid:
slavenode/tasklog?taskid=attempt_<for the taskid>&all=true

I'm not suggesting that there needs to be really sophisticated way to present all the task userlogs in one place, especially with the expected size of the logs. However, it would be nice to be presented with a list of URLs (that are clickable) to all the log files. From here, it would be easy to copy/paste that elsewhere, where I could wget the set of log files and grep through them. What has prevented me from scripting it is a foolproof way to branch down from a job id to all the constituent task ids and logs.

One more thing -- the task detail page:
/taskdetails.jsp?jobid=job_<myid>&tipid=task_<taskid>
gives links to see 4kb, 8kb, and all logs. I think it'd be nice to be able to get a link to just the stdout, stderr, and syslog portions. Most of our debugging is done by examining all of the stderr logs. Maybe it's possible to request that via URL? But I haven't found out how to in documentation."
MAPREDUCE-1296,"Tasks fail after the first disk (/grid/0/) of all TTs reaches 100%, even though other disks still have space.","Tasks fail after the first disk (/grid/0/) of all TTs reaches 100%, even though other disks still have space.

In a cluster, data is distributed almost uniformly.  Disk /grid/0/ reaches 100% first, because of extra filling up of info like logs etc. After it reaches 100% tasks starts to fail with the error, 

java.lang.Throwable: Child Error
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:516)
Caused by: java.io.IOException: Task process exit with nonzero status of 1.
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:503)


This happens even though the other disks are still at 80%, so still can be filled up more.

Steps to reproduce:

1) Bring up  a cluster with Linux task controller.
2) Start filling the dfs up with data using randomwriter or teragen.
3) Once the first disk reaches 100%, the tasks are starting to fail.
"
MAPREDUCE-1295,We need a job trace manipulator to build gridmix runs.,"Rumen produces ""job traces"", which are JSON format files describing important aspects of all jobs that are run [successfully or not] on a hadoop map/reduce cluster.  There are two packages under development that will consume these trace files and produce actions in that cluster or another cluster: gridmix3 [see jira MAPREDUCE-1124 ] and Mumak [a simulator -- see MAPREDUCE-728 ].

It would be useful to be able to do two things with job traces, so we can run experiments using these two tools: change the duration, and change the density.  I would like to provide a ""folder"", a tool that can wrap a long-duration execution trace to redistribute its jobs over a shorter interval, and also change the density by duplicating or culling away jobs from the folded combined job trace."
MAPREDUCE-1294,Build fails to pull latest hadoop-core-* artifacts,This is the same as HDFS-825 for mapreduce.
MAPREDUCE-1293,AutoInputFormat doesn't work with non-default FileSystems,"AutoInputFormat uses the wrong FileSystem.get() method when getting a reference to a FileSystem object. AutoInputFormat gets the default FileSystem, so this method breaks if the InputSplit's path is pointing to a different FileSystem. "
MAPREDUCE-1292,many testcases are failing in trunk with org.apache.hadoop.ipc.RPC.waitForProxy error.,
MAPREDUCE-1291,JobTracker holds stale references to retired jobs via setup tasks,"JobTracker fails to remove setup tip mapping from taskidToTIPMap if the job gets killed before the setup returns.

Here is the scenario :
1) job inits
2) setup task is launched on tt1 and an entry is made in taskidToTIPMap
3) job is killed
4) cleanup gets launched on tt2
5) cleanup returns KILLING the job and removing all the *completed* setup/map/reduce task mappings from taskidToTIPMap. Here the setup is still RUNNING state.
6) job completes and all the map/reduce mappings from taskidToTIPMap are removed
 
In the end the setup tip still lingers in the taskidToTIPMap map. Because of the backreference from the tip to jip, the whole job stays in memory forever."
MAPREDUCE-1290,DBOutputFormat does not support rewriteBatchedStatements when using MySQL jdbc drivers,"The DBOutputFormat adds a semi-colon to the end of the INSERT statement that it uses to save fields to the database.  Semicolons are typically used in command line programs but are not needed when using the JDBC API.  In this case, the stray semi-colon breaks rewriteBatchedStatement support. See: http://forums.mysql.com/read.php?39,271526,271526#msg-271526 for an example.

In my use case, rewriteBatchedStatement is very useful because it increases the speed of inserts and reduces memory consumption."
MAPREDUCE-1289,TestTrackerDistributedCacheManagerWithLinuxTaskController fails,TestTrackerDistributedCacheManagerWithLinuxTaskController fails with INITIALIZE_DISTRIBUTED_CACHE failing in trunk.
MAPREDUCE-1288,DistributedCache localizes only once per cache URI,"As part of the file localization the distributed cache localizer creates a copy of the file in the corresponding user's private directory. The localization in DistributedCache assumes the key as the URI of the cachefile and if it already exists in the map, the localization is not done again. This means that another user cannot access the same distributed cache file. We should change the key to include the username so that localization is done for every user."
MAPREDUCE-1287,Avoid calling Partitioner with only 1 reducer,"Partitioners are currently called for each record, even though all are destined for the same reduce."
MAPREDUCE-1285,DistCp cannot handle -delete if destination is local filesystem,"The following exception is thrown:
{code}
Copy failed: java.io.IOException: wrong value class: org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus is not class org.apache.hadoop.fs.FileStatus
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:988)
	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:977)
	at org.apache.hadoop.tools.DistCp.deleteNonexisting(DistCp.java:1226)
	at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1134)
	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:650)
	at org.apache.hadoop.tools.DistCp.run(DistCp.java:857)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
{code}"
MAPREDUCE-1284,TestLocalizationWithLinuxTaskController fails,"With current trunk, the testcase TestLocalizationWithLinuxTaskController fails with an exit code of 139 from task-controller when doing INITIALIZE_USER"
MAPREDUCE-1283,Support including 3rd party jars supplied in lib/ folder of eclipse project in hadoop jar,"Currently, the eclipse plugin only exports the generated class files to the hadoop jar but if there are any 3rd party jars specified in the lib/ folder, they should also get packaged in the jar for submission to the cluster. Currently this has to be done manually which can slow down development. I am working on a patch to the current plugin to support this."
MAPREDUCE-1282,eclipse plugin cannot be compiled in in windows,"{noformat}
bash-3.2$ ant -Declipse.home=/cygdrive/d/eclipse-java-ganymede-win32/
Buildfile: build.xml
...
BUILD FAILED
d:\@sze\hadoop\latest\src\contrib\build-contrib.xml:112: d:\cygdrive\d\eclipse-java-ganymede-win32\plugins not found.
{noformat}
It seems that build-contrib.xml messed up the path."
MAPREDUCE-1281,Project Split Issue : Eclipse-Plugin under the Common Project in JIRA but the code is under the MapReduce project,"contrib/eclipse-plugin is still listed under the Common Project in JIRA even though the code has been moved to the MapReduce project. As it stands, if one opens a JIRA issue for the eclipse plugin under the common project, one cannot provide a patch and resolve it as the code does not exist in that project."
MAPREDUCE-1280,Eclipse Plugin does not work with Eclipse Ganymede (3.4),"The newest version of Eclipse seems incompatible with the plugin. The plugin as released in 0.16.4 will allow you to add/remove MapReduce servers, and will allow you to browse/manipulate the DFS in the DFS Browser, but will not allow you to run programs. Clicking ""Run As * Run On Hadoop"" will simply not cause the run-on-hadoop server selection window to appear. No error message is given.

Dropping the 0.17.1 copy of the plugin JAR into the eclipse/plugins/ directory does not fix the issue; it is in fact worse: Eclipse does not seem to regard the 0.17 plugin as real. No ""MapReduce Perspective"" is made available in the perspectives selection window."
MAPREDUCE-1276,Shuffle connection logic needs correction ,"While looking at the code with Amareshwari, we realized that  {{Fetcher#copyFromHost}} marks connection as successful when {{url.openConnection}} returns. This is wrong. Connection is done inside implicitly inside {{getInputStream}}; we need to split {{getInputStream}} into {{connect}} and {{getInputStream}} to handle the connection and read time out strategies correctly."
MAPREDUCE-1275,"Several Hudson build tests are failing with NoClassDefFoundError, unrelated to the patches being tested","Over the past few days, several Hudson validation tests for patches have been failing with NoClassDefFoundError. See MAPREDUCE:952, MAPREDUCE:1201.  These failures are definitely unrelated to the patches being tested."
MAPREDUCE-1273,TaskTracker.shutdown() spends lot of time in shutting down jetty,"While testing, I found that the jetty shutdown took ~8mins. This impacts the junit tests."
MAPREDUCE-1270,Hadoop C++ Extention,"  Hadoop C++ extension is an internal project in baidu, We start it for these reasons:
   1  To provide C++ API. We mostly use Streaming before, and we also try to use PIPES, but we do not find PIPES is more efficient than Streaming. So we 

think a new C++ extention is needed for us.
   2  Even using PIPES or Streaming, it is hard to control memory of hadoop map/reduce Child JVM.
   3  It costs so much to read/write/sort TB/PB data by Java. When using PIPES or Streaming, pipe or socket is not efficient to carry so huge data.

   What we want to do: 
   1 We do not use map/reduce Child JVM to do any data processing, which just prepares environment, starts C++ mapper, tells mapper which split it should  deal with, and reads report from mapper until that finished. The mapper will read record, ivoke user defined map, to do partition, write spill, combine and merge into file.out. We think these operations can be done by C++ code.
   2 Reducer is similar to mapper, it was started after sort finished, it read from sorted files, ivoke user difined reduce, and write to user defined record writer.
   3 We also intend to rewrite shuffle and sort with C++, for efficience and memory control.
   at first, 1 and 2, then 3.  

   What's the difference with PIPES:
   1 Yes, We will reuse most PIPES code.
   2 And, We should do it more completely, nothing changed in scheduling and management, but everything in execution.

*UPDATE:*

Now you can get a test version of HCE from this link http://docs.google.com/leaf?id=0B5xhnqH1558YZjcxZmI0NzEtODczMy00NmZiLWFkNjAtZGM1MjZkMmNkNWFk&hl=zh_CN&pli=1
This is a full package with all hadoop source code.
Following document ""HCE InstallMenu.pdf"" in attachment, you will build and deploy it in your cluster.

Attachment ""HCE Tutorial.pdf"" will lead you to write the first HCE program and give other specifications of the interface.

Attachment ""HCE Performance Report.pdf"" gives a performance report of HCE compared to Java MapRed and Pipes.

Any comments are welcomed."
MAPREDUCE-1268,Update streaming tests to JUnit 4 style,Suggested by Chris in MAPREDUCE-1155
MAPREDUCE-1267,Fix typo in mapred-default.xml,There's a typo of mapreduce.client.progerssmonitor.pollinterval instead of mapreduce.client.progressmonitor.pollinterval in mapred-default. Trivial patch to fix.
MAPREDUCE-1266,Allow heartbeat interval smaller than 3 seconds for tiny clusters,"For small clusters, the heartbeat interval has a large effect on job latency. This is especially true on pseudo-distributed or other ""tiny"" (<5 nodes) clusters. It's not a big deal for production, but new users would have a happier first experience if Hadoop seemed snappier.

I'd like to change the minimum heartbeat interval from 3.0 seconds to perhaps 0.5 seconds (but have it governed by an undocumented config parameter in case people don't like this change). The cluster size-based ramp up of interval will maintain the current scalable behavior for large clusters with no negative effect."
MAPREDUCE-1265,Include tasktracker name in the task attempt error log,"When task attempt receive an error, TaskInProgress will log the task attempt id and diagnosis string in the JobTracker log.
Ex:
2009-xx-xx 23:50:45,994 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_2009xxxx_xxxx_r_000009_1: Error: java.lang.OutOfMemoryError: Java heap space
2009-xx-xx 22:53:53,146 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_2009xxxx_xxxx_m_000478_0: Task attempt_2009xxxx_xxxx_m_000478_0 failed to report status for 601 seconds. Killing!

When we want to debug a machine for example, a node has been blacklisted in the past few days.
We have to use the task attempt id to find the TT. This is not very convenient. 

It will be nice if  we can also log the tasktracker which causes this error.
This way we can just grep the hostname to quickly find all the relevant error message."
MAPREDUCE-1264,"Error Recovery failed, task will continue but run forever as new data only comes in very very slowly","Hi,

Sometimes, some of my jobs (It normally always happens in the reducers and on random basis) will not finish and will run forever. I have to manually fail the task so the task will be started and be finished.

The error log on the node is full of entries like:
java.io.IOException: Error Recovery for block blk_-8036012205502614140_21582139 failed  because recovery from primary datanode 192.168.0.3:50011 failed 6 times.  Pipeline was 192.168.0.3:50011. Aborting...
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2582)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2076)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2239)
java.io.IOException: Error Recovery for block blk_-8036012205502614140_21582139 failed  because recovery from primary datanode 192.168.0.3:50011 failed 6 times.  Pipeline was 192.168.0.3:50011. Aborting...
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2582)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2076)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2239)
java.io.IOException: Error Recovery for block blk_-8036012205502614140_21582139 failed  because recovery from primary datanode 192.168.0.3:50011 failed 6 times.  Pipeline was 192.168.0.3:50011. Aborting...
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.processDatanodeError(DFSClient.java:2582)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$1600(DFSClient.java:2076)
        at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:2239)
The error entries all refer to the same data block.

Unfortunately, the reduce function still seems to be called in the reducer with valid data (although very very slowly), so the task will never been killed and restarted and will take forever to run!

If I kill the task, the job will finish without any problems. 

I experienced the same problem under version 0.20.0 as well.


Thanks,
Thibaut"
MAPREDUCE-1263,Hudson doesn't run MapredTestDriver,"It doesn't look like src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java is being run by Hudson. There are no results for MRReliabilityTest, DFSCIOTest or other tests that live under src/test/mapred/org/apache/hadoop that don't have file names beginning with Test (ie not picked up by junit). Intentional?"
MAPREDUCE-1262,Eclipse Plugin does not build for Hadoop 0.20.1,"When trying to run the build script for the Eclipse Plugin in src/contrib/eclipse-plugin there are several errors a user receives. The first error is that the eclipse.home is not set. This is easily remedied by adding a value for eclipse.home in the build.properties file in the eclipse-plugin directory.

The script then states it cannot compile org.apache.hadoop.eclipse.launch.HadoopApplicationLaunchShortcut because it cannot resolve JavaApplicationLaunchShortcut on line 35:
      import org.eclipse.jdt.internal.debug.ui.launcher.JavaApplicationLaunchShortcut;

and fails

I believe this is because there is no jar in the eclipse.home/plugins that has this class in that package. I did however find it in org.eclipse.jdt.debug.ui.launchConfigurations.JavaApplicationLaunchShortcut which was inside in org.eclipse.jdt.debug.ui_3.4.1.v20090811_r351.jar in the plugins dir of Eclipse 3.5

Changing the import in the class in the source to the latter allows the build to complete successfully. The M/R Perspective opens and works on my SLES 10 Linux environment but not on my Macbook Pro. Both are running Eclipse 3.5.

To users wanting to do the same, I built this inside Eclipse. To do that I added org.eclipse.jdt.debug.ui_3.4.1.v20090811_r351.jar and hadoop-0.20.1-core.jar to the ant runtime configuration classpath. I also had to set the version value=0.20.1 in the build.properties. You will also need to copy hadoop-0.20.1-core.jar to hadoop.home/build and commons-cli-1.2.jar to hadoop.home/build/ivy/lib/Hadoop/common."
MAPREDUCE-1261,Enhance mumak to implement a 'stress-test' for the JobTracker,"I propose we enhance mumak to implement a proper 'stress-test' tool for the JobTracker. The idea is that we enhance mumak to have a mode where it can use the *real* JobTracker (and Scheduler of course) and mumak's SimulatedTaskTracker to run real workloads from production job-history traces. Clearly we will need to make necessary changes to allow the SimulatedTaskTrackers to run independently (a thread per SimulatedTT) in a distributed manner.

We can then simulate very large clusters and workloads using a handful of machines (say ~50 machines to simulate workload which originally ran on a 4000 node cluster), also we can use this to stress the JobTracker with synthetic workloads.

Thoughts?"
MAPREDUCE-1260,Update Eclipse configuration to match changes to Ivy configuration,"The .eclipse_templates/.classpath file doesn't match the Ivy configuration, so I've updated it to match."
MAPREDUCE-1259,Add SureLogic annotations' jar into Ivy and Eclipse configs,"In order to use SureLogic analysis tools and allow their concurrency analysis annotations in HDFS code the annotations library has to be automatically pulled from a Maven repo. Also, it has to be added to Eclipse .classpath template."
MAPREDUCE-1258,Fair scheduler event log not logging job info,"The MAPREDUCE-706 patch seems to have left an unfinished TODO in the Fair Scheduler - namely, in the dump() function for periodically dumping scheduler state to the event log, the part that dumps information about jobs is commented out. This makes the event log less useful than it was before.

It should be fairly easy to update this part to use the new scheduler data structures (Schedulable etc) and print the data."
MAPREDUCE-1257,Ability to grab the number of spills,The counters should have information about the number of spills in addition to the number of spill records.
MAPREDUCE-1256,org.apache.hadoop.mapred.TestFairScheduler.testPoolAssignment (from TestFairScheduler) is failing in trunk,"Trunk build is failing. The unit testcase that fail is:

org.apache.hadoop.mapred.TestFairScheduler.testPoolAssignment (from TestFairScheduler) 

http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/160/testReport/org.apache.hadoop.mapred/TestFairScheduler/testPoolAssignment/

Error Message
Timeout occurred. Please note the time in the report does not reflect the time until the timeout.
Stacktrace
junit.framework.AssertionFailedError: Timeout occurred. Please note the time in the report does not reflect the time until the timeout
"
MAPREDUCE-1255,How to write a custom input format and record reader to read multiple lines of text from files,"Can someone explain how to override the ""FileInputFormat"" and ""RecordReader"" in order to be able to read multiple lines of text from input files in a single map task?

Here the key will be the offset of the first line of text and value will be the N lines of text. 

I have overridden the class FileInputFormat:

public class MultiLineFileInputFormat
	extends FileInputFormat<LongWritable, Text>{
...
}

and implemented the abstract method:

public RecordReader createRecordReader(InputSplit split,
                TaskAttemptContext context)
         throws IOException, InterruptedException {...}

I have also overridden the recordreader class:

public class MultiLineFileRecordReader extends RecordReader<LongWritable, Text>
{...}

and in the job configuration, specified this new InputFormat class:

job.setInputFormatClass(MultiLineFileInputFormat.class);

When I  run this new map/reduce program, i get the following java error:

Exception in thread ""main"" java.lang.RuntimeException: java.lang.NoSuchMethodException: CustomRecordReader$MultiLineFileInputFormat.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:115)
	at org.apache.hadoop.mapred.JobClient.writeNewSplits(JobClient.java:882)
	at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:779)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:432)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:447)
	at CustomRecordReader.main(CustomRecordReader.java:257)
Caused by: java.lang.NoSuchMethodException: CustomRecordReader$MultiLineFileInputFormat.<init>()
	at java.lang.Class.getConstructor0(Class.java:2706)
	at java.lang.Class.getDeclaredConstructor(Class.java:1985)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:109)
	... 5 more
"
MAPREDUCE-1253,Making Mumak work with Capacity-Scheduler,"In order to make the capacity-scheduler work in the mumak simulation environment, we have to replace the job-initialization threads of the capacity scheduler with classes that perform event-based initialization. We propose to use aspectj to disable the threads  of the JobInitializationPoller class used by the Capacity Scheduler, and then perform the corresponding initialization tasks through a simulation job-initialization class that receives periodic wake-up calls from the simulator engine."
MAPREDUCE-1251,c++ utils doesn't compile,c++ utils doesn't compile on ubuntu karmic 64-bit. The latest patch for HADOOP-5611 needs to be applied first.
MAPREDUCE-1250,Refactor job token to use a common token interface,The idea is to use a common token interface for both job token and delegation token (HADOOP-6373) so that the RPC layer that uses them don't have to differentiate them.
MAPREDUCE-1249,"mapreduce.reduce.shuffle.read.timeout's default value should be 3 minutes, in mapred-default.xml","mapreduce.reduce.shuffle.read.timeout has a value of 30,000 (30 seconds) in mapred-default.xml, whereas the default value in Fetcher code is 3 minutes.
It should be 3 minutes by default, as it was in pre MAPREDUCE-353."
MAPREDUCE-1248,Redundant memory copying in StreamKeyValUtil,"I found that when MROutputThread collecting the output of  Reducer, it calls StreamKeyValUtil.splitKeyVal() and two local byte-arrays are allocated there for each line of output. Later these two byte-arrays are passed to variable key and val. There are twice memory copying here, one is the System.arraycopy() method, the other is inside key.set() / val.set().

This causes double times of memory copying for the whole output (may lead to higher CPU consumption), and frequent temporay object allocation."
MAPREDUCE-1247,Send out-of-band heartbeat to avoid fake lost tasktracker,"Currently the TaskTracker report task status to jobtracker through heartbeat, sometimes if the tasktracker  lock the tasktracker to do some cleanup  job, like remove task temp data on disk, the heartbeat thread would hang for a long time while waiting for the lock, so the jobtracker just thought it had lost and would reschedule all its finished maps or un finished reduce on other tasktrackers, we call it ""fake lost tasktracker"", some times it doesn't acceptable especially when we run some large jobs.  So We introduce a out-of-band heartbeat mechanism to send an out-of-band heartbeat in that case."
MAPREDUCE-1245,"TestFairScheduler fails with ""too many open files"" error",This was caused by MAPREDUCE-1103 and was observed after MAPREDUCE-1239.
MAPREDUCE-1244,eclipse-plugin fails with missing dependencies,
MAPREDUCE-1243,ant compile-test in contrib/streaming fails,"Compile fails. It seems that hdfs-test jar file cannot be found.
compile-test:
     [echo] contrib: streaming
    [javac] Compiling 44 source files to /home/schen/asf-mapred2/build/contrib/streaming/test
    [javac] /home/schen/asf-mapred2/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestDumpTypedBytes.java:30: cannot find symbol
    [javac] symbol  : class MiniDFSCluster
    [javac] location: package org.apache.hadoop.hdfs
    [javac] import org.apache.hadoop.hdfs.MiniDFSCluster;
    [javac]                              ^
    [javac] /home/schen/asf-mapred2/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestLoadTypedBytes.java:29: cannot find symbol
    [javac] symbol  : class MiniDFSCluster
    [javac] location: package org.apache.hadoop.hdfs
    [javac] import org.apache.hadoop.hdfs.MiniDFSCluster;
    [javac]                              ^
    [javac] /home/schen/asf-mapred2/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestMultipleArchiveFiles.java:36: cannot find symbol
    [javac] symbol  : class MiniDFSCluster
    [javac] location: package org.apache.hadoop.hdfs
    [javac] import org.apache.hadoop.hdfs.MiniDFSCluster;
"
MAPREDUCE-1242,Chain APIs error misleading,"Hi,
I was using the Chain[Mapper/Reducer] APIs , and in Class Chain line 207 the error thrown : 

""The Mapper output key class does not match the previous Mapper input key class""

Shouldn't this be ""The Mapper *input* key class does not match the previous Mapper *Output* key class"" ? Sort of misleads :) 
"
MAPREDUCE-1241,JobTracker should not crash when mapred-queues.xml does not exist,"Currently, if you bring up the JobTracker on an old configuration directory, it gets a NullPointerException looking for the mapred-queues.xml file. It should just assume a default queue and continue."
MAPREDUCE-1240,refreshQueues does not work correctly when dealing with maximum-capacity,"If we comment out or remove maximum-capacity property or set maximum-capacity=-1 for a queue which has maximum-capacity some value (say 60). After using command -:
mapred mradmin -refreshQueues 

When we check the Queue Scheduling from Web UI or from CLI it still retains old value and schedules tasks according up to old maximum-capacity if there no other job in cluster where the expected behavior maximum-capacity not retained
"
MAPREDUCE-1239,Mapreduce test build is broken after HADOOP-5107,
MAPREDUCE-1238,mapred metrics shows negative count of waiting maps and reduces ,Negative waiting_maps and waiting_reduces count is observed in the mapred metrics
MAPREDUCE-1237,Job with no maps or reduces creates graph with XML parsing error,"For some reason, a job that had zero maps and zero reduces got submitted.  When looking at the details of this job in the jobtracker ui, the map completion graph was an XML error rather than something more meaningful."
MAPREDUCE-1236,added LOG.isdebugenabled for LOG.debug() as noted in MAPREDUCE-1026,"in /MAPREDUCE-1026 we introduces few LOG.debug() not constrained by LOG.isdebugenabed() .
Fixing that."
MAPREDUCE-1235,java.io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP. ,"*Description*: java.io.IOException is thrown when trying to import a table to HDFS using Sqoop. Table has ""0"" value in a field of type datetime. 
*Full Exception*: java.io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP. 
*Original question*: http://getsatisfaction.com/cloudera/topics/cant_import_table?utm_content=reply_link&utm_medium=email&utm_source=reply_notification"
MAPREDUCE-1234,getJobID() returns null on org.apache.hadoop.mapreduce.Job after job was submitted,"After an instance of org.apache.hadoop.mapreduce.Job is submitted via submit() the method getJobID() returns null.

The code of the submit() method should include something like:
setJobID(info.getJobID());

after
info = jobClient.submitJobInternal(conf);










"
MAPREDUCE-1233,Incorrect Waiting maps/reduces in Jobtracker metrics ,"Waiting Maps/Reduces are incorrect in Jobtracker metrics when a job fails. when a map/reduce fails(during job failure), waiting maps/reduce got incremented and doesn't get decremented even after job cleanup."
MAPREDUCE-1231,Distcp is very slow,"Currently distcp does a checksums check in addition to file length check to decide if a remote file has to be copied. If the number of files is high (thousands), this checksum check is proving to be fairly costly leading to a long time before the copy is started."
MAPREDUCE-1230,Vertica streaming adapter doesn't handle nulls in all cases,"Test user reported that Vertica adapter throws an npe when retrieving null values for certain types (binary, numeric both reported).  There is no special case handling when serializing nulls."
MAPREDUCE-1229,[Mumak] Allow customization of job submission policy,"Currently, mumak replay job submission faithfully. To make mumak useful for evaluation purposes, it would be great if we can support other job submission policies such as sequential job submission, or stress job submission."
MAPREDUCE-1228,OutOfMemoryErrors in ReducerTask due to int overflow on >2G RAM tasks,"The ReduceTask RAMManager uses ints for tracking amounts of memory. For tasks with >2G RAM allocated, these can overflow and cause memory usage to become incorrectly tracked and run away."
MAPREDUCE-1227,Allow JobTracker to pause task scheduling,"We want to have an ability to pause task scheduling in JobTracker.

The idea is: make job tracker still accept new jobs, but delay their running and do not schedule any new tasks from the currently running jobs.

It will help for example restarting the DFS cluster without affecting jobs: pause execution, restart the DFS, running tasks will fail, but will not be scheduled until the execution is resumed, so the job does not fail.

In general it should help fix non MR problems (DFS, network, etc.) while not failing running jobs and keep accepting new ones.

What do people think of the general idea?"
MAPREDUCE-1225,TT successfully localizes a task even though the corresponding cache-file has already changed on DFS.,"This happens with the first task of a job being localized on this TT. TT doesn't check if the file on DFS is fresh according to the timestamps set in job-conf during submission. After the first task incorrectly gets localized, all further tasks fail on this TT as expected.

Found this issue while trying to improve test-case for MAPREUCE-913."
MAPREDUCE-1224,"Calling ""SELECT t.* from <table> AS t"" to get meta information is too expensive for big tables","The SqlManager uses the query, ""SELECT t.* from <table> AS t"" to get table spec is too expensive for big tables, and it was called twice to generate column names and types.  For tables that are big enough to be map-reduced, this is too expensive to make sqoop useful."
MAPREDUCE-1223,CompositeInputFormat doesn't consider all tuples when run in a local task tracker,"The CrossJoin class does not emit all tuples representing the cross product of values for a given key. The issue only occurs when using the local task tracker, and not when running the job on a cluster. 

Example
{noformat}
table 1
k1 -> a

table 2
k1 ->c
k1 ->d
{noformat}

The expected output is
{noformat}
table 1 inner join table 2
k1->ac
k1->ad
{noformat}

Instead one gets
{noformat}
table 1 inner join table 2
k1->ac
{noformat}"
MAPREDUCE-1222,[Mumak] We should not include nodes with numeric ips in cluster topology.,"Rumen infers cluster topology by parsing input split locations from job history logs. Due to HDFS-778, a cluster node may appear both as a numeric ip or as a host name in job history logs. We should exclude nodes appeared as numeric ips in cluster toplogy when we run mumak until a solution is found so that numeric ips would never appear in input split locations."
MAPREDUCE-1221,Kill tasks on a node if the free physical memory on that machine falls below a configured threshold,"The TaskTracker currently supports killing tasks if the virtual memory of a task exceeds a set of configured thresholds. I would like to extend this feature to enable killing tasks if the physical memory used by that task exceeds a certain threshold.

On a certain operating system (guess?), if user space processes start using lots of memory, the machine hangs and dies quickly. This means that we would like to prevent map-reduce jobs from triggering this condition. From my understanding, the killing-based-on-virtual-memory-limits (HADOOP-5883) were designed to address this problem. This works well when most map-reduce jobs are Java jobs and have well-defined -Xmx parameters that specify the max virtual memory for each task. On the other hand, if each task forks off mappers/reducers written in other languages (python/php, etc), the total virtual memory usage of the process-subtree varies greatly. In these cases, it is better to use kill-tasks-using-physical-memory-limits."
MAPREDUCE-1220,Implement an in-cluster LocalJobRunner,"Currently very small map-reduce jobs suffer from latency issues due to overheads in Hadoop Map-Reduce such as scheduling, jvm startup etc. We've periodically tried to optimize all parts of framework to achieve lower latencies.

I'd like to turn the problem around a little bit. I propose we allow very small jobs to run as a single task job with multiple maps and reduces i.e. similar to our current implementation of the LocalJobRunner. Thus, under certain conditions (maybe user-set configuration, or if input data is small i.e. less a DFS blocksize) we could launch a special task which will run all maps in a serial manner, followed by the reduces. This would really help small jobs achieve significantly smaller latencies, thanks to lesser scheduling overhead, jvm startup, lack of shuffle over the network etc. 

This would be a huge benefit, especially on large clusters, to small Hive/Pig queries.

Thoughts?"
MAPREDUCE-1219,JobTracker Metrics causes undue load on JobTracker,"JobTrackerMetricsInst.doUpdates updates job-level counters of all running jobs into JobTracker's metrics causing very bad performance and hampers heartbeats. Since Job level metrics are better served by JobHistory, it may be a good idea to remove these from the metrics framework."
MAPREDUCE-1218,Collecting cpu and memory usage for TaskTrackers,"The information can be used for resource aware scheduling.
Note that this is related to MAPREDUCE-220. There the per task resource information is collected.
This one collects the per machine information."
MAPREDUCE-1217,TestMapReduceLocal fails intermittently. Assert message is unclear  ,"TestMapReduceLocal fails occasionally with the following assert message
{{MultiFileWordCount failed}}

Besides of the failure, the message is unclear and requires an extra analysis effort."
MAPREDUCE-1216,MRUnit Should Sort Reduce Input,"MRUnit should sort the input for a reduce task, the same way hadoop does.
This is useful if you have a reduce task that, for instance, removes duplicate key value pairs.

example:
{code:java}
class BadReducer extends Reducer{
public void reduce(...){
 Text last = new Text();
 for(Text text: values){
   if(!text.equals(last)){
     context.write(key, text);
     last.set(text);
    }
  }
 }
}
{code}

{code:java}
ReduceDriver driver = new ReduceDriver()
driver.setInputKey(""foo"");
driver.addInputValue(""bar"");
driver.addInputValue(""bar"");
driver.addInputValue(""foo"");
{code}
produces different results than 
{code:java}
ReduceDriver driver = new ReduceDriver()
driver.setInputKey(""foo"");
driver.addInputValue(""bar"");
driver.addInputValue(""foo"");
driver.addInputValue(""bar"");
{code}"
MAPREDUCE-1215,Counter deprecation warnings in jobtracker log are excessive,"In a recent test, the log message
{noformat}
WARN org.apache.hadoop.mapred.Counters: Group org.apache.hadoop.mapred.Task$Counter is deprecated. \
Use org.apache.hadoop.mapreduce.TaskCounter instead
{noformat}
was nearly a third of a 1.3GB jobtracker log."
MAPREDUCE-1213,TaskTrackers restart is very slow because it deletes distributed cache directory synchronously,"We are seeing that when we restart a tasktracker, it tries to recursively delete all the file in the distributed cache. It invoked FileUtil.fullyDelete() which is very very slow. This means that the TaskTracker cannot join the cluster for an extended period of time (upto 2 hours for us). The problem is acute if the number of files in a distributed cache is a few-thousands."
MAPREDUCE-1212,Mapreduce contrib project ivy dependencies are not included in binary target,"As in HADOOP-6370, only Hadoop's own library dependencies are promoted to ${build.dir}/lib; any libraries required by contribs are not redistributed."
MAPREDUCE-1211,Online aggregation and continuous query support,"The purpose of this post is to propose a modified MapReduce architecture that allows data to be pipelined between operators. This extends the MapReduce programming model beyond batch processing, and can reduce completion times and improve system utilization for batch jobs as well. We have built a modified version of the Hadoop MapReduce framework that supports online aggregation, which allows users to see ""early returns"" from a job as it is being computed. Our Hadoop Online Prototype (HOP) also supports continuous queries, which enable MapReduce programs to be written for applications such as event monitoring and stream processing. HOP retains the fault tolerance properties of Hadoop, and can run unmodified user-defined MapReduce programs.

For more information on the HOP design, please see our technical report.
http://www.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-136.html

Further details are discussed in the following blog posts.
http://databeta.wordpress.com/2009/10/18/mapreduce-online/
http://radar.oreilly.com/2009/10/pipelining-and-real-time-analytics-with-mapreduce-online.html
http://dbmsmusings.blogspot.com/2009/10/analysis-of-mapreduce-online-paper.html

The HOP code has been published at the following location.
http://code.google.com/p/hop/"
MAPREDUCE-1210,standalone \r is treated as new line by RecordLineReader,In PIg 0.6.0 we are switching to RecordLineReader from our own implementation. We are seeing differences in record counts that were traced down to the fact that standalone \r is treated as line end. I don't think there is any precedence for this and we would like to get this resolved so that we can use RLR and not break backward compatibility. (This problem was detected with real user data.)
MAPREDUCE-1209,Move common specific part of the test TestReflectionUtils out of mapred into common,"As commented by Tom here (https://issues.apache.org/jira/browse/HADOOP-6230?focusedCommentId=12751058&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12751058), TestReflectionUtils has a single test testSetConf() to test backward compatibility of ReflectionUtils for JobConfigurable objects. TestReflectionUtils can be spilt into two tests - one on common and one in mapred - this single test may reside in mapred till the mapred package is removed."
MAPREDUCE-1207,Allow admins to set java options for map/reduce tasks,"It will be useful for allow cluster-admins to set some java options for child map/reduce tasks. 

E.g. We've had to ask users to set -Djava.net.preferIPv4Stack=true in their jobs, it would be nice to do it for all users in such scenarios even when people override mapred.child.{map|reduce}.java.opts but forget to add this."
MAPREDUCE-1206,"Need a better answer for ""how many reduces?""","http://hadoop.apache.org/common/docs/current/mapred_tutorial.html#Reducer

--snip--
How Many Reduces?

The right number of reduces seems to be 0.95 or 1.75 multiplied by (<no. of nodes> * mapred.tasktracker.reduce.tasks.maximum).
--snip--

Sure, if you only ever run one job on your grid.  There should really be a better answer here, especially explaining what the impact is of a high/low number when chaining multiple map/reduce jobs."
MAPREDUCE-1203,DBOutputFormat: add batch size support for JDBC and recieve  DBWritable object in value not in key,"package mapred.lib.db

added batch size support for JDBC in DBOutputFormat 
recieve  DBWritable object in value not in key in DBOutputFormat


"
MAPREDUCE-1201,Make ProcfsBasedProcessTree collect CPU usage information,This information can be reported back to jobtracker to help profiling jobs and scheduling tasks.
MAPREDUCE-1200,TestGridmixSubmission unit Test is failing in trunk,"

http://hudson.zones.apache.org/hudson/view/Hadoop/job/Hadoop-Mapreduce-trunk/138/testReport/org.apache.hadoop.mapred.gridmix/TestGridmixSubmission/testSubmit/

Error Message
Mismatched input bytes 5127269/5139995

Stacktrace
junit.framework.AssertionFailedError: Mismatched input bytes 5127269/5139995
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.check(TestGridmixSubmission.java:213)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.verify(TestGridmixSubmission.java:145)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$DebugGridmix.checkMonitor(TestGridmixSubmission.java:263)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testSubmit(TestGridmixSubmission.java:297)

"
MAPREDUCE-1198,Alternatively schedule different types of tasks in fair share scheduler,Matei has mentioned in MAPREDUCE-961 that the current scheduler will first try to launch map tasks until canLaunthTask() returns false then look for reduce tasks. This might starve reduce task. He also mention that alternatively schedule different types of tasks can solve this problem.
MAPREDUCE-1196,MAPREDUCE-947 incompatibly changed FileOutputCommitter,MAPREDUCE-947 unfortunately removed FileOutputCommitter.cleanupJob and doesn't call the deprecated method from the base-class i.e. OutputCommitter.cleanupJob; this means that applications which derive FileOutputCommitter.cleanupJob are now broken.
MAPREDUCE-1195,Task resource utilization reporting for profiling and scheduling,"We can make TaskTracker reports its usage on CPU, memory, bandwidth to JobTracker. JobTracker can use the information for scheduling tasks and profiling jobs. 

One way to do this is to first make ProcfsProcessTree to collect the utilization information (CPU, mem...) and write the information in TaskTrackerStatus.taskReports and send them with the heartbeats. Then we can aggregate these information in JobInProgress to do job profiling and scheduling."
MAPREDUCE-1192,Use the DistributedCache for job.xml and job.jar,It would be more efficient if we used the DistributedCache for a job's configuration and jars.
MAPREDUCE-1190,Add package.html to pi and pi.math packages.,package.html is missing in the pi and pi.math packages.
MAPREDUCE-1189,Reduce ivy console output to ovservable level,"It is very hard to see what's going in the build because ivy is literally flood the console with nonsensical messages...
"
MAPREDUCE-1188,NPE in decommissioning blacklisted nodes,Decommissioning a blacklisted node results into a NPE.
MAPREDUCE-1187,mradmin -refreshNodes should be implemented,"dfsadmin -refreshNodes re-reads the include/exclude files for the HDFS, triggers decommisions, etc.  The MapReduce framework should have similar functionality using the same parameter to mradmin."
MAPREDUCE-1186,"While localizing a DistributedCache file, TT sets permissions recursively on the whole base-dir",This is a performance problem.
MAPREDUCE-1185,URL to JT webconsole for running job and job history should be the same,The tracking url for running jobs and the jobs which are retired is different. This creates problem for clients which caches the job running url because soon it becomes invalid when job is retired.
MAPREDUCE-1184,mapred.reduce.slowstart.completed.maps is too low by default,"By default, this value is set to 5%.  I believe for most real world situations the code isn't efficient enough to be set this low.  This should be higher, probably around the 50% mark, especially given the predominance of non-FIFO schedulers."
MAPREDUCE-1182,Reducers fail with OutOfMemoryError while copying Map outputs,"Reducers fail while copying Map outputs with following exception

java.lang.OutOfMemoryError: Java heap space at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.shuffleInMemory(ReduceTask.java:1539) at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1432) at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1285) at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:1216) ,Error:

Reducer's memory usage keeps on increasing and ultimately exceeds -Xmx value  
I even tried with -Xmx6.5g to each reducer but it's still failing 

While looking into the reducer logs, I found that reducers were doing shuffleInMemory every time, rather than doing shuffleOnDisk"
MAPREDUCE-1181,Enforce RSS memory limit in TaskMemoryManagerThread,"TaskMemoryManagerThread will periodically check the rss memory usage of every task. If the memory usage exceeds the specified threshold, the task will be killed. Also if the total rss memory of all tasks exceeds (total amount of memory - specified reserved memory). The task with least progress will be killed to recover the reserved rss memory.

This is similar to the virtual memory limit provided by TaskMemoryManagerThread. But now the limit is for rss memory. This new feature allow us to avoid page swapping which is prone to error.

The following are the related configurations
mapreduce.reduce.memory.rss.mb   // RSS memory allowed for a reduce task
mapreduce.map.memory.rss.mb       // RSS memory allowed for a map task
mapreduce.tasktracker.reserved.memory.rss.mb     // RSS memory reserved (not for tasks) on a tasktracker"
MAPREDUCE-1180,Detailed area chart of map/reduce slots usage,"People are always looking for ideas of things to implement... so here's one. :)

I'd like an app that I can throw at a JobHistory directory that would show me detailed slot usage by job, user, pool, etc, in an area stacked chart format.  This would be very helpful to determine if a particular job, user, or pool is under/over utilizing the capacity, if we need more capacity, what time slots have holes, etc.  I'll see if I can create an example in Excel of what I'm thinking of."
MAPREDUCE-1179,org.apache.hadoop.streaming.TestSymLink.testSymLink is failing ,"This junit testcase is failing. Please address it.


org.apache.hadoop.streaming.TestSymLink.testSymLink (from TestSymLink) 

Failing for the past 1 build (Since #131 ) 
Took 55 sec.
add description

Error Message
java.lang.IllegalArgumentException: port out of range:-1  at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)  at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:367)  at org.apache.hadoop.hdfs.server.namenode.NameNode.activate(NameNode.java:310)  at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:301)  at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:406)  at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:400)  at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1174)  at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:282)  at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:126)  at org.apache.hadoop.streaming.TestSymLink.testSymLink(TestSymLink.java:67)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  at java.lang.reflect.Method.invoke(Method.java:597)  at junit.framework.TestCase.runTest(TestCase.java:168)  at junit.framework.TestCase.runBare(TestCase.java:134)  at junit.framework.TestResult$1.protect(TestResult.java:110)  at junit.framework.TestResult.runProtected(TestResult.java:128)  at junit.framework.TestResult.run(TestResult.java:113)  at junit.framework.TestCase.run(TestCase.java:124)  at junit.framework.TestSuite.runTest(TestSuite.java:232)  at junit.framework.TestSuite.run(TestSuite.java:227)  at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)  at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768) 
Stacktrace
junit.framework.AssertionFailedError: java.lang.IllegalArgumentException: port out of range:-1
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:367)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.activate(NameNode.java:310)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:301)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:406)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:400)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1174)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:282)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:126)
	at org.apache.hadoop.streaming.TestSymLink.testSymLink(TestSymLink.java:67)

	at org.apache.hadoop.streaming.TestSymLink.failTrace(TestSymLink.java:140)
	at org.apache.hadoop.streaming.TestSymLink.testSymLink(TestSymLink.java:132)

"
MAPREDUCE-1178,MultipleInputs fails with ClassCastException ,"When running MultipleInputs against the new API, we get failures with this ClassCastException:

java.lang.ClassCastException: org.apache.hadoop.mapreduce.lib.input.TaggedInputSplit cannot be cast to org.apache.hadoop.mapreduce.lib.input.FileSplit
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:70)
	at org.apache.hadoop.mapreduce.lib.input.KeyValueLineRecordReader.initialize(KeyValueLineRecordReader.java:59)
	at org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.initialize(MapTask.java:439)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:599)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:323)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:257)

The unit test for MultipleInputs doesn't actually run a job so this snuck through while still passing the unit test.  Attached patch fixes the unit test to expose the failure and does a little casting kung-fu in LineRecordReader to avoid the error."
MAPREDUCE-1177,TestTaskTrackerMemoryManager retries a task for more than 100 times.,"TestTaskTrackerMemoryManager retries a task for more than 100 times.
The logs showing the same:
{noformat}
2009-11-02 12:41:20,489 INFO  mapred.JobInProgress (JobInProgress.java:completedTask(2530)) - Task 'attempt_20091102123356106_0001_m_000002_145' has completed task_20091102123356106_0001_m_000002 successfully.
{noformat}

Sometimes the test timesout also.
"
MAPREDUCE-1176,FixedLengthInputFormat and FixedLengthRecordReader,"Hello,
I would like to contribute the following two classes for incorporation into the mapreduce.lib.input package. These two classes can be used when you need to read data from files containing fixed length (fixed width) records. Such files have no CR/LF (or any combination thereof), no delimiters etc, but each record is a fixed length, and extra data is padded with spaces. The data is one gigantic line within a file.

Provided are two classes first is the FixedLengthInputFormat and its corresponding FixedLengthRecordReader. When creating a job that specifies this input format, the job must have the ""mapreduce.input.fixedlengthinputformat.record.length"" property set as follows

myJobConf.setInt(""mapreduce.input.fixedlengthinputformat.record.length"",[myFixedRecordLength]);

OR

myJobConf.setInt(FixedLengthInputFormat.FIXED_RECORD_LENGTH, [myFixedRecordLength]);

This input format overrides computeSplitSize() in order to ensure that InputSplits do not contain any partial records since with fixed records there is no way to determine where a record begins if that were to occur. Each InputSplit passed to the FixedLengthRecordReader will start at the beginning of a record, and the last byte in the InputSplit will be the last byte of a record. The override of computeSplitSize() delegates to FileInputFormat's compute method, and then adjusts the returned split size by doing the following: (Math.floor(fileInputFormatsComputedSplitSize / fixedRecordLength) * fixedRecordLength)

This suite of fixed length input format classes, does not support compressed files. "
MAPREDUCE-1174,Sqoop improperly handles table/column names which are reserved sql words,"In some databases it is legal to name tables and columns with terms that overlap SQL reserved keywords (e.g., {{CREATE}}, {{table}}, etc.). In such cases, the database allows you to escape the table and column names. We should always escape table and column names when possible."
MAPREDUCE-1172,TestReduceFetch failed in 0.20,"When I was testing HDFS-732 on 0.20, TestReduceFetch kept failing."
MAPREDUCE-1171,Lots of fetch failures,"Since we upgraded to hadoop-0.20.1  from hadoop0.18.3, we see lot of more map task failures because of 'Too many fetch-failures'.

One of our jobs makes hardly any progress, because of 3000 reduces not able to get map output of 2 trailing maps (with about 80GB output each), which repeatedly are marked as failures because of reduces not being able to get their map output.
One difference to hadoop-0.18.3 seems to be that reduce tasks report a failed mapoutput fetch even after a single try when it was a read error (cr.getError().equals(CopyOutputErrorType.READ_ERROR). I do not think this is a good idea, as trailing map tasks will be attacked by all reduces simultaneously.

Here is a log output of a reduce task:
{noformat}
2009-10-29 21:38:36,148 WARN org.apache.hadoop.mapred.ReduceTask: attempt_200910281903_0028_r_000000_0 copy failed: attempt_200910281903_0028_m_002781_1 from some host
2009-10-29 21:38:36,148 WARN org.apache.hadoop.mapred.ReduceTask: java.net.SocketTimeoutException: Read timed out        at java.net.SocketInputStream.socketRead0(Native Method)
        at java.net.SocketInputStream.read(SocketInputStream.java:129)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
        at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:687)
        at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:632)
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1064)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getInputStream(ReduceTask.java:1496)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.getMapOutput(ReduceTask.java:1377)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:1289)
        at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:1220)

2009-10-29 21:38:36,149 INFO org.apache.hadoop.mapred.ReduceTask: Task attempt_200910281903_0028_r_000000_0: Failed fetch #1 from attempt_200910281903_0028_m_002781_1
2009-10-29 21:38:36,149 INFO org.apache.hadoop.mapred.ReduceTask: Failed to fetch map-output from attempt_200910281903_0028_m_002781_1 even after MAX_FETCH_RETRIES_PER_MAP retries...  or it is a read error,  reporting to the JobTracker.
{noformat}

Also I saw a few log messages which look suspicious as if successfully fetched map output is discarded because of the map being marked as failed (because of too many fetch failures). This would make the situation even worse.

{noformat}
2009-10-29 22:07:28,729 INFO org.apache.hadoop.mapred.ReduceTask: header: attempt_200910281903_0028_m_001076_0, compressed len: 21882555, decompressed len: 23967845
2009-10-29 22:07:28,729 INFO org.apache.hadoop.mapred.ReduceTask: Shuffling 23967845 bytes (21882555 raw bytes) into RAM from attempt_200910281903_0028_m_001076_0
2009-10-29 22:07:43,602 INFO org.apache.hadoop.mapred.ReduceTask: Read 23967845 bytes from map-output for attempt_200910281903_0028_m_001076_0
2009-10-29 22:07:43,602 INFO org.apache.hadoop.mapred.ReduceTask: Rec #1 from attempt_200910281903_0028_m_001076_0 -> (20, 39772) from some host
...
2009-10-29 22:10:07,220 INFO org.apache.hadoop.mapred.ReduceTask: Ignoring obsolete output of FAILED map-task: 'attempt_200910281903_0028_m_001076_0'
{noformat}



"
MAPREDUCE-1170,MultipleInputs doesn't work with new API in 0.20 branch,"This patch adds support for MultipleInputs (and KeyValueTextInputFormat) in o.a.h.mapreduce.lib.input, working with the new API.  Included passing unit test.  Include for 0.20.2?"
MAPREDUCE-1169,Improvements to mysqldump use in Sqoop,"Improve Sqoop's integration with mysqldump
"
MAPREDUCE-1168,Export data to databases via Sqoop,Sqoop can import from a database into HDFS. It's high time it works in reverse too.
MAPREDUCE-1167,Make ProcfsBasedProcessTree collect rss memory information,"Right now ProcfsBasedProcess collects only virtual memory. We can make it collect rss memory as well.
Later we can use rss in TaskMemoryManagerThread to obtain better memory management."
MAPREDUCE-1166,SerialUtils.cc: dynamic allocation of arrays based on runtime variable is not portable,"In SerialUtils.cc, the following code appears:

    int len;
    if (b < -120) {
      negative = true;
      len = -120 - b;
    } else {
      negative = false;
      len = -112 - b;
    }
    uint8_t barr[len];


as far as I'm aware, this is not legal in ANSI C and will be rejected by ANSI compliant compilers.  Instead, this should be malloc()'d based upon the size of len and free()'d later."
MAPREDUCE-1165,SerialUtils.hh: __PRETTY_FUNCTION__ is a GNU extension and not portable,"SerialUtils.hh uses __PRETTY_FUNCTION__ to print the name of the function during an assertion.  That is a GNU extension and is not portable across compilers.  [C99 defines __func__, which should probably be used instead.]"
MAPREDUCE-1163,hdfsJniHelper.h: Yahoo! specific paths are encoded,"This header file defines USER_CLASSPATH as ""/home/y/libexec/hadoop/conf:/home/y/libexec/hadoop/lib/hadoop-0.1.0.jar"" .  

This define doesn't appear to actually be used anywhere.  But it certainly would be a great way to exploit systems if it used internally at Yahoo!..."
MAPREDUCE-1162,Job history should keep track of which task trackers were blacklisted,It would be useful to have job history keep track of which nodes were blacklisted by the job.  This would be used to build a history of job failure on certain nodes.
MAPREDUCE-1161,NotificationTestCase should not lock current thread,There are 3 instances where NotificationTestCase is locking Thread.currentThread() is being locked and calling sleep on it. There is also a method stdPrintln that doesn't do anything.
MAPREDUCE-1160,Two log statements at INFO level fill up jobtracker logs,"There are two log statements being logged at an INFO level that are unnecessarily filling up JT logs. This is making it difficult to debug issues on large cluster systems.

The two statements identified are the following:

INFO org.apache.hadoop.mapred.JobInProgress: No reduces to schedule for <jobid>
and
INFO org.apache.hadoop.mapred.ResourceEstimator: completedMapsUpdates:22  completedMapsInputSize:656  completedMapsOutputSize:6299

"
MAPREDUCE-1159,Limit Job name on jobtracker.jsp to be 80 char long,"Sometimes a user submits a job with a very long job name. That made jobtracker.jsp very hard to read.
We should limit the size of the job name. User can see the full name when they click on the job.
"
MAPREDUCE-1158,running_maps is not decremented when the tasks of a job is killed/failed ,"running_maps counter in the metrics is not decremented when the tasks of a job is killed/failed. Below are the exact steps to reproduce the problem:
* Initially running_maps=0
* Submit a job with 5 maps. running_maps is set to 5
* Kill 2 attempts of a map task
* Fail 4 attempts of the same map task so that the job is finally marked killed.
* Once the job is marked killed, running_maps is set to 3 and not 0. "
MAPREDUCE-1157,JT UI shows incorrect scheduling info for failed/killed retired jobs,"After a failed/killed job retires, the ""Job Scheduling Information"" section prints a message such as ""<running map tasks at the time the job was killed/failed> running map tasks using <running map slots at the time the job was killed/failed> map slots."" Instead it should print a message such as ""0 running map tasks using 0 map slots""

Same is the case with reduce task/slots."
MAPREDUCE-1155,Streaming tests swallow exceptions,Many of the streaming tests (including TestMultipleArchiveFiles) catch exceptions and print their stack trace rather than failing the job. This means that tests do not fail even when the job fails.
MAPREDUCE-1154,"Large-scale, automated test framwork for Map-Reduce","HADOOP-6332 proposes a large-scale, automated, junit-based test-framework for Hadoop.

This jira is meant to track relevant work to Map-Reduce."
MAPREDUCE-1153,Metrics counting tasktrackers and blacklisted tasktrackers are not updated when trackers are decommissioned.,"MAPREDUCE-1103 added instrumentation on the jobtracker to count the number of actual, blacklisted and decommissioned tasktrackers. When a tracker is decommissioned, the tasktracker count or the blacklisted tracker count is not decremented."
MAPREDUCE-1152,JobTrackerInstrumentation.killed{Map/Reduce} is never called,JobTrackerInstrumentation.killed{Map/Reduce} metrics added as part of MAPREDUCE-1103 is not captured
MAPREDUCE-1151,Cleanup and Setup jobs should only call cleanupJob() and setupJob() methods of the OutputCommitter,"The cleanup and setup jobs run as map jobs and call setUpTask() , needsTaskCommit() and possibly commitTask() and abortTask() methods of the OutputCommitter. They should only be calling the cleanupJob() and setupJob() methods."
MAPREDUCE-1149,SQL identifiers are a superset of Java identifiers,"SQL identifiers can contain arbitrary characters, can start with numbers, can be words like {{class}} which are reserved in Java, etc. If Sqoop uses these names literally for class and field names then compilation errors can occur in auto-generated classes. SQL identifiers need to be cleansed to map onto Java identifiers."
MAPREDUCE-1148,SQL identifiers are a superset of Java identifiers,"SQL identifiers can contain arbitrary characters, can start with numbers, can be words like {{class}} which are reserved in Java, etc. If Sqoop uses these names literally for class and field names then compilation errors can occur in auto-generated classes. SQL identifiers need to be cleansed to map onto Java identifiers."
MAPREDUCE-1147,Map output records counter missing for map-only jobs in new API,"In the new API, the counter for map output records is not incremented for map-only jobs"
MAPREDUCE-1146,Sqoop dependencies break Ecpilse build on Linux,"Under  Linux there's the error in the Eclipse ""Problems"" view:
{noformat}
- ""com.sun.tools cannot be resolved"" at line 166 of  org.apache.hadoop.sqoop.orm.CompilationManager
{noformat}
The problem doesn't appear on MacOS though"
MAPREDUCE-1145,Multiple Outputs doesn't work with new API in 0.20 branch,"I know this is working in the 0.21 branch but it's dependent on a ton of other refactorings and near-impossible to backport.  I hacked together a quick forwards-port in o.a.h.mapreduce.lib.output.MultipleOutputs.  Unit test attached, requires a one-liner change to FileOutputFormat.

Maybe 0.20.2?  "
MAPREDUCE-1144,JT should not hold lock while writing user history logs to DFS,"I've seen behavior a few times now where the DFS is being slow for one reason or another, and the JT essentially locks up waiting on it while one thread tries for a long time to write history files out. The stack trace blocking everything is:

Thread 210 (IPC Server handler 10 on 7277):
  State: WAITING
  Blocked count: 171424
  Waited count: 1209604
  Waiting on java.util.LinkedList@407dd154
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.flushInternal(DFSClient.java:3122)
    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.closeInternal(DFSClient.java:3202)
    org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.close(DFSClient.java:3151)
    org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:67)
    org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)
    sun.nio.cs.StreamEncoder.implClose(StreamEncoder.java:301)
    sun.nio.cs.StreamEncoder.close(StreamEncoder.java:130)
    java.io.OutputStreamWriter.close(OutputStreamWriter.java:216)
    java.io.BufferedWriter.close(BufferedWriter.java:248)
    java.io.PrintWriter.close(PrintWriter.java:295)
    org.apache.hadoop.mapred.JobHistory$JobInfo.logFinished(JobHistory.java:1349)
    org.apache.hadoop.mapred.JobInProgress.jobComplete(JobInProgress.java:2167)
    org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2111)
    org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:873)
    org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:3598)
    org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:2792)
    org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2581)
    sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)

We should try not to do external IO while holding the JT lock, and instead write the data to an in-memory buffer, drop the lock, and then write."
MAPREDUCE-1143,runningMapTasks counter is not properly decremented in case of failed Tasks.,
MAPREDUCE-1142,"When cache.local.size is hit on one disk, DistributedCacheManager aggressively deletes old files on other disks too.","When the size of distributed cache files goes beyond {{mapreduce.tasktracker.cache.local.size}} on one disk, {{TrackerDistributedCacheManager}} deletes old files on other disks too. May be this is a bit aggressive.

An important problem with this excess effort is that issue observed at MAPREDUCE-1141 will be more often."
MAPREDUCE-1141,Localization of a task's distributed-cache files gets blocked by deletion of old unrelated files when mapreduce.tasktracker.cache.local.size is hit.,
MAPREDUCE-1140,Per cache-file refcount can become negative when tasks release distributed-cache files,
MAPREDUCE-1139,Contrib tests should respect scr/test/mapred-site.xml,There is no easy way to enforce some parameter value (as default) on contrib tests. This functionality is available for core test i.e by adding the param to mapred-site.xml in src/test.
MAPREDUCE-1138,Erroneous output folder handling in streaming testcases,"Output folder is shared across testcases. Ideally we should use different output folder for each testcases, Also the deletion failure is silently ignored. MAPREDUCE-947 fixed some part of o/p dir cleaning. "
MAPREDUCE-1137,Mumak should have a unit test to ensure jetty UI is running properly,Mumak should have a unit test that ensures jetty UI is running properly. This will help detecting issues like MAPREDUCE-1104 sooner.
MAPREDUCE-1136,ConcurrentModificationException when tasktracker updates task status to jobtracker,"In Hadoop 0.18.3, the following exception happened during a job execution. It does not happen often.

Here is the stack trace of the exception.
org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.util.ConcurrentModificationException
        at java.util.TreeMap$PrivateEntryIterator.nextEntry(TreeMap.java:1100)
        at java.util.TreeMap$ValueIterator.next(TreeMap.java:1145)
        at org.apache.hadoop.mapred.JobTracker.getAllJobs(JobTracker.java:2376)
        at sun.reflect.GeneratedMethodAccessor32.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:890)
 org.apache.hadoop.ipc.Client.call(Client.java:716)
"
MAPREDUCE-1135,Making JobHistory log format easily extensible in the future,"This jira is branched from MAPREDUCE-1016.

It would be nice to make the JobHistory log format easily extensible in the future."
MAPREDUCE-1134,The API around HistoryEvent has inelegances,"For example, ReduceAttemptFinishedEvent has a getAttemptId() method, but TaskAttemptStartedEvent has a getTaskAttemptId() method.  TaskFailedEvent has a getFailedAttemptID [note that ""ID"" in this context is spelled with an uppercase D, while all the other ""Id""'s are spelled with a lowercase d ] .

Should we make a pass over these things and clean these up before too many people code to this API?

-dk
"
MAPREDUCE-1133,Eclipse .classpath template has outdated jar files and is missing some new ones.,"Eclipse environment is broken in trunk: it still uses *.21*.jar files and includes some libraries which aren't in use any more (similar to HDFS-726).
"
MAPREDUCE-1132,TestGridmixSubmission failing intermittently,"Out of 3 runs on my desktop on trunk, test failed once with failure:
Mismatched input bytes 1159031/1165363
junit.framework.AssertionFailedError: Mismatched input bytes 1159031/1165363
        at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.check(TestGridmixSubmission.java:213)
        at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.verify(TestGridmixSubmission.java:145)
        at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$DebugGridmix.checkMonitor(TestGridmixSubmission.java:263)
        at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testSubmit(TestGridmixSubmission.java:297)

It also failed as part of MAPREDUCE-1103 hudson run. Log at -> http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/200/testReport/org.apache.hadoop.mapred.gridmix/TestGridmixSubmission/testSubmit/"
MAPREDUCE-1131,Using profilers other than hprof can cause JobClient to report job failure,"If task profiling is enabled, the JobClient will download the {{profile.out}} file created by the tasks under profile. If this causes an IOException, the job is reported as a failure to the client, even though all the tasks themselves may complete successfully. The expected result files are assumed to be generated by hprof. Using the profiling system with other profilers will cause job failure."
MAPREDUCE-1129,Assign multiple Map and Reduce tasks in Fairscheduler,"In Hadoop-0.20, the period of heartbeat becomes much longer. 
Fairscheduler assigns at most one Map and one Reduce task per heartbeat.
This makes the cluster become very inefficient. Often time only half of the slots are used.

One idea is that we make Fairscheduler detect this situation (cluster under used) and scheduler more tasks in a heartbeat.
Thoughts?"
MAPREDUCE-1128,MRUnit Allows Iteration Twice,"MRUnit allows one to iterate over a collection of values twice (ie.

reduce(Key key, Iterable<Value> values, Context context){
   for(Value : values ) /* iterate once */;
   for(Value : values ) /* iterate again */;
}

Hadoop will allow this as well, however the second iterator will be empty. MRUnit should either match hadoop's behavior or warn the user that their code is likely flawed."
MAPREDUCE-1127,distcp should timeout later during S3-based transfers,"Per MAPREDUCE-972, rename and other operations on distcp can take longer than the typical mapreduce task timeout. As an interim fix, this timeout should be increased when the distcp destination is S3."
MAPREDUCE-1126,shuffle should use serialization to get comparator,"Currently the key comparator is defined as a Java class.  Instead we should use the Serialization API to create key comparators.  This would permit, e.g., Avro-based comparators to be used, permitting efficient sorting of complex data types without having to write a RawComparator in Java."
MAPREDUCE-1125,SerialUtils.cc: deserializeFloat is out of sync with SerialUtils.hh,"{noformat}
*** SerialUtils.hh ***
  float deserializeFloat(InStream& stream);

*** SerialUtils.cc ***
  void deserializeFloat(float& t, InStream& stream)
  {
    char buf[sizeof(float)];
    stream.read(buf, sizeof(float));
    XDR xdrs;
    xdrmem_create(&xdrs, buf, sizeof(float), XDR_DECODE);
    xdr_float(&xdrs, &t);
  }
{noformat}
"
MAPREDUCE-1124,TestGridmixSubmission fails sometimes,"TestGridmixSubmission fails sometimes with following error :
Mismatched output bytes 4547848/4561267
junit.framework.AssertionFailedError: Mismatched output bytes 4547848/4561267
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.check(TestGridmixSubmission.java:231)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$TestMonitor.verify(TestGridmixSubmission.java:140)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission$DebugGridmix.checkMonitor(TestGridmixSubmission.java:263)
	at org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testSubmit(TestGridmixSubmission.java:297)
"
MAPREDUCE-1121,Hadoop MapReduce - Site Logo,"Hadoop MapReduce - Site Logo 

Update the logo (see attached jpg).
Image has elephant + MapReduce.

With this update, Site logo and Documentation logo will be the same.
"
MAPREDUCE-1119,"When tasks fail to report status, show tasks's stack dump before killing","When the TT kills tasks that haven't reported status, it should somehow gather a stack dump for the task. This could be done either by sending a SIGQUIT (so the dump ends up in stdout) or perhaps something like JDI to gather the stack directly from Java. This may be somewhat tricky since the child may be running as another user (so the SIGQUIT would have to go through LinuxTaskController). This feature would make debugging these kinds of failures much easier, especially if we could somehow get it into the TaskDiagnostic message"
MAPREDUCE-1118,Capacity Scheduler scheduling information is hard to read / should be tabular format,"The scheduling information provided by the capacity scheduler is extremely hard to read on the job tracker web page.  Instead of just flat text, it should be presenting the information in a tabular format, similar to what the fair share scheduler provides.  This makes it much easier to compare what different queues are doing."
MAPREDUCE-1117,ClusterMetrics return metrics for tasks instead of slots',In trunk the issue was fixed as part MAPREDUCE-1048. The fix needs to be ported to 0.21
MAPREDUCE-1115,Support hierarchical pools of directories to use for intermediate MapReduce data files (for SSD drives),"Some initial benchmarking shows that SSDs can help a lot for local data files (for shuffle and other intermediate files). 

Currently mapred.local.dir just round-robins over the provided directories, it would be nice to allocate a set of SSD directories to round-robin across first, then spill over to normal drives if the SSD directories are full.

-- amr
"
MAPREDUCE-1114,Speed up ivy resolution in builds with clever caching,"An awful lot of time is spent in the ivy:resolve parts of the build, even when all of the dependencies have been fetched and cached. Profiling showed this was in XML parsing. I have a sort-of-ugly hack which speeds up incremental compiles (and more importantly ""ant test"") significantly using some ant macros to cache the resolved classpaths."
MAPREDUCE-1113,mumak compiles aspects even if skip.contrib is true,The compile-aspects task in mumak's build.xml runs regardless of the skip.contrib property. Momentarily uploading a patch to fix this.
MAPREDUCE-1112,Fix CombineFileInputFormat for hadoop 0.20,"HADOOP-5759 is already fixed as a part of MAPREDUCE-364  in hadoop 0.21.
This will fix the same problem with CombineFileInputFormat for hadoop 0.20.
"
MAPREDUCE-1111,JT Jetty UI not working if we run mumak.sh off packaged distribution directory.,"JT Jetty UI not working if we run mumak.sh off packaged distribution directory. However, if we directly run mumak.sh from the source directory it is ok."
MAPREDUCE-1109,ConcurrentModificationException in jobtracker.jsp,"The jobtracker.jsp invoked methods tracker.runningJobs(), tracker.completedJobs() and tracker.failedJobs() but these methods are not synchronized and can cause ConcurrentModificationException if the JT is concurrently changing the contents of these datastructures."
MAPREDUCE-1108,Modify test-patch.sh to verify that the number of findBugs warning is always zero,"HADOOP-5661 and MAPREDUCE-769 involve going through pains to make sure findBugs warnings become zero. All that effort would be a waste if patches keep ignoring these warnings. 

We should modify the Hudson test-patch.sh script to always verify that the findBugs warnings are zero in number. It should scream when the warnings go above zero level and make sure trunk is always at zero findBugs warnings.

And to help contributors about what to do when an un-ignorable warning is spelt out by test-patch.sh, we should modify the output of test-patch.sh to point to _src/test/findbugsExcludeFile.xml_ for suppressing any warnings."
MAPREDUCE-1107,Creating a new fairscheduler,"Hi,

I have created a slight modification of existing fairscheduler by adding a job level scheduling to it. The classes are all inherited from the existing classes. I have compiled them all and created a jar file for the same. I wanted this jar to run for fairscheduler instead of the existing fairscheduler.jar. I have placed it in the HADOOP_HOME/lib. Still it doesn't run instead of the present one. What might be the problem? Is there some way to keep it run?

Anjali M"
MAPREDUCE-1106,LocalJobRunner should run with any file-system,LocalJobRunner is hard-coded to run with only the local file-system. This will help users write map/reduce programs in local mode yet accessing input/schema/data files etc. from any file system.
MAPREDUCE-1105,CapacityScheduler: It should be possible to set queue hard-limit beyond it's actual capacity,"Currently the CS caps a queue's capacity to it's actual capacity if a hard-limit is specified to be greater than it's actual capacity. We should allow the queue to go upto the hard-limit if specified.

Also, I propose we change the hard-limit unit to be percentage rather than #slots."
MAPREDUCE-1104,RecoveryManager not initialized in SimulatorJobTracker led to NPE in JT Jetty server,RecoveryManager initialization is not copied to the JobTracker constructor Mumak depends on. This leads to NPE in JT Jetty server.
MAPREDUCE-1103,Additional JobTracker metrics,"It would be useful for tracking the following additional JobTracker metrics:
running{map|reduce}tasks
busy{map|reduce}slots
reserved{map|reduce}slots
"
MAPREDUCE-1101,Rename core jar to common jar,"The project name is common while the jar's name refers to core, odd. "
MAPREDUCE-1100,User's task-logs filling up local disks on the TaskTrackers,Some user's jobs are filling up TT disks by outrageous logging. mapreduce.task.userlog.limit.kb is not enabled on the cluster. Disks are getting filled up before task-log cleanup via mapred.task.userlog.retain.hours can kick in.
MAPREDUCE-1098,Incorrect synchronization in DistributedCache causes TaskTrackers to freeze up during localization of Cache for tasks.,"Currently {{org.apache.hadoop.filecache.DistributedCache.getLocalCache(URI, Configuration, Path, FileStatus, boolean, long, Path, boolean)}} allows only one {{TaskRunner}} thread in TT to localize {{DistributedCache}} across jobs. Current way of synchronization is across baseDir this has to be changed to lock on the same baseDir.
"
MAPREDUCE-1097,Changes/fixes to support Vertica 3.5,"Vertica 3.5 includes three changes that the formatters should handle:

1) deploy_design function that handles much of the logic in the optimize method.  This improvement uses deploy_design if the server version supports it instead of orchestrating in the formatter function.
2) truncate table instead of recreating the table
3) numeric, decimal, money, number types (all the same path)"
MAPREDUCE-1096,Add getNames method to VerticaRecord to retrieve input column names,Minor API addition to VerticaRecord. Function getNames() returns names for columns associated with input or output.
MAPREDUCE-1095,Hadoop 0.20 Compatible IdentityMapper and IdentityReducer,"Certainly useful, and missing from Hadoop 2 API."
MAPREDUCE-1093,Java assertion failures triggered by tests,"While running the tests with java asserts enabled the following two asserts fired:

{code}
testStateRefresh in TestQueueManager:
try{
        Job job = submitSleepJob(10, 2, 10, 10, true,null, ""default"" );
        assert(job.isSuccessful());         <==========
}catch(Exception e){
{code}

{code}
runJobExceedingMemoryLimit in TestTaskTrackerMemoryManager:
for (TaskCompletionEvent tce : taskComplEvents) {
      // Every task HAS to fail
      assert (tce.getTaskStatus() == TaskCompletionEvent.Status.TIPFAILED || tce     <==========
          .getTaskStatus() == TaskCompletionEvent.Status.FAILED);
{code}
"
MAPREDUCE-1092,Enable asserts for tests by default,See HADOOP-6309. Let's make the tests run with java asserts by default.
MAPREDUCE-1091,TaskTrackers only work with same build as the JobTracker,Currently tasktrackers check to ensure that they are the same build as the JobTracker and bail-out if not. This is too restrictive - in the past we've had similar complaints: HADOOP-5203.
MAPREDUCE-1090,Modify log statement in Tasktracker log related to memory monitoring to include attempt id.,"Currently the TaskMemoryManagerThread logs a line like:
org.apache.hadoop.mapred.TaskMemoryManagerThread: Memory usage of ProcessTree 14321 :372686848bytes. Limit : 2147483648bytes. 
It would be very useful to include the Task attempt id for the process tree mentioned in the log statement."
MAPREDUCE-1089,Fair Scheduler preemption triggers NPE when tasks are scheduled but not running,"We see exceptions like this when preemption runs when a task has been scheduled on a TT but has not yet started running.

2009-10-09 14:30:53,989 INFO org.apache.hadoop.mapred.FairScheduler: Should preempt 2 MAP tasks for job_200910091420_0006: tasksDueToMinShare = 2, tasksDueToFairShare = 0
2009-10-09 14:30:54,036 ERROR org.apache.hadoop.mapred.FairScheduler: Exception in fair scheduler UpdateThread
java.lang.NullPointerException
        at org.apache.hadoop.mapred.FairScheduler$2.compare(FairScheduler.java:1015)
        at org.apache.hadoop.mapred.FairScheduler$2.compare(FairScheduler.java:1013)
        at java.util.Arrays.mergeSort(Arrays.java:1270)
        at java.util.Arrays.sort(Arrays.java:1210)
        at java.util.Collections.sort(Collections.java:159)
        at org.apache.hadoop.mapred.FairScheduler.preemptTasks(FairScheduler.java:1013)
        at org.apache.hadoop.mapred.FairScheduler.preemptTasksIfNecessary(FairScheduler.java:911)
        at org.apache.hadoop.mapred.FairScheduler$UpdateThread.run(FairScheduler.java:286)
"
MAPREDUCE-1087,Limit resource usage of Map/Reduce debug script,"As mentioned here by Devaraj [here|https://issues.apache.org/jira/browse/MAPREDUCE-915?focusedCommentId=12763756&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12763756], Map/Reduce debug scripts will run user code and hence need to be resource-limited via ulimits and memory-monitored similar to task-memory-monitoring."
MAPREDUCE-1086,hadoop commands in streaming tasks are trying to write to tasktracker's log,"As HADOOP_ROOT_LOGGER is not set in the environment by TT for the children, the children of task jvm(in case of streaming) are trying to write to TT's log and getting the following Exception. Jobs are succeeded, but the issue is to be resolved by setting the environment variables by TT for use by children of task jvm in case of streaming job.

When streaming calls hadoop commands, it's trying to write to TaskTracker log file.

log4j:ERROR setFile(null,true) call failed.
java.io.FileNotFoundException:
/a/b/tasktracker.log (Permission denied)
        at java.io.FileOutputStream.openAppend(Native Method)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:177)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:102)
        at org.apache.log4j.FileAppender.setFile(FileAppender.java:290)
        at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:164)
        at org.apache.log4j.DailyRollingFileAppender.activateOptions(DailyRollingFileAppender.java:216)
        at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:257)
        at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:133)
        at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:97)
        at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:689)
        at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:647)
        at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:544)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:440)
        at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:476)
        at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:471)
        at org.apache.log4j.LogManager.<clinit>(LogManager.java:125)
        at org.apache.log4j.Logger.getLogger(Logger.java:105)
        at org.apache.commons.logging.impl.Log4JLogger.getLogger(Log4JLogger.java:229)
        at org.apache.commons.logging.impl.Log4JLogger.<init>(Log4JLogger.java:65)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
        at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)
        at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)
        at java.lang.reflect.Constructor.newInstance(Constructor.java:513)
        at org.apache.commons.logging.impl.LogFactoryImpl.newInstance(LogFactoryImpl.java:529)
        at org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:235)
        at org.apache.commons.logging.impl.LogFactoryImpl.getInstance(LogFactoryImpl.java:209)
        at org.apache.commons.logging.LogFactory.getLog(LogFactory.java:351)
        at org.apache.hadoop.conf.Configuration.<clinit>(Configuration.java:138)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:57)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.fs.FsShell.main(FsShell.java:1880)
log4j:ERROR Either File or DatePattern options are not set for appender [DRFA]."
MAPREDUCE-1085,"For tasks, ""ulimit -v -1"" is being run when user doesn't specify mapred.child.ulimit","For tasks, ""ulimit -v -1"" is being run when user doesn't specify mapred.child.ulimit.  Taking -1 as default value and using it in building the command is not right."
MAPREDUCE-1084,Implementing aspects development and fault injeciton framework for MapReduce,"Similar to HDFS-435 and HADOOP-6204 this JIRA will track the introduction of injection framework for MapReduce.
After HADOOP-6204 is in place this particular modification should be very trivial and would take importing (via svn:external) of src/test/build and some tweaking of the build.xml file"
MAPREDUCE-1083, Use the user-to-groups mapping service in the JobTracker,HADOOP-4656 introduces a user-to-groups mapping service on the server-side. The JobTracker should use this to map users to their groups rather than relying on the information passed by the client.
MAPREDUCE-1082,Command line UI for queues' information is broken with hierarchical queues.,"
When the command ""./bin/mapred --config ~/tmp/conf/ queue -list"" is run, it just hangs. I can see the following in the JT logs:

{code}
2009-10-08 13:19:26,762 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 55555 caught: java.lang.NullPointerException
        at org.apache.hadoop.mapreduce.QueueInfo.write(QueueInfo.java:217)
        at org.apache.hadoop.mapreduce.QueueInfo.write(QueueInfo.java:223)
        at org.apache.hadoop.io.ObjectWritable.writeObject(ObjectWritable.java:159)
        at org.apache.hadoop.io.ObjectWritable.writeObject(ObjectWritable.java:126)
        at org.apache.hadoop.io.ObjectWritable.write(ObjectWritable.java:70)
        at org.apache.hadoop.ipc.Server.setupResponse(Server.java:1074)
        at org.apache.hadoop.ipc.Server.access$2400(Server.java:77)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:983)
{code}

Same is the case with ""./bin/mapred --config ~/tmp/conf/ queue -info <any-container-queue>""
"
MAPREDUCE-1081,Move hadoop_archives.xml out of mapreduce project,
MAPREDUCE-1080,Properties max.map.slots and max.reduce.slots should be hyphenated.,"The rest of the properties are hyphenated - for e.g., maximum-capacity, supports-priority etc. Using dots goes against this."
MAPREDUCE-1079,"Split commands_manual.xml into common, mapreduce and hdfs parts",
MAPREDUCE-1077,"When rumen reads a truncated job tracker log, it produces a job whose outcome is SUCCESS.  Should be null.",
MAPREDUCE-1076,ClusterStatus class should be deprecated ,ClusterStatus class should be deprecated infavour of ClusterMetrics and TaskTrackerInfo. This was missed in MAPREDUCE-777
MAPREDUCE-1075,getQueue(String queue) in JobTracker would return NPE for invalid queue name,
MAPREDUCE-1074,Provide documentation for Mark/Reset functionality,HADOOP-5266 introduced support of Mark/Reset of Values Iterator. Documentation needs to be updated for the same.
MAPREDUCE-1071,o.a.h.mapreduce.jobhistory.EventReader constructor should expect DataInputStream,"o.a.h.mapreduce.jobhistory.EventReader constructor should expect DataInputStream, so that it can parse job histories that are aggregated or compressed in file containers such as TFile."
MAPREDUCE-1070,Deadlock in FairSchedulerServlet,FairSchedulerServlet can cause a deadlock with the JobTracker
MAPREDUCE-1069,Implement Sqoop API refactoring,Implement refactoring decisions outlined in MAPREDUCE-1036
MAPREDUCE-1068,In hadoop-0.20.0 streaming job do not throw proper verbose error message if file is not present,"With hadoop-0.20.0 proper error message is not thrown , when streaming job is submitted and if file is not present to be distributed with ""-file"" option. But with hadoop-0.18.* proper verbose message is thrown if file is not present and it is easy for the users to debug.


For example:

With hadoop-0.20.0:
$ hadoop jar $HADOOP_HOME/hadoop-streaming.jar -Dmapred.job.queue.name=general  -input /user/simon/test1.txt -output /user/simon/test.out -mapper ""/bin/cat"" -file dummy -reducer ""/bin/cat""
Streaming Job Failed!


With hadoop-0.18.*:
$ hadoop  jar $HADOOP_HOME/hadoop-streaming.jar -input /user/simon/test1.txt -output /user/simon/test.out -mapper ""/bin/cat"" -file dummy -reducer ""/bin/cat""
09/10/06 10:06:49 ERROR streaming.StreamJob: Unexpected value ""Argument : /home/simon/dummy doesn't exist."" found while processing  -file

---
"
MAPREDUCE-1065,Modify the mapred tutorial documentation to use new mapreduce api.,
MAPREDUCE-1063,Document Gridmix benchmark,The Gridmix benchmark should have forrest documentation and a README pointing to it.
MAPREDUCE-1062,MRReliability test does not work with retired jobs,"Currently the MRReliability uses job clients get all job api which also includes retired jobs.

In case we have retired jobs in cluster, 
The retired jobs are appended at the end of the job list, this results in Test always getting completed job and not spawning off KillTask thread and KillTracker threads."
MAPREDUCE-1061,Gridmix unit test should validate input/output bytes,TestGridmixSubmission currently verifies only that the correct number of jobs have been run. The test should validate the I/O parameters it claims to satisfy.
MAPREDUCE-1060,JT should kill running maps when all the reducers have completed,"We have seen some situations where maps are still running when all the reducers have completed. This could happen because of lost TT's, interplay of speculative tasks with bad TT's etc. If the maps take a long time to run, it unnecessarily delays the job completion time, as this map output is not required anyways. The JT should possibly kill running maps when all the reducers have completed."
MAPREDUCE-1059,distcp can generate uneven map task assignments,"distcp writes out a SequenceFile containing the source files to transfer, and their sizes. Map tasks are created over spans of this file, representing files which each mapper should transfer. In practice, some transfer loads yield many empty map tasks and a few tasks perform the bulk of the work."
MAPREDUCE-1058,analysehistory.jsp should report node where task ran,"It is kind of painful to determine which nodes which tasks ran on.  It would be useful to list this in the web ui, especially for the best/worse performing tasks.   Using that information, it might be easier to see nodes that are over/under performing."
MAPREDUCE-1053,MRReliabilityTest does not kill/fail tasks if history is enabled,"When history is enabled, MRReliabilityTest fails to fail/kill tasks. Also the scenario of lost TTs is not being tested. 


"
MAPREDUCE-1050,Introduce a mock object testing framework,Using mock objects in unit tests can improve code quality (see e.g. http://www.mockobjects.com/). Hadoop would benefit from having a mock object framework for developers to write unit tests with. Doing so will allow a wider range of failure conditions to be tested and the tests will run faster.
MAPREDUCE-1048,Show total slot usage in cluster summary on jobtracker webui,"With High-Ram jobs coming into the picture, its important to also show the slot usage in cluster summary since total-running-maps < total-slots-occupied. "
MAPREDUCE-1047,hadoop.pipes.command.port missing from environment when using bash 4,"I recently upgraded to gnu bash 4.0 and found out that Hadoop Pipes applications break because they cannot read the ""hadoop.pipes.command.port"" environment variable."
MAPREDUCE-1045,Changes to deprecated interfaces break Hive,"I can haz compatibility?
The following things have broken the Hive Shims:
-The removal of a copy constructor in org/apache/hadoop/mapred/lib/CombineFileSplit.java
-The removal of methods involving JobConf in org/apache/hadoop/mapred/lib/CombineFileInputFormat.java

These look like relatively minor fixes to me, and although they are adding to deprecated interfaces, it would be wonderful to get Hive running against trunk Hadoop again.

See HIVE-845 for more details
http://issues.apache.org/jira/browse/HIVE-845"
MAPREDUCE-1044,Ability to automatically move machines from one MR compute cluster to another,We have multiple map-reduce clusters that provide different service and support levels for their users. We have seen that utilization of hardware resources are not optimized if we have a static partition of existing hardware resources into these separate MR clusters. It would be nice to have a automatic way to move nodes from one MR cluster to another based on load characteristics and configured policies. This JIRA will discuss some of the ideas and possible implementations of those ideas.
MAPREDUCE-1042,rumen should be able to output compressed trace files,"rumen is used primarily to create job trace files which are then processed by other tools.

These trace files can exceed 100 gigabytes.  However, gzip compression normally achieves 15:1 compression on these traces.

I would like to modify rumen so it can output compressed files directly, rather than outputting unwieldy uncompressed files and letting me compress it later."
MAPREDUCE-1041,TaskStatuses map in TaskInProgress should be made package private instead of protected,"MAPREDUCE-1028 made TaskStatuses protected. As Nigel pointed out in that Jira, making it package private would suffice."
MAPREDUCE-1039,cluster_setup.xml exists in both mapreduce and common projects,cluster_setup.xml exists in both mapreduce and common projects. And they already deviate because of HADOOP-6217 changes.
MAPREDUCE-1038,Mumak's compile-aspects target weaves aspects even though there are no changes to the Mumak's sources,"This is particularly time consuming and is the bottle neck even for a simple ant build. In the case where no files have been updated in Mumak, there is no reason to recompile sources along with the aspects. compile-aspects should skip this step in these cases."
MAPREDUCE-1037,Failing contrib unit tests should not halt the build,"As in other contrib projects, ( HADOOP-5457 ), failing unit tests should not prevent tests of subsequent modules from running."
MAPREDUCE-1036,An API Specification for Sqoop,"Over the last several months, Sqoop has evolved to a state that is functional and has room for extensions. Developing extensions requires a stable API and documentation. I am attaching to this ticket a description of Sqoop's design and internal APIs, which include some open questions. I would like to solicit input on the design regarding these open questions and standardize the API."
MAPREDUCE-1035,Remove streaming forrest documentation from the common project,A quick look reveals that the streaming documentation in common already reveals that it differs from that in the mapreduce project. We should resolve these differences and retain this documentation only in mapreduce.
MAPREDUCE-1033,Resolve location of scripts and configuration files after project split,"At present, all the sub-projects - common, hdfs and mapreduce - have copies of all the configuration files. Common configuration files should be left in common, mapreduce specific files should be moved to mapreduce project, same with hdfs related files."
MAPREDUCE-1031,ant tar target doens't seem to compile tests in contrib projects,ant tar shouldn't be skipping contrib tests.
MAPREDUCE-1030,Reduce tasks are getting starved in capacity scheduler,reduce tasks are getting starved in capacity scheduler. 
MAPREDUCE-1029,TestCopyFiles fails on testHftpAccessControl(),"Log :
Testcase: testHftpAccessControl took 2.692 sec
        FAILED
expected:<-3> but was:<-999>
junit.framework.AssertionFailedError: expected:<-3> but was:<-999>
        at org.apache.hadoop.tools.TestCopyFiles.testHftpAccessControl(TestCopyFiles.java:853)

"
MAPREDUCE-1028,"Cleanup tasks are scheduled using high memory configuration, leaving tasks in unassigned state.","A cleanup task is launched for a failed task of a job. This task is created based on the TIP of the failed task, and so is marked as requiring as many slots to run as the original task itself. For instance, if a high RAM job requires 2 slots per task, a cleanup task of the high RAM jobs requires 2 slots as well.

Further, a cleanup task is scheduled to a tasktracker by the jobtracker itself and not the scheduler. While doing so, the JT doesn't check if the TT has enough slots free to run a high RAM cleanup task - always assuming 1 slot is enough. Thus, a task is oversubscribed to the TT.

However, on the TT, before launch, we check that the task can actually run, and wait for so many slots to become available. If the slots don't get freed quickly, we will have tasks stuck in an unassigned state."
MAPREDUCE-1027,jobtracker.jsp can have an html text block for announcements by admins.,jobtracker.jsp is the first page for users of Map/Reduce clusters and can be used for sending information across to all users. It will be useful to have a text block on this page where administrators can put any latest notices/announcements time to time.
MAPREDUCE-1026,Shuffle should be secure,"Since the user's data is available via http from the TaskTrackers, we should require a job-specific secret to access it."
MAPREDUCE-1023,Newly introduced findBugs warnings should be suppressed,FindBugs warnings introduced by MAPREDUCE-711 and HADOOP-6230 should be suppressed by modifying src/test/findbugsExcludeFile.xml.
MAPREDUCE-1022,Trunk tests fail because of test-failure in Vertica,"ant test fails with
{code}
    [javac] /home/vinodkv/Workspace/eclipse-workspace/hadoop-mapreduce/src/contrib/vertica/src/test/org/apache/hadoop/vertica/TestVertica.java:43: cannot find symbol
    [javac] symbol  : class JobContextImpl
    [javac] location: package org.apache.hadoop.mapreduce
    [javac] import org.apache.hadoop.mapreduce.JobContextImpl;
    [javac]                                   ^
{code}"
MAPREDUCE-1021,mapred-default.xml does not document all framework config parameters,MAPREDUCE-849 renamed and categorized configuration keys. All the configuration keys should be documented with defaults in mapred-default.xml
MAPREDUCE-1019,Stale user directories left on TTs after MAPREDUCE-856,"MAPREDUCE-856 changed the directory structure of job files on the TT. As part of this, it introduced user directories under taskTracker subdirectory which contains private files of a user. The user directories are created on the TT when the user's first task is assigned to this TT. But these user-directories are never cleaned up from the TT, even when no task of this user is running on this TT. This essentially leaves empty user directories hanging around on the TT, whose number may increase over time.

This was originally intended to be fixed in MAPREDUCE-856, but could not be done because increasing complexity already stretched that issue."
MAPREDUCE-1018,Document changes to the memory management and scheduling model,"There were changes done for the configuration, monitoring and scheduling of high ram jobs. This must be documented in the mapred-defaults.xml and also on forrest documentation"
MAPREDUCE-1017,Compression and output splitting for Sqoop,"Sqoop ""direct mode"" writing will generate a single large text file in HDFS. It is important to be able to compress this data before it reaches HDFS. Due to the difficulty in splitting compressed files in HDFS for use by MapReduce jobs, data should also be split at compression time.
"
MAPREDUCE-1016,Make the format of the Job History be JSON instead of Avro binary,"I forgot that one of the features that would be nice is to off load the job history display from the JobTracker. That will be a lot easier, if the job history is stored in JSON. Therefore, I think we should change the storage now to prevent incompatibilities later."
MAPREDUCE-1015,Map-Reduce interface classification,HADOOP-5073 introduced the ability to classify apis wrt scope and stability. We should do a sweep over the Map-Reduce apis and classify them accordingly.
MAPREDUCE-1014,"After the 0.21 branch, MapReduce trunk doesn't compile","When ant is run, the build fails with compilation problems. The first of that is:
compile-mapred-classes:
  [taskdef] log4j:ERROR Could not instantiate class [org.apache.hadoop.metrics.jvm.EventCounter].
  [taskdef] java.lang.ClassNotFoundException: org.apache.hadoop.metrics.jvm.EventCounter
  [taskdef]     at org.apache.tools.ant.AntClassLoader.findClassInComponents(AntClassLoader.java:1383)
  [taskdef]     at org.apache.tools.ant.AntClassLoader.findClass(AntClassLoader.java:1324)
  [taskdef]     at org.apache.tools.ant.AntClassLoader.loadClass(AntClassLoader.java:1072)
  [taskdef]     at java.lang.ClassLoader.loadClass(ClassLoader.java:254)
  [taskdef]     at java.lang.ClassLoader.loadClassInternal(ClassLoader.java:402)
  [taskdef]     at java.lang.Class.forName0(Native Method)
  [taskdef]     at java.lang.Class.forName(Class.java:169)
  [taskdef]     at org.apache.log4j.helpers.Loader.loadClass(Loader.java:179)
  [taskdef]     at org.apache.log4j.helpers.OptionConverter.instantiateByClassName(OptionConverter.java:320)
  [taskdef]     at org.apache.log4j.helpers.OptionConverter.instantiateByKey(OptionConverter.java:121)
  [taskdef]     at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:664)
  [taskdef]     at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:647)
  [taskdef]     at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:544)
  [taskdef]     at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:440)
  [taskdef]     at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:476)"
MAPREDUCE-1013, MapReduce Project page does not show 0.20.1 documentation/release information.,"The MapReduce Project page shows the documentation for 0.20.0 even though the latest stable release version is 0.20.1. The releases page also shows all the pre 0.20.1 releases, but does not show 0.20.1 eventhough if you click on the ""Download a release now!"" link the mirror links are for hadoop/core."
MAPREDUCE-1012,Context interfaces should be Public Evolving,As discussed in MAPREDUCE-954 the nascent context interfaces should be marked as Public Evolving to facilitate future evolution.
MAPREDUCE-1011,Git and Subversion ignore of build.properties,"Currently ant test-patch can't use build.properties, because it counts as an non-pristine directory. I'll add build.properties to the subversion properties."
MAPREDUCE-1010,Adding tests for changes in archives.,Created this jira so that the tests can be added for HADOOP-6047. The test cases for hadoop archives are in mapreduce.
MAPREDUCE-1009,Forrest documentation needs to be updated to describes features provided for supporting hierarchical queues,Forrest documentation must be updated for describing how to set up and use hierarchical queues in the framework and the capacity scheduler.
MAPREDUCE-1007,MAPREDUCE-777 breaks the UI for hierarchial Queues. ,"
MAPREDUCE-777 breaks jobtracker UI for hierarchial queues. When jobtracker.jsp is accessed, it throws the following exception:

{code}
java.lang.NullPointerException
	at org.apache.hadoop.mapred.CapacityTaskScheduler.getJobs(CapacityTaskScheduler.java:1007)
	at org.apache.hadoop.mapred.JobTracker.getJobsFromQueue(JobTracker.java:3888)
	at org.apache.hadoop.mapred.JobTracker.getQueueInfoArray(JobTracker.java:3869)
	at org.apache.hadoop.mapred.JobTracker.getRootQueues(JobTracker.java:3830)
	at org.apache.hadoop.mapred.jobtracker_jsp.generateSummaryTable(jobtracker_jsp.java:36)
        .... 
{code}
(Issue number and the line number in code match - 1007. Some fun for a Hadoop developer :) )"
MAPREDUCE-1006,Making JobStoryProducer and ClusterStory pluggable in Mumak,Mumak should make JobStoryProducer and ClusterStory pluggable to enable it to simulate synthetic traces and cluster configurations.
MAPREDUCE-1005,why should not capacity sheduler jar not copied under lib during build,"Right now, the capacity-scheduler.jar is not getting copied under trunk/build/hadoop-mapred-0.21.0-dev/lib/. It stays in trunk/build/hadoop-mapred-0.21.0-dev/contrib/capacity-scheduler/hadoop-0.21.0-dev-capacity-scheduler.jar.  Every time somebody tries to build the trunk, they have to copy this jar from contrib to lib manually. 

During any kind of build (ant binary, ant bin-package, ant package) , this jar file should also get copied to lib. If a person uses default or fair sheduler, he will not use it, but still there is no harm of it being in lib. If he uses capacity scheduler, then it gets used automatically. This manual copy should be avoided.

"
MAPREDUCE-1004,ant binary does not  copy the jar files properly,"""ant binary"" does not copy the hadoop-mapred-examples-0.21.0-dev.jar, hadoop-mapred-test-0.21.0-dev.jar, hadoop-mapred-tools-0.21.0-dev.jar to the trunk/build/hadoop-mapred-0.21.0-dev directory and trunk/build/hadoop-mapred-0.21.0-dev /lib directory. 

It should get copied to both these directories."
MAPREDUCE-1003,trunk build fails when -Declipse.home is set,"compile:
     [echo] contrib: eclipse-plugin 
    [javac] Compiling 45 source files to /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/build/contrib/eclipse-plugin/classes
    [javac] /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopJob.java:54: constant expression required
    [javac]         case JobStatus.PREP:
    [javac]                       ^
    [javac] /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopJob.java:56: constant expression required
    [javac]         case JobStatus.RUNNING:
    [javac]                       ^
    [javac] /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopJob.java:58: constant expression required
    [javac]         case JobStatus.FAILED:
    [javac]                       ^
    [javac] /grid/0/hudson/hudson-slave/workspace/Mapreduce-Patch-h3.grid.sp2.yahoo.net/trunk/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopJob.java:60: constant expression required
    [javac]         case JobStatus.SUCCEEDED:
    [javac]                       ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] Note: Some input files use unchecked or unsafe operations.
    [javac] Note: Recompile with -Xlint:unchecked for details.
    [javac] 4 errors
"
MAPREDUCE-1002,"After MAPREDUCE-862, command line queue-list doesn't print any queues","Web-ui correctly prints the queues, it is the command line that is not showing any queues."
MAPREDUCE-1001,Reducing code duplication in Mumak,"The first release of Mumak (MAPREDUCE-728) introduces some coupling between the core mapred code with Mumak code. Specifically, New constructors are added to JobTracker and JobInProgress to allow simulator to subclass and alter JT/JIP behavior. This could be a code maintenance overhead when new changes have to be ported to either the added constructors or the simulation subclasses.

It would be nice to refactor the constructors of JobTracker and JobInProgress to avoid as much code duplication as possible."
MAPREDUCE-1000,JobHistory.initDone() should retain the try ... catch in the body,
MAPREDUCE-999,Improve Sqoop test speed and refactor tests,"Sqoop's tests take a long time to run, but this can be improved (by a factor of 2 or more) by taking advantage of {{jobclient.completion.poll.interval}}."
MAPREDUCE-998,Wrong error message thrown when we try submit to container queue.,"Setup have multilevel queue.
parent queues a,b and has two child queues a11, a12. If we try sub queue ""a"" the following error is thrown -"":
[
org.apache.hadoop.ipc.RemoteException: java.io.IOException: Queue ""a"" does not exist
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:2758)
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:2740)

]
where it should have proper like user cannot submit job to container queue.
"
MAPREDUCE-997,Acls are not working properly when they are set to user groups,"When submit-job-acl set usergroup (ug1).
if user submits a using hadoop.job.ugi=u1,ug2 it is also gets accepted. (user u1 is also part ug1).
In hadoop 0.20.0, job gets rejected. Its a regression issue."
MAPREDUCE-996,Queue Scheduling Information is lost from Ui when we run mapred mradmin -refreshQueues after mapreduce 861,
MAPREDUCE-995,JobHistory should handle cases where task completion events are generated after job completion event,"It is apparently possible, in certain circumstances (failed job, for example), for the job history to get task completion events after the job completion event. This currently causes NPE in job history.
Thanks Hong for identifying this issue"
MAPREDUCE-994,bin/hadoop job -counter help options do not give information on permissible values.,"Right now,  bin/hadoop job -counter  gives this output

bin/hadoop job -counter 
DEPRECATED: Use of this script to execute mapred command is deprecated.
Instead use the mapred command for it.

Usage: CLI [-counter <job-id> <group-name> <counter-name>]

What are these group names and what are the counter-names is not explained. All permissible values of group-name> and <counter-name> should be specified.

Group_name Ex: 
org.apache.hadoop.mapreduce.TaskCounter 

Counter name example:
REDUCE_INPUT_RECORDS
"
MAPREDUCE-993,bin/hadoop job -events <jobid> <from-event-#> <#-of-events> help message is confusing,More explanation needs to be there like a) events always start from 1 b) the message could be like <from-event-number> <to-event-number> where <from-event-number> starts from 1. This will give teh end user idea as to what to enter.
MAPREDUCE-992,bin/hadoop job -events < jobid> gives event links which does not work.,"
 bin/hadoop job -events job_200909170448_0009 1 10000
DEPRECATED: Use of this script to execute mapred command is deprecated.
Instead use the mapred command for it.

Task completion events for job_200909170448_0009
Number of events (from 1) are: 1
SUCCEEDED attempt_200909170448_0009_m_000000_0 http://<machineName FQDN>:50060/tasklog?plaintext=true&taskid=attempt_200909170448_0009_m_000000_0


This link does not work. If it is put ina browser, it gives error saying "" HTTP ERROR: 400

You must supply a value for `filter' (STDOUT, STDERR, or SYSLOG) if you set plainText = true

RequestURI=/tasklog""

These links should work properly.
"
MAPREDUCE-991,HadoopPipes.cc doesn't compile cleanly with SunStudio,"Attempting to compile HadoopPipes.cc throws the following warnings and errors:

{noformat}
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 663: Warning: protocol hides HadoopPipes::TaskContextImpl::protocol.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 844: Warning: status hides HadoopPipes::TaskContextImpl::status.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 871: Warning: key hides HadoopPipes::TaskContextImpl::key.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 871: Warning: value hides HadoopPipes::TaskContextImpl::value.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 943: Error: The function ""sleep"" must have a prototype.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 961: Error: The function ""close"" must have a prototype.
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 1037: Warning (Anachronism): Formal argument 3 of type extern ""C"" void*(*)(void*) in call to pthread_create(unsigned*, const _pthread_attr*, extern ""C"" void*(*)(void*), void*) is being passed void*(*)(void*).
     [exec] ""/export/home/awittena/src/hadoop-0.20.0/src/c++/pipes/impl/HadoopPipes.cc"", line 1057: Error: The function ""close"" must have a prototype.
{noformat}"
MAPREDUCE-988,ant package does not copy the capacity-scheduler.jar under HADOOP_HOME/build/hadoop-mapred-0.21.0-dev/contrib/capacity-scheduler,"ant package does not copy the hadoop-0.21.0-dev-capacity-scheduler.jar under HADOOP_HOME/build/hadoop-mapred-0.21.0-dev/contrib/capacity-scheduler/.

Till yesterday it was copying it properly. Issue seems to be pointing to the latest checkin of  MAPREDUCE-776, which changes build.xml."
MAPREDUCE-987,Exposing MiniDFS and MiniMR clusters as a single process command-line,"It's hard to test non-Java programs that rely on significant mapreduce functionality.  The patch I'm proposing shortly will let you just type ""bin/hadoop jar hadoop-hdfs-hdfswithmr-test.jar minicluster"" to start a cluster (internally, it's using Mini{MR,HDFS}Cluster) with a specified number of daemons, etc.  A test that checks how some external process interacts with Hadoop might start minicluster as a subprocess, run through its thing, and then simply kill the java subprocess.

I've been using just such a system for a couple of weeks, and I like it.  It's significantly easier than developing a lot of scripts to start a pseudo-distributed cluster, and then clean up after it.  I figure others might find it useful as well.

I'm at a bit of a loss as to where to put it in 0.21.  hdfs-with-mr tests have all the required libraries, so I've put it there.  I could conceivably split this into ""minimr"" and ""minihdfs"", but it's specifically the fact that they're configured to talk to each other that I like about having them together.  And one JVM is better than two for my test programs."
MAPREDUCE-986,rumen makes a task with a null type when one of the task lines is truncated,"Rumen was used to produce a job trace, but the job trace contained a LoggedTask that had a null taskType.  This appears to happen when a Task line is truncated.

We should not put the LoggedTask in the trace at all when this happens."
MAPREDUCE-985,job -kill-task <task-id>] and -fail-task <task-id> are not task-ids they are attempt ids,"Right now, bin/hadoop job show soptions as 

-kill-task <task-id> and 
-fail-task <taskid>

These two are confusing as task attempt id and not task ids should be provioded to kill them.

These help messages have to be changed.

"
MAPREDUCE-984,"bin/hadoop job -kill command says"" job successfully killed"" even though job has retired.","After bringing up the cluster, run a command, allow it to finish and move to retired folder. Now try killing the job with ""bin/hadoop job -kill <job_id>"" . It says successfully killed. The message should be . Unable to kill <jobid>"
MAPREDUCE-983,bin/hadoop job -fs file:///sdsdad -list still works,"After bringing up the cluster with latest trunk, if ""bin/hadoop job -fs file:///sdsdad -list"" command is issued, it still displays the previous filesystem that is present in conf and does not take the new fs.

It should pickup the command line fs, overriding any other parameter."
MAPREDUCE-982,Deprecated DistributedCache still used in the new apis in org.apache.hadoop.mapreduce package,"Deprecated DistributedCache still used in the new apis in org.apache.hadoop.mapreduce package e.g. JobContext, we should fix it."
MAPREDUCE-980,Modify JobHistory to use Avro for serialization instead of raw JSON,MAPREDUCE-157 modifies JobHistory to log events using Json Format.  This can be modified to use Avro instead. 
MAPREDUCE-979,JobConf.getMemoryFor{Map|Reduce}Task doesn't fallback to newer config knobs when mapred.taskmaxvmem is set to DISABLED_MEMORY_LIMIT of -1,"JobConf.getMemoryFor{Map|Reduce}Task doesn't fallback to newer config knobs when mapred.taskmaxvmem is set to DISABLED_MEMORY_LIMIT of -1, this results in failed job-submissions when mapred-default.xml has the default value of -1."
MAPREDUCE-978,-file option in streaming does not preserve execute permissions,"For a streaming application I used the -file option to move some executable files to the slave nodes.  On the submit node, they had +x permissions but on the destination node they were created with -x permissions.  This probably has to do with the umask settings on the various nodes, but streaming should preserve the original permissions."
MAPREDUCE-977,Missing jackson jars from Eclipse template,
MAPREDUCE-976,LinuxTaskController binary should be versioned and mapreduce should run only with a particular version,There is a strict coupling between the mapreduce code and the LinuxTaskController binary that it runs. Accidentally/intentionally running different versions of the binary with different versions of the framework may lead to hard-to-debug problems. We should have checks similar to JT-TT version lock-in.
MAPREDUCE-975,Add an API in job client to get the history file url for a given job id,"MAPREDUCE-817 added an API to get history url in RunningJob. Similar API should be added in job client to get the history file given a job id. Something like:
String getHistoryFile(JobId jobid);"
MAPREDUCE-974,"CLI command for viewing tasktrackers should not be under ""job""","For viewing the tasktrackers in a mr cluster the command available is ""./bin/hadoop job -list-tracker"". But the tracker info is cluster level info and not job level. "
MAPREDUCE-973,Move test utilities from examples to test,"The FailJob class (MAPREDUCE-567) is more a test utility than an example. It should either move to src/test, ideally with a unit test built around it, or be removed. Similarly, SleepJob class is mostly used in unit tests."
MAPREDUCE-972,distcp can timeout during rename operation to s3,"rename() in S3 is implemented as copy + delete. The S3 copy operation can perform very slowly, which may cause task timeout."
MAPREDUCE-971,distcp does not always remove distcp.tmp.dir,Sometimes distcp leaves behind its tmpdir when the target filesystem is s3n.
MAPREDUCE-970,task-controller/configuration.c:get_values is broken,"task-controller/configuration.c:get_values is supposed to return a char** with the last element set to NULL.

It doesn't correctly handle empty config-values, #values as an exactly multiple of MAX_SIZE."
MAPREDUCE-969,NullPointerException during reduce freezes job,"We experienced several jobs stuck in Reduce on a cluster. All of the stuck reduce tasks had a similar were stuck at ""Need another 2 map output(s) where 0 is already in progress"" despite all of the mappers having completed, and 0 scheduled. The stuck reducers had experienced the following exception early in the shuffle:

java.lang.NullPointerException
	at java.util.concurrent.ConcurrentHashMap.get(ConcurrentHashMap.java:768)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$GetMapEventsThread.getMapCompletionEvents(ReduceTask.java:2747)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$GetMapEventsThread.run(ReduceTask.java:2670)

Will attach more information and logs momentarily."
MAPREDUCE-968,NPE in distcp encountered when placing _logs directory on S3FileSystem,"If distcp is pointed to an empty S3 bucket as the destination for an s3:// filesystem transfer, it will fail with the following exception

Copy failed: java.lang.NullPointerException
at org.apache.hadoop.fs.s3.S3FileSystem.makeAbsolute(S3FileSystem.java:121)
at org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:332)
at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:633)
at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1005)
at org.apache.hadoop.tools.DistCp.copy(DistCp.java:650)
at org.apache.hadoop.tools.DistCp.run(DistCp.java:857)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
at org.apache.hadoop.tools.DistCp.main(DistCp.java:884) "
MAPREDUCE-967,TaskTracker does not need to fully unjar job jars,"In practice we have seen some users submitting job jars that consist of 10,000+ classes. Unpacking these jars into mapred.local.dir and then cleaning up after them has a significant cost (both in wall clock and in unnecessary heavy disk utilization). This cost can be easily avoided"
MAPREDUCE-966,Rumen interface improvement,Rumen could expose a cleaner interface to simplify the integration with other tools.
MAPREDUCE-965,LinuxTaskController logs some of the errors during initializeJob/initializeTask at INFO level instead of WARN/ERROR.,WARN/ERROR level will make the problem more conspicuous.
MAPREDUCE-964,Inaccurate values in jobSummary logs,"For some jobs the mapSlotSeconds is incorrect.

negative value

09/09/01 18:31:44 INFOmapred.JobInProgress$JobSummary: jobId=job_200908270718_4568,submitTime=1251823543976,launchTime=1251823554310,finishTime=1251829904565,            numMaps=7965,numSlotsPerMap=1,numReduces=40,numSlotsPerReduce=1,user=wile,queue=runner,status=SUCCEEDED,         mapSlotSeconds=-2503133523,reduceSlotsSeconds=186536,clusterMapCapacity=11262,clusterReduceCapacity=3754

or too high

09/09/02 23:59:57 INFO mapred.JobInProgress$JobSummary: jobId=job_200908270718_5861,submitTime=1251935672924,launchTime=1251935687698,finishTime=1251935997949,            numMaps=1026,numSlotsPerMap=1,numReduces=10,numSlotsPerReduce=1,user=dfsload,queue=gridops,status=SUCCEEDED,         
mapSlotSeconds=1251949742,reduceSlotsSeconds=537,clusterMapCapacity=11262,clusterReduceCapacity=3754

"
MAPREDUCE-963,mapred's FileAlreadyExistsException should be deprecated in favor of hadoop-common's one.,"We should use org.apache.hadoop.fs.FileAlreadyExistsException instead of org.apache.hadoop.mapred.FileAlreadyExistsException.
Mapred's one should be deprecated."
MAPREDUCE-962,NPE in ProcfsBasedProcessTree.destroy(),"This causes the following exception in TaskMemoryManagerThread. I observed this while running TestTaskTrackerMemoryManager.
{code}
2009-09-02 12:08:25,835 WARN  mapred.TaskMemoryManagerThread (TaskMemoryManagerThread.java:run(239)) - \
            Uncaught exception in TaskMemoryManager while managing memory of attempt_20090902120812252_0001_m_000003_0 : \
java.lang.NullPointerException
        at org.apache.hadoop.util.ProcfsBasedProcessTree.assertPidPgrpidForMatch(ProcfsBasedProcessTree.java:234)
        at org.apache.hadoop.util.ProcfsBasedProcessTree.assertAndDestroyProcessGroup(ProcfsBasedProcessTree.java:257)
        at org.apache.hadoop.util.ProcfsBasedProcessTree.destroy(ProcfsBasedProcessTree.java:286)
        at org.apache.hadoop.mapred.TaskMemoryManagerThread.run(TaskMemoryManagerThread.java:229)
{code}"
MAPREDUCE-960,Unnecessary copy in mapreduce.lib.input.KeyValueLineRecordReader,"KeyValueLineRecordReader effects the copy from the line to the key/value by creating separate arrays:
{noformat}
      int keyLen = pos;
      byte[] keyBytes = new byte[keyLen];
      System.arraycopy(line, 0, keyBytes, 0, keyLen);
      int valLen = lineLen - keyLen - 1;
      byte[] valBytes = new byte[valLen];
      System.arraycopy(line, pos + 1, valBytes, 0, valLen);
      key.set(keyBytes);
      value.set(valBytes);
{noformat}
Since set triggers another copy and Text has a set taking {{byte[], off, len}}, the intermediate copy can be avoided"
MAPREDUCE-958,TT should bail out early when mapred.job.tracker is bound to 0:0:0:0,"It's OK for your job tracker's config to tells the JobTracker to come up on port 0:0:0:0, but its not OK for the TaskTrackers to get the same mapred.job.tracker configuration value, as it stops the TT from being able to report its heartbeat.

This misconfiguration surfaces in the TT's {{offerService()}} routine catching and logging a ConnectionRefused exception every time it tries to heartbeat. Now we have improved the error message in such a situation, it is still a bit late in the process to encounter a problem which should be obvious the moment the TT looks at its configuration.


Better to have the TT refuse to start up if {{jobTrackAddr.getAddress().isAnyLocalAddress()}}. "
MAPREDUCE-957,Set mapred.job.name for a pipes job,Currently mapred.job.name is not set for a pipes job. It will be useful if this value is set when a pipes job is submitted.
MAPREDUCE-954,The new interface's Context objects should be interfaces,"When I was doing HADOOP-1230, I was persuaded to make the Context objects as classes. I think that was a serious mistake. It caused a lot of information leakage into the public classes."
MAPREDUCE-953,Generate configuration dump for hierarchial queue configuration,Generate configuration dump for hierarchial queue configuration
MAPREDUCE-952,Previously removed Task.Counter reintroduced by MAPREDUCE-318,"HADOOP-5717 introduced org.apache.hadoop.mapreduce.TaskCounters in-lieu of the older org.apache.hadoop.mapred.Task.Counter (see http://tinyurl.com/m4uwgj for the patch). However, MAPREDUCE-318 seems to have accidentally re-introduced it."
MAPREDUCE-951,MAP_INPUT_BYTES counter is missing,"Looks we lost it during one of the merges during project split: 
http://svn.apache.org/viewvc/hadoop/mapreduce/trunk/src/java/org/apache/hadoop/mapreduce/TaskCounter.java?r1=776174&r2=785392&diff_format=h"
MAPREDUCE-949,FileSplit still used by TextInputFormat,"Even though FileSplit is deprecated, TextInputFormat still uses it"
MAPREDUCE-948,FileOutputCommitter should create a _DONE file for successful jobs,Oozie and other workflow systems could use a _DONE file (zero-length) to poll for job-completion to be used as input-availability triggers.
MAPREDUCE-947,OutputCommitter should have an abortJob method,"The OutputCommitter needs an abortJob method to clean up from failed jobs. Currently there is no way to distinguish between failed or succeeded jobs, making it impossible to write output promotion code."
MAPREDUCE-946,Fix regression in LineRecordReader to comply with line length parameters,MAPREDUCE-773 accidentally changed code introduced in HADOOP-3144 controlling max line lengths. The behavior should be restored.
MAPREDUCE-945,Test programs support only default queue.,None of the test program seems to be supporting queue's concept. These programs looks for the default queue only even if some other queue is specified to run these programs.
MAPREDUCE-944,Extend FairShare scheduler to fair-share memory usage in the cluster,"The FairShare Scheduler has an extensible LoadManager API to regulate allocating new tasks on a particular TaskTracker. In similar lines, it would be nice if the FairShare Scheduler can have a pluggable policy to regulate new tasks from a particular job. This will allow one to skip scheduling tasks of a job that  is eating a large percentage of memory in the cluster, i.e. fair-share of memory resources among jobs. 
"
MAPREDUCE-943,TestNodeRefresh timesout occasionally,"TestNodeRefresh timesout occasionally.
One of the hudson patch build with timeout @http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-h6.grid.sp2.yahoo.net/26/testReport/org.apache.hadoop.mapred/TestNodeRefresh/testMRExcludeHostsAcrossRestarts/"
MAPREDUCE-942,job history logs should have a sane extension,"It is not obvious by looking at:

hostname_1251411205412_job_200908271513_0010_DrWho_hadoop-0.20.0-test.jar

that this is a job history log file rather than a jar file."
MAPREDUCE-941,vaidya script calls awk instead of nawk,"The vaidya script uses this construction:

awk 'BEGIN { RS = """" ; FS = ""\n"" } ; { print $1 }'

Under ""old awk"", this fails.  Under ""new awk"", this works.  Depending upon the OS, awk may point to either old or new awk.  In the Solaris case, awk defaults to oawk."
MAPREDUCE-940,Distcp should not use mapred.system.dir,"Distcp uses mapred.system.dir to create files like _distcp_src_files, _distcp_dst_files, etc. Since MAPREDUCE-181 is removing exposing of mapred.stystem.dir, distcp needs to use something like homeDir/.staging/  instead of mapred.system.dir. Please see the patch of MAPREDUCE-181 for more details."
MAPREDUCE-938,Postgresql support for Sqoop,Sqoop should be able to import from postgresql databases.
MAPREDUCE-937,Allow comments in mapred.hosts and mapred.hosts.exclude files,It will be useful to have comments in the mapred.hosts and mapred.hosts.exclude files that will give description to hosts in there and to the file itself so different people maintaining these files will be able to share certain information about the process and hosts.
MAPREDUCE-936,Allow a load difference in fairshare scheduler,"The problem we are facing: It takes a long time for all tasks of a job to get scheduled on the cluster, even if the cluster is almost empty.

There are two reasons that together lead to this situation:
1. The load factor makes sure each TT runs the same number of tasks. (This is the part that this patch tries to change).

2. The scheduler tries to schedule map tasks locally (first node-local, then rack-local). There is a wait time (mapred.fairscheduler.localitywait.node and mapred.fairscheduler.localitywait.rack, both are around 10 sec in our conf), and accumulated wait time (JobInfo.localityWait). The accumulated wait time is reset to 0 whenever a non-local map task is scheduled. That means it takes N * wait_time to schedule N non-local map tasks.

Because of 1, a lot of TT will not be able to take more tasks, even if they have free slots. As a result, a lot of the map tasks cannot be scheduled locally.

Because of 2, it's really hard to schedule a non-local task.

As a result, sometimes we are seeing that it takes more than 2 minutes to schedule all the mappers of a job.
"
MAPREDUCE-931,rumen should use its own interpolation classes to create runtimes for simulated tasks,"Currently, when a simulator or benchmark is running and simulating hadoop jobs using rumen data, and rumen's runtime system is used to get execution times for the tasks in the simulated jobs, rumen would use some ad hoc code, despite the fact that rumen has a perfectly good interpolation framework to generate random variables that fit discrete CDFs.

We should use the interpolation framework."
MAPREDUCE-930,"rumen should interpret job history log input paths with respect to default FS, not local FS",This allows job history log file/directory names that don't specify a file system to use the configured default FS instead of the local FS [when the configured default is not the local].
MAPREDUCE-928,JobTracker startup can get confused if the mapred system dir isn't there,"I'm seeing this in my branch, the JobTracker is catching and ignoring a FileNotFoundException when it tries to delete a nonexistent system dir"
MAPREDUCE-927,Cleanup of task-logs should happen in TaskTracker instead of the Child,"Task logs' cleanup is being done in Child now. This is undesirable atleast for two reasons: 1) failures while cleaning up will affect the user's tasks, and 2) the task's wall time will get affected due to operations that TT actually should own."
MAPREDUCE-926,History viewer on web UI should filter by job-id also,"Job-id is the most famous handle to a job and there should be easier ways of hunting down a job from the history web viewer. Currently, filtering is supported to be based on job name and job owner's name. Job-id is a necessary addition to the list of filters."
MAPREDUCE-925,Not able to run parallel instances of ant tests,"Not able to execute two or more parallel instances of ant test.

Scenario:
=======
Executed  ""TestRecoveryManager"" in a loop for 100 times and ran some other tests in parallel. Encountered following error message in TestRecoveryManager logs:
[junit] 2009-08-27 10:53:48,724 INFO  mapred.TaskTracker (TaskTracker.java:tryToGetOutputSize(1594)) - org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/<job-id>/<attempt-id>/output/file.out in any of the configured local directories

It seems that new ant test removes the existing mapred local directory itself  and recreates it for current test.

"
MAPREDUCE-924,TestPipes must not directly invoke 'main' of pipes as an exit from main could cause the testcase to crash.,"TestPipes invokes the main method of the program running pipes. In MAPREDUCE-421, a change was made to the Pipes command runner to invoke System.exit after completion. This itself is a valid change because the pipes command runner is in itself a user facing program. But when combined with a testcase, it causes the testcase to crash rather than providing feedback on whether the test ran correctly or not.

The testcase should be modified to use Tool instead of running main directly."
MAPREDUCE-923,"Sqoop's ORM uses URLDecoder on a file, which replaces plus signs in a jar file name with spaces","In findThisJar, sqoop runs URLDecoder.decode on the resulting jar, which has the effect of replacing any + signs in the path with a space.  This obviously breaks the classpath variable that it's trying to set, and the sqoop-generated code fails to compile.  Ironically, Cloudera's hadoop distro is the one that puts + characters in jar files, and so exhibits the bug.  Here is an example from running sqoop with log4j at debug level.  Note the space in the very last term, which should read hadoop-0.20.0+61-sqoop.jar rather than hadoop-0.20.0 61-sqoop.jar.

09/08/27 18:00:07 DEBUG orm.CompilationManager: Invoking javac with args: -sourcepath ./ -d /tmp/sqoop/compile/ -classpath /usr/lib/hadoop-0.20/conf:/usr/java/jdk1.6.0_06/lib/tools.jar:/usr/lib/hadoop-0.20:/usr/lib/hadoop-0.20/hadoop-0.20.0+61-core.jar:/usr/lib/hadoop-0.20/lib/commons-cli-2.0-SNAPSHOT.jar:/usr/lib/hadoop-0.20/lib/commons-codec-1.3.jar:/usr/lib/hadoop-0.20/lib/commons-el-1.0.jar:/usr/lib/hadoop-0.20/lib/commons-httpclient-3.0.1.jar:/usr/lib/hadoop-0.20/lib/commons-logging-1.0.4.jar:/usr/lib/hadoop-0.20/lib/commons-logging-api-1.0.4.jar:/usr/lib/hadoop-0.20/lib/commons-net-1.4.1.jar:/usr/lib/hadoop-0.20/lib/core-3.1.1.jar:/usr/lib/hadoop-0.20/lib/hadoop-0.20.0+61-fairscheduler.jar:/usr/lib/hadoop-0.20/lib/hadoop-0.20.0+61-scribe-log4j.jar:/usr/lib/hadoop-0.20/lib/hsqldb-1.8.0.10.jar:/usr/lib/hadoop-0.20/lib/hsqldb.jar:/usr/lib/hadoop-0.20/lib/jasper-compiler-5.5.12.jar:/usr/lib/hadoop-0.20/lib/jasper-runtime-5.5.12.jar:/usr/lib/hadoop-0.20/lib/jets3t-0.6.1.jar:/usr/lib/hadoop-0.20/lib/jetty-6.1.14.jar:/usr/lib/hadoop-0.20/lib/jetty-util-6.1.14.jar:/usr/lib/hadoop-0.20/lib/junit-3.8.1.jar:/usr/lib/hadoop-0.20/lib/junit-4.5.jar:/usr/lib/hadoop-0.20/lib/kfs-0.2.2.jar:/usr/lib/hadoop-0.20/lib/libfb303.jar:/usr/lib/hadoop-0.20/lib/libthrift.jar:/usr/lib/hadoop-0.20/lib/log4j-1.2.15.jar:/usr/lib/hadoop-0.20/lib/mysql-connector-java-5.0.8-bin.jar:/usr/lib/hadoop-0.20/lib/oro-2.0.8.jar:/usr/lib/hadoop-0.20/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hadoop-0.20/lib/slf4j-api-1.4.3.jar:/usr/lib/hadoop-0.20/lib/slf4j-log4j12-1.4.3.jar:/usr/lib/hadoop-0.20/lib/xmlenc-0.52.jar:/usr/lib/hadoop-0.20/lib/jsp-2.1/jsp-2.1.jar:/usr/lib/hadoop-0.20/lib/jsp-2.1/jsp-api-2.1.jar:/usr/local/hadoop/lib/hadoop-gpl-compression.jar:/usr/lib/hadoop-0.20/hadoop-0.20.0+61-core.jar:/usr/lib/hadoop-0.20/contrib/sqoop/hadoop-0.20.0 61-sqoop.jar"
MAPREDUCE-922,Automatic configuration of number of map and reduce slots based on available resources for dealing with heterogenous clusters,"Currently the number of map and reduce slots have to be configured manually, which is reasonable for homogeneous clusters. However, as the clusters start to change over time it becomes rather painful to administer and configure. We should start thinking along the direction of auto-magically configuring the slots based on available resources on the node such as RAM, CPU, disk etc. "
MAPREDUCE-921,Map-Reduce framework should gracefully handle heterogenous clusters,"Currently several parts of the framework: components, configuration etc. implicitly assume uniformity of the cluster. 

This jira is meant to be a meta-issue to track various improvements necessary to handle heterogenous clusters."
MAPREDUCE-920,Add jvm params introduced in MAPREDUCE-478 to mapred-default.xml,"mapred-default.xml still provides definition for old params which were deprecated in MAPREDUCE:478. It should be changed to define the new params such as  mapred.map.child.java.opts, mapred.reduce.child.java.opts, mapred.map.child.env, mapred.reduce.child.env, mapred.map.child.ulimit,  mapred.reduce.child.ulimit.

"
MAPREDUCE-918,Test hsqldb server should be memory-only.,"Sqoop launches a standalone hsqldb server for unit tests, but it currently writes its database to disk and uses a connect string of {{//localhost}}. If multiple test instances are running concurrently, one test server may serve to the other instance of the unit tests, causing race conditions."
MAPREDUCE-917,Remove getInputCounter and getOutputCounter from Contexts,The getInputCounter and getOutputCounter methods need to be removed from the new mapreduce APIs.
MAPREDUCE-916,Hadoop Doc Split: MapReduce Docs,"Hadoop Doc Split: MapReduce Docs

Please note that I am unable to directly check all of the new links. Some links may break and will need to be updated."
MAPREDUCE-915,"For secure environments, the Map/Reduce debug script must be run as the user.","The Taskcontroller model allows admins to set up a cluster configuration that runs tasks as users. The debug script feature of Map/Reduce provided by the configuration options: mapred.map.task.debug.script and mapred.reduce.task.debug.script need to be run as the user as well in such environments, rather than as the tasktracker user."
MAPREDUCE-914,MapReduce source code has significant number of JavaDocs errors and warnings,
MAPREDUCE-913,"TaskRunner crashes with NPE resulting in held up slots, UNINITIALIZED tasks and hung TaskTracker",
MAPREDUCE-912,apache license header missing for some java files,"The following files do not have apache license header :
src/java/org/apache/hadoop/mapred/lib/db/DBWritable.java
src/java/org/apache/hadoop/mapreduce/Counters.java
src/test/mapred/org/apache/hadoop/mapred/lib/db/TestConstructQuery.java
src/examples/org/apache/hadoop/examples/WordCount.java"
MAPREDUCE-911,TestTaskFail fail sometimes,"TestTaskFail  fail sometimes with following error :
junit.framework.AssertionFailedError
	at org.apache.hadoop.mapred.TestTaskFail.validateJob(TestTaskFail.java:136)
	at org.apache.hadoop.mapred.TestTaskFail.testWithDFS(TestTaskFail.java:181)"
MAPREDUCE-910,MRUnit should support counters,incrCounter() is currently a dummy stub method in MRUnit that does nothing. Would be good for the mock reporter/context implementations to support counters.
MAPREDUCE-909,Shell$ExitCodeException while killing/failing a task.,"Encountered ""Shell$ExitCodeException"" in TT logs while killing/failing a job on 0.20.1

Stack Trace:
=========
2009-08-22 16:37:05,867 INFO org.apache.hadoop.mapred.TaskTracker: About to purge task: attempt_200908200732_0541_m_000003_1
2009-08-22 16:37:06,030 WARN org.apache.hadoop.mapred.LinuxTaskController: Exception thrown while launching task JVM : org.apache.hadoop.util.Shell$ExitCodeException:
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:245)
        at org.apache.hadoop.util.Shell.run(Shell.java:172)
        at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:365)
        at org.apache.hadoop.mapred.LinuxTaskController.launchTaskJVM(LinuxTaskController.java:156)
        at org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.runChild(JvmManager.java:397)
        at org.apache.hadoop.mapred.JvmManager$JvmManagerForType$JvmRunner.run(JvmManager.java:386)

2009-08-22 16:37:06,030 WARN org.apache.hadoop.mapred.LinuxTaskController: Exit code from task is : 143
"
MAPREDUCE-908,Defining test.include to run a subset of unit tests no longer works,"The test.include property used to be a convenient way to glob tests, e.g. {{ant -Dtest.include='foo/bar/Test*' test}} used to run all the tests in the {{foo/bar}} package. This no longer works."
MAPREDUCE-907,Sqoop should use more intelligent splits,Sqoop should use the new split generation / InputFormat in MAPREDUCE-885
MAPREDUCE-906,Updated Sqoop documentation,"Here's the latest documentation for Sqoop, in both user-guide and manpage form. Built with asciidoc."
MAPREDUCE-905,Add Eclipse launch tasks for MapReduce,"This is a revival of HADOOP-5911, but only for the MR project.

Eclipse has a notion of ""run configuration"", which encapsulates what's needed to run or debug an application. I use this quite a bit to start various Hadoop daemons in debug mode, with breakpoints set, to inspect state and what not.

This is simply configuration, so no tests are provided.  After running ""ant eclipse-files"" and refreshing your project, you should see entries in the ""Run"" pulldown.  There's a template for testing a specific test, and also templates to run all the tests, the job tracker, and a task tracker.  It's likely that some parameters need to be further tweaked to have the same behavior as ""ant test"", but for most tests, this works."
MAPREDUCE-903,Adding AVRO jar to eclipse classpath,"Avro is missing from the eclipse classpath, which caused Eclipse to whine.  Easy fix."
MAPREDUCE-902,Map output merge still uses unnecessary seeks,"HADOOP-3638 improved the merge of the map output by caching the index files.

But why not also caching the data files?

In our use-case scenario, still using hadoop-0.18.3, but HADOOP-3638 would only help partially, an individual map tasks finishes in less than 30 minutes, but needs 4 hours to merge 70 spills for 20,000 partitions (with lzo compression), reading about 10kB from each spill file (which is re-opened for every partition). As this is just a merge sort, there is no reason to not keep the input files open and eliminate seek altogether with sequential access."
MAPREDUCE-901,Move Framework Counters into a TaskMetric structure,"I think we should move all of the Counters that the framework updates into a single class called TaskMetrics. TaskMetrics would have specific fields for each of the metrics like input records, input bytes, output records, etc.

It would both reduce the serialized size of the heartbeats (by shrinking the Counters down to just the user's counters) and decrease the latency for updates to the JobTracker (since Counters are sent at most 1/minute instead of 1/heartbeat)."
MAPREDUCE-900,Proposed enhancements/tuning to hadoop-mapred/build.xml,"sibling list of HADOOP-6206 and HDFS-560, enhancements to the mapreduce build for easier single-system build/test"
MAPREDUCE-899,"When using LinuxTaskController, localized files may become accessible to unintended users if permissions are misconfigured.","To enforce the accessibility of job files to only the job-owner and the TaskTracker, as per MAPREDUCE-842, it is _trusted_ that the  setuid/setgid linux TaskController binary is group owned by a _special group_ to which only TaskTracker belongs and not just any group to which TT belongs. If the trust is broken, possibly due to misconfiguration by admins, the local files become accessible to unintended users, yet giving false sense of security to the admins."
MAPREDUCE-898,Change DistributedCache to use new api.,
MAPREDUCE-897,Provide information captured as part of JobTrackerStatistics via the Hadoop metrics API,"MAPREDUCE-467 introduced a framework to collect statistics per node on a fixed set of intervals. Presently there is support for collecting statistics related to number of task failures and also health check script failures per hour, day and since start of system. It is felt that this information can be made available via the tasktracker's metrics system as well."
MAPREDUCE-896,Users can set non-writable permissions on temporary files for TT and can abuse disk usage.,"As of now, irrespective of the TaskController in use, TT itself does a full delete on local files created by itself or job tasks. This step, depending upon TT's umask and the permissions set by files by the user, for e.g in job-work/task-work or child.tmp directories, may or may not go through successful completion fully. Thus is left an opportunity for abusing disk space usage either accidentally or intentionally by TT/users."
MAPREDUCE-895,"FileSystem::ListStatus will now throw FileNotFoundException, MapRed needs updated","HADOOP-6201 (and HDFS-538) determined the semantics of FileSystem::ListStatus is not correct and that the actual file system class vary in their implemenations, with some throwing an exception and some returning null.  Fixing this will require adjusting code that calls this method. "
MAPREDUCE-893,Provide an ability to refresh queue configuration without restart.,"While administering a cluster using multiple queues, administrators feel a need to refresh queue properties on the fly without needing to restart the JobTracker. This is partially supported for some properties such as queue ACLs (HADOOP-5396) and state (HADOOP-5913). The idea is to extend the facility to refresh other queue properties as well, including scheduler properties."
MAPREDUCE-892,command line tool to list all tasktrackers and their status,"The ""hadoop mradmin -report"" could list all the tasktrackers that the JobTracker knows about. It will also list a brief status summary for each of the TaskTracker. (This is similar to the hadop dfsadmin -report command that lists all Datanodes)"
MAPREDUCE-891,Streaming tests fail with NPE in MiniDFSCluster,"Streaming testcases' usage of MiniDFSCluster.startDatanodes causes NPE in GenericOptionsParser:

{noformat}
java.lang.NullPointerException
	at org.apache.commons.cli.GnuParser.flatten(GnuParser.java:110)
	at org.apache.commons.cli.Parser.parse(Parser.java:143)
	at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:374)
	at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
	at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:138)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:414)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.streaming.TestDumpTypedBytes.testDumping(TestDumpTypedBytes.java:40)
{noformat}
"
MAPREDUCE-890,"After HADOOP-4491, the user who started mapred system is not able to run job.","Even setup and cleanup task of job fails due exception -: It fails to create job and related directories under mapred.local.dir/taskTracker/jobcache
Directories are created as -:
[dr-xrws--- mapred   hadoop  ]  job_200908190916_0002
mapred is not wrtie under this. Even manually I failed to touch file.
mapred is use of started mr cluster "
MAPREDUCE-889,binary communication formats added to Streaming by HADOOP-1722 should be documented,binary communication formats added to Streaming by HADOOP-1722 should be documented in forrest
MAPREDUCE-888,TestJobHistory sometimes fails while validating history.,"Error Message

Duplicate START_TIME seen for task task_200908190021_0001_m_000003 in history file at line 5

Stacktrace

junit.framework.AssertionFailedError: Duplicate START_TIME seen for task task_200908190021_0001_m_000003 in history file at line 5
	at org.apache.hadoop.mapred.TestJobHistory$TestListener.handle(TestJobHistory.java:163)
	at org.apache.hadoop.mapred.JobHistory.parseLine(JobHistory.java:497)
	at org.apache.hadoop.mapred.JobHistory.parseHistoryFromFS(JobHistory.java:463)
	at org.apache.hadoop.mapred.TestJobHistory.validateJobHistoryFileFormat(TestJobHistory.java:486)
	at org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile(TestJobHistory.java:955)
"
MAPREDUCE-887,"After 4491, task cleaup directory some gets created under the ownershiptasktracker user instread job submitting.","Some time, when task is killed, task cleanup directory is created under the ownership tasktracker launching user instead job submitting user.
dr-xrws--- karams   hadoop  ]  job_200908170914_0020
             |-- [drwxr-sr-x mapred   hadoop  ]  attempt_200908170914_0020_m_000002_0.cleanup
             `-- [drwxrws--- karams   hadoop  ]  attempt_200908170914_0020_m_000012_0


Here karams is user who submitted job and mapred is the use who launched TT. taskattrempt.cleanup created with mapred  user not with karams user.
This issue is intermittent, not always reproducible. "
MAPREDUCE-886,"After 4491, when task-controller exit with some error message, LinuxTaskController only ExitCodeException but does not prints the exit code of task-controller",
MAPREDUCE-885,More efficient SQL queries for DBInputFormat,"DBInputFormat generates InputSplits by counting the available rows in a table, and selecting subsections of the table via the ""LIMIT"" and ""OFFSET"" SQL keywords. These are only meaningful in an ordered context, so the query also includes an ""ORDER BY"" clause on an index column. The resulting queries are often inefficient and require full table scans. Actually using multiple mappers with these queries can lead to O(n^2) behavior in the database, where n is the number of splits. Attempting to use parallelism with these queries is counter-productive.

A better mechanism is to organize splits based on data values themselves, which can be performed in the WHERE clause, allowing for index range scans of tables, and can better exploit parallelism in the database."
MAPREDUCE-884,TestReduceFetchFromPartialMem fails sometimes,"TestReduceFetchFromPartialMem failed with the following exception trace :
{code}
Expected some records not spilled during reduce40980)
junit.framework.AssertionFailedError: Expected some records not spilled during reduce40980)
        at org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.testReduceFromPartialMem(TestReduceFetchFromPartialMem.java:94)
        at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
        at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
        at junit.extensions.TestSetup.run(TestSetup.java:27)
{code}
"
MAPREDUCE-883,harchive: Document how to unarchive,"I was thinking of implementing harchive's 'unarchive' feature, but realized it has been implemented already ever since harchive was introduced.
It just needs to be documented."
MAPREDUCE-882,TestJobHistory fails sometimes,"Testcase: testDoneFolderOnHDFS took 31.892 sec
Testcase: testJobHistoryFile took 27.901 sec
        FAILED
Duplicate START_TIME seen for task task_200908161937_0001_m_000003 in history file at line 5
junit.framework.AssertionFailedError: Duplicate START_TIME seen for task task_200908161937_0001_m_000003 in history file at line 5
        at org.apache.hadoop.mapred.TestJobHistory$TestListener.handle(TestJobHistory.java:164)
        at org.apache.hadoop.mapred.JobHistory.parseLine(JobHistory.java:505)
        at org.apache.hadoop.mapred.JobHistory.parseHistoryFromFS(JobHistory.java:469)
        at org.apache.hadoop.mapred.TestJobHistory.validateJobHistoryFileFormat(TestJobHistory.java:496)
        at org.apache.hadoop.mapred.TestJobHistory.testJobHistoryFile(TestJobHistory.java:964)

Testcase: testJobHistoryUserLogLocation took 75.161 sec
Testcase: testJobHistoryJobStatus took 156.88 sec"
MAPREDUCE-881,Jobtracker continues even if History initialization fails,"If there is some problem in the configuration, Job history initialization fails. JobHistory#init catches the exception and disable the history. This leads to job history not working as expected. However administrators won't notice that there is some problem in the config due to which history got disabled, unless they see the logs. Better approach would be to not catch the exception and let Jobtracker fail to come up if there is error in initialization."
MAPREDUCE-880,TestRecoveryManager times out,
MAPREDUCE-879,TestTaskTrackerLocalization fails on MAC OS,TestTaskTrackerLocalization failed on an 'ant test' run.
MAPREDUCE-878,Rename fair scheduler design doc to fair-scheduler-design-doc.tex and add Apache license header,As suggested by Tsz Wo Sze in MAPREDUCE-706.
MAPREDUCE-877,Required avro class are missing in contrib projects,"Ivy setting in mapreduce root is updated but the contrib ivy settings are not.
"
MAPREDUCE-876,Sqoop import of large tables can time out,"Related to MAPREDUCE-875, Sqoop should use a background thread to ensure that progress is being reported while a database does external work for the MapReduce task."
MAPREDUCE-875,Make DBRecordReader execute queries lazily,"DBInputFormat's DBRecordReader executes the user's SQL query in the constructor. If the query is long-running, this can cause task timeout. The user is unable to spawn a background thread (e.g., in a MapRunnable) to inform Hadoop of on-going progress. "
MAPREDUCE-874,"The name ""PiEstimator"" is misleading","The PiEstimator example mainly illustrates evaluating arbitrary integrals numerically by Map/Reduce jobs but not focusing on computing Pi.  The name ""PiEstimator"" is misleading."
MAPREDUCE-873,Simplify Job Recovery,"On a couple of occasions we have seen the JobTracker not being able to handle job recovery well, and leading to cluster downtime after a restart. The current design for handling job recovery is complex and prone to corner cases not being handled well enough. In retrospect, it seems like the transaction log based approach as was proposed on HADOOP-3245 (http://tinyurl.com/luh9hb), would have been a better/simpler model. However, that is a big project, and it seems for the medium term, just handling job re-submissions after a restart is a good tradeoff. That is, the JobTracker after getting restarted, will resubmit all jobs that were running in its past life. They will all start from the beginning (downside is completed tasks will reexecute). In the long term, the transaction log model or some variant of that should be pursued.

Thoughts/comments welcome."
MAPREDUCE-872,Streaming tests in a clean workspace fail because of avro dependency.,This is similar to [MAPREDUCE-867]. Running streaming (or some other contrib tests) in a clean workspace (empty build/ivy dir) fail with the exception trace mentioned at [MAPREDUCE-859].
MAPREDUCE-871,Job/Task local files have incorrect group ownership set by LinuxTaskController binary,"HADOOP-4491 fixed the secure permissions of local files on a TT. While testing HADOOP-4491 on a cluster, [~karams] found out a bug. All the files/dirs have should be owned by the group corresponding to the group owner of the task-controller binary (via using getegid()) which in turn is a special group to which *only* TT user belongs. HADOOP-4491 incorrectly set it to primary group of the TT via getgid(), and not the special group."
MAPREDUCE-870,Clean up the job Retire code,"Currently completed job's full data structures are kept in memory based on mapred.jobtracker.completeuserjobs.maximum, mapred.jobtracker.retirejob.interval.min, mapred.jobtracker.retirejob.interval and mapred.jobtracker.retirejob.check settings. These controls are not much useful now since MAPREDUCE-817 introduced a cache for keeping just the very basic info of the completed job. These settings should be removed and the job should be purged as soon as the history files are available in HDFS. 
Going forward, clients can read the history files if they need to drill down into more information (MAPREDUCE-864)."
MAPREDUCE-869,Documentation for config to set map/reduce task environment,"HADOOP-2838 added mapred.child.env to allow users to set the map/reduce tasks' environment.

MAPREDUCE-478 will break that into mapred.map.child.env and mapred.reduce.child.env. We need to add documentation (forrest) for these knobs."
MAPREDUCE-868,Trunk  can't be compiled since Avro dependencies cannot be resolved,"{noformat}
[ivy:resolve] :: problems summary ::
[ivy:resolve] :::: WARNINGS
[ivy:resolve]           module not found: org.apache.hadoop#avro;1.0.0
[ivy:resolve]   ==== local: tried
[ivy:resolve]     /home/arunc/.ivy2/local/org.apache.hadoop/avro/1.0.0/ivys/ivy.xml
[ivy:resolve]     -- artifact org.apache.hadoop#avro;1.0.0!avro.jar:
[ivy:resolve]     /home/arunc/.ivy2/local/org.apache.hadoop/avro/1.0.0/jars/avro.jar
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]           ::          UNRESOLVED DEPENDENCIES         ::
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve]           :: org.apache.hadoop#avro;1.0.0: not found
[ivy:resolve]           ::::::::::::::::::::::::::::::::::::::::::::::
[ivy:resolve] 
[ivy:resolve] :: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
{noformat}"
MAPREDUCE-867,trunk builds fails as ivy is lookin for avro jar from the local resolver,
MAPREDUCE-866,Move all memory related parameters and their initialization out of TaskTracker.java into TaskMemoryManagerThread,"Design-wise, they belong to TaskMemoryManager. TaskTracker can use method calls to initialize/set/get the parameters."
MAPREDUCE-865,harchive: Reduce the number of open calls  to _index and _masterindex ,"When I have har file with 1000 files in it, 
   % hadoop dfs -lsr har:///user/knoguchi/myhar.har/
would open/read/close the _index/_masterindex files 1000 times.

This makes the client slow and add some load to the namenode as well.
Any ways to reduce this number?
"
MAPREDUCE-864,Enhance JobClient API implementations to look at history files to get information about jobs that are not in memory,"MAPREDUCE-817 added an API to get the JobHistory URL from the JobTracker. This is useful in two ways:
1) Users can use this API to get the URL, copy the history files to their local disk, and, do processing on them
2) APIs like JobSubmissionProtocol.getJobCounters, can read a part of the history file, and then return the information to the caller (if the job is not there in JT memory). This would  mimic most of the CompletedJobsStatusStore functionality."
MAPREDUCE-863,Improve/standardize job history file content format and the management of the history files,"This jira will track the various improvements that will be done in the JobHistory component of Hadoop. The main goals:
1) Make the content format friendly for consumption by other apps
2) Improve the management of the history files. 
3) Be able to completely rely on the JobHistory files for anything to do with getting the status of completed jobs, both at the JobClient end, and at the web-UI end"
MAPREDUCE-862,Modify UI to support a hierarchy of queues,MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map/Reduce framework. This JIRA is for defining changes to the UI related to queues. This includes the hadoop queue CLI and the web UI on the JobTracker.
MAPREDUCE-861,Modify queue configuration format and parsing to support a hierarchy of queues.,"MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map/Reduce framework. This JIRA is for defining changes to the configuration related to queues. 

The current format for defining a queue and its properties is as follows: mapred.queue.<queue-name>.<property-name>. For e.g. mapred.queue.<queue-name>.acl-submit-job. The reason for using this verbose format was to be able to reuse the Configuration parser in Hadoop. However, administrators currently using the queue configuration have already indicated a very strong desire for a more manageable format. Since, this becomes more unwieldy with hierarchical queues, the time may be good to introduce a new format for representing queue configuration.
"
MAPREDUCE-860,Modify Queue APIs to support a hierarchy of queues,MAPREDUCE-853 proposes to introduce a hierarchy of queues into the Map/Reduce framework. This JIRA is for defining changes to the APIs related to queues.
MAPREDUCE-859,Unable to run examples with current trunk,Running wordcount with trunk gives java.lang.NoClassDefFoundError: org/apache/avro/io/DatumReader. ivy settings need to be updated to get avro jars as well
MAPREDUCE-858,"NPE in heartbeat if ""mapred.job.tracker.history.completed.location"" is not writable ","If ""mapred.job.tracker.history.completed.location"" has been configured to write to a location which is not writable by JT, NullPointerException is thrown in TT heartbeat. Below is the Exception obtained:
{noformat}
2009-08-13 07:56:02,815 INFO org.apache.hadoop.ipc.Server: IPC Server handler <handler> on <port>, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@1e7a6ae, false, false, true, 1775) from <ip>:<port>: error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobHistory$JobHistoryFilesManager.moveToDone(JobHistory.java:215)
        at org.apache.hadoop.mapred.JobHistory$JobInfo.markCompleted(JobHistory.java:1071)
        at org.apache.hadoop.mapred.JobTracker.finalizeJob(JobTracker.java:2413)
        at org.apache.hadoop.mapred.JobInProgress.garbageCollect(JobInProgress.java:2729)
        at org.apache.hadoop.mapred.JobInProgress.jobComplete(JobInProgress.java:2327)
        at org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2259)
        at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:957)
        at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:3946)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3123)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2861)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
{noformat}

Instead of an NPE, it would be helpful if an useful error message is logged."
MAPREDUCE-857,task fails with NPE  when GzipCodec is used for mapred.map.output.compression.codec and native libary is not present,"Ran a job with mapred.map.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec.
Whenmaps of job completes they with following NPE  -:
tasklog -:
2009-08-12 13:48:13,423 INFO org.apache.hadoop.mapred.MapTask: io.sort.mb = 256
2009-08-12 13:48:13,611 INFO org.apache.hadoop.mapred.MapTask: data buffer = 204010944/214748368
2009-08-12 13:48:13,611 INFO org.apache.hadoop.mapred.MapTask: record buffer = 3187670/3355443
2009-08-12 13:49:45,473 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2009-08-12 13:49:45,544 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2009-08-12 13:49:45,545 INFO org.apache.hadoop.io.compress.CodecPool: Got brand-new compressor
2009-08-12 13:49:45,546 WARN org.apache.hadoop.mapred.Child: Error running child : java.lang.NullPointerException
        at org.apache.hadoop.mapred.IFile$Writer.<init>(IFile.java:105)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1248)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1146)
        at org.apache.hadoop.mapred.MapTask$NewOutputCollector.close(MapTask.java:528)
        at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:604)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:318)
        at org.apache.hadoop.mapred.Child.main(Child.java:162)

Line 105 of IFile.java contains followings line in trunk code on which error was seen -:
Line 104: this.compressor = CodecPool.getCompressor(codec);
Line: this.compressor.reset();


If native is available job runs successfully without any failures 
"
MAPREDUCE-856,Localized files from DistributedCache should have right access-control,
MAPREDUCE-853,Support a hierarchy of queues in the Map/Reduce framework,"In MAPREDUCE-824, we proposed introducing a hierarchy of queues in the capacity scheduler. Currently, the M/R framework provides the notion of job queues and handles some functionality related to queues in a scheduler-agnostic manner. This functionality includes:
- Managing the list of ACLs for queues
- Managing the run state of queues - running or stopped
- Displaying scheduling information about queues in the jobtracker web UI and job client CLI
- Displaying list of jobs in a queue in the jobtracker web UI and job client CLI
- Providing APIs for list queues and queue information in JobClient.

Since it would be beneficial to extend this functionality to hierarchical queues, this JIRA is proposing introducing the concept into the map/reduce framework as well. We could treat this as an umbrella JIRA and file additional tasks for each of the changes involved, sticking to the high level approach in this JIRA."
MAPREDUCE-852,ExampleDriver is incorrectly set as a Main-Class in tools in build.xml,"In build.xml,
{code}
  <target name=""examples"" depends=""jar, compile-examples"" description=""Make the Hadoop examples jar."">
...

  <target name=""tools-jar"" depends=""jar, compile-tools"" 
          description=""Make the Hadoop tools jar."">
    <jar jarfile=""${build.dir}/${tools.final.name}.jar""
         basedir=""${build.tools}"">
      <manifest>
        <attribute name=""Main-Class"" 
                   value=""org/apache/hadoop/examples/ExampleDriver""/>
      </manifest>
    </jar>
  </target>
{code}
- ExampleDriver should not be a Main-Class of tools
- Should we rename the target name from ""tools-jar"" to ""tools"", so that the name would be consistent with the ""examples"" target?"
MAPREDUCE-850,PriorityScheduler should use TaskTrackerManager.killJob() instead of JobInProgress.kill(),
MAPREDUCE-849,Renaming of configuration property names in mapreduce,"In-line with HDFS-531, property names in configuration files should be standardized in MAPREDUCE. "
MAPREDUCE-848,TestCapacityScheduler is failing,Looks like the commit of HADOOP-805 broke the CapacityScheduler testcase. 
MAPREDUCE-847,Adding Apache License Headers and reduce releaseaudit warnings to zero,"[rat:report] Summary
[rat:report] -------
[rat:report] Notes: 14
[rat:report] Binaries: 178
[rat:report] Archives: 49
[rat:report] Standards: 1364
[rat:report]
[rat:report] Apache Licensed: 1152
[rat:report] Generated Documents: 9
[rat:report]
[rat:report] JavaDocs are generated and so license header is optional
[rat:report] Generated files do not required license headers
[rat:report]
[rat:report] 203 Unknown Licenses
"
MAPREDUCE-846,A long running init can block job queue details webpage,A long running init of a job can potentially block job queue details page from being displayed as JSPUtils.generateJobTable() takes a lock on JobInProgress. 
MAPREDUCE-845,"build.xml hard codes findbugs heap size, in some configurations 512M is insufficient to successfully build","When attempting the build with the hardcoded value of 512M for findbugs heap size, the build fails with:

 [findbugs] Java Result: -1
     [xslt] Processing /grid/0/gs/gridre/SpringMapRedLevel2/build/test/findbugs/hadoop-findbugs-report.xml to /grid/0/gs/gridre/SpringMapRedLevel2/build/test/findbugs/hadoop-findbugs-report.html
     [xslt] Loading stylesheet /homes/hadoopqa/tools/findbugs/latest/src/xsl/default.xsl
     [xslt] : Error! Premature end of file.
     [xslt] : Error! com.sun.org.apache.xml.internal.utils.WrappedRuntimeException: Premature end of file.
     [xslt] Failed to process /grid/0/gs/gridre/SpringMapRedLevel2/build/test/findbugs/hadoop-findbugs-report.xml

BUILD FAILED
"
MAPREDUCE-844,TestJobTrackerRestartWithLostTracker fails sometimes,"After restart the tasks fail with the following error 

2009-08-10 16:35:56,673 WARN  mapred.TaskTracker (TaskTracker.java:startNewTask(1717)) - Error initializing attempt_200908101626_0001_m_000030_1003:
org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200908101626_0001/work in any of the configured local directories
        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathToRead(LocalDirAllocator.java:394)
        at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathToRead(LocalDirAllocator.java:142)
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.localizeTask(TaskTracker.java:1865)
        at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.launchTask(TaskTracker.java:1978)
        at org.apache.hadoop.mapred.TaskTracker.launchTaskForJob(TaskTracker.java:860)
        at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:854)
        at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1713)
        at org.apache.hadoop.mapred.TaskTracker.access$1200(TaskTracker.java:99)
        at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1678)

leading to job failure. "
MAPREDUCE-842,Per-job local data on the TaskTracker node should have right access-control,
MAPREDUCE-841,Protect Job Tracker against memory exhaustion due to very large InputSplit or JobConf objects,JobTracker only needs to examine a subset of information contained by InputSplit or JobConf objects. But currently JobTracker loads the complete user-defined InputSplit and JobConf objects in memory. This design would leave JobTracker susceptible to memory exhaustion particularly in cases when some bugs in user code which could result in very large input splits or job conf objects (e.g. PIG-901).
MAPREDUCE-840,DBInputFormat leaves open transaction,DBInputFormat.getSplits() does not connection.commit() after the COUNT query. This can leave an open transaction against the database which interferes with other connections to the same table.
MAPREDUCE-839,unit test TestMiniMRChildTask fails on mac os-x,The unit test TestMiniMRChildTask fails on Mac OS-X (10.5.8)
MAPREDUCE-838,Task succeeds even when committer.commitTask fails with IOException,"In MAPREDUCE-837, job succeeded with empty output even though all the tasks were throwing IOException at commiter.commitTask.

{noformat}
2009-08-07 17:51:47,458 INFO org.apache.hadoop.mapred.TaskRunner: Task attempt_200907301448_8771_r_000000_0 is allowed to commit now
2009-08-07 17:51:47,466 WARN org.apache.hadoop.mapred.TaskRunner: Failure committing: java.io.IOException: Can not get the relative path: \
base = hdfs://mynamenode:8020/user/knoguchi/test2.har/_temporary/_attempt_200907301448_8771_r_000000_0 \
child = hdfs://mynamenode/user/knoguchi/test2.har/_temporary/_attempt_200907301448_8771_r_000000_0/_index
  at org.apache.hadoop.mapred.FileOutputCommitter.getFinalPath(FileOutputCommitter.java:150)
  at org.apache.hadoop.mapred.FileOutputCommitter.moveTaskOutputs(FileOutputCommitter.java:106)
  at org.apache.hadoop.mapred.FileOutputCommitter.moveTaskOutputs(FileOutputCommitter.java:126)
  at org.apache.hadoop.mapred.FileOutputCommitter.commitTask(FileOutputCommitter.java:86)
  at org.apache.hadoop.mapred.OutputCommitter.commitTask(OutputCommitter.java:171)
  at org.apache.hadoop.mapred.Task.commit(Task.java:768)
  at org.apache.hadoop.mapred.Task.done(Task.java:692)
  at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:417)
  at org.apache.hadoop.mapred.Child.main(Child.java:170)

2009-08-07 17:51:47,468 WARN org.apache.hadoop.mapred.TaskRunner: Failure asking whether task can commit: java.io.IOException: \
Can not get the relative path: base = hdfs://mynamenode:8020/user/knoguchi/test2.har/_temporary/_attempt_200907301448_8771_r_000000_0 \
child = hdfs://mynamenode/user/knoguchi/test2.har/_temporary/_attempt_200907301448_8771_r_000000_0/_index
  at org.apache.hadoop.mapred.FileOutputCommitter.getFinalPath(FileOutputCommitter.java:150)
  at org.apache.hadoop.mapred.FileOutputCommitter.moveTaskOutputs(FileOutputCommitter.java:106)
  at org.apache.hadoop.mapred.FileOutputCommitter.moveTaskOutputs(FileOutputCommitter.java:126)
  at org.apache.hadoop.mapred.FileOutputCommitter.commitTask(FileOutputCommitter.java:86)
  at org.apache.hadoop.mapred.OutputCommitter.commitTask(OutputCommitter.java:171)
  at org.apache.hadoop.mapred.Task.commit(Task.java:768)
  at org.apache.hadoop.mapred.Task.done(Task.java:692)
  at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:417)
  at org.apache.hadoop.mapred.Child.main(Child.java:170)

2009-08-07 17:51:47,469 INFO org.apache.hadoop.mapred.TaskRunner: Task attempt_200907301448_8771_r_000000_0 is allowed to commit now
2009-08-07 17:51:47,472 INFO org.apache.hadoop.mapred.TaskRunner: Task 'attempt_200907301448_8771_r_000000_0' done.


{noformat}
"
MAPREDUCE-837,harchive fail when output directory has URI with default port of 8020,"% hadoop archive -archiveName abc.har /user/knoguchi/abc hdfs://mynamenode:8020/user/knoguchi

doesn't work on 0.18 nor 0.20
"
MAPREDUCE-836,Examples of hadoop pipes are not getting package a even when -Dcompile.native=yes -Dcompile.c++=yes option are used while running ant package or tar or similar commands.,"Examples of hadoop pies and python are not packed even when -Dcompile.native=yes -Dcompile.c++=yes option are used while running ant package or tar or similar commands. 
The pipes examples are compiled and copied under build/c++-examples but are not being packaged. Similar is case with python examples also."
MAPREDUCE-835,"hadoop-mapred examples,test and tools jar iles are being packaged when ant binary or bin-package is used ","When checking mapreduce trunk.
If run ant binary or ant bin-package commands-:
hadoop-mapred-test-0.21.0-dev.jar, hadoop-mapred-examples-0.21.0-dev.jar, hadoop-mapred-tools-0.21.0-dev.jar are being packaged in tar or build/hadoop-mapred-0.21.0-dev package directory. But they are present under build directory.

For ant tar and ant package they are being packaged correctly under buid/hadoop-mapred-0.21.0-dev directory. and in tar file"
MAPREDUCE-834,When TaskTracker config use old memory management values its memory monitoring is diabled.,"TaskTracker memory config values -:
mapred.tasktracker.vmem.reserved=8589934592
mapred.task.default.maxvmem=2147483648
mapred.task.limit.maxvmem=4294967296
mapred.tasktracker.pmem.reserved=2147483648
TaskTracker start as -:
               2009-08-05 12:39:03,308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.tasktracker.vmem.reserved is no longer used
		2009-08-05 12:39:03,308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.tasktracker.pmem.reserved is no longer used
		2009-08-05 12:39:03,308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.task.default.maxvmem is no longer used
		2009-08-05 12:39:03,308 WARN org.apache.hadoop.mapred.TaskTracker: The variable mapred.task.limit.maxvmem is no longer used
		2009-08-05 12:39:03,308 INFO org.apache.hadoop.mapred.TaskTracker: Starting thread: Map-events fetcher for all reduce tasks on <tracker_name>
		2009-08-05 12:39:03,309 INFO org.apache.hadoop.mapred.TaskTracker:  Using MemoryCalculatorPlugin : org.apache.hadoop.util.LinuxMemoryCalculatorPlugin@19be4777
		2009-08-05 12:39:03,311 WARN org.apache.hadoop.mapred.TaskTracker: TaskTracker's totalMemoryAllottedForTasks is -1. TaskMemoryManager is disabled.

"
MAPREDUCE-833,Jobclient does not print any warning message when old memory config variable used with -D option from command line,
MAPREDUCE-832,Too many WARN messages about deprecated memorty config variables in JobTacker log,"When user submit a mapred job using old memory config vairiable (mapred.task.maxmem) followinig message too many times in JobTracker logs -:
[
WARN org.apache.hadoop.mapred.JobConf: The variable mapred.task.maxvmem is no longer used instead use  mapred.job.map.memory.mb and mapred.job.reduce.memory.mb
]
"
MAPREDUCE-831,Put fair scheduler design doc in SVN,"The JIRA discussion for MAPREDUCE-706 includes a ~10-page design document for the fair scheduler. This should be added in the fair scheduler contrib directory, perhaps as both a .tex and a .pdf."
MAPREDUCE-830,Providing BZip2 splitting support for Text data,"HADOOP-4012 (https://issues.apache.org/jira/browse/HADOOP-4012) is providing support to handle BZip2 compressed data such that the input compressed file is split at arbitrary points.  This JIRA uses that functionality in LineRecordReader.  The benefit of this work is that, if user provides compressed BZip2 Text data, it will be split by Hadoop and hence will be processed by multiple mappers.  So BZip2 compressed data will be able to fully utilize the cluster power.  Currently BZip2 compressed Text file goes to one mapper and is not split.  So the enhancement in this JIRA provides splitting support  and a considerable performance gains."
MAPREDUCE-829,"When localizing job configuration from FS, TTs configuration on local disk is not loaded at all","We should first load the local configuration fConf, over which the job.xml from the JobTracker's file system should be loaded. This is needed so as to enforce settings specific to the TaskTracker if it has some."
MAPREDUCE-827,"""hadoop job -status <jobid>"" command should display job's completion status also.","""hadoop job -status <jobid>"" command doesn't display job status whether it is SUCCEEDED or KILLED. 

 command ""hadoop job -status <jobid>""  displays following info:

file: hdfs://<hostname>/<mapred system dir>/<job-id>/job.xml
tracking URL: http://<hostname>:<port>/jobdetails.jsp?jobid=<jobid>
map() completion: 1.0
reduce() completion: 1.0
Counters: 5
        Job Counters
                SLOTS_MILLIS_MAPS=321309
                Total time spent by all reduces waiting after reserving slots (ms)=0
                Total time spent by all maps waiting after reserving slots (ms)=0
                Launched map tasks=10
                SLOTS_MILLIS_REDUCES=0

This command should  display the job's completion status also."
MAPREDUCE-826,harchive doesn't use ToolRunner / harchive returns 0 even if the job fails with exception,
MAPREDUCE-825,JobClient completion poll interval of 5s causes slow tests in local mode,"The JobClient.NetworkedJob.waitForCompletion() method polls for job completion every 5 seconds. When running a set of short tests in pseudo-distributed mode, this is unnecessarily slow and causes lots of wasted time. When bandwidth is not scarce, setting the poll interval to 100 ms results in a 4x speedup in some tests.  This interval should be parametrized to allow users to control the interval for testing purposes.
"
MAPREDUCE-824,Support a hierarchy of queues in the capacity scheduler,"Currently in Capacity Scheduler, cluster capacity is divided among the queues based on the queue capacity. These queues typically represent an organization and the capacity of the queue represents the capacity the organization is entitled to. Most organizations are large and need to divide their capacity among sub-organizations they have. Or they may want to divide the capacity based on a category or type of jobs they run. This JIRA covers the requirements and other details to provide the above feature."
MAPREDUCE-823,TestCommandLineJobSubmission doesn't need MiniDFSCluster to run,The test is included in the list of fast tests and so might profit from replacing MiniDFSCluster with the local file system.
MAPREDUCE-822,"Jobtracker logs should display the  ""job info persisted to file.."" message after job's completion.","<timestamp> INFO org.apache.hadoop.mapred.JobTracker: Job <job-id> job info persisted to file : <mapred.job.tracker.persist.jobstatus.dir>/<job-id>

message should be logged in the jobtracker's log after job's completion if ""mapred.job.tracker.persist.jobstatus.active"" is active."
MAPREDUCE-821,JobClient.runJob leaks file descriptors,"In a Java-based driver that runs multiple MapReduce jobs (e.g. Mahout's K-means implementation), numerous calls to JobClient.runJob will cause many RPC connections to be opened and then never closed. This results in the driver job leaking file descriptors and will eventually crash once the OS limit is reached for Too Many Open Files.

This has been verified in Hadoop 18.3 by running the driver and as new MapReduce jobs are run, lsof -p dhows an increasing number of open TCP connections to the cluster.

Looking at the current code in the trunk, it looks like this is caused by runJob not calling close() on the JobClient object it creates. Or alternatively, it's cause by the fact that JobClient does not have a destructor that calls close().

I am going to verify this hypothesis and post a patch."
MAPREDUCE-820,NPE in TT heartbeat when there is a problem resolving the network topology,"When there is a problem while resolving the network topology (such as a non existent topology.script.file.name), NPE is being thrown in the TT heartbeats. Below is the exception obtained:

{noformat}
error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.resolveAndAddToTopology(JobTracker.java:2663)
        at org.apache.hadoop.mapred.JobTracker.addNewTracker(JobTracker.java:2645)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3093)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2836)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
{noformat}"
MAPREDUCE-819,DistCP Guide - updates,DistCp Guide - updates to examples. Changes suggested and approved by engineer.
MAPREDUCE-818,org.apache.hadoop.mapreduce.Counters.getGroup returns null if the group name doesnt exist.,org.apache.hadoop.mapreduce.Counters.getGroup returns null if the group name doesnt exist. But the documentation says it returns an empty group if there is none with the specified name.
MAPREDUCE-817,Add a cache for retired jobs with minimal job info and provide a way to access history file url,MAPREDUCE-814 will provide a way to keep the job history files in HDFS. There should be a way to get the url for the completed job history fie. The completed jobs can be purged from memory more aggressively from jobtracker since the clients can retrieve the information from history file. Jobtracker can just maintain the very basic info about the completed jobs.
MAPREDUCE-816,"Rename ""local"" mysql import to ""direct""","A mysqldump-based fast path known as ""local mode"" is used in sqoop when users pass the argument {{--local.}} The restriction that this only import from localhost was based on an implementation technique that was later abandoned in favor of a more general one, which can support remote hosts as well. Thus, {{--local}} is a poor name for the flag. {{--direct}} is more general and more descriptive. This should be used instead."
MAPREDUCE-815,Add AvroInputFormat and AvroOutputFormat so that hadoop can use Avro Serialization,MapReduce needs AvroInputFormat similar to other InputFormats like TextInputFormat to be able to use avro serialization in hadoop. Similarly AvroOutputFormat is needed.
MAPREDUCE-814,Move completed Job history files to HDFS,Currently completed job history files remain on the jobtracker node. Having the files available on HDFS will enable clients to access these files more easily.
MAPREDUCE-813,Streaming Doc and  M/R-Tutorial Doc - updates,"This JIRA addresses issues in the Streaming doc that also require a cross-link to and update in the M/R Tutorial doc. All changes approved by the reviewing engineer.

Streaming issues:

1.  During the execution of a streaming job, the names of the ""mapred"" parameters are transformed. The dots ( . ) become underscores ( _ ).

Docs affected: streaming and m/r tutorial (new sub-sections added under Task Execution & Environment section)

2. For -files and -archives options, Hadoop now creates symlink with same name as file (user-defined symlinks, #mysymlink, currently not supported)

Docs affected:streaming

3. Streaming supports streaming command options and generic command options. Generic options must be placed before streaming options, otherwise command fails.

Docs affected: streaming (reorganized the streaming doc to make distinctions between 2 sets of command options more clear)

"
MAPREDUCE-810,Make TaskInProgress independent of JobTracker reference,As of today the TaskInProgress holds a reference of jobtracker and makes a back-call. These circular calls along with synchronization can lead to deadlocks.
MAPREDUCE-809,Job summary logs show status of completed jobs as RUNNING ,MAPREDUCE-740 added job summary logs. During testing our QA folks noticed that completed jobs show up as RUNNING in the logs.
MAPREDUCE-808,Buffer objects incorrectly serialized to typed bytes,"{{TypedBytesOutput.write()}} should do something like

{code}
Buffer buf = (Buffer) obj;
writeBytes(buf.get(), 0, bug.getCount());
{code}

instead of

{code}
writeBytes(((Buffer) obj).get());
{code}

since the bytes returned by {{Buffer.get()}} are ""only valid between 0 and getCount() - 1""."
MAPREDUCE-807,Stray user files in mapred.system.dir with permissions other than 777 can prevent the jobtracker from starting up.,"With restart disabled, the jobtracker does a _rm -rf_ of the mapred.system.dir. If the mapred.system.dir contains user files with permissions other than 777 then the jobtracker gets stuck in a loop trying to delete the mapred.system.dir (and each time failing with AccessControlException). The JobTracker admin has to manually cleanup the mapred.system.dir if this happens."
MAPREDUCE-806,WordCount example does not compile given the current instructions,"http://hadoop.apache.org/common/docs/r0.20.0/mapred_tutorial.html#Example%3A+WordCount+v1.0

In this example, the classpath is missing commons-cli-2.0-SNAPSHOT.jar

If we compile according to the instructions:

$ javac -classpath /hadoop/core/hadoop-0.20.0-core.jar -d ioperf_classes/ src/WordCount.java
src/WordCount.java:54: cannot access org.apache.commons.cli.Options
class file for org.apache.commons.cli.Options not found
    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();

The correct compilation should be 

$ javac -classpath /hadoop/core/hadoop-0.20.0-core.jar:/hadoop/core/lib/commons-cli-2.0-SNAPSHOT.jar -d ioperf_classes/ src/WordCount.java"
MAPREDUCE-805,Deadlock in Jobtracker,"We are running a hadoop cluster (version 0.20.0) and have detected the following deadlock on our jobtracker:
{code}
""IPC Server handler 51 on 9001"":
	at org.apache.hadoop.mapred.JobInProgress.getCounters(JobInProgress.java:943)
	- waiting to lock <0x00007f2b6fb46130> (a org.apache.hadoop.mapred.JobInProgress)
	at org.apache.hadoop.mapred.JobTracker.getJobCounters(JobTracker.java:3102)
	- locked <0x00007f2b5f026000> (a org.apache.hadoop.mapred.JobTracker)
	at sun.reflect.GeneratedMethodAccessor21.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
 ""pool-1-thread-2"":
	at org.apache.hadoop.mapred.JobTracker.finalizeJob(JobTracker.java:2017)
	- waiting to lock <0x00007f2b5f026000> (a org.apache.hadoop.mapred.JobTracker)
	at org.apache.hadoop.mapred.JobInProgress.garbageCollect(JobInProgress.java:2483)
	- locked <0x00007f2b6fb46130> (a org.apache.hadoop.mapred.JobInProgress)
	at org.apache.hadoop.mapred.JobInProgress.terminateJob(JobInProgress.java:2152)
	- locked <0x00007f2b6fb46130> (a org.apache.hadoop.mapred.JobInProgress)
	at org.apache.hadoop.mapred.JobInProgress.terminate(JobInProgress.java:2169)
	- locked <0x00007f2b6fb46130> (a org.apache.hadoop.mapred.JobInProgress)
	at org.apache.hadoop.mapred.JobInProgress.fail(JobInProgress.java:2245)
	- locked <0x00007f2b6fb46130> (a org.apache.hadoop.mapred.JobInProgress)
	at org.apache.hadoop.mapred.EagerTaskInitializationListener$InitJob.run(EagerTaskInitializationListener.java:86)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:619)
{code}"
MAPREDUCE-804,split.dta is no longer used (?),
MAPREDUCE-803,Provide a command line option to clean up jobtracker system directory,"When the JT is restarted, the mapreduce system directory's contents are used for job recovery. For sites that use this feature, there might be instances when we don't want to restart to read the mapred system directory. A sample use case is if there is a full cluster restart with a (typically minor) version upgrade of the Map/Reduce code base. To easily support such cases, it would be nice to provide a way for clean up the jobtracker system directory so that no files will be available for cleanup."
MAPREDUCE-802,Simplify the job updated event notification between Jobtracker and schedulers,"HADOOP-4053 and HADOOP-4149 added events to take care of updates to the state / property of a job like the run state / priority of a job notified to the scheduler. We've seen some issues with this framework, such as the following:
- Events are not raised correctly at all places. If a new code path is added to kill a job, raising events is missed out.
- Events are raised with incorrect event data. For e.g. typically start time value is missed out.

The resulting contract break between jobtracker and schedulers has lead to problems in the capacity scheduler where jobs remain stuck in the queue without being ever removed and so on.

It has proven complicated to get this right in the framework and fixes have typically still left dangling cases. Or new code paths introduce new bugs.

This JIRA is about trying to simplify the interaction model so that it is more robust and works well."
MAPREDUCE-801,MAPREDUCE framework should issue warning with too many locations for a split,"Customized input-format may be buggy and report misleading locations through input-split, an example of which is PIG-878. When an input split returns too many locations, it would not only artificially inflate the percentage of data local or rack local maps, but also force scheduler to use more memory and work harder to conduct task assignment."
MAPREDUCE-800,MRUnit should support the new API,MRUnit's TestDriver implementations use the old org.apache.hadoop.mapred-based classes. TestDrivers and associated mock object implementations are required for org.apache.hadoop.mapreduce-based code.
MAPREDUCE-799,Some of MRUnit's self-tests were not being run,"Due to method naming issues, some test cases were not being executed."
MAPREDUCE-798,MRUnit should be able to test a succession of MapReduce passes,"MRUnit can currently test that the inputs to a given (mapper, reducer) ""job"" produce certain outputs at the end of the reducer. It would be good to support more end-to-end tests of a series of MapReduce jobs that form a longer pipeline surrounding some data."
MAPREDUCE-797,MRUnit MapReduceDriver should support combiners,"The MapReduceDriver allows you to specify a mapper and a reducer class with a simple sort/""shuffle"" between the passes. It would be nice to also support another Reducer implementation being used as a combiner in the middle."
MAPREDUCE-796,"Encountered ""ClassCastException"" on tasktracker while running wordcount with MultithreadedMapRunner","ClassCastException for OutOfMemoryError is encountered on tasktracker while running wordcount example with MultithreadedMapRunner. 

Stack trace :
=========
java.lang.ClassCastException: java.lang.OutOfMemoryError cannot be cast to java.lang.RuntimeException
	at org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.run(MultithreadedMapper.java:149)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:581)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:303)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)
"
MAPREDUCE-795,JobHistory.markCompleted() should be synchronized,"Since other FS calls in JobHistory are synchronized, this call should also be synchronized. This method moves jobhistory files from running to done folder. So while other JobHistory methods perform a search in the running folder this method might move the files in the FS causing inconsistencies. "
MAPREDUCE-793,Create a new test that consolidates a few tests to be included in the commit-test list,There are few tests that just run similar jobs and test different functionality. It would be useful to have a test that runs one job and tests several of these functionality together so that this test can be included in the fast commit-tests target.
MAPREDUCE-792,javac warnings in DBInputFormat,MAPREDUCE-716 introduces javac warnings
MAPREDUCE-791,Document Hadoop Map-Reduce Architecture,It would be nice to document the Map-Reduce architecture similar to the HDFS design document: http://hadoop.apache.org/common/docs/current/hdfs_design.html.
MAPREDUCE-790,TaskTracker blacklisted by one job should be blacklisted for all other jobs in the queue,"Once a task tracker is blacklisted by one job, it is still being used by all other jobs in the queue. A blacklisted task tracker could be a signal of marginal node, and thus it should be blacklisted for all jobs at least temporarily. Also, even if one task tracker has been blacklisted globally due to too many failures, the blacklists of the jobs in the queue are not affected, and thus will continue to use the bad task tracker. This could result job failure."
MAPREDUCE-789,Oracle support for Sqoop,A separate ConnManager is needed for Oracle to support its slightly different syntax and configuration
MAPREDUCE-788,Modify gridmix2 to use new api.,Modify gridmix2 to use new api.
MAPREDUCE-787,"-files, -archives should honor user given symlink path","Currently, if user gives an option such as
-files hdfs://host:fs_port/user/testfile.txt#testlink
The symlink name ""testlink"" is not honored. It alwasys creates symlink with name testfile.txt in cwd of the task.

If the user has given a symlink name, it should be honored. If no symlink-name is given, then the path.getName() can be used.
"
MAPREDUCE-786,Jobtracker history should be written aysnchronously to the filesystem,"Jobtracker lock is held while writing the history events. This makes the jobtracker slow on flushes, especially when history is written to HDFS. History events should be written asynchronously to avoid this problem."
MAPREDUCE-785,Refactor TestReduceFetchFromPartialMem into a separate test ,The rationale behind doing this is to enable this test alone to be included in the commit-tests target
MAPREDUCE-784,Modify TestUserDefinedCounters to use LocalJobRunner instead of MiniMR,This test can be modified to use LocalJobRunner.
MAPREDUCE-783,"Rename Sqoop ""local"" transfer to ""direct""","Sqoop can use tools such as mysqldump to pull from databases instead of JDBC. This is invoked using the ""--local"" command line argument. This name is based on a misunderstanding; these tools typically do offer remote access capability. Sqoop should pass host and port parameters to underlying tools where appropriate. Similarly, the ""local"" mode should be renamed, e.g., to ""direct"" mode and use --direct as an argument instead."
MAPREDUCE-782,Use PureJavaCrc32 in mapreduce spills,HADOOP-6148 implemented a Pure Java implementation of CRC32 which performs better than the built-in one. This issue is to make use of it in the mapred package
MAPREDUCE-781,distcp overrides user-selected job name,"distcp hard-codes the hadoop job name to ""distcp"" even if the user specifies a job name. This is a problem in general, but especially for generalized replication services since the Job Tracker UI and history can't be made to indicate what is being copied in the job name.
"
MAPREDUCE-779,Add node health failures into JobTrackerStatistics,Add the node health failure counts into {{JobTrackerStatistics}}.
MAPREDUCE-778,[Rumen] Need a standalone JobHistory log anonymizer,"Job history logs contain a rich set of information that can help understand and characterize cluster workload and individual job execution. Examples of work that parses or utilizes job history include HADOOP-3585, MAPREDUCE-534, HDFS-459, MAPREDUCE-728, and MAPREDUCE-776. Some of the parsing tools developed in previous work already contains a component to anonymize the logs. It would be nice to combine these effort and have a common standalone tool that can anonymizes job history logs and preserve much of the structure of the files so that existing tools on top of job history logs continue work with no modification."
MAPREDUCE-777,A method for finding and tracking jobs from the new API,"We need to create a replacement interface for the JobClient API in the new interface. In particular, the user needs to be able to query and track jobs that were launched by other processes."
MAPREDUCE-776,Gridmix: Trace-based benchmark for Map/Reduce,"Previous benchmarks ( HADOOP-2369 , HADOOP-3770 ), while informed by production jobs, were principally load generating tools used to validate stability and performance under saturation. The important dimensions of that load- submission order/rate, I/O profile, CPU usage, etc- only accidentally match that of the real load on the cluster. Given related work that characterizes production load ( MAPREDUCE-751 ), it would be worthwhile to use mined data to impose a corresponding load for tuning and guiding development of the framework.

The first version will focus on modeling task I/O, submission, and memory usage."
MAPREDUCE-775,Add input/output formatters for Vertica clustered ADBMS.,"Add native support for Vertica as an input or output format taking advantage of parallel read and write properties of the DBMS.
 
On the input side allow for parametrized queries (a la prepared statements) and create a split for each combination of parameters.  Also support the parameter list to be generated from a sql statement.  For example - return metrics for all dimensions that meet criteria X with one input split for each dimension.  Divide the read among any number of hosts in the Vertica cluster.
 
On the output side, support Vertica streaming load to any number of hosts in the Vertica cluster.  Output may be to a different cluster than input.
 
Also includes Input and Output formatters that support streaming interface.

Code has been tested and run on live systems under 19 and 20.  Patch for 21 with new API will be ready end of this week.  
"
MAPREDUCE-774,Java/C++ word count examples have different outputs,"I ran the c++ word count example using pipes and got this result:

        Alethea 1488
        Arneb   1508
        Auriculariales  1518
Aktistetae      92126
Animalivora     91969
Aplacentalia    92690
        Aktistetae      1503
        Animalivora     1518
        Aplacentalia    1452
Alethea 91928
Arneb   91926
Auriculariales  92448

The correct result generated by Java word count example is:

Aktistetae      93629
Alethea 93416
Animalivora     93487
Aplacentalia    94142
Arneb   93434
Auriculariales  93966"
MAPREDUCE-773,LineRecordReader can report non-zero progress while it is processing a compressed stream,"Currently, the LineRecordReader returns 0.0 from getProgress() for most inputs (since the ""end"" of the filesplit is set to Long.MAX_VALUE for compressed inputs). This can be improved to return a non-zero progress even for compressed streams (though it may not be very reflective of the actual progress)."
MAPREDUCE-772,Chaging LineRecordReader algo so that it does not need to skip backwards in the stream,"The current algorithm of the LineRecordReader needs to move backwards in the stream (in its constructor) to correctly position itself in the stream.  So it moves back one byte from the start of its split and try to read a record (i.e. a line) and throws that away.  This is so because it is sure that, this line would be taken care of by some other mapper.  This algorithm is difficult and in-efficient if used for compressed stream where data is coming to the LineRecordReader via some codecs. (Although in the current implementation, Hadoop does not split a compressed file and only makes one split from the start to the end of the file and so only one mapper handles it.  We are currently working on BZip2 codecs where splitting is possible to work with Hadoop.  So this proposed change will make it possible to uniformly handle plain as well as compressed stream.)

In the new algorithm, each mapper always skips its first line because it is sure that, that line would have been read by some other mapper.  So now each mapper must finish its reading at a record boundary which is always beyond its upper split limit.  Due to this change, LineRecordReader does not need to move backwards in the stream.
"
MAPREDUCE-771,Setup and cleanup tasks remain in UNASSIGNED state for a long time on tasktrackers with long running high RAM tasks,"When a high RAM job's task is scheduled on a tasktracker, the number of slots it occupies will be more than one. If enough such tasks are scheduled, there can come a situation when there are no more slots free on the node but the number of tasks running is less than the number of slots. The jobtracker currently schedules a setup or cleanup task based on how many tasks are running on the system, rather than slots. As a result of this, it can schedule a setup or cleanup task on a tasktracker without any free slots. If the high RAM job's tasks are long running, this will significantly delay the running of the setup or cleanup task, and thus the entire job."
MAPREDUCE-770,org.apache.hadoop.tools.TestCopyFiles may leave junk files when an assertion fails,"In most of the testXxxYyyZzz methods, the code runs:

   preliminaries

   ToolRunner( ..., new String[] { local and DFS filenames and more filenames });

   assertMaybe(""this result stank"", conditions);
   assertMaybe(""this other result stank"", conditions);

   deldir(deletee's name);
   deldir(second deletee's name);

The assertMaybe's throw AssertionFailedError .  That's what they DO.  Shouldn't this stuff be protected with a try ... finally construct?
"
MAPREDUCE-769,findbugs and javac warnings on trunk is non-zero,"Obsvered that there are Six findbugs warnings in trunk. They would have gone in,  because of manual test-patch with a different findbugs version."
MAPREDUCE-768,Configuration information should generate dump in a standard format., We need to generate the configuration dump in a standard format .
MAPREDUCE-767,to remove mapreduce dependency on commons-cli2,"mapreduce, streaming and eclipse plugin depends on common-cli2 "
MAPREDUCE-766,"Enhance -list-blacklisted-trackers to display host name, blacklisted reason and blacklist report.","Currently, the -list-blacklisted-trackers in the mapred job option list only tracker name. We should enhance it to display as hostname, reason for blacklisting and blacklist report."
MAPREDUCE-765,eliminate the usage of FileSystem.create( ) depracated by Hadoop-5438 ,
MAPREDUCE-764,TypedBytesInput's readRaw() does not preserve custom type codes,"The typed bytes format supports byte sequences of the form {{<custom type code> <length> <bytes>}}. When reading such a sequence via {{TypedBytesInput}}'s {{readRaw()}} method, however, the returned sequence currently is {{0 <length> <bytes>}} (0 is the type code for a bytes array), which leads to bugs such as the one described [here|http://dumbo.assembla.com/spaces/dumbo/tickets/54]."
MAPREDUCE-763,Capacity scheduler should clean up reservations if it runs tasks on nodes other than where it has made reservations,Currently capacity scheduler makes a reservation on nodes for high memory jobs that cannot currently run at the time. It could happen that in the meantime other tasktrackers become free to run the tasks of this job. Ideally in the next heartbeat from the reserved TTs the reservation should be removed. Otherwise it could unnecessarily block capacity for a while (until the TT has enough slots free to run a task of this job).
MAPREDUCE-762,Task's process trees may not be killed if a TT is restarted,"Some work has been done to make sure the tasktrackers kill process trees of tasks when they finish (either successfully, or with failures or when they are killed). Related JIRAs are HADOOP-2721, HADOOP-5488 and HADOOP-5420. But when TTs are restarted, we do not handle killing of process trees - though tasks will themselves die on re-establishing contact with the TT."
MAPREDUCE-761,Revisit MapRed logging information,We should revisit what information should be logged so that debugging becomes easier.
MAPREDUCE-760,TestNodeRefresh might not work as expected,MAPREDUCE-677 fixed one part of the problem. It is possible that the tasktracker might not have joined the jobtracker and hence the asserts might fail.
MAPREDUCE-759,Refactor localization code in TaskTracker,"Localization code in TaskTracker is spread across TaskTracker, TaskTracker.TaskInProgress and TaskRunner. It turns out to be a bit complicated piece of code, as was observed during HADOOP-4491. It would be good if it is refactored into a single class/place."
MAPREDUCE-758,JobInProgressListener events might be garbled,"Consider the following scenario 
# EagerTaskInitializer calls jobtracker.initJob(obj1)
# initJob will snapshot the job run-state to PREP
# Before initJob() issues job1.initTask(), user issues a kill and the job now moves to KILLED state. The jobtracker updates the listener about the PREP->KILLED event.
# Now initJob() issues a job1.initTask() which comes out nicely.
# initJob() now snapshots the job state it will be KILLED
# jobtracker now updates the listener with PREP->KILLED event which is incorrect"
MAPREDUCE-757,JobConf will not be deleted from the logs folder if job retires from finalizeJob(),MAPREDUCE-130 fixed the case where the job is retired from the retire jobs thread. But jobs can also retire when the num-job-per-user limit is exceeded. In such cases the conf file will not be deleted.
MAPREDUCE-754,NPE in expiry thread when a TT is lost,"NullPointerException is obtained in Tracker Expiry Thread. Below is the exception obtained in the JT logs 
{noformat}
ERROR org.apache.hadoop.mapred.JobTracker: Tracker Expiry Thread got exception: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.updateTaskTrackerStatus(JobTracker.java:2971)
        at org.apache.hadoop.mapred.JobTracker.access$300(JobTracker.java:104)
        at org.apache.hadoop.mapred.JobTracker$ExpireTrackers.run(JobTracker.java:381)
        at java.lang.Thread.run(Thread.java:619)
{noformat}
The steps to reproduce this issue are:
* Blacklist a TT. 
* Restart it. 
* The above exception is obtained when the first instance of TT is marked as lost.

However the above exception does not break any functionality.


"
MAPREDUCE-752,DistributedCache.addArchiveToClassPath doesn't work,"addArchiveToClassPath is a method of DistributedCache class. It should be called before running a task. It accepts path to a jar file on a DFS. After it
this method should put this jar file on sitribuuted cache and than add this file to classpath to each map/reduce process on job tracker. 

This method don't work:

in TaskRunner there is an algorithm that looks for correspondence between DFS paths and local paths in distributed cache.
It compares

if (archives[i].getPath().equals(
archiveClasspaths[j].toString())){

instead of

if (archives[i].toString().equals(
archiveClasspaths[j].toString())) "
MAPREDUCE-751,Rumen: a tool to extract job characterization data from job tracker logs," We propose a new map/reduce component, rumen, which can be used to process job history logs to produce any or all of the following:

      * Retrospective info describing the statistical behavior of the
amount of time it would have taken to launch a job into a certain
percentage of the number of mapper slots in the log's cluster, given the
load over the period covered by the log

      * Statistical info as to the runtimes and shuffle times, etc. of
the tasks and jobs covered by the log

      * files describing detailed job trace information, and the
network topology as inferred from the host locations and rack IDs that
arise in the job tracker log.  In addition to this facility, rumen
includes readers for this information to return job and detailed task
information to other tools.

        These other tools include a more advanced version of gridmix, and also includes mumak: see blocked issues.


"
MAPREDUCE-750,Extensible ConnManager factory API,"Sqoop uses the ConnFactory class to instantiate a ConnManager implementation based on the connect string and other arguments supplied by the user. This allows per-database logic to be encapsulated in different ConnManager instances, and dynamically chosen based on which database the user is actually importing from. But adding new ConnManager implementations requires modifying the source of a common ConnFactory class. An indirection layer should be used to delegate instantiation to a number of factory implementations which can be specified in the static configuration or at runtime."
MAPREDUCE-749,Make Sqoop unit tests more Hudson-friendly,Hudson servers (other than Apache's) need to be able to run the sqoop unit tests which depend on thirdparty JDBC drivers / database implementations. The build.xml needs some refactoring to make this happen.
MAPREDUCE-748,"In Job Tracker log map attempt failure reports, failed maps show a HOSTNAME without a rack ID.","For example, from a job tracker log:

MapAttempt TASK_TYPE=""MAP"" TASKID=""task_200904211745_0002_m_000002"" TASK_ATTEMPT_ID=""attempt_200904211745_0002_m_000002_0"" START_TIME=""1240336754665"" TRACKER_NAME=""tracker_redacted1670\.redacted2\.com:localhost/127\.0\.0\.1:47698"" HTTP_PORT=""50060"" .
MapAttempt TASK_TYPE=""MAP"" TASKID=""task_200904211745_0002_m_000002"" TASK_ATTEMPT_ID=""attempt_200904211745_0002_m_000002_0"" TASK_STATUS=""FAILED"" FINISH_TIME=""1240336777673"" HOSTNAME=""redacted1670\.redacted2\.com"" ERROR=""java\.io\.IOException: Task process exit with nonzero status of 15\.
	at org\.apache\.hadoop\.mapred\.TaskRunner\.run(TaskRunner\.java:424)
,java\.io\.IOException: Task process exit with nonzero status of 15\.
	at org\.apache\.hadoop\.mapred\.TaskRunner\.run(TaskRunner\.java:424)
"" .

The hostname should have been [for example] HOSTNAME=""/1\.2\.3\.192/redacted1670\.redacted2\.com""


"
MAPREDUCE-747,"In Job Tracker logs, some host locations [either in SPLITS or in HOSTNAME subrecords] have numeric host locations","For example, instead of saying the normal

  HOSTNAME=""/1\.2\.3\.192/node0123\.hadoop-cluster\.megacorp\.com""

we might see the erroneous

  HOSTNAME=""/1\.2\.3\.192/1\.2\.3\.197""

where the IP address of node0123.hadoop-cluster.megacorp.com is in fact 1.2.3.197 .

This is not a property of certain hosts.  In our cluster, most hosts are occasionally reported in each of the two formats.


"
MAPREDUCE-746,"When a  task tracker is killed, there is a Null Pointer exception thrown.","When a task tracker is killed, the job completes. But tehre is a null pointer exception thrown:

java.io.IOException: java.lang.NullPointerException
	at org.apache.hadoop.mapred.JobTracker$FaultyTrackersInfo.removeHostCapacity(JobTracker.java:759)
	at org.apache.hadoop.mapred.JobTracker$FaultyTrackersInfo.blackListTracker(JobTracker.java:624)
	at org.apache.hadoop.mapred.JobTracker$FaultyTrackersInfo.incrementFaults(JobTracker.java:601)
	at org.apache.hadoop.mapred.JobTracker.finalizeJob(JobTracker.java:2337)
	at org.apache.hadoop.mapred.JobInProgress.garbageCollect(JobInProgress.java:2998)
	at org.apache.hadoop.mapred.JobInProgress.jobComplete(JobInProgress.java:2584)
	at org.apache.hadoop.mapred.JobInProgress.completedTask(JobInProgress.java:2473)
	at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1047)
	at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:3867)
	at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3079)
	at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2817)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:964)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:960)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:958)

Steps to reproduce the issue:
1) Bring up a 5 node cluster.
2) set mapred.max.tracker.failures to 1
3) Run a sleep command with 5 maps and 5 redcues.
4) Kill a task tracker, when map is 80% complete.
5) Kill the task tracker, by using ""kill -9 process_id"". 
6) At the time of killing, it was running 2 maps and 2 reduces.
7) Allow 12 minutes to elapse for that task tracker to go out of job nodes list
8) Then job completes successfully by giving the task attempts of the lost trackers to other nodes.
9) The job tracker logs has this exception.





"
MAPREDUCE-745,TestRecoveryManager fails sometimes,
MAPREDUCE-744,Support in DistributedCache to share cache files with other users after HADOOP-4493,HADOOP-4493 aims to completely privatize the files distributed to TT via DistributedCache. This jira issues focuses on sharing some/all of these files with all other users.
MAPREDUCE-743,Progress of map phase in map task is not updated properly,"Progress of map phase in map task is not updated properly. The progress set by TrackedRecordReader and NewTrackingRecordReader should set the progress object of map phase. It was setting it as the progress of whole task and because of phases, this is not considered as part of map task progress."
MAPREDUCE-742,Improve the java comments for the π examples,"There are 3 examples, pi, bbp and distbbp for &pi; computation.  We should tell the difference between them."
MAPREDUCE-741,New Hadoop MapReduce Site,"New Hadoop MapReduce Site

Set up site (initial pass).
May need to add more content.
May need to update some links.
"
MAPREDUCE-740,Provide summary information per job once a job is finished.,"It would be nice if JobTracker can output a one line summary information per job once a job is finished. Otherwise, users or system administrators would end up scraping individual job history logs."
MAPREDUCE-739,Allow relative paths to be created inside archives.,Archives currently stores the full path from the input sources -- since it allows multiple sources and regular expressions as inputs. So the created archives have the full path of the input sources. This is un intuitive and a user hassle. We should get rid of it and allow users to say that the created archive should be relative to some absolute path and throw an excpetion if the input does not confirm to the relative absolute path.
MAPREDUCE-737,High Availability support for Hadoop,"Currently, We look at the HA of Hadoop cluster. We need to consider the NameNode HA as well as Jobtracker HA. For NameNode, we want to build primary/standy or master-slaves pattern to provide NameNode HA. Therefore, we need to consider how to ship log between primary/standby/slaves and how commit ""write"" operation to NameNode after the agreement among primary/standby/slaves on log. Whether will we use Linux HA package or NameNode-built-in HA package without the help of outter Linux HA package. 
After NameNode become high availability, is it necessary to provide HA for Jobtracker? Can Jobtracker  persist the states of Jobs and tasks into HA NameNode? Or Jobtracker also needs the same approach from NameNode for HA support."
MAPREDUCE-736,Undefined variable is treated as string.,"This issue is related to HADOOP-2838.
For X=$X:Y : Append Y to X (which should be taken from the tasktracker) ,  if  we append to an undefined variable then value for undefined variable should be displayed as blank 
e.g. NEW_PATH=$NEW_PATH2:/tmp should be displayed as 
"":/tmp"" in child's environment 
while that variable is being displayed as a string (""$NEW_PATH2:/tmp"") in the environemnt.

 This is happening in case of default task-controller only. This scenario works fine with linux task-controller."
MAPREDUCE-735,ArrayIndexOutOfBoundsException is thrown by KeyFieldBasedPartitioner,"KeyFieldBasedPartitioner throws ""KeyFieldBasedPartitioner"" when some part of the specified key is missing. 
Scenario :
=======
when  value of num.key.fields.for.partition is greater than the separators provided in the input.
Command:
========
hadoop jar streaming.jar -Dmapred.reduce.tasks=3 -Dnum.key.fields.for.partition=5 -input <input-dir>  -output <output-dir> -mapper org.apache.hadoop.mapred.lib.IdentityMapper -reducer org.apache.hadoop.mapred.lib.IdentityReducer -inputformat org.apache.hadoop.mapred.KeyValueTextInputFormat -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner

"
MAPREDUCE-734,java.util.ConcurrentModificationException observed in unreserving slots for HiRam Jobs,"Ran jobs out which 3 were HiRAM, the job were not removed from scheduler queue even after they successfully completed
hadoop queue -info queue -showJobs displays somwthing like -:
job_200907080724_0031   2       1247059146868   username  NORMAL  0 running map tasks using 0 map slots. 0 additional slots reserved. 0 running reduce tasks using 0 reduce slots. 60 additional slots reserved.
job_200907080724_0030   2       1247059146972   username  NORMAL  0 running map tasks using 0 map slots. 0 additional slots reserved. 0 running reduce tasks using 0 reduce slots. 60 additional slots reserved.

But it does not block anything, but seems like zombie process of system
Jobtracker log show java.util.ConcurrentModificationException

"
MAPREDUCE-733,"When running ant test TestTrackerBlacklistAcrossJobs, losing task tracker heartbeat exception occurs. ","When running ant test TestTrackerBlacklistAcrossJobs, losing task tracker heartbeat. 

It seems when a  task tracker is killed , it throws exception. Instead it should catch it and process it and allow the rest of the flow to go through.

2009-07-08 11:58:26,116 INFO  ipc.Server (Server.java:run(973)) - IPC Server handler 7 on 40193, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@13ec758, false, false, true, 6) from 127.0.0.1:40200: error: java.io.IOException: java.lang.RuntimeException: tracker_host1.rack.com:localhost/127.0.0.1:40197 already has slots reserved for null; being asked to un-reserve for job_200907081158_0001
java.io.IOException: java.lang.RuntimeException: tracker_host1.rack.com:localhost/127.0.0.1:40197 already has slots reserved for null; being asked to un-reserve for job_200907081158_0001
        at org.apache.hadoop.mapreduce.server.jobtracker.TaskTracker.unreserveSlots(TaskTracker.java:162)
        at org.apache.hadoop.mapred.JobInProgress.addTrackerTaskFailure(JobInProgress.java:1580)
        at org.apache.hadoop.mapred.JobInProgress.failedTask(JobInProgress.java:2908)
        at org.apache.hadoop.mapred.JobInProgress.updateTaskStatus(JobInProgress.java:1025)
        at org.apache.hadoop.mapred.JobTracker.updateTaskStatuses(JobTracker.java:3869)
        at org.apache.hadoop.mapred.JobTracker.processHeartbeat(JobTracker.java:3081)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:2819)
        at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:508)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:964)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:960)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:958)
2009-07-08 11:58:26,162 INFO  mapred.TaskTracker (TaskTracker.java:transmitHeartBeat(1196)) - Resending 'status' to 'localhost' with reponseId '6
"
MAPREDUCE-732,"node health check script should not log ""UNHEALTHY"" status for every heartbeat in INFO mode","Currently, when a TT is blacklisted by the node health check script, for every heartbeat a message such as the following is being logged.
{noformat}
<date> <time> INFO org.apache.hadoop.mapred.JobTracker: Adding blacklisted reason for tracker : <blacklisted TT> Reason for blacklisting is : NODE_UNHEALTHY
{noformat}
Due to this, the the JT logs fill up rapidly clogging the logdirs. Hence this message should be logged in DEBUG mode instead of INFO mode.
"
MAPREDUCE-730,allow relative paths to be created inside archives.,"This jira is a shadow jira for mapreduce changes related to HADOOP-3663.
Archives currently stores the full path from the input sources - since it allows multiple sources and regular expressions as inputs. So the created archives have the full path of the input sources. This is un intuitive and a user hassle. We should get rid of it and allow users to say that the created archive should be relative to some absolute path and throw an excpetion if the input does not confirm to the relative absolute path."
MAPREDUCE-728,Mumak: Map-Reduce Simulator,"h3. Vision:

We want to build a Simulator to simulate large-scale Hadoop clusters, applications and workloads. This would be invaluable in furthering Hadoop by providing a tool for researchers and developers to prototype features (e.g. pluggable block-placement for HDFS, Map-Reduce schedulers etc.) and predict their behaviour and performance with reasonable amount of confidence, there-by aiding rapid innovation.

----

h3. First Cut: Simulator for the Map-Reduce Scheduler

The Map-Reduce Scheduler is a fertile area of interest with at least four schedulers, each with their own set of features, currently in existence: Default Scheduler, Capacity Scheduler, Fairshare Scheduler & Priority Scheduler.

Each scheduler's scheduling decisions are driven by many factors, such as fairness, capacity guarantee, resource availability, data-locality etc.

Given that, it is non-trivial to accurately choose a single scheduler or even a set of desired features to predict the right scheduler (or features) for a given workload. Hence a simulator which can predict how well a particular scheduler works for some specific workload by quickly iterating over schedulers and/or scheduler features would be quite useful.

So, the first cut is to implement a simulator for the Map-Reduce scheduler which take as input a job trace derived from production workload and a cluster definition, and simulates the execution of the jobs in as defined in the trace in this virtual cluster. As output, the detailed job execution trace (recorded in relation to virtual simulated time) could then be analyzed to understand various traits of individual schedulers (individual jobs turn around time, throughput, faireness, capacity guarantee, etc). To support this, we would need a simulator which could accurately model the conditions of the actual system which would affect a schedulers decisions. These include very large-scale clusters (thousands of nodes), the detailed characteristics of the workload thrown at the clusters, job or task failures, data locality, and cluster hardware (cpu, memory, disk i/o, network i/o, network topology) etc.


"
MAPREDUCE-727,Move the bin/hadoop jar command over to bin/mapred,"Currently 'bin/hadoop jar' is used to submit jobs, we should move it over to bin/mapred."
MAPREDUCE-726,Move the mapred script to map/reduce,"The mapred script should be moved to mapreduce from Common. This is the parallel of HADOOP-6123.
"
MAPREDUCE-725,CapacityScheduler.TaskSchedulingMgr.hasSpeculativeTask bypasses HADOOP-2141,CapacityScheduler.TaskSchedulingMgr.hasSpeculativeTask has a duplicate of the old speculation code (pre HADOOP-2141) which needs to be fixed in-order for speculation to work correctly.
MAPREDUCE-724,Reducer should not be abstract in order to serve as substitute for IdentityReducer,"The old IdentityReducer class has been deprecated since the new Reducer class's default behavior is the very same. The @deprecated tag indicates Reducer is a substitute. However it is an abstract class and cannot be instantiated, which causes problems. I imagine it is just a matter of removing the 'abstract' keyword."
MAPREDUCE-722,More slots are getting reserved for HiRAM job tasks then required,"Submitted a normal job with map=124=reduces
After submitted High RAM with maps=31=reduces map.memory=1800 reduce.memory=2800
Again 3 job maps=124=reduces
total of 248 slots were reserved for both maps and reduces for High Job which much higher then required.
Is observed in Hadoop 0.20.0"
MAPREDUCE-720,Task logs should have right access-control,
MAPREDUCE-719,"Not able to run Mapred Reliability test as ""other"" user.","While executing ReliabilityTest as ""other"" user, following issues were observed:

--> Tasktrackers are not being killed as ""other"" user is not the owner of tasktrackers.
--> This test program just gives the usage message if not able to kill TTs.
      ""09/07/06 09:37:00 INFO mapred.ReliabilityTest: <hostname>: usage: kill [ -s signal | -p ] [ -a ] pid ...""
      Instead it should give an error message and should stop further execution by giving non-zero exit code.

"
MAPREDUCE-717,Fix some corner case issues in speculative execution (post hadoop-2141),"Some corner case issues can be fixed:
1) Setup task should not add anything to the job statistics (since they are really fast and might affect the statistics of a job with few tasks)
2) The statistics computations should be guarded for cases where things like sumOfSquares could become less than zero (due to rounding errors mostly).
3) The method TaskInProgress.getCurrentProgressRate() should take into account the COMMIT_PENDING state
4) The testcase TestSpeculativeExecution.testTaskLATEScheduling could be made more robust"
MAPREDUCE-716,org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle,"org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle.

The out of the box implementation of the Hadoop is working properly with mysql/hsqldb, but NOT with oracle.
Reason is DBInputformat is implemented with mysql/hsqldb specific query constructs like ""LIMIT"", ""OFFSET"".

FIX:
building a database provider specific logic based on the database providername (which we can get using connection).


I HAVE ALREADY IMPLEMENTED IT FOR ORACLE...READY TO CHECK_IN CODE"
MAPREDUCE-714,JobConf.findContainingJar unescapes unnecessarily on Linux,"In JobConf.findContainingJar, the path name is decoded using URLDecoder.decode(...). This was done by Doug in r381794 (commit msg ""Un-escape containing jar's path, which is URL-encoded.  This fixes things primarily on Windows, where paths are likely to contain spaces."") Unfortunately, jar paths do not appear to be URL encoded on Linux. If you try to use ""hadoop jar"" on a jar with a ""+"" in it, this function decodes it to a space and then the job cannot be submitted.
"
MAPREDUCE-713,Sqoop has some superfluous imports,Some classes have vestigial imports that should be removed
MAPREDUCE-712,RandomTextWriter example is CPU bound,Running the RandomTextWritter example job ( from the examples jar) pegs the machiens' CPUs.
MAPREDUCE-711,Move Distributed Cache from Common to Map/Reduce,Distributed Cache logically belongs as part of map/reduce and not Common.
MAPREDUCE-710,Sqoop should read and transmit passwords in a more secure manner,"Sqoop's current support for passwords involves reading passwords from the command line ""--password foo"", which makes the password visible to other users via 'ps'. An invisible-console approach should be taken.

Related, Sqoop transmits passwords to mysqldump in the same fashion, which is also insecure."
MAPREDUCE-709,node health check script does not display the correct message on timeout,"When the node health check script takes more than ""mapred.healthChecker.script.timeout"" to return, it should display a timeout message. Instead it displays the full stacktrace as below:

{noformat}
java.io.IOException: Stream closed at java.io.BufferedInputStream.getBufIfOpen(BufferedInputStream.java:145) 
at java.io.BufferedInputStream.read(BufferedInputStream.java:308) 
at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:264) 
at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:306) 
at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:158) 
at java.io.InputStreamReader.read(InputStreamReader.java:167) 
at java.io.BufferedReader.fill(BufferedReader.java:136) 
at java.io.BufferedReader.readLine(BufferedReader.java:299) 
at java.io.BufferedReader.readLine(BufferedReader.java:362) 
at org.apache.hadoop.util.Shell.runCommand(Shell.java:202) 
at org.apache.hadoop.util.Shell.run(Shell.java:145) 
at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:338) 
at org.apache.hadoop.mapred.NodeHealthCheckerService$NodeHealthMonitorExecutor.run(NodeHealthCheckerService.java:119) 
at java.util.TimerThread.mainLoop(Timer.java:512) 
at java.util.TimerThread.run(Timer.java:462) 
{noformat}

Also the ""mapred.healthChecker.script.timeout"" is not being reflected in the job.xml. It always picks up the default value. It is just an UI issue."
MAPREDUCE-708,"node health check script does not refresh the ""reason for blacklisting""","After MAPREDUCE-211, the node health check script does not refresh the ""reason for blacklisting"".
The steps to reproduce the issue are:
* Blacklist a TT with an error message 'x'
* Change the health check script to return an error message 'y'
* The ""reason for blacklisting"" still shows 'x'
 
The impact of this issue is that the feature fails to trap transient errors."
MAPREDUCE-707,Provide a jobconf property for explicitly assigning a job to a pool,"A common use case of the fair scheduler is to have one pool per user, but then to define some special pools for various production jobs, import jobs, etc. Therefore, it would be nice if jobs went by default to the pool of the user who submitted them, but there was a setting to explicitly place a job in another pool. Today, this can be achieved through a sort of trick in the JobConf:

{code}
<property>
  <name>mapred.fairscheduler.poolnameproperty</name>
  <value>pool.name</value>
</property>

<property>
  <name>pool.name</name>
  <value>${user.name}</value>
</property>
{code}

This JIRA proposes to add a property called mapred.fairscheduler.pool that allows a job to be placed directly into a pool, avoiding the need for this trick."
MAPREDUCE-706,Support for FIFO pools in the fair scheduler,"The fair scheduler should support making the internal scheduling algorithm for some pools be FIFO instead of fair sharing in order to work better for batch workloads. FIFO pools will behave exactly like the current default scheduler, sorting jobs by priority and then submission time. Pools will have their scheduling algorithm set through the pools config file, and it will be changeable at runtime.

To support this feature, I'm also changing the internal logic of the fair scheduler to no longer use deficits. Instead, for fair sharing, we will assign tasks to the job farthest below its share as a ratio of its share. This is easier to combine with other scheduling algorithms and leads to a more stable sharing situation, avoiding unfairness issues brought up in MAPREDUCE-543 and MAPREDUCE-544 that happen when some jobs have long tasks. The new preemption (MAPREDUCE-551) will ensure that critical jobs can gain their fair share within a bounded amount of time."
MAPREDUCE-705,User-configurable quote and delimiter characters for Sqoop records and record reparsing,"Sqoop needs a mechanism for users to govern how fields are quoted and what delimiter characters separate fields and records. With delimiters providing an unambiguous format, a parse method can reconstitute the generated record data object from a text-based representation of the same record."
MAPREDUCE-703,Sqoop requires dependency on hsqldb in ivy,Sqoop builds crash without explicit dependency on hsqldb.
MAPREDUCE-702,eclipse-plugin jar target fails during packaging,
MAPREDUCE-701,Make TestRackAwareTaskPlacement a unit test,This test can be made into a unit test and the functionality verified without needing to start MiniMR/DFS and launching jobs
MAPREDUCE-700,Too many copies of job-conf with the jobtracker,"As of today the jobtracker has job-conf copies in
# mapred.system.dir : created while job-submission 
# jobtracker-subdir (created by JobInProgress upon creation)
# log-dir : created upon job-init
# history-dir : created upon job-init

Its difficult to manage these conf files. The problem aggravates under restart."
MAPREDUCE-699,Several streaming test cases seem to be failing,"ant test is failing several streaming tests with the following error

Error Message

java.lang.NullPointerException  at org.apache.commons.cli.GnuParser.flatten(GnuParser.java:110)  at org.apache.commons.cli.Parser.parse(Parser.java:143)  at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:374)  at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)  at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:138)  at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1314)  at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:414)  at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)  at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)  at org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles(TestMultipleCachefiles.java:68)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  at java.lang.reflect.Method.invoke(Method.java:597)  at junit.framework.TestCase.runTest(TestCase.java:168)  at junit.framework.TestCase.runBare(TestCase.java:134)  at junit.framework.TestResult$1.protect(TestResult.java:110)  at junit.framework.TestResult.runProtected(TestResult.java:128)  at junit.framework.TestResult.run(TestResult.java:113)  at junit.framework.TestCase.run(TestCase.java:124)  at junit.framework.TestSuite.runTest(TestSuite.java:232)  at junit.framework.TestSuite.run(TestSuite.java:227)  at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:79)  at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)  at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768) 

Stacktrace

junit.framework.AssertionFailedError: java.lang.NullPointerException
	at org.apache.commons.cli.GnuParser.flatten(GnuParser.java:110)
	at org.apache.commons.cli.Parser.parse(Parser.java:143)
	at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:374)
	at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:153)
	at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:138)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1314)
	at org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:414)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:278)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:119)
	at org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles(TestMultipleCachefiles.java:68)

	at org.apache.hadoop.streaming.TestMultipleCachefiles.failTrace(TestMultipleCachefiles.java:141)
	at org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles(TestMultipleCachefiles.java:133)

The following are links to two such failures
http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-vesta.apache.org/337/testReport/
http://hudson.zones.apache.org/hudson/job/Mapreduce-Patch-vesta.apache.org/336/testReport/"
MAPREDUCE-698,Per-pool task limits for the fair scheduler,The fair scheduler could use a way to cap the share of a given pool similar to MAPREDUCE-532.
MAPREDUCE-697,Jobwise list of blacklisted tasktrackers doesn't get refreshed even after restarting blacklisted tasktrackers.,"Jobwise list of blacklisted tasktrackers doesn't get refreshed even after restarting blacklisted tasktrackers. ""jobdetails.jsp"" page keeps on showing the same no. of blacklisted tasktrackers (it doesn't get back to zero).

One associated issue:
=================
--> More than 25% of TTs are blacklisted in a job.
--> Restart the blacklisted TTs. All the tasktrackers are healthy now.
--> try to blacklist other TT for the same job.

Not able to blacklist the ""other"" tasktracker even if  ""mapred.max.tracker.failures"" exceeds the specified limit."
MAPREDUCE-695,MiniMRCluster while shutting down should not wait for currently running jobs to finish,Currently in {{org.apache.hadoop.mapred.MiniMRCluster.shutdown()}} we do a {{waitTaskTrackers()}} which can cause {{MiniMRCluster}} to hang indefinitely when used in conjunction with Controlled jobs.
MAPREDUCE-694,JSP jars should be added to dependcy list for Capacity scheduler,"Currently JSP*.jar is not added in dependency list for junit target causing, {{TestQueueCapacities}} to throw {{ClassNotFoundException}} while {{MiniMRCluster}} starts up"
MAPREDUCE-693,"Conf files not moved to ""done"" subdirectory after JT restart","After MAPREDUCE-516, when a job is submitted and the JT is restarted (before job files have been written) and the job is killed after recovery, the conf files fail to be moved to the ""done"" subdirectory.
The exact scenario to reproduce this issue is:
* Submit a job
* Restart JT before anything is written to the job files
* Kill the job
* The old conf files remain in the history folder and fail to be moved to ""done"" subdirectory"
MAPREDUCE-692,Make Hudson run Sqoop unit tests,Running 'ant test-contrib' didn't test Sqoop because it wasn't explicitly listed in the build.xml file in src/contrib/
MAPREDUCE-690,"Sqoop's test ""hive"" script needs to be executable",The testdata/hive/bin/hive script needs to be chmod +x so that unit tests can run it. This needs to be set with an svn property.
MAPREDUCE-689,Update distcp guide for new distcp features,"Please udpate the distcp guide with new features from MAPREDUCE-642, HADOOP-5762, HADOOP-5620"
MAPREDUCE-688,TestLostTracker sometimes fails ,"Observed that TestLostTracker failed once with follwing assertion failure:
Invalid start time 0
junit.framework.AssertionFailedError: Invalid start time 0
	at org.apache.hadoop.mapred.TestLostTracker.testTaskStatuses(TestLostTracker.java:109)
	at org.apache.hadoop.mapred.TestLostTracker.testLostTracker(TestLostTracker.java:99)
	at org.apache.hadoop.mapred.TestLostTracker.testLostTracker(TestLostTracker.java:161)"
MAPREDUCE-687,TestMiniMRMapRedDebugScript fails sometimes,"Testcase: testMapDebugScript took 149.994 sec
        FAILED
null expected:<...t Script
Bailing out[]> but was:<...t Script
Bailing out[
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.Task).
log4j:WARN Please initialize the log4j system properly.]>
junit.framework.ComparisonFailure: null expected:<...t Script
Bailing out[]> but was:<...t Script
Bailing out[
log4j:WARN No appenders could be found for logger (org.apache.hadoop.mapred.Task).
log4j:WARN Please initialize the log4j system properly.]>
        at org.apache.hadoop.mapred.TestMiniMRMapRedDebugScript.testMapDebugScript(TestMiniMRMapRedDebugScript.java:212)
"
MAPREDUCE-686,Move TestSpeculativeExecution.Fake* into a separate class so that it can be used by other tests also,TestSpeculativeExecution has some utility classes in FakeJobTracker and FakeJobInProgress that could be put to use by other tests as well. It makes sense to move these to a separate class
MAPREDUCE-685,Sqoop will fail with OutOfMemory on large tables using mysql,"The default MySQL JDBC client behavior is to buffer the entire ResultSet in the client before allowing the user to use the ResultSet object. On large SELECTs, this can cause OutOfMemory exceptions, even when the client intends to close the ResultSet after reading only a few rows. The MySQL ConnManager should configure its connection to use row-at-a-time delivery of results to the client."
MAPREDUCE-684,distcp returns success but does not copy files due to connection problem. Error is logged on target HDFS log directory,"Distcp returns success even though files are not copied due to connection problem.  It creates empty directory structure on the target and log the error message on the target HDFS log directory.

distcp command is run on hadoop 20 fetching data from hadoop 18 cluster.

-bash-3.1$ hadoop  distcp -Dmapred.job.queue.name=xxxx -i -p -update -delete hftp://xxx.mydomain.com:50070/user/gogate/mirror_test2 hdfs://yyy.mydomain.com:8020/user/gogate/mirror_test2'
09/06/30 18:41:29 INFO tools.DistCp: srcPaths=[hftp://xxx.mydomain.com:50070/user/gogate/mirror_test2]
09/06/30 18:41:29 INFO tools.DistCp: destPath=hdfs://yyy.mydomain.com:8020/user/gogate/mirror_test2
09/06/30 18:41:30 INFO tools.DistCp: hdfs://yyy.mydomain.com:8020/user/gogate/mirror_test2 does not exist.
09/06/30 18:41:30 INFO tools.DistCp: srcCount=4
09/06/30 18:41:36 INFO mapred.JobClient: Running job: job_200906290541_3336
09/06/30 18:41:37 INFO mapred.JobClient:  map 0% reduce 0%
09/06/30 18:43:05 INFO mapred.JobClient:  map 100% reduce 0%
09/06/30 18:43:28 INFO mapred.JobClient: Job complete: job_200906290541_3336
echo $?
09/06/30 18:43:35 INFO mapred.JobClient: Counters: 8
09/06/30 18:43:35 INFO mapred.JobClient:   Job Counters 
09/06/30 18:43:35 INFO mapred.JobClient:     Launched map tasks=1
09/06/30 18:43:35 INFO mapred.JobClient:   FileSystemCounters
09/06/30 18:43:35 INFO mapred.JobClient:     HDFS_BYTES_READ=534
09/06/30 18:43:35 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=3655
09/06/30 18:43:35 INFO mapred.JobClient:   distcp
09/06/30 18:43:35 INFO mapred.JobClient:     Files failed=2
09/06/30 18:43:35 INFO mapred.JobClient:   Map-Reduce Framework
09/06/30 18:43:35 INFO mapred.JobClient:     Map input records=3
09/06/30 18:43:35 INFO mapred.JobClient:     Spilled Records=0
09/06/30 18:43:35 INFO mapred.JobClient:     Map input bytes=434
09/06/30 18:43:35 INFO mapred.JobClient:     Map output records=2
-bash-3.1$ echo $?
0


target HDFS log directory message.

-bash-3.1$ hadoop fs -cat /user/gogate/_distcp_logs_f7twl9/part-00000
FAIL pig_1245890239320.log : java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
	at java.net.Socket.connect(Socket.java:519)
	at java.net.Socket.connect(Socket.java:469)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:157)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:394)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:529)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:233)
	at sun.net.www.http.HttpClient.New(HttpClient.java:306)
	at sun.net.www.http.HttpClient.New(HttpClient.java:323)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:788)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:729)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:654)
	at sun.net.www.protocol.http.HttpURLConnection.followRedirect(HttpURLConnection.java:1868)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1172)
	at org.apache.hadoop.hdfs.HftpFileSystem.open(HftpFileSystem.java:142)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:351)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.copy(DistCp.java:410)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:537)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:306)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)

FAIL dir1/xxx.pig : java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
	at java.net.Socket.connect(Socket.java:519)
	at java.net.Socket.connect(Socket.java:469)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:157)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:394)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:529)
	at sun.net.www.http.HttpClient.<init>(HttpClient.java:233)
	at sun.net.www.http.HttpClient.New(HttpClient.java:306)
	at sun.net.www.http.HttpClient.New(HttpClient.java:323)
	at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:788)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:729)
	at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:654)
	at sun.net.www.protocol.http.HttpURLConnection.followRedirect(HttpURLConnection.java:1868)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1172)
	at org.apache.hadoop.hdfs.HftpFileSystem.open(HftpFileSystem.java:142)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:351)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.copy(DistCp.java:410)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:537)
	at org.apache.hadoop.tools.DistCp$CopyFilesMapper.map(DistCp.java:306)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:356)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
	at org.apache.hadoop.mapred.Child.main(Child.java:170)

-bash-3.1$ 


"
MAPREDUCE-683,TestJobTrackerRestart fails with Map task completion events ordering mismatch,{{TestJobTrackerRestart}} fails consistently with Map task completion events ordering mismatch error.
MAPREDUCE-682,Reserved tasktrackers should be removed when a node is globally blacklisted,"When support was added to reserve tasktrackers for high RAM jobs per MAPREDUCE-516, we missed removing reservations on tasktrackers that are globally blacklisted. This is not a major concern, just that the reservation might cause the job to finish a little later than if the reservation is removed when the blacklisting happens."
MAPREDUCE-681,Some testcases wait forever on a condition which might result into timeouts,MAPREDUCE-502 and MAPREDUCE-130 testcases should change to fail instead of timeout upon failure.
MAPREDUCE-680,Reuse of Writable objects is improperly handled by MRUnit,"As written, MRUnit's MockOutputCollector simply stores references to the objects passed in to its collect() method. Thus if the same Text (or other Writable) object is reused as an output containiner multiple times with different values, these separate values will not all be collected. MockOutputCollector needs to properly use io.serializations to deep copy the objects sent in."
MAPREDUCE-679,XML-based metrics as JSP servlet for JobTracker,"In HADOOP-4559, a general REST API for reporting metrics was proposed but work seems to have stalled. In the interim, we have a simple XML translation of the existing JobTracker status page which provides the same metrics (including the tables of running/completed/failed jobs) as the human-readable page. This is a relatively lightweight addition to provide some machine-understandable metrics reporting."
MAPREDUCE-678,distcp -m option does not work ,"In spite of -m 10 , number of launched map tasks are 15.  

bin/hadoop  distcp -Dmapred.job.queue.name=xxxx -i -p -update -m 10   -delete  hftp://xxxx.yyyy.com:50070/user/xxxx/QA_incremental hdfs://aaaa.yyyy.com:8020/user/xxxxx/QA_incremental'

09/06/29 19:14:24 INFO tools.DistCp: srcPaths=[hftp://xxxxx.yyyy.com:50070/user/xxxx/QA_incremental]
09/06/29 19:14:24 INFO tools.DistCp: destPath=hdfs://zzzz.yyyy.com:8020/user/xxxx/QA_incremental
09/06/29 19:14:34 INFO tools.DistCp: sourcePathsCount=62
09/06/29 19:14:34 INFO tools.DistCp: filesToCopyCount=15
09/06/29 19:14:34 INFO tools.DistCp: bytesToCopyCount=18.0g
09/06/29 19:14:37 INFO mapred.JobClient: Running job: job_200906290541_1523
09/06/29 19:14:38 INFO mapred.JobClient:  map 0% reduce 0%
09/06/29 19:15:22 INFO mapred.JobClient:  map 2% reduce 0%
09/06/29 19:26:57 INFO mapred.JobClient:  map 9% reduce 0%
09/06/29 19:36:02 INFO mapred.JobClient:  map 16% reduce 0%
09/06/29 19:36:46 INFO mapred.JobClient:  map 22% reduce 0%
09/06/29 19:37:25 INFO mapred.JobClient:  map 29% reduce 0%
09/06/29 19:38:28 INFO mapred.JobClient:  map 36% reduce 0%
09/06/29 19:39:41 INFO mapred.JobClient:  map 42% reduce 0%
09/06/29 19:40:08 INFO mapred.JobClient:  map 46% reduce 0%
09/06/29 19:44:08 INFO mapred.JobClient:  map 53% reduce 0%
09/06/29 19:44:19 INFO mapred.JobClient:  map 60% reduce 0%
09/06/29 19:44:39 INFO mapred.JobClient:  map 66% reduce 0%
09/06/29 19:45:04 INFO mapred.JobClient:  map 73% reduce 0%
09/06/29 19:46:08 INFO mapred.JobClient:  map 80% reduce 0%
09/06/29 19:46:24 INFO mapred.JobClient:  map 86% reduce 0%
09/06/29 19:46:38 INFO mapred.JobClient:  map 93% reduce 0%
09/06/29 19:48:00 INFO mapred.JobClient:  map 100% reduce 0%
09/06/29 19:48:19 INFO mapred.JobClient: Job complete: job_200906290541_1523
09/06/29 19:48:19 INFO mapred.JobClient: Counters: 10
09/06/29 19:48:19 INFO mapred.JobClient:   Job Counters 
09/06/29 19:48:19 INFO mapred.JobClient:     Launched map tasks=15
09/06/29 19:48:19 INFO mapred.JobClient:   FileSystemCounters
09/06/29 19:48:19 INFO mapred.JobClient:     HDFS_BYTES_READ=7742
09/06/29 19:48:19 INFO mapred.JobClient:     HDFS_BYTES_WRITTEN=19294982191
09/06/29 19:48:19 INFO mapred.JobClient:   distcp
09/06/29 19:48:19 INFO mapred.JobClient:     Files copied=15
09/06/29 19:48:19 INFO mapred.JobClient:     Bytes copied=19294982191
09/06/29 19:48:19 INFO mapred.JobClient:     Bytes expected=19294982191
09/06/29 19:48:19 INFO mapred.JobClient:   Map-Reduce Framework
09/06/29 19:48:19 INFO mapred.JobClient:     Map input records=16
09/06/29 19:48:19 INFO mapred.JobClient:     Spilled Records=0
09/06/29 19:48:19 INFO mapred.JobClient:     Map input bytes=3190
09/06/29 19:48:19 INFO mapred.JobClient:     Map output records=0

"
MAPREDUCE-677,TestNodeRefresh timesout,
MAPREDUCE-676,Existing diagnostic rules fail for MAP ONLY jobs,some of the existing rules fail with divide by zero or arithmetic exception as map only jobs do not log reduce side counters. Vaidya driver code and Rules need to be modified to take care of such jobs.  
MAPREDUCE-675,Sqoop should allow user-defined class and package names,"Currently Sqoop generates a class for each table to be imported; the class names are equal to the table names and they are not part of any package.

This adds --class-name and --package-name parameters to Sqoop, allowing these aspects of code generation to be controlled."
MAPREDUCE-674,"Sqoop should allow a ""where"" clause to avoid having to export entire tables","Sqoop currently only exports at the granularity of a table.  This doesn't work well on systems with large tables, where the overhead of performing a full dump each time is significant.  Allowing the user to specify a where clause is a relatively simple task which will give Sqoop a lot more flexibility."
MAPREDUCE-673,"Sqoop depends on commons-cli, which is not in its ivy.xml.",Sqoop's ivy.xml needs commons-cli in order to build from scratch.
MAPREDUCE-672,"Consider adding a new ""component"" for Sqoop in JIRA",The development of Sqoop now spans several patches. It would be good to have a contrib/sqoop component to tag them with to keep related work together in the JIRA.
MAPREDUCE-671,Update ignore list,"MAPREDUCE-551 added conf/fair-scheduler.xml.template, but did not add conf/fair-scheduler.xml to the ignore list.

.gitignore is also missing conf/core-site.xml, conf/hdfs-site.xml, ivy/ivy-\*.jar from its ignore list."
MAPREDUCE-670, Create target for 10 minute patch test build for mapreduce,Creating a new Jira to track HADOOP-5628 for MapReduce
MAPREDUCE-669,eclipse-files target does not create MR_Ant_Builder,"This is the result of project splitting, same as HDFS-450.
The ""eclipse-files"" build target used to create Hadoop_Ant_Builder - an ant based builder for eclipse.
The target still works fine for hadoop/common, but not for for MapReduce or HDFS."
MAPREDUCE-668,Improve CompletedJobStatusStore setup/testcases,mapred.job.tracker.persist.jobstatus.hours expects value in hour. It should be made as an interval. Also sleep time is set to 1hour which is too much. Allowing to configure these values will help in testcases. Also the testcase can be made faster by using mock jobs instead of starting a whole new jobtracker. There is no testcase for checking if status objects are cleanedup or not.
MAPREDUCE-667,"Re HADOOP-2141, JobTracker's clock is not used everywhere","HADOOP-2141 introduced the concept of clock. I can see someplaces where its not used namely
# JobInProgress
# JobHistory 
etc"
MAPREDUCE-666,Job scheduling information on jobtracker.jsp makes it clunky,"Job scheduling information is displayed for each job on the jobtracker.jsp along with many other details. Though it is empty by default, when it is in use, for e.g. with high memory jobs in capacity scheduler, the UI looks clunky with long strings of job scheduling information."
MAPREDUCE-665,Move libhdfs to HDFS project,The subtree src/c++/libhdfs currently resides in mapreduce.  It should be moved to HDFS.
MAPREDUCE-664,distcp with -delete option does not display number of files deleted from the target that were not present on source ,distcp with -delete option should provide information on total number of files deleted from the target that were not present on the source. 
MAPREDUCE-663,distcp command should return hadoop job id ,"When distcp is used through some wrapper script to periodically copy data from source to target, it would be good to have hadoop job ids returned by distcp.  It would help if wrapper script is terminated abnormally, corresponding distcp jobs can be cleaned up, if needed. "
MAPREDUCE-662,distcp -update fails if source directory is empty (i.e. no files to copy) and target directory does not exists.,"It should either create empty target directory or not make any changes on the target (as there is nothing to copy from source), but it should return success. 

Tested version of hadoop has  HADOOP-5675.

-bash-3.1$ bin/hadoop  distcp -Dmapred.job.queue.name=xxx -i -p -update -m 10  hftp://xxx.yyy.com:50070/user/gogate/mirror_test1 hdfs://zzz.yyy.com:8020/user/gogate/mirror_test1

09/06/24 19:46:42 INFO tools.DistCp: srcPaths=[hftp://xxx.yyy.com:50070/user/gogate/mirror_test1]
09/06/24 19:46:42 INFO tools.DistCp: destPath=hdfs://zzz.yyy.com:8020/user/gogate/mirror_test1
09/06/24 19:46:44 INFO tools.DistCp: hdfs://zzz.yyy.com:8020/user/gogate/mirror_test1 does not exist.
09/06/24 19:46:44 INFO tools.DistCp: sourcePathsCount=1
09/06/24 19:46:44 INFO tools.DistCp: filesToCopyCount=0
09/06/24 19:46:44 INFO tools.DistCp: bytesToCopyCount=0.0
With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.FileNotFoundException: File does not exist: hdfs://zzz.yyy.com:8020/user/gogate/mirror_test1
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:457)
	at org.apache.hadoop.tools.DistCp.finalize(DistCp.java:706)
	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:653)
	at org.apache.hadoop.tools.DistCp.run(DistCp.java:858)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
	at org.apache.hadoop.tools.DistCp.main(DistCp.java:885)
"
MAPREDUCE-661,distcp doesn't ignore read failures with -i in setup() before MapReduce job is started,"After HADOOP-3873, file checksums are checked in setup() before actual MapReduce job is started. And when getFileChecksum() fails with socketTimeoutException when called from setup(), distcp fails even though -i option is specified by user. Similar to how map tasks ignore read failures, setup() should also ignore them and continue processing remaining files."
MAPREDUCE-660,MRBench throws NPE,"On running ""hadoop  org.apache.hadoop.mapred.MRBench"" the following exception is obtained:
{noformat}
Exception in thread ""main"" java.lang.NullPointerException
        at java.util.Hashtable.put(Hashtable.java:394)
        at java.util.Properties.setProperty(Properties.java:143)
        at org.apache.hadoop.conf.Configuration.set(Configuration.java:403)
        at org.apache.hadoop.mapred.JobConf.setJar(JobConf.java:208)
        at org.apache.hadoop.mapred.MRBench.runJobInSequence(MRBench.java:177)
        at org.apache.hadoop.mapred.MRBench.main(MRBench.java:280)
{noformat}
"
MAPREDUCE-659,gridmix2 not compiling under mapred module trunk/src/benchmarks/gridmix2 ,"When build is tried in gridmix2, it fails

trunk/src/benchmarks/gridmix2 $ ant
Buildfile: build.xml

init:

compile:
    [javac] Compiling 3 source files to /home/iyappans/new_trunk1/mapreduce/trunk/src/benchmarks/gridmix2/build
    [javac] /home/iyappans/new_trunk1/mapreduce/trunk/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapred/GridMixRunner.java:40: package org.apache.hadoop.streaming does not exist
    [javac] import org.apache.hadoop.streaming.StreamJob;
    [javac]                                   ^
    [javac] /home/iyappans/new_trunk1/mapreduce/trunk/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapred/GridMixRunner.java:123: cannot find symbol
    [javac] symbol: variable StreamJob
    [javac]         JobConf jobconf = StreamJob.createJob(args);
    [javac]                           ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 2 errors

BUILD FAILED
/home/iyappans/new_trunk1/mapreduce/trunk/src/benchmarks/gridmix2/build.xml:27: Compile failed; see the compiler error output for details.

Total time: 1 second
"
MAPREDUCE-658,NPE in distcp if source path does not exist,distcp throws NullPointerException if the source path does not exist. It should emit a proper exception with meaningful error message.
MAPREDUCE-657,CompletedJobStatusStore hardcodes filesystem to hdfs,"Today, completedjobstatusstore stores only to hdfs. It should be configurable to write to local-fs too."
MAPREDUCE-656,Change org.apache.hadoop.mapred.SequenceFile* classes to use new api,
MAPREDUCE-655,Change KeyValueLineRecordReader and KeyValueTextInputFormat to use new api.,
MAPREDUCE-654,Add an option -count to distcp for displaying some info about the src files,"Add an option -count to distcp for displaying metadata about src files like number of files to be copied and total size of src files to be copied.
WIth -count, distcp doesn't do any copy. Just displays info and exits.
This is useful specifically when used with -update.
 distcp -update -count <src>* <dst> 
      would display the number of files to be updated and the total size of copy needs to be done(by comparing the file sizes and checksums at src and dst). Based on this info, users could allocate the number of nodes needed for the actual update job."
MAPREDUCE-653,distcp can support bandwidth limiting,distcp should support an option for user to specify the bandwidth limit for the distcp job.
MAPREDUCE-652,Logging turned on by default while using distcp,"Distcp should have an option to disable logging during a distcp

eg: hadoop distcp --nolog <source dir> <destination dir>

By default logging is enabled or turned on while using distcp.This generates logs in DFS, which need to be cleaned up periodically. During this time, critical applications sometimes fail, when they see distcp logs in the DFS."
MAPREDUCE-651,distcp can retry copying specified number of times in case of transient failures,"distcp can retry specified number of times copying if the mapreduce job fails with transient error.

Providing option -retries <num_tries> to discp would be useful for users who copy large amount of data and see transient errors."
MAPREDUCE-650,Add atomic move option,"Provide support for update to move directories/files atomically by copying the src directory to a tmp directory (with random/unique name) then move the directory to its target destination name after all subdirs/files are copied and verified.

example option ideas
  hadoop ... distcp -update -move src dst
or
  hadoop ... distcp -update -atomic src dst

to assure file correctness at the destination, before distcp performs the  'move' at the end of the copy process, it should first perform a strong signature/cksum (e.g. MD4) on the files.

The issue/need for this is that applications may attempt to start processing data (because files are present), prior to completion of a whole directory copy -- resulting in work against an incomplete data set."
MAPREDUCE-649,distcp should validate the data copied,"distcp should validate the files copied by checking the checksums, if the filesystem supports checksums."
MAPREDUCE-648,Two distcp bugs,"h4. 1. distcp -update launches job when there is at least one dir in source paths to be copied, even though there is nothing to copy.

HADOOP-5675 added fileCount > 0 to be checked to decide whether to launch job. And HADOOP-5762 changed this to fileCount + dirCount > 0 to solve the issue of empty directories not getting copied to destination. With -update, dirCount is incremented without checking if that dir already exists at the destination. So distcp job is launched because of dirCount > 0 even though there is nothing to copy. Incrementing dirCount can be skipped if that dir already exists at the destination in case of -update.

h4. 2. distcp doesn't skip copying file when we do -update on single file if the destfile already exists.

When we do

hadoop distcp -update srcfilename destfilename

it seems to be comparing checksums of srcfilename and destfilename/srcfilename and so skip is not done. It should compare checksums of srcfilename and destfilename.

See also MAPREDUCE-644."
MAPREDUCE-647,"Update the DistCp forrest doc to make it consistent with the latest changes (5472, 5620, 5762, 5826)",New features have been added to DistCp and the documentation must be updated.
MAPREDUCE-646,distcp should place the file distcp_src_files in distributed cache,"When large number of files are being copied by distcp, accessing distcp_src_files seems to be an issue, as all map tasks would be accessing this file. The error message seen is:

09/06/16 10:13:16 INFO mapred.JobClient: Task Id : attempt_200906040559_0110_m_003348_0, Status : FAILED
java.io.IOException: Could not obtain block: blk_-4229860619941366534_1500174
file=/mapredsystem/hadoop/mapredsystem/distcp_7fiyvq/_distcp_src_files
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1757)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1585)
        at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1712)
        at java.io.DataInputStream.readFully(DataInputStream.java:178)
        at java.io.DataInputStream.readFully(DataInputStream.java:152)
        at org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:1450)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1428)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1417)
        at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1412)
        at org.apache.hadoop.mapred.SequenceFileRecordReader.<init>(SequenceFileRecordReader.java:43)
        at org.apache.hadoop.tools.DistCp$CopyInputFormat.getRecordReader(DistCp.java:299)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:336)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
        at org.apache.hadoop.mapred.Child.main(Child.java:170)


This could be because of HADOOP-6038 and/or HADOOP-4681.

If distcp places this special file distcp_src_files in distributed cache, that could solve the problem."
MAPREDUCE-645,"When disctp is used to overwrite a file, it should return immediately with an error message","When disctp is triggered to copy a directory to an already existing file, it just shows a ""copy failed"" error message after 4 attempts without showing any useful error message. This is extremely time consuming on a large cluster and especially when the directory being copied contains several sub-directories.
Instead, it would be an improvement if distcp could return immediately displaying a useful error message when an user attempts such an operation. (This is an unlikely situation but still a valid test case)"
MAPREDUCE-644,distcp does not skip copying file if we are updating single file,"distcp doesn't skip copying file when we do -update on single file if the destfile already exists.

When we do 

hadoop distcp -update srcfilename destfilename

it seems to be comparing checksums of srcfilename and destfilename/srcfilename and so skip is not done. It should compare checksums of srcfilename and destfilename."
MAPREDUCE-643,distcp -pugp error message is not clear when chgrp fail.,"To achieve rsync-like behavior between a local directory and an HDFS instance, a pseudo-distributed MapReduce cluster was started, connected to a fully distributed HDFS instance. An initial distcp from HDFS down to the local fileystem succeeded. The following day, another distcp was run with:

$ bin/hadoop distcp -pugp -update hdfs://nn:7276/data/raw file:///data/raw

It failed; its output is below:

09/06/07 13:14:51 INFO tools.DistCp: srcPaths=[hdfs://nn:7276/data/raw]
09/06/07 13:14:51 INFO tools.DistCp: destPath=file:/data/raw
09/06/07 13:14:55 INFO tools.DistCp: srcCount=10955
09/06/07 13:14:56 INFO mapred.JobClient: Running job: job_200906071310_0001
09/06/07 13:14:57 INFO mapred.JobClient: map 0% reduce 0%
09/06/07 13:15:24 INFO mapred.JobClient: map 1% reduce 0%
09/06/07 13:17:34 INFO mapred.JobClient: map 2% reduce 0%
09/06/07 13:20:04 INFO mapred.JobClient: map 3% reduce 0%
09/06/07 13:20:49 INFO mapred.JobClient: map 4% reduce 0%
09/06/07 13:21:44 INFO mapred.JobClient: map 5% reduce 0%
09/06/07 13:22:33 INFO mapred.JobClient: map 6% reduce 0%
09/06/07 13:25:14 INFO mapred.JobClient: map 7% reduce 0%
09/06/07 13:27:14 INFO mapred.JobClient: map 8% reduce 0%
09/06/07 13:33:34 INFO mapred.JobClient: map 9% reduce 0%
09/06/07 13:37:30 INFO mapred.JobClient: map 10% reduce 0%
09/06/07 13:40:05 INFO mapred.JobClient: map 11% reduce 0%
09/06/07 13:44:55 INFO mapred.JobClient: map 12% reduce 0%
09/06/07 13:48:55 INFO mapred.JobClient: map 13% reduce 0%
09/06/07 13:54:41 INFO mapred.JobClient: map 14% reduce 0%
09/06/07 13:58:30 INFO mapred.JobClient: map 15% reduce 0%
09/06/07 14:00:46 INFO mapred.JobClient: map 16% reduce 0%
09/06/07 14:01:36 INFO mapred.JobClient: map 17% reduce 0%
09/06/07 14:04:12 INFO mapred.JobClient: map 13% reduce 0%
09/06/07 14:04:12 INFO mapred.JobClient: Task Id : attempt_200906071310_0001_m_000006_0, Status : FAILED
java.io.IOException: Copied: 0 Skipped: 264 Failed: 39
at org.apache.hadoop.tools.DistCp$CopyFilesMapper.close(DistCp.java:542) at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:227)
at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2210)

09/06/07 14:04:19 INFO mapred.JobClient: Task Id : attempt_200906071310_0001_m_000006_1, Status : FAILED
java.io.FileNotFoundException: File does not exist: hdfs://nn:7276/tmp/hadoop/mapred/system/distcp_m8n2e/_distcp_src_files
at org.apache.hadoop.dfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:412)
at org.apache.hadoop.fs.FileSystem.getLength(FileSystem.java:684)
at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1420)
at org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1415)
at org.apache.hadoop.mapred.SequenceFileRecordReader.<init>(SequenceFileRecordReader.java:43)
at org.apache.hadoop.tools.DistCp$CopyInputFormat.getRecordReader(DistCp.java:272)
at org.apache.hadoop.mapred.MapTask.run(MapTask.java:219)
at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2210)

(several more tasks fail for the same reason with FileNotFoundException)

With failures, global counters are inaccurate; consider running with -i
Copy failed: java.io.IOException: Job failed!
at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1113)
at org.apache.hadoop.tools.DistCp.copy(DistCp.java:619)
at org.apache.hadoop.tools.DistCp.run(DistCp.java:768)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
at org.apache.hadoop.tools.DistCp.main(DistCp.java:788)


This distcp update operation does succeed without -pugp. 
"
MAPREDUCE-642,distcp could have an option to preserve the full source path,It would be helpful to have an option that preserves the full source path when copying files from one location to another. This is specially important when archiving/moving files from one cluster to another one.
MAPREDUCE-641,WordCount unit test plus a helper class to facilitate testing Mappers and Reducers,"There are to pieces to this The first is a test for WordCount, not because word count actually needed one but because it would be useful to beginners to have an example of how to unit test Mappers and Reducers.

The second piece is AOutputCollector and it's associated unit test TestAOutputCollector. This is an abstract class that can be quickly extended by a stub OutputCollector in your unit tests to collect the output from your Mapper and Reducer tests and make it available for easy retreival when testing to see if the fourth key that was emitted was the one you expected.  I think that this would be a useful tool to have in the main test folder but wasn't sure where would be best to put it. Also, since nothing else in Hadoop uses Hungarian notation you'll probably want to rename it. I didn't because I'm not confident about the naming conventions here and figured that since it  and its test probably wouldn't end up living in the same folder as WordCount that you could just rename it when you moved it.

"
MAPREDUCE-639,Update the TeraSort to reflect the new benchmark rules for '09,The terabyte sort rules have been changed and the example should be updated to match them.
MAPREDUCE-637,Check in the codes that compute the 10^15+1st bit of π,"We have an improved version of the current BaileyBorwinPlouffe example, which able to compute at least the10^15+1st bit of π.  See also http://developer.yahoo.net/blogs/hadoop/2009/05/hadoop_computes_the_10151st_bi.html"
MAPREDUCE-635,IllegalArgumentException is thrown if mapred local dir is not writable.,"If specified mapred local directory doesn't have write permission or is non-existent  then ""IllegalArgumentException"" is thrown. Following error message was displayed while running a sleep job with non-writable mapred local directory specified in mapred-site.xml. 

sleep job command : $hadoop_home/bin/hadoop jar hadoop-examples.jar sleep -m 100 -r 10 

2009-05-12 05:36:46,491 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_200905120525_0001_m_000000_0: java.lang.IllegalArgumentException: n must be positive
        at java.util.Random.nextInt(Random.java:250)
        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.confChanged(LocalDirAllocator.java:243)
        at org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext.getLocalPathForWrite(LocalDirAllocator.java:289)
        at org.apache.hadoop.fs.LocalDirAllocator.getLocalPathForWrite(LocalDirAllocator.java:124)
        at org.apache.hadoop.mapred.MapOutputFile.getSpillFileForWrite(MapOutputFile.java:107)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.sortAndSpill(MapTask.java:1115)
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1028)
        at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:357)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:305)
        at org.apache.hadoop.mapred.Child.main(Child.java:170)

This error message(i.e. IllegalArgumentException) ,somehow, doesn't clearly indicate that problem is with mapred local directory. Error message should be more specific in this case."
MAPREDUCE-634,Jython WordCount.py example fails with Java >= 1.4,"I had a hard time getting the Jython WordCount.py example to work due to changes to Java:

   cd ~/Desktop/hadoop-0.9.2/src/examples/python
   bash compile
   1  ./jpywork/org/apache/hadoop/examples/getopt.java:268: as of release 1.4,
   'assert' is a keyword, and may not be used as an identifier
   (try -source 1.3 or lower to use 'assert' as an identifier)
           if (frame.getglobal(""__debug__"").__nonzero__())
   Py.assert(frame.getglobal(""len"").__call__(frame.getlocal(2))._eq(i$9));

To work around the problem, I updated the compile file.  I added
'--compileropts ""-source 1.3""' to the jythonc call.  Perhaps the
underlying problem is Jython-specific, but at least there's a
workaround for us."
MAPREDUCE-632,Merge TestCustomOutputCommitter with TestCommandLineJobSubmission,TestCommandLineJobSubmission tests job submisison with different command line options. This can be easily enhanced to test custom output committer too and we can do away with TestCustomOutputCommitter
MAPREDUCE-631,TestJobInProgressListener brings up MinMR/DFS clusters for every test,"TestJobInProgressListener brings up/down the cluster several times. Instead, the cluster should just be brought up once, all tests run and then brought down"
MAPREDUCE-630,TestKillCompletedJob can be modified to improve execution times,This test can be easily made into a unit test
MAPREDUCE-629,Modify TestQueueManager to improve execution time,"With a few small changes, the run time of this test can be brought down by half."
MAPREDUCE-628,TestJobInProgress brings up MinMR/DFS clusters for every test,"TestJobInProgress brings up MiniMR clusters in setUp and brings it down in tearDown methods. Since these methods are called before each test, the test brings up/down the cluster several times. Instead, the cluster should just be brought up once, all tests run and then brought down"
MAPREDUCE-627,Modify TestTrackerBlacklistAcrossJobs to improve execution time,Some minor modifications can be made to the test case to improve test execution time
MAPREDUCE-626,Modify TestLostTracker to improve execution time,This test can be made faster with a few modifications
MAPREDUCE-625,Modify TestTaskLimits to improve execution time,"With some small modifications like using a sleep job instead of PI Estimator and using localFS instead of DFS, the run time of this test can be reduced almost by half."
MAPREDUCE-623,Resolve javac warnings in mapred,"Towards a solution for HADOOP-5628, we need to resolve all javac warnings. This jira will try to resolve javac warnings where ever possible and suppress them where resolution is not possible."
MAPREDUCE-622,Streaming should include more unit tests to test more features that it provides.,Currently streaming has only one test that runs with ant test. It should include more tests to check for the features that streaming provides.
MAPREDUCE-621,"hadoop streaming to support shell pipes: ""tr ' ' '\t' | cut -f 3,4""","Hadoop streaming does not support shell pipes, but a lot of times shell pipes are very useful for processing streams of data.

I don't see any reason that hadoop streaming cannot support it.
"
MAPREDUCE-620,Streaming: support local execution,"For streaming, local execution does not involve hadoop.
It is just
  hdfs -cat input | mapper-command | sort | reducer command

While a user can do this herself, having an option to do this by using the infrastructure would greatly simplify user script and and make it easier to ensure that the process will run on the cluster as expected."
MAPREDUCE-617,Streaming should not throw java.lang.RuntimeException and ERROR while displaying help,"Run streaming command as -:
bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar -help 
it will dislay following -:
ERROR streaming.StreamJob: Missing required option -input
Usage: $HADOOP_HOME/bin/hadoop [--config dir] jar \
          $HADOOP_HOME/hadoop-streaming.jar [options]
Options:
  -input    <path>     DFS input file(s) for the Map step
  -output   <path>     DFS output directory for the Reduce step
  -mapper   <cmd|JavaClassName>      The streaming command to run
  -combiner <JavaClassName> Combiner has to be a Java class
  -reducer  <cmd|JavaClassName>      The streaming command to run
  -file     <file>     File/dir to be shipped in the Job jar file
  -dfs    <h:p>|local  Optional. Override DFS configuration
  -jt     <h:p>|local  Optional. Override JobTracker configuration
  -additionalconfspec specfile  Optional.
  -inputformat TextInputFormat(default)|SequenceFileAsTextInputFormat|JavaClassName Optional.
  -outputformat TextOutputFormat(default)|JavaClassName  Optional.
  -partitioner JavaClassName  Optional.
  -numReduceTasks <num>  Optional.
  -inputreader <spec>  Optional.
  -jobconf  <n>=<v>    Optional. Add or override a JobConf property
  -cmdenv   <n>=<v>    Optional. Pass env.var to streaming commands
  -mapdebug <path>  Optional. To run this script when a map task fails
  -reducedebug <path>  Optional. To run this script when a reduce task fails
  -cacheFile fileNameURI
  -cacheArchive fileNameURI
  -verbose

For more details about these options:
Use $HADOOP_HOME/bin/hadoop jar build/hadoop-streaming.jar -info

Exception in thread ""main"" java.lang.RuntimeException:
        at org.apache.hadoop.streaming.StreamJob.fail(StreamJob.java:542)
        at org.apache.hadoop.streaming.StreamJob.exitUsage(StreamJob.java:481)
        at org.apache.hadoop.streaming.StreamJob.parseArgv(StreamJob.java:203)
        at org.apache.hadoop.streaming.StreamJob.go(StreamJob.java:105)
        at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:33)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:155)

It should not display execption and -input and error about missin -input option "
MAPREDUCE-616,"Streaming: when a job is killed, the message should say it was ""killed"" rather than ""failed""",
MAPREDUCE-615,need more unit tests for Hadoop streaming,
MAPREDUCE-613,Streaming should allow to re-start the command if it failed in the middle of input,"Sometimes, we need to use imperfect programs to process data.

Recently, I used a public domain program that did what I needed, but crashed after processing few million records (in my case, more than half of the mappers would succeed, with the rest failing at different %%).

It would be nice to be able to tell the Streaming Framework :

     if the streaming command fails at some input record (and you get ""pipe broken"" from it), 
     restart the command and continue feeding it the data.
     Please log the failing record.

In textmining, quite often, loosing few record of the input makes no  difference at all.
Of course this feature should be disabled by default, and should some ""are really sure"" provision.  (an expert feature).
"
MAPREDUCE-612,streaming should default to KeyValueTextInputFormat with IdentityMapper,"in 15.3 - streaming defaults to TextInputFormat (without -inputformat option).

this is great in case the PipeMapper is used. but in many cases people want to do an IdentityMapper - and it fails with the IdentityMapper:
a) the map output key type becomes LongWritable (but hadoop has already defaulted to expect Text)
b) the map output key is the Line number - and intuitively - this is not what the user expects (almost no one wants to use the line number as the map key).

if we could simply default to KeyValueTextInputFormat with IdentityMapper - that would resolve both of these problems. This would change default behavior though - so a little leery ..

using '-mapper cat' is the common workaround - but it just seems like a needless waste of resources .."
MAPREDUCE-611,Streaming infrastructure should report information about runtime errors ,"For example, if the streaming command is Perl script an syntax error or a runtime error occurs during script execution, the error message (the stack trace) should be reported to the user, separate from and in addition to the rest of the logs and the stderr output."
MAPREDUCE-607,Streaming has its own methods to monitor jobs. It should use the jobclient methods to monitor the jobs,The job monitor methods in streaming has duplicated code. It should use the jobclient methods with retries.
MAPREDUCE-606,Implement a binary input/output format for Streaming,"Lots of streaming applications process textual data with 1 record per line and fields separated by a delimiter. It turns out that there is no point in using any of Hadoop's input/output formats since the streaming script/binary itself will parse the input and break into records and fields. In such cases we should provide users with a binary input/output format which just sends 64k (or so) blocks of data directly from HDFS to the streaming application.

I did something very similar for Pig-Streaming (PIG-94 - BinaryStorage) which resulted in 300%+ speedup for scanning (identity mapper & map-only jobs) data... the parsing done by input/output formats in these cases were pure-overhead."
MAPREDUCE-603,Fix unchecked warnings in contrib code,"There are unchecked warnings in abacus, data_join and streaming."
MAPREDUCE-602,The streaming code should be moved from contrib to Hadoop main framework,"Before the actual move, the code needs a bit of further clean up in the following areas:

1. coding style/convention, and code quality

2. XMLRecordReader: the current implementation is too hacky.

3. Better javadoc

"
MAPREDUCE-601,Streaming command should be logged on the cluster,"Currently, when a streaming job fails, it is difficult for the cluster administrator to figure out what was going on.
Logging all streaming commands in a centralized place will make trouble shooting more efficient."
MAPREDUCE-600,"Streaming command should be able to take its input from a ""file"", rather then from stdin","In some cases, especially when a streaming command is a 3rd party or legacy application, 
it is impossible of inconvenient to make it take its input from stdin.
The command may require that the input file name is specified as a command line option, or the input file name is hard coded.

The streaming infrastructure should allow to specify a name that can be used in open() to create an input stream equivalent to what would be fed to a streaming command as stdin by default."
MAPREDUCE-598,Streaming: better conrol over input splits,"In steaming, the map command usually expect to receive it's input uninterpreted -- just as it is stored in DFS.
However, the split (the beginning and the end of the portion of data that goes to a single map task) is often important and is not ""any line break"".
Often the input consists of multi-line docments -- e.g. in XML.

There should be a way to specify a pattern that separates logical records.
Existing ""Streaming XML record reader"" kind of provides this functionality.  However, it is accepted that ""Streaming XML"" is a hack and needs to be replaced "
MAPREDUCE-596,can't package zip file with hadoop streaming -file argument,"I'm unable to ship a file with a .zip suffix to the mapper using the -file argument for hadoop streaming.  I am able to ship it if I change the suffix to .zipp.  Is this a bug, or perhaps has something to do with the jar file format which is used to send files to the instance?

For example, with this hadoop invocation, and local files ""/tmp/boto.zip"" and ""/tmp/boto.zipp"" which are copies of each other:

$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-0.17.0-streaming.jar -mapper $KCLUSTER_SRC/testmapper.py -reducer $KCLUSTER_SRC/testreducer.py -input input/foo -output output -file /tmp/foo.txt -file /tmp/boto.zip -file /tmp/boto.zipp

I see this line in the invocation standard output:

packageJobJar: [/tmp/foo.txt, /tmp/boto.zip, /tmp/boto.zipp, /tmp/hadoop-karl/hadoop-unjar6899/] [] /tmp/streamjob6900.jar tmpDir=null

But in the current directory of the mapper process, ""boto.zip"" does not exist, while ""boto.zipp"" does.
"
MAPREDUCE-595,streaming command line does not honor -jt option,"ran hadoop streaming command as -:
bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar -input <input path> -mapper <mapper> -reducer <reducer> -output <output path>  -dfs h:p -jt h:p

(Make sure hadoop-site.xml is not in config dir. dfs abnd jt are running )
Streaming will run as local runner 
On looking at StreamJob.java following was found -:
String jt = (String)cmdLine.getValue(""mapred.job.tracker"");
      if (null != jt){
        userJobConfProps_.put(""fs.default.name"", jt);        
      }
Where usage is having create option like -:
Option jt = createOption(""jt"", 
                             ""Optional. Override JobTracker configuration"", ""<h:p>|local"", 1, false);


"
MAPREDUCE-594,Streaming: org.apache.hadoop.mapred.lib.IdentityMapper should not inserted unnecessary keys,"When streaming command specifies 
-mapper org.apache.hadoop.mapred.lib.IdentityMapper
the reducer should receive exactly the same text lines as where present in the input.
The only modification is the reordering the input.
Currently, org.apache.hadoop.mapred.lib.IdentityMapper inserts ofsets in the input as keys.  Which renders it useless.

Moreover, in the latest release org.apache.hadoop.mapred.lib.IdentityMapper just crashes:
>java.io.IOException: Type mismatch in key from map: e
xpected org.apache.hadoop.io.Text, recieved org.apache.hadoop.io.LongWritable
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:331)
        at org.apache.hadoop.mapred.lib.IdentityMapper.map(IdentityMapper.java:40)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:192)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1760)

(I open only one bug, as it is broken anyway, the new behavior does not actually make it any worse than before)"
MAPREDUCE-593,org.apache.hadoop.streaming.TestUlimit fails on JRockit 64-bit; not enough memory,"the testUlimit test sets a memory limit that is too small for Java to start. So it fails with a -1 response instead, which breaks the test. "
MAPREDUCE-592,Streaming does not checks whether  -mapper option is provided or not,"Ran hadoop command as -:
bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar -input in -output out
(Here no mapper is provided using -mapper option).
Stream job will start and map of that job fails.

Streaming should check about the presence of -mapper option and throw proper error is it not there.
"
MAPREDUCE-591,TestStreamingStderr fails occassionally,TestStreamingStderr fails occassionally with a timeout on trunk.
MAPREDUCE-590,permissions of local files change when using the -file option,"When running hadoop streaming, all files mentioned in the -file option have their permissions changed from default to 777.  If the files are not readable by the owner before hadoop is run the job fails but permissions are still changed (and thus, for example, the job will succeed if run again immediately)."
MAPREDUCE-589,StreamXMLRecordReader does not support gzipped files,"I am using Hadoop Streaming to analyze Wikipedia data files, which are in XML format and are compressed because they are so large.  While doing some preliminary tests, I discovered that you cannot use StreamXMLRecordReader with gzipped data files -- the data is fed into the mapper script as raw data.
"
MAPREDUCE-588,streaming failed without printing out the cause (IllegalArgumentException),"When looking at HADOOP-5259, streaming failed as 

$ $HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/contrib/streaming/hadoop-0.21.0-dev-streaming.jar -input (inputpath) -output hdfs:/user/knoguchi/outputpath -mapper cat -reducer cat
packageJobJar: [/tmp/hadoop-unjar27612/] [] /tmp/streamjob27613.jar tmpDir=null
Streaming Command Failed!
$ echo $?
1
"
MAPREDUCE-587,Stream test TestStreamingExitStatus fails with Out of Memory,contrib/streaming tests are failing a test with an Out of Memory error on an OS/X Mac -same problem does not surface on Linux.
MAPREDUCE-586,Streaming reducers throw OutOfMemory for not so large inputs,"I am seeing OutOfMemoryError for moderate size inputs (~70 text files, 20k each ) causing job to fail in streaming. For very small inputs it still succeeds. Looking into details. 
"
MAPREDUCE-585,A corrupt text file causes the maps to hang,A corrupt file hangs a map. The map keeps reading the same record again and again and never finishes.
MAPREDUCE-584,"In Streaming, crashes after all the input is consumed, are not detected","In a Hadoop Streaming, if the user code crashes after all the input has been consumed, the framework considers the process to be successful.
 "
MAPREDUCE-583,get rid of excessive flushes from PipeMapper/Reducer,"there's a flush on the buffered output streams in mapper/reducer for every row of data.

      // 2/4 Hadoop to Tool                                                                                                                   
      if (numExceptions_ == 0) {
        if (!this.ignoreKey) {
          write(key);
          clientOut_.write('\t');
        }
        write(value);
        if(!this.skipNewline) {
            clientOut_.write('\n');
        }
        clientOut_.flush();
      } else {
        numRecSkipped_++;
      }

tried to measure impact of removing this. number of context switches reported by vmstat shows marked decline. 

with flush (10 second intervals):
 r  b   swpd   free   buff  cache   si   so    bi    bo   in    cs us sy id wa
 4  2    784  23140  83352 3114648    0    0  4819 32397 1175 13220 59 11 13 17
 1  2    784 129724  80704 3075696    0    0  4614 27196 1156 14797 49 11 19 21
 4  0    784  24160  83440 3174880    0    0    96 36070 1337 10976 67 11  9 12
 5  0    784 155872  84400 3158840    0    0   125 44084 1280 11044 68 14 10  8
 2  1    784 365128  87048 2892032    0    0   119 38472 1317 11610 69 14 10  7

without flush:
 5  0    784  24652  56056 3217864    0    0   310 29499 1379  7603 76  9  7  8
 5  3    784 118456  54568 3209992    0    0  3249 33426 1173  6828 63 11 12 14
 0  2    784 227628  54820 3198560    0    0  7840 30063 1146  8899 60 10 15 15
 3  1    784  25608  55048 3313512    0    0  3251 36276 1194  7915 60 10 15 15
 1  2    784 197324  49968 3194572    0    0  4714 35479 1281  8204 62 13 12 13

cs goes down by about 20-30%. but having trouble measuring overall speed improvement (too many variables due to spec. execution etc. - need better benchmark).

can't hurt.
"
MAPREDUCE-582,"Streaming: if streaming command finds errors in the --config , it reports that the input file is not found and fails","The error message is 
 ERROR streaming.StreamJob: Error Launching job : Input Pattern ....../* matches 0 files
which is quite confusing and scary.
Neds better error handling."
MAPREDUCE-581,"slurpHadoop(Path, FileSystem) ignores result of java.io.InputStream.read(byte[], int, int)","org.apache.hadoop.streaming.StreamUtil.java line 326

This method call ignores the return value of java.io.InputStream.read() which may read fewer bytes than requested.
"
MAPREDUCE-580,Streaming doesn't accept -cluster local,"Here is the bug fix:

...src/contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java
384,385d383
<     Option cluster = createOption(""cluster"", 
<             ""The cluster to process the data"", ""<h:p>|local"", 1, false);
422d419
<       withOption(cluster).
461d457
<       System.out.println(""  -cluster <h:p|local> optional -- overrides cluster config"");
805c801
< "
MAPREDUCE-579,"Streaming ""slowmatch"" documentation","The documentation for the Streaming module do not include any mention of the ""slowmatch"" parameter, which checks for CDATA sections while looking for XML records.

An important point is that ""slowmatch=true"" violates the principle of least surprise: the ""begin"" and ""end"" parameters become regular expressions instead of exact strings.  This is probably a useful feature, but should definitely be noted since users will be tempted to use the XML record reader on not-strictly-xml files, which may require escaping the ""begin"" and ""end"" patterns.
"
MAPREDUCE-578,Unit test fails on linux: org.apache.hadoop.streaming.TestStreamingExitStatus.testReduceFailNotOk,"Unit test fails on linux: org.apache.hadoop.streaming.TestStreamingExitStatus.testReduceFailNotOk

This fails on Linux (Red Hat Enterprise Linux AS release 4 (Nahant Update 5)) only and passed on Solaris (Hadoop Nightly) and Windows

This is a test that was added as part of 
#  HADOOP-2057.  Streaming should optionally treat a non-zero exit status of a child process as a failed task.

Exception:
java.lang.RuntimeException: Failed to delete /home/hadoopqa/hudson/jobs/Hadoop-Trunk-LinuxTest/workspace/hadoopSource/build/contrib/streaming/test/data/out/_temporary/_reduce_xidrsy
	at org.apache.hadoop.streaming.UtilTest.recursiveDelete(UtilTest.java:48)
	at org.apache.hadoop.streaming.UtilTest.recursiveDelete(UtilTest.java:44)
	at org.apache.hadoop.streaming.UtilTest.recursiveDelete(UtilTest.java:44)
	at org.apache.hadoop.streaming.TestStreamingExitStatus.tearDown(TestStreamingExitStatus.java:70)

Standard Output

test.build.data-or-user.dir=/home/hadoopqa/hudson/jobs/Hadoop-Trunk-LinuxTest/workspace/hadoopSource/build/contrib/streaming/test/data
"
MAPREDUCE-577,Duplicate Mapper input when using StreamXmlRecordReader,"I have an XML file with 93626 rows.  A row is marked by <row>...</row>.

I've confirmed this with grep and the Grep example program included with HADOOP.

Here is the grep example output.  93626	<row>

I've setup my job configuration as follows:   

conf.set(""stream.recordreader.class"", ""org.apache.hadoop.streaming.StreamXmlRecordReader"");
conf.set(""stream.recordreader.begin"", ""<row>"");
conf.set(""stream.recordreader.end"", ""</row>"");

conf.setInputFormat(StreamInputFormat.class);

I have a fairly simple test Mapper.

Here's the map method.

  public void map(Text key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {
        try {

            output.collect(totalWord, one);

            if (key != null && key.toString().indexOf(""01852"") != -1) {
                output.collect(new Text(""01852""), one);
            }

        } catch (Exception ex) {
            Logger.getLogger(TestMapper.class.getName()).log(Level.SEVERE, null, ex);
            System.out.println(value);
        }

    }

For totalWord (""TOTAL""), I get:

TOTAL	140850

and for 01852 I get.

01852	86

There are 43 instances of 01852 in the file.

I have the following setting in my config.  

   conf.setNumMapTasks(1);

I have a total of six machines in my cluster.

If I run without this, the result is 12x the actual value, not 2x.

Here's some info from the cluster web page.

Maps	Reduces	Total Submissions	Nodes	Map Task Capacity	Reduce Task Capacity	Avg. Tasks/Node
0	0	1	6	12	12	4.00

I've also noticed something really strange in the job's output.  It looks like it's starting over or redoing things.
This was run using all six nodes and no limitations on map or reduce tasks.  I haven't seen this behavior in any other case.

08/06/03 10:50:35 INFO mapred.FileInputFormat: Total input paths to process : 1
08/06/03 10:50:36 INFO mapred.JobClient: Running job: job_200806030916_0018
08/06/03 10:50:37 INFO mapred.JobClient:  map 0% reduce 0%
08/06/03 10:50:42 INFO mapred.JobClient:  map 2% reduce 0%
08/06/03 10:50:45 INFO mapred.JobClient:  map 12% reduce 0%
08/06/03 10:50:47 INFO mapred.JobClient:  map 31% reduce 0%
08/06/03 10:50:48 INFO mapred.JobClient:  map 49% reduce 0%
08/06/03 10:50:49 INFO mapred.JobClient:  map 68% reduce 0%
08/06/03 10:50:50 INFO mapred.JobClient:  map 100% reduce 0%
08/06/03 10:50:54 INFO mapred.JobClient:  map 87% reduce 0%
08/06/03 10:50:55 INFO mapred.JobClient:  map 100% reduce 0%
08/06/03 10:50:56 INFO mapred.JobClient:  map 0% reduce 0%
08/06/03 10:51:00 INFO mapred.JobClient:  map 0% reduce 1%
08/06/03 10:51:05 INFO mapred.JobClient:  map 28% reduce 2%
08/06/03 10:51:07 INFO mapred.JobClient:  map 80% reduce 4%
08/06/03 10:51:08 INFO mapred.JobClient:  map 100% reduce 4%
08/06/03 10:51:09 INFO mapred.JobClient:  map 100% reduce 7%
08/06/03 10:51:10 INFO mapred.JobClient:  map 90% reduce 9%
08/06/03 10:51:11 INFO mapred.JobClient:  map 100% reduce 9%
08/06/03 10:51:12 INFO mapred.JobClient:  map 100% reduce 11%
08/06/03 10:51:13 INFO mapred.JobClient:  map 90% reduce 11%
08/06/03 10:51:14 INFO mapred.JobClient:  map 97% reduce 11%
08/06/03 10:51:15 INFO mapred.JobClient:  map 63% reduce 11%
08/06/03 10:51:16 INFO mapred.JobClient:  map 48% reduce 11%
08/06/03 10:51:17 INFO mapred.JobClient:  map 21% reduce 11%
08/06/03 10:51:19 INFO mapred.JobClient:  map 0% reduce 11%
08/06/03 10:51:20 INFO mapred.JobClient:  map 15% reduce 12%
08/06/03 10:51:21 INFO mapred.JobClient:  map 27% reduce 13%
08/06/03 10:51:22 INFO mapred.JobClient:  map 67% reduce 13%
08/06/03 10:51:24 INFO mapred.JobClient:  map 22% reduce 16%
08/06/03 10:51:25 INFO mapred.JobClient:  map 46% reduce 16%
08/06/03 10:51:26 INFO mapred.JobClient:  map 70% reduce 16%
08/06/03 10:51:27 INFO mapred.JobClient:  map 73% reduce 18%
08/06/03 10:51:28 INFO mapred.JobClient:  map 85% reduce 19%
08/06/03 10:51:29 INFO mapred.JobClient:  map 7% reduce 19%
08/06/03 10:51:32 INFO mapred.JobClient:  map 100% reduce 20%
08/06/03 10:51:35 INFO mapred.JobClient:  map 100% reduce 22%
08/06/03 10:51:37 INFO mapred.JobClient:  map 100% reduce 23%
08/06/03 10:51:38 INFO mapred.JobClient:  map 100% reduce 46%
08/06/03 10:51:39 INFO mapred.JobClient:  map 100% reduce 58%
08/06/03 10:51:40 INFO mapred.JobClient:  map 100% reduce 80%
08/06/03 10:51:42 INFO mapred.JobClient:  map 100% reduce 90%
08/06/03 10:51:43 INFO mapred.JobClient:  map 100% reduce 100%
08/06/03 10:51:44 INFO mapred.JobClient: Job complete: job_200806030916_0018
08/06/03 10:51:44 INFO mapred.JobClient: Counters: 17
08/06/03 10:51:44 INFO mapred.JobClient:   File Systems
08/06/03 10:51:44 INFO mapred.JobClient:     Local bytes read=1705
08/06/03 10:51:44 INFO mapred.JobClient:     Local bytes written=29782
08/06/03 10:51:44 INFO mapred.JobClient:     HDFS bytes read=1366064660
08/06/03 10:51:44 INFO mapred.JobClient:     HDFS bytes written=23
08/06/03 10:51:44 INFO mapred.JobClient:   Job Counters 
08/06/03 10:51:44 INFO mapred.JobClient:     Launched map tasks=37
08/06/03 10:51:44 INFO mapred.JobClient:     Launched reduce tasks=10
08/06/03 10:51:44 INFO mapred.JobClient:     Data-local map tasks=22
08/06/03 10:51:44 INFO mapred.JobClient:     Rack-local map tasks=15
08/06/03 10:51:44 INFO mapred.JobClient:   Map-Reduce Framework
08/06/03 10:51:44 INFO mapred.JobClient:     Map input records=942105
08/06/03 10:51:44 INFO mapred.JobClient:     Map output records=942621
08/06/03 10:51:44 INFO mapred.JobClient:     Map input bytes=1365761556
08/06/03 10:51:44 INFO mapred.JobClient:     Map output bytes=9426210
08/06/03 10:51:44 INFO mapred.JobClient:     Combine input records=942621
08/06/03 10:51:44 INFO mapred.JobClient:     Combine output records=49
08/06/03 10:51:44 INFO mapred.JobClient:     Reduce input groups=2
08/06/03 10:51:44 INFO mapred.JobClient:     Reduce input records=49
08/06/03 10:51:44 INFO mapred.JobClient:     Reduce output records=2


"
MAPREDUCE-576,writing to status reporter before consuming standard input causes task failure.,"A Hadoop Streaming task which writes a status reporter line before consuming input causes the task to fail.  Writing after consuming input does not fail.

I caused this failure using a Python reducer and writing a ""reporter:status:foo\n"" line to stderr.  Didn't try writing anything else.

The reducer script which fails:

  #!/usr/bin/env python

  import sys

  if __name__ == ""__main__"":
      sys.stderr.write('reporter:status:foo\n')
      sys.stderr.flush()
      for line in sys.stdin:
          print line

The reducer script which succeeds:

  #!/usr/bin/env python

  import sys

  if __name__ == ""__main__"":
      for line in sys.stdin:
          sys.stderr.write('reporter:status:foo\n')
          sys.stderr.flush()
          print line

The hadoop invocation which I used:

hadoop jar /usr/local/hadoop-0.18.1/contrib/streaming/hadoop-0.18.1-streaming.jar -mapper cat -reducer ./reducer_foo.py -input vectors -output clusters_1 -jobconf mapred.map.tasks=512 -jobconf mapred.reduce.tasks=512 -file ./reducer_foo.py

This is on a 64 node hadoop-ec2 cluster.

One of the errors listed on the failures page (they all appear to be the same):

java.io.IOException: subprocess exited successfully
R/W/S=1/0/0 in:0=1/41 [rec/s] out:0=0/41 [rec/s]
minRecWrittenToEnableSkip_=9223372036854775807 LOGNAME=null
HOST=null
USER=root
HADOOP_USER=null
last Hadoop input: |null|
last tool output: |null|
Date: Mon Oct 20 19:13:38 EDT 2008
MROutput/MRErrThread failed:java.lang.NullPointerException
	at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.setStatus(PipeMapRed.java:497)
	at org.apache.hadoop.streaming.PipeMapRed$MRErrorThread.run(PipeMapRed.java:429)

	at org.apache.hadoop.streaming.PipeReducer.reduce(PipeReducer.java:103)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:318)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2207)

The stderr log for a failed task:

Exception in thread ""Timer thread for monitoring mapred"" java.lang.NullPointerException
	at org.apache.hadoop.metrics.ganglia.GangliaContext.xdr_string(GangliaContext.java:195)
	at org.apache.hadoop.metrics.ganglia.GangliaContext.emitMetric(GangliaContext.java:138)
	at org.apache.hadoop.metrics.ganglia.GangliaContext.emitRecord(GangliaContext.java:123)
	at org.apache.hadoop.metrics.spi.AbstractMetricsContext.emitRecords(AbstractMetricsContext.java:304)
	at org.apache.hadoop.metrics.spi.AbstractMetricsContext.timerEvent(AbstractMetricsContext.java:290)
	at org.apache.hadoop.metrics.spi.AbstractMetricsContext.access$000(AbstractMetricsContext.java:50)
	at org.apache.hadoop.metrics.spi.AbstractMetricsContext$1.run(AbstractMetricsContext.java:249)
	at java.util.TimerThread.mainLoop(Timer.java:512)
	at java.util.TimerThread.run(Timer.java:462)
"
MAPREDUCE-575,Job completes but command doesn't return,"I've had a job submission command hang on many different occasions.  I can't tell exactly what makes it complete some times and hang others.  Here's some information about one time when it hanged.

I started a job at 12:40.  Here is the info from 'ps aux' including the full command line:

/ibrix/home/awm27/jdk1.6.0/bin/java -Xmx1000m -Dhadoop.log.dir=/ibrix/home/awm27/hadoop/logs/log.f17880 -Dhadoop.log.file=hadoop.log -Dhadoop.home.dir=/ibrix/home/awm27/hadoop/bin/.. -Dhadoop.id.str= -Dhadoop.root.logger=INFO,console -Djava.library.path=/ibrix/home/awm27/hadoop/bin/../lib/native/Linux-amd64-64 -classpath /ibrix/home/awm27/hadoop/dynamic_conf/tmp.FkrUc17883:/ibrix/home/awm27/jdk1.6.0/lib/tools.jar:/ibrix/home/awm27/hadoop/bin/../build/classes:/ibrix/home/awm27/hadoop/bin/../build:/ibrix/home/awm27/hadoop/bin/../build/test/classes:/ibrix/home/awm27/hadoop/bin/..:/ibrix/home/awm27/hadoop/bin/../hadoop-0.10.1-core.jar:/ibrix/home/awm27/hadoop/bin/../lib/commons-cli-2.0-SNAPSHOT.jar:/ibrix/home/awm27/hadoop/bin/../lib/commons-codec-1.3.jar:/ibrix/home/awm27/hadoop/bin/../lib/commons-httpclient-3.0.1.jar:/ibrix/home/awm27/hadoop/bin/../lib/commons-logging-1.0.4.jar:/ibrix/home/awm27/hadoop/bin/../lib/commons-logging-api-1.0.4.jar:/ibrix/home/awm27/hadoop/bin/../lib/jets3t.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-5.1.4.jar:/ibrix/home/awm27/hadoop/bin/../lib/junit-3.8.1.jar:/ibrix/home/awm27/hadoop/bin/../lib/log4j-1.2.13.jar:/ibrix/home/awm27/hadoop/bin/../lib/lucene-core-1.9.1.jar:/ibrix/home/awm27/hadoop/bin/../lib/servlet-api.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-ext/ant.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-ext/commons-el.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-ext/jasper-compiler.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-ext/jasper-runtime.jar:/ibrix/home/awm27/hadoop/bin/../lib/jetty-ext/jsp-api.jar org.apache.hadoop.util.RunJar /ibrix/home/awm27/hadoop/build/hadoop-streaming.jar -jobconf mapred.job.name=""MRPSO_RBF_2"" -input MRPSO_RBF/MRPSO_RBF_1 -output MRPSO_RBF/MRPSO_RBF_2 -mapper /ibrix/home/awm27/svn/mrpso/mapper.py -combiner /ibrix/home/awm27/svn/mrpso/reducer.py -reducer /ibrix/home/awm27/svn/mrpso/reducer.py -cmdenv PYTHONPATH=/ibrix/home/awm27/svn/python -cmdenv MRPSO_FUNCTION=RBF -cmdenv MRPSO_DATAFILES=/tmp/tmpT9M4cq


At the time of submission, the jobtracker reported receiving the job and began processing it.  The first line in this part of the logs is:

2007-01-29 12:40:44,072 INFO org.apache.hadoop.mapred.JobInProgress: Choosing cached task tip_0002_m_000002


At 13:16, the job completed, with the following normal log messages:

2007-01-29 13:16:36,115 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000001_0' has completed tip_0002_r_000001 successfully.
2007-01-29 13:16:36,117 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000001_0' has completed.
2007-01-29 13:16:36,566 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000002_0' has completed tip_0002_r_000002 successfully.
2007-01-29 13:16:36,566 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000002_0' has completed.
2007-01-29 13:16:36,879 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000003_0' has completed tip_0002_r_000003 successfully.
2007-01-29 13:16:36,879 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000003_0' has completed.
2007-01-29 13:16:41,808 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_r_000000_0' has completed tip_0002_r_000000 successfully.
2007-01-29 13:16:41,930 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_r_000000_0' has completed.
2007-01-29 13:16:41,940 INFO org.apache.hadoop.mapred.JobInProgress: Job job_0002 has completed successfully.
2007-01-29 13:16:41,942 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000002_0' from 'tracker_m4b-3-2.local:50050'
...
2007-01-29 13:16:50,660 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000016_0' from 'tracker_m4b-3-8.local:50050'
2007-01-29 13:16:50,661 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000044_0' from 'tracker_m4b-3-8.local:50050'
2007-01-29 13:16:50,662 INFO org.apache.hadoop.mapred.JobTracker: Removed completed task 'task_0002_m_000046_0' from 'tracker_m4b-3-8.local:50050'


At 14:03, the hadoop-streaming command (process 21261) that started at 12:40 was still running and using 0.0% of the CPU.  The output of the command ended with:

07/01/29 13:16:41 INFO streaming.StreamJob:  map 100%  reduce 93%
07/01/29 13:16:42 INFO streaming.StreamJob:  map 100%  reduce 100%
07/01/29 13:16:42 INFO streaming.StreamJob: Job complete: job_0002

It seems odd that hadoop-streaming would hang instead of returning.

I hope this information is helpful.  Thanks."
MAPREDUCE-574,Fix -file option in Streaming to use Distributed Cache,"The -file option works by putting the script into the job's jar file by unjar-ing, copying and then jar-ing it again.
We should rework the -file option to use the DistributedCache and the symlink option it provides."
MAPREDUCE-572,If #link is missing from uri format of -cacheArchive then streaming does not throw error.,"Ran hadoop streaming command as -:
bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar -input in -output out -mapper ""xargs cat""  -reducer ""bin/cat"" -cahceArchive hdfs://h:p/pathofJarFile
Streaming submits job to jobtracker and map fails.
For similar with -cacheFile -:
bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar -input in -output out -mapper ""xargs cat""  -reducer ""bin/cat"" -cahceFile hdfs://h:p/pathofFile
followinng error is repoerted back -:
[
You need to specify the uris as hdfs://host:port/#linkname,Please specify a different link name for all of your caching URIs
]


Streaming should check about present #link after uri of cacheArchive and should throw proper error .
"
MAPREDUCE-570,Streaming job fails with with identity mapper class,"Streaming job command: 
$HADOOP_HOME/bin/hadoop  jar $HADOOP_HOME/hadoop-streaming.jar \
    -input myInputDirs \
    -output myOutputDir \
    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \
    -reducer org.apache.hadoop.mapred.lib.IndentityReducer

Error in job tracker hadoop.log:

2008-11-24 22:18:12,637 INFO org.apache.hadoop.mapred.TaskInProgress: Error from attempt_200811242217_0001_m_000001_3: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, recieved org.apache.hadoop.io.LongWritable^D
        at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:415)^D
        at org.apache.hadoop.mapred.lib.IdentityMapper.map(IdentityMapper.java:37)^D
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:47)^D
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:227)^D
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2207)^D
"
MAPREDUCE-568,Streaming causes a lot of broken pipes which leads to job failure,"java.io.IOException: Broken pipe
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:260)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:124)
	at java.io.DataOutputStream.flush(DataOutputStream.java:106)
	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:77)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:215)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1247)


	at org.apache.hadoop.streaming.PipeMapper.map(PipeMapper.java:88)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:48)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:215)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1247)

A lot of these errors occur in streaming. THis leads to job failure. I still am not sure what the reason might be of these errors, but these erros occur too often. I will try and invetigate more to see what the reason might be."
MAPREDUCE-567,Add a new example MR that always fails,"For testing how Hadoop behaves when jobs fail, it's nice to have an example job that simply fails in either the mappers or the reducers."
MAPREDUCE-566,Add default port for jobtracker (mapred.job.tracker),"HADOOP-3317 standardizes port 8020 as the default port for NameNode / HDFS URIs. The mapred.job.tracker property has no such analogue.

I propose specifying a default port of 8021 if no port-component is specified in the user's mapred.job.tracker property."
MAPREDUCE-565,Partitioner does not work with new API," Partitioner does not work with the new API. MapTask.java looks for ""mapred.partitioner.class"" whereas the new API sets it to mapreduce.partitioner.class"
MAPREDUCE-564,Provide a way for the client to get the number of currently running maps/reduces,Add counters for Number of Succeeded Maps and Number of Succeeded Reduces so that client can get this number without iterating through all the task reports while the job is in progress.
MAPREDUCE-563,Security features for Map/Reduce,"This is a top-level tracking JIRA for security work we are doing in Map/reduce. Please add reference to this when opening new security related JIRAs.
 
Logically a subpiece of HADOOP-4487."
MAPREDUCE-562,A single slow (but not dead) map TaskTracker impedes MapReduce progress,"We see cases where there may be a large number of mapper nodes running many tasks (e.g., a thousand). The reducers will pull 980 of the map task intermediate files down, but will be unable to retrieve the final intermediate shards from the last node. The TaskTracker on that node returns data to reducers either slowly or not at all, but its heartbeat messages make it back to the JobTracker -- so the JobTracker doesn't mark the tasks as failed. Manually stopping the offending TaskTracker works to migrate the tasks to other nodes, where the shuffling process finishes very quickly. Left on its own, it can take hours to unjam itself otherwise.

We need a mechanism for reducers to provide feedback to the JobTracker that one of the mapper nodes should be regarded as lost."
MAPREDUCE-561,Restructure the hadoop.mapred package,"The MapReduce code should be split into org.apache.hadoop.mapreduce for the user API (covered by HADOOP-1230), and org.apache.hadoop.mapreduce.server for the server components."
MAPREDUCE-560,Rename dfs package to hdfs for the generated servlet classes,The package name for the generated servlet classes is still org.apache.hadoop.dfs.
MAPREDUCE-559,Clean up javadoc to reflect the public and private interfaces,"Currently hdfs appears in public javadoc. It should not since it not a public interface.
- remove hdfs from the ant target javadoc.
- create a new build target call ""javadoc-dev"" that build the full java doc for developers."
MAPREDUCE-558,"Refactor src structure, but leave package structure alone","This Jira proposes that the src structure be split  as below.
 The package structure remains the same for this Jira. (Package renaming is part of other JIras  such as HADOOP-2885).

The idea is that the src will be split   BEFORE the package restructuring

The new proposed src structure is

src/test - unchanged

src/java - will no longer exist , its content will be move to one of core, hdfs, or mapred

src/core - this will contain the core classes that hadoop applications need to link against.
  It will contain client side libraries of  all fs file systems:  local, hdfs, kfs, etc


   src/core/org.apache.hadoop.{conf, fs, filechache, io, ipc, log, metrics, net, record, security, tools, util)
   src/core/org.apache.hadoop.dfs - this will contain only the client side parts of dfs.
                   HADOOP-2885 will rename package dfs  to package  fs.hdfs 

src/hdfs/org.apache.hadoop.dfs - this will contain only the server side of hdfs. 
      HADOOP-2885 will rename package dfs  to package  fs.hdfs later; a compatible dfs.DistributedFileSystem will be left for compatibility/


src/mapred/org.apache.hadoop.mapred.*

This Jira will not split the jar files."
MAPREDUCE-557,Restructure the hadoop.dfs package,"This Jira proposes restructurign the package hadoop.dfs.

1. Move all server side and internal protocols (NN-DD etc) to hadoop.dfs.server.*

2. Further breakdown of dfs.server.
- dfs.server.namenode.*
- dfs.server.datanode.*
- dfs.server.balancer.*
- dfs.server.common.* - stuff shared between the various servers
- dfs.protocol.*  - internal protocol between DN, NN and Balancer etc.

3. Client interface:
- hadoop.dfs.DistributedFileSystem.java
- hadoop.dfs.ChecksumDistributedFileSystem.java
- hadoop.dfs.HftpFilesystem.java
- hadoop.dfs.protocol.* - the client side protocol"
MAPREDUCE-556,Refactor Hadoop package structure and source tree.,"This Jira proposes refactoring the Hadoop package structure and source tree

Goals
1. A little finer package structure.
   - Current structure is a little flat
   - Smaller files (name node and data node are way too big)

2. The client interfaces and data types sent across the wire should be clearly identifiable by the package they sit in.  This will help preserving app compatibility since it will be very obvious when one breaks
the interface.
3. Split dfs's client and server side jars.
4. Move map-reduce into separate src tree (but same SVN repository) along with its separate jar.
5. The Javadoc for users of Hadoop should not contain the internal server-side interfaces/classes
6. Fix all compiler warnings
7. Fix/minimize findbug warnings


The top level package structure remains unchanged:
   hadoop.fs
   hadoop.dfs 
   hadoop.mapred
   Etc.

Considered changing hadoop.dfs to hadoop.hdfs but the ""h"" does not really add much since hadoop is already part of the package name;  didn't seem worth going to
through the trouble of breaking compatibility.

Changes will occur internally within the above packages.
   sub-Jira HADOOP-2885 proposes restructuring hadoop.dfs.

Other Jiras will be filed for restructuring other parts."
MAPREDUCE-555,Provide an option to turn off priorities in jobs,"The fairshare scheduler can define pools mapping to queues (as defined in the capacity scheduler - HADOOP-3445). When used in this manner, one can imagine queues set up to be used by users who come from disparate teams or organizations (say a default queue). For such a queue, it makes sense to ignore job priorities and consider the queue as strict FIFO, as it is difficult to compare priorities of jobs from different users. "
MAPREDUCE-552,Make fair scheduler's per-job scheduling info visible in the default web UI,HADOOP-3930 added an API for displaying per-job and per-queue scheduling info in the JobTracker web UI and the command-line tools. The fair scheduler should set this info for jobs so it can integrate better with these tools.
MAPREDUCE-551,Add preemption to the fair scheduler,"Task preemption is necessary in a multi-user Hadoop cluster for two reasons: users might submit long-running tasks by mistake (e.g. an infinite loop in a map program), or tasks may be long due to having to process large amounts of data. The Fair Scheduler (HADOOP-3746) has a concept of guaranteed capacity for certain queues, as well as a goal of providing good performance for interactive jobs on average through fair sharing. Therefore, it will support preempting under two conditions:
1) A job isn't getting its _guaranteed_ share of the cluster for at least T1 seconds.
2) A job is getting significantly less than its _fair_ share for T2 seconds (e.g. less than half its share).

T1 will be chosen smaller than T2 (and will be configurable per queue) to meet guarantees quickly. T2 is meant as a last resort in case non-critical jobs in queues with no guaranteed capacity are being starved.

When deciding which tasks to kill to make room for the job, we will use the following heuristics:
- Look for tasks to kill only in jobs that have more than their fair share, ordering these by deficit (most overscheduled jobs first).
- For maps: kill tasks that have run for the least amount of time (limiting wasted time).
- For reduces: similar to maps, but give extra preference for reduces in the copy phase where there is not much map output per task (at Facebook, we have observed this to be the main time we need preemption - when a job has a long map phase and its reducers are mostly sitting idle and filling up slots).
"
MAPREDUCE-548,Global scheduling in the Fair Scheduler,"The current schedulers in Hadoop all examine a single job on every heartbeat when choosing which tasks to assign, choosing the job based on FIFO or fair sharing. There are inherent limitations to this approach. For example, if the job at the front of the queue is small (e.g. 10 maps, in a cluster of 100 nodes), then on average it will launch only one local map on the first 10 heartbeats while it is at the head of the queue. This leads to very poor locality for small jobs. Instead, we need a more ""global"" view of scheduling that can look at multiple jobs. To resolve the locality problem, we will use the following algorithm:
- If the job at the head of the queue has no node-local task to launch, skip it and look through other jobs.
- If a job has waited at least T1 seconds while being skipped, also allow it to launch rack-local tasks.
- If a job has waited at least T2 > T1 seconds, also allow it to launch off-rack tasks.
This algorithm improves locality while bounding the delay that any job experiences in launching a task.

It turns out that whether waiting is useful depends on how many tasks are left in the job - the probability of getting a heartbeat from a node with a local task - and on whether the job is CPU or IO bound. Thus there may be logic for removing the wait on the last few tasks in the job.

As a related issue, once we allow global scheduling, we can launch multiple tasks per heartbeat, as in HADOOP-3136. The initial implementation of HADOOP-3136 adversely affected performance because it only launched multiple tasks from the same job, but with the wait rule above, we will only do this for jobs that are allowed to launch non-local tasks."
MAPREDUCE-546,Provide sample fair scheduler config file in conf/ and use it by default if no other config file is specified,"The capacity scheduler includes a config file template in hadoop/conf, so it would make sense to create a similar one for the fair scheduler and mention it in the README."
MAPREDUCE-543,large pending jobs hog resources,"observing the cluster over the last day - one thing i noticed is that small jobs (single digit tasks) are not doing a good job competing against large jobs. what seems to happen is that:

- large job comes along and needs to wait for a while for other large jobs.
- slots are slowly transfered from one large job to another
- small tasks keep waiting forever.

is this an artifact of deficit based scheduling? it seems that long pending large jobs are out-scheduling small jobs"
MAPREDUCE-540,Upate thread in FairScheduler runs too frequently,The UpdateThread in FairScheduler runs every 500ms (hardcoded). This proves to be very costly when running large clusters. UpdateThread tries to acquire lock on JT object every that often and so seriously affects HeartBeat processing besides everything else. The update interval should be a function of the cluster size. Or in the minimum it should be configurable and by default should be set to a reasonably high default value.
MAPREDUCE-539,Implement a config validator tool for the capacity scheduler,"The capacity scheduler sanity checks configuration when it starts and halts if there are any problems found. For ease of deployment, it would help to have a simple utility that will validate the configuration before the capacity scheduler can be started, and report errors / warnings to the user about (possible) misconfigurations."
MAPREDUCE-538,Port HADOOP-4667 to teh capacity scheduler,HADOOP-4667 has implemented 'global scheduling' for the fair-share scheduler with very promising results - we should port the same to the capacity scheduler.
MAPREDUCE-537,Instrument events in the capacity scheduler for collecting metrics information,We need to instrument various events in the capacity scheduler so that we can collect metrics about them. This data will help us determine improvements to scheduling strategies itself.
MAPREDUCE-536,The information displayed by the capacity scheduler can be improved,"As of now the information displayed by the capacity scheduler is sequential. Following are some ways I think we can improve the display
- It would make more sense if we display it as a table where comparing the information across queues would be easy. Something like
|| ||Queue1||Queue2||
|guaranteed cap|75%|25%|
- Along with  {{Reclaim Time Limit}} there should be a hint/info about how much time capacity-scheduler thinks it will take to reclaim i.e it would be nice to know the time left to reclaim.
|| ||Queue1||Queue2||
|Reclaim time limit|300000|300000|
|Time left to reclaim|500|120000|
- All the timing information should have units specified. {{Reclaim time limit : 300000}} doesnt give any information what the unit is.
|| ||Queue1||Queue2||
|Reclaim time limit|5 mins|5 mins|
|Time left to reclaim|500 msec| 2 mins|

- Common information like disclaimers can move out of the table/display to a common place.
- Showing guaranteed and (actual) running tasks doesnt convey much info. It should be shown together. Something like 
|| ||Queue1||Queue2||
|running/guaranteed maps|1/16|15/16|
- We can also improve/enhance the way boolean information is displayed using ticks and crosses. Something like
|| ||Queue1||Queue2||
|Priorities|(/)|(x)|"
MAPREDUCE-534,Provide accounting functionality for Hadoop resource manager,"HADOOP-3421 describes requirements for a new resource manager in Hadoop to schedule Map/Reduce jobs. In production systems, it would be useful to produce accounting information related to the scheduling - such as job start and run times, resources used, etc. This information can be consumed by other systems to build accounting for shared resources. This JIRA is for tracking the requirements, approach and implementation for producing accounting information."
MAPREDUCE-533,Support task preemption in Capacity Scheduler,"Without preemption, it is not possible to guarantee capacity since long running jobs may occupy task slots for an arbitrarily long time."
MAPREDUCE-532,Allow admins of the Capacity Scheduler to set a hard-limit on the capacity of a queue,"For jobs which call external services, (eg: distcp, crawlers) user/admin should be able to control max parallel tasks spawned. There should be a mechanism to cap the capacity available for a queue/job. "
MAPREDUCE-531,Have end to end tests based on MiniMRCluster to verify the correct behaviour of user limits,"We should have the following:
 - Basic user limit tests
     -- Submit jobs one after another and see that the jobs' usage honours user limits in the steady state.
     -- Submit jobs simultaneously and see that the jobs' usage honours user limits in the steady state.
 - User limit test with unequal share
     -- Submit jobs so that users get unequal share of the cluster. For e.g. configuring the cluster with min-user-limit of 40% and with 3 users should result in a distribution of 40%, 40% and 20%."
MAPREDUCE-529,"Code to create the UI display string for queues in the Capacity Scheduler needs to be synchronized, and needs to better update its information","There are a couple of problems with _SchedulingInfo.toString()_, the code which creates the UI display string for a queue: 
* it needs synchronized access to the _QueueSchedulingInfo_ object, as this same object can be updated by the reclaim-capacity thread, and during a heartbeat.
* the code directly updates its count of running map/reduce tasks. this should be done in a better way, perhaps by calling updateQSIObjects(), rather than walking through the data structures directly. It's also not clear that we want to pay the performance penalty of updating the structures. it maybe OK to provide slightly stale info (the 'staleness' is tiny, in a steady-state and large system, where heartbeats are coming in frequently). "
MAPREDUCE-528,NPE in jobqueue_details.jsp page if scheduler has not started,NullPointerException is observed in jobqueue_details.jsp page if the scheduler has not yet started
MAPREDUCE-527,Capacity Scheduler does not kill reduce tasks if all reducers are in the progress of their last record.,"If the Capacity Scheduler decides to kill a reduce job then it selects the task that made the least progress. In my test setup I created a dummy reduce task that does nothing but waiting indefinitely. All reduce progresses are ""1"" because all reducers are in the progress of their last record. Now the ""getRunningTaskWithLeastProgress(tip)"" will return null, so no task is killed.

Although not very likely this will occur in a production setup (timeout killing would kick in anyway) but it may be a bit unexpecting.

I will attach a patch."
MAPREDUCE-526,Sometimes job does not get removed from scheduler queue after it is killed,"Sometimes when we kill a job, it does get removed from waiting queue, while job status: ""Killed"" with Job Setup and Cleanup: ""Successful"" 
Also JobTracker webui shows job under failed jobs lists and hadoop job -list all, hadoop queue <queuename> -showJobs also shows jobs state=5.
Prior to killing job state was ""Running""
"
MAPREDUCE-525,Have end to end tests based on MiniMRCluster to verify the correct behaviour of job priorities.,"We should have the following tests:
 - Basic priority test: submit jobs with different priorities and verify their proper ordering and running.
 - New jobs with higher priority are submitted: verify that they are inserted at right positions in the queue and that they run accordingly.
 - Changing the priority of an existing waiting job: verify that the order of jobs is rehashed.
 - Changing the priority of an existing running job: verify that the order of jobs is rehashed and that running of the jobs is affected.
"
MAPREDUCE-524,Have end to end tests based on MiniMRCluster to verify the correct behaviour of job initialization.,Write tests to verify that the right number of jobs in the right order are initialized and that the limits on the number of jobs that can stay initialized at any time are honoured.
MAPREDUCE-523,User limit is not expanding back properly.,User limit is not expanding back properly.
MAPREDUCE-522,Rewrite TestQueueCapacities to make it simpler and avoid timeout errors,"We have seen TestQueueCapacities fail periodically and there have been a couple of times fixes partially fixed the problem, the most recent instance being HADOOP-5869. I found another instance of failure, while running tests locally while testing a different patch. This was a different symptom from the ones we've seen before. The core problem is that the test is too complex and relies on too many things working correctly to be useful. It would make sense to revisit the purpose of the test and see if a simpler model can serve it."
MAPREDUCE-521,After JobTracker restart  Capacity Schduler does not schedules pending tasks from already running tasks.,After JobTracker restart  Capacity Schduler does not schedules pending task from already running tasks.
MAPREDUCE-520,The capacity schedule must start a timer when a queue is underserved,"It is important to the user that the timer that controls preemption be started when a queue is underserved, regardless of whether any other queues are over allocation."
MAPREDUCE-519,Fix capacity scheduler's documentation,Parent jira for all documentation related issues in capacity scheduler.
MAPREDUCE-518,Have end to end tests based on MiniMRCluster to verify correct behaviour of slot reclamation by queues.,"We should have a test that submits long running jobs to different queues one after the other, and ensures that queues get required capacity or get back taken-away capacity after killing tasks within the specified amount of time."
MAPREDUCE-517,The capacity-scheduler should assign multiple tasks per heartbeat,"HADOOP-3136 changed the default o.a.h.mapred.JobQueueTaskScheduler to assign multiple tasks per TaskTracker heartbeat, the capacity-scheduler should do the same."
MAPREDUCE-516,Fix the 'cluster drain' problem in the Capacity Scheduler wrt High RAM Jobs,"When a HighRAMJob turns up at the head of the queue, the current implementation of support for HighRAMJobs in the Capacity Scheduler has problem in that the scheduler stops assigning tasks to all TaskTrackers in the cluster until a HighRAMJob finds a suitable TaskTrackers for all its tasks.

This causes a severe utilization problem since effectively no new tasks are allowed to run until the HighRAMJob (at the head of the queue) gets slots."
MAPREDUCE-515,CapacityTaskScheduler.MapSchedulingMgr.killTasksFromJob() will not work as expected,"Once capacity-scheduler decides on killing tasks, it selects running-jobs from the queue and issues {{killTasksFromJob()}}. The order in which it kills is as follows
- non-local maps
- local maps

_Killing non-local maps :_
The code here uses {{JobInProgress.getNonLocalRunningMaps()}}. HADOOP-2119 introduced this for handling cases like _random-writer_. Hence this api will return an empty structure if there are reducers in the job. Hence the code fails to serve its purpose. 
"
MAPREDUCE-514,Check for invalid queues in capacity scheduler,"The {{ResourceManagerConf}} class that is being moved to the capacity scheduler of HADOOP-3445 needs to check for a queue name that is not configured in the {{resource-manager-conf.xml}} file in its APIs and fail if it is not available. This feature was originally available, but due to subsequent changes in HADOOP-3698, queues are no longer being configured as part of the mentioned configuration file. Hence we need a different mechanism to check for valid queues."
MAPREDUCE-513,Prior code fix in Capacity Scheduler prevents speculative execution in jobs,"As part of the code fix for HADOOP-4035, the Capacity Scheduler obtains a task from JobInProgress (calling obtainNewMapTask() or obtainNewReduceTask()) only if the number of pending tasks for a job is greater than zero (see the if-block in TaskSchedulingMgr.getTaskFromJob()). So, if a job has no pending tasks and only has running tasks, it will never be given a slot, and will never have a chance to run a speculative task. 
"
MAPREDUCE-512,Add tests for the DFS HTML and JSP pages,"Add some basic tests to look for the standard JSP pages on a locally deployed MiniMR cluster

1. namenode: check that dfshealth is present
2. datanode: check that all the datanode JSPs load
3. GET the standard servlets.

The initial checks can just use httpclient to GET the pages; no need (yet) for HtmlUnit. 

If the tests were designed to take optional URLs  (e.g test.namenode.url and test.datanode.url) they could be run against processes brought up externally/remotely

They would
* help test that the JSP pages are being compiled down and bundled into the JARS
* verify the classpath is getting set up right
* check that the Jasper engine is working
* check the servlets are all registering

I've effectively had to do this in my own code; having a set of these tests inside hadoop would make it easier to point the blame at the classpath setup or something else. "
MAPREDUCE-510,A way to get tasks current working directory via JobConf,"It would be good to have tasks know its current working directory via JobConf, instead of deriving the same or trying to get local current working directory. I see that we already derive that while updating classpath. Would it be good idea to have it as a config variable to make it available in task execution environment? "
MAPREDUCE-509,Setting the network interface for TaskTracker connection to task tracker http server,"I ma running TestDFSIO using different network interfaces.
For that, I am modifying the IP address in hadoop-default.xml, hadoop-site.xml and slaves files in the conf directory.
Unfortunately, I can still observed connection from TaskTracker to task tracker http server over the default network interface (eth0) when it is configured to use different network interface.
Can you tell me what should be done to be sure that all connection used a unique network interfaces?
"
MAPREDUCE-508,dynamic heartbeat interval for the locality-aware task scheduling,"In current hadoop release (0.17.0), there is no special scheduling policy for those tasktrackers who have no data for some jobs. So, there would be inefficient in some senarios. For example, tasktracker A has the data for a job, but tasktracker B, which has no data for this job, sends the heartbeat message to the jobtracker for a new task before tasktrack A. The task may be scheduled to B instead of A. While Jobtracker has to find a new task for tasktracker A when A ask for a new task. 

In this situation, if jobtracker has some reservation policy, such as reserve the task for tasktracker A and let B ask for new task in the next heartbeat message, that would be more efficient. Because before tasktracker B asking for new task the second time, tasktracker A has applied for a new task and jobtracker has scheduled the task to A.

Here is a rough idea to deal with the senario above:
(1) Jobtracker receives the heartbeat message sent by tasktracker B, which has no data for any job.
(2) Jobtracker send response message to tasktracker B with a new heartbeat message interval, but does not schedule new task to B.  The new heartbeat interval should be shorter the current heartbeat interval, for example, current_heartbeat_interval/2.
(3) Tasktracker B receive the response from jobtracker, and sends another heartbeat message for a new task after a period of current_heartbeat_interval/2 .
(4) Jobtracker then find a new task for tasktracker B.

This is just an primary idea for the improvement of the locality-aware scheduling. Any comments are welcome."
MAPREDUCE-507,Have backlinks from history pages to main jobtracker page,"When we go from jobtracker.jsp to the job history page, and from then on to any other page in history, there is no way to go back to the jobtracker page. It would be nice to add this."
MAPREDUCE-506,make HistoryViewer a public class.,org.apache.hadoop.mapred.HistoryViewer is useful to access Job history files from application code. The class can be made public.
MAPREDUCE-504,JobTracker's configuration should be shown on jobtracker.jsp,A job's configuration is displayed for each job on {{jobdetails.jsp}}.. It would be really useful if {{JobTracker}}'s config is also displayed on jobtracker.jsp.
MAPREDUCE-503,Add visual cue to denote if a job is running or not in scheduler UI page,add visual cue to denote if a job is running or not in scheduler UI page.
MAPREDUCE-502,Allow jobtracker to be configured with zero completed jobs in memory,There is no way to specify that the jobtracker should not keep any completed job in memory.
MAPREDUCE-501,Spawning tasks faster,"In the current implementation, tasks are assigned to tasktrackers by adding an appropriate action to the heartbeat response list. Each heartbeat response can start one task. As the minimum interval between heartbeats is 5 sec (by default), if the nodes are strong machines (say, each node has 10 task ""slots"") and the cluster is idle, this means that some tasks are spawned after some time (in our example, the last task will be spawned after 45 seconds).

This can be significantly improve the end-to-end execution time if most jobs are finished in the order of minutes.

The patch I attach requests from each TaskTracker to reply in 1/5th of the regular heartbeat interval time if it was assigned a task in this round, making spawning of multiple tasks much more efficient.

A better approach would be to have each TaskTracker report the number of free slots it has (instead of only if it can accept more work or not) and have the JobTracker push the appropriate number of tasks in one response, but this will require changes in the current communication protocol."
MAPREDUCE-500,Clean up the JobTracker code,"My IDE flags a lot of trouble in the JobTracker code, but I dont want to mix those changes with any lifecycle changes. After doing that, then I'd like to clean up the code in JobTracker

-move to generic types and foreach loops over Vector and iterators.
-give all threads the correct type
-stop using package scoped static variables to pass instance-data around specifically 
 TASKTRACKER_EXPIRY_INTERVAL
 RETIRE_JOB_CHECK_INTERVAL
 RETIRE_JOB_INTERVAL
-fix up all the javadoc warnings 
-remove the needless this. references on lots of local variables
-replace the log + stringifyException with log(text,exception). 

Its only an hour or so of work, and would improve the code maintainability, but it would  make merging existing code harder."
MAPREDUCE-499,Revert extra debugging,"It appears that HADOOP-3647 is actually caused by a bad disk, unobserved given HADOOP-4277. The extra debugging can be removed."
MAPREDUCE-497,"TaskTracker.addDiagnostics(String file, int num, String tag) could exit early if num==0","When a TaskTracker job finishes,  taskFinished() is invoked. 

as part of its work it
 1. loads in a conf option (that is not in hadoop-default, incidentally) , mapred.debug.out.lines , default value -1;
 2. calls addDiagnostics passing in that line count

addDiagnostics either builds a string buffer of all the output, or creates a linear array of lines and runs adds them, shuffling them up if there are more lines than expected. 

This is all unneeded if the number of lines to print == 0; the entire reading in of the output file can be skipped. This may speed up termination slightly on a run with a large output file and mapred.debug.out.lines ==0. 

Note also that a circular buffer would handle the lines>0 problem without having to copy all the strings around."
MAPREDUCE-495,Makes hidden file filter at public scope,
MAPREDUCE-493,Provide -outputcommitter option for streaming and pipes,"Similar to -inputformat and -outputformat options in streaming and pipes, we should have -outputcommitter option to specify the job outputcommitter to specify the configuration property _mapred.output.committer.class_ ."
MAPREDUCE-492,"Pending, running, completed tasks should also be shown as percentage",
MAPREDUCE-490,Allow printing of TaskEvents for a Job from command line,"It might make sense to have these commands:

bin/hadoop job -numEvents <job_id> : this will print the number of events that the job generated so far

bin/hadoop job <fromEvent> <maxEvents> <job_id> : this will print the events in the range {fromEvent, fromEvent + maxEvents} for the given job id (only the contents of the event objects, not the actual logs). For example, it might print 
      event# 100, Map/Reduce, Success, http://foo.com:port/, taskId

bin/hadoop job <fromEvent> <maxEvents> <full> <job_id> : This will print the contents of the logs (like what the JobClient does today)
"
MAPREDUCE-488,JobTracker webui should report heap memory used,As of today JobTracker's webui reports _total-available-heap-memory_ and _max-heap-memory_. I think it will be useful to show the _actual_ heap memory used i.e {{total - free}}. 
MAPREDUCE-487,DBInputFormat support for Oracle,DBInputFormat doesnt support interfacing with Oracle.
MAPREDUCE-486,JobTracker web UI counts COMMIT_PENDING tasks as Running,"In jobdetails.jsp, tasks in COMMIT_PENDING state are listed as ""Running"". I propose creating another column in this table for COMMIT_PENDING tasks, since users find it confusing that a given job can have more tasks ""Running"" than their total cluster capacity."
MAPREDUCE-485,jobID() lookup failure should notify client,"https://issues.apache.org/jira/browse/HADOOP-4420 (which also fixes https://issues.apache.org/jira/browse/HADOOP-4419) gracefully handles null ptr exceptions if JobTracker.setJobPriority() and killJob() get a null reference back from JobID lookup by returning silently.  Future versions, though, should throw a better exception back to the client (see this comment: https://issues.apache.org/jira/browse/HADOOP-4419?focusedCommentId=12639889#action_12639889) so they can handle the problem.

This JIRA is for the separate issue of the API change that would require. 
"
MAPREDUCE-484,Logos for Hive and JobTracker,"Greetings fine Hadoop peoples,

While working on a few projects here at Cloudera we found ourselves wanting for some sort of icon for both the JobTracker and for Hive. After checking on the project page for Hive (the JobTracker doesn't really have one) and finding that these items have no icons, we rolled up our sleeves and made some. We'd like to contribute these to the project, so if you want 'em, they're all yours. "
MAPREDUCE-481,Improvements to Global Black-listing of TaskTrackers,"HADOOP-4305 added a global black-list of tasktrackers.

We saw a scenario on one of our clusters where a few jobs caused a lot of tasktrackers to immediately be blacklisted. This was caused by a specific set of jobs which (same user) whose tasks were shot down the by the TaskTracker for being over the vmem limit of 2G. Each of these jobs had over 600 failures of the same kind. This resulted in each of the users black-listing some tasktrackers, which in itself is wrong since the failures had nothing to do with the node on which the failure occurred (i.e. high memory usage) and shouldn't have had to penalized the tasktracker. We clearly need to start treating system and user failures separately for black-listing etc. A DiskError is fatal and should probably we blacklisted immediately while a task which was 'failed' for using more memory shouldn't count against the tasktracker at all!

The other problem is that we never configured mapred.max.tracker.blacklists and continue to use the default value of 4. Further more this config should really be a percent of the cluster-size and not a whole number. "
MAPREDUCE-480,Dependency cycle: log and mapred,There's a dependency cycle between org.apache.hadoop.log and org.apache.hadoop.mapred. Moving the inner servlet class in LogLevel to StatusHttpServer fixes it
MAPREDUCE-479,Add reduce ID to shuffle clienttrace,Current clienttrace messages from shuffles note only the destination map ID but not the source reduce ID. Having both source and destination ID of each shuffle enables full tracing of execution. 
MAPREDUCE-478,separate jvm param for mapper and reducer,"Memory footprint of mapper and reducer can differ. 
It would be nice if we can pass different jvm param (mapred.child.java.opts) for mappers and reducers."
MAPREDUCE-477,Support for reading bzip2 compressed file created using concatenation of multiple .bz2 files ,Bzip2Codec supported in Hadoop 0.19/0.20  should support for reading bzip2 compressed file created using concatenation of multiple .bz2 files 
MAPREDUCE-476,extend DistributedCache to work locally (LocalJobRunner),"The DistributedCache does not work locally when using the outlined recipe at http://hadoop.apache.org/core/docs/r0.16.0/api/org/apache/hadoop/filecache/DistributedCache.html 

Ideally, LocalJobRunner would take care of populating the JobConf and copying remote files to the local file sytem (http, assume hdfs = default fs = local fs when doing local development.
"
MAPREDUCE-475,JobConf should validate key names in well-defined namespaces and warn on misspelling,"A discussion on the mailing list reveals that some configuration strings in the JobConf are deprecated over time and new configuration names replace them:

e.g., ""mapred.output.compression.type"" is now replaced with ""mapred.map.output.compression.type""

Programmers who have been manually specifying the former string, however, receive no diagnostic output during testing to suggest that their compression type is being silently ignored.

It would be desirable to notify developers of this change by printing a warning message when deprecated configuration names are used in a newer version of Hadoop. More generally, when any configuration string in the mapred.\*, fs.\*, dfs.\*, etc namespaces are provided by a user and are not recognized by Hadoop, it is desirable to print a warning, to indicate malformed configurations. No warnings should be printed when configuration keys are in user-defined namespaces (e.g., ""myprogram.mytask.myvalue"").

"
MAPREDUCE-474,ability to report numeric progress within a particular key,"I'd like some mechanism to report numeric progress in maps that have side effects. In the common case, there is exactly one key/value for each map and they do a lot of work (minutes to hours) while working on that key. It would be nice if mapred.Reporter had a progress(float) method that set the progress within the current key."
MAPREDUCE-472,Unassigned tasks cannot be killed/failed from the web UI,"Even though private actions are enabled, tasks in UNASSIGNED state cannot be killed/failed from the web UI like other tasks as there are no such hyper-links on taskdetails.jsp."
MAPREDUCE-471,Refactor JobTracker.Expire* arround an utility class,"I would like to propose a new class, called ExpiringHashSet, which could factorize the code from JobTracker.ExpireLaunchingTasks and JobTracker.ExpireTrackers.

It behaves like an ordinary HashSet, but adds two methods and one argument to the constructor.
That argument, {{lifeTime}}, tells after how much milliseconds an element added to the container expire and is removed.
The first method, {{update(element)}}, takes an element as it argument and delay it's expiration by {{lifeTime}} milliseconds.
The last method, {{makeExpire}} is called by the ExpiringHashSet just before it remove an old item. If that method return false, the item won't be removed.
Nothing expire while we're synchronized on the ExpiringHashSet."
MAPREDUCE-470,jobdetails.jsp could show analysejobhistory.jsp details after job is complete,It would be good to have analysejobhistory details shown on jobdetails.jsp for successfully completed jobs. 
MAPREDUCE-468,Let users specify -classpath for the tasks,"One user requested 

bq.  what I am not able to solve is to add the jar file that is inside the (distributedCache) archive to the task's class path.

I believe letting users add the classpath by ""mapred.child.java.opts"" would be useful.
Currently, this '-classpath' is ignored due to the same problem as HADOOP-1493."
MAPREDUCE-467,Collect information about number of tasks succeeded / total per time unit for a tasktracker. ,"Collecting information of number of tasks succeeded / total per tasktracker and being able to see these counts per hour, day and since start time will help reason about things like the blacklisting strategy."
MAPREDUCE-466,The code in ReduceTask::fetchOutputs that deals with fetch failures can be refactored to a separate method,"There is big chunk of code to handle fetch failures in ReduceTask::fetchOutputs. To improve the readability of code, this should be moved out to a separate method."
MAPREDUCE-465,Deprecate org.apache.hadoop.mapred.lib.MultithreadedMapRunner,Deprecate org.apache.hadoop.mapred.lib.MultithreadedMapRunner to use org.apache.hadoop.mapreduce.lib.MultithreadedMapRunner 
MAPREDUCE-463,The job setup and cleanup tasks should be optional,"For jobs that require low latency and do not require setup or cleanup tasks for the job, it should be possible to turn them off for that job."
MAPREDUCE-461,Enable ServicePlugins for the JobTracker,Allow ServicePlugins (see HADOOP-5257) for the JobTracker.
MAPREDUCE-459,Elegant decommission of lighty loaded tasktrackers from a map-reduce cluster,There is a need to elegantly move some machines from one map-reduce cluster to another. This JIRA is to discuss how to find lightly loaded tasktrackers that are candidates for decommissioning and then to elegantly decommission them by waiting for existing tasks to finish.
MAPREDUCE-458,Adding caching to Hadoop which is independent of the task trackers.,"It would be nice to have a feature in Hadoop that could cache files locally that is independent of TaskTrackers and JobTrackers. Hadoop-288 caching is dependent on the tasktrackers. In an environment where you would dynamically bring up and down the TaskTrackers for resource sharing, that is problematic. It would be good to have this feature wherein you can install tasktrackers/jobtrackers on these machines using this caching mechanism. The caching feature could use something like Bittorent /http/rsync to copy the main hadoop.jar."
MAPREDUCE-456,add a link to the dfs from job tracker WI,add a link to the dfs from job tracker WI
MAPREDUCE-453,Provide more flexibility in the way tasks are run,"*The aim*
With [HADOOP-3421] speaking about sharing a cluster among more than one organization (so potentially with non-cooperative users), and posts on the ML speaking about virtualization and the ability to re-use the TaskTracker's VM to run new tasks, it could be useful for admins to choose the way TaskRunners run their children. 

More specifically, it could be useful to provide a way to imprison a Task in its working directory, or in a virtual machine.
In some cases, reusing the VM might be useful, since it seems that this feature is really wanted ([HADOOP-249]).

*Concretely*
What I propose is a new class, called called SeperateVMTaskWrapper which contains the current logic for running tasks in another JVM. This class extends another, called TaskWrapper, which could be inherited to provide new ways of running tasks.
As part of this issue I would also like to provide two other TaskWrappers : the first would run the tasks as Thread of the TaskRunner's VM (if it is possible without too much changes), the second would use a fixed pool of local unix accounts to insulate tasks from each others (so potentially non-cooperating users will be hable to share a cluster, as described in [HADOOP-3421])."
MAPREDUCE-452,tasktracker checkpointing capability,"This relates to allowing a resource manager (e.g., hadoop on demand) to grow and (rarely) shrink jobs on the fly.

Growing is already supported. Shrinking could be done in 2 ways - (1) consider the machine dead and allow speculative execution to take care of it or (2) moving the existing map outputs from that machine somewhere else (another machine, dfs) - ""task tracker checkpointing"" 

In the case of IO only intensive jobs,  checkpointing the tasktracker doesn't do much for you.  But, in the case of CPU or other scarce resource (e.g., a DB or Webpage cache...), the checkpointing could be very useful.  The question is how often is this the case and how useful?





"
MAPREDUCE-451,TaskTracker's Memory resource should be considered when tasktracker asks for new task,"Currently, taskTracker only considers enough free disk space left when it asks for new task, memory resource should be considered too, or it may works badly in SMP environment.
"
MAPREDUCE-450,"OutputFormat should have a ""close"" method called after all the reducers have completed","It would be very useful for OutputFormat's to have a ""close"" method so that any global logic for outputting can take place there. For example, to output a meta data file along with all the reduce outputs. The close method should have the following signature and be run after all the reducers have finished, but before the ""work output path"" is renamed to the final output path:

void close(FileSystem fs, JobConf job, Progressable progress) throws IOException"
MAPREDUCE-449,There is little information provided when the TaskTracker kills a Task that has not reported within the timeout (600 sec) interval - this patch provides a stack trace of the task ,"When we have a task that is killed for not reporting, sometimes there is an obvious programming error, and sometimes the reason the job didn't report is unclear.
This patch will cause the TaskTracker to try to generate a stack trace of the offending task before the task is killed.
Given how opaque process control is in java, a program is run to generate the stack trace, using the PID extracted from the undocumented UNIXProcess class

The attached patch is against 0.16.0, as that is the release we use.
This will only work on Unix machines -- or JVM's what use the java.lang.UNIXProcess implementation for the java Process object.
The script that generates the stack trace is very linux specific.
The code changes will run on jvm's where the UNIXProcess class is not available, without failure, but no stack trace will be generated.
"
MAPREDUCE-448,Facility to connect back to a job from the command line. ,"There should a facility to connect back to a job from the command line. Once the job is fired from the client and say for some reason the connection is lost, there is no way to connect back for tracking the job's progress from the command line. Something like 'bin/hadoop job -connect <job-id>'. "
MAPREDUCE-447,Add Serialization for RecordIO,"Implement org.apache.hadoop.io.serialization.Serialization/Serializer/Deserializer interfaces

"
MAPREDUCE-446,The WebUI pages that display the list of map and reduce tasks should also include the hostname where the task is running,"Currently, the page that displays the list of map tasks shows ""Task, Complete, Status, Start time, End Time, Counters"". If this could show the hostname as well, it could be helpful in analyzing cases where tasks in a given set of nodes execute much slower than the rest."
MAPREDUCE-445,Web service interface to the JobTracker,I think we need to provide a web services interface to submit and track jobs. This will simplify cross-version and non-Java access to JobTracker functionality.
MAPREDUCE-444,Job should be able to specify whether task vm is 32 or 64 bit,"Perhaps a job should be able to specify whether it wants it's task VM's to be 32 or 64 bit.  This could be accomplished by the -d32 and -d64 java options when the task VM is exec'd.  This becomes important for native libs.
"
MAPREDUCE-443,snapshot a map-reduce to DFS ... and restore,"The idea is to be able to issue a command to the job tracker that
will halt a map-reduce and archive it to a directory in such a way
that it can later be restarted.

We could also set a mode that would cause this to happen to a job
when it fails.  This would allow one to debug and restart a failing
job reasonably, which might be important, for long running jobs.  It
has certainly been important in similar systems I've seen before.  One 
could restart with a new jar or work bench a single failing map or reduce.
"
MAPREDUCE-442,Ability to re-configure hadoop daemons online,"Example : 
Like we have _bin hadoop mradmin -refreshNodes_ we should also have _bin hadoop mradmin -reconfigure_ which re-configures mr while the cluster is online. Few parameters like job-expiry-interval etc can be changed in this way without having to restart the whole cluster. 

Master, once reconfigured, can ask the slaves to reconfigure (reload its config) from a well defined location on hdfs or via heartbeat. 

We can have some whitelisted configs that have _reloadable_ property. "
MAPREDUCE-441,TestMapReduceJobControl.testJobControlWithKillJob timedout in of the hudson runs,"TestMapReduceJobControl.testJobControlWithKillJob timedout in of the hudson runs @
http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/530/testReport/org.apache.hadoop.mapreduce.lib.jobcontrol/TestMapReduceJobControl/testJobControlWithKillJob/"
MAPREDUCE-440,-archives option in JobConf doesn't support symlink for an uncompressed archive directory,"According to http://hadoop.apache.org/core/docs/r0.19.1/streaming.html#Large+files+and+archives+in+Hadoop+Streaming, it should be possible to have an archive uncompressed into the working directory of a job with a given alias.  The documentation here says that
""The -archives option allows you to copy jars locally to the cwd of tasks and automatically unjar the files. For example:

-archives hdfs://host:fs_port/user/testfile.jar#testlink3

In the example above, a symlink testlink3 is created in the current working directory of tasks. This symlink points to the directory that stores the unjarred contents of the uploaded jar file. ""

This feature currently breaks because the entires string, including the alias, is validated as a filename by the GenericOptionsParser
I've pasted a stacktrace ( with modified filenames/hosts) below

java.io.FileNotFoundException: File hdfs://host:fs_port/user/testfile.jar#testlink3 does not exist.
        at org.apache.hadoop.util.GenericOptionsParser.validateFiles(GenericOptionsParser.java:319)
        at org.apache.hadoop.util.GenericOptionsParser.processGeneralOptions(GenericOptionsParser.java:247)
        at org.apache.hadoop.util.GenericOptionsParser.parseGeneralOptions(GenericOptionsParser.java:345)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:136)
        at org.apache.hadoop.util.GenericOptionsParser.<init>(GenericOptionsParser.java:121)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:59)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.streaming.HadoopStreaming.main(HadoopStreaming.java:32)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:165)
        at org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)

This breaks a number of jobs that worked with the cacheArchives option in hadoop streaming."
MAPREDUCE-437,JobTracker must ask for a new FS instance and close it when terminated.,"This is something I've been experimenting with HADOOP-3268; I'm not sure what the right action is here.

-currently, the JobTracker does not close() its filesystem when it is shut down. This will cause it to leak filesystem references if JobTrackers are started and stopped in the same process.

-The TestMRServerPorts test explicitly closes the filesystem
        jt.fs.close();
        jt.stopTracker();

-If you move the close() operation into the stopTracker()/terminate logic, the filesystem gets cleaned up, but 
TestRackAwareTaskPlacement and TestMultipleLevelCaching fail with a FilesystemClosed error (stack traces to follow)

Should the JobTracker close its filesystem whenever it is terminated? If so, there are some tests that need to be reworked slightly to not expect the fileystem to be live after the jobtracker is taken down."
MAPREDUCE-436,NPE in TaskRunner.run if hadoop.log.dir not set,"I'm getting an NPE in TaskRunner.run, looks like it happens when the system property hadoop.log.dir is unset"
MAPREDUCE-435,JobTracker might not accept first few jobs if restarted immediately,If the jobtracker is restarted in a very short span of time (e.g. test case). First few submissions might fail as the jobtracker identifier remains same new jobid given by {{JobTracker.getNewJobId()}} might return an existing job id.
MAPREDUCE-434,LocalJobRunner limited to single reducer,"when mapred.job.tracker is set to 'local', my setNumReduceTasks call is ignored, and the number of reduce tasks is set at 1.
This prevents me from locally debugging my partition function, which tries to partition based on the number of reduce tasks."
MAPREDUCE-433,TestReduceFetch failed.,"{noformat}
Testcase: testReduceFromMem took 23.625 sec
	FAILED
Non-zero read from local: 83
junit.framework.AssertionFailedError: Non-zero read from local: 83
	at org.apache.hadoop.mapred.TestReduceFetch.testReduceFromMem(TestReduceFetch.java:289)
	at junit.extensions.TestDecorator.basicRun(TestDecorator.java:24)
	at junit.extensions.TestSetup$1.protect(TestSetup.java:23)
	at junit.extensions.TestSetup.run(TestSetup.java:27)
{noformat}
Ran TestReduceFetch a few times on a clean trunk.  It failed consistently."
MAPREDUCE-432,JobClient should check input/output specifications  before copying the job files on the DFS,JobClient copies/creates job files on the DFS first and then checks for input/output specifications. This can be better done by first checking the specifications and then copy/create the job files to the DFS.
MAPREDUCE-431,Task left in RUNNING state even after the job completion,"Task could be left in RUNNING state in the following scenario:
1. Job was killed from command-line.
2. TaskTracker running the task didnt come back.
3. JobTracker marks the tracker as lost, but since Job is not RUNNING, it does not change the Task's state. 
The code doing the same in JobTracker.lostTaskTracker method is :
{noformat}
          // if the job is done, we don't want to change anything
          if (job.getStatus().getRunState() == JobStatus.RUNNING ||
              job.getStatus().getRunState() == JobStatus.PREP) {
            job.failedTask(tip, taskId, (""Lost task tracker: "" + trackerName), 
               ........
{noformat}
"
MAPREDUCE-430,Task stuck in cleanup with OutOfMemoryErrors,"Obesrved a task with OutOfMemory error, stuck in cleanup.

"
MAPREDUCE-429,HADOOP-801 doesn't add property to hadoop-default.xml,HADOOP-801 (in fixing HADOOP-805) adds a new configuration option -- jobclient.output.filter.  This property should have also been added to hadoop-default.xml with a default value of NONE (the current default of FAILURE is too verbose with INFO exceptions).
MAPREDUCE-428,Reducers reported completion % is generally incorrect when consuming compressed map outputs,"When processing compressed map outputs, reducers often report over 100% completion (up to 220%). This is regardless of the compression codec and of whether native compression is used or not."
MAPREDUCE-427,Earlier key-value buffer from MapTask.java is still referenced even though its not required anymore.,"Consider the following events for a map task
Before HADOOP-1965:
|| Stage || Description || Buffers used || Memory used||
|Stage-1 | MapOutputBuffer simply collects | KeyVal1 (by collect) | io.sort.mb|
|Stage-2 | KeyVal1 buffer is full and needs spilling so Sort-Spill starts | KeyVal1 (by Sort-Spill) | io.sort.mb|
|Stage-3 | Sort-Spill finished | KeyVal1 (referenced by comparator ) | io.sort.mb|
|Stage-4 |  MapOutputBuffer starts collecting | KeyVal2(by collect) + KeyVal1(by comparator) | 2*io.sort.mb|
|Stage-5 | KeyVal2 buffer is full and needs spilling so Sort-Spill starts  | KeyVal2 (by Sort-Spill) | io.sort.mb|
So for the time duration between Stage-4 and Stage-5 the memory used becomes {{2 * io.sort.mb}} which can be totally avoided by removing the comparator's reference to the earlier key-val buffer. So the maximum memory usage can be clamped to {{io.sort.mb}}

After HADOOP-1965:
|| Stage || Description || Buffers used || Memory used ||
|Stage-1 | MapOutputBuffer simply collects | KeyVal1 (by collect)| io.sort.mb/2|
|Stage-2 | KeyVal1 buffer is full and needs spilling, so Sort-Spill starts in parallel | KeyVal1 (by Sort-Spill) | io.sort.mb/2|
|Stage-3 |  MapOutputBuffer simply collects + Sort-Spill | KeyVal2(by collect) + KeyVal1(by Sort-Spill) | io.sort.mb|
|Stage-4 | MapOutputBuffer simply collects + Sort-Spill finishes, Sort-Impl's are closed but the comparators still hold the reference to KeyVal1 buffer | KeyVal2 (by collect) + KeyVal1 (referred by comparator) | io.sort.mb|
|Stage-5 | KeyVal2 buffer is full and needs spilling, so Sort-Spill starts in parallel | KeyVal2 (by Sort-Spill) | io.sort.mb/2|
So for the time duration between Stage-4 and Stage-5 there is an unwanted reference to the keyval buffer which prevents the GC from claiming it. However the maximum memory usage will be {{io.sort.mb}}.
"
MAPREDUCE-426,Race condition in LaunchTaskAction and KillJobAction,"One task wasn't killed when its job was killed. 
On the TaskTracker log, it showed, 

2007-08-21 17:02:29,219 INFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction: task_0133_r_000080_2    <**************
2007-08-21 17:02:29,232 INFO org.apache.hadoop.mapred.TaskTracker: Received 'KillJobAction' for job: job_0131         <**************
2007-08-21 17:02:29,233 INFO org.apache.hadoop.mapred.TaskRunner: task_0131_m_000077_0 done; removing files.
2007-08-21 17:02:29,376 INFO org.apache.hadoop.mapred.TaskTracker: Received 'KillJobAction' for job: job_0133
2007-08-21 17:02:29,376 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000060_0 done; removing files.
2007-08-21 17:02:29,378 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000071_2 done; removing files.
2007-08-21 17:02:29,381 INFO org.apache.hadoop.mapred.TaskRunner: task_0133_r_000066_1 done; removing files.
2007-08-21 17:02:31,272 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce > copy >
2007-08-21 17:02:32,275 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce > copy >
2007-08-21 17:02:33,277 INFO org.apache.hadoop.mapred.TaskTracker: task_0133_r_000080_2 0.0% reduce > copy >
...
[task_0133_r_000080_2 continue to run]



Of course the JobTracker kept on complaining
2007-08-22 19:06:37,880 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status, cannot find taskid task_0133_r_000080_2
2007-08-22 19:06:38,124 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status, cannot find taskid task_0133_r_000080_2
2007-08-22 19:06:47,885 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status, cannot find taskid task_0133_r_000080_2
"
MAPREDUCE-425,NPE in TaskInProgress.cleanup,"This may be something that only my code triggers; an NPE in TaskTracker$TaskInProgress.cleanup
{code}
[sf-startdaemon-debug] 09/01/28 11:41:06 [TaskLauncher for task] INFO mapred.TaskTracker : Error cleaning up task runner: java.lang.NullPointerException
[sf-startdaemon-debug] 	at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.cleanup(TaskTracker.java:2487)
[sf-startdaemon-debug] 	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:1825)
[sf-startdaemon-debug] 	at org.apache.hadoop.mapred.TaskTracker.access$1100(TaskTracker.java:104)
[sf-startdaemon-debug] 	at org.apache.hadoop.mapred.TaskTracker$TaskLauncher.run(TaskTracker.java:1779)
{code}

Looking at the code, the only source of NPE's on that line is localJobConf
{code}
  if (localJobConf.getNumTasksToExecutePerJvm() == 1) {
{code}

It looks like if TaskInProgress.cleanup() ever gets called with no valid localJobConf, then an NPE is the result. The exception gets logged and discarded, but it does appear in the logs."
MAPREDUCE-424,Unreachable code in TaskInProgress.inCompleteSubTask,"TaskInProgress.incompleteSubTask has the following unreachable-code :
{noformat}
    if (taskState != TaskStatus.State.FAILED && 
          taskState != TaskStatus.State.KILLED &&
          taskState != TaskStatus.State.FAILED_UNCLEAN &&
          taskState != TaskStatus.State.KILLED_UNCLEAN) {
        LOG.info(""Task '"" + taskid + ""' running on '"" + trackerName + 
                ""' in state: '"" + taskState + ""' being failed!"");
        status.setRunState(TaskStatus.State.FAILED);
        taskState = TaskStatus.State.FAILED;
      }
{noformat}
It would never reach this code, because it is never called from other places, where taskState is not FAILED, KILLED, FAILED_UNCLEAN and KILLED_UNCLEAN.
Also status != null is not required, since status is never null."
MAPREDUCE-423,Remove getNumResolvedTaskTrackers() api from JobTracker,
MAPREDUCE-422,TaskTracker directoryCleanupThread never gets terminated,"When a task tracker starts its work it calls startCleanupThreads() to create a directoryCleanupThread.

only, that thread is never terminated; it runs for the life of the process. 

It should be terminated when the TaskTracker itself is terminated, presumably after it has done the last cleanup. 
"
MAPREDUCE-421,mapred pipes might return exit code 0 even when failing,"up to  hadoop 0.18.3 org.apache.hadoop.mapred.JobShell ensured that 'hadoop jar' returns non-zero exit code when the job fails.
This is no longer true after moving this to org.apache.hadoop.util.RunJar.

Pipes jobs submitted through cli never returned proper exit code.

The main methods in org.apache.hadoop.util.RunJar. and org.apache.hadoop.mapred.pipes.Submitter should be modified to return an exit code similar to how org.apache.hadoop.mapred.JobShell did it."
MAPREDUCE-420,FileNotFoundException when finishing a profiled task that doesn't generate an output file,"When running a hadoop job with mapred.task.profile=true, hadoop assumes that mapred.task.profile.params contains a ""%s"" that can be changed for a file name that will be created by the profiler containing its text output. If the profiler doesn't generate such an output file, profiled tasks will raise a FileNotFound exception at the end of their execution:

09/02/05 15:39:10 INFO mapred.JobClient:  map 100% reduce 0%
09/02/05 15:39:10 INFO mapred.JobClient: Communication problem with server: java.io.FileNotFoundException: http://machine1:50060/tasklog?plaintext=true&taskid=attempt_200901221838_0043_m_000000_0&filter=profile
        at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1239)
        at org.apache.hadoop.mapred.JobClient.downloadProfile(JobClient.java:1089)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1166)
        at JavaCat.main(JavaCat.java:46)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:165)
        at org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
        at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)
        at org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)

This happens because it's assumed users will use the default hprof profiler, which actually allows you to set the output file name. Not all profilers are like that and some don't have any option to create a text output log at all or don't allow you to change the name of the output file. In my case, I'm a profiler that doesn't generate text output and only allows you to set the output directory for the snapshot files it generates.

"
MAPREDUCE-419,mapred.userlog.limit.kb has inconsistent defaults,"The default for ""mapred.userlog.limit.kb"" in mapred-default.xml is 0 whereas it's 100KB in the code.  These defaults should be consistent."
MAPREDUCE-418,JT not able to find task id while updating status,"JT not able to find task ids while updating status in gridmix2. Even though the jobs are completed successfully, JT is displaying following message for most of the tasks:
2009-02-20 14:46:29,488 INFO org.apache.hadoop.mapred.JobTracker: Serious problem.  While updating status, cannot find taskid attempt_200902201433_0020_r_000003_1
"
MAPREDUCE-417,Logging could hang/fail when drive is filled by mapred outputs.,"HADOOP-1252 addresses the mapred disk problems.
In addition to those problems, if mapred fills up the drive used for logging, it might affect TaskTracker/DataNodes.

Simple solution for now is not to use the logging drive in MapReduce. "
MAPREDUCE-416,Move the completed jobs' history files to a DONE subdirectory inside the configured history directory,"Whenever a job completes, the history file can be moved to a directory called DONE. That would make the management of job history files easier (for example, administrators can move the history files from that directory to some other place, delete them, archive them, etc.)."
MAPREDUCE-415,JobControl Job does always has an unassigned name,"When creating and adding org.apache.hadoop.mapred.jobcontrol.Job(s) they don't use the names specified in their respective JobConf files.  Instead it's just hardcoded to ""unassigned""."
MAPREDUCE-413,"job.jar, job.xml not deleted when JobClient submitJob method  fail with exception ","If mapred.system.dir is set to /hadoop/mapred/system, 

$ hadoop dfs -lsr /hadoop
/hadoop/mapred  <dir>
/hadoop/mapred/system   <dir>
$ 

$ hadoop jar hadoop-examples.jar wordcount  invaliddirectoryname  output
org.apache.hadoop.mapred.InvalidInputException: Input path doesnt exist : /user/_____/invaliddirectoryname
        at org.apache.hadoop.mapred.InputFormatBase.validateInput(InputFormatBase.java:138)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:316)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:371)
        at org.apache.hadoop.examples.WordCount.main(WordCount.java:143)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:143)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:40)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:155)

$ hadoop dfs -lsr /hadoop
/hadoop/mapred  <dir>
/hadoop/mapred/system   <dir>
/hadoop/mapred/system/submit_gpw022     <dir>
/hadoop/mapred/system/submit_gpw022/job.jar     <r 10>  19397

$ ls -l hadoop-examples.jar
-rw-r--r--  1 _____ _____ 19397  hadoop-examples.jar
"
MAPREDUCE-412,JobConf needs better javadoc,"The org.apache.hadoop.mapred.JobConf class needs better javadoc comments.  

In general terms, these guidelines should be followed:
  - http://java.sun.com/j2se/javadoc/writingdoccomments/#styleguide
      - document the unchecked exceptions that the caller might reasonably want to catch
      - use <code> font appropriately (detailed in link above)
  - document default values and appropriate configuration file properties
  - comments, tags, links, etc used consistently across API

In particular, the javadoc for this class should at least answer these questions:
  - all constructors: what happens if the supplied class, file path, or configuration doesn't exist or is null?
  - JobConf() constructor: where are default values loaded from?
  - JobConf(Configuration) constructor: indicate that this is effectively a copy constructor
  - JobConf(String) constructor: are there any format requirements on the string?  local and dfs paths allowed?
  - setter methods that take a path: what happens if the path doesn't exist?
  - getter methods returning objects: if value has not been set, is null returned or something else?
  - are JobConf objects immutable?  If not, why not?
  - setNum*Tasks: is this per TaskTracker? or something else?
  - methods that take a Path: what if the path is relative?
  - setWorkingDirectory: is this deleted at the end of a job?  should it be local or dfs?
  - *KeepFailedTaskFiles: if they are kept, where can they be found?
  - *KeepTaskFilesPattern: what does ""the files"" mean? if they are kept, where can they be found?
  - deleteLocalFiles: undoubtedly a risky operation.  Need a good spec.  Is it a recursive delete?
  - which configuration entries are mandatory (i.e. must be set before submitting the job)?
"
MAPREDUCE-411,Inconsistent strings for job and queue related scheduling information in UI when the information is not available.,"HADOOP-3930 added support for displaying queue related and job related scheduling information. When this information is not available, it is displayed as 'N/A' in some cases and 'NA' in some cases. They should read the same for UI consistency."
MAPREDUCE-410,JobTracker TaskInitialization failure on cygwin,"I wanted to test new release and have been trying to queue new job.
But it didn't work.

This error is found in JobTracker's log.

========================================
2008-11-29 21:39:00,276 ERROR org.apache.hadoop.mapred.EagerTaskInitializationListener: Job initialization failed:
java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 47
Leibnitz_[0-9]+_job_200811292137_0001_leibnitz\hadoop_\Qwordcount\E+
                                               ^
	at java.util.regex.Pattern.error(Unknown Source)
	at java.util.regex.Pattern.escape(Unknown Source)
	at java.util.regex.Pattern.atom(Unknown Source)
	at java.util.regex.Pattern.sequence(Unknown Source)
	at java.util.regex.Pattern.expr(Unknown Source)
	at java.util.regex.Pattern.compile(Unknown Source)
	at java.util.regex.Pattern.<init>(Unknown Source)
	at java.util.regex.Pattern.compile(Unknown Source)
	at org.apache.hadoop.mapred.JobHistory$JobInfo.getJobHistoryFileName(JobHistory.java:638)
	at org.apache.hadoop.mapred.JobHistory$JobInfo.logSubmitted(JobHistory.java:803)
	at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:353)
	at org.apache.hadoop.mapred.EagerTaskInitializationListener$JobInitThread.run(EagerTaskInitializationListener.java:55)
	at java.lang.Thread.run(Unknown Source)
========================================

leibnitz is Jobtracker's hostname and hadoop is username.

Then I wanted to fix it and created  this patch.
========================================
--- src/mapred/org/apache/hadoop/mapred/JobHistory.java	(revision 721683)
+++ src/mapred/org/apache/hadoop/mapred/JobHistory.java	(working copy)
@@ -95,6 +95,10 @@
   private static final String SECONDARY_FILE_SUFFIX = "".recover"";
   private static long jobHistoryBlockSize = 0;
   private static String jobtrackerHostname;
+  /** Set to true on Windows platforms */
+    public static final boolean WINDOWS /* borrowed from Path.WINDOWS */
+                  = System.getProperty(""os.name"").startsWith(""Windows"");
+
   /**
    * Record types are identifiers for each line of log in history files. 
    * A record type appears as the first token in a single line of log. 
@@ -634,6 +638,9 @@
       
       jobName = escapeRegexChars( jobName );
 
+      if (WINDOWS) {
+        user = escapeRegexChars( user );
+      }
       // Make the pattern matching the job's history file
       final Pattern historyFilePattern = 
         Pattern.compile(jobtrackerHostname + ""_"" + ""[0-9]+"" + ""_"" 
========================================

Hadoop Core patched this seems to work well.

Maybe my environment is wrong. But if this is bug, please fix."
MAPREDUCE-408,TestKillSubProcesses fails with assertion failure sometimes,"org.apache.hadoop.mapred.TestKillSubProcesses.testJobKillFailAndSucceed fails sometimes with following error Message:
{noformat}
Unexpected: The subprocess at level 3 in the subtree is not alive before Job completion
{noformat}

Stacktrace
{noformat}
junit.framework.AssertionFailedError: Unexpected: The subprocess at level 3 in the subtree is not alive before Job completion
	at org.apache.hadoop.mapred.TestKillSubProcesses.runJobAndSetProcessHandle(TestKillSubProcesses.java:221)
	at org.apache.hadoop.mapred.TestKillSubProcesses.runFailingJobAndValidate(TestKillSubProcesses.java:112)
	at org.apache.hadoop.mapred.TestKillSubProcesses.runTests(TestKillSubProcesses.java:327)
	at org.apache.hadoop.mapred.TestKillSubProcesses.testJobKillFailAndSucceed(TestKillSubProcesses.java:310)
{noformat}

one such failure at http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/495/testReport/org.apache.hadoop.mapred/TestKillSubProcesses/testJobKillFailAndSucceed/"
MAPREDUCE-407,JobClient looking for classes for submitted job in the wrong place,"JobClient does some checking of the job being submitted when it submits a jar file along with the job. The problem is that the JobClient pulls classes from the classpath rather than the submitted jar file. Because the jar file may contain newer (or older) versions of classes on the classpath this behavior leads to confusing errors when the job is run. It is also a pain to ensure that the jar file being submitted is on the classpath. Further, if the JobClient uses the submitted jar file rather than the classpath, missing classes from the jar file can be detected earlier.

This patch will cause the JobClient to load the classes for a job from the jar file rather than the classpath. Because of the class loading precedence rules in Java, if the class is on the system class path, it will be loaded from there rather than the submitted jar file, but now users need not (and should not) put job classfiles on the system classpath.

This patch also allows config files to be put in a configuration directory rather than on the classpath, which also eliminates some confusing behavior when there are duplicate instances of config files in different parts of the classpath. "
MAPREDUCE-406,setting fs.default.name to an invalid URI format kills init thread in JobTracker,"If you set fs.default.name in a JobConf object to something that causes java.net.URI to throw an IllegalArgumentException, the job not only fails initalization, but kills the JobInitThread"
MAPREDUCE-405,ReduceTask logs show negative values,"While running some tests I can see negative values in reducers log. Something like 
{noformat}
 localhost Will be considered after:  -2 seconds
{noformat}

Looking at the code it looks like this happens when a node which was temporarily down comes back (i.e becomes available). In such a case the node is still in the penalty box and also in the unique hosts structure."
MAPREDUCE-404,NPE in text.encode when writing an invalid(?) JobProfile,"I see an NPE in one of my tests in Text.encode(String), further up the stack is  JobProfile.write(), which appears to write a null user"
MAPREDUCE-403,"ProcessTree can try and kill a ""null"" PID","Saw this in a test run, while trying to shut down a TaskTracker
[sf-startdaemon-debug] 09/05/07 16:42:42 [Map-events fetcher for all reduce tasks on tracker_morzine.hpl.hp.com:localhost/127.0.0.1:36239] INFO mapred.TaskTracker : Shutting down: Map-events fetcher for all reduce tasks on tracker_morzine.hpl.hp.com:localhost/127.0.0.1:36239
[sf-startdaemon-debug] 09/05/07 16:42:42 [TerminatorThread] WARN util.ProcessTree : Error executing shell command org.apache.hadoop.util.Shell$ExitCodeException: ERROR: garbage process ID ""-null"".
"
MAPREDUCE-402,TaskTracker doesnt recheck job tracker version on reconnect,"This isnt anything I have a test for/encountered, just something I noticed when reviewing TaskTracker.
1. TaskTracker sets a justStarted flag to true when starting up
2. One way it uses this flag is to check job tracker versions -the version is only checked when justStarted==true, which is reset after the check.
3. If a JobTracker is unreachable, then the TaskTracker sleeps for 5 seconds and then continues

There is a risk, therefore, that if the job tracker goes down, a different version might come back up, and the Task Tracker will not notice until it makes an incompatible IPC call.

This is a pretty unlikely scenario; you've got to kill the job tracker and bring up a different versioned one in 5 seconds. And the consequence of IPC incompatiblity will be a lost task, regardless of whether this happens early or later in the process. I'm not sure it's worth fixing. "
MAPREDUCE-401,du fails on Ubuntu in TestJobHistory,"TestJobHistory.testJobHistoryUserLogLocation is failing, and there is an error in the log related to du failing in the mini MR cluster"
MAPREDUCE-400,WebUI shows 100% Map Complete even though some maps are still running,I have a job that has 50K maps. The web UI shows maps as 100% complete even though the last few maps (20 or so) are still running. 
MAPREDUCE-399,Duplicate destroy of process trees in TaskMemoryManager.,"TaskMemoryManager currently works only on Linux and terminates tasks that transgress memory-limits by first calling TaskTracker.purgeTask() and then explicitly destroying the process tree to be sure that the whole process tree is cleaned up. After HADOOP-2721, we don't need this explicit process-tree destroying as the usual code-path of killing tasks itself takes care of cleaning up the whole process-trees."
MAPREDUCE-398,Task process exit with nonzero status of 134.        ,"During fetcher2 stage, i got these errors on all datanodes.
java.io.IOException: Task process exit with nonzero status of 134.      
        at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java: 424)

When fetching more than 1000000 urls, these errors occur."
MAPREDUCE-397,"In JobInProgress, failed TIP should be added back to the non-running queue only if the tip has not failed.","In case of a task failure, the corresponding TIP is added back to the non-running list via {{failMap()/failReduce()}} api. This reentry should be done only for TIPs that have not failed. Reentry is useless for failed TIPs."
MAPREDUCE-395,Dependency cycle: Submitter and TaskTracker,there's a cycle between org.apache.hadoop.mapred.pipes org.apache.hadoop.mapred; breaking the dependency between Submitter and TaskTracker fixes it.
MAPREDUCE-394,"Hadoop Pipes do not load custom InputFormats at appropriate time, rendering them useless in certain scenarios","There's a patch provided below.
It was created on the 0.17.0 version,
but with a little tweaking can be applied
to the 0.18.0 as well. It fixes a timing bug,
whereas a custom inputformat was loaded
from the jar file, but the inputformat was being
processed much earlier in time, resulting
in a class not found exception.
"
MAPREDUCE-393,Two small improvements to pipes,"Working with the ..mapred.pipes class a bit today, I found one bug and one possible interface improvement:

- Application.java in its constructor assumes that DistributedCache.getLocalCacheFiles () always returns non-zero, and returns an array with at least one element -- appropriate checks and exceptions should be thrown here.
- Submitter.java provides a ""submitJob ()"" method, yet it acts like it's a runJob method (and also invokes mapred.JobClient.runClient ()) -- it should provide two interface methods, one runJob () and one submitJob (), who act just like the JobClient counterparts.

Here is the small patch that implements both changes, based on the 0.17.1 release source -- just in case anyone cares for this minor improvement."
MAPREDUCE-392,streaming and pipes should reuse jvm's by default,"With HADOOP-249, tasks can now reuse JVMs.  Pipes and streaming run little user code in their JVMs and should generally benefit from JVM reuse.  Thus I propose we change the default for these to be JVM reuse."
MAPREDUCE-390,Corner case exists in detecting Java process deaths that might lead to orphan pipes processes lying around in memory,"In HADOOP-2092, the child pipes process periodically pings the parent Java process to find out whether it is alive. The ping cycle is 5 seconds. Consider the following scenario:
1) The Java task dies at the beginning of the ping cycle
2) A new Java task starts and binds to the same port as the earlier Java task's port
3) The pipes process wakes up and does a ping - it will still be successful since the port number hasn't changed
This will lead to orphan processes lying around in memory. The detection of parent process deaths can be made more reliable at least on Unix'ish platforms by checking whether the parent process ID is 1, and if so exit. This will take care of the most common platform that hadoop is run on. For non-unix platforms, the existing ping mechanism can be retained. Thoughts?"
MAPREDUCE-389,pipes should wait for the process to exit and fail if the return code is bad,
MAPREDUCE-388,pipes combiner has a large memory footprint,"Pipes combiner implementation can have a huge memory overhead compared to the spill size. How much, depends on the record size. E.g., an application asks for >2GB memory when io.sort.mb=500, key is 16 bytes, and value is 4 bytes."
MAPREDUCE-387,Hadoop Pipes Submitter assumes that presence of a Java InputFormat implies a Java RecordReader,"The Submitter's command line parsing makes this assumption, which might not be true always..."
MAPREDUCE-386,The combiner in pipes is closed before the last values are passed in.,Currently the last spill is sent to the combiner after the close method is called.
MAPREDUCE-385,pipes does not allow jobconf values containing commas,"Currently hadoop pipes does not allow a
-jobconf <key>=<value>,<key>=<value>...
commandline parameter with one or more commas in one of the values of the key-value pairs.

One use case is key=mapred.join.expr, where the value is required to have commas.
And it is not always convenient to add this to a configuration file.
Submitter.java could easily be changed to check for backslash in front of a comma before using it as a delimiter."
MAPREDUCE-384,Exception thrown from pipes Map task is not handled properly,"  In Pipes environment, when map task throws an exception it is not killed immediately. But the tracker is waiting for 603 seconds (10 mins) for the report and then killing the task.  
When I threw exception from word count sample program the maptask exits after 603 seconds showing the following on console:
07/09/14 11:09:26 INFO mapred.JobClient: Task Id : task_200709141017_0002_m_000001_1, Status : FAILED
task_200709141017_0002_m_000001_1: terminate called after throwing an instance of 'std::exception'
task_200709141017_0002_m_000001_1:   what():  St9exception

And the Job UI shows:
Task task_200709141017_0002_m_000001_1 failed to report status for 603 seconds. Killing!

Thus, each map task is taking  10 mins for exiting and  is tried 4 times.
"
MAPREDUCE-383,pipes combiner does not reset properly after a spill,"When using a pipes combiner, the variable numBytes is not reset to 0 in spillAll, effectively reducing the effect of running a combiner to the first spill."
MAPREDUCE-382,Create a test that would inject random failures for tasks in large jobs and would also inject TaskTracker failures,Create a test that would inject random failures for tasks in large jobs and would also inject TaskTracker failures
MAPREDUCE-381,Add framework hooks to get the running/completed/pending tasks for a given job. Add a way to query the list of currently active tasktrackers from the JobTracker.,Add framework hooks to get the IDs of running/completed/pending tasks for a given job. Add a way to query the list of currently active tasktrackers from the JobTracker. These are required to inject failures.
MAPREDUCE-376,Add serialization for Thrift,"Thrift (http://incubator.apache.org/thrift/) is cross-language serialization and RPC framework. This issue is to write a ThriftSerialization to support using Thrift types in MapReduce programs, including an example program. This should probably go into contrib.

(There is a prototype implementation in https://issues.apache.org/jira/secure/attachment/12370464/hadoop-serializer-v2.tar.gz)"
MAPREDUCE-375, Change org.apache.hadoop.mapred.lib.NLineInputFormat and org.apache.hadoop.mapred.MapFileOutputFormat to use new api.,
MAPREDUCE-374,Change org.apache.hadoop.mapred.lib.MultipleSequenceFileOutputFormat/MultipleTextOutputFormat to use new api.,
MAPREDUCE-373,Change org.apache.hadoop.mapred.lib. FieldSelectionMapReduce to use new api.,
MAPREDUCE-372,Change org.apache.hadoop.mapred.lib.ChainMapper/Reducer to use new api.,
MAPREDUCE-371,Change org.apache.hadoop.mapred.lib.KeyFieldBasedComparator and org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner to use new api,
MAPREDUCE-370,Change org.apache.hadoop.mapred.lib.MultipleOutputs to use new api.,
MAPREDUCE-369,Change org.apache.hadoop.mapred.lib.MultipleInputs to use new api.,
MAPREDUCE-368,Change org.apache.hadoop.mapred.jobcontrol to use new api,
MAPREDUCE-367,Change org.apache.hadoop.mapred.lib. CombineFileInputFormat to use new api,Change org.apache.hadoop.mapred.lib. CombineFileInputFormat to use new api
MAPREDUCE-366,Change org.apache.hadoop.mapred.lib.TotalOrderPartitioner to use new api,Change org.apache.hadoop.mapred.lib.TotalOrderPartitioner to use new api
MAPREDUCE-365,Change org.apache.hadoop.examples.PiEstimator to use new mapreduce api.,
MAPREDUCE-364,Change org.apache.hadoop.examples.MultiFileWordCount to use new mapreduce api.,
MAPREDUCE-363,Change org.apache.hadoop.examples.Grep to use new mapreduce api.,
MAPREDUCE-362,Change org.apache.hadoop.examples.Sort to use new api.,
MAPREDUCE-361,Change org.apache.hadoop.examples.terasort to use new mapreduce api,
MAPREDUCE-360,Change org.apache.hadoop.examples.dancing to use new mapreduce api,
MAPREDUCE-359,Change org.apache.hadoop.examples.DBCountPageView to use new mapreduce api.,Change org.apache.hadoop.examples.DBCountPageView to use new mapreduce api.
MAPREDUCE-358,Change org.apache.hadoop.examples. AggregateWordCount and  org.apache.hadoop.examples.AggregateWordHistogram to use new mapreduce api.,Change org.apache.hadoop.examples.AggregateWordCount and  org.apache.hadoop.examples.AggregateWordHistogram to use new mapreduce api.
MAPREDUCE-357,Change org.apache.hadoop.examples.RandomWriter and  org.apache.hadoop.examples.RandomTextWriter to use new mapreduce api.,
MAPREDUCE-356,Change org.apache.hadoop.examples.SleepJob to use new api.,Change org.apache.hadoop.examples.SleepJob to use new api.
MAPREDUCE-355,Change org.apache.hadoop.mapred.join to use new api,"To change org.apache.hadoop.examples.Join to use new api, we need to change org.apache.hadoop.mapred.join to use new api. So,
Deprecate the code in org.apache.hadoop.mapred.join. 
Copy the code to org.apache.hadoop.mapreduce.lib.join and Change it to use new api. 
Thoughts ?"
MAPREDUCE-354,the map output servlet should only locate the index if it isn't in the cache,"Currently, the map output servlet locates the cache file using the local dir allocator, before it determines whether the information is in the cache. It would avoid a lot of filesystem lookups if it waited."
MAPREDUCE-353,Allow shuffle read and connection timeouts to be configurable,It would be good for latency-sensitive applications to tune the shuffle read/connection timeouts... in fact this made a huge difference to terasort since we were seeing individual shuffles stuck for upwards of 60s and had to have a very small read timeout.
MAPREDUCE-352,Avoid creating JobInProgress objects before Access checks and Queues checks are done in JobTracker submitJob ,"In JobTracker submitJob , JobInProgress instance gets created . after this checks are done for access and queue state. In event of checks failed . There isn't any use for these JIP objects , hence in event of failure only reason these objects were created was to get conf data and be deleted.

We need to fetch the information required to only do the checks instead of creating a JobInProgress object"
MAPREDUCE-350,Generalize the SequenceFileInputFilter to apply to any InputFormat,"I'd like to generalize the SequenceFileInputFormat that was introduced in HADOOP-412 so that it can be applied to any InputFormat. To do this, I propose:

interface WritableFilter {
   boolean accept(Writable item);
}

class FilterInputFormat implements InputFormat {
  ...
}

FilterInputFormat would look in the JobConf for:
   mapred.input.filter.source = the underlying input format
   mapred.input.filter.filters = a list of class names that implement WritableFilter

The FilterInputFormat will work like the current SequenceFilter, but use an internal RecordReader rather than the SequenceFile. This will require adding a next(key) and getCurrentValue(value) to the RecordReader interface, but that will be addressed in a different issue."
MAPREDUCE-348,A proposal to merge common functionality of various Schedulers,"There are at least 3 Schedulers in Hadoop today: Default, Capacity, and Fairshare. Over time, we're seeing a lot of functionality common to all three. Many bug fixes, improvements to existing functionality, and new functionality are applicable to all three schedulers. This trend seems to be getting stronger, as we notice similar problems, solutions, and ideas. This is a proposal to detect and consolidate such common functionality.

"
MAPREDUCE-346,Report Map-Reduce Framework Counters in pipeline order,Currently there is no order in which counters are printed. It would be more user friendly if Map-Reduce Framework counters are reported in the pipeline order.
MAPREDUCE-345,Investigate whether the array in the JobInProgress that holds TIP references can be removed,"The array, in JobInProgress, that holds the references to TIPs is required now only to serve the clients (web UI via JSPs and JobClient APIs, that traverse the array and create the output). The array can now be removed since HADOOP-2119 introduces some datastructures for running/non-running TIPs and we could probably add some more if required (e.g., for completed TIPs). That way, we will gain when we have large jobs (many tasks) in the sense that we don't have to go through the big array every time a client request is made. We could instead iterate over the datastructures. Also, we should do these traversals without locking the JobTracker to avoid cases where long traversal leads to loss of heartbeats, etc. Some staleness at the client side (in favor of improving the JobTracker's performance) is probably okay."
MAPREDUCE-344,Remove dead code block in  JobInProgress.completedTask,"Since the taskCommitThread ensures that one and only one task of a given TIP is marked as SUCCEEDED, we don't need the code block in JobInProgress.completedTask which checks if the TIP is complete and then just marks the task as complete:

{noformat}
    // Sanity check: is the TIP already complete? 
    if (tip.isComplete()) {
      // Mark this task as KILLED
      tip.alreadyCompletedTask(taskid);

      // Let the JobTracker cleanup this taskid if the job isn't running
      if (this.status.getRunState() != JobStatus.RUNNING) {
        jobtracker.markCompletedTaskAttempt(status.getTaskTracker(), taskid);
      }
      return false;
    } 
{noformat}
"
MAPREDUCE-343,Failed jobs should report the reason of failure on the web ui,"From user's perspective it is difficult to detect why the job failed . Users might need to go through the jobtracker logs or task attempts list to see why the job failed. It would be good to show the reason on the job web ui. Something like
{code}
User: bob
Job Name: example
Job File: hdfs://location/job.xml
Status: Failed
Reason : Map/Reduce task # 47 failed x number of times.
{code}"
MAPREDUCE-342,Create a public scheduler API,"The work in HADOOP-3412 provided an API to support pluggable schedulers. However implementations have to be in the org.apache.hadoop.mapred package, which is undesirable. The goal of this issue is to create a public API for scheduler writers to code against."
MAPREDUCE-338,Need more complete API of JobClient class,"We need a programmatic way to find out the information about a map/reduce cluster and the jobs on the cluster.
The current API is not complete.
In particular, the following API functions are needed:

1. jobs()  currently, there is an API function JobsToComplete, which returns running/waiting jobs only.  jobs() should return the complete list.
2. TaskReport[] getMap/ReduceTaskReports(String jobid)
3. getStartTime()
4. getJobStatus(String jobid);
5. getJobProfile(String jobid);




"
MAPREDUCE-336,The logging level of the tasks should be configurable by the job,It would be nice to be able to configure the logging level of the Task JVM's separately from the server JVM's. Reducing logging substantially increases performance and reduces the consumption of local disk on the task trackers.
MAPREDUCE-334,Change mapred.lib code to use new api,Deprecate the code in org.apache.hadoop.mapred.lib. Copy the code to org.apache.hadoop.mapreduce.lib and Change it to use new api.
MAPREDUCE-332,"When assigning tasks to trackers, the job tracker should try to balance the number of tasks among the available trackers","

I encounter a number of situations like this:
A job tracker has 200 task trackers, each with 2 mapper slots and reducer slots.
When a job with 200 or fewer reducers was submitted to the job tracker,
one normally each task tracker will run one reducer.
Unfortunately, it seems that only  about 1/3 of trackers have one reducer, and 1/3 trackers don't have reducer, and 1/3 have 2 reducers!
"
MAPREDUCE-331,Make jobtracker resilient to memory issues,"JobTracker is vulnerable to memory errors/attacks. Few of them are as follows
- *JOB INIT :* lot of users submitting large jobs. As every jobs is expanded, the jobtracker's memory can be completely used up
- *JSP :* jsp (jobhistory.jsp etc) can also interfere with jobtracker's memory and hence the jobtracker should be protected against such attacks
- *OLD JOBS :* lot of completed jobs can garble up jobtracker's memory and hence should be periodically cleaned up. HADOOP-4766 addresses this.

The main intention of this issue is to track various jira's that help jobtracker battle memory attacks. Jobtracker should always be up and available. "
MAPREDUCE-330,Log information regarding changes to job in jobtracker,"Some actions like changing the priority of a job, killing a job, killing a task may need to be tracked for admin purposes. It would be good to, at a minimum, log these at an INFO level in the JT logs."
MAPREDUCE-328,Cluster summary should have total tasks in the JT and pending tasks to run.,Cluster summary already shows the running maps and running reduces. It is useful to have total tasks from all initialized jobs and pending tasks from initialized jobs that still need to be run. Pending tasks can be derived from total tasks and running tasks.
MAPREDUCE-325,JobTracker's processHeartbeat() should not call System.currentTimeMillis() everytime,"Consider the following
{code:title=JobTracker.java|borderStyle=solid}
private synchronized boolean processHeartbeat(
                                                TaskTrackerStatus trackerStatus, boolean initialContact) {
    String trackerName = trackerStatus.getTrackerName();
    trackerStatus.setLastSeen(System.currentTimeMillis());
{code}
Here, the call to {{System.currentTimeMillis()}} on every call to {{JobTracker.processHeartbeat()}} might prove costly. While testing/benchmarking HADOOP-2119, we recorded that the JobTracker was able to serve ~130 tasks/sec. So that means we might make ~130 calls to {{System.currentTimeMillis()}} per second. I think in these cases (_last-seen-status_ etc) such a high level of accuracy in terms of timestamp is unnecessary and hence can be avoided."
MAPREDUCE-323,Improve the way job history files are managed,"Today all the jobhistory files are dumped in one _job-history_ folder. This can cause problems when there is a need to search the history folder (job-recovery etc). It would be nice if we group all the jobs under a _user_ folder. So all the jobs for user _amar_ will go in _history-folder/amar/_. Jobs can be categorized using various features like _jobid, date, jobname_ etc but using _username_ will make the search much more efficient and also will not result into namespace explosion. "
MAPREDUCE-322,TaskTracker shuold run user tasks nicely in the local machine,"If one task tried to use all CPUs in a local machine, all other tasks or processes (includes tasktracker and datanode daemons) may hardly get a chance to run."
MAPREDUCE-319,Use Grizzly for Fetching Map Output in Shuffle,"As mentioned in HADOOP-1273 and references therefrom, Jetty 6 still doesn't seem to be stable enough for use in Hadoop. Instead, we've decided to consider the usage of Grizzly Framework [https://grizzly.dev.java.net/] for NIO based communication."
MAPREDUCE-318,Refactor reduce shuffle code,The reduce shuffle code has become very complex and entangled. I think we should move it out of ReduceTask and into a separate package (org.apache.hadoop.mapred.task.reduce). Details to follow.
MAPREDUCE-317,Submitting job information via DFS in Map/Reduce causing consistency and performance issues,"Job submission involves two steps: submitting jobs to the System directory on DFS (done by the client), then submit the job via the JobSubmissionProtocol to JobTracker. This two step process is seen to have some issues:

- Since the files need to be read from DFS, slowness in the DFS can cause job initialization to become costly. We faced this as described in HADOOP-5286 and HADOOP-4664.
- The two step process could lead to inconsistent information being left around - like in HADOOP-5327 and HADOOP-5335.

This JIRA is to explore options to remove the two step process in submitting a job."
MAPREDUCE-316,Splittability of input should be controllable by application,"Currently, isSplittable method of FileInputFormat always returns true. For some applications, it becomes necessary that the map task process entire file, rather than a block. Therefore, splittability of input (i.e. block-level split vs file-level-split) should be controllable by user via a configuration variable. The default could be block-level split, as is.
"
MAPREDUCE-314,Avoid priority inversion that could result due to scheduling running jobs in an order sorted by priority,"- Consider a job, J1, with priority NORMAL that is running reduce tasks occupying all reduce slots and has running and pending map tasks. 
- At this point, suppose a job, J2, is submitted with priority HIGH or say its priority is changed to HIGH from NORMAL.
- The schedulers typically will start scheduling tasks from job J2, as J1's running maps complete. The default scheduler in Hadoop does this, and with HADOOP-4471, so will the capacity scheduler.
- However, as there are still pending maps in J1, the reduce tasks of J1 are all stuck and no reduce tasks of J2 can run. 
- So, all map tasks of J2 will complete, followed by completion of all map tasks of J1, and then reduce tasks from J1 will start getting freed for J2 to complete. 

This could result in jobs completing slowly. Also, if there are enough jobs of higher priority, they could result in low priority jobs being starved. At the same time more and more resources (such as intermediate disk space) will get consumed without jobs completing.

This jira is to discuss and implement a solution for the above problem."
MAPREDUCE-313,Add additional jobs of new types to gridmix,"
Currently, gridmix does not contain any jobs using combiners nor a job sorting compressed input data
Word count like jobs should be a good candidate of using combiners.
Sorting compressed input data should exercise the mapper spill logic and/or the effect of map output compression.
 "
MAPREDUCE-312,Port HADOOP-4667 to the default Map-Reduce scheduler,HADOOP-4667 has implemented 'global scheduling' for the fair-share scheduler with very promising results - we should port the same to the default o.a.h.mapred.JobQueueTaskScheduler.
MAPREDUCE-310,JobClient should keep on retrying if the jobtracker is still initializing,"When the user submits the job while the jobtracker is still initializing, the jobclient comes out with an exception. ideally the jobclient should keep on retrying until the jobtracker is up and ready. This will also take care of HADOOP-3289. "
MAPREDUCE-309,The cluster admin should be able to configure a name for the job tracker,"It would be good if the cluster admin could define a job tracker name that was used to form the unique part of the job ids. I think something like:

mapred.jobtracker.name = xxx

job_xxx_200808081200_00001

if it is undefined, it would default to the current behavior of just using the timestamp. "
MAPREDUCE-308,A JobInProgressLIstener can change a job without informing other listeners,As of now the {{JobInProgressListener}} adds itself to the {{JobTracker}} and gets updated/informed. Some of there {{JobInProgressListener}}'s control these changes/events (e.g.  {{EagerTaskInitializer}}). The issue with this model is that a listener can change the job without informing other listeners. 
MAPREDUCE-307,Iterator for MapFileOutputFormat,"MapFileOutputFormat produces output data that is sorted locally in each part-NNNNN file - however, there is no easy way to iterate over keys from all parts in a globally ascending order."
MAPREDUCE-306,"job submission protocol should have a method for getting the ""task capacity"" of the cluster",It would help the InputFormats make informed decisions if the JobSubmissionProtocol had a method the returned the number of tasks that the cluster can run at once.
MAPREDUCE-303,refactor the mapred package into small pieces,"The mapred package has gotten too big, so I propose changing it to split it into parts.

I propose the following splits:

org.apache.hadoop.mapred = client API
org.apache.hadoop.mapred.task = code for task tracker
org.apache.hadoop.mapred.job = code for job tracker
org.apache.hadoop.mapred.utils = non public code that is shared between the servers

Does anyone have any other divisions that would help?

I would make the classes sent through RPC public classes in the server's package.

Thoughts?"
MAPREDUCE-301,mapred.child.classpath.extension property,It would be useful to be able to extend the classpath for the task processes on a job per job basis via a {{mapred.child.classpath.extension}} property.
MAPREDUCE-300,Ability to thread task execution,"Currently Hadoop spawns a single threaded JVM for each task.  While good for many tasks, this does not maximize resource usage for slaves that have many cores (machines with more cores are getting more cost effective everyday) _and_ are running jobs that require many gigabytes of read-only in-memory resources to maximize throughput.  Running in separate JVMs requires redundantly loading large amounts of data, reducing the possible number of parallel tasks that can run per a machine even though more cpus are available.

Adding this ability will give hadoop users the flexibility to balance their need for maximizing memory usage & throughput and task segmentation.

Note: This is a blocking bug in porting processes over to hadoop for my own organization.  I am testing a patch for this now that leaves the existing behavior for single threaded operation in-tact.  All synchronization is done through wrapper classes and helper methods and should not add any overhead to non-threaded processes."
MAPREDUCE-297,generalize the TT / JT servers to handle more generic tasks,"We've been discussing a proposal to generalize the TT / JT servers to handle more generic tasks and move job specific work out of the job tracker and into client code so the whole system is both much more general and has more coherent layering.  The result would look more like condor/pbs like systems (or presumably borg) with map-reduce as a user job.

Such a system would allow the current map-reduce code to coexist with other work-queuing libraries or maybe even persistent services on the same Hadoop cluster, although that would be a stretch goal.  We'll kick off a thread with some documents soon.

Our primary goal in going this way would be to get better utilization out of map-reduce clusters and support a richer scheduling model.  The ability to support alternative job frameworks would just be gravy!

----

Putting this in as a place holder.  Hope to get folks talking about this to post some more detail."
MAPREDUCE-296,job statistics should be displayed in the web/ui,"It would be really nice, if the job page in the web/ui showed the time that:
  1. first map started
  2. last map finished
  3. last reduce finished shuffle
  4. last reduce finished sort
  5. last reduce finished"
MAPREDUCE-291,Optionally a separate daemon should serve JobHistory,Currently the JobTracker serves the JobHistory to end-users off files local-disk/hdfs. While running very large clusters with a large user-base might result in lots of traffic for job-history which needlessly taxes the JobTracker. The proposal is to have an optional daemon which handles serving of job-history requests.
MAPREDUCE-289,JobTracker should not expand jobs if its running low on memory,When the JobTracker detects that its running low on memory it should not expand new jobs if the job has the potential to bring it down. Consider and example where the JobTracker runs on 60% of the max memory and a new job is submitted which can take upto 40% of the max memory.  Ideally the JobTracker should _queue_ the job for expansion and expand when sufficient memory is available.
MAPREDUCE-288,Documention for using external profilers on Map-Reduce applications,"We should document the usage of external profilers such as YourKit/NetBeans on Map-Reduce tasks in http://hadoop.apache.org/core/docs/current/mapred_tutorial.html#Profiling. Specifically the ability to use the DistributedCache for distributing the shared object, setting up the LD_LIBRARY_PATH etc."
MAPREDUCE-286,Optimize the last merge of the map output files,"In ReduceTask, today we do merges of io.sort.factor number of files everytime we merge and write the result back to disk. The last merge can probably be better. For example, if there are io.sort.factor + 10 files at the end, today we will merge 100 files into one and then return an iterator over the remaining 11 files. This can be improved (in terms of disk I/O) to merge the smallest 11 files and then return an iterator over the 100 remaining files. Other option is to not do any single level merge when we have io.sort.factor + n files remaining (where n << io.sort.factor) but just return the iterator directly. Thoughts?"
MAPREDUCE-284,Improvements to RPC between Child and TaskTracker,"We could improve the RPC between the Child and TaskTracker:
   * Set ping interval lower by default to 5s
   * Disable nagle's algorithm (tcp no-delay)"
MAPREDUCE-283,We should reuse key and value objects in the MultithreadedMapRunner.,"Currently, each key/value pair read from the record reader is allocated a new a key and value. It would be better if it had a pool of key/value pairs that were reused. I'm picturing something like:

BlockingQueue<KeyValuePair> empties;
BlockingQueue<KeyValuePair> newInputs;

the record reader thread would take a KeyValuePair from the empties queue, read into it using the RecordReader, and put it on the newInputs queue.

The work threads would read from newInputs, process the key and value and put the processed objects on the empties queue. The initialization would put the desired number of key-value pairs on the empties queue to start it off."
MAPREDUCE-280,TextInputFormat should allow different treatment on carriage return char '\r',"
The current implementation treat '\r' and '\n' both as line breakers. However, in some cases, it is desiable to strictly use '\n' as the solely line breaker and treat '\r' as a part of data in a line. 

One way to do this is to make readline function as a member function so that the user can create a subclass to overwrite the function with the desired behavior.

"
MAPREDUCE-279,Map-Reduce 2.0,"Re-factor MapReduce into a generic resource scheduler and a per-job, user-defined component that manages the application execution.

"
MAPREDUCE-278,Proposal for redesign/refactoring of the JobTracker and TaskTracker,"During discussions on HADOOP-815 wrt some hard-to-maintain code on the JobTracker we all agreed that the current state-of-affairs there is brittle and merits some rework.

Case in point: there are back-calls from TaskInProgress to JobTracker and from JobInProgress to JobTracker which mean that synchronization is quite involved and brittle, leading to issues like HADOOP-600. Also one is forced to lock several data-structures individually before certain operations (taskTrackers, trackerExpiryQueue, jobs etc.)

Hence I'd like to present some early thoughts (which have undergone a quick iteration) on how we could do slightly better by a bit of redesign/refactoring, also during discussions with Owen on the same we agreed that HADOOP-554 is an integral part along the same direction... and I also feel that a good candidate to be done along with this is HADOOP-398 (mapred package refactoring).

Context:
---------
a) The unit of communication between the JobTracker & TaskTracker is a 'task'.
b) Due to (a) the JobTracker maintains a bunch of information related on the 'taskid' i.e. taskidToTipMap, taskidToTrackerMap etc. and hence we need to update the JobTracker's data-structures via back-calls from TaskInProgress & JobInProgress where the context is available (complete/failed task, already-completed task etc.)
c) This implies that we have a fairly elaborate and hard to maintain locking structures and also some redundant information in the JobTracker; making it harder to maintain.

Overall at both the JobTracker & TaskTracker the concept of a 'job' is overshadowed by the 'task'; which I propose we fix.


Proposal:
----------

Here is the main flow of control:
JobTracker -> JobInProgress -> TaskInProgress -> task_attempt

The main idea is to break the existing nexus between the JobTracker & TaskInProgress/taskid by (I've put code for illustrative purposes only, and ignored pieces irrelevant to this discussion):

a) Making the 'job' the primary unit of communication between JobTracker & TaskTracker.

b) TaskTrackerStatus now looks like this: 

  class TaskTrackerStatus {
    List<JobStatus> jobStatuses; // the status of the 'jobs' running on a TaskTracker
    String getTrackerName();
  }
  class JobStatus {
    List<TaskStatus> taskStatuses; // the status of the 'tasks' belonging to a job
    JobId getJobId();
  }

c) The JobTracker maintains only a single map of jobid -> JobInProgress, and mapping from taskTracker -> List<JobInProgress>

  Map<JobId, JobInProgress> allJobs;
  Map<String, List<JobInProgress>> trackerToJobsMap;

d) The JobTracker delegates a bunch of responsibilities to the JobInProgress to reflect the fact the primary 'concept' in map/reduce is the 'job', thus empowering the JobInProgress class:

  class JobInProgress {
    TaskInProgress[] mapTasks;
    TaskInProgress[] reduceTasks;
    
    Map<String, List<TaskInProgress>> trackerToTasksMap; // tracker -> tasks running
    Map<String, List<TaskAttempt>> trackerToMarkedTasksMap; // tracker -> completed (success/failed/killed) task-attempt, 
                                                                                         //                but the tracker doesn't know it yet

    void updateStatus(JobStatus jobStatus);
    MapOutputLocation[] getMapOutputLocations(int[] mapTasksNeeded, int reduce);
    TaskAttempt getTaskToRun(String taskTracker);
    List<TaskTrackerAction> getTaskToKill(String taskTracker);
  }
  
d) On receipt of TaskTrackerStatus from a tracker, the processeing of heartbeat looks like this:

  for (JobStatus jobStatus : taskTrackerStatus.getJobStatuses()) {
   JobInProgress job = allJobs.get(jobId);
   synchronized (job) {
     job.updateStatus(jobStatus);

     return (HeartbeatResponse(repsonseId,
                               job.getTaskAttemptToRun(trackerName), 
                               job.getTaskToKill(trackerName)
                              ));
    }
  }
   
The big change is that the JobTracker delegates a lot of responsibility to the JobInProgress, we get away from all the complicated synchronization constructs: simply lock the JobInProgress object at all places via allJobs/trackerToJobsMap and we are done. This also enhances throughput since mostly we will not need to lock up the JobTracker (even in the heartbeat loop); locking the JobInProgress or the 2 maps is sufficient in most cases... thus enhance the inherent parallelism of the JobTracker's inner loop (processing heartbeat) and provide better response when multiple jobs are running on the cluster. 

Hence the JobInProgress is responsible for maintaining it's TaskInProgress'es which in turn are completely responsible for the TaskAttempt`s, the JobInProgress also provides sufficient information as and when needed to the JobTracker to schedule jobs/tasks and the JobTracker is blissfully unaware of the innards of jobs/tasks.

-*-*-

I hope to articulate more a general direction towards an improved and maintainable 'mapred' and would love to hear out how we can improve and pitfalls to avoid... lets discuss. We could take this piecemeal an implement or at one go...

Last, not least; I propose that while we are at this we redo the nomenclature a bit:
JobInProgress -> Job
TaskInProgress -> Task
taskid -> replace with a new TaskAttempt
this should help clarify each class and it's roles.

Of course we will probably need a separate org.apache.hadoop.mapred.job.Task v/s org.apache.hadoop.mapred.task.Task which is why I feel HADOOP-554 (refactoring of mapred packages) would be very important to get a complete, coherent solution.

Thoughts?
"
MAPREDUCE-277,Job history counters should be avaible on the UI.,"Job history is logging counters. But they are not visible on the UI. 
Job history parser and UI should be modified to view counters."
MAPREDUCE-276,Multiple copies of jobconf is present in history-dir after restart,"Across restarts, when a job is inited, jobconf for this job is localized to the history folder. These filenames have jobtracker-identifier which changes across restarts. Hence we see multiple jobconfs in the history folder. "
MAPREDUCE-275,Display lost tracker information on the jobtracker webui and persist it across restarts,As of today its difficult to distinguish between active tracker and lost trackers (lost trackers are considered active). It will be nice if the jobtracker can display what all trackers are lost and maintain it across restarts. HADOOP-5643 does something similar for decommissioned trackers.
MAPREDUCE-274,Hadoop JobClient can return specific exit codes for specific classes of exceptions,"Today if a job tracker becomes unresponsive or dies, the hadoop JobClient throws an exception subclass of IOException and exits with an exit code of 1. However, it would probably fail with the same exit code if there's any other type of exception as well. Programs like HOD which use this client (indirectly through the hadoop script) can make better decisions if the error code is more distinguishable. For e.g. if it's a network related exception, we can treat the cluster are unusable, or retry after awhile etc. More generically, if categories of exceptions can be treated with specific exit codes, it will help. 

Comments ?"
MAPREDUCE-273,Jobs should not be initialized while the recovery is in progress,"In the default case, the eager-task-initializer tries to init a job as soon as its added. There is actually no need for external inits as recovery manager itself does a forceful inits. The important thing is to enforce this delay on inits across schedulers."
MAPREDUCE-271,Change examples code to use new mapreduce api.,"Currently only Wordcount and SecondarySort examples are written using new mapreduce api.
Other examples, in org.apache.hadoop.examples package : BaileyBorweinPlouffe, DBCountPageView, Grep, Join,  MultiFileWordCount, PiEstimator, RandomTextWriter, RandomWriter, SleepJob, Sort should be changed to use new mapreduce api."
MAPREDUCE-270,TaskTracker could send an out-of-band heartbeat when the last running map/reduce completes,"Currently the TaskTracker strictly respects the heartbeat interval, this causes utilization issues when all running tasks complete. We could send an out-of-band heartbeat in that case."
MAPREDUCE-268,Implement memory-to-memory merge in the reduce,"HADOOP-3446 fixed the reduce to not flush the in-memory shuffled map-outputs before feeding to the reduce. However for latency-sensitive applications with lots of memory like the terasort this hurts performance since the fan-in for the final in-memory merge is too large (all 8000 map-outputs very in-memory) resulting in less than optimal performance.

When I put in an intermediate memory-to-memory merge for the terasort's reduce (there-by avoiding disk i/o) to cut the fan-in from 8000 to <100 the 'reduce' phase (including the local datanode-write) sped-up 250% (from 10s to 4s). "
MAPREDUCE-266,Remove deprecated MultiFileInputFormat,Remove the deprecated class org.apache.hadoop.mapred.MultiFileInputFormat
MAPREDUCE-265,check permissions for job inputs and outputs,"On job submission, filesystem permissions should be checked to ensure that the input directory is readable and that the output directory is writable."
MAPREDUCE-264,"When combiners exist, postpone mappers' spills of map output to disk until combiners are unsuccessful.","When a map/reduce job is set up with a combiner, the mapper tasks each build up an in-heap collection of 100K key/value pairs -- and then apply the combiner to reduce that to whatever it becomes by applying the combiner to sets with like keys before spilling to disk to send it to the reducers.

Typically running the combiner consumes a lot less resources than shipping the data, especially since the data end up in a reducer where probably the same code will be run anyway.

I would like to see this changed so that when the combiner shrinks the 100K key/value pairs to less than, say, 90K, we just keep running the mapper and combiner alternately until we get enough distinct keys to make this unlikely to be worthwhile [or until we run out of input, of course].

This has two costs: the whole internal buffer has to be re-sorted so we can apply the combiner even though as few as 10K new elements have been added, and in some cases we'll call the combiner on many singletons.  

The first of these costs can be avoided by doing a mini-sort in the new pairs section and doing a merge to develop the combiner sets and the new sorted retained elements section.

The second of these costs can be avoided by detecting what would otherwise be singleton combiner calls and not making them, which is a good idea in itself even if we don't decide to do this reform.

The two techniques combine well; recycled elements of the buffer need not be combined if there's no new element with the same key.

-dk

"
MAPREDUCE-262,Optimize finding of speculative tasks,"Assuming HADOOP-2119 provides better data structures for handling running TIPs, finding new speculative tasks can be further optimized. Two of which could be 
1) {{conf.getMapSpeculativeExecution()}} and {{conf.getReduceSpeculativeExecution()}} should be moved to {{JobInProgress}}. A simple check for this boolean can prove useful before checking for speculative tasks. This will be useful for jobs with large maps and reducers where scanning all the TIPs  can be costly. 
2) Since the progress of a TIP changes only when {{TaskInProgress.recomputeProgress()}} is invoked, it makes more sense to check for speculation in {{JobInProgress.updateTaskStatus()}} and move the TIPs that can be speculated to the front of the running queue."
MAPREDUCE-261,Blacklisting of TaskTrackers should take into account the user-ID,"With HADOOP-4305, it is possible to blacklist TaskTrackers across jobs. It might make sense to also take into account the users whose tasks are being run on the TaskTrackers, and use it in the blacklisting strategy."
MAPREDUCE-260,control-c of the submitting program should kill the job,"Currently, if you kill the process that submitted the job, the job continues. The default behavior should be to kill the job if the launching process dies."
MAPREDUCE-259,Rack-aware Shuffle,"We could try and experiment with *rack-aware* scheduling of fetches per-reducer. Given the disparities between in-rack and off-rack bandwidth it could be a improvement to do something along these lines:

{noformat}
if (no. of known map-output locations > than no. of copier threads) {
  try to schedule 75% of copies off-rack
  try schedule 25% of copies in-rack
}
{noformat}

This could lead to better utilization of both in-rack & switch b/w...

Clearly we want to schedule more cross-switch than in-rack since off-rack copies will take significantly more time; hence the 75-25 split.
"
MAPREDUCE-258,Update MapOutputServlet to use NIO channels,"The TaskTracker can serve the map output segments using RandomAccessFileBuffer, added in [JETTY-748|https://jira.codehaus.org/browse/JETTY-748]."
MAPREDUCE-257,Preventing node from swapping,"When a node swaps, it slows everything: maps running on that node, reducers fetching output from the node, and DFS clients reading from the DN. We should just treat it the same way as if OS exhausts memory and kill some tasks to free up memory."
MAPREDUCE-255,avoid bzip2 decompressor throwing exception on corrupted (prematurely truncated) file,"running map-reduce streaming job using the bzip2 compressor, job fails with one of either of the two following java exceptions:

This seems to happen when one of the bz2 input files is corrupted (probably when the file is prematurely truncated).  Example,

Can we fix the bzip2 decompresser so that it does not throw the above two exceptions?


2008-07-16 07:23:39,605 WARN org.apache.hadoop.mapred.TaskTracker: Error 
running child
java.io.IOException: mark/reset not supported
       at java.io.InputStream.reset(InputStream.java:334)
       at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.readLine(Bzip2TextInputFormat.java:117) 

       at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.next(Bzip2TextInputFormat.java:140) 

       at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.next(Bzip2TextInputFormat.java:34) 

       at 
org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:158)
       at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:45)
       at org.apache.hadoop.mapred.MapTask.run(MapTask.java:219)
       at 
org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2124)

or

2008-07-16 20:49:28,020 WARN org.apache.hadoop.mapred.TaskTracker: Error 
running child
java.io.IOException: CRC error
        at 
org.apache.tools.bzip2r.CBZip2InputStream.cadvise(CBZip2InputStream.java:74)
        at 
org.apache.tools.bzip2r.CBZip2InputStream.crcError(CBZip2InputStream.java:378)
        at 
org.apache.tools.bzip2r.CBZip2InputStream.endBlock(CBZip2InputStream.java:351)
        at 
org.apache.tools.bzip2r.CBZip2InputStream.setupNoRandPartA(CBZip2InputStream.java:851)
        at 
org.apache.tools.bzip2r.CBZip2InputStream.setupNoRandPartB(CBZip2InputStream.java:903)
        at 
org.apache.tools.bzip2r.CBZip2InputStream.read(CBZip2InputStream.java:240)
        at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.readLine(Bzip2TextInputFormat.java:102)
        at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.next(Bzip2TextInputFormat.java:140)
        at 
org.apache.hadoop.mapred.Bzip2TextInputFormat$BZip2LineRecordReader.next(Bzip2TextInputFormat.java:34)
        at 
org.apache.hadoop.mapred.MapTask$TrackedRecordReader.next(MapTask.java:158)
        at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:45)
        at org.apache.hadoop.mapred.MapTask.run(MapTask.java:219)
        at 
org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2124)


Example:
$HADOOP_HOME/bin/hadoop jar -libjars $<path>/jars/bzip2.jar 
$HADOOP_HOME/hadoop-streaming.jar \
  -inputformat org.apache.hadoop.mapred.Bzip2TextInputFormat \
  -mapper ""cat"" \
  -reducer ""cat"" \
  -numReduceTasks 20 \
  -input '<path>/corrupt-data.bz2'  \
  -output bzip2_bug_example \
  -jobconf stream.num.map.output.key.fields=1 \
  -jobconf stream.num.reduce.output.fields=1 \
  -jobconf num.key.fields.for.partition=1
"
MAPREDUCE-253,getDiagnostics in TaskReport should return exceptions,"Currently, getDiagnostics() returns Strings. When exceptions are thrown in user code and/or Hadoop, it would be cleaner to propagate the exception back to the application for better error handling. Hadoop should return the exceptions instead of returning string representations that correspond to printStackTrace() output."
MAPREDUCE-252,Create an InputFormat for reading lines of text as Java Strings,"Such a StringInputFormat would be like TextInputFormat but with input types of Long and String, rather than LongWritable and Text. This would allow users to write MapReduce programs that used only Java native types (i.e. no Writables).

This is currently not possible to write without changes to Hadoop due to a limitation in the RecordReader interface explained here: https://issues.apache.org/jira/browse/HADOOP-3413?focusedCommentId=12597935#action_12597935"
MAPREDUCE-250,JobTracker should log the scheduling of setup/cleanup task,Setup/Cleanup is launched under (m+1)^th^ tip or (r+1)^th^ tip. It will be nice if jobtracker logs this info.
MAPREDUCE-249,[mapred] Enable tasks' memory management on Windows.,HADOOP-4173 disabled this.
MAPREDUCE-248,Add error reporting support to LocalJobRunner,"- This feature is very useful for unit testing map/reduce tasks, it would allow verifying an expected failure reason.

- The class mapred.LocalJobRunner currently returns an empty TaskCompletionEvent array when requested for task completion events

- In line 231 in LocalJobRunner.java a map/reduce exception is caught and *not* propagated  to the user.

- I would be useful to get the exception message through a TaskCompletionEvent or event or by any other means.
"
MAPREDUCE-247,Improve job history web page,"There are some minor improvements :
# Remove running jobs from the job history page.
# If the user wants to search jobs with jobname having _sleep_ then the search query required will be ':sleep' which is not very intuitive. Simply _sleep_ should work.
"
MAPREDUCE-246,"Job recovery should fail or kill a job that fails ACL checks upon restart, if the job was running previously","Consider a scenario where a job was submitted to the M/R system and runs for a while. Then say the JT is restarted, and before that the ACLs for the user are changed so that that user can no longer submit jobs to that queue. Since the job could potentially be using resources alloted to that queue and could be account for it, this might lead to accounting inconsistencies. A suggestion is for the jobtracker to fail / kill this job."
MAPREDUCE-245,Job and JobControl classes should return interfaces rather than implementations,"See HADOOP-2202 and HADOOP-2268 for background on this. I am creating a new issue, since the previous two did not fix the problem, and it can be addressed when we make non backwards compatible changes to Hadoop (perhaps along with HADOOP-1230).

"
MAPREDUCE-244,Duplicate code in JobHistory TaskAttempt's can be collapsed into super class. ,"There is a lot of common code for MapAttempt, ReduceAttempt. All the duplicate code can be moved to TaskAttempt class. The methods logFailed() and logKilled() methods differ only in one string. They can be collapased into a single method."
MAPREDUCE-243,Allow hadoop to run in an osgi container,"I have been running some tests getting hadoop to run within an osgi environment (specifically the Newton framework) and this has uncovered a number of minor bugs when mapred classes are instantiated from a different start point than their main methods.

I have created a number of patches which I'll attach which solve these issues. It's possible these patches could be dealt with as separate issues but all are required to resolve the osgi issue. Happy to split up if easier to manage though.

classpath.patch: this rearranges the classloader hierarchies for Task objects such that a Task is able to resolve api classes in the case where the api classes are no longer loaded from the system classloader.

tasklog.patch: this ensures the log files are able to be resolved in the case where the child process is launched from a different directory to the parent process

taskrunner.patch: this enables the TaskRunner to find a log dir in the case where the parent jvm is not launched by the hadoop scripts, also allows for a client to specify a substitute main class (which delegates to the TaskTracker$Child) in this case for purposes of resolving osgi classpaths but could be more general? Finally adds some extra logging in case where things go wrong.

tasktracker.patch: allow parent to pass through configuration to child taskrunner (specifically in this case for purposes of passing classpath and laucher to taskrunner)"
MAPREDUCE-242,TaskTracker can skip a dfs check on every task launch.,"When tasktracker gets a new task to run, it queries the namenode to find out the job directory _size_. This _size_ is required if the job files are not yet localized. But if its already localized then the dfs call gets wasted. This will be true for all but 1 tasks that run for a job on a tracker. One can avoid it but checking if the job is already localized."
MAPREDUCE-241,JobQueueTaskScheduler could assign multiple reduces per heartbeat,"Currently the JobQueueTaskScheduler assigns only 1 reduce per heartbeat, for applications where latency is important we could assign more reduces (upto available slots)."
MAPREDUCE-240,"Improve the shuffle phase by using the ""connection: keep-alive"" and doing batch transfers of files","We should do transfers of map outputs at the granularity of  *total-bytes-transferred* rather than the current way of transferring a single file and then closing the connection to the server. A single TaskTracker might have a couple of map output files for a given reduce, and we should transfer multiple of them (upto a certain total size) in a single connection to the TaskTracker. Using HTTP-1.1's keep-alive connection would help since it would keep the connection open for more than one file transfer. We should limit the transfers to a certain size so that we don't hold up a jetty thread indefinitely (and cause timeouts for other clients).
Overall, this should give us improved performance."
MAPREDUCE-239,Attribute to mark Mappers and Reducers as side-effect free,"There should be an annotation to mark Mapper and Reducer classes as side-effect free. This annotation could then be used to disable speculative execution for such classes. Furthermore, defining a class without the NoSideEffect attribute as a combiner would be a run-time error. 

@NoSideEffects
class MyMapper extends MapReduceBase implements Mapper { ... }

would declare that MyMapper may be run speculatively.

@NoSideEffects
class MyReducer extends MapReduceBase implements Reducer { ...}

declares that MyReducer can be run speculative and as a combiner."
MAPREDUCE-238,OutputFormat should be given the reduce id directly rather than a filename,"The OutputFormat API should be changed to be more evolution proof:

public interface OutputFormatContext {
  JobConf getJobConf();
  Progressable getProgress();
}

public interface OutputFormat {
  RecordWriter getRecordWriter(int reduce, OutputFormatContext context) throws IOException;
  void checkOutputSpecs(OutputFormatContext context) throws IOException;
}

And OutputFormatBase would be renamed:

public abstract class FileOutputFormat implements OutputFormat {
  protected Path getOutputPath(int reduce, OutputFormatContext context) throws IOException { ... }
  ... current OutputFormatBase methods ...
}"
MAPREDUCE-237,Runtimes of TestJobTrackerRestart* testcases are high again,"[junit] Running org.apache.hadoop.mapred.TestJobTrackerRestart
[junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 575.887 sec
[junit] Running org.apache.hadoop.mapred.TestJobTrackerRestartWithLostTracker
[junit] Tests run: 1, Failures: 0, Errors: 0, Time elapsed: 864.319 sec

Something I saw on trunk."
MAPREDUCE-236,mapred.jar property in a job configuration file handles only absolute path into the local file system,"Why does this property does not handle URL ?
I think it could be more comfortable to specify the URL of a jar instead of an absolute path in the local file system.
It also could be great to be able to specify a path relative to the job configuration file.

WDYT ?"
MAPREDUCE-235,Custom Splitter for handling many small files,"
Hadoop by default allocates a Map to a file irrespective of size. This is not optimal if you have a large number of small files, for e.g:- If you 2000 100KB files, 2000 Maps will be allocated for the job.

The Custom Multi File Splitter collapses all the small files to a single split till the DFS Block Size is hit. 
It also take care of handling big files by splitting them on Block Size and adding up all the reminders(if any) to a further splits of Block Size. "
MAPREDUCE-234,Isolation runner needs a testcase,I think there is no way to know if IsolationRunner breaks. A testcase can be added to run IsolationRunner.
MAPREDUCE-233,Integrate TaskTracker with the Service base class,"Following on from the initial service patch, we need to bring TaskTracker into the fold. This separate issue  does this activity"
MAPREDUCE-231,Split map/reduce into sub-project,
MAPREDUCE-230,Need to document the controls for sorting and grouping into the reduce,"The JavaDoc for the Reducer should document how to control the sort order of keys and values via the JobConf methods:

{code}
  setOutputKeyComparatorClass
  setOutputValueGroupingComparator
{code}

Both methods desperately need better names. (I'd vote for setKeySortingComparator and setKeyGroupingComparator.)"
MAPREDUCE-229,Provide a command line option to check if a Hadoop jobtracker is idle,"This is an RFE for providing a way to determine from the hadoop command line whether a jobtracker is idle. One possibility is to have something like hadoop jobtracker -idle <time>. Hadoop would return true (maybe via some stdout output) if the jobtracker had no work to do (jobs running / prepared) since <time> seconds, false otherwise.

This would be useful for management / provisioning systems like Hadoop-On-Demand [HADOOP-1301], which can then deallocate the idle, provisioned clusters automatically, and release resources."
MAPREDUCE-227,Ability to pause/resume jobs,"Consider a case where the user job depends on some external entity/service like a database or a web service. If the service needs restart or encounters a failure, the user should be able to pause the job and resume only when the service is up. This will be better than re-executing the whole job. Hence there should be some way to pause/resume jobs (from web-ui/command line) etc."
MAPREDUCE-225,Fault tolerant Hadoop Job Tracker,"The Hadoop framework has been designed, in an eort to enhance perfor-
mances, with a single JobTracker (master node). It's responsibilities varies
from managing job submission process, compute the input splits, schedule
the tasks to the slave nodes (TaskTrackers) and monitor their health.
In some environments, like the IBM and Google's Internet-scale com-
puting initiative, there is the need for high-availability, and performances
becomes a secondary issue. In this environments, having a system with
a Single Point of Failure (such as Hadoop's single JobTracker) is a major
concern.
My proposal is to provide a redundant version of Hadoop by adding
support for multiple replicated JobTrackers. This design can be approached
in many dierent ways. 

In the document at: http://sites.google.com/site/hadoopthesis/Home/FaultTolerantHadoop.pdf?attredirects=0

I wrote an overview of the problem and some approaches to solve it.

I post this to the community to gather feedback on the best way to proceed in my work.

Thank you!"
MAPREDUCE-224,limit running tasks per job,"It should be possible to specify a limit to the number of tasks per job permitted to run simultaneously.  If, for example, you have a cluster of 50 nodes, with 100 map task slots and 100 reduce task slots, and the configured limit is 25 simultaneous tasks/job, then four or more jobs will be able to run at a time.  This will permit short jobs to pass longer-running jobs.  This also avoids some problems we've seen with HOD, where nodes are underutilized in their tail, and it should permit improved input locality.

"
MAPREDUCE-223,JobClient should work with -1/+1 version of JobTracker,"Currently there is version check on the RPC calls that enforces the same Hadoop version on the client and the server.

To enable phased upgrades of systems using Hadoop and Hadoop itself the {{JobClient}} should be able to interact with a {{JobTracker}} of the previous and the next version of Hadoop (or with a range)."
MAPREDUCE-221,Generic 'Sort' Infrastructure for Map-Reduce framework.,"It would be useful to add a generic *sort* infrastructure to the Map-Reduce framework to ease usage.
Specifically the idea to add a fairly generic and powerful *comparator* which can be configured by the user to meet his specific needs.

Spec:
--------
 
  The proposal is to model generic (uber) comparator along the lines of the the standard unix *sort* command. The comparator provides the following (configurable) functionality:

  a) Separator for breaking up the data (stream) into 'columns'.
  b) Multiple key ranges for specifying priorities of 'columns'. (ala --keys/-k option of unix sort i.e. -k 2,3 -k 1,4 etc.)
  c) A variant of a) to let user specify byte range-boundaries without using a separator for 'columns'.
  d) Option to sort 'reverse'.
  e) Option to do a 'stable' sort i.e. don't do a last-ditch comparision of all bytes if all key ranges match.
  f) Option to do 'numeric' comparisions instead of lexicographical comparisions?

  Of course all these are optional with the default behaviour as-is today.

     - * - * -

 Anything more/less?

thanks,
Arun
"
MAPREDUCE-220,Collecting cpu and memory usage for MapReduce tasks,It would be nice for TaskTracker to collect cpu and memory usage for individual Map or Reduce tasks over time.
MAPREDUCE-219,JT should remember blacklisted TT after restart,"Currently, when JT is restarted , it does not remember any TT(s) which was blacklisted across the cluster before the restart. It would be useful if a new feature could be added for JT to remember blacklisted TT(s) even after restart. This would avoid JT from assigning tasks to faulty TT(s) each time after restart."
MAPREDUCE-218,Map/Reduce job with SequenceFileOutputFormat should be able to add user specified metadata to the output file,"When creating a map/reduce job with SequenceFileFormat, 
the user would like to add some metada to the output files automatically. 
In particular, if the output value class was a JuteRecord class generated from a Jute IDL, 
we would like to add JUTE_IDL/IDL_STRING as a attribute/value pair of the metadata.
This way, the output files will be self describing: 
When an application that tries to use the files may not have the value class with it. 
But the application can use Jute tool to generate the classes on demand.
Or better yet, the SequenceFile record reader may be able to do that automatically.


"
MAPREDUCE-217,Tasks to run on a different jvm version than the TaskTracker,"We use 32-bit jvm for TaskTrackers. 
Sometimes our users want to call 64-bit JNI libraries from their tasks.
This requires tasks to be running on 64-bit jvm.
On Solaris, you can simply use -d32/-d64 to choose, but on Linux, it's on a completely different package.

So far, tasks run on the same jvm version as the TaskTracker.
{noformat}
// use same jvm as parent
File jvm =   new File(new File(System.getProperty(""java.home""), ""bin""), ""java"");
{noformat}

Is it possible to let users provide a java home path 
or let them choose from a pre-selected list of paths?

"
MAPREDUCE-216,Job setup and take down on Nodes,"It would be nice if there was a hook for doing job provisioning and cleanup on compute nodes. The TaskTracker implicitly knows when a job starts (a task for the job is received) and pollForTaskWithClosedJob() will explicitly say that a job is finished if a Map task has been run (If only Reduce tasks have run and are finished I don't think pollForTaskWithClosedJob() will return anything will it?), but child Tasks do not get this information.

It would be nice if there was a hook so that programmers could do some provisioning when a job starts and cleanup when a job ends. Caching addresses some of the provisioning, but in some cases a helper daemon may need to be started or the results of queries need to be retrieved and having startJob(), finishJob() callbacks that happen exactly once for each node that runs part of the job would be wonderful."
MAPREDUCE-215,"Improve facilities for job-control, job-queues etc.","Today, Map-Reduce has _some_ support for job-control - basically JobClient provides a facility to monitor jobs, one can setup a job-ending notification and there is {{JobControl}}.

Links:
http://lucene.apache.org/hadoop/docs/r0.15.1/mapred_tutorial.html#Job+Control
http://lucene.apache.org/hadoop/docs/r0.15.1/mapred_tutorial.html#JobControl

Looks like users could do more with better facilities for job-control and maybe more advanced features like job-queues etc.

Lets discuss... "
MAPREDUCE-213,Provide a way to query job tracker about its daemon thread's status,Admin needs to know the status of all threads in JobTracker (whether they are alive or not) at any point of time. This helps alot in debugging crashes.
MAPREDUCE-212,want InputFormat for task logs,"We should provide an InputFormat implementation that includes all the task logs from a job. Folks should be able to do something like:

job = new JobConf();
job.setInputFormatClass(TaskLogInputFormat.class);
TaskLogInputFormat.setJobId(jobId);
...

Tasks should ideally be localized to the node that each log is on.

Examining logs should be as lightweight as possible, to facilitate debugging. It should not require a copy to HDFS. A faster debug loop is like a faster search engine: it makes people more productive. The sooner one can find that, e.g., most tasks failed with a NullPointerException on line 723, the better. "
MAPREDUCE-211,Provide a node health check script and run it periodically to check the node health status,"Hadoop must have some mechanism to find the health status of a node . It should run the health check script periodically and if there is any errors, it should black list the node. This will be really helpful when we run static mapred clusters. Else we may have to run some scripts/daemons periodically to find the node status and take it offline manually.

"
MAPREDUCE-209,Support for metrics aggregation module in JobTracker,"JobTracker should support starting up and shutting down a generic metrics aggregation module. We are currently thinking about plugging in a module that gets time series data from the task trackers, aggregates it and log this data into a global DFS so that it is analysed later (even after the map reduce cluster is shutdown). Some of this data can also be plotted on the JobTracker UI in realtime. This is particulary useful for analyzing data from dynamic mapreduce cluster like the ones deployed using HOD."
MAPREDUCE-208,Provide an admin page displaying events in the cluster along with cluster status/health,"Here are few things that will help admins understand whats happening in the cluster
# Events updates
  ## recently added tracker
  ## lost trackers
  ## recently submitted jobs
  ## user updates
  ## killed/failed attempts/tasks 
  ## killed jobs and the reason
  ## recent exceptions like oom etc
  ## expired tasks
  ## recovery manager updates
  ## memory/cpu usage
  ## black listing of tracker 
  ## killing of maps based on fetch failures
  ## info about why some jobs was rejected(acls, max tasks)/failed(failures)/killed (user)
  ## etc
# Status :
  ## tracker health and status
  ## User status
    ### num jobs submitted
    ### total time the cluster was used
    ### success/failed/killed history
  ## job status
     ### task completion events
     ### recently scheduled tasks
     ### progress
     ### killed/failed/success history
  ## space on the box where the jt is running
  ## etc
# Config :
  ## slot info
  ## acl info
  ## etc

----
Graphical views and auto updation would be cool. Raising alarms upon certain events would be super cool."
MAPREDUCE-202,should dump stacks before timing out task,"When a task process times out and is killed it is often difficult to determine why.  If its stack was dumped prior to killing it, then debugging would be vastly simplified.  Ideally the stack dump would be available through the web ui, but even the log would be sufficient."
MAPREDUCE-201,Map directly to HDFS or reduce(),"For situations where you know that the output of the Map phase is already aggregated (e.g. the input is the output of another Map-reduce job and map() preserves the aggregation), then there should be a way to tell the framework that this is the case so that it can pipe the map() output directly to the reduce() function, or HDFS in the case of IdentityReducer.  This will probably require forcing the number of map tasks to equal the number of reduce tasks.  This will save the disk I/O required to generate intermediate files.
"
MAPREDUCE-198,Log job history events to a common dump file,As of today all the jobhistory events are logged to separate files. It would be nice to also dump all this info into a common file so that external tools (e.g Chukwa) can harvest history info. Job configuration should also be dumped. Whether to use a same log file for history dumps and configuration dumps should be configurable (by default everything goes to one file). 
MAPREDUCE-196,"Create enum for the TaskTypes (Map, Reduce, JobSetup, JobCleanup, TaskCleanup)","Create enum for the TaskTypes - Map, Reduce, JobSetup, JobCleanup, TaskCleanup. Change the framework to use these enum constants and remove usages of booleans like isMap."
MAPREDUCE-194,Split Information errors when input data volumn is trivial,"The mapreduce input is a text file with only 8 lines ( filepath: /in_wc/pretty ), and we set ""conf.setNumMapTasks(8)""  in the program. I thought there will generate 8 maptasks, but actually, it generated 9 maptask. Counters of map tasks from the website show that, 0~7 maptask has ""Map input records  	1"", and 8 maptask has ""Map input records  	0""

The following is map task list information:

task_200903121214_0029_m_000000	        hdfs://guoleitao:9200/in_wc/pretty:0+4

task_200903121214_0029_m_000001		hdfs://guoleitao:9200/in_wc/pretty:4+4

task_200903121214_0029_m_000002		hdfs://guoleitao:9200/in_wc/pretty:8+4

task_200903121214_0029_m_000003		hdfs://guoleitao:9200/in_wc/pretty:12+4

task_200903121214_0029_m_000004		hdfs://guoleitao:9200/in_wc/pretty:16+4

task_200903121214_0029_m_000005		hdfs://guoleitao:9200/in_wc/pretty:20+4

task_200903121214_0029_m_000006		hdfs://guoleitao:9200/in_wc/pretty:24+4

task_200903121214_0029_m_000007		hdfs://guoleitao:9200/in_wc/pretty:28+4

task_200903121214_0029_m_000008		hdfs://guoleitao:9200/in_wc/pretty:32+4"
MAPREDUCE-193,NPEs in JobClient when mapred.jobtracker.completeuserjobs.maximum is set to zero.,Throwing NPEs is not enough of information for the user. Proper exceptions should be thrown with relevant messages.
MAPREDUCE-192,"In TaskTracker, the notification for waking up the completion-events fetcher thread may be lost","In the TaskTracker, there is a completion events fetcher thread that fetches new events from the JobTracker. Normally, the fetcher thread would sleep for heartbeatInterval amount of time per cycle. When a reduce task asks for completion events from the corresponding TaskTracker and the TaskTracker currently doesn't have anything to hand out, a notification is sent to the completion events fetcher thread to wake up and fetch new events if any. Sometimes this notification could be lost and the reduce task would be idle for a few seconds. This hurts the performance of jobs like terasort."
MAPREDUCE-191,Mapper fail rate increases significantly as the number of reduces increase,"I ran a large sort job, with about 8400 mappers.
In the first run, I used 301 reducers. About 600 mapper tasks failed.
In another run, I used 607 reducers. More than 3800 mapper tasks failed.

"
MAPREDUCE-190,MultipleOutputs should use newer Hadoop serialization interface since 0.19,"We have a system based on Hadoop 0.18 / Cascading 0.8.1 and now I'm trying to port it to Hadoop 0.19 / Cascading 1.0. The first serious problem I've got into that we're extensively using MultipleOutputs in our jobs dealing with sequence files that store Cascading's Tuples.

Since Cascading 0.9, Tuples stopped being WritableComparable and implemented generic Hadoop serialization interface and framework. However, in Hadoop 0.19, MultipleOutputs require use of older WritableComparable interface. Thus, trying to do something like:

{noformat}
MultipleOutputs.addNamedOutput(conf, ""output-name"",
MySpecialMultiSplitOutputFormat.class, Tuple.class, Tuple.class);
mos = new MultipleOutputs(conf);
...
mos.getCollector(""output-name"", reporter).collect(tuple1, tuple2);
{noformat} 

yields an error:

{noformat}
java.lang.RuntimeException: java.lang.RuntimeException: class
cascading.tuple.Tuple not org.apache.hadoop.io.WritableComparable
       at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:752)
       at org.apache.hadoop.mapred.lib.MultipleOutputs.getNamedOutputKeyClass(MultipleOutputs.java:252)
       at org.apache.hadoop.mapred.lib.MultipleOutputs$InternalFileOutputFormat.getRecordWriter(MultipleOutputs.java:556)
       at org.apache.hadoop.mapred.lib.MultipleOutputs.getRecordWriter(MultipleOutputs.java:425)
       at org.apache.hadoop.mapred.lib.MultipleOutputs.getCollector(MultipleOutputs.java:511)
       at org.apache.hadoop.mapred.lib.MultipleOutputs.getCollector(MultipleOutputs.java:476)
       at my.namespace.MyReducer.reduce(MyReducer.java:xxx)
{noformat}

MultipleOutputs should eventually be ported to use more generic Hadoop serialization, as I understand."
MAPREDUCE-189,Change Map-Reduce framework to use JAAS instead of UGI,"Hadoop embraced JAAS via HADOOP-4348.

We need to fix Map-Reduce to use JAAS concepts such as Subject, Principal, Permission etc. rather than UserGroupInformation for user identification, queue-acls etc."
MAPREDUCE-188,Web UI JSP: need to HTML-Escape log file contents,"Web UI JSP: need to HTML-Escape log (file) contents

Displaying the task's error log or the mapred.Reporter status String:

the content should 
have all ""<"" and "">"" converted to ""&lt;"" and ""&gt;"", 
or use ""<pre>"" tag. 
Otherwise, ant HTML/XML tags within will not be displayed correctly

This problem occurs for ex. when using hadoopStreaming and 
a MapRed record is a chunk of HTML/XML content (and a task fails)

ex. problematic view:
http://jobtracker:50030/taskdetails.jsp?jobid=job_0009&taskid=tip_0009_m_000000
Other jsp pages may also need a change.




"
MAPREDUCE-187,Generalize mapred.child.ulimit so as to help setting up other limits.,"Currently mapred.child.ulimit cannot be used for anything other than for setting virtual limits. It is hardcoded to set virtual mem limits (ulimit -v) only. This should be changed so that other limits like open file descriptors, max user processes etc can be set."
MAPREDUCE-186,TaskLogServlet returns 410 when trying to access log early in task life,"Early in a map task life, or for tasks that died quickly, the file $task/syslog might not exist.  In this case, the TaskLogServlet gives a status 410."
MAPREDUCE-185,Checksum error during sorting in reducer,"Many reduce tasks got killed due to checksum error. The strange thing is that the file was generated by the sort function, and was on a local disk. Here is the stack: 

Checksum error:  ../task_0011_r_000140_0/all.2.1 at 5342920704
	at org.apache.hadoop.fs.FSDataInputStream$Checker.verifySum(FSDataInputStream.java:134)
	at org.apache.hadoop.fs.FSDataInputStream$Checker.read(FSDataInputStream.java:110)
	at org.apache.hadoop.fs.FSDataInputStream$PositionCache.read(FSDataInputStream.java:170)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:313)
	at java.io.DataInputStream.readFully(DataInputStream.java:176)
	at org.apache.hadoop.io.DataOutputBuffer$Buffer.write(DataOutputBuffer.java:55)
	at org.apache.hadoop.io.DataOutputBuffer.write(DataOutputBuffer.java:89)
	at org.apache.hadoop.io.SequenceFile$Reader.readBuffer(SequenceFile.java:1061)
	at org.apache.hadoop.io.SequenceFile$Reader.seekToCurrentValue(SequenceFile.java:1126)
	at org.apache.hadoop.io.SequenceFile$Reader.nextRaw(SequenceFile.java:1354)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeStream.next(SequenceFile.java:1880)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergeQueue.merge(SequenceFile.java:1938)
	at org.apache.hadoop.io.SequenceFile$Sorter$MergePass.run(SequenceFile.java:1802)
	at org.apache.hadoop.io.SequenceFile$Sorter.mergePass(SequenceFile.java:1749)
	at org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:1494)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:240)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1066)
"
MAPREDUCE-184,Submitted jobs on jobtracker.jsp,"Sometimes initTasks,job-setup task and the subsequent change of job state to RUNNING takes a while and a newly submitted job is not displayed on jobtracker.jsp till then. It would be good to have submitted jobs also on the ui."
MAPREDUCE-183,The description for some of the configuration entries in the default xml files are outdated and needs to be updated,"Description for some configuration entries in mapred-default.xml are outdated. For example, io.sort.mb. This file needs to be revisited and descriptions updated. The same is probably true for the other defaults as well (core-defaults and hdfs-defaults)"
MAPREDUCE-181,Secure job submission ,Currently the jobclient accesses the {{mapred.system.dir}} to add job details. Hence the {{mapred.system.dir}} has the permissions of {{rwx-wx-wx}}. This could be a security loophole where the job files might get overwritten/tampered after the job submission. 
MAPREDUCE-180,task tracker cannot find mapoutput files,"I ran a large job on our cluster over the weekend. At some point, some map tasks were re-run successfully. However, when trying to handle the reducers requests to fetch mapoutput files of those map tasks, the http server complained file not found.

This happened multiple times on different machines for the same map task until the job tracker aborted the job.


"
MAPREDUCE-179,setProgress not called for new RecordReaders,"NewTrackingRecordReader does not call setProgress in nextKeyValue, as the old API did"
MAPREDUCE-178,Inconsistency in handling lost trackers upon jobtracker restart,"If a tasktracker is lost, the jobtracker kills all the tasks that were successful on that tracker and re-executes it somewhere else. In-memory datastructures are all cleared up for the lost tracker. Now if the jobtracker restarts, the new jobtracker has no clue about the trackers that were lost and hence if the lost tracker join back, they will be accepted and all the tasks on those tracker will join back. Following are the issues
- If the running task on the lost tracker is killed, its cleanup attempt will be launched. Now the new jobtracker has no idea about this attempt. Also the lost tracker can join back and hence there are 2 attempts that are running with the same id, one which can move the tip to success and other which moves the tip to killed state.
- Ideally, the lost tracker should be asked to re-init which wont happen now."
MAPREDUCE-177,Hadoop performance degrades significantly as more and more jobs complete,"When I ran the gridmix 2 benchmark load on a fresh cluster of 500 nodes with hadoop trunk, 
the gridmix load, consisting of 202 map/reduce jobs of various sizes, completed in 32 minutes. 
Then I ran the same set of the jobs on the same cluster, yhey completed in 43 minutes.
When I ran them the third times, it took (almost) forever --- the job tracker became non-responsive.

The job  tracker's heap size was set to 2GB. 
The cluster is configured to keep up to 500 jobs in memory.

The job tracker kept one cpu busy all the time. Look like it was due to GC.

I believe the release 0.18/0.19 have the similar behavior.



I believe 0.18 and 0.18 also have the similar behavior.

"
MAPREDUCE-175,"Sometimes, Reduce tasks hang， State is unassigned","Hi, all

When our cluster runs for a long time, some reduce tasks running on some tasktrackers hang. Their states are UNASSIGNED.  Then, all reduce tasks on these tasktracker will hang.

We kill the hang reduce task, then the reduce task attempt is re-scheduled to this tasktracker, the attempt task continues to hang. We fail it, it goes to another tasktracker, it is executed successfully. 

Tasktracker which has hang reduce task will receive new reduce task, but the reduce  task continue to hang for ever.

When we reboot the tasktracker machine, reduce task no longer hangs.
"
MAPREDUCE-174,JobTracker.close() gets stuck occasionally,JobTracker.close() shuts down all the worker threads by interrupting them and then doing a join. This will work if the thread is in {{WAITING}} state. Most of the time the worker threads are in the {{RUNNING}} state and the JT waits forever on the join(). 
MAPREDUCE-173,JobConf should also load resources from hdfs (or other filesystems),{{JobConf conf = new JobConf(path)}} doesnt load the configuration if _path_ points to a resource on hdfs. 
MAPREDUCE-172,Reducers stuck in 'sort',"A couple of reduces seem stuck on a small 20-node cluster in the 'sort' phase for almost an hour:

TaskTracker logs:
------------------------
2007-03-28 14:13:46,471 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce > sort
2007-03-28 14:13:46,478 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce > sort
2007-03-28 14:13:47,476 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce > sort
2007-03-28 14:13:47,483 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce > sort
...
...
...
2007-03-28 15:06:04,376 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce > sort
2007-03-28 15:06:04,411 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce > sort
2007-03-28 15:06:05,379 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000005_0 0.33333334% reduce > sort
2007-03-28 15:06:05,414 INFO org.apache.hadoop.mapred.TaskTracker: task_0002_r_000009_0 0.33333334% reduce > sort


Eventually the JobTracker declared the same TT 'lost' (presumably for no heartbeats):

2007-03-28 15:18:20,341 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker 'tracker_XXX:9020'
"
MAPREDUCE-171,TestJobTrackerRestartWithLostTracker sometimes fails while validating history.,"TestJobTrackerRestartWithLostTracker fails with following error
Duplicate START_TIME seen for task task_200906151249_0001_m_000001 in history file at line 54
junit.framework.AssertionFailedError: Duplicate START_TIME seen for task task_200906151249_0001_m_000001 in history file at line 54
	at org.apache.hadoop.mapred.TestJobHistory$TestListener.handle(TestJobHistory.java:161)
	at org.apache.hadoop.mapred.JobHistory.parseLine(JobHistory.java:335)
	at org.apache.hadoop.mapred.JobHistory.parseHistoryFromFS(JobHistory.java:299)
	at org.apache.hadoop.mapred.TestJobHistory.validateJobHistoryFileFormat(TestJobHistory.java:478)
	at org.apache.hadoop.mapred.TestJobTrackerRestartWithLostTracker.testRecoveryWithLostTracker(TestJobTrackerRestartWithLostTracker.java:116)
	at org.apache.hadoop.mapred.TestJobTrackerRestartWithLostTracker.testRestartWithLostTracker(TestJobTrackerRestartWithLostTracker.java:162)
"
MAPREDUCE-170,JobTracker doesn't need to download job's jar file onto its local filesystem.,
MAPREDUCE-169,JobHistory should log everything when a job fails or gets killed.,
MAPREDUCE-167,SAXParseException causes test to run forever,"Occassionally, while running TestMiniMRClasspath, I get a SAXParseException that causes the test to run forever.  Two questions I have:

1) what is the underlying cause of the SAXParseException? 
2) does the JobTracker realize that a task got lost?

Here's the pertinent test trace:
    [junit] 2007-02-13 19:26:56,058 INFO  mapred.JobClient (JobClient.java:runJob(400)) - Running job: job_0001
    [junit] 2007-02-13 19:26:57,062 INFO  mapred.JobClient (JobClient.java:runJob(417)) -  map 0% reduce 0%
    [junit] 2007-02-13 19:27:05,258 INFO  mapred.JobInProgress (JobInProgress.java:findNewTask(421)) - Choosing cached task tip_0001_m_000000
    [junit] 2007-02-13 19:27:05,259 INFO  mapred.JobTracker (JobTracker.java:createTaskEntry(690)) - Adding task 'task_0001_m_000000_0' to tip tip_0001_m_000000, for tracker 'tracker_ucdev15.yst.corp.yahoo.com:50067'
    [junit] 2007-02-13 19:27:05,260 INFO  mapred.JobInProgress (JobInProgress.java:findNewTask(421)) - Choosing cached task tip_0001_m_000001
    [junit] 2007-02-13 19:27:05,261 INFO  mapred.JobTracker (JobTracker.java:createTaskEntry(690)) - Adding task 'task_0001_m_000001_0' to tip tip_0001_m_000001, for tracker 'tracker_ucdev15.yst.corp.yahoo.com:50063'
    [junit] 2007-02-13 19:27:05,262 INFO  mapred.TaskTracker (TaskTracker.java:startNewTask(822)) - LaunchTaskAction: task_0001_m_000000_0
    [junit] 2007-02-13 19:27:05,262 INFO  mapred.JobInProgress (JobInProgress.java:findNewTask(421)) - Choosing cached task tip_0001_m_000002
    [junit] 2007-02-13 19:27:05,263 INFO  mapred.JobTracker (JobTracker.java:createTaskEntry(690)) - Adding task 'task_0001_m_000002_0' to tip tip_0001_m_000002, for tracker 'tracker_ucdev15.yst.corp.yahoo.com:50066'
    [junit] 2007-02-13 19:27:05,263 INFO  mapred.TaskTracker (TaskTracker.java:startNewTask(822)) - LaunchTaskAction: task_0001_m_000001_0
    [junit] 2007-02-13 19:27:05,267 INFO  mapred.TaskTracker (TaskTracker.java:startNewTask(822)) - LaunchTaskAction: task_0001_m_000002_0
    [junit] 2007-02-13 19:27:05,270 INFO  mapred.JobInProgress (JobInProgress.java:findNewTask(453)) - Choosing normal task tip_0001_r_000000
    [junit] 2007-02-13 19:27:05,270 INFO  mapred.JobTracker (JobTracker.java:createTaskEntry(690)) - Adding task 'task_0001_r_000000_0' to tip tip_0001_r_000000, for tracker 'tracker_ucdev15.yst.corp.yahoo.com:50062'
    [junit] 2007-02-13 19:27:05,271 INFO  mapred.TaskTracker (TaskTracker.java:startNewTask(822)) - LaunchTaskAction: task_0001_r_000000_0
    [junit] 2007-02-13 19:27:05,285 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-4805938806139473507 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,289 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-4805938806139473507 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,292 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-4805938806139473507 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,295 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-4805938806139473507 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,312 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_3019208026182045172 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,312 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_3019208026182045172 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,352 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-1390246588917827761 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,355 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-1390246588917827761 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,367 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_4739954315939188869 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,368 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_3019208026182045172 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,367 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_4739954315939188869 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,416 FATAL conf.Configuration (Configuration.java:loadResource(552)) - error parsing conf file: org.xml.sax.SAXParseException: Premature end of file.
    [junit] 2007-02-13 19:27:05,417 ERROR mapred.TaskTracker (TaskTracker.java:offerService(535)) - Caught exception: java.lang.RuntimeException: org.xml.sax.SAXParseException: Premature end of file.
    [junit] 	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:553)
    [junit] 	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:472)
    [junit] 	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:453)
    [junit] 	at org.apache.hadoop.conf.Configuration.get(Configuration.java:201)
    [junit] 	at org.apache.hadoop.mapred.JobConf.getJar(JobConf.java:112)
    [junit] 	at org.apache.hadoop.mapred.TaskTracker.localizeJob(TaskTracker.java:332)
    [junit] 	at org.apache.hadoop.mapred.TaskTracker.startNewTask(TaskTracker.java:835)
    [junit] 	at org.apache.hadoop.mapred.TaskTracker.offerService(TaskTracker.java:509)
    [junit] 	at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:864)
    [junit] 	at org.apache.hadoop.mapred.MiniMRCluster$TaskTrackerRunner.run(MiniMRCluster.java:130)
    [junit] 	at java.lang.Thread.run(Thread.java:595)
    [junit] Caused by: org.xml.sax.SAXParseException: Premature end of file.
    [junit] 	at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:264)
    [junit] 	at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:292)
    [junit] 	at javax.xml.parsers.DocumentBuilder.parse(DocumentBuilder.java:98)
    [junit] 	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:510)
    [junit] 	... 10 more
    [junit] [Fatal Error] :-1:-1: Premature end of file.
    [junit] 2007-02-13 19:27:05,423 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_3019208026182045172 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,444 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_-1390246588917827761 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,453 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_4739954315939188869 to /66.228.166.95
    [junit] 2007-02-13 19:27:05,638 INFO  dfs.DistributedFileSystem (InMemoryFileSystem.java:initialize(69)) - Initialized InMemoryFileSystem: ramfs://mapoutput8574467 of size (in bytes): 78643200
    [junit] 2007-02-13 19:27:05,639 INFO  mapred.TaskRunner (ReduceTaskRunner.java:<init>(380)) - task_0001_r_000000_0 Created an InMemoryFileSystem, uri: ramfs://mapoutput8574467
    [junit] 2007-02-13 19:27:05,733 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(446)) - task_0001_r_000000_0 Need 3 map output(s)
    [junit] 2007-02-13 19:27:05,733 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(450)) - task_0001_r_000000_0 Need 3 map output location(s)
    [junit] 2007-02-13 19:27:05,735 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(461)) - task_0001_r_000000_0 Got 0 map outputs from jobtracker
    [junit] 2007-02-13 19:27:05,735 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(476)) - task_0001_r_000000_0 Got 0 known map output location(s); scheduling...
    [junit] 2007-02-13 19:27:05,736 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(505)) - task_0001_r_000000_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
    [junit] 2007-02-13 19:27:05,736 INFO  mapred.TaskRunner (ReduceTaskRunner.java:run(162)) - task_0001_r_000000_0 Started thread: Map output copy reporter for task task_0001_r_000000_0
    [junit] 2007-02-13 19:27:06,741 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.0% reduce > copy > 
    [junit] 2007-02-13 19:27:06,957 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_2428305120985131059 to /66.228.166.95
    [junit] 2007-02-13 19:27:06,959 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_6899441376756315813 to /66.228.166.95
    [junit] 2007-02-13 19:27:07,216 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_m_000002_0 0.0% hdfs://localhost:65314/testing/ext/input/part-0:20+10
    [junit] 2007-02-13 19:27:07,218 INFO  mapred.TaskTracker (TaskTracker.java:reportDone(1062)) - Task task_0001_m_000002_0 is done.
    [junit] 2007-02-13 19:27:07,267 INFO  mapred.JobInProgress (JobInProgress.java:completedTask(496)) - Task 'task_0001_m_000002_0' has completed tip_0001_m_000002 successfully.
    [junit] 2007-02-13 19:27:07,267 INFO  mapred.TaskInProgress (TaskInProgress.java:completedTask(379)) - Task 'task_0001_m_000002_0' has completed.
    [junit] 2007-02-13 19:27:07,470 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_2428305120985131059 to /66.228.166.95
    [junit] 2007-02-13 19:27:07,503 INFO  dfs.DataNode (DataNode.java:readBlock(719)) - Served block blk_6899441376756315813 to /66.228.166.95
    [junit] 2007-02-13 19:27:07,744 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.0% reduce > copy > 
    [junit] 2007-02-13 19:27:07,805 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_m_000000_0 1.0% hdfs://localhost:65314/testing/ext/input/part-0:0+10
    [junit] 2007-02-13 19:27:07,807 INFO  mapred.TaskTracker (TaskTracker.java:reportDone(1062)) - Task task_0001_m_000000_0 is done.
    [junit] 2007-02-13 19:27:07,817 INFO  mapred.JobInProgress (JobInProgress.java:completedTask(496)) - Task 'task_0001_m_000000_0' has completed tip_0001_m_000000 successfully.
    [junit] 2007-02-13 19:27:07,818 INFO  mapred.TaskInProgress (TaskInProgress.java:completedTask(379)) - Task 'task_0001_m_000000_0' has completed.
    [junit] 2007-02-13 19:27:08,111 INFO  mapred.JobClient (JobClient.java:runJob(417)) -  map 66% reduce 0%
    [junit] 2007-02-13 19:27:08,746 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.0% reduce > copy > 
    [junit] 2007-02-13 19:27:09,748 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.0% reduce > copy > 
    [junit] 2007-02-13 19:27:10,736 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(446)) - task_0001_r_000000_0 Need 3 map output(s)
    [junit] 2007-02-13 19:27:10,737 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(450)) - task_0001_r_000000_0 Need 3 map output location(s)
    [junit] 2007-02-13 19:27:10,738 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(461)) - task_0001_r_000000_0 Got 2 map outputs from jobtracker
    [junit] 2007-02-13 19:27:10,738 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(476)) - task_0001_r_000000_0 Got 2 known map output location(s); scheduling...
    [junit] 2007-02-13 19:27:10,738 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(505)) - task_0001_r_000000_0 Scheduled 1 of 2 known outputs (0 slow hosts and 1 dup hosts)
    [junit] 2007-02-13 19:27:10,738 INFO  mapred.TaskRunner (ReduceTaskRunner.java:copyOutput(278)) - task_0001_r_000000_0 Copying task_0001_m_000000_0 output from ucdev15.yst.corp.yahoo.com.
    [junit] 2007-02-13 19:27:10,750 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.0% reduce > copy > 
    [junit] 2007-02-13 19:27:10,756 INFO  mapred.TaskRunner (ReduceTaskRunner.java:copyOutput(304)) - task_0001_r_000000_0 done copying task_0001_m_000000_0 output from ucdev15.yst.corp.yahoo.com.
    [junit] 2007-02-13 19:27:10,757 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(446)) - task_0001_r_000000_0 Need 2 map output(s)
    [junit] 2007-02-13 19:27:10,757 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(450)) - task_0001_r_000000_0 Need 1 map output location(s)
    [junit] 2007-02-13 19:27:11,752 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.11111112% reduce > copy (1 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:12,755 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.11111112% reduce > copy (1 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:13,757 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.11111112% reduce > copy (1 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:14,760 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.11111112% reduce > copy (1 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:15,738 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(461)) - task_0001_r_000000_0 Got 0 map outputs from jobtracker
    [junit] 2007-02-13 19:27:15,739 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(476)) - task_0001_r_000000_0 Got 1 known map output location(s); scheduling...
    [junit] 2007-02-13 19:27:15,739 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(505)) - task_0001_r_000000_0 Scheduled 1 of 1 known outputs (0 slow hosts and 0 dup hosts)
    [junit] 2007-02-13 19:27:15,739 INFO  mapred.TaskRunner (ReduceTaskRunner.java:copyOutput(278)) - task_0001_r_000000_0 Copying task_0001_m_000002_0 output from ucdev15.yst.corp.yahoo.com.
    [junit] 2007-02-13 19:27:15,753 INFO  mapred.TaskRunner (ReduceTaskRunner.java:copyOutput(304)) - task_0001_r_000000_0 done copying task_0001_m_000002_0 output from ucdev15.yst.corp.yahoo.com.
    [junit] 2007-02-13 19:27:15,754 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(446)) - task_0001_r_000000_0 Need 1 map output(s)
    [junit] 2007-02-13 19:27:15,754 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(450)) - task_0001_r_000000_0 Need 1 map output location(s)
    [junit] 2007-02-13 19:27:15,762 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:16,145 INFO  mapred.JobClient (JobClient.java:runJob(417)) -  map 66% reduce 11%
    [junit] 2007-02-13 19:27:16,764 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:17,766 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:18,768 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:19,770 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 

And then this log snippet is repeated forever:
    [junit] 2007-02-13 19:27:20,740 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(461)) - task_0001_r_000000_0 Got 0 map outputs from jobtracker
    [junit] 2007-02-13 19:27:20,740 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(476)) - task_0001_r_000000_0 Got 0 known map output location(s); scheduling...
    [junit] 2007-02-13 19:27:20,740 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(505)) - task_0001_r_000000_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
    [junit] 2007-02-13 19:27:20,772 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:21,775 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:22,777 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:23,779 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:24,781 INFO  mapred.TaskTracker (TaskTracker.java:reportProgress(1013)) - task_0001_r_000000_0 0.22222224% reduce > copy (2 of 3 at 0.00 MB/s) > 
    [junit] 2007-02-13 19:27:25,742 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(446)) - task_0001_r_000000_0 Need 1 map output(s)
    [junit] 2007-02-13 19:27:25,742 INFO  mapred.TaskRunner (ReduceTaskRunner.java:prepare(450)) - task_0001_r_000000_0 Need 1 map output location(s)
"
MAPREDUCE-166,"Remove distcp from hadoop core libraries, and publish documentation","Every time we want to ship a change in distcp, not only do we have to replace the entire version of map-reduce deployed to the clusters, we also have to update internal documentation to reflect those changes.
"
MAPREDUCE-163,TaskTracker's Jetty throws SocketException followed by IllegalStateException,"When running the sort benchmark, these exceptions (271 pairs of them) were noted in the log of the task tracker that was ""lost"".

2007-01-05 19:02:28,663 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_0001_m_009177_0,2415) failed :
java.net.SocketException: Broken pipe
        at java.net.SocketOutputStream.socketWrite0(Native Method)
        at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92)
        at java.net.SocketOutputStream.write(SocketOutputStream.java:136)
        at org.mortbay.http.ChunkingOutputStream.bypassWrite(ChunkingOutputStream.java:151)
        at org.mortbay.http.BufferedOutputStream.write(BufferedOutputStream.java:139)
        at org.mortbay.http.HttpOutputStream.write(HttpOutputStream.java:423)
        at org.mortbay.jetty.servlet.ServletOut.write(ServletOut.java:54)
        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:1526)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)

2007-01-05 19:02:28,664 WARN /: /mapOutput?map=task_0001_m_009177_0&reduce=2415:
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.servlet.ServletHttpResponse.resetBuffer(ServletHttpResponse.java:212)
        at org.mortbay.jetty.servlet.ServletHttpResponse.sendError(ServletHttpResponse.java:375)
        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:1551)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
"
MAPREDUCE-162,[mapred] Change TaskMemoryManager to use JvmIDs instead of TaskIDs for memory-tracking.,"To monitor tasks, TaskMemoryManager uses taskIDs to find pidFiles of the tasks. HADOOP-249 introduced jvm re-use because of which multiple tasks can run in a single JVM, and so will share the same pid(pidFile). HADOOP-249 works on a new task by creating a symlink to the pid-file of the task that ran first in the same jvm. Also, the process(jvm) is repeatedly added and removed from monitoring when tasks(under same jvm) come and go. The symlinks and the repetitive addition/removal from monitoring can be avoided if TaskMemoryManager uses JvmIDs instead of TaskIDs."
MAPREDUCE-161,Tasks are not scheduled even though task trackers have extra slots,"
I ran a job with 51 reduce tasks on a cluster with 13 task trackers running Hadoop 0.19. Each task tracker has 5 reduce slots.
Initially, each task tracker accepted 4 reduce tasks as expected. However,  3 task trackers were put into blacklist because many tasks failed on them.
However, those failed tasks stayed in pending state, not being scheduled to other task trackers, even though each of the other healthy tracker has one free slot.
"
MAPREDUCE-160,Final map task gets stuck,"I've seen numerous jobs lately where the final map task gets stuck, never finishing.
The jobtracker doesn't reassign the task. A restart of the tasktracker solves the issue and the job can finish.
In the web interface it turns up as:

task_0028_m_000534_0 node17.herd1 RUNNING 0.00%    10-Nov-2006 12:21:12 10-Nov-2006 12:22:19 (1mins, 6sec)
Task failed to report status for 604 seconds. Killing.

Only exception I find in that tasktracker log is this (a few times):
java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:125)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:294)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.flushBuffer(SocketChannelOutputStream.java:108)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.write(SocketChannelOutputStream.java:89)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:532)"
MAPREDUCE-158,mapred.userlog.retain.hours killing long running tasks,"One can reproduce the scenario by configuring mapred.userlog.retain.hours to 1hr, and running tasks that take more than an hour.

More info on closed ticket HADOOP-5591."
MAPREDUCE-157,Job History log file format is not friendly for external tools.,"Currently, parsing the job history logs with external tools is very difficult because of the format. The most critical problem is that newlines aren't escaped in the strings. That makes using tools like grep, sed, and awk very tricky."
MAPREDUCE-156,ProcessTree.destroy() is sleeping for 5 seconds holding the task slot,"Currently, in ProcessTree.destroy(), after sending SIGTERM to the task JVM, TT sleeps for 5 seconds(default value of mapred.tasktracker.tasks.sleeptime-before-sigkill) before sending SIGKILL. This seems to be blocking the task slot(not getting released) for 5 seconds. We should avoid this so that another task could be launched in that slot immediately."
MAPREDUCE-155,Each task tracker should not execute more than one speculative task,"
I noticed that sometimes, a tasktracker started 2 or three speculative mapper tasks.
That seems counter productive. You want to speculative execution complete as soon as possible.
Thus, it is better to spread speculative execution over multiple trackers. A simple way to 
achieve that is to limit the number of speculative eecution concurrently.
"
MAPREDUCE-154,Mapper runs out of memory,"The hadoop job has the task of processing 4 directories in HDFS, each with 15 files.  This is sample data, a test run, before I go to the needed 5 directories of about 800 documents each.  The mapper takes in nearly 200 pages (not files) and throws an OutOfMemory exception.  The largest file is 17 MB.

If this problem is something on my end and not truly a bug, I apologize.  However, after Googling a bit, I did see many threads of people running out of memory with small data sets."
MAPREDUCE-153,TestJobInProgressListener sometimes timesout,"It times out with ""Could not find /taskTracker/jobcache/jobid/work in any of the configured local directories""."
MAPREDUCE-152,getMapOutput() keeps failing too many times before the tasktracker fails,"We are running a big job on our cluster. There are about 400 reducers. Around 361 reducers finished successfully while the last batch of 39 reducers all failed roughly around the same time. After examining the log files, the following error info was found 858 times for a single tasktracker:

2008-04-21 02:42:45,368 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2,396) failed :
2008-04-21 02:42:49,468 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2,396) failed :
2008-04-21 02:43:03,717 WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(task_200804101742_0001_m_032077_2,396) failed :


Shouldn't the task tracker failed early without trying so many times?"
MAPREDUCE-151,JobClient doesn't wait for all task completion events before exiting,The JobClient should pull all of the task completion events from the JobTracker before exiting the loop and returning to the application. Otherwise the failing task may be lost in the backlog since only 10 task events are fetched per a second.
MAPREDUCE-149,Class JobControl needs to be rewritten for safe concurrency,"The use of concurrency control and synchronization in JobControl is broken.  Consider

- The locking in addToQueue() and toArrayList() is supposed to create per-queue locking for the queues referenced by the fields readyJobs, runningJobs, successfulJobs, waitingJobs, and failedJobs.  But this is compromised by the fact that these methods are always called when the thread is already synchronized on ""this"".

- The run() method is written to use a busy-loop and Thread.sleep(int). But runnerState is not generally accessed using synchronization, nor is it volatile. This means that the run() is not guaranteed to ever view updates to runnerState.  The run() method really needs to be changed to use wait(), and to be signaled when changes are made to runnerState or to any of the queues.

Let's also consider the existing synchronized methods:

addJob() -- I'm pretty sure that the synchronization in addJob is only necessary to protect the (indirect) access to the long field nextJobID. This situation could be simplified by moving the synchronization to getNextJobID(). As it stands, it makes the locking in addToQueue() redundant. 

allFinished() -- This is synchronized to provide an atomic snapshot of the state of the queues. It should be changed to use wait() and be notified whenever the size of one of the queues changes. 

checkRunningJobs(), checkWaitingJobs(), and startReadyJobs() -- These are all synchronized to prevent them from interfering with each other, themselves, and with addJobs(). This is too conservative. We really only need to be sure that each one doesn't interfere with itself (otherwise we could end up processing entries twice in parallel), but this is not possible based on the intended usage: they are are only called from the run(), so they can never be concurrency invoked. I don't see any danger from them running concurrently with addJob(), as long as the integrity of the underlying queues is protected. As with addJob(), the synchronization on these methods makes the per-queue synchronization in addToQueue redundant. 

This class should be rewritten as follows:

    * The field groupName should be made final. 

    * Add a new private boolean field stateChanged that is set to true whenever the state of the object is changed from a public method call. This is checked and reset by run(). 

    * The per-queue synchronization needs to be scrapped: it isn't being exploited any way. 

    * The five queue fields plus the fields runnerState, nextJobID, and the new stateChanged should all be protected by the lock this. 

    * The run() method should be rewritten to use wait(). 

    * public methods that change the state of the queues or runnerState should set stateChanged to true and call notifyAll(). 

    * Ideally, allFinished() should be changed to use wait() as well. This would change the public interface of the class and break existing clients.  So this method should be @Deprecated, and a new waitForAllFinished() method should be added.

    * The queue fields should be assigned HashMap objects instead of Hashtable objects. There is no advantage to using the synchronization provided by Hashtable. 
"
MAPREDUCE-148,A successful tip can fail unnecessarily,"Consider the following sequence of events
1. tip _t_ has 5 attempts, _attempt_0-4_. Lets assume that _attempt_0,attempt_1_ and _attempt_2_ have failed. _attempt_3_ and _attempt_4_ are running. 
2. _attempt_3_ runs on tracker _t1_ and attempt_4 runs on tracker _t2_
3. _attempt_3_ reports success and the tip _t_ is marked successful
4. _attempt_4_ reports failure and the tip _t_ is failed based on the call to _TaskInProgress.incompleteSubTask()_.
Here the tip _t_ is failed unnecessarily."
MAPREDUCE-147,server can't set username in JobClient.submitJob for jobs submitted on behalf of other users,"I have a rpc server that sits in front of hadoop and submits mapreduce jobs on behalf of users (humans).  However, because hadoop gets username information from the unix username of the submitting process, all my jobs appear to be from the unix account used by the webserver.

I tried to fix it by doing this:

JobConf conf = ...
JobClient client = ...
conf.setUser(username);
client.submitJob(conf);

But that doesn't work because submitJob overwrites the username I wrote with setUser.

Instead, submitJob should only insert a username into the job if it is not in the config already.  Alternately, the username might be inserted at the time of creation of the JobConf, so that I have an opportunity to overwrite it, or the JobConf could supply some hook for me to insert some alternate username."
MAPREDUCE-146,Stale job files in mapred system directory,"In one scenario, job client uploaded the job split file and job jar onto the mapred system directory but got killed before the actual job got submitted and/or before the job got known to the JT. In such situations, the split and jar files are left as garbage as JT doesn't know of the job yet. On a long running JT, this garbage can accumulate."
MAPREDUCE-145,DiskChecker$DiskErrorException when 'reduce > reduce',"We have  9900 maptasks and 60 reducetasks in the job. When all the other 59 reducetasks have finished, the last reducetask runs so slow and finally finished after throwing out a lot of DiskErrorExceptions.

The following is the tasktracker log on which the reducetask is running. 

2009-03-18 14:39:52,025 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:39:57,028 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories

2009-03-18 14:40:00,695 INFO org.apache.hadoop.mapred.TaskTracker: attempt_200903171026_0091_r_000030_0 0.977961% reduce > reduce

2009-03-18 14:40:02,032 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:07,036 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:12,040 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:17,045 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:22,050 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:27,054 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:32,058 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:37,062 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:42,066 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:47,136 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:52,140 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:40:57,143 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:41:02,147 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories

2009-03-18 14:41:06,760 INFO org.apache.hadoop.mapred.TaskTracker: attempt_200903171026_0091_r_000030_0 0.9788374% reduce > reduce

2009-03-18 14:41:07,152 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:41:09,762 INFO org.apache.hadoop.mapred.TaskTracker: attempt_200903171026_0091_r_000030_0 0.9788374% reduce > reduce
2009-03-18 14:41:12,158 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:41:17,162 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:41:22,168 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
2009-03-18 14:41:27,172 INFO org.apache.hadoop.mapred.TaskTracker: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find taskTracker/jobcache/job_200903171026_0091/attempt_200903171026_0091_r_000030_0/output/file.out in any of the configured local directories
"
MAPREDUCE-144,TaskMemoryManager should log process-tree's status while killing tasks.,This helps a lot in debugging why a particular task has gone beyond memory limits.
MAPREDUCE-143,OOM in the TaskTracker while serving map outputs,"Saw this exception in the TT logs:

2009-02-06 06:18:08,553 ERROR org.mortbay.log: EXCEPTION
java.lang.OutOfMemoryError: GC overhead limit exceeded
2009-02-06 06:18:11,247 ERROR org.mortbay.log: Error for /mapOutput
java.lang.OutOfMemoryError: GC overhead limit exceeded
2009-02-06 06:18:11,247 ERROR org.mortbay.log: Error for /mapOutput
java.lang.OutOfMemoryError: Java heap space
        at java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:39)
        at java.nio.ByteBuffer.allocate(ByteBuffer.java:312)
        at org.mortbay.io.nio.IndirectNIOBuffer.<init>(IndirectNIOBuffer.java:28)
        at org.mortbay.jetty.nio.AbstractNIOConnector.newBuffer(AbstractNIOConnector.java:71)
        at org.mortbay.jetty.AbstractBuffers.getBuffer(AbstractBuffers.java:131)
        at org.mortbay.jetty.HttpGenerator.addContent(HttpGenerator.java:145)
        at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:642)
        at org.mortbay.jetty.AbstractGenerator$Output.write(AbstractGenerator.java:577)
        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:2879)"
MAPREDUCE-142,Race condition in DistributedCache,"When an older version of a file in DistributedCache exists locally and multiple tasks per node start, they can run into a race condition:

dir/mapred/local/taskTracker/archive/subdir/filename is in use and cannot be refreshed
	at org.apache.hadoop.filecache.DistributedCache.localizeCache(DistributedCache.java:313)
	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:161)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:134)

We ran a job with the wrong file, then around 50 minutes later we put the fixed version into DFS, and ran the same job again. The job had 11,000 maps ~ about 4-5 waves of map tasks and produced 3,500 failed tasks with above error. We eventually killed it and restarted the same job again, with no problems this time.
"
MAPREDUCE-141,reduce % complete incorrect in webui,"I have a running job that has 1002 reduces.  Currently the JobTracker WebUI has the following:

Kind	 %Complete	Num Tasks	Pending	Running	Complete  Killed  Failures
map <snip>
reduce  100.00%	1002	0	2	1000	0	10

So 2 reduces are still running but the % complete is 100%."
MAPREDUCE-140,TaskMemoryManager not enforcing memory limits in the presence of rogue tasks,
MAPREDUCE-139,JobTracker crashes Sun JVM,"From our jobtacker's .out file:

#
# An unexpected error has been detected by HotSpot Virtual Machine:
#
#  SIGSEGV (0xb) at pc=0xf27bf825, pid=24028, tid=1856498608
#
# Java VM: Java HotSpot(TM) Server VM (1.5.0_06-b05 mixed mode)
# Problematic frame:
# J  org.mortbay.util.ByteArrayPool.getByteArray(I)[B
#
# An error report file with more information is saved as hs_err_pid24028.log
#
# If you would like to submit a bug report, please visit:
#   http://java.sun.com/webapps/bugreport/crash.jsp
#

And the relevant parts of that hs_err_pid24028.log file:

#
# An unexpected error has been detected by HotSpot Virtual Machine:
#
#  SIGSEGV (0xb) at pc=0xf27bf825, pid=24028, tid=1856498608
#
# Java VM: Java HotSpot(TM) Server VM (1.5.0_06-b05 mixed mode)
# Problematic frame:
# J  org.mortbay.util.ByteArrayPool.getByteArray(I)[B
#

---------------  T H R E A D  ---------------

Current thread (0x086e0088):  JavaThread ""SocketListener0-0"" [_thread_in_Java, id=24112]

siginfo:si_signo=11, si_errno=0, si_code=2, si_addr=0x00022008

Registers:
EAX=0x00022000, EBX=0x75a0fac8, ECX=0x00000000, EDX=0x75b31258
ESP=0x6ea7ded0, EBP=0x6ea7df3c, ESI=0x71b6def5, EDI=0x00000402
EIP=0xf27bf825, CR2=0x00022008, EFLAGS=0x00010217

Top of Stack: (sp=0x6ea7ded0)
0x6ea7ded0:   71549561 6ea7def0 00002000 00000400
0x6ea7dee0:   339dc50d 086e0088 6ea7df3c 6ea7df50
0x6ea7def0:   00000000 71b6def5 7154d7c9 f2595a80
0x6ea7df00:   6ea7df3c 6ea7df50 7154d7d8 6ea7df14
0x6ea7df10:   6ea7df3c f2501a14 00002000 e57bd350
0x6ea7df20:   6ea7df20 71b6def5 6ea7df50 71b71798
0x6ea7df30:   00000000 71b6df80 6ea7df44 6ea7df78
0x6ea7df40:   f2501aeb 719431e8 00002000 e57bd2d0 

Instructions: (pc=0xf27bf825)
0xf27bf815:   8b 98 a4 00 00 00 8b 4b 20 89 4c 24 20 8b 41 08
0xf27bf825:   8b 70 08 8b de 4b 8b 4c 24 10 23 cb 89 4c 24 10 

Stack: [0x6e9fe000,0x6ea7f000),  sp=0x6ea7ded0,  free space=511k
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
J  org.mortbay.util.ByteArrayPool.getByteArray(I)[B
j  org.mortbay.http.HttpInputStream.<init>(Ljava/io/InputStream;I)V+15
j  org.mortbay.http.HttpConnection.<init>(Lorg/mortbay/http/HttpListener;Ljava/net/InetAddress;Ljava/io/InputStream;Ljava/io/OutputStream;Ljava/lang/Object;)V+97
j  org.mortbay.http.SocketListener.createConnection(Ljava/net/Socket;)Lorg/mortbay/http/HttpConnection;+18
j  org.mortbay.http.SocketListener.handleConnection(Ljava/net/Socket;)V+2
j  org.mortbay.util.ThreadedServer.handle(Ljava/lang/Object;)V+19


---------------  P R O C E S S  ---------------

Java Threads: ( => current thread )
  0x086bb8a0 JavaThread ""Thread-0"" [_thread_blocked, id=24117]
  0x0859dd38 JavaThread ""Thread-20"" [_thread_blocked, id=24116]
  0x0859a8a8 JavaThread ""Thread-19"" [_thread_blocked, id=24115]
  0x0859a1f8 JavaThread ""Thread-18"" [_thread_blocked, id=24114]
  0x085d54d8 JavaThread ""SocketListener0-1"" [_thread_in_native, id=24113]
=>0x086e0088 JavaThread ""SocketListener0-0"" [_thread_in_Java, id=24112]

[...]

Heap
 PSYoungGen      total 21248K, used 19699K [0xe4640000, 0xe6a00000, 0xf2470000)
  eden space 19584K, 92% used [0xe4640000,0xe57def08,0xe5960000)
  from space 1664K, 99% used [0xe5960000,0xe5afe020,0xe5b00000)
  to   space 8384K, 0% used [0xe61d0000,0xe61d0000,0xe6a00000)
 PSOldGen        total 390080K, used 370693K [0x75470000, 0x8d160000, 0xe4640000)
  object space 390080K, 95% used [0x75470000,0x8be716e0,0x8d160000)
 PSPermGen       total 16384K, used 8080K [0x71470000, 0x72470000, 0x75470000)
  object space 16384K, 49% used [0x71470000,0x71c54298,0x72470000)

[...]

VM Arguments:
jvm_args: -Xmx2000m -Dhadoop.log.dir=/export//current/../run2/log -Dhadoop.log.file=hadoop-jobtracker.log -Dhadoop.home.dir=/export/current -Dhadoop.id.str=crawler -Dhadoop.root.logger=INFO,DRFA
java_command: org.apache.hadoop.mapred.JobTracker
Launcher Type: SUN_STANDARD

Environment Variables:
JAVA_HOME=/export//java/jdk
PATH=/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin:/usr/X11R6/bin:/export//current/bin
LD_LIBRARY_PATH=/export/java/jdk1.5.0_06/jre/lib/i386/server:/export//java/jdk1.5.0_06/jre/lib/i386:/export//java/jdk1.5.0_06/jre/../lib/i386
SHELL=/bin/tcsh
HOSTTYPE=x86_64-linux
OSTYPE=linux
MACHTYPE=x86_64
"
MAPREDUCE-138,Rework job-setup and job-cleanup tasks,"Currently we have a notion of map-{setup|cleanup} TIP and reduce-{setup|cleanup} TIP of which only 1 setup and cleanup tasks are picked by the JobInProgress. Also a lot of state-maintenence of these TIPs are done by the JobInProgress itself, outside of the more logical place i.e. TaskInProgress.

We really should rework this to have a single setup and cleanup task which isn't associated with a map or reduce task i.e. into separate task _types_. What we have currently is quite ungainly and hard to maintain."
MAPREDUCE-137,org.apache.hadoop.mapred.TestJobDirCleanup.testJobDirCleanup timesout occasionally ,"org.apache.hadoop.mapred.TestJobDirCleanup.testJobDirCleanup timesout occasionally in hudson builds.
One such build @ http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/496/testReport/"
MAPREDUCE-135,speculative task failure can kill jobs,"We had a case where the random writer example was killed by speculative execution. It happened like:

task_0001_m_000123_0 -> starts
task_0001_m_000123_1 -> starts and fails because attempt 0 is creating the file
task_0001_m_000123_2 -> starts and fails because attempt 0 is creating the file
task_0001_m_000123_3 -> starts and fails because attempt 0 is creating the file
task_0001_m_000123_4 -> starts and fails because attempt 0 is creating the file

job_0001 is killed because map_000123 failed 4 times. From this experience, I think we should change the scheduling so that:

  1. Tasks are only allowed 1 speculative attempt.
  2. TIPs don't kill jobs until they have 4 failures AND the last task under that tip fails.

Thoughts?"
MAPREDUCE-134,TaskTracker startup fails if any mapred.local.dir entries don't exist,"This appears to have been introduced with the ""check for enough free space"" before startup.

It's debatable how best to fix this bug. I will submit a patch which ignores directories for which the DF utility fails. This is letting me continue operation on my cluster (where the number of drives varies, so there are entries in mapred.local.dir for drives that aren't on all cluster nodes), but a cleaner solution is probably better. I'd lean towards ""check for existence"", and ignore the dir if it doesn't  - but don't depend on DF to fail, since DF could fail for other reasons without meaning you're out of disk space. I argue that a TaskTracker should start up if *all* directories that *can be written to* in the list have enough space. Otherwise, a failed drive per cluster machine means no work ever gets done."
MAPREDUCE-133,Getting errors in reading the output files of a map/reduce job immediately after the job is complete,"
I have an app that fire up map/reduce jobs sequentially. The output of one job if the input of the next.
I observe that many map tasks failed due to file read errors:

java.rmi.RemoteException: java.io.IOException: Cannot open filename /user/runping/runping/docs_store/stage_2/base_docs/part-00186 at org.apache.hadoop.dfs.NameNode.open(NameNode.java:130) at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:585) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:237) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:216) at org.apache.hadoop.ipc.Client.call(Client.java:303) at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:141) at org.apache.hadoop.dfs.$Proxy1.open(Unknown Source) at org.apache.hadoop.dfs.DFSClient$DFSInputStream.openInfo(DFSClient.java:315) at org.apache.hadoop.dfs.DFSClient$DFSInputStream.(DFSClient.java:302) at org.apache.hadoop.dfs.DFSClient.open(DFSClient.java:95) at org.apache.hadoop.dfs.DistributedFileSystem.openRaw(DistributedFileSystem.java:78) at org.apache.hadoop.fs.FSDataInputStream$Checker.(FSDataInputStream.java:46) at org.apache.hadoop.fs.FSDataInputStream.(FSDataInputStream.java:220) at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:146) at org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:234) at org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:226) at org.apache.hadoop.mapred.SequenceFileRecordReader.(SequenceFileRecordReader.java:36) at org.apache.hadoop.mapred.SequenceFileInputFormat.getRecordReader(SequenceFileInputFormat.java:53) at org.apache.hadoop.mapred.MapTask.run(MapTask.java:105) at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:709) 

Those tasks succeeded in the second or third try.

After interting 10 seconds sleep between consecutive jobs, the problem disappear.

Here is my code to detect whether a job is completed:

      try {
        running = jc.submitJob(job);
        String jobId = running.getJobID();
        System.out.println(""start job:\t"" + jobId);
        while (!running.isComplete()) {
          try {
            Thread.sleep(1000);
          } catch (InterruptedException e) {}
          running = jc.getJob(jobId);
        }
        sucess = running.isSuccessful();
      } finally {
        if (!sucess && (running != null)) {
          running.killJob();
        }
        jc.close();
      }

"
MAPREDUCE-132,getSetupAndCleanupTasks should return multiple tasks in a heartbeat,"getSetupAndCleanupTasks in JobTracker returns one task per heartbeat. With HADOOP-3136, schedulers give multiple tasks  per heartbeat, getSetupAndCleanupTasks should also give multiple tasks per heartbeat."
MAPREDUCE-131,"After HADOOP-5420, tasks hang when the taskcontroller.cfg has multiple entries for mapred.local.dir","HADOOP-5420 refactored code from taskcontroller.c -> check_tt_root() to configuration.c for reuse. While doing this, this bug got introduced because of which all tasks hang when a cluster is configured with multiple mapred local directories. This happens because of the latest code in check_tt_root() which never advances the mapred_local_dir pointer and gets stuck in an infinite loop."
MAPREDUCE-130,Delete the jobconf copy from the log directory of the JobTracker when the job is retired,"The JobTracker (for web-ui viewing purposes), copies the jobconf from the hdfs and store it in the log directory. The file should be deleted when the job is retired (removed from memory)."
MAPREDUCE-129,job_null_0001 in jobid,"When I submit a job before jobtracker is fully up, I occasionally get  jobid of job_null_0001.

[knoguchi ]$ hadoop -jar ...
07/10/12 00:15:07 INFO mapred.FileInputFormat: Total input paths to process : 4
07/10/12 00:15:08 INFO mapred.JobClient: Running job: *job_null_0001*
07/10/12 00:15:09 INFO mapred.JobClient:  map 0% reduce 0%
"
MAPREDUCE-127,Task trackers don't register with the job tracker until after they clean out their working directory,"When TaskTrackers are started, they immediately start deleting their working directory, which can take 30+ minutes. Unfortunately, that means they don't register themselves with the JobTracker for a long time, so it looks like the cluster is ""missing""."
MAPREDUCE-126,Job history analysis showing wrong job runtime,"Analysis of completed jobs shows wrong runtime. Here is the faulty code
{code:title=analysisjobhistory.jsp|borderStyle=solid}
<b>Finished At : </b>  <%=StringUtils.getFormattedTimeWithDiff(dateFormat, job.getLong(Keys.FINISH_TIME), job.getLong(Keys.LAUNCH_TIME)) %><br/>
{code}
I think it should be 
{code:title=analysisjobhistory.jsp|borderStyle=solid}
<b>Finished At : </b>  <%=StringUtils.getFormattedTimeWithDiff(dateFormat, job.getLong(Keys.FINISH_TIME), job.getLong(Keys.SUBMIT_TIME)) %><br/>
{code}
"
MAPREDUCE-125,JobTracker might wrongly log a tip as failed,"Consider the following case
1) attempt _attempt_1_0_ from tip _tip_1_ that ran on tracker _tracker_1_ failed
2) jobtracker will mark _attempt_1_0_ for removal under _tracker_1_. Marking basically means removal of the mapping _tracker_1_->_attempt_1_0_
3) Marked attempts are removed only on next heartbeat from _tracker__1 or when _tracker_1_ is lost.
4) Consider a case where _tracker_1_ goes down.
5) In the meanwhile attempt _attempt_1_1_ succeeds on _tracker_2_ and the jobtracker marks the tip _tip_1_ as complete
6) Now the expiry-tracker thread detect that _tracker_1_ is lost and fails all the attempt under _tracker_1_. 
7) Here the jobtracker will kill _attempt_1_0_ *again* and log tip _tip_1_ as failed in the history although tip _tip_1_ is really complete/succeeded.

The events in the history file would be something like
{noformat}
tip_1 start
---------
attempt_1_0 start
attempt_1_0 failed
---------
attempt_1_1 start
attempt_1_1 finished
tip_1 finished
---------
tip_1 failed
{noformat}

Note that this true even for tasks that expire. Tasks that are scheduled and never come back are killed by the {{ExpireLaunchingTasks}} thread. It will also call {{JobInProgress.failedTask()}} which will fail the attempt and log the TIP as failed."
MAPREDUCE-124,"When abortTask of OutputCommitter fails with an Exception for a map-only job, the task is marked as success",Running TestTaskFail with numreduces = 0 demonstrates this problem.
MAPREDUCE-123,HistoryViewer usage string is misleading.,"$ hadoop job -history
Usage: JobClient [-history <jobOutputDir>]

The input is actually a history-location (for e.g., specified by hadoop.job.history.user.location) which happens to default to a jobOutputDir. The usage string should reflect this.

Also the restriction for history files to be in a _logs/history sub-directory is stringent. This could be changed so that history can be directly put in hadoop.job.history.user.location similar to how we store directly in hadoop.job.history.location. Seems like _logs/history is only intended to be used in conjuction with jobOutputDir, as a default location."
MAPREDUCE-122,JobTracker.addNewTracker() unnecessarily resolves already resolved nodes,_hostnameToNodeMap_ maintains a map from _hostname_ to _resolved-address_. {{JobTracker.addNewTracker()}} resolves a node's address if the node is not present in _hostnameToNodeMap_ but uses _tracker-name_ to index into _hostnameToNodeMap_ instead of _hostname_. 
MAPREDUCE-119,JobTracker and TaskTracker enter infinite loop when TaskTracker reports bad taskid,"If the TaskTracker somehow gets into a state where it has a task in COMMIT_PENDING state that the JobTracker does not know about, the JobTracker will throw NPEs while processing heartbeats. Due to HADOOP-3987, this causes the JT and TT to enter an infinite heartbeat loop with no delays, and the TT fails to make progress."
MAPREDUCE-118,Job.getJobID() will always return null,"JobContext is used for a read-only view of job's info. Hence all the readonly fields in JobContext are set in the constructor. Job extends JobContext. When a Job is created, jobid is not known and hence there is no way to set JobID once Job is created. JobID is obtained only when the JobClient queries the jobTracker for a job-id., which happens later i.e upon job submission."
MAPREDUCE-116,Have a test to verify that descendent processes of tasks that ignore SIGTERM are eventually cleaned up by a SIGKILL,"HADOOP-2721 added TestKillSubProcesses to test that all the processes descending from a task are cleaned up with a SIGTERM when task finishes. The functionality to eventually send a SIGKILL to processes that ignore SIGTERM is already in place, but we don't have a test verifying this yet."
MAPREDUCE-115,Map tasks are receiving FileNotFound Exceptions for spill files on a regular basis and are getting killed,"The following is the log -- Map tasks are unable to locate the spill files when they are doing the final merge (mergeParts). 

java.io.FileNotFoundException: File /xxx/mapred-tt/mapred-local/taskTracker/jobcache/job_200808190959_0001/attempt_200808190959_0001_m_000000_0/output/spill23.out does not exist.
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:420)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:244)
	at org.apache.hadoop.fs.FileSystem.getContentSummary(FileSystem.java:682)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.getFileLength(ChecksumFileSystem.java:218)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.seek(ChecksumFileSystem.java:259)
	at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:37)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1102)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:769)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:255)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2208)
"
MAPREDUCE-114,"All reducer tasks are finished, while some mapper tasks are still running","In a high load environment (i.e. multiple jobs are queued up to be executed), when all reducer tasks of a job are finished, some mapper tasks of the same job may still running (possibly re-executed due to lost task tracker, etc).

This should not happen when a job has at least one reducer task. When all reducer tasks are in SUCCEEDED state, the Hadoop JobTracker should kill all running mapper tasks, since execution would be meaningless. The job should also switch to SUCCEEDED state when all reducer tasks of that job succeeded successfully."
MAPREDUCE-113,[mapred] Job submission to an invalid queue should fail.,"If ACLs are enabled, this case is handled, though not with a clear message to the user. Job submission to an invalid queue should be detected and dealt with. Irrespective of ACLs."
MAPREDUCE-112,Reduce Input Records and Reduce Output Records counters are not being set when using the new Mapreduce reducer API,"After running the examples/wordcount (which uses the new API), the reduce input and output record counters always show 0. This is because these counters are not getting updated in the new API"
MAPREDUCE-111,JobTracker.getSystemDir throws NPE if it is called during intialization,"JobTracker.getSystemDir throws NPE if it is called during intialization.
It should check if fileSystem is null and throw IllegalStateException, as in getFilesystemName method."
MAPREDUCE-110,Unit tests for LinuxTaskController binary,We should have unit tests in C for various functions used by LinuxTaskController binary. These would help a lot in maintaining the code and easy spotting of bugs.
MAPREDUCE-108,Blacklisted hosts may not be able to serve map outputs,"After a node fails 4 mappers (tasks), it is added to blacklist thus it will no longer accept tasks.
But, it will continue serve the map outputs of any mappers that ran successfully there. 
However, the node may not be able serve the map outputs either. 
This will cause the reducers to mark the corresponding map outputs as from slow hosts, 
but continue to try to get the map outputs from that node.
This may lead to waiting forever.
"
MAPREDUCE-107,Tasks fail due to lost mapout,"When I ran a job, each map task of which generates Gbytes of map output, I saw many tasks failed with following errors:
Map output lost, rescheduling: getMapOutput(task_0993_m_000013_0,140) failed :
java.io.FileNotFoundException: /hadoop/mapred/local/task_0993_m_000013_0/file.out
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:332)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:245)
	at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:1657)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
	at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
	at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
	at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
	at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
	at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
	at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
	at org.mortbay.http.HttpServer.service(HttpServer.java:954)
	at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
	at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
	at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
	at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
	at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
	at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)"
MAPREDUCE-106,The temporary disk space limits should not skip jobs,"In HADOOP-657, we added disk space modeling and throttling. The scheduler currently picks the next job if there isn't enough space, which can lead to starvation of jobs that require a lot of space. It should not schedule any task if the first job can't use the space."
MAPREDUCE-104,Not able to refresh file cache,"I ran a map/reduce job with file caching. When I reran it with an updated file jar, I got the following error :

java.io.IOException: Cache XXX/hadoop/mapred/local/taskTracker/archive/YYY/input_data/cdxcore.Linux.jar is in use and cannot be refreshed
	at org.apache.hadoop.filecache.DistributedCache.localizeCache(DistributedCache.java:195)
	at org.apache.hadoop.filecache.DistributedCache.getLocalCache(DistributedCache.java:86)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:108)"
MAPREDUCE-103,The TaskTracker's shell environment should not be passed to the children.,"HADOOP-2838 and HADOOP-5981 added support to make the TaskTracker's shell environment available to the tasks. This has two problems:
  1. It makes the task tracker's environment part of the interface to the task, which is fairly brittle.
  2. Security code typically only passes along whitelisted environment variables instead of everything to prevent accidental leakage from the administrator's account."
MAPREDUCE-102,NPE in tracker expiry thread.,"
I see NullPointerExceptions in Task Expiry thread of the JobTracker. Exception log in JT:
{code}
2009-02-28 07:22:51,392 ERROR org.apache.hadoop.mapred.JobTracker: Tracker Expiry Thread got exception: java.lang.NullPointerException
{code}"
MAPREDUCE-100,Sporadic TestEmptyJobWithDFS failure due to NPE is JobTracker.submitJob(),"org.apache.hadoop.mapred.TestEmptyJobWithDFS has failed a couple of times (low reproducibility) with the following exception:

2006-10-17 21:48:24,875 INFO  ipc.Server (Server.java:run(516)) - Server handler 2 on 50050 call error: java.io.IOException: java.lang.NullPointerException
java.io.IOException: java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobTracker.submitJob(JobTracker.java:1020)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:385)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:514)

Complete test log attached."
MAPREDUCE-99,Reducers throw oom exceptions during fetching map outputs,"I have a job that ran fine if the flag for compressing the map output data to false.
However, if the flag is set to true and the compression type set to block, then 
the reducers all died due to out of memory exceptions.
The heap size was set to 512M.
The problem persists even when the heapsize set to 1000M.
"
MAPREDUCE-98,NullPointerException when retrieving task reports,"It appears as thought Counters is null for a given task which causes an NPE in the logs (and clients to hang)
"
MAPREDUCE-97,Increase map/reduce child tasks' heapsize from current default of 200M to 512M,"I guess we should look to check why we get OOMs with 200M, I'd suspect io.sort.mb hogs a lot of the default 200M. However, HADOOP-1867 should be the right way to solve it. 

For now, I propose we bump up the child-vm default heapsize to 512M; too many people are getting burnt by 200M."
MAPREDUCE-96,mapper failed due to exceptions,"

From time to time, I observed that mapper tasks failed due to the following exception:
../logs/userlogs/task_200711032036_0145_m_000000_0/stdout (No such file or directory)
	at java.io.FileOutputStream.openAppend(Native Method)
	at java.io.FileOutputStream.(FileOutputStream.java:177)
	at org.apache.hadoop.mapred.TaskRunner.copyStream(TaskRunner.java:400)
	at org.apache.hadoop.mapred.TaskRunner.runChild(TaskRunner.java:432)
	at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:292)

The re-run of the task succeeded. The machine where the task failed seemed to be normal.


"
MAPREDUCE-95,"In PipeMarRed.java, log related fields seems useless","In PipeMapRed.java, the fields log_ & LOGNAME seems useless since they remain null throughout. It might cause issues at PipeMapRed.java:[line 352]. Also, the field mapRedKey_ in the same file is always null and might cause issues if the getContext() method is ever invoked (it is never invoked in the current code). 
We possibly can remove references to these fields."
MAPREDUCE-94,Speculative execution does not work properly,"

One mapper of my job stuck when it reached 87.7%.
Speculative execution was set to true.
But no speculative execution was fired for that task.
The whole job was stalled.

"
MAPREDUCE-92,Reduce task stuck at 95.71% for a long time and the speculative execution does not kick in,"

I have a job with speculative execution set on.
However, its last reduce task has been stuck for a long time at 95.71%, and no speculative execution was started.
I did see speculative executions for other tasks started and killed though.
"
MAPREDUCE-91,task attempt failing to report status just after the intialization,"In sort500 runs, I noticed task attempts failing to report status : saying
Task attempt_200807220707_0002_r_000336_1 failed to report status for 605 seconds. Killing!

And the task logs has NullPointerException saying:
*stderr logs*
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2146)

Task tracker logs for the same attempt are:
2008-07-22 08:07:37,110 INFO org.apache.hadoop.mapred.TaskTracker: LaunchTaskAction: attempt_200807220707_0002_r_000336_1
2008-07-22 08:17:42,144 INFO org.apache.hadoop.mapred.TaskTracker: attempt_200807220707_0002_r_000336_1: Task attempt_200807220707_0002_r_000336_1 failed toreport status for 605 seconds. Killing!
2008-07-22 08:17:42,162 INFO org.apache.hadoop.mapred.TaskTracker: About to purge task: attempt_200807220707_0002_r_000336_1
2008-07-22 08:17:42,163 INFO org.apache.hadoop.mapred.TaskRunner: attempt_200807220707_0002_r_000336_1 done; removing files.
2008-07-22 08:18:15,481 WARN org.apache.hadoop.mapred.TaskTracker: Unknown child task finshed: attempt_200807220707_0002_r_000336_1. Ignored.
"
MAPREDUCE-90,incrementing counters should not be used for triggering record skipping,"The following code is really problematic:

{code}
public void incrCounter(String group, String counter, long amount) {
  if (counters != null) {
    counters.incrCounter(group, counter, amount);
  }
  if(skipping && SkipBadRecords.COUNTER_GROUP.equals(group) && (
     SkipBadRecords.COUNTER_MAP_PROCESSED_RECORDS.equals(counter) ||
     SkipBadRecords.COUNTER_REDUCE_PROCESSED_GROUPS.equals(counter))) {
     //if application reports the processed records, move the 
     //currentRecStartIndex to the next.
     //currentRecStartIndex is the start index which has not yet been 
     //finished and is still in task's stomach.
     for(int i=0;i<amount;i++) {
        currentRecStartIndex = currentRecIndexIterator.next();
     }
   ...
}
{code}

In particular, if the user updates a counter with the wrong name, bad things will presumably happen..."
MAPREDUCE-89,Distinguish between killed and failed jobs on jobtracker.jsp,
MAPREDUCE-88,Illegal state exception in printTaskLog -> sendError,"This error shows up in my logs:

2007-08-23 16:40:08,028 WARN /: /tasklog?taskid=task_200708212126_0043_m_000100_0&all=true: 
java.lang.IllegalStateException: Committed
        at org.mortbay.jetty.servlet.ServletHttpResponse.resetBuffer(ServletHttpResponse.java:212)
        at org.mortbay.jetty.servlet.ServletHttpResponse.sendError(ServletHttpResponse.java:375)
        at org.apache.hadoop.mapred.TaskLogServlet.printTaskLog(TaskLogServlet.java:61)
        at org.apache.hadoop.mapred.TaskLogServlet.doGet(TaskLogServlet.java:125)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
"
MAPREDUCE-87,exporting pid doesn't work if the user's shell is not bash,"HADOOP-5488 added exporting of pid using  ""export JVM_PID=`echo $$` ""  for saving pid of task JVM. This exporting of pid wouldn't work if the user's shell is not bash when running the MR job."
MAPREDUCE-86,Custom FileSystem class not found during child process initialization,"If a custom FileSystem class is used for Reducer output, initialization of the child task fails with an uncaught ClassNotFoundException. Trace follows.

java.lang.RuntimeException: java.lang.ClassNotFoundException: cascading.tap.hadoop.S3HttpFileSystem
java.io.IOException: java.lang.RuntimeException: java.lang.ClassNotFoundException: cascading.tap.hadoop.S3HttpFileSystem
       at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:607)
       at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:161)
       at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
       at org.apache.hadoop.mapred.Task.getTaskOutputPath(Task.java:195)
       at org.apache.hadoop.mapred.Task.setConf(Task.java:400)
       at org.apache.hadoop.mapred.TaskInProgress.getTaskToRun(TaskInProgress.java:733)
       at org.apache.hadoop.mapred.JobInProgress.obtainNewMapTask(JobInProgress.java:568)
       at org.apache.hadoop.mapred.JobTracker.getNewTaskForTaskTracker(JobTracker.java:1409)
       at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:1191)
       at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)

Task.getTaskOutputPath only attempts to force the path into a fully qualified reference. It already handles thrown IOE, and should possibly just catch Exception, or atleast explicitly catch the CNFE. On a catch, can continue to return the original Path instance passed. 

{code:title=Bar.java|borderStyle=solid}
  private Path getTaskOutputPath(JobConf conf) {
    Path p = new Path(conf.getOutputPath(), (""_"" + taskId));
    try {
      FileSystem fs = p.getFileSystem(conf);
      return p.makeQualified(fs);
    } catch (IOException ie) {  // SHOULD BE BROADENED?
      LOG.warn(StringUtils.stringifyException(ie));
      return p;
    }
  }
{code}"
MAPREDUCE-85,Setting lastProgressReport time in TIP's constructor causes TT to wrongly kill tasks.,
MAPREDUCE-84,JobClient waitForCompletion() method sometimes throws an NPE,"java.lang.NullPointerException
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.isComplete(JobClient.java:113)
        at org.apache.hadoop.mapred.JobClient$NetworkedJob.waitForCompletion(JobClient.java:128)

Does someone have an idea why this happens ?
Thanks for any help."
MAPREDUCE-83,Job completion delayed,"A job with all reduces completed but with some incomplete re-executed maps is not declared complete till all tasks are complete.
Couldn't the incomplete maps just be killed off?
Even if maps write to dfs directly, these incomplete maps must have been successful before, so there should be no reason to wait for them."
MAPREDUCE-82,Revert the temporary change made to collection of Job's metrics done by HADOOP-3521,"HADOOP-3521 is a temporary fix, it needs to be reverted."
MAPREDUCE-81,missing userlogs,"I noticed that a long-running job taking more than 1 day can have reduce tasks with missing stderr and stdout log directories (the syslog files exist).

I wonder whether it has to do with the default value of 12 hours for mapred.userlog.retain.hours, resulting in deletion of the stderr/stdout directories for reduce tasks idling till they start to actually reduce. "
MAPREDUCE-80,Counter formatting for the user logs should be pulled out of the public Counters API,Currently the mapred.Counters class includes an obsolete format (makeCompactString) and a format that is only used by the user logs (makeEscapeCompactString). makeCompactString should be deprecated and later removed.The makeEscapeCompactString should be refactored to a non-public class.
MAPREDUCE-78,tasks should not run on nodes where they were previously lost,We had a case where a task tracker was getting lost every 15 minutes and the same reduce kept getting scheduled on it (15 times). Tasks that are killed should not reschedule on the node where they were previously killed.
MAPREDUCE-77,JobConf is deprecated but Job does not support a constructor for Configuration,JobConf has been deprecated but Job does not support any constructor for Configuration which is replacing JobConf.
MAPREDUCE-76,JobControl should handle exceptions,"If the JobControl encounters non IOExceptions, then JobControl fails without reporting failures. JobControl should handle all exceptions and report the failure to launch jobs. In addition, an API to support the querying of failure to launch jobs should be supported."
MAPREDUCE-75,Job history log does not output final counters if job is failed or killed,The last log entry in job history contains important counters. This information is missing if the job is killed or failed.
MAPREDUCE-74,JobClient hangs when getting map-task reports,"a call to JobClient.getMapTaskReports() has been hung for 6+ days
"
MAPREDUCE-73,Deadlock in JobTracker initJobs,"Found one Java-level deadlock:
=============================
""SocketListener0-26"":
  waiting to lock monitor 0x08ed5ce4 (object 0x567924c0, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 1 on 9001""
""IPC Server handler 1 on 9001"":
  waiting to lock monitor 0x08f7da88 (object 0x5744f5b8, a org.apache.hadoop.mapred.JobInProgress),
  which is held by ""initJobs""
""initJobs"":
  waiting to lock monitor 0x08ed5ce4 (object 0x567924c0, a org.apache.hadoop.mapred.JobTracker),
  which is held by ""IPC Server handler 1 on 9001""

Java stack information for the threads listed above:
===================================================
""SocketListener0-26"":
        at org.apache.hadoop.mapred.JobTracker.getClusterStatus(JobTracker.java:2313)
        - waiting to lock <0x567924c0> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.jobtracker_jsp._jspService(jobtracker_jsp.java:104)
        at org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:94)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
""IPC Server handler 1 on 9001"":
        at org.apache.hadoop.mapred.JobInProgress.obtainTaskCleanupTask(JobInProgress.java:935)
        - waiting to lock <0x5744f5b8> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.JobTracker.getSetupAndCleanupTasks(JobTracker.java:2167)
        - locked <0x56795708> (a java.util.TreeMap)
        - locked <0x567924c0> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobTracker.heartbeat(JobTracker.java:1902)
        - locked <0x567924c0> (a org.apache.hadoop.mapred.JobTracker)
        at sun.reflect.GeneratedMethodAccessor3278.invoke(Unknown Source)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:481)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:894)
""initJobs"":
        at org.apache.hadoop.mapred.JobTracker.finalizeJob(JobTracker.java:1539)
        - waiting to lock <0x567924c0> (a org.apache.hadoop.mapred.JobTracker)
        at org.apache.hadoop.mapred.JobInProgress.garbageCollect(JobInProgress.java:2320)
        - locked <0x5744f5b8> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.JobInProgress.terminateJob(JobInProgress.java:2004)
        - locked <0x5744f5b8> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.JobInProgress.initTasks(JobInProgress.java:472)
        - locked <0x575b7ec8> (a org.apache.hadoop.mapred.JobInProgress$JobInitKillStatus)
        - locked <0x5744f5b8> (a org.apache.hadoop.mapred.JobInProgress)
        at org.apache.hadoop.mapred.EagerTaskInitializationListener$JobInitThread.run(EagerTaskInitializationListener.java:55)

Found 1 deadlock."
MAPREDUCE-72,Move handling of Task debugging out of TaskTracker,"Currently {{TaskTracker.TaskInProgress.taskFinished}} handles the responsibility of executing the debug scripts for Map/Reduce tasks. Ideally we should keep this confined to TaskRunner (which currently executes the actual tasks) or a separate pre/post processing classes.

The current situation leads to bugs like HADOOP-3696."
MAPREDUCE-71,JobClient can be constructed without initializing object state,The JobClient class has a no-arg constructor that does nothing.  This leaves critical object state uninitialized.
MAPREDUCE-70,Unify  the way job history filename is parsed,"Job history filename has the following meta-info :
- jobtracker's hostname
- job id
- username
- jobname

{{HistoryViewer.java}} and {{jobhistory.jsp}} are required to parse the history filename to extract the meta-info. It makes more sense to provide a common utility in {{JobHistory}} to do it."
MAPREDUCE-69,NPE in TaskTracker RenitTrackerAction ,"TaskTracker log shows =============

2007-03-28 02:32:18,076 INFO org.apache.hadoop.mapred.TaskTracker: Recieved RenitTrackerAction from JobTracker
2007-03-28 02:32:18,494 ERROR org.apache.hadoop.mapred.TaskTracker: Can not start task tracker because java.lang.NullPointerException
  at org.apache.hadoop.mapred.TaskTracker$TaskInProgress.jobHasFinished(TaskTracker.java:1187)
  at org.apache.hadoop.mapred.TaskTracker.close(TaskTracker.java:430)
  at org.apache.hadoop.mapred.TaskTracker.run(TaskTracker.java:917)
  at org.apache.hadoop.mapred.TaskTracker.main(TaskTracker.java:1589)

JobTracker log shows ==============
2007-03-28 02:31:18,977 INFO org.apache.hadoop.mapred.JobTracker: Lost tracker '____.____.com'
...
2007-03-28 02:31:18,977 INFO org.apache.hadoop.mapred.JobInProgress: TaskTracker at 'tracker____.___.com' turned 'flaky'
...
2007-03-28 02:32:18,075 WARN org.apache.hadoop.mapred.JobTracker: Status from unknown Tracker : tracker____.___.com:#####
"
MAPREDUCE-68,Hadoop reduce scheduler sometimes leaves machines idle,"I have a MapReduce application with number of reducers equal to the number of machines in the cluster (and with speculative execution turned off). However, Hadoop schedules multiple reduces to run on single machines and leaves other machines idle. This causes contention and seriously slows down the job. Hadoop should employ the simple heuristic of utilizing as many machines as possible when scheduling reduces."
MAPREDUCE-67,"Few tasks failed while creating the work directory for a job, when job tracker was restarted","A randomwriter job was running when the job tracker restarted. After the jobtracker restarted, some tasktrackers were sent a reinit action. After this, some new tasks of the random writer were scheduled to be run on the same task trackers. These failed in the job localization while creating the work directory. However, the next attempts of the same job ran successfully and the job succeeded. This happened in about 1% of the total number of tasks."
MAPREDUCE-66,The local bytes read of Mapper tasks are too high than bytes written,"
The local bytes read are 6 times that of local bytes written.
This is very hard to explain.

Here is the relevant counters:

Counters for tip_200810170704_0044_m_000001

File Systems
	Local bytes read 	6,684,486,486
	Local bytes written 	1,007,113,506
	HDFS bytes read 	147,200,700

Map-Reduce Framework
	Map input records 	3,588,883
	Map output records 	3,588,883
	Map input bytes 	147,200,579
	Map output bytes 	464,822,403
	Combine input records 	0
	Combine output records 	0"
MAPREDUCE-65,TaskTrackers never (re)connect back to the JobTracker if the JobTracker node/machine is changed,"I tried the following 
1) Started a hadoop cluster.
2) Killed the JT
3) Selected a new node for starting JT. 
4) Changed the entry on the tasktracker to reflect the new (old) hostname to (new) ip mapping. Checked if the tracker node correctly resolves the hostname to the new ip.
5) Start the JT on the new node
The tasktracker fails to connect to the new jobtracker. It seems that the hostname resolution remains stale and is never updated.
"
MAPREDUCE-64,Map-side sort is hampered by io.sort.record.percent,"Currently io.sort.record.percent is a fairly obscure, per-job configurable, expert-level parameter which controls how much accounting space is available for records in the map-side sort buffer (io.sort.mb). Typically values for io.sort.mb (100) and io.sort.record.percent (0.05) imply that we can store ~350,000 records in the buffer before necessitating a sort/combine/spill.

However for many applications which deal with small records e.g. the world-famous wordcount and it's family this implies we can only use 5-10% of io.sort.mb i.e. (5-10M) before we spill inspite of having _much_ more memory available in the sort-buffer. The word-count for e.g. results in ~12 spills (given hdfs block size of 64M). The presence of a combiner exacerbates the problem by piling serialization/deserialization of records too...

Sure, jobs can configure io.sort.record.percent, but it's tedious and obscure; we really can do better by getting the framework to automagically pick it by using all available memory (upto io.sort.mb) for either the data or accounting."
MAPREDUCE-62,job.xml should have high replication factor by default,"job.xml is set the default replication factor of 3 by the JobClient. The same config file is accessed from the DFS by JT as well as all the TTs. Hence it should be set a high replication factor say 10, just like the job.jar."
MAPREDUCE-61,Counters value of  reduce input records do not match map output records,"Counters value of  reduce input records do not match map output records under certain circumstances. 
somehow reproducable"
MAPREDUCE-60,Nested class TaskTracker.TaskInProgress needs additional synchronization,"The nested class TaskTracker.TaskInProgress needs additional synchronization to work properly with the Java Memory Model.  Presumably this class is accessed by more than one thread, because it already contains synchronization.  However, it needs additional synchronization, especially to protect access to the long fields lastProgressReport and taskTimeOut.  Long fields are not guaranteed to be read/written atomically, so not only do you risk reading stale values, but you risk reading corrupted values.

The field wasKilled also needs synchronization, as it is polled from within the TaskTracker class.  

I suggest the following improvements to the class
- Make the fields task and taskStatus final.  They are used this way already.  Making them final clarifies there behavior in a current environment.
- Add the synchronized modifier to the methods getLastProgressReport() and getTaskTimeout().
- Make the field wasKilled private and add a new public synchronized wasKilled() getter method.  Replace the use of the field with this method in TaskTracker.
- Add a comment to localizeTask() indicating that the caller must be synchronized on this.
"
MAPREDUCE-59,'job -kill' from command line should inform if the job doesn't exist,"Killing an invalid job from command line succeeds with a message stating ""job killed"". "
MAPREDUCE-58,Duplicate metric name getTask,"I've been seeing the following error in some tasks:

{noformat}
org.apache.hadoop.ipc.RemoteException: java.io.IOException: java.lang.IllegalArgumentException: Duplicate metricsName:getTask
        at org.apache.hadoop.metrics.util.MetricsRegistry.add(MetricsRegistry.java:56)
        at org.apache.hadoop.metrics.util.MetricsTimeVaryingRate.<init>(MetricsTimeVaryingRate.java:89)
        at org.apache.hadoop.metrics.util.MetricsTimeVaryingRate.<init>(MetricsTimeVaryingRate.java:99)
        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:522)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:959)
        at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:955)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:396)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:953)
        at org.apache.hadoop.ipc.Client.call(Client.java:736)
        at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
        at $Proxy0.getTask(Unknown Source)
        at org.apache.hadoop.mapred.Child.main(Child.java:109)
{noformat}
"
MAPREDUCE-57,The JobConf instance passed to JobClient is unnecessarily modified,"The JobConf instance passed to the JobClient.submitJob method is modified by that method.  This side effect is surprising.  IMHO, the passed in JobConf should either be defensively copied or the side effect should be documented.

Trying to reuse a JobConf instance in multiple calls to JobClient.submitJob causes the following exception:

java.io.IOException: /dfstmp/mapred/system/submit_r7mxti/job.jar: No such file or directory
        at org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:80)
        at org.apache.hadoop.dfs.DistributedFileSystem.copyFromLocalFile(DistributedFileSystem.java:188)
        at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:291)
        at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:368)
        at org.apache.hadoop.examples.NNBench.main(NNBench.java:274)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:143)
        at org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:41)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:149)
"
MAPREDUCE-56,Client recovery from Job tracker restarts and connectivity failures,"This Jira addresses the client side recovery from Jobtracker restarts, fail overs and network connectivity issues. This does not address Jobtracker high availability and tracks only the client side recovery.
"
MAPREDUCE-55,Reduce task should stop shuffle-retrying in case of out-of-memory errors,"In ReduceTask, MapOutputCopier threads catch Throwble and retry happens for the shuffle. It should not retry incase of Errors suchas OutOfMemoryError etc.

May be it should retry only in case of Connect/Read failures and die in all other cases. Thoughts?"
MAPREDUCE-54,distcp failed due to problem in creating files,"When I run a distcp program to copy files from one dfs to another, my job failed with
the mappers throwing the following exception:

org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.AlreadyBeingCreatedException: failed to create file /xxxxx/part-00007 for DFSClient_task_200710122302_0002_m_000456_2 on client 72.30.43.23 because current leaseholder is trying to recreate file.
	at org.apache.hadoop.dfs.FSNamesystem.startFileInternal(FSNamesystem.java:850)
	at org.apache.hadoop.dfs.FSNamesystem.startFile(FSNamesystem.java:806)
	at org.apache.hadoop.dfs.NameNode.create(NameNode.java:333)
	at sun.reflect.GeneratedMethodAccessor13.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:379)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:596)

	at org.apache.hadoop.ipc.Client.call(Client.java:482)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)
	at org.apache.hadoop.dfs.$Proxy1.create(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at org.apache.hadoop.dfs.$Proxy1.create(Unknown Source)
	at org.apache.hadoop.dfs.DFSClient$DFSOutputStream.(DFSClient.java:1432)
	at org.apache.hadoop.dfs.DFSClient.create(DFSClient.java:376)
	at org.apache.hadoop.dfs.DistributedFileSystem.create(DistributedFileSystem.java:121)
	at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.copy(CopyFiles.java:284)
	at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.map(CopyFiles.java:352)
	at org.apache.hadoop.util.CopyFiles$FSCopyFilesMapper.map(CopyFiles.java:217)
	at org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:50)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:195)
	at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:1750)


It seems that this problem happened  in the 2nd, 3rd, 4th attempts,
after the first attemp failed.
"
MAPREDUCE-53,JUnit tests should not create directories in the current directory,"PiEstimator.java, TestMapRed.java, and TestRecordMR.java create test directories in the current directory. I think that a better place is directory ""./build/test""."
MAPREDUCE-51,TestTaskLimits fails occassionally,"When I run TestTaskLimits locally, it fails sometimes with a timeout. This is with trunk."
MAPREDUCE-49,JobTracker UI shows Incorrect reporter progress.,"Hadoop UI is showing a Job in completed box where the reducer progress percentage is 99.97 % .  
The job have no exceptions and was successfully completed.

"
MAPREDUCE-48,Expired launching tasks affect small jobs' execution time,"Currently when a task is given to a TT, the JT doesn't mark the task as running till the TT responds back to the JT. And within 10 mins(hard-coded), if the task doesn't come back, then only the task gets relaunched. For small jobs, this is a lot of time.
"
MAPREDUCE-47,Tasklog servlet doesn't display any logs when logs are short,"After running a job that died after only writing a little bit of logs, the tasklog servlet shows an empty log.  In the log directory, however, there are non-empty stderr and stdout logs:

$ ls -la
total 92
drwxrwsr-x  2 mapreduce mapreduce  4096 Mar 19 16:24 .
drwxrwsr-x 95 mapreduce mapreduce 69632 Mar 19 16:24 ..
-rw-r--r--  1 mapreduce mapreduce    78 Mar 19 16:24 log.index
-rw-rw-r--  1 mapreduce mapreduce   350 Mar 19 16:24 stderr
-rw-rw-r--  1 mapreduce mapreduce  4413 Mar 19 16:24 stdout
$ cat log.index 
LOG_DIR:attempt_200902160142_0040_m_000000_3
stdout:0 0
stderr:0 0
syslog:0 0
"
MAPREDUCE-46,mapred/local/jobTracker is not cleanup correctly,"Jobtracker store 1.jar file and 1 .xml per job in /srv/hadoop/var/mapred/local/jobTracker.

They seems to be correctly delete in most cases BUT not when a job is launch with 
Map total: 0 and Reduce total: 0
This happen when the job doesn't find any input file to process.

After few months, lots of disk space is lost because of that.

This issue is different from HADOOP-2427 since it's on the jobtracker, not on the nodes, but it may be related in some way in the code (my 2 cents)."
MAPREDUCE-45,JobStatus should contain user name and carry forward start time when job is killed.,"If an initialized job is killed, the jobs start time is set to zero. Job status don't seem to have user name set properly."
MAPREDUCE-44,"Hang JobTracker, running out of memory","This may be expected.

Hang JobTracker with 1G heapsize, top showed 99% cpu. 

Ran about 80 jobs.  Each with 2500 mappers 200 reducers.  They finish quite fast.  3-4 mins avg per job.
(200k tasks)


How much memory does JobTracker use for 'completed'  (but not expired) jobs ?

jmap -heap showed 
{noformat} 
...
PS Old Generation
   capacity = 932118528 (888.9375MB)
   used     = 932118528 (888.9375MB)
...
{noformat} 

jmap -histo showed 
{noformat} 
num   #instances    #bytes  class name
--------------------------------------
  1:   3974182   355869992  [C
  2:   5216606   125198544  java.lang.String
  3:   2238560   107450880  java.util.TreeMap
  4:    463206   101673488  [B
  5:   1979995    63359840  java.util.TreeMap$Entry
  6:    248400    35769600  org.apache.hadoop.mapred.TaskInProgress
  7:    308803    30898112  [Ljava.lang.Object;
  8:    978240    23477760  org.apache.hadoop.mapred.Counters$CounterRec
  9:    249876    19990080  org.apache.hadoop.mapred.TaskStatus
 10:    248836    19906880  java.net.URI
 11:    230337    16584264  org.apache.hadoop.mapred.MapTask
...
{noformat} 

Log showing many heartbeat discarded messages
{noformat} 
2007-10-30 22:55:46,912 WARN org.apache.hadoop.ipc.Server: IPC Server handler 6 on 58567, call heartbeat(org.apache.hadoop.mapred.TaskTrackerStatus@1afb9c9, false, true, 3942) from 99.99.99.99:9999 discarded for being too old (2578616)
{noformat} 

Is the solution either to increase the jobtracker heapsize or set shorter 'mapred.userlog.retain.hours'  ?


"
MAPREDUCE-43,Retired jobs are not present in the job list returned to the job-client.,"After {{mapred.jobtracker.retirejob.interval}} elapses, completed jobs are no longer maintained by the JT, but instead when job-client ask for job status, counters or task completion events, the relevant information is picked up from completed job store. But a retired job is not listed in the output of ""{{hadoop job -list all}}"", without which other information from completed job store isn't quite useful unless a job-id is known from elsewhere."
MAPREDUCE-42,task trackers should not restart for having a late heartbeat,TaskTrackers should not close and restart themselves for having a late heartbeat. The JobTracker should just accept their current status.
MAPREDUCE-41,Write unit tests to verify  the fix for HADOOP-5349,
MAPREDUCE-40,Memory management variables need a backwards compatibility option after HADOOP-5881,HADOOP-5881 modified variables related to memory management without looking at the backwards compatibility angle. This JIRA is to adress the gap. Marking it a blocker for 0.20.1
MAPREDUCE-39,Task tracker should wait for the process to exit before declaring the task successful or failed.,"Currently when a task declares it is done, the status in the task tracker is changed immediately. Instead it should wait for the subprocess to actually be done before it moves to one of the final states. This lead to a race condition where the task was still generating log data after the job tracker had reported the task as done."
MAPREDUCE-38,TaskCompletionEvents do not distinguish between FAILED and KILLED task-attempts,"It is very disconcerting to see {{KILLED}} task-attempts (e.g. speculative tasks) on the user-console showing up as {{FAILED}}, it would be nice to ignore them and only print the {{FAILED}} ones (and add a filter for {{KILLED}} if need be...)"
MAPREDUCE-37,MAP_OUTPUT_BYTES counter is not recorded in Job history log for Map only jobs,"Here is an example Map task entry in job history log, it has MAP_OUTPUT_RECORDS but no MAP_OUTPUT_BYTES

Task TASKID=""task_200905250540_0578_m_000000"" TASK_TYPE=""MAP"" TASK_STATUS=""SUCCESS"" FINISH_TIME=""1243294056346"" COUNTERS=""{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(56630)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(28327)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2681)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_INPUT_BYTES)(Map input bytes)(28327)][(MAP_OUTPUT_RECORDS)(Map output records)(2681)]}"" .
MapAttempt TASK_TYPE=""MAP"" TASKID=""task_200905250540_0578_m_000001"" TASK_ATTEMPT_ID=""attempt_200905250540_0578_m_000001_0"" START
_TIME=""1243294026959"" TRACKER_NAME=""tracker_xxx1031\.xxxx\.com:localhost/127\.0\.0\.1:56939"" HTTP_PORT=""50060"" .
MapAttempt TASK_TYPE=""MAP"" TASKID=""task_200905250540_0578_m_000001"" TASK_ATTEMPT_ID=""attempt_200905250540_0578_m_000001_0"" TASK_STATUS=""SUCCESS"" FINISH_TIME=""1243294041638"" HOSTNAME=""/xx\.xx\.xx\.xxx/xxx1031\.xxxx\.com"" STATE_STRING=""Records R/W\=2634/1"" COUNTERS=""{(FileSystemCounters)(FileSystemCounters)[(HDFS_BYTES_READ)(HDFS_BYTES_READ)(28316)][(HDFS_BYTES_WRITTEN)(HDFS_BYTES_WRITTEN)(28303)]}{(org\.apache\.hadoop\.mapred\.Task$Counter)(Map-Reduce Framework)[(MAP_INPUT_RECORDS)(Map input records)(2634)][(SPILLED_RECORDS)(Spilled Records)(0)][(MAP_INPUT_BYTES)(Map input bytes)(28303)][(MAP_OUTPUT_RECORDS)(Map output records)(2634)]}"" .
"
MAPREDUCE-36,LInks in http://jobtracker/machines.jsp are broken while running hadoop locally,"While running hadoop locally, the tasktracker information on machines.jsp is represented as http://localhost.localdomain:50060 which doesn't work. It should be http://localhost:50060. "
MAPREDUCE-35,There can be more than 'mapred.jobtracker.completeuserjobs.maximum' jobs for a user in the jobtracker,The check for max-completed-jobs-per-user is made in finalize job and hence there can be a case where the user finishes more than 'mapred.jobtracker.completeuserjobs.maximum' jobs within  JobTracker.MIN_TIME_BEFORE_RETIRE units of time and doesnt submit any job after that which can cause more number of jobs to be in memory than allowed. There is no check made for this limit anywhere else.
MAPREDUCE-34,Reduce step hangs while recovering a block from bad datanode,The reduce step hangs infinitely when its trying to recover a block from a bad datanode. The node from which the block is being retrieved is alive and TT and DN are up and running.
MAPREDUCE-33,Avoid using deprecated api's,There are code paths in {{mapred}} that use deprecated apis.
MAPREDUCE-32,Killed task is logged as Failed upon a lost tracker,"Upon a lost tracker, the successful attempt is killed but the tip is marked as failed. "
MAPREDUCE-31,Have a better shutdown and cleanup mechanism in JobTracker,"The {{main()}} of JobTracker waits for {{offerSerice()}} to complete. {{offerService()}} does a {{Thread.join()}} on {{interTrackerServer}}. 
{{JobTracker.close()}} stops {{interTrackerServer}} pretty early and hence there is a fair chance of JobTracker exiting before other threads are stopped _properly_.  "
MAPREDUCE-30,setting io.sort.factor does not have effect?,"I have a m/r job with 84000 mappers.
I set io.sort.factor to 200.

The reducers still generates 800+ merged files, not  400+ I expected."
MAPREDUCE-29,JVM reuse across task types,"Currently, JVM-reuse is across tasks of same type of the same job, i.e. JVMs are kind of marked as map-JVMs and reduce JVMs. May be we can reuse JVMs across tasks of different types but of the same job."
MAPREDUCE-28,TestQueueManager takes too long and times out some times,"TestQueueManager takes long time for the run and timeouts sometimes.
See the failure at http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3875/testReport/.
Looking at the console output, before the test finsihes, it was timed-out.
On my machine, the test takes about 5 minutes.

"
MAPREDUCE-27,Jobs with 0 maps will never get removed from the default scheduler,Jobs' with 0 maps finish/succeed in the init phase i.e while the job is in the _PREP_ state. {{EagerTaskInitializationListener}} removes the job after initing but {{JobQueueJobInProgressListener}} waits for a job-state change event to be raised and aonly then removes the job from the queue and hence the job will stay forever with the {{JobQueueJobInProgressListener}}. Looks like {{FairScheduler}} periodically scans the job list and removes completed jobs. {{CapacityScheduler}} has a concept of waiting jobs and scans waiting queue for completed jobs and purges them.
MAPREDUCE-26,The shuffle keeps the ReduceTask locked while doing a FileSystem.rename leading to task timeouts,"The shuffle in ReduceTask.ReduceCopier.MapOutputCopier.copyOutput locks the entire ReduceTask while doing a FileSystem.rename operation. Unfortunately the RawLocalFileSystem implements rename as a copy and delete, which can take a long time. As a result the reduce is being killed as not reporting progress for 10 minutes."
MAPREDUCE-25,Non-speculative and speculative tasks for a TIP start at the same time.,I ran into a situation where the non-speculative task and the speculative task were started at the same time. Ideally there should be a 1 min gap for speculation. One possible reason would be the usage of {{startTime}} in deciding whether there is a speculative lag.
MAPREDUCE-24,Reduce stuck in pending state for ever even though the job tracker shows a lot of free slots,"
A job with 38 mappers and 38 reducers running on a cluster with 36 slots.
All mapper tasks completed. 17 reducer tasks completed. 11 reducers are still in the running state
and one is in the oending state and stay there forever.

"
MAPREDUCE-23,Start times for some tasks are missing from task reports after job tracker restart,"When a JobTracker with the {{mapred.jobtracker.restart.recover}} option turned on, restarts, it recovers task statuses from all tasks recorded in the history for running jobs. Task trackers rejoin the restarted JobTracker and report the statuses of the tasks they had last run. These tasks' start time is set to 0 in the task reports on the restarted JobTracker. This is as seen in the web UI, or from the value of {{TaskReport.startTime}} retrieved from the job client."
MAPREDUCE-22,Per task memory usage stats from TaskMemoryManager on mapred web ui,It would be good to have per-task memory usage statistics from the TaskMemoryManager displayed on the web ui  as the task progresses on. This would make it easy for users to (roughly) track their tasks' memory usage.
MAPREDUCE-21,NegativeArraySizeException in reducer with new api,"I observed one of the reducers failing with NegativeArraySizeException with new api.
The exception trace:

java.lang.NegativeArraySizeException
	at org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:119)
	at org.apache.hadoop.io.BytesWritable.setSize(BytesWritable.java:98)
	at org.apache.hadoop.io.BytesWritable.readFields(BytesWritable.java:153)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:67)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:40)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKeyValue(ReduceContext.java:142)
	at org.apache.hadoop.mapreduce.ReduceContext.nextKey(ReduceContext.java:121)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:189)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:542)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:409)
	at org.apache.hadoop.mapred.Child.main(Child.java:159)

The corresponding line in ReduceContext is 
{code}
line#142    key = keyDeserializer.deserialize(key);
{code}"
MAPREDUCE-20,"If a mapper of a map/reduce job with combiner has to spill the map output, the performance degrades significantly","I have a map/reduce job whose reducers combine a group of values into a single value.
The average reduction rate is about 3 to 1. The execution time for the job with the reducer as its combiner , 
is twice of that for the case without using combiner. This is completely counter-intuitive.
When I looked at the job execution more carefully, I noticed that this longer execution time for the 
job was mainly due to a few mappers that generated spills. The final merge of the spills seems 
took a much longer time with combiner than without combiner. 


"
MAPREDUCE-19,TaskMemoryMonitorThread is not stopped in close,"The task memory monitor thread is created in initialize, but is not stopped in close. So, if there's a reinit, this can result in a thread becoming a zombie as the thread variable is replaced in initialize."
MAPREDUCE-18,Under load the shuffle sometimes gets incorrect data,"While testing HADOOP-5223 under load, we found reduces receiving completely incorrect data. It was often random, but sometimes was the output of the wrong map for the wrong map. It appears to either be a Jetty or JVM bug, but it is clearly happening on the server side. In the HADOOP-5223 code, I added information about the map and reduce that were included and we should add similar protection to 0.20 and trunk."
MAPREDUCE-17,Changing priority of a completed job causes problems in JobInProgressListeners,"If the priority of a completed job is changed, a {{JobChangeEvent}} is raised and the {{JobInProgressListeneners}}, like the capacity scheduler, are notified. Most implementations handle the event by re-sorting their data structures, and thus could end up re-inserting the completed job into their lists."
MAPREDUCE-16,"Reduce task failed at shuffling time, throwing null pointer exception","

This happened for 0.17.0 branch.

Here is the stack trace:

2008-04-11 13:45:54,171 ERROR org.apache.hadoop.mapred.ReduceTask: Map output copy failure: java.lang.NullPointerException
	at org.apache.hadoop.fs.InMemoryFileSystem$RawInMemoryFileSystem.getFileStatus(InMemoryFileSystem.java:302)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:242)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.copyOutput(ReduceTask.java:853)
	at org.apache.hadoop.mapred.ReduceTask$ReduceCopier$MapOutputCopier.run(ReduceTask.java:777)
"
MAPREDUCE-14,extensive map tasks failures because of SocketTimeoutException during statusUpdate,"A job with 3600 tasks on a cluster of 1350 nodes (up 3 tasks per node) shows extensive map tasks failures because of connection timeouts at the end of the task (c++ application using pipes interface completed successfully)
More than 600 tasks failed, slowing down the job because of retries. Only a portion of the tasks fail because of the timeout issue, but they spawn other failures because retries and speculatively executed tasks cannot even get  a connection and fail just after a few seconds.

JobTracker is running with 60 handlers. We allow up to 10 attempts for maps.

I attach the log of a task failing because of timeout (which includes a thread dump), and the log of one task which could not start.

2007-10-18 15:58:41,743 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=MAP, sessionId=
2007-10-18 15:58:41,827 INFO org.apache.hadoop.mapred.MapTask: numReduceTasks: 3600
2007-10-18 16:12:28,918 INFO org.apache.hadoop.util.NativeCodeLoader: Loaded the native-hadoop library
2007-10-18 16:12:28,920 INFO org.apache.hadoop.io.compress.zlib.ZlibFactory: Successfully loaded & initialized native-zlib library
2007-10-18 17:43:00,785 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response
	at org.apache.hadoop.ipc.Client.call(Client.java:484)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)
	at org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)
	at org.apache.hadoop.mapred.Task$1.run(Task.java:293)
	at java.lang.Thread.run(Thread.java:619)

2007-10-18 17:44:03,833 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response
	at org.apache.hadoop.ipc.Client.call(Client.java:484)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)
	at org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)
	at org.apache.hadoop.mapred.Task$1.run(Task.java:293)
	at java.lang.Thread.run(Thread.java:619)

2007-10-18 17:45:06,838 INFO org.apache.hadoop.mapred.TaskRunner: Communication exception: java.net.SocketTimeoutException: timed out waiting for rpc response
	at org.apache.hadoop.ipc.Client.call(Client.java:484)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:184)
	at org.apache.hadoop.mapred.$Proxy0.statusUpdate(Unknown Source)
	at org.apache.hadoop.mapred.Task$1.run(Task.java:293)
	at java.lang.Thread.run(Thread.java:619)

2007-10-18 17:45:40,258 INFO org.apache.hadoop.mapred.TaskRunner: Process Thread Dump: Communication exception
8 active threads
Thread 13 (Comm thread for task_200710172336_0016_m_000071_0):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 4128
  Stack:
    sun.management.ThreadImpl.getThreadInfo0(Native Method)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:147)
    sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:123)
    org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:114)
    org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:162)
    org.apache.hadoop.mapred.Task$1.run(Task.java:315)
    java.lang.Thread.run(Thread.java:619)
Thread 12 (org.apache.hadoop.dfs.DFSClient$LeaseChecker@141b571):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6403
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.dfs.DFSClient$LeaseChecker.run(DFSClient.java:558)
    java.lang.Thread.run(Thread.java:619)
Thread 9 (IPC Client connection to /127.0.0.1:49458):
  State: RUNNABLE
  Blocked count: 21
  Waited count: 2063
  Stack:
    java.net.SocketInputStream.socketRead0(Native Method)
    java.net.SocketInputStream.read(SocketInputStream.java:129)
    java.io.FilterInputStream.read(FilterInputStream.java:116)
    org.apache.hadoop.ipc.Client$Connection$1.read(Client.java:181)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
    java.io.BufferedInputStream.read(BufferedInputStream.java:237)
    java.io.DataInputStream.readInt(DataInputStream.java:370)
    org.apache.hadoop.ipc.Client$Connection.run(Client.java:258)
Thread 8 (org.apache.hadoop.io.ObjectWritable Connection Culler):
  State: TIMED_WAITING
  Blocked count: 0
  Waited count: 6402
  Stack:
    java.lang.Thread.sleep(Native Method)
    org.apache.hadoop.ipc.Client$ConnectionCuller.run(Client.java:404)
Thread 4 (Signal Dispatcher):
  State: RUNNABLE
  Blocked count: 0
  Waited count: 0
  Stack:
Thread 3 (Finalizer):
  State: WAITING
  Blocked count: 398
  Waited count: 2270
  Waiting on java.lang.ref.ReferenceQueue$Lock@c278b5
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:116)
    java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:132)
    java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:159)
Thread 2 (Reference Handler):
  State: WAITING
  Blocked count: 257
  Waited count: 2269
  Waiting on java.lang.ref.Reference$Lock@1c66ec7
  Stack:
    java.lang.Object.wait(Native Method)
    java.lang.Object.wait(Object.java:485)
    java.lang.ref.Reference$ReferenceHandler.run(Reference.java:116)
Thread 1 (main):
  State: RUNNABLE
  Blocked count: 1
  Waited count: 10
  Stack:
    java.io.FileInputStream.readBytes(Native Method)
    java.io.FileInputStream.read(FileInputStream.java:199)
    org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.read(RawLocalFileSystem.java:105)
    java.io.BufferedInputStream.fill(BufferedInputStream.java:218)
    java.io.BufferedInputStream.read1(BufferedInputStream.java:258)
    java.io.BufferedInputStream.read(BufferedInputStream.java:317)
    java.io.DataInputStream.read(DataInputStream.java:132)
    org.apache.hadoop.fs.FSInputChecker.readFully(FSInputChecker.java:378)
    org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.readChunk(ChecksumFileSystem.java:200)
    org.apache.hadoop.fs.FSInputChecker.readChecksumChunk(FSInputChecker.java:234)
    org.apache.hadoop.fs.FSInputChecker.fill(FSInputChecker.java:176)
    org.apache.hadoop.fs.FSInputChecker.read1(FSInputChecker.java:193)
    org.apache.hadoop.fs.FSInputChecker.read(FSInputChecker.java:157)
    org.apache.hadoop.fs.FSInputChecker.readFully(FSInputChecker.java:378)
    org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:359)
    org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.seek(ChecksumFileSystem.java:254)
    org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:37)
    org.apache.hadoop.io.SequenceFile$Reader.seek(SequenceFile.java:1793)
    org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1217)
    org.apache.hadoop.io.SequenceFile$Reader.(SequenceFile.java:1142)

2007-10-18 17:45:40,258 WARN org.apache.hadoop.mapred.TaskRunner: Last retry, killing task_200710172336_0016_m_000071_0


Log of task that could not start:
2007-10-18 17:43:55,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 1 time(s).
2007-10-18 17:43:56,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 2 time(s).
2007-10-18 17:43:57,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 3 time(s).
2007-10-18 17:43:58,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 4 time(s).
2007-10-18 17:43:59,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 5 time(s).
2007-10-18 17:44:00,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 6 time(s).
2007-10-18 17:44:01,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 7 time(s).
2007-10-18 17:44:02,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 8 time(s).
2007-10-18 17:44:03,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 9 time(s).
2007-10-18 17:44:04,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: /127.0.0.1:53972. Already tried 10 time(s)."
MAPREDUCE-13,Mapper failed due to out of memory,"
When a map/reduce job takes block compressed sequence files as input, 
the input data may be expanded significantly in size (a few to tens X, depending on
the compression ratio of the particular data blocks in the files).
This may cause out of memory problem in mappers.

In my case, I set heap space to 1GB.
The mappers started to fail when the accumulated expanded input size reaches above 300MB
 
"
MAPREDUCE-12,Tasks execed by the task controller shouldn't inherit tasktracker groups,"Mapred tasks process seem to inherit the group list from the TaskTracker daemon instead of the task owner. 

tom   26633 15736  0 21:33 ?        00:00:02 /usr/bin/java  ...  org.apache.hadoop.mapred.Child 127.0.0.1 51207 ..
mapred   15736     1  2 Apr08 ?        03:54:59 /usr/bin/java ... org.apache.hadoop.mapred.TaskTracker

hadoop1:~$ id mapred
uid=50589(mapred) gid=100(users) groups=100(users),20001(hadoop)
hadoop1:~$ fgrep Groups /proc/26633/status
Groups: 100 20001 
hadoop1:~$ id tom
uid=47765(tom) gid=100(users) groups=100(users),10764(ninjas)

org.apache.hadoop.mapred.LinuxTaskController should set the user supplimentary group list. "
MAPREDUCE-11,Cleanup JobHistory file naming to do with job recovery,"The JobTracker uses the job history files for doing job recovery upon startup. To handle cases where JobTracker goes down again while the recovered job is running, there is some logic that plays with files and it ends up having two history files for some window of time during the life of the job - actual history file, .recover file. The idea being that upon the next restart we should be able to the maximal number of events for the job. It led to performance problems in the job submission / recovery (part of which got addressed in HADOOP-4372). It also looks pretty unlikely that a running job will traverse across multiple JT restarts. Even if it did, without the .recover file, it'd only mean that we lose some tasks that got completed in a subsequent restart. I propose that we remove the .recover file logic and base the recovery on only the original job history file. "
MAPREDUCE-10,NPE in SocketChannelOutputStream during large sort benchmark,"Running sort benchmark, I saw this NPE trace in the JobTracker log

...
2007-02-04 02:07:23,753 INFO org.apache.hadoop.mapred.JobInProgress: Already complete TIP tip_0002_m_032689 has completed task task_0002_m_032689_2
2007-02-04 02:07:23,753 INFO org.apache.hadoop.mapred.TaskInProgress: Task 'task_0002_m_032689_2' has completed.
2007-02-04 02:07:24,566 WARN org.apache.hadoop.ipc.Server: handler output errorjava.io.IOException: Connection reset by peer
        at sun.nio.ch.FileDispatcher.write0(Native Method)
        at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:29)
        at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:104)
        at sun.nio.ch.IOUtil.write(IOUtil.java:75)
        at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:302)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.flushBuffer(SocketChannelOutputStream.java:108)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.write(SocketChannelOutputStream.java:89)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:556)
2007-02-04 02:07:24,569 WARN org.apache.hadoop.ipc.Server: handler output error
java.lang.NullPointerException
        at org.apache.hadoop.ipc.SocketChannelOutputStream.flushBuffer(SocketChannelOutputStream.java:108)
        at org.apache.hadoop.ipc.SocketChannelOutputStream.write(SocketChannelOutputStream.java:89)
        at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65)
        at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123)
        at java.io.DataOutputStream.flush(DataOutputStream.java:106)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:556)
2007-02-04 02:07:32,510 INFO org.apache.hadoop.mapred.JobInProgress: Task 'task_0002_m_077715_2' has completed tip_0002_m_077715 successfully.
...
"
MAPREDUCE-9,Path separator in DistributedCache does not work between windows and unix,"DistributedCache.addfileToClassPath adds the files to mapred.job.classpath.files which can be seen in the jobs xml description. When the job is created and submitted from a windows machine the path separator is "";"". This can be seen in the configuration: mapred.job.classpath.files	/user/garo/lib/javolution.jar;/user/garo/lib/java-utils.jar

When the job is submitted over network to a Hadoop cluster running on Linux the path separator is "":"". This affects the DistributedCache.getFileClassPath method which separates the mapred.job.classpath.files configuration using the system path separator, which is "":"". This renders all classpath additions invalid using DistributedCache.addFileToClassPath.

Temporary sollution: I've simply added "";"" to the StringTokenizer in DistributedCache.getFileClassPath, but I'm not certain if it's a good sollution."
MAPREDUCE-8,"""Bad File Descriptor"" in closing local file","Running the sort benchmark, I had a map fail with this exception:

2006-11-28 17:59:36,770 INFO org.apache.hadoop.mapred.TaskInProgress: Error from task_0001_m_001906_0: Map output lost, rescheduling: getMapOutput(task_0001_m_001906_0,786) failed :
java.io.IOException: Bad file descriptor
        at java.io.FileInputStream.close0(Native Method)
        at java.io.FileInputStream.close(FileInputStream.java:245)
        at org.apache.hadoop.fs.LocalFileSystem$LocalFSFileInputStream.close(LocalFileSystem.java:100)
        at java.io.FilterInputStream.close(FilterInputStream.java:159)
        at org.apache.hadoop.fs.FSDataInputStream$Checker.close(FSDataInputStream.java:162)
        at java.io.FilterInputStream.close(FilterInputStream.java:159)
        at java.io.BufferedInputStream.close(BufferedInputStream.java:440)
        at java.io.FilterInputStream.close(FilterInputStream.java:159)
        at org.apache.hadoop.mapred.TaskTracker$MapOutputServlet.doGet(TaskTracker.java:1446)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)
        at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)
        at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)
        at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)
        at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)
        at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)
        at org.mortbay.http.HttpServer.service(HttpServer.java:954)
        at org.mortbay.http.HttpConnection.service(HttpConnection.java:814)
        at org.mortbay.http.HttpConnection.handleNext(HttpConnection.java:981)
        at org.mortbay.http.HttpConnection.handle(HttpConnection.java:831)
        at org.mortbay.http.SocketListener.handleConnection(SocketListener.java:244)
        at org.mortbay.util.ThreadedServer.handle(ThreadedServer.java:357)
        at org.mortbay.util.ThreadPool$PoolThread.run(ThreadPool.java:534)
"
MAPREDUCE-7,Reduce progress in the Reducer crosses 1,"I printed the progress in the {{Progress.java}} for every progress made and I found this scenario
{noformat}
update called for reduce with progress 0.99998355
update called for reduce with progress 0.99998355
update called for reduce with progress 1.0000043
update called for reduce with progress 1.0000043
update called for reduce with progress 1.0000244
{noformat}
Following are the lines I added to get this 
{code:title=Progress.java|borderStyle=solid}
/** Called during execution on a leaf node to set its progress. */
  public synchronized void set(float progress) {
    System.out.println(""update called for "" + status + "" with progress "" + progress);
    this.progress = progress;
  }
{code}

This needs investigation and will also explain why occasionally users see jobs that are complete and their progress less that 100%."
MAPREDUCE-6,Task attempt stopped shuffling and hung the job,"I was running a job and one of the reducer task attempts got stuck during the shuffle phase. The percentage complete froze at 33.1%, and the logs for the attempt looked like:

2009-04-29 15:21:24,431 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0: Got 0 new map-outputs & number of known map outputs is 0
2009-04-29 15:21:24,431 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
2009-04-29 15:22:24,580 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Need another 1 map output(s) where 0 is already in progress
2009-04-29 15:22:24,581 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0: Got 0 new map-outputs & number of known map outputs is 0
2009-04-29 15:22:24,581 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
2009-04-29 15:23:24,692 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Need another 1 map output(s) where 0 is already in progress
2009-04-29 15:23:24,693 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0: Got 0 new map-outputs & number of known map outputs is 0
2009-04-29 15:23:24,693 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
2009-04-29 15:24:24,718 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Need another 1 map output(s) where 0 is already in progress
2009-04-29 15:24:24,718 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0: Got 0 new map-outputs & number of known map outputs is 0
2009-04-29 15:24:24,719 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)
2009-04-29 15:25:24,742 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Need another 1 map output(s) where 0 is already in progress
2009-04-29 15:25:24,743 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0: Got 0 new map-outputs & number of known map outputs is 0
2009-04-29 15:25:24,743 INFO org.apache.hadoop.mapred.ReduceTask: attempt_200904250602_2468_r_000024_0 Scheduled 0 of 0 known outputs (0 slow hosts and 0 dup hosts)

The mappers and other reducers were long finished. When I manually killed the task attempt process after 20 minutes of seeing it frozen, it restarted on another machine and succeeded just fine.
"
MAPREDUCE-5,"Shuffle's getMapOutput() fails with EofException, followed by IllegalStateException","During the shuffle phase, I'm seeing a large sequence of the following actions:

1) WARN org.apache.hadoop.mapred.TaskTracker: getMapOutput(attempt_200905181452_0002_m_000010_0,0) failed : org.mortbay.jetty.EofException
2) WARN org.mortbay.log: Committed before 410 getMapOutput(attempt_200905181452_0002_m_000010_0,0) failed : org.mortbay.jetty.EofException
3) ERROR org.mortbay.log: /mapOutput java.lang.IllegalStateException: Committed

The map phase completes with 100%, and then the reduce phase crawls along with the above errors in each of the TaskTracker logs.  None of the tasktrackers get lost.  When I run non-data jobs like the 'pi' test from the example jar, everything works fine."
MAPREDUCE-4,TestJobTrackerRestart.testJobRecoveryWithEmptyHistory doesnt test the expected,"The test uses TestEmptyJob.CommitterWithDelayCleanup to delay cleanup. But the committer requires configuration property ""share"" to be set, which is not done in the test. So, cleanup fails in the test instead of getting delayed. 
Test should have an assert for Job is successful in the end. "
MAPREDUCE-3,"Set mapred.child.ulimit automatically to the value of the RAM limits for a job, if they are set","Memory based monitoring and scheduling allow users to set memory limits for the tasks of their jobs. This parameter is the total memory taken by the task, and any children it may launch (for e.g. in the case of streaming). A related parameter is mapred.child.ulimit which is a hard limit on the memory used by a single process of the entire task tree. For user convenience, it would be sensible for the system to set the ulimit to atleast the memory required by the task, if the user has specified the latter."
MAPREDUCE-2,ArrayOutOfIndex error in KeyFieldBasedPartitioner on empty key,"When using KeyFieldBasedPartitioner, if the record doesn't contain the specified field, the endChar would equal with array.length, which throw ArrayOutOfIndex exception, losing that record!"
MAPREDUCE-1,Hadoop  mapreduce should always ship the jar file(s) specified by the user,"when I run a hadoop job like:

    bin/hadoop jar myjar org.apache.hadoop.mapred.lib.aggregate.ValueAggregatorJob other_args

myjar is not shipped. The job failed because the class loader cannot find the classes specified in myjar.

"
